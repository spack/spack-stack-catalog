2lambda123/CHM:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: 2lambda123/CHM
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">The Canadian Hydrological Model</h1><a id=\"user-content-the-canadian-hydrological-model\"\
    \ class=\"anchor\" aria-label=\"Permalink: The Canadian Hydrological Model\" href=\"\
    #the-canadian-hydrological-model\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>The Canadian Hydrological Model (CHM) is\
    \ a novel modular unstructured mesh based approach for hydrological modelling.\
    \ It can move between spatial scale, temporal scale, and spatial extents. It is\
    \ designed for developing and testing process representations for hydrological\
    \ models.</p>\n\n<ul>\n<li><a href=\"#usage\">Usage</a></li>\n<li><a href=\"#motivation\"\
    >Motivation</a></li>\n<li><a href=\"#design-goals\">Design goals</a></li>\n<li><a\
    \ href=\"#publications\">Publications</a></li>\n<li>\n<a href=\"#features\">Features</a>\n\
    <ul>\n<li><a href=\"#spatial-scales\">Spatial Scales</a></li>\n<li><a href=\"\
    #visualization\">Visualization</a></li>\n<li><a href=\"#netcdf-support\">netCDF\
    \ support</a></li>\n<li><a href=\"#process-representations\">Process representations</a></li>\n\
    <li><a href=\"#unstructured-mesh\">Unstructured mesh</a></li>\n<li><a href=\"\
    #parallel-computing\">Parallel computing</a></li>\n<li><a href=\"#uncertainty-analysis\"\
    >Uncertainty analysis</a></li>\n</ul>\n</li>\n<li>\n<a href=\"#demonstration\"\
    >Demonstration</a>\n<ul>\n<li><a href=\"#snowcast\">SnowCast</a></li>\n<li><a\
    \ href=\"#large-extent\">Large extent</a></li>\n<li><a href=\"#point-scale\">Point\
    \ scale</a></li>\n<li><a href=\"#blowing-snow\">Blowing snow</a></li>\n</ul>\n\
    </li>\n</ul>\n\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Usage</h1><a id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink:\
    \ Usage\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Details on how to use CHM, as well as more implimentation\
    \ details, can be found in the <a href=\"https://chm.readthedocs.io/en/dev/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n<div class=\"markdown-heading\"><h1\
    \ class=\"heading-element\">Motivation</h1><a id=\"user-content-motivation\" class=\"\
    anchor\" aria-label=\"Permalink: Motivation\" href=\"#motivation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Modelling of hydrological\
    \ processes at any scale is hampered by large uncertainties in parameters and\
    \ forcing data, incomplete process representations (the scientific conceptualization\
    \ of a phenomena codified numerically), and arbitrary process representation selections\
    \ and linkages (collectively \u2018model structure\u2019). There is also consistent\
    \ difficulty or an inability to easily test and estimate the uncertainty due to\
    \ variations in model structure, parameter values, number of parameters, forcing\
    \ data requirements, and spatial discretization requirements (collectively \u2018\
    model complexity\u2019).</p>\n<p>In this work, a new distributed model framework\
    \ is presented that can examine a variety of process representations, process\
    \ linkages and levels of model complexity. Algorithms can be easily interchanged,\
    \ removed, and decoupled while preserving the underlying model framework. Thus,\
    \ uncertainty propagation and subsequent feedbacks within the model structure\
    \ can be quantified. Unstructured meshes represent the spatial heterogeneity of\
    \ surface and sub-surface features in a computationally efficient manner and also\
    \ decreases number of parameters and initial conditions. The parallel architecture\
    \ allows for efficient uncertainty testing of parameter ranges. By utilizing unstructured\
    \ meshes, fewer than 5% of the computational elements of high-resolution structured\
    \ (raster) grids are usually necessary.  This preserves surface and sub-surface\
    \ heterogeneity but results in fewer parameters and initial conditions.</p>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Design goals</h1><a\
    \ id=\"user-content-design-goals\" class=\"anchor\" aria-label=\"Permalink: Design\
    \ goals\" href=\"#design-goals\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<ul>\n<li>Multi-scale, multi-physics, variable complexity\
    \ and domain model</li>\n<li>Assessment of model structural, parameter, and data\
    \ uncertainty</li>\n<li>Easily test multiple hypotheses, avoid rigid model structures</li>\n\
    <li>Incorporate existing code</li>\n<li>Contribute to decision support systems</li>\n\
    </ul>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\">Publications</h1><a\
    \ id=\"user-content-publications\" class=\"anchor\" aria-label=\"Permalink: Publications\"\
    \ href=\"#publications\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The following publications provide an overview of CHM and\
    \ its capabilities</p>\n<ul>\n<li>V. Vionnet, Marsh, C.B., B. Menounos, S. Gascoin,\
    \ N.E. Wayand, J. Shea, K. Mukherjee, and J.W. Pomeroy. Multi-scale snowdrift-permitting\
    \ modelling of mountain snowpack. The Cryosphere Discussions, 2020:1--43, 2020.</li>\n\
    <li>Marsh, C.B., J.W. Pomeroy, and H.S. Wheater. The Canadian Hydrological Model\
    \ (CHM) v1.0: a multi-scale, multi-extent, variable-complexity hydrological model\
    \ \u2013 design and overview. Geoscientific Model Development, 13(1):225--247,\
    \ 2020.</li>\n<li>Marsh, C.B, J. W. Pomeroy, R.J. Spiteri, and H.S Wheater. A\
    \ Finite Volume Blowing Snow Model for Use With Variable Resolution Meshes. Water\
    \ Resources Research, 56(2), 2020.</li>\n<li>Marsh, C.B, R. J. Spiteri, J.W. Pomeroy,\
    \ and H.S. Wheater. Multi-objective unstructured triangular mesh generation for\
    \ use in hydrological and land surface models. Computers &amp; Geosciences, 119:49--67,\
    \ 2018.</li>\n</ul>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Features</h1><a id=\"user-content-features\" class=\"anchor\" aria-label=\"Permalink:\
    \ Features\" href=\"#features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Spatial Scales</h2><a id=\"user-content-spatial-scales\" class=\"anchor\" aria-label=\"\
    Permalink: Spatial Scales\" href=\"#spatial-scales\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>CHM is applicable to multiple\
    \ scales from the basin scale, to the provincial/state scale and beyond. It may\
    \ also be applied at a single point-scale.\n<a target=\"_blank\" rel=\"noopener\
    \ noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Visualization</h2><a id=\"user-content-visualization\"\
    \ class=\"anchor\" aria-label=\"Permalink: Visualization\" href=\"#visualization\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Output is in the vtu file format, allowing for visualization, analysis, and\
    \ timeseries animation in <a href=\"https://www.paraview.org/\" rel=\"nofollow\"\
    >ParaView</a>. Date-time support has been added to ParaView via an filter <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\"\
    ><img src=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\" alt=\"\
    vtk-paraview-datetimefilter\" style=\"max-width: 100%;\"></a>.</p>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">netCDF support</h2><a id=\"user-content-netcdf-support\"\
    \ class=\"anchor\" aria-label=\"Permalink: netCDF support\" href=\"#netcdf-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Input meterology may be either in a standard ASCII file, or as a netCDF file\
    \ allowing for ease of use when using climate model outputs.</p>\n<p>The below\
    \ figure shows virtual stations that correspond to the center of the 2.5 km GEM\
    \ numerical weather prediction output in netCDF format.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Process representations</h2><a id=\"user-content-process-representations\"\
    \ class=\"anchor\" aria-label=\"Permalink: Process representations\" href=\"#process-representations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Process represetenation will be extented to include the entirety of the hydrological\
    \ cycle. However, current representation includes mostly surface and cold regions\
    \ processes</p>\n<table>\n<thead>\n<tr>\n<th>Process</th>\n<th>Module</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>Canopy</td>\n<td>Open/forest (exp/log) (Pomeroy et\
    \ al., 1998; Ellis et al., 2010)</td>\n</tr>\n<tr>\n<td>Snowpack</td>\n<td>2-layer\
    \ Snobal (Marks et al, 1999); Multi-layer Snowpack (Lehning et al., 1999); Various\
    \ albedo e.g., CLASS (Verseghy 1991)</td>\n</tr>\n<tr>\n<td>Soil</td>\n<td>Frozen\
    \ soil infiltration (Gray et al., 2001)</td>\n</tr>\n<tr>\n<td>Mass redistribution</td>\n\
    <td>PBSM3D (Marsh et al, 2018 in review); Snowslide (Bernhardt 2010)</td>\n</tr>\n\
    </tbody>\n</table>\n<p>Input meterology is spatially interpolated and down-scaled\
    \ from the input station or virtual-station (e.g., from numerical weather prediction)\
    \ to produce a spatially distributed driving dataset. There are a number of ways\
    \ to downscale these meterology.</p>\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n\
    <th>Type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Air temperature</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant, neutral stability) (Kunkel, 1989,\
    \ Dodson et al., 1997)</td>\n</tr>\n<tr>\n<td>Relative humidity</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant) (Kunkel, 1989)</td>\n</tr>\n<tr>\n\
    <td>Horizontal wind</td>\n<td>Topographic curvature (Liston, et al., 2006); Mason-Sykes\
    \ (Mason and Sykes, 1979); uniform wind</td>\n</tr>\n<tr>\n<td>Precipitation</td>\n\
    <td>Elevation based lapse (Thornton, 1997)</td>\n</tr>\n<tr>\n<td>Precipitation\
    \ Phase</td>\n<td>Linear; Psychometric (Harder and Pomeroy, 2013); Threshold</td>\n\
    </tr>\n<tr>\n<td>Solar radiation</td>\n<td>Terrain shadows (Marsh et al., 2011,\
    \ Dozier and Frew, 1990); Clear sky transmittance (Burridge, 1975); Transmittance\
    \ from observations; Cloud fraction estimates (Walcek, 1994); Direct/diffuse splitting\
    \ (Iqbal, 19xx)</td>\n</tr>\n<tr>\n<td>Longwave</td>\n<td>T, RH based (Sicart\
    \ et al., 2006); Constant (Marty et al., 2002)</td>\n</tr>\n</tbody>\n</table>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Unstructured mesh</h2><a\
    \ id=\"user-content-unstructured-mesh\" class=\"anchor\" aria-label=\"Permalink:\
    \ Unstructured mesh\" href=\"#unstructured-mesh\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>CHM uses an unstructured triangular\
    \ mesh to representent the terrain. This mesh is generated by <a target=\"_blank\"\
    \ rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/mesher\"><img\
    \ src=\"https://github.com/Chrismarsh/mesher\" alt=\"Mesher\" style=\"max-width:\
    \ 100%;\"></a>, a novel multi-objective unstructured mesh generation software\
    \ that allows mesh generation to be generated from an arbitrary number of hydrologically\
    \ important features while maintaining a variable spatial resolution. Triangle\
    \ quality is guaranteed as well as a smooth graduation from small to large triangles.\
    \ Including these additional features resulted in a better representation of spatial\
    \ heterogeneity versus classic topography-only mesh generation while significantly\
    \ reducing the total number of computational elements.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Parallel computing</h2><a id=\"user-content-parallel-computing\"\
    \ class=\"anchor\" aria-label=\"Permalink: Parallel computing\" href=\"#parallel-computing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>In CHM, parallelism is currently implemented via the shared memory API OpenMP.\
    \ As described above, modules may either be point-scale models that are applied\
    \ to each triangle independently or require knowledge of the surrounding triangles.\
    \ Mixing these two types of parallelism complicates the implementation of parallel\
    \ code. To provide as much seamless parallelism as possible to the modules, each\
    \ module declares the type of algorithm it is: data parallel or domain parallel.\
    \ Data parallel modules are point-scale models that are applied to every triangle.\
    \ Domain parallel modules are modules that require knowledge of surrounding mesh\
    \ points. Thus, after the topological sort is performed to determine module execution\
    \ order, the modules are scheduled together into groups that share a parallelism\
    \ type</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Uncertainty\
    \ analysis</h2><a id=\"user-content-uncertainty-analysis\" class=\"anchor\" aria-label=\"\
    Permalink: Uncertainty analysis\" href=\"#uncertainty-analysis\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>A key feature of CHM\
    \ is the ability to, on the command line, change any value specified by a configuration\
    \ parameter. CHM provides a seamless mechanism to easily allow modules to obtain\
    \ parameter data from configuration files.</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">subprocess</span>\n\
    <span class=\"pl-k\">import</span> <span class=\"pl-s1\">shutil</span>\n\n\n<span\
    \ class=\"pl-s1\">prj_path</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s\">\"CHM.config\"</span>\n\n<span class=\"pl-s1\">cf1</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s\">\"-c output.VistaView.file:vv_dodson.txt\"\
    </span>\n<span class=\"pl-s1\">cf2</span> <span class=\"pl-c1\">=</span> <span\
    \ class=\"pl-s\">\"-c output.UpperClearing.file:uc_dodson.txt\"</span>\n<span\
    \ class=\"pl-s1\">cf3</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\"\
    >\"-c output.FiserraRidge.file:fr_dodson.txt\"</span>\n<span class=\"pl-s1\">cf4</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"--add-module Dodson_NSA_ta\"\
    </span>\n<span class=\"pl-s1\">subprocess</span>.<span class=\"pl-en\">check_call</span>([<span\
    \ class=\"pl-s\">'./CHM %s %s %s %s %s'</span> <span class=\"pl-c1\">%</span>\
    \ (<span class=\"pl-s1\">prj_path</span>, <span class=\"pl-s1\">cf1</span>, <span\
    \ class=\"pl-s1\">cf2</span>, <span class=\"pl-s1\">cf3</span>,<span class=\"\
    pl-s1\">cf4</span>)], <span class=\"pl-s1\">shell</span><span class=\"pl-c1\"\
    >=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Demonstration</h1><a id=\"user-content-demonstration\"\
    \ class=\"anchor\" aria-label=\"Permalink: Demonstration\" href=\"#demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">SnowCast</h2><a\
    \ id=\"user-content-snowcast\" class=\"anchor\" aria-label=\"Permalink: SnowCast\"\
    \ href=\"#snowcast\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a href=\"http://www.snowcast.ca\" rel=\"nofollow\">SnowCast</a>\
    \ is an experimental, daily data product that uses the Global Environmental Multiscale\
    \ (GEM) model forecasts from Environment and Climate Change Canada (ECCC) to drive\
    \ the Canadian Hydrological Model (CHM). Estimates of snowpack are provided over\
    \ the a Bow River Basin, centered over Banff, Canada.</p>\n<p>SnowCast is developed\
    \ as part of <a href=\"https://gwf.usask.ca/\" rel=\"nofollow\">Global Water Futures</a>\
    \ and the <a href=\"https://www.usask.ca/hydrology/\" rel=\"nofollow\">Centre\
    \ for Hydrology</a>, University of Saskatchewan.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Large extent</h2><a id=\"user-content-large-extent\"\
    \ class=\"anchor\" aria-label=\"Permalink: Large extent\" href=\"#large-extent\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Hourly solar radiation modelling for the territory of Yukon, Canada.\n<a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Point scale</h2><a id=\"user-content-point-scale\"\
    \ class=\"anchor\" aria-label=\"Permalink: Point scale\" href=\"#point-scale\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Comparison of CHM driving Snobal and Snowpack at the Upper Clearing site at\
    \ Marmot Creek Research Basin in Alberta, Canada\n<a target=\"_blank\" rel=\"\
    noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Blowing snow</h2><a id=\"user-content-blowing-snow\"\
    \ class=\"anchor\" aria-label=\"Permalink: Blowing snow\" href=\"#blowing-snow\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Blowing snow for a small sub-basin of Wolf Creek Reserach Basin, located in\
    \ the Yukon, Canada.\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\"\
    \ href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1701550455.0
2lambda123/ComputationalRadiationPhysics-picongpu:
  data_format: 2
  description: null
  filenames:
  - etc/picongpu/karolina-it4i/spack/spack.yaml
  full_name: 2lambda123/ComputationalRadiationPhysics-picongpu
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">PIConGPU\
    \ - Particle-in-Cell Simulations for the Exascale Era</h1><a id=\"user-content-picongpu---particle-in-cell-simulations-for-the-exascale-era\"\
    \ class=\"anchor\" aria-label=\"Permalink: PIConGPU - Particle-in-Cell Simulations\
    \ for the Exascale Era\" href=\"#picongpu---particle-in-cell-simulations-for-the-exascale-era\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a href=\"https://gitlab.com/hzdr/crp/picongpu/pipelines/dev/latest\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/125203476855eed65aafe582a647b1069957d7712afc8bf5ef3a898bc949a2f7/68747470733a2f2f6769746c61622e636f6d2f687a64722f6372702f7069636f6e6770752f6261646765732f6465762f706970656c696e652e7376673f6b65795f746578743d646576\"\
    \ alt=\"Code Status dev\" data-canonical-src=\"https://gitlab.com/hzdr/crp/picongpu/badges/dev/pipeline.svg?key_text=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"http://picongpu.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9cea3b90b922dc6f00ab2c48c4bfef19c2a640766193239c29c07c84a48f12ca/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7069636f6e6770752f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/picongpu/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"http://computationalradiationphysics.github.io/picongpu\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2a4731ccf21a72c7b8100ae71e23e31c0f321f009bc22bc2072d63e152c18955/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c75652e737667\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://isocpp.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/e7fb0089d24cbec0919fda1a3406c2bb3ddfc5e6e70c69420c4d6b59e4136f37/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\"\
    \ alt=\"Language\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/gpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a0bd3a0d9faf8801c3f3d2b531d68a18c4f608993d6d2690d5c5674718837d60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c76332d626c75652e7376673f6c6162656c3d5049436f6e475055\"\
    \ alt=\"License PIConGPU\" data-canonical-src=\"https://img.shields.io/badge/license-GPLv3-blue.svg?label=PIConGPU\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e96c3d71824144a10728f6b056d442e94291887c05ccc1f0ce76af5083860fb9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c75652e7376673f6c6162656c3d504d616363\"\
    \ alt=\"License PMacc\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue.svg?label=PMacc\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"http://www.youtube.com/watch?v=nwZuG-XtUDE\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1c697bed4b1ee228f398a1f1d9f6ca347a03622cf9081a9de5a05a4aafb26429/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6e775a75472d58745544452f302e6a7067\"\
    \ alt=\"PIConGPU Presentation Video\" data-canonical-src=\"http://img.youtube.com/vi/nwZuG-XtUDE/0.jpg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"http://www.youtube.com/watch?v=nwZuG-XtUDE\"\
    \ rel=\"nofollow\"><img src=\"docs/logo/pic_logo_vert_158x360.png\" alt=\"PIConGPU\
    \ Release\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Introduction</h2><a id=\"user-content-introduction\"\
    \ class=\"anchor\" aria-label=\"Permalink: Introduction\" href=\"#introduction\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>PIConGPU is a fully relativistic,\n<a href=\"https://en.wikipedia.org/wiki/Manycore_processor\"\
    \ rel=\"nofollow\">manycore</a>,\n3D3V particle-in-cell (<a href=\"http://en.wikipedia.org/wiki/Particle-in-cell\"\
    \ rel=\"nofollow\">PIC</a>)\ncode. The Particle-in-Cell algorithm is a central\
    \ tool in plasma physics.\nIt describes the dynamics of a plasma by computing\
    \ the motion of\nelectrons and ions in the plasma based on\n<a href=\"http://en.wikipedia.org/wiki/Maxwell%27s_equations\"\
    \ rel=\"nofollow\">Maxwell's equations</a>.</p>\n<p>PIConGPU implements various\
    \ numerical schemes to solve the PIC cycle.\nIts features for the electro-magnetic\
    \ PIC algorithm include:</p>\n<ul>\n<li>a central or Yee-lattice for fields</li>\n\
    <li>particle pushers that solve the equation of motion for charged and neutral\n\
    particles, e.g., the <em>Boris-</em> and the\n<a href=\"http://dx.doi.org/10.1063/1.2837054\"\
    \ rel=\"nofollow\"><em>Vay-Pusher</em></a>\n</li>\n<li>Maxwell field solvers,\
    \ e.g.\n<a href=\"http://dx.doi.org/10.1109/TAP.1966.1138693\" rel=\"nofollow\"\
    ><em>Yee's</em></a> and\n<a href=\"http://dx.doi.org/10.1103/PhysRevSTAB.16.021301\"\
    \ rel=\"nofollow\"><em>Lehe's</em></a> scheme</li>\n<li>rigorously charge conserving\
    \ current deposition schemes, such as\n<a href=\"http://dx.doi.org/10.1016/S0010-4655%2800%2900228-9\"\
    \ rel=\"nofollow\"><em>Esirkepov</em></a>\nand <em>EZ</em> (Esirkepov meets ZigZag)</li>\n\
    <li>macro-particle form factors ranging from NGP (0th order), CIC (1st),\nTSC\
    \ (2nd), PQS (3rd) to PCS (4th)</li>\n</ul>\n<p>and the electro-magnetic PIC algorithm\
    \ is further self-consistently coupled to:</p>\n<ul>\n<li>classical radiation\
    \ reaction\n(<a href=\"http://dx.doi.org/10.1016/j.cpc.2016.04.002\" rel=\"nofollow\"\
    >DOI:10.1016/j.cpc.2016.04.002</a>)</li>\n<li>advanced field ionization methods\n\
    (<a href=\"http://dx.doi.org/10.1103/PhysRevA.59.569\" rel=\"nofollow\">DOI:10.1103/PhysRevA.59.569</a>,\n\
    <a href=\"http://www.jetp.ac.ru/cgi-bin/dn/e_020_05_1307.pdf\" rel=\"nofollow\"\
    >LV Keldysh</a>, BSI)</li>\n</ul>\n<p>Besides the electro-magnetic PIC algorithm\
    \ and extensions to it, we developed\na wide range of tools and diagnostics, e.g.:</p>\n\
    <ul>\n<li>online, far-field radiation diagnostics for coherent and incoherent\
    \ radiation\nemitted by charged particles</li>\n<li>full restart and output capabilities\
    \ via <a href=\"http://openPMD.org\" rel=\"nofollow\">openPMD</a>,\nincluding\
    \ <a href=\"http://hdfgroup.org/\" rel=\"nofollow\">parallel HDF5</a>\n</li>\n\
    <li>2D and 3D live view and diagnostics tools</li>\n<li>a large selection of extensible\n\
    <a href=\"http://picongpu.readthedocs.io/en/latest/usage/plugins.html\" rel=\"\
    nofollow\">online-plugins</a>\n</li>\n</ul>\n<p>As one of our supported compute\
    \ platforms, GPUs provide a computational\nperformance of several\n<a href=\"\
    http://en.wikipedia.org/wiki/FLOPS\" rel=\"nofollow\">TFLOP/s</a> at considerable\
    \ lower invest and\nmaintenance costs compared to multi CPU-based compute architectures\
    \ of similar\nperformance. The latest high-performance systems\n(<a href=\"http://www.top500.org/\"\
    \ rel=\"nofollow\">TOP500</a>) are enhanced by accelerator hardware that\nboost\
    \ their peak performance up to the multi-PFLOP/s level. With its\noutstanding\
    \ performance and scalability to more than 18'000 GPUs,\nPIConGPU was one of the\
    \ <strong>finalists</strong> of the 2013\n<a href=\"http://sc13.supercomputing.org/content/acm-gordon-bell-prize\"\
    \ rel=\"nofollow\">Gordon Bell Prize</a>.</p>\n<p>PIConGPU is developed and maintained\
    \ by the\n<a href=\"https://www.hzdr.de/db/Cms?pNid=2097\" rel=\"nofollow\">Computational\
    \ Radiation Physics Group</a>\nat the <a href=\"http://www.hzdr.de/db/Cms?pNid=132\"\
    \ rel=\"nofollow\">Institute for Radiation Physics</a>\nat <a href=\"http://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> in close collaboration with the Center\nfor Information\
    \ Services and High Performance Computing\n(<a href=\"http://tu-dresden.de/die_tu_dresden/zentrale_einrichtungen/zih\"\
    \ rel=\"nofollow\">ZIH</a>) of the\nTechnical University Dresden (<a href=\"http://www.tu-dresden.de\"\
    \ rel=\"nofollow\">TUD</a>). We are a\nmember of the <a href=\"http://ccoe-dresden.de/\"\
    \ rel=\"nofollow\">Dresden GPU Center of Excellence</a> that\ncooperates on a\
    \ broad range of scientific GPU and manycore applications,\nworkshops and teaching\
    \ efforts.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Attribution</h2><a id=\"user-content-attribution\" class=\"anchor\" aria-label=\"\
    Permalink: Attribution\" href=\"#attribution\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>PIConGPU is a <em>scientific project</em>.\
    \ If you <strong>present and/or publish</strong> scientific\nresults that used\
    \ PIConGPU, you should set a <strong>reference</strong> to show your support.</p>\n\
    <p>Our according <strong>up-to-date publication</strong> at <strong>the time of\
    \ your publication</strong>\nshould be inquired from:</p>\n<ul>\n<li><a href=\"\
    https://raw.githubusercontent.com/ComputationalRadiationPhysics/picongpu/master/REFERENCE.md\"\
    \ rel=\"nofollow\">REFERENCE.md</a></li>\n</ul>\n<p>Please also consider adding\
    \ yourself to our <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu-communitymap\"\
    >community map</a>.\nWe would love to hear from you!</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Oral Presentations</h2><a id=\"user-content-oral-presentations\"\
    \ class=\"anchor\" aria-label=\"Permalink: Oral Presentations\" href=\"#oral-presentations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The following slide should be part of <strong>oral presentations</strong>.\
    \ It is intended to\nacknowledge the team maintaining PIConGPU and to support\
    \ our community:</p>\n<p>(<em>coming soon</em>) presentation_picongpu.pdf\n(svg\
    \ version, key note version, png version: 1920x1080 and 1024x768)</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Software License</h2><a id=\"\
    user-content-software-license\" class=\"anchor\" aria-label=\"Permalink: Software\
    \ License\" href=\"#software-license\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p><em>PIConGPU</em> is licensed under the\
    \ <strong>GPLv3+</strong>. Furthermore, you can develop your\nown particle-mesh\
    \ algorithms based on our general library <em>PMacc</em> that is\nshipped alongside\
    \ PIConGPU. <em>PMacc</em> is <em>dual licensed</em> under both the\n<strong>GPLv3+\
    \ and LGPLv3+</strong>.\nFor a detailed description, please refer to <a href=\"\
    LICENSE.md\">LICENSE.md</a></p>\n<hr>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Install</h2><a id=\"user-content-install\" class=\"anchor\"\
    \ aria-label=\"Permalink: Install\" href=\"#install\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>See our notes in <a href=\"\
    INSTALL.rst\">INSTALL.rst</a>.</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Users</h2><a id=\"user-content-users\" class=\"anchor\" aria-label=\"\
    Permalink: Users\" href=\"#users\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>Dear User, we hereby emphasize that we\
    \ are still actively developing PIConGPU at great\nspeed and do, from time to\
    \ time, break backwards compatibility.</p>\n<p>When using this software, please\
    \ stick to the latest release or use the <code>dev</code> branch containing the\n\
    latest changes. It also contains a file <code>CHANGELOG.md</code> with the\nlatest\
    \ changes (and how to update your simulations). Read it first before\nupdating\
    \ between two versions! Also, we add a git <code>tag</code> according to a version\n\
    number for each release.</p>\n<p>For any questions regarding the usage of PIConGPU\
    \ please <strong>do not</strong> contact the\ndevelopers and maintainers directly.</p>\n\
    <p>Instead, please <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/issues/new\"\
    >open an issue on GitHub</a>.</p>\n<p>Before you post a question, browse the PIConGPU\n\
    <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/search?l=markdown\"\
    >documentation</a>,\n<a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/wiki\"\
    >wiki</a> and the\n<a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/issues\"\
    >issue tracker</a>\nto see if your question has been answered, already.</p>\n\
    <p>PIConGPU is a collaborative project.\nWe thus encourage users to engage in\
    \ answering questions of other users and post solutions to problems to the list.\n\
    A problem you have encountered might be the future problem of another user.</p>\n\
    <p>In addition, please consider using the collaborative features of GitHub if\
    \ you have questions or comments on code or documentation.\nThis will allow other\
    \ users to see the piece of code or documentation you are referring to.</p>\n\
    <p>Main ressources are in our <a href=\"https://picongpu.readthedocs.io\" rel=\"\
    nofollow\">online manual</a>, the <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/wiki\"\
    >user section</a> of our wiki, documentation files in <a href=\"http://commonmark.org/help/\"\
    \ rel=\"nofollow\"><code>.md</code> (Markdown)</a> and <a href=\"http://www.sphinx-doc.org/en/stable/rest.html\"\
    \ rel=\"nofollow\"><code>.rst</code> (reStructuredText)</a> format in this repository\
    \ and a <a href=\"http://www.youtube.com/watch?v=7ybsD8G4Rsk\" rel=\"nofollow\"\
    >getting started video</a>.\nFeel free to visit <a href=\"http://picongpu.hzdr.de\"\
    \ rel=\"nofollow\">picongpu.hzdr.de</a> to learn more about the PIC algorithm.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Software Upgrades</h2><a\
    \ id=\"user-content-software-upgrades\" class=\"anchor\" aria-label=\"Permalink:\
    \ Software Upgrades\" href=\"#software-upgrades\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>PIConGPU ships new and frequent changes\
    \ to the code in the development branch <code>dev</code>.</p>\n<p>From time to\
    \ time we publish a new release\nof PIConGPU. Before you pull the changes in,\
    \ please read our\n<a href=\"CHANGELOG.md\">ChangeLog</a>!\nYou may have to update\
    \ some of your simulation <code>.param</code> and <code>.cfg</code> files by\n\
    hand since PIConGPU is an active project and new features often require changes\n\
    in input files. Additionally, a full description of new features and fixed bugs\n\
    in comparison to the previous release is provided in that file.</p>\n<p>In case\
    \ you decide to use <em>new, potentially buggy and experimental</em> features\n\
    from our <code>dev</code> branch, be aware that you must participate or at least\
    \ follow the development yourself.\nSyntax changes and in-development bugs will\
    \ <em>not</em> be announced outside of their according pull\nrequests and issues.</p>\n\
    <p>Before drafting a new release, we open a new <code>release-*</code> branch\
    \ from <code>dev</code> with\nthe <code>*</code> being the version number of the\
    \ upcoming release. This branch only\nreceives bug fixes (feature freeze) and\
    \ users are welcome to try it out\n(however, the change log and a detailed announcement\
    \ might still be missing in\nit).</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Developers</h2><a id=\"user-content-developers\" class=\"anchor\"\
    \ aria-label=\"Permalink: Developers\" href=\"#developers\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">How to participate</h3><a id=\"user-content-how-to-participate\"\
    \ class=\"anchor\" aria-label=\"Permalink: How to participate\" href=\"#how-to-participate\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>See <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a></p>\n<p>If you like to\
    \ jump in right away, see<br>\n<a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22\"\
    ><img src=\"https://camo.githubusercontent.com/bb0bf342046b4c1bd77a159bc6c94725512f51a78d24f6ff7f021e1e9d04a384/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d7261772f436f6d7075746174696f6e616c526164696174696f6e506879736963732f7069636f6e6770752f676f6f64253230666972737425323069737375652e7376673f636f6c6f723d353663626566\"\
    \ alt=\"open &quot;good first issue&quot; issues\" data-canonical-src=\"https://img.shields.io/github/issues-raw/ComputationalRadiationPhysics/picongpu/good%20first%20issue.svg?color=56cbef\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Active Team</h2><a id=\"user-content-active-team\" class=\"\
    anchor\" aria-label=\"Permalink: Active Team\" href=\"#active-team\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Scientific Supervision</h3><a id=\"user-content-scientific-supervision\"\
    \ class=\"anchor\" aria-label=\"Permalink: Scientific Supervision\" href=\"#scientific-supervision\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>Dr. Michael Bussmann</li>\n</ul>\n<div class=\"markdown-heading\"><h3\
    \ class=\"heading-element\">Maintainers* and core developers</h3><a id=\"user-content-maintainers-and-core-developers\"\
    \ class=\"anchor\" aria-label=\"Permalink: Maintainers* and core developers\"\
    \ href=\"#maintainers-and-core-developers\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<ul>\n<li>Dr. Sergei Bastrakov*</li>\n\
    <li>Finn-Ole Carstens</li>\n<li>Dr. Alexander Debus</li>\n<li>Dr. Marco Garten*</li>\n\
    <li>Dr. Axel Huebl*</li>\n<li>Brian Edward Marre</li>\n<li>Pawel Ordyna</li>\n\
    <li>Dr. Richard Pausch*</li>\n<li>Franz Poeschel</li>\n<li>Dr. Klaus Steiniger*</li>\n\
    <li>Rene Widera*</li>\n</ul>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Former Members, Contributions and Thanks</h3><a id=\"user-content-former-members-contributions-and-thanks\"\
    \ class=\"anchor\" aria-label=\"Permalink: Former Members, Contributions and Thanks\"\
    \ href=\"#former-members-contributions-and-thanks\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>The PIConGPU Team expresses\
    \ its gratitude to:</p>\n<p>Florian Berninger, Heiko Burau, Fabia Dietrich, Robert\
    \ Dietrich, Carlchristian Eckert,\nSimeon Ehrig, Wen Fu, Ph.D., Alexander Grund,\
    \ Sebastian Hahn, Anton Helm, Wolfgang Hoehnig,\nDr.-Ing. Guido Juckeland, Jeffrey\
    \ Kelling, Maximilian Knespel, Dr. Remi Lehe,\nFelix Schmitt, Frank Winkler, Benjamin\
    \ Schneider, Joseph Schuchart, Conrad Schumann,\nStefan Tietze, Marija Vranic,\
    \ Ph.D., Benjamin Worpitz, Erik Zenker,\nSophie Rudat, Sebastian Starke, Alexander\
    \ Matthes, Kseniia Bastrakova,\nBernhard Manfred Gruber, Jakob Trojok, Anton Lebedev,\
    \ Nils Prinz,\nFelix Meyer, Lennert Sprenger, Manhui Wang, Maxence Thevenet, Ilja\
    \ Goethel,\nMika Soren Vo\xDF, Lei Bifeng, Andrei Berceanu, Felix Meyer,\nLennert\
    \ Sprenger and Nico Wrobel.</p>\n<p>Kudos to everyone, mentioned or unmentioned,\
    \ who contributed further in any\nway!</p>\n<hr>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"docs/images/lwfa_iso.png\"><img src=\"docs/images/lwfa_iso.png\"\
    \ alt=\"image of an lwfa\" title=\"LWFA\" style=\"max-width: 100%;\"></a>\n<a\
    \ target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/images/StrongScalingPIConGPU_log.png\"\
    ><img src=\"docs/images/StrongScalingPIConGPU_log.png\" alt=\"image of our strong\
    \ scaling\" title=\"Strong Scaling\" style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1705512140.0
ACCESS-NRI/ACCESS-OM2:
  data_format: 2
  description: 'ACCESS-OM2: ACCESS Ocean-Sea Ice Model'
  filenames:
  - spack.yaml
  full_name: ACCESS-NRI/ACCESS-OM2
  latest_release: 2024.03.0
  readme: '<div class="markdown-heading"><h1 class="heading-element">ACCESS-OM2: ACCESS
    Ocean-Ice Model Release Configurations</h1><a id="user-content-access-om2-access-ocean-ice-model-release-configurations"
    class="anchor" aria-label="Permalink: ACCESS-OM2: ACCESS Ocean-Ice Model Release
    Configurations" href="#access-om2-access-ocean-ice-model-release-configurations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">About the model</h2><a
    id="user-content-about-the-model" class="anchor" aria-label="Permalink: About
    the model" href="#about-the-model"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>ACCESS-OM2 is a global coupled ocean - sea ice model developed by <a href="http://www.cosima.org.au"
    rel="nofollow">COSIMA</a>.</p>

    <p>ACCESS-OM2 consists of the <a href="https://github.com/ACCESS-NRI/MOM5">MOM
    5</a> ocean model, <a href="https://github.com/ACCESS-NRI/cice5">CICE 5</a> sea
    ice model, and a file-based atmosphere called <a href="https://github.com/ACCESS-NRI/libaccessom2">YATM</a>
    coupled together using <a href="https://github.com/ACCESS-NRI/oasis3-mct">OASIS3-MCT
    v2.0</a>. ACCESS-OM2 builds on the ACCESS-OM (<a href="http://www.bom.gov.au/jshess/docs/2013/bi2_hres.pdf"
    rel="nofollow">Bi et al., 2013</a>) and AusCOM (<a href="https://50years.acs.org.au/content/dam/acs/50-years/journals/jrpit/JRPIT39.2.137.pdf"
    rel="nofollow">Roberts et al., 2007</a>; <a href="https://www.cawcr.gov.au/technical-reports/CTR_027.pdf"
    rel="nofollow">Bi and Marsland, 2010</a>) models originally developed at <a href="http://www.csiro.au"
    rel="nofollow">CSIRO</a>.</p>

    <p>The model code, configurations and performance were described in <a href="https://doi.org/10.5194/gmd-13-401-2020"
    rel="nofollow">Kiss et al. (2020)</a>, with further details in the draft <a href="https://github.com/COSIMA/ACCESS-OM2-1-025-010deg-report">ACCESS-OM2
    technical report</a>. The current code and configurations differ from this version
    in a number of ways (biogeochemistry, updated forcing, improvements and bug fixes),
    as described by <a href="https://doi.org/10.1029/2021GL097211" rel="nofollow">Solodoch
    et al. (2022)</a>, <a href="https://dx.doi.org/10.1029/2023JC019697" rel="nofollow">Hayashida
    et al. (2023)</a>, <a href="https://doi.org/10.5194/egusphere-2023-390" rel="nofollow">Menviel
    et al. (2023)</a> and <a href="https://doi.org/10.5194/gmd-2023-123" rel="nofollow">Wang
    et al. (2023)</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Support</h2><a id="user-content-support"
    class="anchor" aria-label="Permalink: Support" href="#support"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p><a href="https://www.access-nri.org.au" rel="nofollow">ACCESS-NRI</a> has assumed
    responsibility for supporting ACCESS-OM2 for the Australian Research Community.
    As part of this support ACCESS-NRI has developed a new build and deployment system
    for ACCESS-OM2 to align with plans for supporting a range of Earth System Models.</p>

    <p>Any questions about ACCESS-NRI releases of ACCESS-OM2 should be done through
    the <a href="https://forum.access-hive.org.au/" rel="nofollow">ACCESS-Hive Forum</a>.
    See the <a href="https://forum.access-hive.org.au/t/access-help-and-support/908"
    rel="nofollow">ACCESS Help and Support topic</a> for details on how to do this.</p>

    <div class="markdown-heading"><h3 class="heading-element">Build</h3><a id="user-content-build"
    class="anchor" aria-label="Permalink: Build" href="#build"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>ACCESS-NRI is using <a href="https://spack.io" rel="nofollow">spack</a>, a
    build from source package manager designed for use with high performance computing.
    This repository contains a <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environment</a> definition file (<a href="https://github.com/ACCESS-NRI/ACCESS-OM2/blob/main/spack.yaml"><code>spack.yaml</code></a>)
    that defines all the essential components of the ACCESS-OM2 model, including exact
    versions.</p>

    <p>Spack automatically builds all the components and their dependencies, producing
    model component executables. Spack already contains support for compiling thousands
    of common software packages. Spack packages for the components in ACCESS-OM2 are
    defined in the <a href="https://github.com/ACCESS-NRI/spack_packages/">spack packages
    repository</a>.</p>

    <p>ACCESS-OM2 is built and deployed automatically to <code>gadi</code> on NCI
    (see below). However it is possible to use spack to compile the model using the
    <code>spack.yaml</code> environment file in this repository. To do so follow the
    <a href="https://forum.access-hive.org.au/t/how-to-build-access-om2-on-gadi/1545"
    rel="nofollow">instructions on the ACCESS Forum for configuring spack on <code>gadi</code></a>.</p>

    <p>Then clone this repository and run the following commands on <code>gadi</code>:</p>

    <div class="highlight highlight-source-shell"><pre>spack env create access-om2
    spack.yaml

    spack env activate access-om2

    spack install</pre></div>

    <p>to create a spack environment called <code>access-om2</code> and build all
    the ACCESS-OM2 components, the locations of which can be found using <code>spack
    find --paths</code>.</p>

    <p>In contrast, the <a href="https://github.com/COSIMA/access-om2">COSIMA ACCESS-OM2
    repository</a> uses <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"
    rel="nofollow">submodules</a> to bring all the code dependencies into a single
    repository and build all the models together.</p>

    <div class="markdown-heading"><h3 class="heading-element">Deployment</h3><a id="user-content-deployment"
    class="anchor" aria-label="Permalink: Deployment" href="#deployment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>ACCESS-OM2 is deployed automatically when a new version of the <a href="https://github.com/ACCESS-NRI/ACCESS-OM2/blob/main/spack.yaml"><code>spack.yaml</code></a>
    file is committed to <code>main</code> or a dedicated <code>backport/VERSION</code>
    branch. All the ACCESS-OM2 components are built using <code>spack</code> on <code>gadi</code>
    and installed under the <a href="https://my.nci.org.au/mancini/project/vk83" rel="nofollow"><code>vk83</code></a>
    project in <code>/g/data/vk83</code>. It is necessary to be a member of <a href="https://my.nci.org.au/mancini/project/vk83"
    rel="nofollow"><code>vk83</code></a> project to use ACCESS-NRI deployments of
    ACCESS-OM2.</p>

    <p>The deployment process also creates a GitHub release with the same tag. All
    releases are available under the <a href="https://github.com/ACCESS-NRI/ACCESS-OM2/releases">Releases
    page</a>. Each release has a changelog and meta-data with detailed information
    about the build and deployment, including:</p>

    <ul>

    <li>paths on <code>gadi</code> to all executables built in the deployment process
    (<code>spack.location</code>)</li>

    <li>a <code>spack.lock</code> file, which is a complete build provenance document,
    listing all the components that were built and their dependencies, versions, compiler
    version, build flags and build architecture</li>

    <li>the environment <code>spack.yaml</code> file used for deployment</li>

    </ul>

    <p>Additionally the deployment creates environment modulefiles, the <a href="https://opus.nci.org.au/display/Help/Environment+Modules"
    rel="nofollow">standard method for deploying software on <code>gadi</code></a>.
    To view available ACCESS-OM2 versions:</p>

    <div class="highlight highlight-source-shell"><pre>module use /g/data/vk83/apps/spack/0.20/release/modules/linux-rocky8-x86_64

    module avail access-om2</pre></div>

    <p>For users of ACCESS-OM2 model configurations released by ACCESS-NRI the exact
    location of the ACCESS-OM2 model executables is not required. Model configurations
    will be updated with new model components when necessary.</p>

    <p>For information on contributing your own fixes to the ACCESS-OM2 <code>spack.yaml</code>,
    see the <a href="./CONTRIBUTING.md">CONTRIBUTING.md</a> file.</p>

    '
  stargazers_count: 5
  subscribers_count: 11
  topics:
  - model
  - ocean
  - sea-ice
  - spack
  updated_at: 1717134304.0
ACCESS-NRI/ACCESS-OM2-BGC:
  data_format: 2
  description: 'ACCESS-OM2-BGC: ACCESS Ocean-Sea Ice Model with WOMBAT Biogeochemistry'
  filenames:
  - spack.yaml
  full_name: ACCESS-NRI/ACCESS-OM2-BGC
  latest_release: 2024.03.0
  readme: '<div class="markdown-heading"><h1 class="heading-element">ACCESS-OM2: ACCESS
    Ocean-Sea Ice Model with WOMBAT Biogeochemistry</h1><a id="user-content-access-om2-access-ocean-sea-ice-model-with-wombat-biogeochemistry"
    class="anchor" aria-label="Permalink: ACCESS-OM2: ACCESS Ocean-Sea Ice Model with
    WOMBAT Biogeochemistry" href="#access-om2-access-ocean-sea-ice-model-with-wombat-biogeochemistry"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">About the model</h2><a
    id="user-content-about-the-model" class="anchor" aria-label="Permalink: About
    the model" href="#about-the-model"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>ACCESS-OM2-BGC is a global coupled ocean - sea ice model with WOMBAT biogeochemistrydeveloped
    by <a href="http://www.cosima.org.au" rel="nofollow">COSIMA</a>.</p>

    <p>ACCESS-OM2-BGC consists of the <a href="https://github.com/ACCESS-NRI/MOM5">MOM
    5</a> ocean model with WOMBAT Biogeochemistry, <a href="https://github.com/ACCESS-NRI/cice5">CICE
    5</a> sea ice model, and a file-based atmosphere called <a href="https://github.com/ACCESS-NRI/libaccessom2">YATM</a>
    coupled together using <a href="https://github.com/ACCESS-NRI/oasis3-mct">OASIS3-MCT
    v2.0</a>. ACCESS-OM2-BGC builds on the ACCESS-OM (<a href="http://www.bom.gov.au/jshess/docs/2013/bi2_hres.pdf"
    rel="nofollow">Bi et al., 2013</a>) and AusCOM (<a href="https://50years.acs.org.au/content/dam/acs/50-years/journals/jrpit/JRPIT39.2.137.pdf"
    rel="nofollow">Roberts et al., 2007</a>; <a href="https://www.cawcr.gov.au/technical-reports/CTR_027.pdf"
    rel="nofollow">Bi and Marsland, 2010</a>) models originally developed at <a href="http://www.csiro.au"
    rel="nofollow">CSIRO</a>.</p>

    <p>The model code, configurations and performance were described in <a href="https://doi.org/10.5194/gmd-13-401-2020"
    rel="nofollow">Kiss et al. (2020)</a>, with further details in the draft <a href="https://github.com/COSIMA/ACCESS-OM2-1-025-010deg-report">ACCESS-OM2
    technical report</a>. The current code and configurations differ from this version
    in a number of ways (biogeochemistry, updated forcing, improvements and bug fixes),
    as described by <a href="https://doi.org/10.1029/2021GL097211" rel="nofollow">Solodoch
    et al. (2022)</a>, <a href="https://dx.doi.org/10.1029/2023JC019697" rel="nofollow">Hayashida
    et al. (2023)</a>, <a href="https://doi.org/10.5194/egusphere-2023-390" rel="nofollow">Menviel
    et al. (2023)</a> and <a href="https://doi.org/10.5194/gmd-2023-123" rel="nofollow">Wang
    et al. (2023)</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Support</h2><a id="user-content-support"
    class="anchor" aria-label="Permalink: Support" href="#support"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p><a href="https://www.access-nri.org.au" rel="nofollow">ACCESS-NRI</a> has assumed
    responsibility for supporting ACCESS-OM2-BGC for the Australian Research Community.
    As part of this support ACCESS-NRI has developed a new build and deployment system
    for ACCESS-OM2-BGC to align with plans for supporting a range of Earth System
    Models.</p>

    <p>Any questions about ACCESS-NRI releases of ACCESS-OM2-BGC should be done through
    the <a href="https://forum.access-hive.org.au/" rel="nofollow">ACCESS-Hive Forum</a>.
    See the <a href="https://forum.access-hive.org.au/t/access-help-and-support/908"
    rel="nofollow">ACCESS Help and Support topic</a> for details on how to do this.</p>

    <div class="markdown-heading"><h3 class="heading-element">Build</h3><a id="user-content-build"
    class="anchor" aria-label="Permalink: Build" href="#build"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>ACCESS-NRI is using <a href="https://spack.io" rel="nofollow">spack</a>, a
    build from source package manager designed for use with high performance computing.
    This repository contains a <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environment</a> definition file (<a href="https://github.com/ACCESS-NRI/ACCESS-OM2-BGC/blob/main/spack.yaml"><code>spack.yaml</code></a>)
    that defines all the essential components of the ACCESS-OM2-BGC model, including
    exact versions.</p>

    <p>Spack automatically builds all the components and their dependencies, producing
    model component executables. Spack already contains support for compiling thousands
    of common software packages. Spack packages for the components in ACCESS-OM2-BGC
    are defined in the <a href="https://github.com/ACCESS-NRI/spack_packages/">spack
    packages repository</a>.</p>

    <p>ACCESS-OM2-BGC is built and deployed automatically to <code>gadi</code> on
    NCI (see below). However it is possible to use spack to compile the model using
    the <code>spack.yaml</code> environment file in this repository. To do so follow
    the <a href="https://forum.access-hive.org.au/t/how-to-build-access-om2-on-gadi/1545"
    rel="nofollow">instructions on the ACCESS Forum for configuring spack on <code>gadi</code></a>.</p>

    <p>Then clone this repository and run the following commands on <code>gadi</code>:</p>

    <pre><code>spack env create access-om2-bgc spack.yaml

    spack env activate access-om2-bgc

    spack install

    </code></pre>

    <p>to create a spack environment called <code>access-om2-bgc</code> and build
    all the ACCESS-OM2-BGC components, the locations of which can be found using <code>spack
    find --paths</code>.</p>

    <p>In contrast, the <a href="https://github.com/COSIMA/access-om2">COSIMA ACCESS-OM2
    repository</a> uses <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"
    rel="nofollow">submodules</a> to bring all the code dependencies into a single
    repository and build all the models together.</p>

    <div class="markdown-heading"><h3 class="heading-element">Deployment</h3><a id="user-content-deployment"
    class="anchor" aria-label="Permalink: Deployment" href="#deployment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>ACCESS-OM2-BGC is deployed automatically when a new version of the <a href="https://github.com/ACCESS-NRI/ACCESS-OM2-BGC/blob/main/spack.yaml"><code>spack.yaml</code></a>
    file is committed to this repository and tagged with a new version. All the ACCESS-OM2-BGC
    components are built using <code>spack</code> on <code>gadi</code> and installed
    under the <a href="https://my.nci.org.au/mancini/project/vk83" rel="nofollow"><code>vk83</code></a>
    project in <code>/g/data/vk83</code>. It is necessary to be a member of <a href="https://my.nci.org.au/mancini/project/vk83"
    rel="nofollow"><code>vk83</code></a> project to use ACCESS-NRI deployments of
    ACCESS-OM2-BGC.</p>

    <p>The deployment process also creates a GitHub release with the same tag. All
    releases are available under the <a href="https://github.com/ACCESS-NRI/ACCESS-OM2-BGC/releases">Releases
    page</a>. Each release has a changelog and meta-data with detailed information
    about the build and deployment, including:</p>

    <ul>

    <li>paths on <code>gadi</code> to all executables built in the deployment process
    (<code>spack.location</code>)</li>

    <li>a <code>spack.lock</code> file, which is a complete build provenance document,
    listing all the components that were built and their dependencies, versions, compiler
    version, build flags and build architecture</li>

    <li>the environment <code>spack.yaml</code> file used for deployment</li>

    </ul>

    <p>Additionally the deployment creates environment modulefiles, the <a href="https://opus.nci.org.au/display/Help/Environment+Modules"
    rel="nofollow">standard method for deploying software on <code>gadi</code></a>.
    To view available ACCESS-OM2-BGC versions:</p>

    <pre><code>module use /g/data/vk83/apps/spack/0.20/release/modules/linux-rocky8-x86_64

    module avail access-om2-bgc

    </code></pre>

    <p>For users of ACCESS-OM2-BGC model configurations released by ACCESS-NRI the
    exact location of the ACCESS-OM2-BGC model executables is not required. Model
    configurations will be updated with new model components when necessary.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1710289078.0
AMReX-Codes/pyamrex:
  data_format: 2
  description: GPU-Enabled, Zero-Copy AMReX Python Bindings including AI/ML
  filenames:
  - spack.yaml
  - docs/spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: '24.05'
  readme: '<div class="markdown-heading"><h1 class="heading-element">pyAMReX</h1><a
    id="user-content-pyamrex" class="anchor" aria-label="Permalink: pyAMReX" href="#pyamrex"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/e751dc39d18bc7613b561655f2f3551a2c999fc64fb85aeda826e0351492e168/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e"><img
    src="https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e"
    alt="Python3 API: Beta" title="Status: Beta" data-canonical-src="https://img.shields.io/badge/phase-beta-yellowgreen"
    style="max-width: 100%;"></a>

    <a href="https://pyamrex.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/a72575f4cba18887d71f6084dbe806f54cb6f8be5eedbb5e542adbb89e81e956/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7079616d7265782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/pyamrex/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://github.com/AMReX-Codes/pyamrex/discussions"><img src="https://camo.githubusercontent.com/1160c9b83b0d3a01df9f7384cf556f0cc92a304b6496afd616efe2ca068089b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667"
    alt="Discussions" data-canonical-src="https://img.shields.io/badge/chat-discussions-turquoise.svg"
    style="max-width: 100%;"></a><br>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/actions/workflows/ubuntu.yml/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/actions/workflows/ubuntu.yml/badge.svg?branch=development"
    alt="Linux" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/actions/workflows/macos.yml/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/actions/workflows/macos.yml/badge.svg?branch=development"
    alt="macOS" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/actions/workflows/windows.yml/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/actions/workflows/windows.yml/badge.svg?branch=development"
    alt="Windows" style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License pyAMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.8408733" rel="nofollow"><img src="https://camo.githubusercontent.com/cd9d78571166339d2799568898526d14004a42389158e25e813c645cfef06db3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e383430383733332d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.8408733-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>The Python binding pyAMReX bridges the compute in AMReX block-structured codes
    and data science:

    it provides zero-copy application GPU data access for AI/ML, in situ analysis,
    application coupling and enables rapid, massively parallel prototyping.

    pyAMReX enhances the <a href="https://amrex-codes.github.io" rel="nofollow">Block-Structured
    AMR Software Framework AMReX</a> and its applications.</p>

    <div class="markdown-heading"><h2 class="heading-element">Users</h2><a id="user-content-users"
    class="anchor" aria-label="Permalink: Users" href="#users"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>pyAMReX <a href="https://pyamrex.readthedocs.io/en/latest/install/users.html"
    rel="nofollow">can be installed</a> with package managers or from source.</p>

    <div class="markdown-heading"><h3 class="heading-element">Usage</h3><a id="user-content-usage"
    class="anchor" aria-label="Permalink: Usage" href="#usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Please see the <a href="https://pyamrex.readthedocs.io/en/latest/usage/how_to_run.html"
    rel="nofollow">manual</a> and our <a href="https://github.com/AMReX-Codes/pyamrex/tree/development/tests">test
    cases</a> for detailed examples.</p>

    <p>Use AMReX objects and APIs from Python:</p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>.<span class="pl-s1">space3d</span> <span class="pl-k">as</span>
    <span class="pl-s1">amr</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">IntVect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">IntVect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <div class="markdown-heading"><h2 class="heading-element">Developers</h2><a id="user-content-developers"
    class="anchor" aria-label="Permalink: Developers" href="#developers"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <div class="markdown-heading"><h3 class="heading-element">Dependencies</h3><a
    id="user-content-dependencies" class="anchor" aria-label="Permalink: Dependencies"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B17" rel="nofollow">C++17</a>
    compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.20.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.12.0+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.8+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://mpi4py.readthedocs.io" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (for
    CUDA support, needs 3.7.9+ and 4.2+ is recommended)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://pandas.pydata.org/" rel="nofollow">pandas</a> 2+: for DataFrame
    support</li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <p>Optional CUDA-capable dependencies for tests include:</p>

    <ul>

    <li>

    <a href="https://github.com/cupy/cupy#installation">cupy</a> 11.2+</li>

    <li>

    <a href="https://numba.readthedocs.io/en/stable/user/installing.html" rel="nofollow">numba</a>
    0.56+</li>

    <li>

    <a href="https://pytorch.org/get-started/locally/" rel="nofollow">torch</a> 1.12+</li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">Install Dependencies</h3><a
    id="user-content-install-dependencies" class="anchor" aria-label="Permalink: Install
    Dependencies" href="#install-dependencies"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.20.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pip

    python3 -m pip install -U build packaging setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <p>Some of our tests depend on optional third-party modules (e.g., <code>pandas</code>,
    <code>cupy</code>, <code>numba</code>, and/or <code>pytorch</code>).

    If these are not installed then their tests will be skipped.</p>

    <div class="markdown-heading"><h3 class="heading-element">Configure your compiler</h3><a
    id="user-content-configure-your-compiler" class="anchor" aria-label="Permalink:
    Configure your compiler" href="#configure-your-compiler"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <div class="markdown-heading"><h3 class="heading-element">Build</h3><a id="user-content-build"
    class="anchor" aria-label="Permalink: Build" href="#build"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    python3 -m pip install -U -r requirements.txt

    python3 -m pip install -v --force-reinstall --no-deps <span class="pl-c1">.</span></pre></div>

    <p>If you are iterating on builds, it will faster to rely on <code>ccache</code>
    and to let CMake call the <code>pip</code> install logic:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build -DAMReX_SPACEDIM=<span class="pl-s"><span class="pl-pds">"</span>1;2;3<span
    class="pl-pds">"</span></span>

    cmake --build build --target pip_install -j 8</pre></div>

    <div class="markdown-heading"><h3 class="heading-element">Test</h3><a id="user-content-test"
    class="anchor" aria-label="Permalink: Test" href="#test"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>After successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests</span>

    python3 -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python3 -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python3 -m pytest tests/test_intvect.py::test_iv_conversions


    <span class="pl-c"><span class="pl-c">#</span> Run all tests, do not capture "print"
    output and be verbose</span>

    python3 -m pytest -s -vvvv tests/</pre></div>

    <div class="markdown-heading"><h3 class="heading-element">Build Options</h3><a
    id="user-content-build-options" class="anchor" aria-label="Permalink: Build Options"
    href="#build-options"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>"1;2;3"</td>

    <td>Dimension(s) of AMReX as a <code>;</code>-separated list</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>PYBIND11_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    <tr>

    <td><code>PYAMREX_LIBDIR</code></td>

    <td><em>None</em></td>

    <td>If set, search for pre-built a pyAMReX library</td>

    </tr>

    <tr>

    <td><code>PYAMREX_CCACHE</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Search and use CCache to speed up rebuilds</td>

    </tr>

    <tr>

    <td><code>PYAMREX_IPO</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Compile with interprocedural/link optimization (IPO/LTO)</td>

    </tr>

    <tr>

    <td><code>PYINSTALLOPTIONS</code></td>

    <td><em>None</em></td>

    <td>Additional options for <code>pip install</code>, e.g., <code>-v --user</code>

    </td>

    </tr>

    </tbody>

    </table>

    <p>Furthermore, pyAMReX adds a few selected CMake build options:</p>

    <table>

    <thead>

    <tr>

    <th>CMake Option</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMReX_SPACEDIM</code></td>

    <td>

    <strong>3</strong>, use <code>"1;2;3"</code> for all</td>

    <td>Dimension(s) of AMReX as a <code>;</code>-separated list</td>

    </tr>

    <tr>

    <td><code>pyAMReX_CCACHE</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Search and use CCache to speed up rebuilds</td>

    </tr>

    <tr>

    <td><code>pyAMReX_IPO</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Compile with interprocedural/link optimization (IPO/LTO)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_INSTALL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Enable install targets for pyAMReX</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_src</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_internal</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_repo</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_branch</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>pyAMReX_amrex_repo</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_src</code></td>

    <td><em>None</em></td>

    <td>Absolute path to pybind11 source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_internal</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_repo</code></td>

    <td><code>https://github.com/pybind/pybind11.git</code></td>

    <td>Repository URI to pull and build pybind11 from</td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_branch</code></td>

    <td><code>v2.12.0</code></td>

    <td>Repository branch for <code>pyAMReX_pybind11_repo</code>

    </td>

    </tr>

    <tr>

    <td><code>Python_EXECUTABLE</code></td>

    <td>(newest found)</td>

    <td>Path to Python executable</td>

    </tr>

    </tbody>

    </table>

    <p>As one example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <div class="markdown-heading"><h2 class="heading-element">Acknowledgements</h2><a
    id="user-content-acknowledgements" class="anchor" aria-label="Permalink: Acknowledgements"
    href="#acknowledgements"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This work was supported by the Laboratory Directed Research and Development
    Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy
    Contract No. DE-AC02-05CH11231.</p>

    <div class="markdown-heading"><h2 class="heading-element">Copyright Notice</h2><a
    id="user-content-copyright-notice" class="anchor" aria-label="Permalink: Copyright
    Notice" href="#copyright-notice"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>pyAMReX Copyright (c) 2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory, National Renewable Energy

    Laboratory Alliance for Sustainable Energy, LLC and Lawrence Livermore

    National Security, LLC (subject to receipt of any required approvals from the
    U.S.

    Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Intellectual Property Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>Please see the full license agreement in <a href="LICENSE">LICENSE</a>.<br>

    Please see the notices in <a href="NOTICE">NOTICE</a>.<br>

    The SPDX license identifier is <code>BSD-3-Clause-LBNL</code>.</p>

    '
  stargazers_count: 31
  subscribers_count: 16
  topics:
  - amrex
  - python
  updated_at: 1717051123.0
AMReX-Microelectronics/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Docs/spack.yaml
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">ARTEMIS</h1><a\
    \ id=\"user-content-artemis\" class=\"anchor\" aria-label=\"Permalink: ARTEMIS\"\
    \ href=\"#artemis\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs\
    \ Solver) is a high-performance coupled electrodynamics\u2013micromagnetics solver\
    \ for full physical modeling of signals in microelectronic circuitry. The overall\
    \ strategy couples a finite-difference time-domain (FDTD) approach for Maxwell\u2019\
    s equations to a magnetization model described by the Landau\u2013Lifshitz\u2013\
    Gilbert (LLG) equation. The algorithm is implemented in the Exascale Computing\
    \ Project (ECP) software framework, AMReX, which provides effective scalability\
    \ on manycore and GPU-based supercomputing architectures. Furthermore, the code\
    \ leverages ongoing developments of the Exascale Application Code, WarpX, which\
    \ is primarily being developed for plasma wakefield accelerator modeling. Our\
    \ temporal coupling scheme provides second-order accuracy in space and time by\
    \ combining the integration steps for the magnetic field and magnetization into\
    \ an iterative sub-step that includes a trapezoidal temporal discretization for\
    \ the magnetization. The performance of the algorithm is demonstrated by the excellent\
    \ scaling results on NERSC multicore and GPU systems, with a significant (59\xD7\
    ) speedup on the GPU using a node-by-node comparison. The utility of our code\
    \ is validated by performing simulations of transmission lines, rectangle electromagnetic\
    \ waveguides, magnetically tunable filters, on-chip coplanar waveguides and resonators,\
    \ magnon-photon coupling circuits, and so on.</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Installation</h1><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Download AMReX Repository</h2><a\
    \ id=\"user-content-download-amrex-repository\" class=\"anchor\" aria-label=\"\
    Permalink: Download AMReX Repository\" href=\"#download-amrex-repository\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p><code>git\
    \ clone git@github.com:AMReX-Codes/amrex.git</code></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Download Artemis Repository</h2><a id=\"user-content-download-artemis-repository\"\
    \ class=\"anchor\" aria-label=\"Permalink: Download Artemis Repository\" href=\"\
    #download-artemis-repository\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><code>git clone git@github.com:AMReX-Microelectronics/artemis.git</code></p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Build</h2><a id=\"\
    user-content-build\" class=\"anchor\" aria-label=\"Permalink: Build\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Make sure that the AMReX and Artemis are cloned in the same location in their\
    \ filesystem. Navigate to the Exec folder of Artemis and execute\n<code>make -j\
    \ 4</code>. <br>\nYou can turn on and off the LLG equation by specifying <code>USE_LLG</code>\
    \ during compilation. <br>\nThe following command compiles Artemis without LLG\n\
    <code>make -j 4 USE_LLG=FALSE</code> <br>\nThe following command compiles Artemis\
    \ with LLG\n<code>make -j 4 USE_LLG=TRUE</code> <br>\nThe default value of <code>USE_LLG</code>\
    \ is <code>TRUE</code>.</p>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Running Artemis</h1><a id=\"user-content-running-artemis\" class=\"anchor\" aria-label=\"\
    Permalink: Running Artemis\" href=\"#running-artemis\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Example input scripts are\
    \ located in <code>Examples</code> directory.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Simple Testcase without LLG</h2><a id=\"user-content-simple-testcase-without-llg\"\
    \ class=\"anchor\" aria-label=\"Permalink: Simple Testcase without LLG\" href=\"\
    #simple-testcase-without-llg\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>You can run the following to simulate an air-filled X-band\
    \ rectangle waveguide:</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >For MPI+OMP build</h2><a id=\"user-content-for-mpiomp-build\" class=\"anchor\"\
    \ aria-label=\"Permalink: For MPI+OMP build\" href=\"#for-mpiomp-build\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p><code>make\
    \ -j 4 USE_LLG=FALSE</code> <br>\n<code>mpirun -n 4 ./main3d.gnu.TPROF.MTMPI.OMP.GPUCLOCK.ex\
    \ Examples/Waveguide/inputs_3d_empty_X_band</code></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">For MPI+CUDA build</h2><a id=\"user-content-for-mpicuda-build\"\
    \ class=\"anchor\" aria-label=\"Permalink: For MPI+CUDA build\" href=\"#for-mpicuda-build\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><code>make -j 4 USE_LLG=FALSE USE_GPU=TRUE</code> <br>\n<code>mpirun -n 4 ./main3d.gnu.TPROF.MTMPI.CUDA.GPUCLOCK.ex\
    \ Examples/Waveguide/inputs_3d_empty_X_band</code></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Simple Testcase with LLG</h2><a id=\"user-content-simple-testcase-with-llg\"\
    \ class=\"anchor\" aria-label=\"Permalink: Simple Testcase with LLG\" href=\"\
    #simple-testcase-with-llg\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>You can run the following to simulate an X-band magnetically\
    \ tunable filter:</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >For MPI+OMP build</h2><a id=\"user-content-for-mpiomp-build-1\" class=\"anchor\"\
    \ aria-label=\"Permalink: For MPI+OMP build\" href=\"#for-mpiomp-build-1\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p><code>make\
    \ -j 4 USE_LLG=TRUE</code> <br>\n<code>mpirun -n 8 ./main3d.gnu.TPROF.MTMPI.OMP.GPUCLOCK.ex\
    \ Examples/Waveguide/inputs_3d_LLG_filter</code></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">For MPI+CUDA build</h2><a id=\"user-content-for-mpicuda-build-1\"\
    \ class=\"anchor\" aria-label=\"Permalink: For MPI+CUDA build\" href=\"#for-mpicuda-build-1\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><code>make -j 4 USE_LLG=TRUE USE_GPU=TRUE</code> <br>\n<code>mpirun -n 8 ./main3d.gnu.TPROF.MTMPI.CUDA.GPUCLOCK.ex\
    \ Examples/Waveguide/inputs_3d_LLG_filter</code></p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Visualization and Data Analysis</h1><a id=\"user-content-visualization-and-data-analysis\"\
    \ class=\"anchor\" aria-label=\"Permalink: Visualization and Data Analysis\" href=\"\
    #visualization-and-data-analysis\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>Refer to the following link for several\
    \ visualization tools that can be used for AMReX plotfiles.</p>\n<p><a href=\"\
    https://amrex-codes.github.io/amrex/docs_html/Visualization_Chapter.html\" rel=\"\
    nofollow\">Visualization</a></p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Data Analysis in Python using yt</h3><a id=\"user-content-data-analysis-in-python-using-yt\"\
    \ class=\"anchor\" aria-label=\"Permalink: Data Analysis in Python using yt\"\
    \ href=\"#data-analysis-in-python-using-yt\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>You can extract the data in numpy\
    \ array format using yt (you can refer to this for installation and usage of <a\
    \ href=\"https://yt-project.org/\" rel=\"nofollow\">yt</a>. After you have installed\
    \ yt, you can do something as follows, for example, to get variable 'Ex' (x-component\
    \ of electric field)</p>\n<pre><code>import yt\nds = yt.load('./plt00001000/')\
    \ # for data at time step 1000\nad0 = ds.covering_grid(level=0, left_edge=ds.domain_left_edge,\
    \ dims=ds.domain_dimensions)\nE_array = ad0['Ex'].to_ndarray()\n</code></pre>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Publications</h1><a\
    \ id=\"user-content-publications\" class=\"anchor\" aria-label=\"Permalink: Publications\"\
    \ href=\"#publications\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<ol>\n<li>Z. Yao, R. Jambunathan, Y. Zeng and A. Nonaka, A\
    \ massively parallel time-domain coupled electrodynamics\u2013micromagnetics solver.\
    \ The International Journal of High Performance Computing Applications. 2022;36(2):167-181.\
    \ doi:10.1177/10943420211057906\n<a href=\"https://journals.sagepub.com/doi/full/10.1177/10943420211057906\"\
    \ rel=\"nofollow\">link</a>\n</li>\n<li>S. S. Sawant, Z. Yao, R. Jambunathan and\
    \ A. Nonaka, Characterization of transmission lines in microelectronic circuits\
    \ Using the ARTEMIS solver, IEEE Journal on Multiscale and Multiphysics Computational\
    \ Techniques, vol. 8, pp. 31-39, 2023, doi: 10.1109/JMMCT.2022.3228281\n<a href=\"\
    https://ieeexplore.ieee.org/abstract/document/9980353\" rel=\"nofollow\">link</a>\n\
    </li>\n<li>R. Jambunathan, Z. Yao, R. Lombardini, A. Rodriguez, and A. Nonaka,\
    \ Two-fluid physical modeling of superconducting resonators in the ARTEMIS framework,\
    \ Computer Physics Communications, 291, p.108836. doi:10.1016/j.cpc.2023.108836\n\
    <a href=\"https://www.sciencedirect.com/science/article/pii/S0010465523001819?casa_token=rWpwl8cmtUYAAAAA:rZTndzf_pqx0lo9jtTRzLLxh0tIf_AD0zHcRRJ_ciwMw-n-X2doK5RprMS4wyrO9TEw5oDZAB7Kr\"\
    \ rel=\"nofollow\">link</a>\n</li>\n</ol>\n"
  stargazers_count: 10
  subscribers_count: 5
  topics: []
  updated_at: 1716409719.0
Alpine-DAV/spack_configs:
  data_format: 2
  description: spack envs
  filenames:
  - _experimental/envs/alpinedav/ubuntu_18_devel/spack.yaml
  - _experimental/envs/alpinedav/ubuntu_18_cuda_10.1_devel/spack.yaml
  full_name: Alpine-DAV/spack_configs
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">spack_configs</h1><a
    id="user-content-spack_configs" class="anchor" aria-label="Permalink: spack_configs"
    href="#spack_configs"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>shared spack configs repo</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1639176281.0
C2SM/spack-c2sm:
  data_format: 2
  description: Repository for c2sm spack config and repo files
  filenames:
  - upstreams/daint/icon-dsl/spack.yaml
  - upstreams/daint/base/spack.yaml
  full_name: C2SM/spack-c2sm
  latest_release: v0.20.1.9
  readme: '<div class="markdown-heading"><h1 class="heading-element">The spack extension
    of C2SM and MCH</h1><a id="user-content-the-spack-extension-of-c2sm-and-mch" class="anchor"
    aria-label="Permalink: The spack extension of C2SM and MCH" href="#the-spack-extension-of-c2sm-and-mch"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/3c31b5169516720383f9b49508fd95cfc457c5907282d9b1001af3280dc35326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616e7369636f6c6f72746167732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/ansicolortags/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is the package manager used by C2SM and MeteoSwiss to install and deploy
    software on supercomputers, local machines and the cloud.</p>

    <div class="markdown-heading"><h2 class="heading-element">Documentations</h2><a
    id="user-content-documentations" class="anchor" aria-label="Permalink: Documentations"
    href="#documentations"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><strong>Infos about c2sm-supported software and machines</strong></p>

    <ul>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow">spack-c2sm
    latest</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.4" rel="nofollow">spack-c2sm
    v0.20.1.4</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.3" rel="nofollow">spack-c2sm
    v0.20.1.3</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.0" rel="nofollow">spack-c2sm
    v0.20.1.0</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.12" rel="nofollow">spack-c2sm
    v0.18.1.12</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.10" rel="nofollow">spack-c2sm
    v0.18.1.10</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.9" rel="nofollow">spack-c2sm
    v0.18.1.9</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.8" rel="nofollow">spack-c2sm
    v0.18.1.8</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.7" rel="nofollow">spack-c2sm
    v0.18.1.7</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.6" rel="nofollow">spack-c2sm
    v0.18.1.6</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.5" rel="nofollow">spack-c2sm
    v0.18.1.5</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.4" rel="nofollow">spack-c2sm
    v0.18.1.4</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.3" rel="nofollow">spack-c2sm
    v0.18.1.3</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.2" rel="nofollow">spack-c2sm
    v0.18.1.2</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.1" rel="nofollow">spack-c2sm
    v0.18.1.1</a> [deprecated]</p>

    </li>

    </ul>

    <p><strong>General infos about spack</strong></p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/v0.20.1/" rel="nofollow">Official
    spack v0.20.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/v0.18.1/" rel="nofollow">Official
    spack v0.18.1</a></li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Workflow</h2><a id="user-content-workflow"
    class="anchor" aria-label="Permalink: Workflow" href="#workflow"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>With spack v0.18 we suggest local/individual spack instances and the use of
    spack environments.</p>

    <p>A user clones the spack repo</p>

    <div class="highlight highlight-source-shell"><pre>git clone --depth 1 --recurse-submodules
    --shallow-submodules -b v0.20.1.5 https://github.com/C2SM/spack-c2sm.git</pre></div>

    <p>gets spack in the command line</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">.</span>
    spack-c2sm/setup-env.sh</pre></div>

    <p>activates an environment</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate <span class="pl-k">&lt;</span>path_to_env<span
    class="pl-k">&gt;</span></pre></div>

    <p>and starts exploring</p>

    <div class="highlight highlight-source-shell"><pre>spack info <span class="pl-k">&lt;</span>package<span
    class="pl-k">&gt;</span>

    spack spec <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>and building</p>

    <div class="highlight highlight-source-shell"><pre>spack install <span class="pl-k">&lt;</span>spec<span
    class="pl-k">&gt;</span>

    spack dev-build <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>a package.</p>

    <p>Updating spack-c2sm is in the hands of the user.</p>

    <div class="highlight highlight-source-shell"><pre>git pull

    git submodule update --recursive</pre></div>

    <p>After an update we advice to clean</p>

    <div class="highlight highlight-source-shell"><pre>spack uninstall -a

    spack clean -a

    rm -rf <span class="pl-k">~</span>/.spack</pre></div>

    <p>and rebuild.</p>

    <div class="markdown-heading"><h2 class="heading-element">Command cheat sheet</h2><a
    id="user-content-command-cheat-sheet" class="anchor" aria-label="Permalink: Command
    cheat sheet" href="#command-cheat-sheet"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Clone</td>

    <td><code>git clone --depth 1 --recurse-submodules --shallow-submodules -b &lt;branch/tag&gt;
    https://github.com/C2SM/spack-c2sm.git</code></td>

    </tr>

    <tr>

    <td>Load</td>

    <td>

    <code>. spack-c2sm/setup-env.sh</code> autodetects machine <br>or<br><code>. spack-c2sm/setup-env.sh
    &lt;machine&gt;</code> forces machine<br>or<br><code>. spack-c2sm/setup-env.sh
    unknown</code> uses blank config<br><code>spack compiler find</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-compiler-find"
    rel="nofollow">autodetects compilers</a><br><code>spack external find --all</code>
    <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-external-find"
    rel="nofollow">autodetects externally installed packages</a>

    </td>

    </tr>

    <tr>

    <td>Update</td>

    <td>

    <code>git pull</code><br><code>git submodule update --recursive</code>

    </td>

    </tr>

    <tr>

    <td>Clean</td>

    <td>

    <code>spack uninstall -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-uninstall"
    rel="nofollow">uninstalls all packages</a><br><code>spack clean -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-clean"
    rel="nofollow">cleans all misc caches</a><br><code>rm -rf ~/.spack</code> removes
    user scope data</td>

    </tr>

    </tbody>

    </table>

    <p><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><strong>Spec syntax</strong></a>: <code>&lt;package&gt;</code><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#version-specifier"
    rel="nofollow"><code>@&lt;version&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-specifier"
    rel="nofollow"><code>%&lt;compiler&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#variants"
    rel="nofollow"><code>+&lt;variant&gt; ~&lt;variant&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><code>^&lt;sub-package&gt; +&lt;sub-package-variant&gt;</code></a><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-flags"
    rel="nofollow"><code>&lt;compiler flags&gt;</code></a></p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Find</td>

    <td>

    <code>spack find</code> lists all installed packages. <br><code>spack find &lt;spec&gt;</code>
    lists all installed packages that match the spec.</td>

    </tr>

    <tr>

    <td>Info</td>

    <td><code>spack info &lt;package&gt;</code></td>

    </tr>

    <tr>

    <td>Spec</td>

    <td>

    <code>spack spec &lt;spec&gt;</code> concretizes abstract spec (unspecfied variant
    = <strong>any</strong>)<br><em>Spack is not required to use the default of an
    unspecified variant. The default value is only a tiebreaker for the concretizer.</em>

    </td>

    </tr>

    <tr>

    <td>Install</td>

    <td><code>spack install &lt;spec&gt;</code></td>

    </tr>

    <tr>

    <td>Locate</td>

    <td>

    <code>spack location --install-dir &lt;spec&gt;</code> prints location of <strong>all</strong>
    installs that satisfy the spec</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-load"
    rel="nofollow">Load env</a></td>

    <td>

    <code>spack load &lt;spec&gt;</code> loads run environment</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Activate
    env</a></td>

    <td><code>spack env activate &lt;env_name&gt;</code></td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Deactivate
    env</a></td>

    <td><code>spack deactivate</code></td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 7
  subscribers_count: 18
  topics: []
  updated_at: 1716815007.0
CHIP-SPV/chipStar-Spack:
  data_format: 2
  description: Support for building chipStar and related libraries via Spack
  filenames:
  - Environments/LevelZero/spack.yaml
  full_name: CHIP-SPV/chipStar-Spack
  latest_release: null
  readme: '

    <div class="markdown-heading"><h1 class="heading-element">Overview</h1><a id="user-content-overview"
    class="anchor" aria-label="Permalink: Overview" href="#overview"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p><a href="https://github.com/CHIP-SPV/chipStar">chipStar</a> (formerly CHIP-SPV)

    is software that allows software written to use the

    <a href="https://https://github.com/ROCm-Developer-Tools/HIP" rel="nofollow">Heterogeneous-compute
    Interface for Portability

    (HIP)</a>

    interface and kernel language to target GPUs via the

    <a href="https://registry.khronos.org/spir" rel="nofollow">SPIR-V</a> intermediate
    language.

    chipStar can use either the Intel Level Zero runtime or an OpenCL

    runtime as a backend.</p>

    <p>This repository contains support for building chipStar and its

    dependencies via the <a href="https://github.com/spack/spack">Spack</a> package

    manager.</p>

    <p>Note: most development to date has been done with the Level Zero

    environment, and it is expected that substantial work is needed for

    the environment targeting the OpenCL backend to work.</p>

    <div class="markdown-heading"><h1 class="heading-element">Prerequisites</h1><a
    id="user-content-prerequisites" class="anchor" aria-label="Permalink: Prerequisites"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>An x86_64 system running a common Linux distribution.  OpenSLES 15 is

    the best tested to date.</li>

    <li>A working Spack installation.</li>

    <li>A recent Clang installation that is registered with Spack as a compiler.

    Versions 15 and 16 are best tested, but 14 might work.  We suggest

    installing the compiler via Spack (i.e., by installing something like

    <code>llvm@16.0.2</code> and then using <code>spack compiler add</code> with the
    llvm

    package''s install location), because the <code>chipstar</code> package defined

    in this repository depends on the <code>llvm</code> package anyway.</li>

    <li>A recent (at least version 2023.1) Intel OneAPI compiler installation

    that is registered with Spack as a compiler.  The recommended way

    of doing this is by installing the Spack <code>intel-oneapi-compilers</code>

    package, then registering the location of its compilers with Spack.

    E.g.,</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>$ spack install intel-oneapi-compilers@2023

    $ spack compiler add <span class="pl-s"><span class="pl-pds">$(</span>spack location
    -i intel-oneapi-compilers@2023<span class="pl-pds">)</span></span>/compiler/latest/linux</pre></div>

    <div class="markdown-heading"><h1 class="heading-element">Usage</h1><a id="user-content-usage"
    class="anchor" aria-label="Permalink: Usage" href="#usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ol start="0">

    <li>Clone this repository to the target system.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ git clone https://github.com/CHIP-SPV/CHIP-SPV-Spack</pre></div>

    <ol start="2">

    <li>Activate the environment you want to build.  E.g., for the

    environment that just builds chipStar with Level Zero backend:</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ <span class="pl-c1">cd</span>
    CHIP-SPV-Spack/Environments/LevelZero

    $ spack env activate <span class="pl-c1">.</span></pre></div>

    <ol start="3">

    <li>Concretize the active environment.  (In Spack terminology,

    "to concretize" means to let Spack examine the package specifications

    it has been asked to build, plus the available package repositories,

    resolve dependencies and check constraints, and decide exactly which

    packages it will build, in which order, and with which configuration.)</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack concretize -f -U</pre></div>

    <p>We suggest examining the output from running the <code>spack concretize</code>

    command to make sure that Spack''s concretizer has truly decided to

    use the configuration options and especially the compilers that you

    want it to use.  Note that the environment and related configuration

    are purposefully not overly constrained to use the given compiler

    for every dependency package, so even though there are some packages

    that must be built with <code>%clang</code>, there are others that may be

    built (or re-used from already-installed packages) using <code>%gcc</code> such

    as the system''s GCC installation.</p>

    <p>If Spack''s concretizer  didn''t do what you want, you can re-concretize

    the environment and be more explicit about what you want using command-line

    configuration options (recommended) or by editing the environment''s

    <code>spack.yaml</code> file or other configuration options that your Spack installation

    is using.  (Use <code>spack config blame</code> to see which configuration files
    Spack is

    using.)  For instance, if you have both <code>clang@16.0.2</code> and <code>clang@15.0.7</code>

    installed and registered as Spack compilers, and you want to build

    using <code>clang@15.0.7</code>, you may have to use a concretize command like
    the

    following:</p>

    <div class="highlight highlight-source-shell"><pre>$ spack -c <span class="pl-s"><span
    class="pl-pds">"</span>packages:chipstar:require:''%clang@15.0.7''<span class="pl-pds">"</span></span>
    concretize -f -U</pre></div>

    <p>As before, verify from the output of the <code>spack concretize</code> command
    that it

    is using the compiler version you want, <code>clang@15.0.7</code> in this example.</p>

    <ol start="4">

    <li>Build the environment.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack install</pre></div>

    <p>Spack supports some options for controlling the build and installation,

    such as <code>-j</code> to limit the number of processes used for parallel builds,

    useful for being a good citizen on shared systems by not allowing Spack

    to use all available cores (its default).  See the Spack documentation for

    more information.</p>

    <p>Assuming all goes well with the build and install, a <code>spack find</code>

    should show the packages that you just built.</p>

    <ol start="5">

    <li>Use the installed software.  There are several ways you might

    update your environment to use the software, including:</li>

    </ol>

    <ul>

    <li><code>spack load chipstar</code></li>

    <li>Activating the environment that you used to build the software</li>

    <li>If your Spack configuration is such that it can generate module files

    and module files have been generated for the software you built

    via this environment, <code>module load chipstar</code>

    </li>

    </ul>

    <p>Note that you may need to modify your environment to be able to run

    programs produced using chipStar and the H4I libraries built

    using this Spack repository.  For instance, on some systems,

    one must load the <code>intel_compute_runtime</code> module before being

    able to run programs that use the Intel Level Zero runtime.</p>

    <div class="markdown-heading"><h1 class="heading-element">TODO</h1><a id="user-content-todo"
    class="anchor" aria-label="Permalink: TODO" href="#todo"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>Clean up and verify the OpenCL-based environment.</li>

    <li>Ensure the OpenCL-based environment can use any OpenCL implementation.</li>

    <li>Incorporate H4I HIP libraries like H4I-HipBLAS into an environments.</li>

    <li>Support using the software installed by the environment via

    <code>module</code> command.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1687550793.0
COSIMA/spack-config:
  data_format: 2
  description: Spack configuration installed at /g/data/ik11/spack/ to provide ACCESS-OM3
    dependencies
  filenames:
  - environments/cesm-0_x_0/spack.yaml
  full_name: COSIMA/spack-config
  latest_release: access-om3-v0.2.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">COSIMA Spack\
    \ Configuration</h1><a id=\"user-content-cosima-spack-configuration\" class=\"\
    anchor\" aria-label=\"Permalink: COSIMA Spack Configuration\" href=\"#cosima-spack-configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>This repository contains the spack configuration and the spack environments\
    \ used\nby COSIMA to deploy software on gadi.</p>\n\n<ul>\n<li><a href=\"#installation-instructions\"\
    >Installation instructions</a></li>\n<li>\n<a href=\"#installing-software\">Installing\
    \ software</a>\n<ul>\n<li><a href=\"#step-by-step-instructions\">Step-by-step\
    \ instructions</a></li>\n</ul>\n</li>\n<li><a href=\"#updating-to-a-new-spack-version\"\
    >Updating to a new spack version</a></li>\n<li>\n<a href=\"#design-notes\">Design\
    \ notes</a>\n<ul>\n<li><a href=\"#package-installation-path\">Package installation\
    \ path</a></li>\n<li><a href=\"#environment-modules\">Environment modules</a></li>\n\
    <li><a href=\"#python-virtual-environment\">Python virtual environment</a></li>\n\
    <li><a href=\"#repository-structure\">Repository structure</a></li>\n<li><a href=\"\
    #git-branches\">Git branches</a></li>\n</ul>\n</li>\n</ul>\n\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Installation instructions</h2><a id=\"user-content-installation-instructions\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation instructions\" href=\"\
    #installation-instructions\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Clone this repository and its submodules to some appropriate\
    \ location (e.g.,\n<code>/g/data/ik11/spack/0.21.2</code>):</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">git clone\
    \ --recursive https://github.com/COSIMA/spack-config.git /g/data/ik11/spack/0.21.2</span></pre></div>\n\
    <p>Next, create the python virtual environment:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\">cd</span> /g/data/ik11/spack/0.21.2</span>\n\
    $ <span class=\"pl-s1\">./bootstrap_venv.sh</span></pre></div>\n<p>Finally, to\
    \ use this spack installation one just needs to activate the python\nenvironment:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$  <span class=\"pl-s1\"\
    ><span class=\"pl-c1\">.</span> /g/data/ik11/spack/0.21.2/venv/bin/activate</span>\n\
    $ <span class=\"pl-s1\">which spack</span>\n<span class=\"pl-c1\">spack ()</span>\n\
    <span class=\"pl-c1\">{ </span>\n<span class=\"pl-c1\">    : this is a shell function\
    \ from: /g/data/ik11/spack/0.21.2/spack/share/spack/setup-env.sh;</span>\n<span\
    \ class=\"pl-c1\">    : the real spack script is here: /g/data/ik11/spack/0.21.2/spack/bin/spack;</span>\n\
    <span class=\"pl-c1\">    _spack_shell_wrapper \"$@\";</span>\n<span class=\"\
    pl-c1\">    return $?</span>\n<span class=\"pl-c1\">}</span></pre></div>\n<p>Most\
    \ of the paths in the Spack configurations files in this repository are\nrelative\
    \ to the Spack location (e.g.,\n<code>/g/data/ik11/spack/0.21.2/spack</code>).\
    \ Unfortunately this is not the case for the\nglobal source's mirror defined in\
    \ <code>config/system/mirror.yaml</code>, so the URL in\nthis file needs to be\
    \ updated if usage of a mirror is planned (see next\nsection).</p>\n<p>At this\
    \ point it might be worth reviewing the compilers and packages defined in\n<code>config/system/compilers.yaml</code>\
    \ and <code>config/system/packages.yaml</code> and update them\nif necessary.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Installing software</h2><a\
    \ id=\"user-content-installing-software\" class=\"anchor\" aria-label=\"Permalink:\
    \ Installing software\" href=\"#installing-software\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>It is recommended that\
    \ all software be installed using spack\nenvironments. Currently the following\
    \ environments are provided (the names\nshould be self-explanatory):</p>\n<ol>\n\
    <li><code>access-om3-0_1_0</code></li>\n<li><code>access-om3-0_2_0</code></li>\n\
    <li><code>access-om3-0_x_0</code></li>\n<li><code>cesm-0_1_0</code></li>\n<li><code>common_tools_and_libraries</code></li>\n\
    </ol>\n<p>Installation of a spack environment is usually quite straightforward,\
    \ but\nbecause this can be a CPU intensive operation and take quite some time,\
    \ it is\nbest to do this in parallel and to use an interactive job.</p>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Step-by-step instructions</h3><a\
    \ id=\"user-content-step-by-step-instructions\" class=\"anchor\" aria-label=\"\
    Permalink: Step-by-step instructions\" href=\"#step-by-step-instructions\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<ol>\n\
    <li>Activate spack environment</li>\n</ol>\n<p>First activate the spack environment</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >spack env activate <span class=\"pl-k\">&lt;</span>env<span class=\"pl-k\">&gt;</span></span></pre></div>\n\
    <p>where <code>&lt;env&gt;</code> by the actual name of the environment.</p>\n\
    <ol start=\"2\">\n<li>Download the sources</li>\n</ol>\n<p>As the compute nodes\
    \ do not have internet access, one needs to download all the\nnecessary sources\
    \ from the login node. This is done using a spack mirror.</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">spack mirror create\
    \ -d sources -a</span></pre></div>\n<p>Here <code>sources</code> is the name of\
    \ a mirror that has already been configured.</p>\n<p>Note that the spack environment\
    \ must have been concretized before creating the\nmirror, otherwise spack will\
    \ not know which files need downloading. To\nconcretize an environment, one uses\
    \ the following command:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack concretize</span></pre></div>\n<ol start=\"\
    3\">\n<li>Submit interactive job</li>\n</ol>\n<p>This should not use more than\
    \ a single node. Also, make sure to add <code>gdata/ik11</code>\nand <code>scratch/ik11</code>\
    \ to the storage options.</p>\n<ol start=\"4\">\n<li>Install software</li>\n</ol>\n\
    <p>Once the job has started, because it starts a completely new shell session,\
    \ one\nneeds to activate again both the python and the spack environments:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    ><span class=\"pl-c1\">.</span> /g/data/ik11/spack/0.21.2/venv/bin/activate</span>\n\
    $ <span class=\"pl-s1\">spack env activate <span class=\"pl-k\">&lt;</span>env<span\
    \ class=\"pl-k\">&gt;</span></span></pre></div>\n<p>Then one can simply do</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >spack install </span></pre></div>\n<p>In this case, although each individual\
    \ build will use some level of parallelism,\nspack will proceed through the installation\
    \ of the packages sequentially. To\nfully use parallelism one needs to tell spack\
    \ to create a Makefile and use this\nto install the software:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">spack env\
    \ depfile -o Makefile</span>\n$ <span class=\"pl-s1\">make -j</span></pre></div>\n\
    <p>In the end, all the packages should be available in some subdirectory of\n\
    <code>/g/data/ik11/spack/0.21.2/opt/</code> and the corresponding environment\
    \ modules are\ninstalled under a subdirectory of <code>/g/data/ik11/spack/0.21.2/modules</code>.\
    \ The\nactual subdirectories depend on the selected environment.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Updating to a new spack version</h2><a\
    \ id=\"user-content-updating-to-a-new-spack-version\" class=\"anchor\" aria-label=\"\
    Permalink: Updating to a new spack version\" href=\"#updating-to-a-new-spack-version\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The way this repository is set up assumes that no update of spack will take\n\
    place within a given instance. This is to make sure all packages available\nwithin\
    \ a given instance are installed with the same version of spack and are\nfully\
    \ reproducible. This means that, in order to update spack, one needs to\ncreate\
    \ a new instance. Most of the process is therefore very similar to what is\ndescribed\
    \ in the <a href=\"#installation-instructions\">Installation instructions</a>\n\
    section, with a few modifications.</p>\n<p>Start by cloning this repository and\
    \ its submodules to some appropriate location\n(e.g., <code>/g/data/ik11/spack/0.21.2</code>):</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >git clone --recursive https://github.com/COSIMA/spack-config.git /g/data/ik11/spack/0.21.2</span></pre></div>\n\
    <p>Next, create and checkout a new branch in the repository, using the spack\n\
    version as branch name:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\">cd</span> /g/data/ik11/spack/0.21.2</span>\n\
    $ <span class=\"pl-s1\">git checkout -b 0.21.2</span></pre></div>\n<p>This is\
    \ not mandatory, but it helps keeping all the different configurations and\nenvironments\
    \ clearly separated. It also allows to update instances that are\nusing different\
    \ versions of spack independently.</p>\n<p>Then we proceed with updating the spack\
    \ submodule:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$\
    \ <span class=\"pl-s1\"><span class=\"pl-c1\">cd</span> spack</span>\n$ <span\
    \ class=\"pl-s1\">git fetch --tags</span>\n$ <span class=\"pl-s1\">git checkout\
    \ v0.21.2</span>\n$ <span class=\"pl-s1\"><span class=\"pl-c1\">cd</span> ..</span>\n\
    $ <span class=\"pl-s1\">git commit spack -m <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Update spack to 0.21.2 tag.<span class=\"pl-pds\">\"</span></span></span></pre></div>\n\
    <p>Note that the <code>git fetch</code> step is only strictly necessary if you\
    \ want to use a\ntag from the spack repository (which is recommended).</p>\n<p>Finally,\
    \ just follow the remaining instructions in the <a href=\"#installation-instructions\"\
    >Installation\ninstructions</a> section to create the python virtual\nenvironment.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Design notes</h2><a\
    \ id=\"user-content-design-notes\" class=\"anchor\" aria-label=\"Permalink: Design\
    \ notes\" href=\"#design-notes\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>This section describes some of the design decisions and\
    \ their rationale.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Package installation path</h3><a id=\"user-content-package-installation-path\"\
    \ class=\"anchor\" aria-label=\"Permalink: Package installation path\" href=\"\
    #package-installation-path\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>In this repository, spack is configured to install the\
    \ packages to a path of the\nfollowing form:</p>\n<p><code>opt/{architecture}/{compiler.name}-{compiler.version}/{name}-{version}-{hash:7}</code></p>\n\
    <p>By adding the architecture, compiler name, and compiler version to the path,\n\
    installations of packages built with different compilers on different\narchitectures\
    \ are allowed to coexist without any clashes. The inclusion of part\nof the spack\
    \ hash also allows for the same version of a given package to be\ncompiled with\
    \ different options. Note that there is nothing specific to the\nspack environments,\
    \ as this is not necessary (two environments that require\nexactly the same package\
    \ built in exactly the same way will share the\ncorresponding installation).</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Environment modules</h3><a\
    \ id=\"user-content-environment-modules\" class=\"anchor\" aria-label=\"Permalink:\
    \ Environment modules\" href=\"#environment-modules\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>By default, the TCL environment\
    \ modules use the following naming scheme:</p>\n<p>`{name}/{version}-{compiler.name}-{compiler.version}-{hash:7}``</p>\n\
    <p>This ensures that there are no clashes, but unfortunately the inclusion of\
    \ the\nspack hash makes the use of the modules a bit cumbersome. To avoid the\
    \ use of\nthe hash, one can set the modules installation path and naming scheme\
    \ at the\nlevel of the spack environments. The existing environments include the\
    \ following\ndefinitions in their <code>spack.yaml</code> file:</p>\n<div class=\"\
    highlight highlight-source-yaml\"><pre>  <span class=\"pl-ent\">modules</span>:\n\
    \    <span class=\"pl-ent\">default</span>:\n      <span class=\"pl-ent\">roots</span>:\n\
    \        <span class=\"pl-ent\">tcl</span>: <span class=\"pl-s\">$spack/../modules/&lt;env\
    \ path&gt;</span>\n      <span class=\"pl-ent\">tcl</span>:\n        <span class=\"\
    pl-ent\">naming_scheme</span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>{name}/{version}<span\
    \ class=\"pl-pds\">'</span></span></pre></div>\n<p>where <code>&lt;env path&gt;</code>\
    \ is a user-defined path for the environment in question. No\ncompiler information\
    \ is used, as our environments only use one compiler. We\nrecommend to follow\
    \ this scheme in all environments. Note that spack will\nautomatically append\
    \ the architecture to the root path. This allows to install\nthe same environment\
    \ on two different architectures without clashes.</p>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Python virtual environment</h3><a id=\"user-content-python-virtual-environment\"\
    \ class=\"anchor\" aria-label=\"Permalink: Python virtual environment\" href=\"\
    #python-virtual-environment\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Using a python virtual environment for the spack installation\
    \ has several\nadvantages. Besides the usual advantages of using such environments\
    \ (stability,\nportability and reproducibility), it allows to automatically perform\
    \ a few tasks\nwhen activating the environment, thus providing a more user-friendly\n\
    experience. These tasks include:</p>\n<ul>\n<li>Sourcing the <code>spack/share/spack/setup-env.sh</code>\
    \ file that takes care of setting\nup several environment variables and functions\
    \ necessary to use spack.</li>\n<li>Loading the appropriate Gadi python environment\
    \ module.</li>\n<li>Setting up some environment variables to customize the behavior\
    \ of spack.</li>\n</ul>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Repository structure</h3><a id=\"user-content-repository-structure\" class=\"\
    anchor\" aria-label=\"Permalink: Repository structure\" href=\"#repository-structure\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>This git repository contains the following directories:</p>\n<ul>\n<li>\n<code>config</code>:\
    \ the spack configuration files.</li>\n<li>\n<code>environments</code>: spack\
    \ environment definitions.</li>\n<li>\n<code>repos</code>: several repositories\
    \ of spack package definitions.</li>\n<li>\n<code>spack</code>: the spack sources,\
    \ included as a git submodule.</li>\n</ul>\n<p>The following directories will\
    \ be created by spack:</p>\n<ul>\n<li>\n<code>modules</code>: environment modules\
    \ created by spack.</li>\n<li>\n<code>sources</code>: mirror for package sources.</li>\n\
    <li>\n<code>opt</code>: path where packages are installed.</li>\n<li>\n<code>user_cache</code>\
    \ and <code>var/cache</code>: several caches used by spack.</li>\n</ul>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Git branches</h3><a\
    \ id=\"user-content-git-branches\" class=\"anchor\" aria-label=\"Permalink: Git\
    \ branches\" href=\"#git-branches\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>Each branch in this git repository corresponds\
    \ to a spack version and is named\nafter that version (e.g. branch <code>0.21.2</code>\
    \ corresponds to the <code>v0.21.2</code> spack\nrelease). Note that there is\
    \ no <code>main</code> branch. Instead, the default branch is\nthe latest spack\
    \ version supported. This means that the default branch should be\nchanged whenever\
    \ support for a newer version of spack is added.</p>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1692145219.0
CUP-ECS/beatnik:
  data_format: 2
  description: Initial Cabana/Cajita Low/High-order Z-model Interface Solver. Benchmark
    for evaluating the performance of algorithms requiring global communication. Beatnik
    is also a precursor to potential later a High Performance Parallel Interface solver.
  filenames:
  - configs/unm/hopper/spack.yaml
  - configs/llnl/lassen/spack.yaml
  full_name: CUP-ECS/beatnik
  latest_release: v1.0.0
  readme: '<div class="markdown-heading"><h1 class="heading-element">Beatnik - A Prototype
    High Performance Parallel Interface Benchmark</h1><a id="user-content-beatnik---a-prototype-high-performance-parallel-interface-benchmark"
    class="anchor" aria-label="Permalink: Beatnik - A Prototype High Performance Parallel
    Interface Benchmark" href="#beatnik---a-prototype-high-performance-parallel-interface-benchmark"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">Description</h2><a id="user-content-description"
    class="anchor" aria-label="Permalink: Description" href="#description"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Beatnik is a benchmark for global communication based on Pandya and Shkoller''s
    3D fluid interace "Z-Model" in the Cabana/Cajita mesh framework [1]. The goals

    of Beatnik are to:</p>

    <ol>

    <li>Provide an interesting and meaningful benchmark for numerical methods that
    require global communication, for example for far-field force calculations. This
    includes fast fourier transforms, distance sort cutoff-based methods, and (eventually)
    fast multi-pole methods.</li>

    <li>Understand the performance characteristics of different parallel decompositions
    of the Z-Model based on both a 2D decomposition based on logical mesh location
    location and a space-filling curve mesh decomposition.</li>

    <li>Provide a working prototype parallel implementation of the fluid interface
    model that other codes can use to create multi-scale models and codes.</li>

    </ol>

    <p>Beatnik uses a simple mesh-based representation of the surface manifold as
    a Cabana grid 2D mesh in I/J space and a regular block 2D decomposition of this
    manifold. The physical position of each element in the mesh is stored as a separate
    vector in the nodes of the mesh. This design results in simple and efficient computation
    and communication strategies for surface normals, artificial viscosity, and Fourier
    transforms elements. However, it complicates methods where the data decomposition
    and communication is based on the spatial location of manifold points, requiring
    them to either maintain a separate spatial decomposition of the surface or to
    continually construct a spatial decomposition. A surface mesh that decomposed
    the mesh by spatial location would be an interesting alternative but would have
    the opposite issue - communication for surface calculations would be more complex
    but the (expensive) far force methods that rely on spatial decompositions (e.g.
    distance sort and spatial tree methods like the fast multi-pole method) would
    be less expensive.</p>

    <div class="markdown-heading"><h2 class="heading-element">Building Beatnik</h2><a
    id="user-content-building-beatnik" class="anchor" aria-label="Permalink: Building
    Beatnik" href="#building-beatnik"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Beatnik relies on multiple external packages to build, including:</p>

    <ul>

    <li>ECP CoPA''s Cabana/Grid particle and mesh framework [2]</li>

    <li>UT-Knoxville''s HeFFTe fast fourier transform library [3]</li>

    <li>A high-performance GPU-aware MPI implementation such as OpenMPI, MPICH, or
    MVAPICH</li>

    </ul>

    <p>To ease building Beatnik, the configs/ directory includes Spack configuration
    files for building in spack environments on multiple systems and test case run
    scripts for a variety of systems. In addition, the latest version of Spack includes
    a package description for directly building Beatnik. More information on building
    Beatnik can be found in the README.md file in the configs/ directory.</p>

    <div class="markdown-heading"><h2 class="heading-element">Running Beatnik</h2><a
    id="user-content-running-beatnik" class="anchor" aria-label="Permalink: Running
    Beatnik" href="#running-beatnik"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>By default, Beatnik solves a simple multi-mode rocket rig problem sized for
    a single serial CPU core with approximately 4GB of memory. It also includes command
    line options to change initial problem state, I/O frequency, and to weak-scale
    scale up the initial problem to larger number of processes. It also includes problem-specific
    command line parameters; setting these parameters accurately generally requires
    expertise in fluid interface models. However, we provide several useful examples
    drawn from the ZModel papers that recreate the results in those papers.</p>

    <div class="markdown-heading"><h3 class="heading-element">General command line
    parameters</h3><a id="user-content-general-command-line-parameters" class="anchor"
    aria-label="Permalink: General command line parameters" href="#general-command-line-parameters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>

    <code>-x [cuda|threads|serial]</code> - The node-level parallelism/accelerator
    backend to use</li>

    <li>

    <code>-F [write-frequency]</code> - Interval between timesteps when I/O is written</li>

    <li>

    <code>-O [solution order]</code> - Order of solver to use (''high'', ''medium'',
    or ''low''). ''low'' is the default.</li>

    <li>`-w [weak scaling factor] - Scale up the problem specification, including
    the x/y bounding box, to be N times larger</li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">Problem-specific command
    line parameters</h3><a id="user-content-problem-specific-command-line-parameters"
    class="anchor" aria-label="Permalink: Problem-specific command line parameters"
    href="#problem-specific-command-line-parameters"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <ul>

    <li>

    <code>-n [i/j mesh dimension ]</code> - Number of points on the interface manifold
    in the I and J dimensions</li>

    <li>`-t [timesteps] - number of timesteps to simulate</li>

    <li>

    <code>-I [interface initialization]</code> - Function to use for interface initial
    condition. Currently only ''cos'' and ''sech2'' are supported.</li>

    <li>

    <code>-m [magnitude]</code> - The maximum magnitude of the initialization function.</li>

    <li>

    <code>-p [period]</code> - The number of periods of the interface in the initial
    bounding box</li>

    <li>

    <code>-a [atwood]</code> - Atwood''s constant for the difference in pressure between
    the two fluids</li>

    <li>

    <code>-g [gravity]</code> - Gravitational acceleration in the -Z direction</li>

    <li>

    <code>-a [atwood]</code> -  Atwood''s constant for the difference in pressure
    between the two fluids</li>

    <li>

    <code>-M [mu]</code> - Mu, the artificial viscosity constant used in the Z-Model</li>

    <li>

    <code>-e [epsilon]</code> - Epsilon, the desingularization constant used in the
    Z-Model expressed as a fraction of the distance between interface mesh points</li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">Example 1: Periodic
    Multi-mode Rocket Rig</h3><a id="user-content-example-1-periodic-multi-mode-rocket-rig"
    class="anchor" aria-label="Permalink: Example 1: Periodic Multi-mode Rocket Rig"
    href="#example-1-periodic-multi-mode-rocket-rig"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>The simplest test case and the one to which the rocketrig example program defaults
    is an initial interface distributed according to a cosine function. Simple usage
    examples:</p>

    <ol>

    <li>Serial execution: <code>bin/rocketrig -x serial</code>

    </li>

    <li>Cuda execution (on systems with GPUs) with a 512x512 mesh: <code>bin/rocketrig
    -x cuda -n 512</code>

    </li>

    <li>Cuda execution with a 1024x1024 problem scaled up to be sixteen times as large
    in terms of bounding box and number of total points with no I/O: bin/rocketrig
    -x cuda -n 1024 -F 0 -w 16`</li>

    </ol>

    <div class="markdown-heading"><h3 class="heading-element">Example 2: Non-periodic
    Single-mode Gaussian Rollup</h3><a id="user-content-example-2-non-periodic-single-mode-gaussian-rollup"
    class="anchor" aria-label="Permalink: Example 2: Non-periodic Single-mode Gaussian
    Rollup" href="#example-2-non-periodic-single-mode-gaussian-rollup"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Another test case is a single-mode rollup test where the intitial interface
    is set according to a hyperbolic secant function. This testcase recreates the
    the Gaussian perturbation results in Panda and Shkoller''s paper from sections
    2.3 and 2.4.  To run this testcase with a high-order model, use the following
    command line parameters. Note that this works best with a GPU accelerator, as
    the exact high-order far field force solver is very compute intensive and is generally
    impractical for non-trivial mesh sizes without GPU acceleration:

    <code>bin/rocketrig -x cuda -O high -n 64 -I sech2 -m 0.1 -p 9.0 -b free -a 0.15
    -M 2 -e 2</code></p>

    <div class="markdown-heading"><h2 class="heading-element">Planned Development
    Steps</h2><a id="user-content-planned-development-steps" class="anchor" aria-label="Permalink:
    Planned Development Steps" href="#planned-development-steps"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Beatnik is being implemented in multiple distinct steps, with associated planned
    releases:</p>

    <ul>

    <li>

    <p>Version 1.0 Features</p>

    <ol>

    <li>A low-order model implementation that relies on Cabana Grid/HeFFTe Fourier
    transforms for estimating velocity interface at mesh points.</li>

    <li>A high-order model implementation based on brute-force exact computation of
    long-range forces</li>

    <li>A medium-order model that uses the Fourier transform for estimating interface
    velocity and the far-field force solver for estimating how the vorticity changes
    at each interface point.</li>

    <li>Support for periodic boundary conditions and free boundary conditions</li>

    <li>Simple benchmark examples including a single-mode Gaussian roll-up test and
    the multi-mode rocket rig experiment.</li>

    <li>Direct support for weak scaling of benchmarks through command line arguments</li>

    </ol>

    </li>

    <li>

    <p>Version 1.X Planned Features</p>

    <ol>

    <li>Rearchitecting of the z-model solve into explicitly-coupled surface mesh and
    spatial mesh solvers</li>

    <li>A spatial mesh cutoff-based approach for calculating far-field forces using
    the Cabana particle framework. The goal of this work is to understand the accuracy/performance
    tradeoffs in the Z-Model, particularly in the medium-order</li>

    <li>Improved timestep, desingularization, and artificial viscosity parameter handling.
    The goal of this is to provide good defaults when other input parameters are changed.</li>

    <li>Additional interface initialization options, including Gaussian random and
    file-based interface initialization (also useful for checkpointing)</li>

    <li>Support for coupling with other applications through either I/O (e.g. ADIOS)
    or Communication (e.g. Portage)</li>

    <li>Additional test case definitions</li>

    </ol>

    </li>

    <li>

    <p>Potential later (e.g. &gt;=2.0) features</p>

    <ol>

    <li>Direct fast multi-pole or P3M solver for scalable, high precision high-order
    model solves.</li>

    <li>Support for multiple interface manifolds in a single simulation.</li>

    </ol>

    </li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Acknowledgment, Contributors,
    and Copyright Information</h2><a id="user-content-acknowledgment-contributors-and-copyright-information"
    class="anchor" aria-label="Permalink: Acknowledgment, Contributors, and Copyright
    Information" href="#acknowledgment-contributors-and-copyright-information"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Beatnik is primarily available as open source under a 3-Clause BSD License.
    It is being developed at the University of New Mexico, Tennessee Tech University,
    and the University of Alabama under funding the U.S. Department of Energy''s Predictive
    Science Academic Alliance Partnership III (PSAAP-III) program. Contributors to
    Beatnik development include:</p>

    <ul>

    <li>Patrick G. Bridges (<a href="mailto:patrickb@unm.edu">patrickb@unm.edu</a>)</li>

    <li>Thomas Hines (<a href="mailto:tmhines3@ua.edu">tmhines3@ua.edu</a>)</li>

    <li>Jered Dominguez-Trujillo (<a href="mailto:jereddt@unm.edu">jereddt@unm.edu</a>)</li>

    <li>Jacob McCullough (<a href="mailto:jmccullough12@unm.edu">jmccullough12@unm.edu</a>)</li>

    <li>Jason Stewart (<a href="mailto:jastewart@unm.edu">jastewart@unm.edu</a>)</li>

    </ul>

    <p>The general structure of Beatnik and the rocketrig examples were taken from
    the ExaMPM proxy application (<a href="https://github.com/ECP-copa/ExaMPM">https://github.com/ECP-copa/ExaMPM</a>)
    developed by the ECP Center for Particle Applications (CoPA), which was also available
    under a 3-Clause BSD License when used for creating application structure.</p>

    <div class="markdown-heading"><h2 class="heading-element">References</h2><a id="user-content-references"
    class="anchor" aria-label="Permalink: References" href="#references"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ol>

    <li>

    <p>Gavin Pandya and Steve Shkoller. "3d Interface Models for Raleigh-Taylor Instability."
    Published as arxiv.org preprint <a href="https://arxiv.org/abs/2201.04538" rel="nofollow">https://arxiv.org/abs/2201.04538</a>,
    2022.</p>

    </li>

    <li>

    <p><a href="https://github.com/ECP-copa/Cabana/">https://github.com/ECP-copa/Cabana/</a></p>

    </li>

    <li>

    <p>Innovative Computing Laboratory. "heFFTe." URL: <a href="https://icl.utk.edu/fft/"
    rel="nofollow">https://icl.utk.edu/fft/</a></p>

    </li>

    </ol>

    '
  stargazers_count: 4
  subscribers_count: 4
  topics: []
  updated_at: 1716587778.0
Chrismarsh/CHM:
  data_format: 2
  description: The Canadian Hydrological Model
  filenames:
  - spack.yaml
  full_name: Chrismarsh/CHM
  latest_release: 1.4.0
  readme: "<blockquote>\n<p>[!WARNING]\nThe default branch was renamed from <code>master</code>\
    \ to <code>develop</code>. <code>Develop</code> will always be in a state of development\n\
    with tags  serving to marke quasi-stable releases</p>\n</blockquote>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">The Canadian Hydrological Model</h1><a id=\"user-content-the-canadian-hydrological-model\"\
    \ class=\"anchor\" aria-label=\"Permalink: The Canadian Hydrological Model\" href=\"\
    #the-canadian-hydrological-model\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>The Canadian Hydrological Model (CHM) is\
    \ a novel modular unstructured mesh based approach for hydrological modelling.\
    \ It can move between spatial scale, temporal scale, and spatial extents. It is\
    \ designed for developing and testing process representations for hydrological\
    \ models.</p>\n\n<ul>\n<li><a href=\"#usage\">Usage</a></li>\n<li><a href=\"#motivation\"\
    >Motivation</a></li>\n<li><a href=\"#design-goals\">Design goals</a></li>\n<li><a\
    \ href=\"#publications\">Publications</a></li>\n<li>\n<a href=\"#features\">Features</a>\n\
    <ul>\n<li><a href=\"#spatial-scales\">Spatial Scales</a></li>\n<li><a href=\"\
    #visualization\">Visualization</a></li>\n<li><a href=\"#netcdf-support\">netCDF\
    \ support</a></li>\n<li><a href=\"#process-representations\">Process representations</a></li>\n\
    <li><a href=\"#unstructured-mesh\">Unstructured mesh</a></li>\n<li><a href=\"\
    #parallel-computing\">Parallel computing</a></li>\n<li><a href=\"#uncertainty-analysis\"\
    >Uncertainty analysis</a></li>\n</ul>\n</li>\n<li>\n<a href=\"#demonstration\"\
    >Demonstration</a>\n<ul>\n<li><a href=\"#snowcast\">SnowCast</a></li>\n<li><a\
    \ href=\"#large-extent\">Large extent</a></li>\n<li><a href=\"#point-scale\">Point\
    \ scale</a></li>\n<li><a href=\"#blowing-snow\">Blowing snow</a></li>\n</ul>\n\
    </li>\n</ul>\n\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Usage</h1><a id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink:\
    \ Usage\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Details on how to use CHM, as well as more implimentation\
    \ details, can be found in the <a href=\"https://chm.readthedocs.io/\" rel=\"\
    nofollow\">documentation</a>.</p>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">Motivation</h1><a id=\"user-content-motivation\" class=\"anchor\"\
    \ aria-label=\"Permalink: Motivation\" href=\"#motivation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Modelling of hydrological\
    \ processes at any scale is hampered by large uncertainties in parameters and\
    \ forcing data, incomplete process representations (the scientific conceptualization\
    \ of a phenomena codified numerically), and arbitrary process representation selections\
    \ and linkages (collectively \u2018model structure\u2019). There is also consistent\
    \ difficulty or an inability to easily test and estimate the uncertainty due to\
    \ variations in model structure, parameter values, number of parameters, forcing\
    \ data requirements, and spatial discretization requirements (collectively \u2018\
    model complexity\u2019).</p>\n<p>In this work, a new distributed model framework\
    \ is presented that can examine a variety of process representations, process\
    \ linkages and levels of model complexity. Algorithms can be easily interchanged,\
    \ removed, and decoupled while preserving the underlying model framework. Thus,\
    \ uncertainty propagation and subsequent feedbacks within the model structure\
    \ can be quantified. Unstructured meshes represent the spatial heterogeneity of\
    \ surface and sub-surface features in a computationally efficient manner and also\
    \ decreases number of parameters and initial conditions. The parallel architecture\
    \ allows for efficient uncertainty testing of parameter ranges. By utilizing unstructured\
    \ meshes, fewer than 5% of the computational elements of high-resolution structured\
    \ (raster) grids are usually necessary.  This preserves surface and sub-surface\
    \ heterogeneity but results in fewer parameters and initial conditions.</p>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Design goals</h1><a\
    \ id=\"user-content-design-goals\" class=\"anchor\" aria-label=\"Permalink: Design\
    \ goals\" href=\"#design-goals\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<ul>\n<li>Multi-scale, multi-physics, variable complexity\
    \ and domain model</li>\n<li>Assessment of model structural, parameter, and data\
    \ uncertainty</li>\n<li>Easily test multiple hypotheses, avoid rigid model structures</li>\n\
    <li>Incorporate existing code</li>\n<li>Contribute to decision support systems</li>\n\
    </ul>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\">Publications</h1><a\
    \ id=\"user-content-publications\" class=\"anchor\" aria-label=\"Permalink: Publications\"\
    \ href=\"#publications\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The following publications provide an overview of CHM and\
    \ its capabilities</p>\n<ul>\n<li>V. Vionnet, Marsh, C.B., B. Menounos, S. Gascoin,\
    \ N.E. Wayand, J. Shea, K. Mukherjee, and J.W. Pomeroy. Multi-scale snowdrift-permitting\
    \ modelling of mountain snowpack. The Cryosphere Discussions, 2020:1--43, 2020.</li>\n\
    <li>Marsh, C.B., J.W. Pomeroy, and H.S. Wheater. The Canadian Hydrological Model\
    \ (CHM) v1.0: a multi-scale, multi-extent, variable-complexity hydrological model\
    \ \u2013 design and overview. Geoscientific Model Development, 13(1):225--247,\
    \ 2020.</li>\n<li>Marsh, C.B, J. W. Pomeroy, R.J. Spiteri, and H.S Wheater. A\
    \ Finite Volume Blowing Snow Model for Use With Variable Resolution Meshes. Water\
    \ Resources Research, 56(2), 2020.</li>\n<li>Marsh, C.B, R. J. Spiteri, J.W. Pomeroy,\
    \ and H.S. Wheater. Multi-objective unstructured triangular mesh generation for\
    \ use in hydrological and land surface models. Computers &amp; Geosciences, 119:49--67,\
    \ 2018.</li>\n</ul>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Features</h1><a id=\"user-content-features\" class=\"anchor\" aria-label=\"Permalink:\
    \ Features\" href=\"#features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Spatial Scales</h2><a id=\"user-content-spatial-scales\" class=\"anchor\" aria-label=\"\
    Permalink: Spatial Scales\" href=\"#spatial-scales\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>CHM is applicable to multiple\
    \ scales from the basin scale, to the provincial/state scale and beyond. It may\
    \ also be applied at a single point-scale.\n<a target=\"_blank\" rel=\"noopener\
    \ noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Visualization</h2><a id=\"user-content-visualization\"\
    \ class=\"anchor\" aria-label=\"Permalink: Visualization\" href=\"#visualization\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Output is in the vtu file format, allowing for visualization, analysis, and\
    \ timeseries animation in <a href=\"https://www.paraview.org/\" rel=\"nofollow\"\
    >ParaView</a>. Date-time support has been added to ParaView via an filter <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\"\
    ><img src=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\" alt=\"\
    vtk-paraview-datetimefilter\" style=\"max-width: 100%;\"></a>.</p>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">netCDF support</h2><a id=\"user-content-netcdf-support\"\
    \ class=\"anchor\" aria-label=\"Permalink: netCDF support\" href=\"#netcdf-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Input meterology may be either in a standard ASCII file, or as a netCDF file\
    \ allowing for ease of use when using climate model outputs.</p>\n<p>The below\
    \ figure shows virtual stations that correspond to the center of the 2.5 km GEM\
    \ numerical weather prediction output in netCDF format.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Process representations</h2><a id=\"user-content-process-representations\"\
    \ class=\"anchor\" aria-label=\"Permalink: Process representations\" href=\"#process-representations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Process represetenation will be extented to include the entirety of the hydrological\
    \ cycle. However, current representation includes mostly surface and cold regions\
    \ processes</p>\n<table>\n<thead>\n<tr>\n<th>Process</th>\n<th>Module</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>Canopy</td>\n<td>Open/forest (exp/log) (Pomeroy et\
    \ al., 1998; Ellis et al., 2010)</td>\n</tr>\n<tr>\n<td>Snowpack</td>\n<td>2-layer\
    \ Snobal (Marks et al, 1999); Multi-layer Snowpack (Lehning et al., 1999); Various\
    \ albedo e.g., CLASS (Verseghy 1991)</td>\n</tr>\n<tr>\n<td>Soil</td>\n<td>Frozen\
    \ soil infiltration (Gray et al., 2001)</td>\n</tr>\n<tr>\n<td>Mass redistribution</td>\n\
    <td>PBSM3D (Marsh et al, 2018 in review); Snowslide (Bernhardt 2010)</td>\n</tr>\n\
    </tbody>\n</table>\n<p>Input meterology is spatially interpolated and down-scaled\
    \ from the input station or virtual-station (e.g., from numerical weather prediction)\
    \ to produce a spatially distributed driving dataset. There are a number of ways\
    \ to downscale these meterology.</p>\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n\
    <th>Type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Air temperature</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant, neutral stability) (Kunkel, 1989,\
    \ Dodson et al., 1997)</td>\n</tr>\n<tr>\n<td>Relative humidity</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant) (Kunkel, 1989)</td>\n</tr>\n<tr>\n\
    <td>Horizontal wind</td>\n<td>Topographic curvature (Liston, et al., 2006); Mason-Sykes\
    \ (Mason and Sykes, 1979); uniform wind</td>\n</tr>\n<tr>\n<td>Precipitation</td>\n\
    <td>Elevation based lapse (Thornton, 1997)</td>\n</tr>\n<tr>\n<td>Precipitation\
    \ Phase</td>\n<td>Linear; Psychometric (Harder and Pomeroy, 2013); Threshold</td>\n\
    </tr>\n<tr>\n<td>Solar radiation</td>\n<td>Terrain shadows (Marsh et al., 2011,\
    \ Dozier and Frew, 1990); Clear sky transmittance (Burridge, 1975); Transmittance\
    \ from observations; Cloud fraction estimates (Walcek, 1994); Direct/diffuse splitting\
    \ (Iqbal, 19xx)</td>\n</tr>\n<tr>\n<td>Longwave</td>\n<td>T, RH based (Sicart\
    \ et al., 2006); Constant (Marty et al., 2002)</td>\n</tr>\n</tbody>\n</table>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Unstructured mesh</h2><a\
    \ id=\"user-content-unstructured-mesh\" class=\"anchor\" aria-label=\"Permalink:\
    \ Unstructured mesh\" href=\"#unstructured-mesh\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>CHM uses an unstructured triangular\
    \ mesh to representent the terrain. This mesh is generated by <a target=\"_blank\"\
    \ rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/mesher\"><img\
    \ src=\"https://github.com/Chrismarsh/mesher\" alt=\"Mesher\" style=\"max-width:\
    \ 100%;\"></a>, a novel multi-objective unstructured mesh generation software\
    \ that allows mesh generation to be generated from an arbitrary number of hydrologically\
    \ important features while maintaining a variable spatial resolution. Triangle\
    \ quality is guaranteed as well as a smooth graduation from small to large triangles.\
    \ Including these additional features resulted in a better representation of spatial\
    \ heterogeneity versus classic topography-only mesh generation while significantly\
    \ reducing the total number of computational elements.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Parallel computing</h2><a id=\"user-content-parallel-computing\"\
    \ class=\"anchor\" aria-label=\"Permalink: Parallel computing\" href=\"#parallel-computing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>In CHM, parallelism is currently implemented via the shared memory API OpenMP.\
    \ As described above, modules may either be point-scale models that are applied\
    \ to each triangle independently or require knowledge of the surrounding triangles.\
    \ Mixing these two types of parallelism complicates the implementation of parallel\
    \ code. To provide as much seamless parallelism as possible to the modules, each\
    \ module declares the type of algorithm it is: data parallel or domain parallel.\
    \ Data parallel modules are point-scale models that are applied to every triangle.\
    \ Domain parallel modules are modules that require knowledge of surrounding mesh\
    \ points. Thus, after the topological sort is performed to determine module execution\
    \ order, the modules are scheduled together into groups that share a parallelism\
    \ type</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Uncertainty\
    \ analysis</h2><a id=\"user-content-uncertainty-analysis\" class=\"anchor\" aria-label=\"\
    Permalink: Uncertainty analysis\" href=\"#uncertainty-analysis\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>A key feature of CHM\
    \ is the ability to, on the command line, change any value specified by a configuration\
    \ parameter. CHM provides a seamless mechanism to easily allow modules to obtain\
    \ parameter data from configuration files.</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">subprocess</span>\n\
    <span class=\"pl-k\">import</span> <span class=\"pl-s1\">shutil</span>\n\n\n<span\
    \ class=\"pl-s1\">prj_path</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s\">\"CHM.config\"</span>\n\n<span class=\"pl-s1\">cf1</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s\">\"-c output.VistaView.file:vv_dodson.txt\"\
    </span>\n<span class=\"pl-s1\">cf2</span> <span class=\"pl-c1\">=</span> <span\
    \ class=\"pl-s\">\"-c output.UpperClearing.file:uc_dodson.txt\"</span>\n<span\
    \ class=\"pl-s1\">cf3</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\"\
    >\"-c output.FiserraRidge.file:fr_dodson.txt\"</span>\n<span class=\"pl-s1\">cf4</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"--add-module Dodson_NSA_ta\"\
    </span>\n<span class=\"pl-s1\">subprocess</span>.<span class=\"pl-en\">check_call</span>([<span\
    \ class=\"pl-s\">'./CHM %s %s %s %s %s'</span> <span class=\"pl-c1\">%</span>\
    \ (<span class=\"pl-s1\">prj_path</span>, <span class=\"pl-s1\">cf1</span>, <span\
    \ class=\"pl-s1\">cf2</span>, <span class=\"pl-s1\">cf3</span>,<span class=\"\
    pl-s1\">cf4</span>)], <span class=\"pl-s1\">shell</span><span class=\"pl-c1\"\
    >=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Demonstration</h1><a id=\"user-content-demonstration\"\
    \ class=\"anchor\" aria-label=\"Permalink: Demonstration\" href=\"#demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">SnowCast</h2><a\
    \ id=\"user-content-snowcast\" class=\"anchor\" aria-label=\"Permalink: SnowCast\"\
    \ href=\"#snowcast\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a href=\"http://www.snowcast.ca\" rel=\"nofollow\">SnowCast</a>\
    \ is an experimental, daily data product that uses the Global Environmental Multiscale\
    \ (GEM) model forecasts from Environment and Climate Change Canada (ECCC) to drive\
    \ the Canadian Hydrological Model (CHM). Estimates of snowpack are provided over\
    \ the a Bow River Basin, centered over Banff, Canada.</p>\n<p>SnowCast is developed\
    \ as part of <a href=\"https://gwf.usask.ca/\" rel=\"nofollow\">Global Water Futures</a>\
    \ and the <a href=\"https://www.usask.ca/hydrology/\" rel=\"nofollow\">Centre\
    \ for Hydrology</a>, University of Saskatchewan.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Large extent</h2><a id=\"user-content-large-extent\"\
    \ class=\"anchor\" aria-label=\"Permalink: Large extent\" href=\"#large-extent\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Hourly solar radiation modelling for the territory of Yukon, Canada.\n<a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Point scale</h2><a id=\"user-content-point-scale\"\
    \ class=\"anchor\" aria-label=\"Permalink: Point scale\" href=\"#point-scale\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Comparison of CHM driving Snobal and Snowpack at the Upper Clearing site at\
    \ Marmot Creek Research Basin in Alberta, Canada\n<a target=\"_blank\" rel=\"\
    noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Blowing snow</h2><a id=\"user-content-blowing-snow\"\
    \ class=\"anchor\" aria-label=\"Permalink: Blowing snow\" href=\"#blowing-snow\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Blowing snow for a small sub-basin of Wolf Creek Reserach Basin, located in\
    \ the Yukon, Canada.\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\"\
    \ href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 36
  subscribers_count: 11
  topics: []
  updated_at: 1716583148.0
Chrismarsh/mesher:
  data_format: 2
  description: A multi-objective triangular meshing algorithm
  filenames:
  - py-mesher-spack.yaml
  full_name: Chrismarsh/mesher
  latest_release: 2.1.3
  readme: '<div class="markdown-heading"><h1 class="heading-element">mesher</h1><a
    id="user-content-mesher" class="anchor" aria-label="Permalink: mesher" href="#mesher"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Mesher is a novel multi-objective unstructured mesh generation software that
    allows mesh generation to be generated from an arbitrary number of hydrologically
    important features while maintaining a variable spatial resolution. Triangle quality
    is guaranteed as well as a smooth graduation from small to large triangles. Including
    these additional features resulted in a better representation of spatial heterogeneity
    versus classic topography-only mesh generation. The paper describing <em>mesher</em>
    can be <a href="https://www.usask.ca/hydrology-old/papers/Marsh,_et_al_2018.pdf"
    rel="nofollow">found here</a>.</p>

    <p><a target="_blank" rel="noopener noreferrer" href="docs/source/images/mesher_veg.png"><img
    src="docs/source/images/mesher_veg.png" alt="" style="max-width: 100%;"></a></p>

    <div class="markdown-heading"><h3 class="heading-element">How to use</h3><a id="user-content-how-to-use"
    class="anchor" aria-label="Permalink: How to use" href="#how-to-use"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Detailed documentation is given <a href="https://mesher-hydro.readthedocs.io"
    rel="nofollow">here</a>.</p>

    <div class="markdown-heading"><h3 class="heading-element">Install</h3><a id="user-content-install"
    class="anchor" aria-label="Permalink: Install" href="#install"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Build requirements</p>

    <ul>

    <li>Python &gt;= 3.7</li>

    <li>C++14 compliant gcc (&gt;= gcc 7.3)</li>

    <li>gdal &gt;=3.8, cgal, boost, vtk&gt;=9, metis</li>

    </ul>

    <pre><code>$ pip install mesher

    </code></pre>

    <p>or</p>

    <pre><code>$ conda install mesher

    </code></pre>

    <p>Detailed documentation on how to install is given <a href="https://mesher-hydro.readthedocs.io/en/latest/installation.html"
    rel="nofollow">here</a>.</p>

    <div class="markdown-heading"><h4 class="heading-element">Spack</h4><a id="user-content-spack"
    class="anchor" aria-label="Permalink: Spack" href="#spack"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>Clone <a href="https://github.com/Chrismarsh/spack-repo">https://github.com/Chrismarsh/spack-repo</a>

    </li>

    <li>Add <code>spack-repo</code> to spack <code>repos.yaml</code> <a href="https://spack.readthedocs.io/en/latest/repositories.html"
    rel="nofollow">https://spack.readthedocs.io/en/latest/repositories.html</a>

    </li>

    <li><code>spack install py-mesher</code></li>

    </ul>

    '
  stargazers_count: 26
  subscribers_count: 7
  topics: []
  updated_at: 1715557678.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/23.08/oneapi-x86_64/spack.yaml
  - environments/24.05/arm64-gcc-cuda-ubuntu22.04/spack.yaml
  - environments/24.02/amd64-gcc-cpu-ubuntu20.04/spack.yaml
  - environments/22.05/oneapi.spack.yaml
  - environments/24.02/arm64-gcc-cuda-ubuntu20.04/spack.yaml
  - environments/23.02/cuda-ppc64le/spack.yaml
  - environments/21.08/spack.yaml
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/23.08/cuda-aarch64/spack.yaml
  - environments/22.05/cuda-ppc64le.spack.yaml
  - environments/22.08/cuda-aarch64.spack.yaml
  - environments/24.05/amd64-gcc-cuda-ubuntu22.04/spack.yaml
  - environments/23.05/cuda-x86_64/spack.yaml
  - environments/24.05/amd64-oneapi-ubuntu22.04/spack.yaml
  - environments/22.08/cuda-ppc64le.spack.yaml
  - environments/22.05/cuda-x86_64.spack.yaml
  - environments/22.05/rocm.spack.yaml
  - environments/23.08/cuda-x86_64/spack.yaml
  - environments/24.05/arm64-gcc-cpu-ubuntu22.04/spack.yaml
  - environments/23.02/cuda-x86_64/spack.yaml
  - environments/23.11/cuda-ppc64le/spack.yaml
  - environments/24.05/ppc64-gcc-cuda-ubuntu20.04/spack.yaml
  - environments/24.05/amd64-gcc-cpu-ubuntu22.04/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: v24.05
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d548c41497648f97178f367a87401d9f73f533daf22804b7fef0b85f7d8e3ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/5d548c41497648f97178f367a87401d9f73f533daf22804b7fef0b85f7d8e3ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/b8248e747ce21198bc44bfd5d4a8f9e5ec64a7a2c68b6e619cbfb5301a954f91/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/b8248e747ce21198bc44bfd5d4a8f9e5ec64a7a2c68b6e619cbfb5301a954f91/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/1bfba11ecd687250fe889e3506d82375ddaaed674b6fd8cda2605a56dd15ad89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/1bfba11ecd687250fe889e3506d82375ddaaed674b6fd8cda2605a56dd15ad89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/e0d5e7562db6d38a29491be3391fe00bbcb5813c3a1a60a0e7bfbf4c32fa19be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/e0d5e7562db6d38a29491be3391fe00bbcb5813c3a1a60a0e7bfbf4c32fa19be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">E4S</h1><a id=\"user-content-e4s\" class=\"anchor\" aria-label=\"\
    Permalink: E4S\" href=\"#e4s\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >Extreme-scale Scientific Software Stack (E4S)</a> is a community effort to provide\
    \ open source\nsoftware packages for developing, deploying and running scientific\
    \ applications on high-performance\ncomputing (HPC) platforms. E4S provides from-source\
    \ builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Useful Links</h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-label=\"Permalink: Useful Links\" href=\"#useful-links\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>User Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\"\
    >https://e4s.readthedocs.io</a>\n</li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub:\
    \ <a href=\"https://github.com/E4S-Project/\">https://github.com/E4S-Project/</a>\n\
    </li>\n<li>E4S Slack Channel: <a href=\"https://e4s-project.slack.com\" rel=\"\
    nofollow\">https://e4s-project.slack.com</a>\n</li>\n<li>Slack Channel Invitation:\
    \ <a href=\"https://communityinviter.com/apps/e4s-project/e4s\" rel=\"nofollow\"\
    >https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n<li>E4S Dashboard:\
    \ <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Related\
    \ Projects</h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-label=\"\
    Permalink: Related Projects\" href=\"#related-projects\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<ul>\n<li>\n<p><a href=\"\
    https://github.com/E4S-Project/E4S-Project.github.io\">E4S-Project/E4S-Project.github.io</a>\
    \ - E4S Documentation repo that is hosted on <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">License</h2><a id=\"user-content-license\" class=\"\
    anchor\" aria-label=\"Permalink: License\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>E4S is released as\
    \ MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Contact</h2><a id=\"user-content-contact\" class=\"anchor\" aria-label=\"Permalink:\
    \ Contact\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 25
  subscribers_count: 10
  topics: []
  updated_at: 1716324686.0
E4S-Project/e4s-alc:
  data_format: 2
  description: "E4S \xE0 la carte is a tool that allows a user to customize a container\
    \ image by adding packages to it. These can be system packages and Spack packages. "
  filenames:
  - examples/ubuntu/light_spack.yaml
  full_name: E4S-Project/e4s-alc
  latest_release: v1.0.2
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">E4S \xE0\
    \ la Carte</h1><a id=\"user-content-e4s-\xE0-la-carte\" class=\"anchor\" aria-label=\"\
    Permalink: E4S \xE0 la Carte\" href=\"#e4s-\xE0-la-carte\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Description</h2><a id=\"user-content-description\"\
    \ class=\"anchor\" aria-label=\"Permalink: Description\" href=\"#description\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>E4S \xE0 la Carte is a practical tool designed to facilitate the generation\
    \ of Dockerfiles and Singularity definition files infused with OS packages, Spack\
    \ packages, as well as custom commands. In the simplifying the process, this tool\
    \ targets the elimination of manual definition files scripting, enabling users\
    \ to concentrate on critical aspects such as application-specific resources and\
    \ configurations.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Documentation</h2><a id=\"user-content-documentation\" class=\"anchor\" aria-label=\"\
    Permalink: Documentation\" href=\"#documentation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p><a href=\"https://e4s-alc.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e5acd072c8c398a55a66f319a1a3a5b0323cf625b6adbb1c37566b74cd56fd11/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732d616c632f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/e4s-alc/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our documentation is located here: <a\
    \ href=\"https://e4s-alc.readthedocs.io/en/latest/\" rel=\"nofollow\">Documentation</a></p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Overview</h2><a\
    \ id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\"\
    \ href=\"#overview\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The <code>e4s-alc</code> tool is designed to facilitate\
    \ the process of crafting Dockerfiles and Singularity definition files. This tool\
    \ leverages <code>.yaml</code> files as input to generate images' definition files.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Installation</h2><a\
    \ id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Installing <code>e4s-alc</code> is simple.</p>\n<p>Clone\
    \ the project:</p>\n<pre><code>git clone https://github.com/E4S-Project/e4s-alc.git\n\
    </code></pre>\n<p>Run <code>make</code>:</p>\n<pre><code>cd e4s-alc &amp;&amp;\
    \ make install\n</code></pre>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Example</h2><a id=\"user-content-example\" class=\"anchor\" aria-label=\"Permalink:\
    \ Example\" href=\"#example\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Here is an example <code>.yaml</code> file. This input\
    \ file creates a Dockerfile using a Rhel8 base image. It installs gcc@11.2 and\
    \ installs kokkos using gcc@11.2. Notice how I've chosen to exclude parameters\
    \ to fit my build. This is one of the example <code>.yaml</code> files in the\
    \ <code>examples</code> directory.</p>\n<pre><code># rhel8-gcc11.2-kokkos.yaml\n\
    \n######## Base group ########\nbackend: podman\nregistry: registry.access.redhat.com\n\
    image: ubi8/ubi\n\n####### Spack group #######\nspack-version: latest\nspack-compiler:\
    \ gcc@11.2\nspack-packages:\n  - kokkos\n</code></pre>\n<p>I build the Dockerfile\
    \ and image with:</p>\n<pre><code>e4s-alc create -f rhel8-gcc11.2-kokkos.yaml\n\
    podman build .\n</code></pre>\n<p>Then, run the image in interactive mode and\
    \ inspect the install:</p>\n<pre><code>[root@c5ad0d45ba1d /]# module avail\n-----------------------------\
    \ /modulefiles/linux-rhel8-power9le -----------------------------------\ngcc/11.2.0\
    \  kokkos/4.0.01  \n[root@c5ad0d45ba1d /]# module load gcc\n[root@c5ad0d45ba1d\
    \ /]# module load kokkos\n</code></pre>\n<div class=\"markdown-heading\"><h4 class=\"\
    heading-element\">Example YAML file with matrix feature</h4><a id=\"user-content-example-yaml-file-with-matrix-feature\"\
    \ class=\"anchor\" aria-label=\"Permalink: Example YAML file with matrix feature\"\
    \ href=\"#example-yaml-file-with-matrix-feature\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Here is an example <code>.yaml</code>\
    \ file that creates multiple Dockerfiles using a single <code>.yaml</code> file.\
    \ Notice that for each <code>registry-image-matrix</code> item that we specify,\
    \ we build out a Dockerfile using each <code>spack-compiler-matrix</code> item.\
    \ This feature could be powerful for testing Spack packages across different operating\
    \ systems and compilers.</p>\n<pre><code>backend: podman\nregistry-image-matrix:\n\
    \  - registry.access.redhat.com/ubi8/ubi\n  - ubuntu:20.04\n\n####### Spack group\
    \ #######\nspack: True\nspack-version: latest\n\nspack-compiler-matrix:\n  - gcc@8.5.0\
    \ \n  - gcc@11.2.0 \n  - gcc@12.0\n  - gcc@12.3.0\n\nspack-packages: \n  - kokkos\n\
    </code></pre>\n<p>This <code>.yaml</code> file would create a directory named\
    \ <code>dockerfiles</code> that contains the following Dockerfiles:</p>\n<pre><code>Dockerfile.rhel8.8-gcc@8.5.0\n\
    Dockerfile.rhel8.8-gcc@11.5.0\nDockerfile.rhel8.8-gcc@12.0\nDockerfile.rhel8.8-gcc@12.3.0\n\
    Dockerfile.ubuntu20.04-gcc@8.5.0\nDockerfile.ubuntu20.04-gcc@11.5.0\nDockerfile.ubuntu20.04-gcc@12.0\n\
    Dockerfile.ubuntu20.04-gcc@12.3.0\n</code></pre>\n"
  stargazers_count: 5
  subscribers_count: 4
  topics: []
  updated_at: 1716571832.0
ECP-CANDLE/Supervisor:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: ECP-CANDLE/Supervisor
  latest_release: null
  stargazers_count: 7
  subscribers_count: 11
  topics:
  - nci-doe-collaboration-capability
  updated_at: 1716583724.0
EnzymeAD/CMake-Template:
  data_format: 2
  description: "\U0001F528 A template for using Enzyme with CMake"
  filenames:
  - spack.yaml
  full_name: EnzymeAD/CMake-Template
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">CMake-Template</h1><a\
    \ id=\"user-content-cmake-template\" class=\"anchor\" aria-label=\"Permalink:\
    \ CMake-Template\" href=\"#cmake-template\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Usage</h2><a id=\"user-content-usage\" class=\"anchor\"\
    \ aria-label=\"Permalink: Usage\" href=\"#usage\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"><h3\
    \ class=\"heading-element\">Install dependencies</h3><a id=\"user-content-install-dependencies\"\
    \ class=\"anchor\" aria-label=\"Permalink: Install dependencies\" href=\"#install-dependencies\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>cmake</li>\n<li>make</li>\n<li>llvm</li>\n<li>enzyme</li>\n</ul>\n<p>Using\
    \ spack:</p>\n<pre><code>spack env activate .\nspack install\n</code></pre>\n\
    <p>Using homebrew:</p>\n<pre><code>brew bundle install\n</code></pre>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Configure and build</h3><a id=\"\
    user-content-configure-and-build\" class=\"anchor\" aria-label=\"Permalink: Configure\
    \ and build\" href=\"#configure-and-build\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Configure the CMake project using\
    \ the version of Enzyme installed on the system:</p>\n<pre><code>mkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake\n</code></pre>\n<p>Configure the CMake project using\
    \ a custom Enzyme version:</p>\n<pre><code>mkdir build &amp;&amp; cd build\ncmake\
    \ -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics:
  - cmake
  - enzyme-ad
  - template
  updated_at: 1687815556.0
ExCALIBUR-NEPTUNE/NESO:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: ExCALIBUR-NEPTUNE/NESO
  latest_release: v0.1.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">NESO (Neptune\
    \ Exploratory SOftware)</h1><a id=\"user-content-neso-neptune-exploratory-software\"\
    \ class=\"anchor\" aria-label=\"Permalink: NESO (Neptune Exploratory SOftware)\"\
    \ href=\"#neso-neptune-exploratory-software\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>This is a work-in-progress respository\
    \ for exploring the implementation of\na series of tokamak exhaust relevant models\
    \ combining high order finite\nelements with particles, written in C++ and SYCL.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Dependencies</h2><a\
    \ id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\"\
    \ href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<ul>\n<li>CMake</li>\n<li>Boost &gt;= 1.74 (for tests)</li>\n\
    <li>SYCL implementation Hipsycl and fftw or OneAPI and MKL.</li>\n<li>Nektar++</li>\n\
    <li>NESO-Particles</li>\n</ul>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Building with Spack</h3><a id=\"user-content-building-with-spack\" class=\"anchor\"\
    \ aria-label=\"Permalink: Building with Spack\" href=\"#building-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The easiest way to install NESO is using the\n<a href=\"https://spack.readthedocs.io/en/latest/index.html\"\
    \ rel=\"nofollow\">Spack package manager</a>, although\nthis can take a few hours\
    \ the first time you do it or if you change\ncompilers. This repository has been\
    \ set up so you can use a\nvariation of the <a href=\"https://spack-tutorial.readthedocs.io/en/latest/tutorial_developer_workflows.html\"\
    \ rel=\"nofollow\">Spack developer\nworkflow</a>. Simply\nrun the following commands\
    \ at the top level of the repository:</p>\n<p>If you don't already have Spack\
    \ available on your computer, install it\naccording to the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">official documentation</a>, or as follows:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Ensure all prerequisites are installed</span>\napt update <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> For Ubuntu; other distros have their own\
    \ commands</span>\napt install build-essential ca-certificates coreutils curl\
    \ environment-modules gfortran git gpg lsb-release python3 python3-distutils python3-venv\
    \ unzip zip\n\ngit clone -c feature.manyFiles=true -b v0.19.0 https://github.com/spack/spack.git\
    \ <span class=\"pl-smi\">$HOME</span>/.spack\n<span class=\"pl-c1\">echo</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">'</span>export SPACK_ROOT=$HOME/.spack<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span\
    \ class=\"pl-smi\">$HOME</span>/.bashrc\n<span class=\"pl-c1\">echo</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span>source $SPACK_ROOT/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span\
    \ class=\"pl-smi\">$HOME</span>/.bashrc\n<span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-smi\">$HOME</span>/.spack\n<span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$SPACK_ROOT</span>/share/spack/setup-env.sh</pre></div>\n<p>Next,\
    \ install the Intel compilers if they are not already present on\nyour computer.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>spack install intel-oneapi-compilers\n\
    spack load intel-oneapi-compilers\nspack compiler find\nspack unload intel-oneapi-compilers</pre></div>\n\
    <p>Now, activate the NESO development environment and build it and its\ndependencies.\
    \ This must be done from the top level of this\nrepository.</p>\n<pre><code>git\
    \ submodule update --init\n. activate\nspack install\n</code></pre>\n<p>The <code>activate</code>\
    \ script sets some useful environment variables and runs\n<code>spack activate\
    \ ...</code>. This activates an <a href=\"https://spack.readthedocs.io/en/latest/environments.html#anonymous-environments\"\
    \ rel=\"nofollow\">anonymous Spack\nenvironment</a>\nbased on the settings in\
    \ <a href=\"spack.yaml\">the spack.yaml file</a>. These\nconfigurations tell Spack\
    \ to install NESO and all of its\ndependencies. Rather than pulling fresh NESO\
    \ and Nektar++ source code\nfrom GitHub, it will use the copy of the code in your\
    \ current working\ndirectory and the Nektar++ submodule (respectively). You can\
    \ leave\nthis environment at any time by running <code>deactivate</code>.</p>\n\
    <p><code>spack install</code> will build two copies of NESO: one with\nGCC/hipSYCL/FFTW3\
    \ and one with Intel's OneAPI/DPC++/MKL. These\npackages and their dependencies\
    \ will be installed in the usual Spack\nlocations. They will also be linked into\
    \ <a href=\"https://spack.readthedocs.io/en/latest/environments.html#filesystem-views\"\
    \ rel=\"nofollow\">\"filesystem\nviews\"</a>\n<code>view/gcc-hipsycl</code> and\
    \ <code>view/oneapi-dpcpp</code>. The NESO builds will be\ndone in directories\
    \ called something like <code>spack-build-abc1234</code> (the\nhashes at the end\
    \ will differ). If you change your spack installation\nin some way (e.g., upgrading\
    \ the version of a dependency) then the\nhash will change and NESO and/or Nektar++\
    \ will be rebuilt. The\nactivation provides the convenience command <code>cleanup</code>\
    \ to delete these\nold builds.</p>\n<p>In order to tell which build is which,\
    \ symlinks <code>builds/gcc-hipsycl</code>\nand <code>builds/oneapi-dpcpp</code>\
    \ are provided. As Nektar++ is being built\nfrom the submodule, its build trees\
    \ are located at\n<code>nektar/spack-build-abc1234</code> (the hashes at the end\
    \ will differ) and\ncan be accessed with symlinks <code>nektar/builds/gcc</code>\
    \ and\n<code>nektar/builds/oneapi</code>. Test binaries will be contained within\n\
    these build directories. The activation script launches a background\ntask which\
    \ regularly checks whether the hashes of your NESO and\nNektar++ builds has changed.\
    \ If they have, it will update the\nsymlinks. They will also be checked whenever\
    \ the environment is\nactivated or deactivated.</p>\n<p>It has been found that\
    \ the oneAPI and clang\ncompilers struggle to build NumPy and Boost due to very\
    \ large memory\nrequirements. As such, the oneAPI build of NESO compiles these\n\
    dependencies using another compiler  (the Intel Classic compilers by default).\
    \ Feel free to\nexperiment with changing these or seeing if there is a way to\
    \ make the\nbuilds work with oneAPI.</p>\n<div class=\"markdown-heading\"><h4\
    \ class=\"heading-element\">Developing</h4><a id=\"user-content-developing\" class=\"\
    anchor\" aria-label=\"Permalink: Developing\" href=\"#developing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>As you develop the\
    \ code, there are a few options for how you\nrecompile. One is simply to run <code>spack\
    \ install</code> again. This will reuse\nthe existing build directory and reinstall\
    \ the results of the\nbuild. The build environment used is determined by the package\n\
    configuration for NESO (as specificed in the NESO <a href=\"https://github.com/ExCALIBUR-NEPTUNE/NESO-Spack\"\
    >package\nrepository</a> and is\nthe same as if you were doing a traditional Spack\
    \ installation of a\nnamed version of NESO. This has the particular advantage\
    \ of building\nwith all toolchaings (i.e., GCC, OneAPI) at one time. It also works\n\
    well if you are developing NESO and Nektar++ simultaneously, as it\nwill rebuild\
    \ both. The main disadvantage of this approach is that\nSpack hides the output\
    \ of CMake during the build process and will only\nshow you any information on\
    \ the build if there is an error. This means\nyou will likely miss any compiler\
    \ warnings, unless you check the build\nlogs. There is also some overhead associated\
    \ with running Spack, which\nmakes the build a little slow.</p>\n<p>An alternative\
    \ approach is to prefix your usual build commands with\n<code>spack build-env\
    \ neso%gcc</code> or <code>spack build-env neso%oneapi</code> (depending\non which\
    \ compiler you want to use). This will cause the commands to be run in the\nsame\
    \ build environment as when installing that version of NESO. For example, you\n\
    could run</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack build-env\
    \ neso%gcc cmake <span class=\"pl-c1\">.</span> -B build\nspack build-env neso%gcc\
    \ cmake --build build</pre></div>\n<p>This would cause the build to occur in the\
    \ directory <code>build</code>. This\napproach works quite well. A slight downside\
    \ is the commands are\na bit cumbersome. It also won't build for both compilers\
    \ at once,\nalthough you might not want to do that anyway, early during the development\n\
    of a new feature.</p>\n<p>Finally, you could take advantage of the filesystem\
    \ views created\nwhen you installed the environment and which give you access\n\
    to all of the resources for the build that you need. For example, you\ncould run</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>cmake -DCMAKE_PREFIX_PATH=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span class=\"pl-pds\">)</span></span>/gcc-hipsycl\
    \ <span class=\"pl-c1\">.</span> -B build\ncmake --build build</pre></div>\n<p>CMake\
    \ will automatically be able to find all of the packages it needs\nin <code>gcc-hipsycl</code>.\
    \ The downside of this approach is that there is a\nrisk CMake will end up using\
    \ a different compiler or compiler version\nthan intended. This is especially\
    \ likely if not using a system\ncompiler. You should ensure you are aware of what\
    \ compilers you have\ninstalled and, if necessary, explicitly specify to CMake\
    \ which you\nwant to use.</p>\n<p>In general, it is recommended to use the <code>spack\
    \ build-env ...</code>\ncommand for compiling earlier in the development process\
    \ (if you\naren't simultaneously making changes to Nektar++), to ensure you see\n\
    any warnings and so you aren't spending extra times compiling things\ntwice. Once\
    \ you believe you have a working implementation with one\ncompiler (of if you\
    \ are working on NESO and Nektar++ simultaneously),\nyou can use <code>spack install</code>\
    \ to test the build against other\ncompilers. It is <em>not</em> recommended to\
    \ use the Spack views, as building\nthis way is less likely to be reproducible.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Manually Installing\
    \ Dependencies</h3><a id=\"user-content-manually-installing-dependencies\" class=\"\
    anchor\" aria-label=\"Permalink: Manually Installing Dependencies\" href=\"#manually-installing-dependencies\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h4 class=\"heading-element\">CMake</h4><a id=\"\
    user-content-cmake\" class=\"anchor\" aria-label=\"Permalink: CMake\" href=\"\
    #cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Ensure a recent version of <a href=\"https://cmake.org/download/\" rel=\"nofollow\"\
    >CMake</a> is available.\nIf necessary, install with</p>\n<pre><code>wget https://github.com/Kitware/CMake/releases/download/v3.23.1/cmake-3.23.1.tar.gz\n\
    tar xvf cmake-3.23.1.tar.gz\ncd cmake-3.23.1/\n./configure\nmake\n</code></pre>\n\
    <div class=\"markdown-heading\"><h4 class=\"heading-element\">Boost</h4><a id=\"\
    user-content-boost\" class=\"anchor\" aria-label=\"Permalink: Boost\" href=\"\
    #boost\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The test suite requires the <a href=\"https://www.boost.org/\" rel=\"nofollow\"\
    >Boost library</a> (version &gt;= 1.74).\nIf this is not available on your system,\
    \ it can be built from source by doing</p>\n<pre><code>wget https://boostorg.jfrog.io/artifactory/main/release/1.79.0/source/boost_1_79_0.tar.gz\n\
    tar xvf boost_1_79_0.tar.gz\ncd boost_1_79_0/\n./bootstrap.sh\n./b2\n</code></pre>\n\
    <p>If the install is not automatically found by cmake, specify the path to the\n\
    install dir at configure time:</p>\n<pre><code>cmake -DBoost_INCLUDE_DIR=/path/to/boost_1_79_0/\
    \ . -B build\n</code></pre>\n<div class=\"markdown-heading\"><h4 class=\"heading-element\"\
    >Nektar++</h4><a id=\"user-content-nektar\" class=\"anchor\" aria-label=\"Permalink:\
    \ Nektar++\" href=\"#nektar\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>To build with Nektar++, ensure that Nektar++ is installed\
    \ on your system.\nDetailed instructions can be found in the <a href=\"https://doc.nektar.info/userguide/latest/user-guidese3.html#x7-60001.3\"\
    \ rel=\"nofollow\">Nektar user guide</a>,\nbut briefly,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>git clone https://gitlab.nektar.info/nektar/nektar\n\
    <span class=\"pl-c1\">cd</span> nektar\nmkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build\ncmake .. \ncmake --build <span class=\"\
    pl-c1\">.</span>\nmake install</pre></div>\n<p>should install Nektar++.</p>\n\
    <p>To build NESO with Nektar++, set the <code>Nektar++_DIR</code> flag in cmake,\
    \ e.g.</p>\n<pre><code>cmake -DNektar++_DIR=/path/to/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>where <code>/path/to/nektar/build/dist/lib64/nektar++/cmake</code>\
    \ is the folder containing\nthe <code>Nektar++Config.cmake</code> file.\nNote\
    \ that for this file to exist, you must do <code>make install</code> at the end\
    \ of the\nNektar++ build.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >NESO-Particles</h3><a id=\"user-content-neso-particles\" class=\"anchor\" aria-label=\"\
    Permalink: NESO-Particles\" href=\"#neso-particles\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Install NESO-Particles\
    \ by following the installation instructions at <a href=\"https://github.com/ExCALIBUR-NEPTUNE/NESO-Particles\"\
    >https://github.com/ExCALIBUR-NEPTUNE/NESO-Particles</a>. Additional configuration\
    \ options for NESO-Particles can be passed when NESO is configured through cmake.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">NESO</h3><a id=\"\
    user-content-neso\" class=\"anchor\" aria-label=\"Permalink: NESO\" href=\"#neso\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Manually building\
    \ NESO</h3><a id=\"user-content-manually-building-neso\" class=\"anchor\" aria-label=\"\
    Permalink: Manually building NESO\" href=\"#manually-building-neso\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>To build the code\
    \ and the tests, do</p>\n<pre><code>cmake . -B build\ncmake --build build\n</code></pre>\n\
    <p>It may be necessary to tell CMake the location of dependencies:</p>\n<ul>\n\
    <li>Boost by setting <code>-DBoost_INCLUDE_DIR</code>\n</li>\n<li>SYCL compiler\
    \ by setting <code>-DCMAKE_CXX_COMPILER</code>\n</li>\n<li>Nektar++ by setting\
    \ the location of <code>Nektar++Config.cmake</code> using <code>-DNektar++_DIR</code>\n\
    </li>\n</ul>\n<p>For example:</p>\n<pre><code>cmake -DCMAKE_CXX_COMPILER=dpcpp\
    \ -DBoost_INCLUDE_DIR=/root/code/boost_1_78_0 -DNektar++_DIR=/root/code/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>The executable <code>NESO</code>\
    \ is created in <code>bin</code>.</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Handling Submodules when Developing</h2><a id=\"user-content-handling-submodules-when-developing\"\
    \ class=\"anchor\" aria-label=\"Permalink: Handling Submodules when Developing\"\
    \ href=\"#handling-submodules-when-developing\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>This repository contains some git\
    \ submodules, for code which is likely\nto undergo development tightly-coupled\
    \ with NESO (e.g., Nektar) or\nwhich it is convenient to distribute this way (NESO-spack).\
    \ When\nchecking out different branches, on which submodules are at different\n\
    commits, it can be easy to end up with working against different\nversions of\
    \ submodules than you think. This can cause headaches when\ntrying to reproduce\
    \ certain behaviour. Run <code>git submodule update --recursive</code> to ensure\
    \ everything is at the correct commit. You can\navoid this issue altogether by\
    \ using <code>git checkout --recurse-submodules</code>. You can also set this\
    \ as a default for your\ncopy of the repository by running <code>git config --local\
    \ submodule.recurse true</code>. Note, however, that these latter two options\n\
    can cause git to complain if trying to switch between two branches,\nonly one\
    \ of which contains a submodule.</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">System-specific information</h2><a id=\"user-content-system-specific-information\"\
    \ class=\"anchor\" aria-label=\"Permalink: System-specific information\" href=\"\
    #system-specific-information\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Dirac (CSD3 @ Cambridge)</h3><a id=\"user-content-dirac-csd3--cambridge\" class=\"\
    anchor\" aria-label=\"Permalink: Dirac (CSD3 @ Cambridge)\" href=\"#dirac-csd3--cambridge\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>module unload intel/compilers/2017.4\nmodule unload intel/mkl/2017.4\n\
    module load gcc/11\nmodule load intel/oneapi/2022.1.0/compiler\nmodule load intel/oneapi/2022.1.0/mkl\n\
    module load intel/oneapi/2022.1.0/tbb\nexport  LD_LIBRARY_PATH=/usr/local/software/intel/oneapi/2022.1/compiler/latest/linux/lib:$LD_LIBRARY_PATH\n\
    </code></pre>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Testing</h2><a\
    \ id=\"user-content-testing\" class=\"anchor\" aria-label=\"Permalink: Testing\"\
    \ href=\"#testing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>CMake also builds a suite unit tests (e.g. <code>&lt;build_dir&gt;/test/unitTests</code>)\n\
    and integration tests (<code>&lt;build_dir&gt;/test/integrationTests</code>).\
    \ The build\ndirectories are <code>builds/gcc-hipsycl</code> and <code>builds/oneapi-dpcpp</code>.</p>\n\
    <p>A subset of the tests may be run using appropriate flags:\ne.g. <code>path/to/testExecutable\
    \ --gtest_filter=TestSuiteName.TestName</code>.\nSee the <a href=\"http://google.github.io/googletest/\"\
    \ rel=\"nofollow\">googletest user guide</a>\nfor more info, especially with regards\
    \ to running <a href=\"https://google.github.io/googletest/advanced.html#selecting-tests\"\
    \ rel=\"nofollow\">specific\ntests</a>.</p>\n<p>Alternatively, you can call\n\
    <a href=\"https://cmake.org/cmake/help/latest/manual/ctest.1.html\" rel=\"nofollow\"\
    >CTest</a> from\nwithin the build directory to execute your tests.</p>\n<div class=\"\
    markdown-heading\"><h1 class=\"heading-element\">Solvers</h1><a id=\"user-content-solvers\"\
    \ class=\"anchor\" aria-label=\"Permalink: Solvers\" href=\"#solvers\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Each solver has</p>\n\
    <ul>\n<li>Source code: <code>solvers/&lt;solver_name&gt;</code>\n</li>\n<li>Integration\
    \ tests: <code>test/integration/solvers/&lt;solver_name&gt;</code>\n</li>\n<li>Examples:\
    \ <code>examples/&lt;solver_name&gt;/&lt;example_name&gt;</code>\n</li>\n</ul>\n\
    <p>To run a solver example:</p>\n<pre><code>./scripts/run_eg.sh  [solver_name]\
    \ [example_name] &lt;-n num_MPI&gt; &lt;-b build_dir&gt;\n</code></pre>\n<p>which\
    \ will look for the solver executable in the most recently modified spack-build-*\
    \ directory, unless one is supplied with <code>-b</code>.  Output is generated\
    \ in <code>example-runs/&lt;solver_name&gt;/&lt;example_name&gt;</code>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Address Sanitizers</h2><a\
    \ id=\"user-content-address-sanitizers\" class=\"anchor\" aria-label=\"Permalink:\
    \ Address Sanitizers\" href=\"#address-sanitizers\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>To debug for memory leaks,\
    \ compile with the options</p>\n<pre><code>cmake . -B -DENABLE_SANITIZER_ADDRESS=on\
    \ -DENABLE_SANITIZER_LEAK=on\n</code></pre>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Generating meshes</h2><a id=\"user-content-generating-meshes\"\
    \ class=\"anchor\" aria-label=\"Permalink: Generating meshes\" href=\"#generating-meshes\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>One pipeline for creating simple Nektar++ meshes is through Gmsh and NekMesh.\n\
    .geo -&gt; .msh in Gmsh\n.msh -&gt; .xml with NekMesh</p>\n<p>A .geo file can\
    \ be created using the Gmsh UI (each command adds a new line to the .geo file.\
    \  For simple meshes it may be easier to produce the .geo file in a text editor.\
    \  .geo files can also be loaded into the UI to edit.</p>\n<details>\n  <summary>Expand</summary>\n\
    \  mesh.geo\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">//</span>Create construction points for the corners\
    \ of the mesh</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Point(i)\
    \ = (x, y, z, scale)</span>\n<span class=\"pl-c1\">Point</span>(<span class=\"\
    pl-c1\">1</span>) = {<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>,\
    \ <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1.0</span>};\n<span class=\"\
    pl-c1\">Point</span>(<span class=\"pl-c1\">2</span>) = {<span class=\"pl-c1\"\
    >0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span\
    \ class=\"pl-c1\">1.0</span>};\n<span class=\"pl-c1\">Point</span>(<span class=\"\
    pl-c1\">3</span>) = {<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>,\
    \ <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1.0</span>};\n<span class=\"\
    pl-c1\">Point</span>(<span class=\"pl-c1\">4</span>) = {<span class=\"pl-c1\"\
    >1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span\
    \ class=\"pl-c1\">1.0</span>};\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Create\
    \ construction lines for the edges of the mesh</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span>Line(i) = (Start_i, End_i) </span>\n<span class=\"pl-en\"\
    >Line</span>(<span class=\"pl-c1\">1</span>) = {<span class=\"pl-c1\">1</span>,\
    \ <span class=\"pl-c1\">2</span>};\n<span class=\"pl-en\">Line</span>(<span class=\"\
    pl-c1\">2</span>) = {<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>};\n\
    <span class=\"pl-en\">Line</span>(<span class=\"pl-c1\">3</span>) = {<span class=\"\
    pl-c1\">3</span>, <span class=\"pl-c1\">4</span>};\n<span class=\"pl-en\">Line</span>(<span\
    \ class=\"pl-c1\">4</span>) = {<span class=\"pl-c1\">4</span>, <span class=\"\
    pl-c1\">1</span>};\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Add physical\
    \ lines from the construction lines</span>\nPhysical <span class=\"pl-en\">Line</span>(<span\
    \ class=\"pl-c1\">5</span>) = {<span class=\"pl-c1\">1</span>};\nPhysical <span\
    \ class=\"pl-en\">Line</span>(<span class=\"pl-c1\">6</span>) = {<span class=\"\
    pl-c1\">2</span>};\nPhysical <span class=\"pl-en\">Line</span>(<span class=\"\
    pl-c1\">7</span>) = {<span class=\"pl-c1\">3</span>};\nPhysical <span class=\"\
    pl-en\">Line</span>(<span class=\"pl-c1\">8</span>) = {<span class=\"pl-c1\">4</span>};\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Close the lines with a curve\
    \ loop</span>\nCurve <span class=\"pl-en\">Loop</span>(<span class=\"pl-c1\">1</span>)\
    \ = {<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"\
    pl-c1\">3</span>,<span class=\"pl-c1\">4</span>};\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span>Create a construction surface out of the curve loop</span>\n\
    Plane <span class=\"pl-en\">Surface</span>(<span class=\"pl-c1\">1</span>) = {<span\
    \ class=\"pl-c1\">1</span>};\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Create\
    \ a physical surface out of the construction surface</span>\nPhysical <span class=\"\
    pl-en\">Surface</span>(<span class=\"pl-c1\">1</span>) = {<span class=\"pl-c1\"\
    >1</span>};\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>A transfinite\
    \ line means that 65 points are created along lines</span>\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">//</span> 1 and 3, which will form the corners of 64 mesh\
    \ elements.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Progression\
    \ 1 means they are uniformly spaced</span>\nTransfinite Line {<span class=\"pl-c1\"\
    >1</span>, <span class=\"pl-c1\">3</span>} = <span class=\"pl-c1\">65</span> Using\
    \ Progression <span class=\"pl-c1\">1</span>;\nTransfinite Line {<span class=\"\
    pl-c1\">2</span>, <span class=\"pl-c1\">4</span>} = <span class=\"pl-c1\">2</span>\
    \ Using Progression <span class=\"pl-c1\">1</span>;\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span>Set the surface</span>\nTransfinite Surface {<span class=\"\
    pl-c1\">1</span>};\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>The default\
    \ is tris, this line is necessary to produce quads</span>\nRecombine Surface <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>*<span class=\"pl-pds\">\"</span></span>;</pre></div>\n\
    </details>\n<p>Selecting 2D mesh in Gmsh and saving will produce a .msh file.\
    \  The mesh should be visible in the UI to check before saving.  Alternatively\
    \ for simple meshes one can jump straight to this step by writing the .msh file\
    \ in a text editor.</p>\n<details>\n  <summary>Expand</summary>\n   mesh.msh\n\
    <pre><code>$MeshFormat\n4.1 0 8\n$EndMeshFormat\n$Entities\n4 4 1 0\n.\n.\n.\n\
    $EndEntities\n$Nodes\n9 130 1 130\n0 1 0 1\n.\n.\n.\n$EndNodes\n$Elements\n5 194\
    \ 1 194\n1 1 1 64\n.\n.\n.\n$EndElements\n</code></pre>\n</details>\n<p>Next call\
    \ NekMesh on the .msh file to convert it to .xml format</p>\n<pre><code>./NekMesh\
    \ path/to/src/mesh.msh path/to/dst/mesh.xml\n</code></pre>\n<p>This will produce\
    \ a .xml file like the following:</p>\n<details>\n  <summary>Expand</summary>\n\
    \   mesh.xml\n<pre><code>&lt;NEKTAR&gt;\n  &lt;GEOMETRY DIM=\"2\" SPACE=\"2\"\
    &gt;\n    &lt;VERTEX COMPRESSED=\"B64Z-LittleEndian\" BITSIZE=\"64\"&gt;eJx912dsjWEYxvFjz9qUmq3aW+1Zu0VttalVWlup7TwSMT4UH3wQiZFIDoKQVFqCKEWt2tUqpWZRW+1RrqfJfee9Ivrljvz7u5/Tc95z3sPl+v9PPse/3nXlnp96YDDmJvm9AvT7a0/k/v3ZKL3gP/1O6YXI5xyH3yG9MPnrszD3SC9CPugS/G7pRcm3s+cfkl6M/KIj8AelFye/bgzmYeklyFdPgY+VXpJ8mn38R6R7kZ94BT5eeinyvgbzuPTS5D1J8MeklyHfwf79CdLLkvdLgD8pvRz5sCGYp6WXJ18kHf6U9Ark19vn74z0iuS33YRPlF6J/MEpmOeke5NvmQx/Vnpl8in2+T8vvQr5pHPwSdJ9yP+IxrwovSr5sfb5uyC9Gnl/g3lZenXy74/CX5Jeg/yA9ZhXpNckvyYWPll6LfJ51/816b7kvQ/AX5XuRz45BPO69NrkQ+3rp/v9yeddPzek1yHvew1e99clnxOKeVN6PfLZl+F1f33ya+31d0t6A/JxF+B1f0PyPmGYKdIbkTf2+tH9jckfsNfvbelNyPdLhNf9Tcl3j8BMld6MfCV7/en+5uRT7fWfJr0F+Uz7+av7W5KPnI95R3oA+X32+tX9rcj/su+fdOmtyS+Mg9f9bchvXIZ5V3pb8oH2+tf97cj7G8x70tuTL3oIXvd3IB+/GjNDekfyKfvhdX8n8n3t+/e+9M7kt++F1/1dyD+IwXwgnW/YkR543R9IPjoIM1N6N/JfdsHr/u7kI3r9HUZ9D/JeeP+7tfckv8Ue+FB6L/LmFs5X35v8eTxhRn0f8h9x/3VrDyL/1b7gj6QHkw9Pxfnq+5KvjwvSqO9HPj0N52vvT36kfUM9lh5CPsTeP9UPIL8OHwhG/UDyCXdxvvZB5OPtB9oT6YPJB2TgfPVDyGfhA9moH0recx/nax9G3tveMJ5KH07eJxPnqw8l3xs3PKN+BPmYhzhf+0jy0faG/Uz6KPKuxzhf/WjyHnzhMOrHEI96gvO1jyV/235hypI+jvyzpzhf/XjyhfGFzqifQH50Fs7XHka+jf1C+lz6RPLJz3G++knkp+ILtVE/mXzgS5yvfQr5zfY/BC+kTyUfm43z1YeTT8Qw6qeRr/sa52ufTv7DT+zXHkF+6xtnjyTv9w37X0qfQd7rnbPPJD/4E/Zrn0XevHf22eRtd2dLn0P+4wdnn0s+yv592ueRD89x9vnkv7/F/lfSo8inf3L2BeR74vHlal9IPuSLs0eT34DH534tfRH5hK/Ovph82mfs176EfMB3Z19KPu/1fyN9GXnPD2dfTn4meq72FeR9fjn7SvJx6O630t3kY347uyHvnC7XKte/frT/AaQ8q4UA&lt;/VERTEX&gt;\n\
    \    &lt;EDGE COMPRESSED=\"B64Z-LittleEndian\" BITSIZE=\"64\"&gt;eJx1j1VXFlEARbG7i1BRQhAFgxBUQpBSVDCwaFAwABWwQezu7u7ujp/mg+c8uNf65mWvWfvsuXeCgv49XYL+f/zeNcB7twDvQXjvDnrfA7Tvid6+F7z3vQP4PgH6vui874fOvj96+wEBvjcQ37MfhN5+MM7xfgjOsR+K3n4Yzvd+OM63H4HefiTu5f0o3Ms+GL19CO7rfSjuax+G3n40/sP7MfgP+7Ho7cPFkdiPE0fBj0dvHyEGYx8phsBHobePFkOxnyCGwcegt48VR2M/URwDH4fefpI4FvvJYjh8PHr7BHEc9lPE8fBT0dtPEyOwny5Gwieit08So7BPFqPhU9DbzxAnYJ8qxsCnobefKcZiP0ucCD8bvX26GId9hjgJPhO9fZY4Gfs5Yjx8Nnr7HDEB+7niFPhc9PZ54lTs88Vp8AXo7QvF6djPExPh56O3LxKTsF8gJsMvRG+/SEzBvlicAV+C3n6xmIr9EjENfil6+2XiTOxLxVnwy9HbrxBnY79STIdfhd5+tZiBfZmYCV+O3r5CzMK+UpwDX4XevlrMxr5GzIGvRW9fJ87Ffo2YC78WvX29mId9g5gPvw69/XqxAPsNYiH8RvT2jeI87JvE+fDN6O03iUXYbxYXwG9Bb98iLsS+VVwE34befqtYjP02sQR+O3r7HeJi7HeKS+B3obffLS7Fvl1cBt+B3n6PWIp9p7gcfi96+33iCuz3iyvhD6C3Pyiuwv6QuBr+MHr7I2IZ9kfFcvhj6O2PixXYnxAr4U+itz8lVmF/WqyGP4Pe/qxYg/05sRb+PHr7C2Id9hfFNfCX0NtfFtdif0Wsh7+K3v6a2ID9dXEd/A309jfF9djfEjfA30Zvf0fciP1dsRH+Hnr7+2IT9g/EZviH6O0fiZuwfyxuhn+C3v6puAX7Z2IL/HP09i/EVuxfim3wr9Dbvxa3Yv9G3Ab/Fr39O3E79u/FHfAf0Nt/FHdi/0ncBf8Zvf0XcTf2X8V2+G/o7b+LHdj/EPfA/0Rv/0vsxP63uBf+D3r7v21uqaIA&lt;/EDGE&gt;\n\
    \    &lt;ELEMENT&gt;\n      &lt;Q COMPRESSED=\"B64Z-LittleEndian\" BITSIZE=\"\
    64\"&gt;eJx1zuc30GEYh3EkZe+99957k5REA1EaGtpZlbIpKqSFtFRaEmkplSR/mjfX74XvOT1vPudc9znPfZuYrH+maIYb/tPNcSNayNzom3AzWsq/RrdCa7SRPUa3RTu0l31Gd0BHdJI7je6MLugqdxvdDd3RQ+43uid6oTdaSvdBX/RDK+n+GICBaC09CIMxBG2kh2IYhqOt9AiMxCi0kx6NMRiL9tLjMB4T0EF6IiZhMjpKT8FUTEMn6emYgZnoLD0LszEHXaTnYh7mo6v0AizELegmvQi3YjG6S9+G27EEPaTvwFLciZ7Sy7Acd6GX9N24B/eit/QKrMQq9JG+D6uxBn2l78cDWIt+0g/iITyM/tKPYB0exQDpx/A4nsBA6fV4Ek9hkPTTeAbPYrD0c3geL2CI9AZsxCYMld6MLXgRw6RfwsvYiuHSr+BVbMMI6e3YgZ0YKb0Lu7EHo6T3Yh9ew2jp17EfBzBG+g28ibcwVvogDuEwxkm/jSN4B+Ol38V7eB8TpD/AURzDROnj+BAnMEn6I3yMTzBZ+lN8hpOYIv05vsCXmCp9Cl/ha0yT/gbf4jtMlz6N73EGM6R/wFmcw0zpH3EeP2GW9M/4Bb9itvRvuIDfMUf6D1zEn5gr/Rf+xiXMk/4Hl/Ev5ktfwX+4imuOL2ei&lt;/Q&gt;\n\
    \    &lt;/ELEMENT&gt;\n    &lt;COMPOSITE&gt;\n      &lt;C ID=\"1\"&gt; Q[0-63]\
    \ &lt;/C&gt;\n      &lt;C ID=\"5\"&gt; E[3,6,9,12,15,18,21,24,27,30,33,36,39,42,45,48,51,54,57,60,63,66,69,72,75,78,81,84,87,90,93,96,99,102,105,108,111,114,117,120,123,126,129,132,135,138,141,144,147,150,153,156,159,162,165,168,171,174,177,180,183,186,189,192]\
    \ &lt;/C&gt;\n      &lt;C ID=\"6\"&gt; E[191] &lt;/C&gt;\n      &lt;C ID=\"7\"\
    &gt; E[190,187,184,181,178,175,172,169,166,163,160,157,154,151,148,145,142,139,136,133,130,127,124,121,118,115,112,109,106,103,100,97,94,91,88,85,82,79,76,73,70,67,64,61,58,55,52,49,46,43,40,37,34,31,28,25,22,19,16,13,10,7,4,1]\
    \ &lt;/C&gt;\n      &lt;C ID=\"8\"&gt; E[0] &lt;/C&gt;\n    &lt;/COMPOSITE&gt;\n\
    \    &lt;DOMAIN&gt;\n&lt;D ID=\"0\"&gt; C[1] &lt;/D&gt;\n    &lt;/DOMAIN&gt;\n\
    \  &lt;/GEOMETRY&gt;\n&lt;Metadata&gt;\n  &lt;Provenance&gt;\n    &lt;GitBranch&gt;refs/heads/master&lt;/GitBranch&gt;\n\
    \    &lt;GitSHA1&gt;X&lt;/GitSHA1&gt;\n    &lt;Hostname&gt;X&lt;/Hostname&gt;\n\
    \    &lt;NektarVersion&gt;5.5.0&lt;/NektarVersion&gt;\n    &lt;Timestamp&gt;T&lt;/Timestamp&gt;\n\
    \  &lt;/Provenance&gt;\n  &lt;NekMeshCommandLine&gt;path/to/src/mesh.msh path/to/dst/mesh.xml\
    \ &lt;/NekMeshCommandLine&gt;\n&lt;/Metadata&gt;\n  &lt;EXPANSIONS&gt;\n    &lt;E\
    \ COMPOSITE=\"C[1]\" NUMMODES=\"4\" TYPE=\"MODIFIED\" FIELDS=\"u\"/&gt;\n  &lt;/EXPANSIONS&gt;\n\
    &lt;/NEKTAR&gt;\n</code></pre>\n</details>\n<p>Note the edge composites run in\
    \ opposite directions.  To align them to the same direction use the NekMesh module\
    \ peralign as follows:</p>\n<pre><code>./NekMesh -m peralign:surf1=5:surf2=7:dir=x\
    \ path/to/src/mesh.xml path/to/dst/mesh_aligned.xml\n</code></pre>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Licence</h2><a id=\"user-content-licence\"\
    \ class=\"anchor\" aria-label=\"Permalink: Licence\" href=\"#licence\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>This is licenced under\
    \ MIT.</p>\n<p>In order to comply with the licences of dependencies, this software\
    \ is not to be released as a binary.</p>\n"
  stargazers_count: 4
  subscribers_count: 8
  topics: []
  updated_at: 1715782886.0
Exawind/exawind-builder:
  data_format: 2
  description: Scripts to help building Exawind codes on various systems
  filenames:
  - etc/spack/nrel-eagle/spack.yaml
  - etc/spack/spack/spack.yaml
  full_name: Exawind/exawind-builder
  latest_release: v0.1.0
  readme: '<div class="markdown-heading"><h1 class="heading-element">ExaWind Code
    Builder</h1><a id="user-content-exawind-code-builder" class="anchor" aria-label="Permalink:
    ExaWind Code Builder" href="#exawind-code-builder"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p><a href="https://exawind.github.io/exawind-builder" rel="nofollow">Documentation</a></p>

    <p>ExaWind Builder is a collection of bash scripts to configure and compile the

    codes used within the <a href="https://github.com/exawind">ExaWind</a> project
    on various

    high-performance computing (HPC) systems. The builder provides the following</p>

    <ul>

    <li>

    <p><strong>Platform configuration</strong>: Provides the minimal set of modules
    that must be

    loaded when compiling with different compilers and MPI libraries on different

    HPC systems.</p>

    </li>

    <li>

    <p><strong>Software configuration</strong>: Provides baseline CMake configuration
    that can be

    used to configure the various options when building a <em>project</em>, e.g.,

    enable/disable optional modules, automate specification of paths to various

    libraries, configure release vs. debug builds.</p>

    </li>

    <li>

    <p><strong>Build script generation</strong>: Generates an executable end-user
    script for a

    combination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>

    </li>

    <li>

    <p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific

    script that allows the user to recreate the exact environment used to build

    the codes during runtime.</p>

    </li>

    </ul>

    <p>The build scripts are intended for developers who might want to compile the

    codes with different configuration options, build different branches during

    their development cycle, or link to a different development version of a library

    that is currently not available in the standard installation on the system. Please
    see the

    <a href="https://exawind.github.io/exawind-builder" rel="nofollow">documentation</a>
    for

    details on how to use this to build ExaWind software.</p>

    <div class="markdown-heading"><h2 class="heading-element">Installation and usage</h2><a
    id="user-content-installation-and-usage" class="anchor" aria-label="Permalink:
    Installation and usage" href="#installation-and-usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h3 class="heading-element">Using exawind-builder
    with pre-installed ExaWind environment</h3><a id="user-content-using-exawind-builder-with-pre-installed-exawind-environment"
    class="anchor" aria-label="Permalink: Using exawind-builder with pre-installed
    ExaWind environment" href="#using-exawind-builder-with-pre-installed-exawind-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>ExaWind Builder is already installed and setup on OLCF Summit, NREL

    Eagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly

    to using build scripts from the central installation. Please consult <a href="https://exawind.github.io/exawind-builder/basic.html#basic-usage"
    rel="nofollow">user

    manual</a> to

    learn how to use the scripts.</p>

    <div class="markdown-heading"><h3 class="heading-element">Bootstrapping exawind-builder
    with pre-configured system definitions</h3><a id="user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions"
    class="anchor" aria-label="Permalink: Bootstrapping exawind-builder with pre-configured
    system definitions" href="#bootstrapping-exawind-builder-with-pre-configured-system-definitions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>ExaWind builder has <a href="https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems"
    rel="nofollow">pre-built

    configurations</a>

    for several systems. On these systems you can use the <code>bootstrap</code> script
    to

    quickly get up and running. Please consult <a href="https://exawind.github.io/exawind-builder/installation.html"
    rel="nofollow">installation

    manual</a>. The

    relevant steps are shown below.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Download bootstrap script</span>

    curl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Make it executable</span>

    chmod a+x bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Execute bootstrap and provide system/compiler
    combination</span>

    ./bootstrap.sh -s [SYSTEM] -c [COMPILER]


    <span class="pl-c"><span class="pl-c">#</span> Examples</span>

    ./bootstrap.sh -s spack -c clang       <span class="pl-c"><span class="pl-c">#</span>
    On MacOS with homebrew</span>

    ./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system

    ./bootstrap.sh -s eagle -c gcc         <span class="pl-c"><span class="pl-c">#</span>
    NREL Eagle</span>

    ./bootstrap.sh -s cori -c intel        <span class="pl-c"><span class="pl-c">#</span>
    NERSC Cori</span>

    ./bootstrap.sh -s snl-ascicgpu -c gcc  <span class="pl-c"><span class="pl-c">#</span>
    SNL GPU development machine</span></pre></div>

    <div class="markdown-heading"><h3 class="heading-element">Creating new system
    configuration</h3><a id="user-content-creating-new-system-configuration" class="anchor"
    aria-label="Permalink: Creating new system configuration" href="#creating-new-system-configuration"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>You can add new system definitions to exawind-builder for use on new systems

    that are not used by ExaWind team. Please see <a href="https://exawind.github.io/exawind-builder/advanced.html"
    rel="nofollow">manual

    installation</a> and

    <a href="https://exawind.github.io/exawind-builder/newsys.html" rel="nofollow">adding
    a new system</a>

    sections in the user manual.</p>

    <div class="markdown-heading"><h2 class="heading-element">Links</h2><a id="user-content-links"
    class="anchor" aria-label="Permalink: Links" href="#links"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li><a href="https://www.exawind.org" rel="nofollow">ExaWind</a></li>

    <li><a href="https://github.com/exawind">ExaWind GitHub Organization</a></li>

    <li><a href="https://a2e.energy.gov/about/hfm" rel="nofollow">A2e HFM</a></li>

    </ul>

    '
  stargazers_count: 3
  subscribers_count: 5
  topics:
  - cmake
  - build
  - exawind
  - hpc
  - exawind-builder
  updated_at: 1643028069.0
FairRootGroup/FairMQ:
  data_format: 2
  description: C++ Message Queuing Library and Framework
  filenames:
  - spack.yaml
  full_name: FairRootGroup/FairMQ
  latest_release: v1.8.4
  readme: '

    <div class="markdown-heading"><h1 class="heading-element">FairMQ</h1><a id="user-content-fairmq"
    class="anchor" aria-label="Permalink: FairMQ" href="#fairmq"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p><a href="COPYRIGHT"><img src="https://camo.githubusercontent.com/f1b04dc9744be18d2e4a57e93eb675e9d34c7fd88dd2af920a23cbf2b6126c9b/68747470733a2f2f616c66612d63692e6773692e64652f736869656c64732f62616467652f6c6963656e73652d4c47504c2d2d332e302d6f72616e67652e737667"
    alt="license" data-canonical-src="https://alfa-ci.gsi.de/shields/badge/license-LGPL--3.0-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.1689985" rel="nofollow"><img src="https://camo.githubusercontent.com/61eb705b099605db7fd32ca363bc81333685424ab3d43368fb9eb92d2d20fcf8/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e313638393938352e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.1689985.svg"
    style="max-width: 100%;"></a>

    <a href="https://bestpractices.coreinfrastructure.org/projects/6915" rel="nofollow"><img
    src="https://camo.githubusercontent.com/1f8dec075c5bd5f9939e67adf475385a6ef6f10683061f1192c191ea31d3ffc3/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f363931352f6261646765"
    alt="OpenSSF Best Practices" data-canonical-src="https://bestpractices.coreinfrastructure.org/projects/6915/badge"
    style="max-width: 100%;"></a>

    <a href="https://github.com/FairRootGroup/FairMQ/actions/workflows/fair-software.yml"><img
    src="https://camo.githubusercontent.com/cf9de53206b2701f8f690c12ded388c94ec29b8b4366cc55a64f1442b196ae01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666169722d2d736f6674776172652e65752d2545322539372538462532302532302545322539372538462532302532302545322539372538422532302532302545322539372538462532302532302545322539372538462d79656c6c6f77"
    alt="fair-software.eu" data-canonical-src="https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B%20%20%E2%97%8F%20%20%E2%97%8F-yellow"
    style="max-width: 100%;"></a>

    <a href="https://repology.org/project/fairmq/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/a986833bc26fb382ffb3173c4f42c00cc0953f0b09ee7fc10e5c97df7f86c5a2/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f76657273696f6e2d666f722d7265706f2f737061636b2f666169726d712e737667"
    alt="Spack package" data-canonical-src="https://repology.org/badge/version-for-repo/spack/fairmq.svg"
    style="max-width: 100%;"></a></p>

    <p>C++ Message Queuing Library and Framework</p>

    <p>Docs: <a href="https://github.com/FairRootGroup/FairMQ/blob/dev/README.md#documentation">Book</a></p>

    <p>Find all FairMQ releases <a href="https://github.com/FairRootGroup/FairMQ/releases">here</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Introduction</h2><a
    id="user-content-introduction" class="anchor" aria-label="Permalink: Introduction"
    href="#introduction"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>FairMQ is designed to help implementing large-scale data processing workflows
    needed in next-generation Particle Physics experiments. FairMQ is written in C++
    and aims to</p>

    <ul>

    <li>provide <strong>an asynchronous message passing abstraction</strong> of different
    data transport technologies,</li>

    <li>provide a reasonably <strong>efficient data transport</strong> service (zero-copy,
    high throughput),</li>

    <li>be <strong>data format agnostic</strong>, and</li>

    <li>provide <strong>basic building blocks</strong> that can be used to implement
    higher level data processing workflows.</li>

    </ul>

    <p>The core of FairMQ provides an abstract asynchronous message passing API with
    scalability protocols

    inspired by <a href="https://github.com/zeromq/libzmq">ZeroMQ</a> (e.g. PUSH/PULL,
    PUB/SUB).

    FairMQ provides multiple implementations for its API (so-called "transports",

    e.g. <code>zeromq</code> and <code>shmem</code> (latest release of the <code>ofi</code>
    transport in v1.4.56, removed since v1.5+)) to cover

    a variety of use cases

    (e.g. inter-thread, inter-process, inter-node communication) and machines (e.g.
    Ethernet, Infiniband).

    In addition to this core functionality FairMQ provides a framework for creating
    "devices" - actors which

    are communicating through message passing. FairMQ does not only allow the user
    to use different transport

    but also to mix them; i.e: A Device can communicate using different transport
    on different channels at the

    same time. Device execution is modelled as a simple state machine that shapes
    the integration points for

    the user task. Devices also incorporate a plugin system for runtime configuration
    and control.

    Next to the provided <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/devices">devices</a>
    and

    <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/plugins">plugins</a>
    the user can extend FairMQ

    by developing his own plugins to integrate his devices with external configuration
    and control services.</p>

    <p>FairMQ has been developed in the context of its mother project <a href="https://github.com/FairRootGroup/FairRoot">FairRoot</a>
    -

    a simulation, reconstruction and analysis framework.</p>

    <div class="markdown-heading"><h2 class="heading-element">Installation from Source</h2><a
    id="user-content-installation-from-source" class="anchor" aria-label="Permalink:
    Installation from Source" href="#installation-from-source"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Recommended:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/FairRootGroup/FairMQ
    fairmq_source

    cmake -S fairmq_source -B fairmq_build -GNinja -DCMAKE_BUILD_TYPE=Release

    cmake --build fairmq_build

    ctest --test-dir fairmq_build --output-on-failure --schedule-random -j<span class="pl-k">&lt;</span>ncpus<span
    class="pl-k">&gt;</span>

    cmake --install fairmq_build --prefix <span class="pl-s"><span class="pl-pds">$(</span>pwd<span
    class="pl-pds">)</span></span>/fairmq_install</pre></div>

    <p>Please consult the <a href="https://cmake.org/cmake/help/latest/manual/cmake.1.html"
    rel="nofollow">manpages of your CMake version</a> for more options.</p>

    <p>If dependencies are not installed in standard system directories, you can hint
    the installation location via

    <code>-DCMAKE_PREFIX_PATH=...</code> or per dependency via <code>-D{DEPENDENCY}_ROOT=...</code>
    (<code>*_ROOT</code> variables can also be environment variables).</p>

    <div class="markdown-heading"><h2 class="heading-element">Usage</h2><a id="user-content-usage"
    class="anchor" aria-label="Permalink: Usage" href="#usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>FairMQ ships as a CMake package, so in your <code>CMakeLists.txt</code> you
    can discover it like this:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">find_package</span>(FairCMakeModules
    1.0 <span class="pl-k">REQUIRED</span>)

    <span class="pl-c1">include</span>(FairFindPackage2)

    find_package2(FairMQ)

    find_package2_implicit_dependencies()</pre></div>

    <p>The <a href="https://fairrootgroup.github.io/FairCMakeModules/latest/module/FairFindPackage2.html"
    rel="nofollow"><code>FairFindPackage2</code> module</a> is part of the <a href="https://fairrootgroup.github.io/FairCMakeModules"
    rel="nofollow"><code>FairCMakeModules</code> package</a>.</p>

    <p>If FairMQ is not installed in system directories, you can hint the installation:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">list</span>(PREPEND
    CMAKE_PREFIX_PATH /path/to/fairmq_install)</pre></div>

    <div class="markdown-heading"><h2 class="heading-element">Dependencies</h2><a
    id="user-content-dependencies" class="anchor" aria-label="Permalink: Dependencies"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li><a href="https://www.boost.org/" rel="nofollow">Boost</a></li>

    <li><a href="https://cmake.org/" rel="nofollow">CMake</a></li>

    <li><a href="http://www.doxygen.org/" rel="nofollow">Doxygen</a></li>

    <li>

    <a href="https://github.com/FairRootGroup/FairCMakeModules">FairCMakeModules</a>
    (optionally bundled)</li>

    <li><a href="https://github.com/FairRootGroup/FairLogger">FairLogger</a></li>

    <li>

    <a href="https://github.com/google/googletest">GTest</a> (optionally bundled)</li>

    <li><a href="http://zeromq.org/" rel="nofollow">ZeroMQ</a></li>

    </ul>

    <p>Which dependencies are required depends on which components are built.</p>

    <p>Supported platform is Linux. macOS is supported on a best-effort basis.</p>

    <div class="markdown-heading"><h2 class="heading-element">CMake options</h2><a
    id="user-content-cmake-options" class="anchor" aria-label="Permalink: CMake options"
    href="#cmake-options"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>On command line:</p>

    <ul>

    <li>

    <code>-DDISABLE_COLOR=ON</code> disables coloured console output.</li>

    <li>

    <code>-DBUILD_TESTING=OFF</code> disables building of tests.</li>

    <li>

    <code>-DBUILD_EXAMPLES=OFF</code> disables building of examples.</li>

    <li>

    <code>-DBUILD_DOCS=ON</code> enables building of API docs.</li>

    <li>

    <code>-DFAIRMQ_CHANNEL_DEFAULT_AUTOBIND=OFF</code> disable channel <code>autoBind</code>
    by default</li>

    <li>You can hint non-system installations for dependent packages, see the #installation-from-source
    section above</li>

    </ul>

    <p>After the <code>find_package(FairMQ)</code> call the following CMake variables
    are defined:</p>

    <table>

    <thead>

    <tr>

    <th>Variable</th>

    <th>Info</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>${FairMQ_PACKAGE_DEPENDENCIES}</code></td>

    <td>the list of public package dependencies</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_VERSION}</code></td>

    <td>the minimum <code>&lt;dep&gt;</code> version FairMQ requires</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_COMPONENTS}</code></td>

    <td>the list of <code>&lt;dep&gt;</code> components FairMQ depends on</td>

    </tr>

    <tr>

    <td><code>${FairMQ_PACKAGE_COMPONENTS}</code></td>

    <td>the list of components FairMQ consists of</td>

    </tr>

    <tr>

    <td><code>${FairMQ_#COMPONENT#_FOUND}</code></td>

    <td>

    <code>TRUE</code> if this component was built</td>

    </tr>

    <tr>

    <td><code>${FairMQ_VERSION}</code></td>

    <td>the version in format <code>MAJOR.MINOR.PATCH</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_GIT_VERSION}</code></td>

    <td>the version in the format returned by <code>git describe --tags --dirty --match
    "v*"</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_PREFIX}</code></td>

    <td>the actual installation prefix</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BINDIR}</code></td>

    <td>the installation bin directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_INCDIR}</code></td>

    <td>the installation include directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_LIBDIR}</code></td>

    <td>the installation lib directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_DATADIR}</code></td>

    <td>the installation data directory (<code>../share/fairmq</code>)</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CMAKEMODDIR}</code></td>

    <td>the installation directory of shipped CMake find modules</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BUILD_TYPE}</code></td>

    <td>the value of <code>CMAKE_BUILD_TYPE</code> at build-time</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CXX_FLAGS}</code></td>

    <td>the values of <code>CMAKE_CXX_FLAGS</code> and <code>CMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE}</code>
    at build-time</td>

    </tr>

    </tbody>

    </table>

    <div class="markdown-heading"><h2 class="heading-element">Documentation</h2><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ol>

    <li>

    <a href="docs/Device.md#1-device">Device</a>

    <ol>

    <li><a href="docs/Device.md#11-topology">Topology</a></li>

    <li><a href="docs/Device.md#12-communication-patterns">Communication Patterns</a></li>

    <li><a href="docs/Device.md#13-state-machine">State Machine</a></li>

    <li><a href="docs/Device.md#15-multiple-devices-in-the-same-process">Multiple
    devices in the same process</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Transport.md#2-transport-interface">Transport Interface</a>

    <ol>

    <li>

    <a href="docs/Transport.md#21-message">Message</a>

    <ol>

    <li><a href="docs/Transport.md#211-ownership">Ownership</a></li>

    </ol>

    </li>

    <li><a href="docs/Transport.md#22-channel">Channel</a></li>

    <li><a href="docs/Transport.md#23-poller">Poller</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Configuration.md#3-configuration">Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#31-device-configuration">Device Configuration</a></li>

    <li>

    <a href="docs/Configuration.md#32-communication-channels-configuration">Communication
    Channels Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#321-json-parser">JSON Parser</a></li>

    <li><a href="docs/Configuration.md#322-suboptparser">SuboptParser</a></li>

    </ol>

    </li>

    <li><a href="docs/Configuration.md#33-introspection">Introspection</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Development.md#4-development">Development</a>

    <ol>

    <li><a href="docs/Development.md#41-testing">Testing</a></li>

    <li>

    <a href="docs/Development.md#42-static-analysis">Static Analysis</a>

    <ol>

    <li><a href="docs/Development.md#421-cmake-integration">CMake Integration</a></li>

    <li><a href="docs/Development.md#422-extra-compiler-arguments">Extra Compiler
    Arguments</a></li>

    </ol>

    </li>

    </ol>

    </li>

    <li>

    <a href="docs/Logging.md#5-logging">Logging</a>

    <ol>

    <li><a href="docs/Logging.md#51-log-severity">Log severity</a></li>

    <li><a href="docs/Logging.md#52-log-verbosity">Log verbosity</a></li>

    <li><a href="docs/Logging.md#53-color">Color for console output</a></li>

    <li><a href="docs/Logging.md#54-file-output">File output</a></li>

    <li><a href="docs/Logging.md#55-custom-sinks">Custom sinks</a></li>

    </ol>

    </li>

    <li><a href="docs/Examples.md#6-examples">Examples</a></li>

    <li>

    <a href="docs/Plugins.md#7-plugins">Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#71-usage">Usage</a></li>

    <li><a href="docs/Plugins.md#72-development">Development</a></li>

    <li>

    <a href="docs/Plugins.md#73-provided-plugins">Provided Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#731-pmix">PMIx</a></li>

    </ol>

    </li>

    </ol>

    </li>

    </ol>

    '
  stargazers_count: 82
  subscribers_count: 12
  topics:
  - fairroot
  - fairmq
  - zeromq
  - shmem
  - c-plus-plus
  updated_at: 1715254520.0
FairRootGroup/FairSoft:
  data_format: 2
  description: Repository for installation routines of the external software required
    by FairRoot
  filenames:
  - env/jun19/sim/spack.yaml
  - env/dev/sim_mt_headless/spack.yaml
  - test/env/fairlogger/spack.yaml
  - env/apr21/sim_mt/spack.yaml
  full_name: FairRootGroup/FairSoft
  latest_release: jan24
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">FairSoft</h1><a\
    \ id=\"user-content-fairsoft\" class=\"anchor\" aria-label=\"Permalink: FairSoft\"\
    \ href=\"#fairsoft\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The FairSoft distribution provides the software packages\
    \ needed to compile and run the <a href=\"https://github.com/FairRootGroup/FairRoot\"\
    >FairRoot framework</a> and experiment packages based on FairRoot. FairSoft is\
    \ a source distribution with recurring releases for macOS and Linux.</p>\n<div\
    \ class=\"markdown-heading\"><h2 class=\"heading-element\">Installation from Source</h2><a\
    \ id=\"user-content-installation-from-source\" class=\"anchor\" aria-label=\"\
    Permalink: Installation from Source\" href=\"#installation-from-source\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Choose\
    \ between the classic (called \"Legacy\") installation method or the new Spack-based\
    \ one:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Legacy (Recommended)</strong></th>\n\
    <th><strong>Spack (EXPERIMENTAL)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>This is the classic bash/cmake based setup system.</td>\n<td>This is an ongoing\
    \ standardization and modernization effort based on Spack (which itself is still\
    \ under heavy development). Most things are already working. For early adopters.</td>\n\
    </tr>\n<tr>\n<td>Releases are reflected in the git history via tags and branches,\
    \ e.g.: <code>jan24</code>, <code>nov22</code>, <code>apr21p2</code>, <code>apr21_patches</code>\n\
    </td>\n<td>Always use the latest <code>dev</code> branch. Multiple releases are\
    \ described within the metadata contained in the repo (read on in the Installation\
    \ instructions on how to select a release).</td>\n</tr>\n<tr>\n<td>\u25BA <a href=\"\
    legacy/README.md\">continue</a>\n</td>\n<td>\u25BA <a href=\"docs/README.md\"\
    >continue</a>\n</td>\n</tr>\n</tbody>\n</table>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Installation of pre-compiled Binaries</h2><a id=\"\
    user-content-installation-of-pre-compiled-binaries\" class=\"anchor\" aria-label=\"\
    Permalink: Installation of pre-compiled Binaries\" href=\"#installation-of-pre-compiled-binaries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><em>Note</em>: FairSoft is primarily a source distribution. Availability of\
    \ latest releases as pre-compiled binaries may be delayed.</p>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">GSI Virgo Cluster</h3><a id=\"\
    user-content-gsi-virgo-cluster\" class=\"anchor\" aria-label=\"Permalink: GSI\
    \ Virgo Cluster\" href=\"#gsi-virgo-cluster\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>For all <a href=\"https://hpc.gsi.de/virgo/platform/software.html#application-environment\"\
    \ rel=\"nofollow\">VAEs</a> at <code>/cvmfs/fairsoft.gsi.de/&lt;vae-os&gt;/fairsoft/&lt;release&gt;</code>.\
    \ Use by exporting the <code>SIMPATH</code> environment variable pointing to one\
    \ of the directories.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >macOS (beta)</h3><a id=\"user-content-macos-beta\" class=\"anchor\" aria-label=\"\
    Permalink: macOS (beta)\" href=\"#macos-beta\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>FairSoft config: <a href=\"FairSoftConfig.cmake\"\
    >default</a>, no other configs planned</p>\n<ol>\n<li>Install <em>Command Line\
    \ Tools for Xcode</em> from <a href=\"https://developer.apple.com/downloads\"\
    \ rel=\"nofollow\">https://developer.apple.com/downloads</a> (requires Apple account)</li>\n\
    <li>Install <a href=\"https://brew.sh/\" rel=\"nofollow\">Homebrew</a>\n</li>\n\
    <li>Run <code>brew update &amp;&amp; brew doctor</code> and fix potential issues\
    \ reported by these commands until <code>Your system is ready to brew.</code>\n\
    </li>\n<li>Run</li>\n</ol>\n<pre><code>brew tap fairrootgroup/fairsoft\nbrew install\
    \ fairsoft\n</code></pre>\n<ol start=\"5\">\n<li>Use via <code>export SIMPATH=$(brew\
    \ --prefix fairsoft)</code>\n</li>\n</ol>\n<p><em>Note</em>: macOS is a fast moving\
    \ target and it is possible the packages will stop working from one day to another\
    \ after some system component was updated. We try our best to keep up, one great\
    \ way to help is to provide detailed problem reports <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\
    >here on github</a>.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Other platforms</h3><a id=\"user-content-other-platforms\" class=\"anchor\" aria-label=\"\
    Permalink: Other platforms\" href=\"#other-platforms\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Binary packages for non-GSI\
    \ Linux as well as Spack binary caches and/or pre-populated install trees are\
    \ planned for the future.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Contributing</h2><a id=\"user-content-contributing\" class=\"anchor\" aria-label=\"\
    Permalink: Contributing\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Please ask your questions, request\
    \ features, and report issues by <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\
    >creating a github issue</a>.</p>\n"
  stargazers_count: 13
  subscribers_count: 14
  topics: []
  updated_at: 1705588914.0
GEOS-DEV/GEOS:
  data_format: 2
  description: GEOS Simulation Framework
  filenames:
  - scripts/pygeosx_configs/toss_4_x86_64_ib/spack.yaml
  full_name: GEOS-DEV/GEOS
  latest_release: v1.0.1
  readme: '<p><a href="https://zenodo.org/badge/latestdoi/131810578" rel="nofollow"><img
    src="https://camo.githubusercontent.com/9c0760932d168b68bde7fb1623f1727acad25f306fc5609a1b38d392888ae7dd/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3133313831303537382e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/131810578.svg" style="max-width:
    100%;"></a>

    <a href="https://codecov.io/github/GEOS-DEV/GEOS" rel="nofollow"><img src="https://camo.githubusercontent.com/1c8900c4ee778b688be56b9a8e1618325ce04dbe7f3db14f033e4af735640493/68747470733a2f2f636f6465636f762e696f2f6769746875622f47454f532d4445562f47454f532f67726170682f62616467652e7376673f746f6b656e3d30565445485051473538"
    alt="codecov" data-canonical-src="https://codecov.io/github/GEOS-DEV/GEOS/graph/badge.svg?token=0VTEHPQG58"
    style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/GEOS-DEV/GEOS/actions/workflows/ci_tests.yml/badge.svg"><img
    src="https://github.com/GEOS-DEV/GEOS/actions/workflows/ci_tests.yml/badge.svg"
    alt="CI" style="max-width: 100%;"></a>

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2b6c2fc0d68b06cb042bb53ee5bcc4f8d55169fc19297eeff32d0cf3ca8b9b91/68747470733a2f2f72656164746865646f63732e636f6d2f70726f6a656374732f67656f73782d67656f73782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="docs" data-canonical-src="https://readthedocs.com/projects/geosx-geosx/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <div class="markdown-heading"><h2 class="heading-element">Welcome to the GEOS
    project!</h2><a id="user-content-welcome-to-the-geos-project" class="anchor" aria-label="Permalink:
    Welcome to the GEOS project!" href="#welcome-to-the-geos-project"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>GEOS is a simulation framework for modeling coupled flow, transport, and geomechanics

    in the subsurface.  The code provides advanced solvers for a number of target
    applications,

    including</p>

    <ul>

    <li>carbon sequestration,</li>

    <li>geothermal energy,</li>

    <li>and similar systems.</li>

    </ul>

    <p>A key focus of the project is achieving scalable performance on current and
    next-generation

    high performance computing systems.  We do this through a portable programming
    model and research into scalable algorithms.</p>

    <p>You may want to browse our

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Publications.html"
    rel="nofollow">publications</a>

    page for more details on the HPC, numerics,

    and applied engineering components of this effort.</p>

    <div class="markdown-heading"><h2 class="heading-element">Documentation</h2><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Our documentation is hosted <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/?"
    rel="nofollow">here</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Who develops GEOS?</h2><a
    id="user-content-who-develops-geos" class="anchor" aria-label="Permalink: Who
    develops GEOS?" href="#who-develops-geos"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>GEOS is an open source project and is developed by a community of researchers
    at

    several institutions.  The bulk of the code has been written by contributors from

    four main organizations:</p>

    <ul>

    <li>Lawrence Livermore National Laboratory,</li>

    <li>Stanford University,</li>

    <li>TotalEnergies,</li>

    <li>Chevron</li>

    </ul>

    <p>See our

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Contributors.html"
    rel="nofollow">authors</a>

    and

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Acknowledgements.html"
    rel="nofollow">acknowledgements</a>

    page for more details.</p>

    <div class="markdown-heading"><h2 class="heading-element">How does GEOS relate
    to the earlier GEOS code?</h2><a id="user-content-how-does-geos-relate-to-the-earlier-geos-code"
    class="anchor" aria-label="Permalink: How does GEOS relate to the earlier GEOS
    code?" href="#how-does-geos-relate-to-the-earlier-geos-code"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>GEOS is the offshoot of an earlier code developed at LLNL also called GEOS.  The
    new

    code differs from our previous efforts in two important ways:</p>

    <ul>

    <li>This new code GEOS uses a fundamentally different programming model to achieve

    high performance on the complicated chip architectures common on today''s

    HPC systems.  This code is ready for exascale-class systems as they are delivered.</li>

    <li>The new code has been released as an open-source effort to encourage collaboration

    within the research and industrial community.  See the release notes below

    for details of the <a href="./LICENSE">LGPL 2.1 License</a> that has been adopted.</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Release</h2><a id="user-content-release"
    class="anchor" aria-label="Permalink: Release" href="#release"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>For release details and restrictions, please read the <a href="./LICENSE">LICENSE</a>
    file.</p>

    <p>For copyrights, please read the <a href="./COPYRIGHT">COPYRIGHT</a> file.</p>

    <p>For contributors, please read the <a href="./CONTRIBUTORS">CONTRIBUTORS</a>
    file.</p>

    <p>For acknowledgements, please read the <a href="./ACKNOWLEDGEMENTS">ACKNOWLEDGEMENTS</a>
    file.</p>

    <p>For notice, please read the <a href="./NOTICE">NOTICE</a> file.</p>

    <p><code>LLNL-CODE-812638</code>  <code>OCEC-18-021</code></p>

    '
  stargazers_count: 200
  subscribers_count: 30
  topics:
  - hpc
  - reservoir-simulation
  - geomechanics
  - gpu
  - carbon-storage
  - llnl
  updated_at: 1717186619.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1658856345.0
JCSDA/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/gfs-v16.2/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/jedi-mpas-nvidia-dev/spack.yaml
  - configs/templates/skylab-dev/spack.yaml
  - configs/templates/gsi-addon-dev/spack.yaml
  - configs/templates/ufs-weather-model-static/spack.yaml
  - configs/templates/unified-dev/spack.yaml
  full_name: JCSDA/spack-stack
  latest_release: 1.7.0
  readme: '<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"><img
    src="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"
    width="425" style="max-width: 100%;"></a></p>

    <p>Spack-stack is a framework for installing software libraries to support

    NOAA''s Unified Forecast System (UFS) applications and the

    Joint Effort for Data assimilation Integration (JEDI) coupled to

    several Earth system prediction models (MPAS, NEPTUNE, UM, FV3, GEOS, UFS).</p>

    <p>Spack-stack supports installations on a range of R&amp;D and operational platforms.

    It provides a set of installation templates (package lists), default package settings,

    system configurations for a range of <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">macOS and Linux workstation, HPC, and cloud

    platforms</a>, and Spack extensions, and uses a fork of the

    <a href="https://github.com/spack/spack">Spack repository</a>. <a href="https://spack.io/"
    rel="nofollow">Spack</a> is a

    community-supported, multi-platform package manager

    developed by Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about Spack, see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for Spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">Spack
    documentation</a>.</p>

    <p><strong>To get started with spack-stack</strong>, either by using an existing

    installation on a <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">supported platform</a>

    or by <a href="https://spack-stack.readthedocs.io/en/latest/CreatingEnvironments.html"
    rel="nofollow">creating a new installation</a>, see the

    <a href="https://spack-stack.readthedocs.io/en/latest/Overview.html#getting-started"
    rel="nofollow">Getting Started</a> documentation page.

    Full documentation with table of contents can be found at <a href="https://spack-stack.readthedocs.io/en/latest/"
    rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a>.</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li><a href="https://epic.noaa.gov" rel="nofollow">Earth Prediction Innovation
    Center (EPIC)</a></li>

    <li><a href="https://https://www.nrl.navy.mil" rel="nofollow">U.S. Naval Research
    Laboratory (NRL)</a></li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    '
  stargazers_count: 21
  subscribers_count: 10
  topics: []
  updated_at: 1716514406.0
JiakunYan/hpx-lci_scripts:
  data_format: 2
  description: New sets of scripts for HPX+LCI experiments based on spack and python
  filenames:
  - spack_env/rostam/hpx-lcw-openmpi-griddim2/spack.yaml
  - spack_env/expanse/hpx-lcw-relDeb/spack.yaml
  - spack_env/delta/hpx-lcw-sc24-cray/spack.yaml
  - spack_env/polaris/mpich-test/spack.yaml
  - spack_env/perlmutter/hpx-lci-bell24-master/spack.yaml
  - spack_env/delta/hpx-lci-cpu-debug/spack.yaml
  - spack_env/expanse/hpx-lcw-debug/spack.yaml
  - spack_env/rostam/hpx-lcw-pcounter/spack.yaml
  - spack_env/delta/hpx-lcw/spack.yaml
  - spack_env/rostam/hpx-lcw-analyze/spack.yaml
  full_name: JiakunYan/hpx-lci_scripts
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">HPX/LCI Scripts</h1><a
    id="user-content-hpxlci-scripts" class="anchor" aria-label="Permalink: HPX/LCI
    Scripts" href="#hpxlci-scripts"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h3 class="heading-element">Overview</h3><a id="user-content-overview"
    class="anchor" aria-label="Permalink: Overview" href="#overview"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This is a scripts collection for running HPX/LCI related software on clusters.

    All scripts are written in Python (including those that will be submitted to

    SLURM). The execution environment are managed by Spack environment.</p>

    <div class="markdown-heading"><h3 class="heading-element">File Structure</h3><a
    id="user-content-file-structure" class="anchor" aria-label="Permalink: File Structure"
    href="#file-structure"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>include: common python scripts imported by others

    <ul>

    <li>platforms: platform-specific configurations.</li>

    </ul>

    </li>

    <li>spack_env/&lt;platform_name&gt;/&lt;env_name&gt;: spack environment yaml file</li>

    <li>lci: Scripts to run LCI software.</li>

    <li>hpx: Scripts to run HPX software.</li>

    <li>hpx_pingpong: Scripts to run the HPX Ping-pong benchmark.</li>

    <li>octotiger: Scripts to run Octo-Tiger.</li>

    </ul>

    <p>Within the lci/hpx/hpx_pingpong_octotiger directory, there are a number of

    subdirectories, such as "benchmark", "debug", "perf", serving different

    purposes. Within each subdirectory, you may find the following scripts:</p>

    <ul>

    <li>run.py: the script that submit one or more jobs to platforms (typically

    through SLRUM <code>sbatch</code>).</li>

    <li>slurm.py: the script that <code>run.py</code> submit to the platforms. Users
    generally

    should not run this script directly.</li>

    <li>parse.py: the script that parse the experiment results from log file

    into <code>csv</code> file.</li>

    <li>draw.py: the script that plot the experiment results from the <code>csv</code>
    file.</li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">A typical workflow</h3><a
    id="user-content-a-typical-workflow" class="anchor" aria-label="Permalink: A typical
    workflow" href="#a-typical-workflow"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Suppose we are on Perlmutter and want to run Octo-Tiger benchmarks.</p>

    <p>Setup phase:</p>

    <ol>

    <li>

    <code>spack environment activate path/to/hpx-lci_scripts/spack_env/perlmutter/hpx-lcw</code>:

    activate the spack environment we want to use.</li>

    <li>

    <code>spack concretize ; spack install</code>: install the environment.</li>

    </ol>

    <p>Experiment phase:</p>

    <ol>

    <li><code>cd path/to/hpx-lci_scripts/octotiger/benchmark</code></li>

    <li>

    <code>vim run.py</code>: decide which configurations I want to run</li>

    <li>

    <code>run.py 5</code>: run all configurations 5 times.</li>

    <li>

    <code>parse.py</code>: (After all jobs complete) parse all SLURM output files.</li>

    <li>

    <code>draw.py</code>: plot the results.</li>

    </ol>

    <div class="markdown-heading"><h3 class="heading-element">Important notes on how
    the scripts work</h3><a id="user-content-important-notes-on-how-the-scripts-work"
    class="anchor" aria-label="Permalink: Important notes on how the scripts work"
    href="#important-notes-on-how-the-scripts-work"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <div class="markdown-heading"><h4 class="heading-element">Persistent shell</h4><a
    id="user-content-persistent-shell" class="anchor" aria-label="Permalink: Persistent
    shell" href="#persistent-shell"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Using python to run shell command can be difficult, because the environment

    or current path does not persist through multiple <code>subprocess</code> or <code>os.system</code>

    calls. For example, the following python code will not work</p>

    <pre><code>os.system("module load openmpi")

    os.system("export DEBUG_MODE=1")

    os.system("cd workspace/hello_world")

    os.system("mpirun -n 2 hello_world")

    </code></pre>

    <p>As a result, all shell commands invoked by the python scripts in this project

    are all through the special <a href="include/pshell.py">pshell</a> (persistent
    shell) module.

    The following python code will work</p>

    <pre><code>pshell.run("module load openmpi")

    pshell.run("export DEBUG_MODE=1")

    pshell.run("cd workspace/hello_world")

    pshell.run("mpirun -n 2 hello_world")

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1709678887.0
JuliaParallel/github-actions-buildcache:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: JuliaParallel/github-actions-buildcache
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Spack buildcache
    for MPI.jl CI</h1><a id="user-content-spack-buildcache-for-mpijl-ci" class="anchor"
    aria-label="Permalink: Spack buildcache for MPI.jl CI" href="#spack-buildcache-for-mpijl-ci"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This repository provides a <a href="https://spack.readthedocs.io/en/latest/binary_caches.html#oci-docker-v2-registries-as-build-cache"
    rel="nofollow">Spack OCI buildcache</a> to be used in CI of <a href="https://github.com/JuliaParallel/MPI.jl"><code>MPI.jl</code></a>
    and other JuliaParallel projects.

    This is based on <a href="https://github.com/spack/github-actions-buildcache">spack/github-actions-buildcache</a>.</p>

    <p>You can see the <a href="https://github.com/JuliaParallel/github-actions-buildcache/pkgs/container/github-actions-buildcache">list
    of packages</a> produced by this buildcache.</p>

    <p>If you want to have more packages in this buildcache, add them to the <a href="./spack.yaml"><code>spack.yaml</code></a>
    file.</p>

    '
  stargazers_count: 0
  subscribers_count: 14
  topics: []
  updated_at: 1698970197.0
LLNL/AMS:
  data_format: 2
  description: null
  filenames:
  - .github/containers/x86_64-broadwell-gcc11.2.1/spack.yaml
  - .github/containers/x86_64-broadwell-cuda11.6.1/spack.yaml
  full_name: LLNL/AMS
  latest_release: 07.25.23-alpha
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Autonomous\
    \ MultiScale Library (AMS)</h1><a id=\"user-content-autonomous-multiscale-library-ams\"\
    \ class=\"anchor\" aria-label=\"Permalink: Autonomous MultiScale Library (AMS)\"\
    \ href=\"#autonomous-multiscale-library-ams\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>A library (under construction) to\
    \ simplify machine learning surrogate model integration in HPC codes.</p>\n<div\
    \ class=\"markdown-heading\"><h2 class=\"heading-element\">Getting Involved</h2><a\
    \ id=\"user-content-getting-involved\" class=\"anchor\" aria-label=\"Permalink:\
    \ Getting Involved\" href=\"#getting-involved\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>AMS is an open-source project, and\
    \ we welcome contributions from the community.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Contributions</h2><a id=\"user-content-contributions\"\
    \ class=\"anchor\" aria-label=\"Permalink: Contributions\" href=\"#contributions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>We welcome all kinds of contributions: new features, bug fixes, documentation\
    \ edits; it's all great!</p>\n<p>To contribute, make a pull request, with develop\
    \ as the destination branch.</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Authors</h2><a id=\"user-content-authors\" class=\"anchor\"\
    \ aria-label=\"Permalink: Authors\" href=\"#authors\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Thanks to all of AMS contributors.</p>\n\
    <p>AMS was created under the AMS LDRD-SI project (22-SI-004).</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Citation</h2><a id=\"user-content-citation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Citation\" href=\"#citation\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>If\
    \ you use this software, please cite it as below:</p>\n<ul>\n<li>Bhatia, Harsh,\
    \ Patki, Tapasya A., Brink, Stephanie, Pottier, Lo\xEFc, Stitt, Thomas M., Parasyris,\
    \ Konstantinos, Milroy, Daniel J., Laney, Daniel E., Blake, Robert C., Yeom, Jae-Seung,\
    \ Bremer, Peer-Timo, and Doutriaux, Charles. Autonomous MultiScale Library. Computer\
    \ Software. <a href=\"https://github.com/LLNL/AMS\">https://github.com/LLNL/AMS</a>.\
    \ US DOE National Nuclear Security Administration (NNSA). 01 May. 2023. Web. doi:10.11578/dc.20230721.1.</li>\n\
    </ul>\n<p>or get the format you prefer from <a href=\"https://www.osti.gov/doecode/biblio/110346\"\
    \ rel=\"nofollow\">here</a></p>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">Release</h1><a id=\"user-content-release\" class=\"anchor\"\
    \ aria-label=\"Permalink: Release\" href=\"#release\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>AMSLib is released under\
    \ Apache License (Version 2.0) with LLVM exceptions. For more details, please\
    \ see the <a href=\"./LICENSE\">LICENSE</a></p>\n<p><code>LLNL-CODE-851455</code></p>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Installation Instructions</h1><a\
    \ id=\"user-content-installation-instructions\" class=\"anchor\" aria-label=\"\
    Permalink: Installation Instructions\" href=\"#installation-instructions\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>See\
    \ <a href=\"./INSTALL.md\">INSTALL.md</a> for full instructions.</p>\n"
  stargazers_count: 3
  subscribers_count: 5
  topics:
  - machine-learning
  - hpc
  updated_at: 1709316608.0
LLNL/DiHydrogen:
  data_format: 2
  description: null
  filenames:
  - .gitlab/spack/environments/quartz/spack.yaml
  - .gitlab/spack/environments/pascal/spack.yaml
  - .gitlab/spack/environments/lassen/spack.yaml
  full_name: LLNL/DiHydrogen
  latest_release: v0.3.0
  readme: '<div class="markdown-heading"><h1 class="heading-element">DiHydrogen</h1><a
    id="user-content-dihydrogen" class="anchor" aria-label="Permalink: DiHydrogen"
    href="#dihydrogen"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>DiHydrogen is the second version of the

    <a href="https://github.com/llnl/elemental">Hydrogen</a> fork of the well-known

    distributed linear algebra library,

    <a href="https://github.com/elemental/elemental">Elemental</a>.  DiHydrogen aims

    to be a basic distributed multilinear algebra interface with a

    particular emphasis on the needs of the distributed machine learning

    effort, <a href="https://github.com/llnl/lbann">LBANN</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>DiHydrogen is distributed under the terms of the Apache License (Version 2.0).</p>

    <p>All new contributions must be made under the Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/LLNL/DiHydrogen/blob/develop/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/NOTICE">NOTICE</a> for
    details.</p>

    <p>SPDX-License-Identifier: Apache-2.0</p>

    <p>LLNL-CODE-800100</p>

    '
  stargazers_count: 5
  subscribers_count: 11
  topics:
  - cpp
  - math-physics
  updated_at: 1715784470.0
LLNL/Umpire:
  data_format: 2
  description: An application-focused API for memory management on NUMA & GPU architectures
  filenames:
  - .spack_env/darwin/spack.yaml
  full_name: LLNL/Umpire
  latest_release: v2024.02.1
  readme: '<div class="markdown-heading"><h1 class="heading-element">

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/16f93148e0fba6da82ea7e29bc163792e4adfa6d97964ef301f27bb5804fe1ce/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"><img
    src="https://camo.githubusercontent.com/16f93148e0fba6da82ea7e29bc163792e4adfa6d97964ef301f27bb5804fe1ce/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"
    width="128" valign="middle" alt="Umpire" data-canonical-src="https://cdn.rawgit.com/LLNL/Umpire/develop/share/umpire/logo/umpire-logo.png"
    style="max-width: 100%;"></a>  Umpire v2024.02.1</h1><a id="user-content---umpire-v2024021"
    class="anchor" aria-label="Permalink:   Umpire v2024.02.1" href="#--umpire-v2024021"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://travis-ci.com/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/7b035b6565b7e96277667acd970a34d855ba58259be899a270de459ba1a42393/68747470733a2f2f7472617669732d63692e636f6d2f4c4c4e4c2f556d706972652e7376673f6272616e63683d646576656c6f70"
    alt="Travis Build Status" data-canonical-src="https://travis-ci.com/LLNL/Umpire.svg?branch=develop"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/davidbeckingsale/Umpire/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/67d5cb2c08560bb4582131e7ab385863faee5e7f89266ef73c47bdc7c0ff4544/68747470733a2f2f6465762e617a7572652e636f6d2f64617669646265636b696e6773616c652f556d706972652f5f617069732f6275696c642f7374617475732f4c4c4e4c2e556d706972653f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/davidbeckingsale/Umpire/_apis/build/status/LLNL.Umpire?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://umpire.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c43adcc35db9b22246733d2caaad138c624a56e87031c1e8e5f72f0c3752d0f5/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756d706972652f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/umpire/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/dec8e40b05ba312fc266977dc2ea2803d478e338856c3b8838437a8c72cf7264/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f556d706972652f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/Umpire/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a> <a href="https://gitter.im/LLNL/Umpire?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/b97e5039e17f725e41c4f915579646596c1bee4d17b93bcd958360b41c38c4d8/68747470733a2f2f6261646765732e6769747465722e696d2f4c4c4e4c2f556d706972652e737667"
    alt="Join the chat at https://gitter.im/LLNL/Umpire" data-canonical-src="https://badges.gitter.im/LLNL/Umpire.svg"
    style="max-width: 100%;"></a></p>

    <p>Umpire is a resource management library that allows the discovery, provision,

    and management of memory on machines with multiple memory devices like NUMA and
    GPUs.</p>

    <p>Umpire uses CMake and BLT to handle builds. Since BLT is included as a

    submodule, first make sure you run:</p>

    <pre><code>$ git submodule init &amp;&amp; git submodule update

    </code></pre>

    <p>Then, make sure that you have a modern compiler loaded, and the configuration
    is as

    simple as:</p>

    <pre><code>$ mkdir build &amp;&amp; cd build

    $ cmake ..

    </code></pre>

    <p>CMake will provide output about which compiler is being used. Once CMake has

    completed, Umpire can be built with Make:</p>

    <pre><code>$ make

    </code></pre>

    <p>For more advanced configuration you can use standard CMake variables.</p>

    <div class="markdown-heading"><h1 class="heading-element">Documentation</h1><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Both user and code documentation is available <a href="http://umpire.readthedocs.io/"
    rel="nofollow">here</a>.</p>

    <p>The Umpire <a href="https://umpire.readthedocs.io/en/develop/sphinx/tutorial.html"
    rel="nofollow">tutorial</a> provides a step by step introduction to Umpire features.</p>

    <p>If you have build problems, we have comprehensive <a href="https://umpire.readthedocs.io/en/develop/sphinx/advanced_configuration.html"
    rel="nofollow">build system documentation</a> too!</p>

    <div class="markdown-heading"><h1 class="heading-element">Getting Involved</h1><a
    id="user-content-getting-involved" class="anchor" aria-label="Permalink: Getting
    Involved" href="#getting-involved"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Umpire is an open-source project, and we welcome contributions from the community.</p>

    <div class="markdown-heading"><h2 class="heading-element">Mailing List</h2><a
    id="user-content-mailing-list" class="anchor" aria-label="Permalink: Mailing List"
    href="#mailing-list"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The Umpire mailing list is hosted on Google Groups, and is a great place to
    ask questions:</p>

    <ul>

    <li><a href="https://groups.google.com/forum/#!forum/umpire-users" rel="nofollow">Umpire
    Users Google Group</a></li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Contributions</h2><a
    id="user-content-contributions" class="anchor" aria-label="Permalink: Contributions"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits; it''s all great!</p>

    <p>To contribute, make a <a href="https://github.com/LLNL/Umpire/compare">pull
    request</a>, with <code>develop</code> as the destination branch.

    We use Travis to run CI tests, and your branch must pass these tests before being
    merged.</p>

    <p>For more information, see the <a href="https://github.com/LLNL/Umpire/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <div class="markdown-heading"><h1 class="heading-element">Authors</h1><a id="user-content-authors"
    class="anchor" aria-label="Permalink: Authors" href="#authors"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Thanks to all of Umpire''s

    <a href="https://github.com/LLNL/Umpire/graphs/contributors">contributors</a>.</p>

    <p>Umpire was created by David Beckingsale (<a href="mailto:david@llnl.gov">david@llnl.gov</a>).</p>

    <div class="markdown-heading"><h2 class="heading-element">Citing Umpire</h2><a
    id="user-content-citing-umpire" class="anchor" aria-label="Permalink: Citing Umpire"
    href="#citing-umpire"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>If you are referencing Umpire in a publication, please use the following citation:</p>

    <ul>

    <li>D. Beckingsale, M. Mcfadden, J. Dahm, R. Pankajakshan and R. Hornung, <a href="https://ieeexplore.ieee.org/document/8907404"
    rel="nofollow">"Umpire: Application-Focused Management and Coordination of Complex
    Hierarchical Memory,"</a> in IBM Journal of Research and Development. 2019. doi:
    10.1147/JRD.2019.2954403</li>

    </ul>

    <div class="markdown-heading"><h1 class="heading-element">Release</h1><a id="user-content-release"
    class="anchor" aria-label="Permalink: Release" href="#release"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Umpire is released under an MIT license. For more details, please see the

    <a href="./LICENSE">LICENSE</a> and <a href="./RELEASE">RELEASE</a> files.</p>

    <p><code>LLNL-CODE-747640</code>

    <code>OCEC-18-031</code></p>

    '
  stargazers_count: 304
  subscribers_count: 17
  topics:
  - hpc
  - memory-management
  - gpu
  - blt
  - portability
  - radiuss
  - cpp
  updated_at: 1716462549.0
LLNL/UnifyFS:
  data_format: 2
  description: 'UnifyFS: A file system for burst buffers'
  filenames:
  - .spack-env/unifyfs-lsf-gcc4_9_3/spack.yaml
  full_name: LLNL/UnifyFS
  latest_release: v2.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">UnifyFS:\
    \ A User-Level File System for Supercomputers</h1><a id=\"user-content-unifyfs-a-user-level-file-system-for-supercomputers\"\
    \ class=\"anchor\" aria-label=\"Permalink: UnifyFS: A User-Level File System for\
    \ Supercomputers\" href=\"#unifyfs-a-user-level-file-system-for-supercomputers\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Node-local storage is becoming an indispensable hardware resource on\nlarge-scale\
    \ supercomputers to buffer the bursty I/O from scientific\napplications. However,\
    \ there is a lack of software support for node-local storage to\nbe used efficiently\
    \ by applications that use shared files.</p>\n<p>UnifyFS is an ephemeral, user-level\
    \ file system under active development.\nUnifyFS addresses a major usability factor\
    \ of current and future systems because it enables\napplications to gain performance\
    \ advantages from distributed storage devices on the system while being as easy\
    \ to use as a center-wide parallel file system.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Documentation</h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>UnifyFS documentation is at <a href=\"https://unifyfs.readthedocs.io\" rel=\"\
    nofollow\">https://unifyfs.readthedocs.io</a>.</p>\n<p>For instructions on how\
    \ to build and install UnifyFS,\nsee <a href=\"http://unifyfs.readthedocs.io/en/dev/build.html\"\
    \ rel=\"nofollow\">Build UnifyFS</a>.</p>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Build Status</h2><a id=\"user-content-build-status\"\
    \ class=\"anchor\" aria-label=\"Permalink: Build Status\" href=\"#build-status\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Status of UnifyFS development branch (dev):</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    ><img src=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://unifyfs.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/32daa6ee48d97cb528194d1ea7f20969e697b70bcd7fc76a159c9c10a5ed371b/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756e69667966732f62616467652f3f76657273696f6e3d646576\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/unifyfs/badge/?version=dev\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">UnifyFS Citation</h2><a id=\"user-content-unifyfs-citation\"\
    \ class=\"anchor\" aria-label=\"Permalink: UnifyFS Citation\" href=\"#unifyfs-citation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>We recommend that you use this citation for UnifyFS:</p>\n<ul>\n<li>Michael\
    \ Brim, Adam Moody, Seung-Hwan Lim, Ross Miller, Swen Boehm, Cameron Stanavige,\
    \ Kathryn Mohror, Sarp Oral, \u201CUnifyFS: A User-level Shared File System for\
    \ Unified Access to Distributed Local Storage,\u201D 37th IEEE International Parallel\
    \ &amp; Distributed Processing Symposium (IPDPS 2023), St. Petersburg, FL, May\
    \ 2023.</li>\n</ul>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Contribute and Develop</h2><a id=\"user-content-contribute-and-develop\" class=\"\
    anchor\" aria-label=\"Permalink: Contribute and Develop\" href=\"#contribute-and-develop\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>If you would like to help, please see our <a href=\"https://unifyfs.readthedocs.io/en/dev/contribute-ways.html\"\
    \ rel=\"nofollow\">contributing guidelines</a>.</p>\n"
  stargazers_count: 96
  subscribers_count: 19
  topics:
  - system-software
  - burst-buffers
  - file-system
  updated_at: 1715810413.0
LLNL/axom:
  data_format: 2
  description: CS infrastructure components for HPC applications
  filenames:
  - scripts/spack/configs/toss_4_x86_64_ib_cray/spack.yaml
  - scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/darwin/spack.yaml
  - scripts/spack/configs/linux_ubuntu_20/spack.yaml
  - scripts/spack/configs/blueos_3_ppc64le_ib_p9/spack.yaml
  - scripts/spack/configs/docker/ubuntu20/spack.yaml
  full_name: LLNL/axom
  latest_release: v0.9.0
  readme: '<div class="markdown-heading"><h1 class="heading-element"><a target="_blank"
    rel="noopener noreferrer" href="/share/axom/logo/axom_logo_transparent.png?raw=true"><img
    src="/share/axom/logo/axom_logo_transparent.png?raw=true" width="250" valign="middle"
    alt="Axom" style="max-width: 100%;"></a></h1><a id="" class="anchor" aria-label="Permalink:
    " href="#"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://dev.azure.com/axom/axom/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/2e86a2917fe6af2683654deb988253bb0643de772d9b144c44792e0dee8267c5/68747470733a2f2f6465762e617a7572652e636f6d2f61786f6d2f61786f6d2f5f617069732f6275696c642f7374617475732f4c4c4e4c2e61786f6d3f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/axom/axom/_apis/build/status/LLNL.axom?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://axom.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/8723959c981c1cd7fa64e597cc73c149d9a423922f12dcaa572a9ddf30bb689c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f61786f6d2f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/axom/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/blob/develop/LICENSE"><img src="https://camo.githubusercontent.com/aa27bfae9200ad81b9c64e82edafa3aef061e2b59e4089eb0841297d510d5db9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/License-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/releases/latest"><img src="https://camo.githubusercontent.com/6532c8239e2f1f30a988264904337c2f4904be4b6867e704eb39e6c48a4b6f0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4c4c4e4c2f61786f6d2e737667"
    alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/LLNL/axom.svg"
    style="max-width: 100%;"></a></p>

    <p>Axom provides robust, flexible software infrastructure for the development
    of multi-physics applications and computational tools.</p>

    <div class="markdown-heading"><h2 class="heading-element">Documentation</h2><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Latest docs on Develop branch: <a href="https://axom.readthedocs.io" rel="nofollow">https://axom.readthedocs.io</a></p>

    <p>To access docs for other versions: <a href="https://readthedocs.org/projects/axom/"
    rel="nofollow">https://readthedocs.org/projects/axom/</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Getting Involved</h2><a
    id="user-content-getting-involved" class="anchor" aria-label="Permalink: Getting
    Involved" href="#getting-involved"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Axom is an open-source project and we welcome contributions from the community.</p>

    <div class="markdown-heading"><h2 class="heading-element">Mailing List</h2><a
    id="user-content-mailing-list" class="anchor" aria-label="Permalink: Mailing List"
    href="#mailing-list"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The project maintains two email lists:</p>

    <ul>

    <li>''<a href="mailto:axom-users@llnl.gov">axom-users@llnl.gov</a>'' is how Axom
    users can contact developers for questions, report issues, etc.</li>

    <li>''<a href="mailto:axom-dev@llnl.gov">axom-dev@llnl.gov</a>'' is for communication
    among team members.</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Contributions</h2><a
    id="user-content-contributions" class="anchor" aria-label="Permalink: Contributions"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits.</p>

    <p>To contribute, make a <a href="https://github.com/llnl/axom/compare">pull request</a>,
    with <code>develop</code>

    as the destination branch. We use CI testing and your branch must pass these tests
    before

    being merged.</p>

    <p>For more information, see the <a href="https://github.com/llnl/axom/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Authors</h2><a id="user-content-authors"
    class="anchor" aria-label="Permalink: Authors" href="#authors"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Thanks to all of Axom''s

    <a href="https://github.com/llnl/axom/graphs/contributors">contributors</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Copyright (c) 2017-2024, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Axom project are retained by contributors.

    No copyright assignment is required to contribute to Axom.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution

    <code>LLNL-CODE-741217</code> <code>OCEC-17-187</code></p>

    <div class="markdown-heading"><h2 class="heading-element">SPDX usage</h2><a id="user-content-spdx-usage"
    class="anchor" aria-label="Permalink: SPDX usage" href="#spdx-usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">External Packages</h2><a
    id="user-content-external-packages" class="anchor" aria-label="Permalink: External
    Packages" href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Axom bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: CLI11<br>

    PackageHomePage: <a href="https://github.com/CLIUtils/CLI11">https://github.com/CLIUtils/CLI11</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: fmt<br>

    PackageHomePage: <a href="https://github.com/fmtlib/fmt">https://github.com/fmtlib/fmt</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sol<br>

    PackageHomePage: <a href="https://github.com/ThePhD/sol2">https://github.com/ThePhD/sol2</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sparsehash<br>

    PackageHomePage: <a href="https://github.com/sparsehash/sparsehash">https://github.com/sparsehash/sparsehash</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 142
  subscribers_count: 25
  topics:
  - hpc
  - parallel-computing
  - llnl
  - cpp
  - c-plus-plus
  - app-infrastructure
  - radiuss
  - fortran
  updated_at: 1717170159.0
LLNL/benchpark:
  data_format: 2
  description: An open collaborative repository for reproducible specifications of
    HPC benchmarks and cross site benchmarking environments
  filenames:
  - configs/LLNL-Tioga-HPECray-zen3-MI250X-Slingshot/spack.yaml
  - configs/LLNL-Sierra-IBM-power9-V100-Infiniband/spack.yaml
  - configs/LLNL-Pascal-Penguin-broadwell-P100-OmniPath/spack.yaml
  - configs/nosite-AWS_PCluster_Hpc7a-zen4-EFA/spack.yaml
  - configs/CSCS-Daint-HPECray-haswell-P100-Infiniband/spack.yaml
  - configs/CSCS-Eiger-HPECray-zen2-Slingshot/spack.yaml
  full_name: LLNL/benchpark
  latest_release: null
  stargazers_count: 24
  subscribers_count: 10
  topics:
  - benchmark
  - hpc
  updated_at: 1717171695.0
LLNL/hiop:
  data_format: 2
  description: HPC solver for nonlinear optimization problems
  filenames:
  - scripts/platforms/newell/spack.yaml
  - scripts/platforms/marianas/spack.yaml
  full_name: LLNL/hiop
  latest_release: v1.0.3
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">HiOp - HPC\
    \ solver for optimization</h1><a id=\"user-content-hiop---hpc-solver-for-optimization\"\
    \ class=\"anchor\" aria-label=\"Permalink: HiOp - HPC solver for optimization\"\
    \ href=\"#hiop---hpc-solver-for-optimization\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p><a target=\"_blank\" rel=\"noopener\
    \ noreferrer\" href=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\"\
    ><img src=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\" alt=\"tests\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>HiOp is an optimization solver for solving\
    \ certain mathematical optimization problems expressed as nonlinear programming\
    \ problems. HiOp is a lightweight HPC solver that leverages application's existing\
    \ data parallelism to parallelize the optimization iterations by using specialized\
    \ parallel linear algebra kernels.</p>\n<p>Please cite the user manual whenever\
    \ HiOp is used:</p>\n<pre><code>@TECHREPORT{hiop_techrep,\n  title={{HiOp} --\
    \ {U}ser {G}uide},\n  author={Petra, Cosmin G. and Chiang, NaiYuan and Jingyi\
    \ Wang},\n  year={2018},\n  institution = {Center for Applied Scientific Computing,\
    \ Lawrence Livermore National Laboratory},\n  number = {LLNL-SM-743591}\n}\n</code></pre>\n\
    <p>In addition, when using the quasi-Newton solver please cite:</p>\n<pre><code>@ARTICLE{Petra_18_hiopdecomp,\n\
    title = {A memory-distributed quasi-Newton solver for nonlinear programming problems\
    \ with a small number of general constraints},\njournal = {Journal of Parallel\
    \ and Distributed Computing},\nvolume = {133},\npages = {337-348},\nyear = {2019},\n\
    issn = {0743-7315},\ndoi = {https://doi.org/10.1016/j.jpdc.2018.10.009},\nurl\
    \ = {https://www.sciencedirect.com/science/article/pii/S0743731518307731},\nauthor\
    \ = {Cosmin G. Petra},\n}\n</code></pre>\n<p>and when using the the PriDec solver\
    \ please cite:</p>\n<pre><code>@article{wang2023,\n  archivePrefix = {arXiv},\n\
    \  author = {J. Wang and C. G. Petra},\n  title = {A Sequential Quadratic Programming\
    \ Algorithm for Nonsmooth Problems with Upper-$\\mathcal{C}^2$ Objective},\n \
    \ journal = {SIAM Journal on Optimization},\n  volume = {33},\n  number = {3},\n\
    \  pages = {2379-2405},\n  year = {2023},\n  doi = {10.1137/22M1490995}\n}\n@INPROCEEDINGS{wang2021,\n\
    \  author={J. Wang and N. Chiang and C. G. Petra},\n  booktitle={2021 20th International\
    \ Symposium on Parallel and Distributed Computing (ISPDC)}, \n  title={An asynchronous\
    \ distributed-memory optimization solver for two-stage stochastic programming\
    \ problems}, \n  year={2021},\n  volume={},\n  number={},\n  pages={33-40},\n\
    \  doi={10.1109/ISPDC52870.2021.9521613}}\n }\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Build/install instructions</h2><a id=\"user-content-buildinstall-instructions\"\
    \ class=\"anchor\" aria-label=\"Permalink: Build/install instructions\" href=\"\
    #buildinstall-instructions\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>HiOp uses a CMake-based build system. A standard build\
    \ can be done by invoking in the 'build' directory the following</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> cmake\
    \ ..\n$<span class=\"pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span>\
    \ make <span class=\"pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make\
    \ install</pre></div>\n<p>This sequence will build HiOp, run integrity and correctness\
    \ tests, and install the headers and the library in the directory '_dist-default-build'\
    \ in HiOp's root directory.</p>\n<p>Command <code>make test</code> runs extensive\
    \ tests of the various modules of HiOp to check integrity and correctness. The\
    \ tests suite range from unit testing to solving concrete optimization problems\
    \ and checking the performance of HiOp solvers on these problems against known\
    \ solutions. By default <code>make test</code> runs <code>mpirun</code> locally,\
    \ which may not work on some HPC machines. For these HiOp allows using <code>bsub</code>\
    \ to schedule <code>make test</code> on the compute nodes; to enable this, the\
    \ use should use <em>-DHIOP_TEST_WITH_BSUB=ON</em> with cmake when building and\
    \ run <code>make test</code> in a bsub shell session, for example,</p>\n<pre><code>bsub\
    \ -P your_proj_name -nnodes 1 -W 30\nmake test\nCTRL+D\n</code></pre>\n<p>The\
    \ installation can be customized using the standard CMake options. For example,\
    \ one can provide an alternative installation directory for HiOp by using</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span>\
    \ cmake -DCMAKE_INSTALL_PREFIX=/usr/lib/hiop ..<span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span></span></pre></div>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Selected HiOp-specific build options</h3><a id=\"user-content-selected-hiop-specific-build-options\"\
    \ class=\"anchor\" aria-label=\"Permalink: Selected HiOp-specific build options\"\
    \ href=\"#selected-hiop-specific-build-options\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<ul>\n<li>Enable/disable MPI: <em>-DHIOP_USE_MPI=[ON/OFF]</em>\
    \ (by default ON)</li>\n<li>GPU support: <em>-DHIOP_USE_GPU=ON</em>. MPI can be\
    \ either off or on. For more build system options related to GPUs, see \"Dependencies\"\
    \ section below.</li>\n<li>Enable/disable \"developer mode\" build that enforces\
    \ more restrictive compiler rules and guidelines: <em>-DHIOP_DEVELOPER_MODE=ON</em>.\
    \ This option is by default off.</li>\n<li>Additional checks and self-diagnostics\
    \ inside HiOp meant to detect abnormalities and help to detect bugs and/or troubleshoot\
    \ problematic instances: <em>-DHIOP_DEEPCHECKS=[ON/OFF]</em> (by default ON).\
    \ Disabling HIOP_DEEPCHECKS usually provides 30-40% execution speedup in HiOp.\
    \ For full strength, it is recommended to use HIOP_DEEPCHECKS with debug builds.\
    \ With non-debug builds, in particular the ones that disable the assert macro,\
    \ HIOP_DEEPCHECKS does not perform all checks and, thus, may overlook potential\
    \ issues.</li>\n</ul>\n<p>For example:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_MPI=ON -DHIOP_DEEPCHECKS=ON\
    \ ..\n$<span class=\"pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span>\
    \ make <span class=\"pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make\
    \ install</pre></div>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Other useful options to use with CMake</h3><a id=\"user-content-other-useful-options-to-use-with-cmake\"\
    \ class=\"anchor\" aria-label=\"Permalink: Other useful options to use with CMake\"\
    \ href=\"#other-useful-options-to-use-with-cmake\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<ul>\n<li>\n<em>-DCMAKE_BUILD_TYPE=Release</em>\
    \ will build the code with the optimization flags on</li>\n<li>\n<em>-DCMAKE_CXX_FLAGS=\"\
    -O3\"</em> will enable a high level of compiler code optimization</li>\n</ul>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Dependencies</h3><a\
    \ id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\"\
    \ href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>A complete list of dependencies is maintained <a href=\"\
    https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/hiop/package.py\"\
    >here</a>.</p>\n<p>For a minimal build, HiOp requires LAPACK and BLAS. These dependencies\
    \ are automatically detected by the build system. MPI is optional and by default\
    \ enabled. To disable use cmake option '-DHIOP_USE_MPI=OFF'.</p>\n<p>HiOp has\
    \ support for NVIDIA <strong>GPU-based computations</strong> via CUDA and Magma.\
    \ To enable the use of GPUs, use cmake with '-DHIOP_USE_GPU=ON'. The build system\
    \ will automatically search for CUDA Toolkit. For non-standard CUDA Toolkit installations,\
    \ use '-DHIOP_CUDA_LIB_DIR=/path' and '-DHIOP_CUDA_INCLUDE_DIR=/path'. For \"\
    very\" non-standard CUDA Toolkit installations, one can specify the directory\
    \ of cuBlas libraries as well with '-DHIOP_CUBLAS_LIB_DIR=/path'.</p>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Using RAJA and Umpire portability\
    \ libraries</h3><a id=\"user-content-using-raja-and-umpire-portability-libraries\"\
    \ class=\"anchor\" aria-label=\"Permalink: Using RAJA and Umpire portability libraries\"\
    \ href=\"#using-raja-and-umpire-portability-libraries\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Portability libraries allow\
    \ running HiOp's linear algebra either on host (CPU) or a device (GPU). RAJA and\
    \ Umpire are disabled by default. You can turn them on together by passing <code>-DHIOP_USE_RAJA=ON</code>\
    \ to CMake. If the two libraries are not automatically found, specify their installation\
    \ directories like this:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_RAJA=ON -DRAJA_DIR=/path/to/raja/dir\
    \ -Dumpire_DIR=/path/to/umpire/dir</pre></div>\n<p>If the GPU support is enabled,\
    \ RAJA will run all HiOp linear algebra kernels on GPU, otherwise RAJA will run\
    \ the kernels on CPU using an OpenMP execution policy.</p>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Support for GPU computations</h3><a id=\"user-content-support-for-gpu-computations\"\
    \ class=\"anchor\" aria-label=\"Permalink: Support for GPU computations\" href=\"\
    #support-for-gpu-computations\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>When GPU support is on, HiOp requires Magma linear solver\
    \ library and CUDA Toolkit. Both are detected automatically in most cases. The\
    \ typical cmake command to enable GPU support in HiOp is</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_GPU=ON\
    \ ..</pre></div>\n<p>When Magma is not detected, one can specify its location\
    \ by passing <code>-DHIOP_MAGMA_DIR=/path/to/magma/dir</code> to cmake.</p>\n\
    <p>For custom CUDA Toolkit installations, the locations to the (missing/not found)\
    \ CUDA libraries can be specified to cmake via <code>-DNAME=/path/cuda/directory/lib</code>,\
    \ where <code>NAME</code> can be any of</p>\n<pre><code>CUDA_cublas_LIBRARY\n\
    CUDA_CUDART_LIBRARY\nCUDA_cudadevrt_LIBRARY\nCUDA_cusparse_LIBRARY\nCUDA_cublasLt_LIBRARY\n\
    CUDA_nvblas_LIBRARY\nCUDA_culibos_LIBRARY\n</code></pre>\n<p>Below is an example\
    \ for specifiying <code>cuBlas</code>, <code>cuBlasLt</code>, and <code>nvblas</code>\
    \ libraries, which were <code>NOT_FOUND</code> because of a non-standard CUDA\
    \ Toolkit instalation:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span\
    \ class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_GPU=ON -DCUDA_cublas_LIBRARY=/usr/local/cuda-10.2/targets/x86_64-linux/lib/lib64\
    \ -DCUDA_cublasLt_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ -DCUDA_nvblas_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>A detailed example on how to compile HiOp straight\
    \ of the box on <code>summit.olcf.ornl.gov</code> is available <a href=\"README_summit.md\"\
    >here</a>.</p>\n<p>RAJA and UMPIRE dependencies are usually detected by HiOp's\
    \ cmake build system.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Kron reduction</h3><a id=\"user-content-kron-reduction\" class=\"anchor\" aria-label=\"\
    Permalink: Kron reduction\" href=\"#kron-reduction\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Kron reduction functionality\
    \ of HiOp is disabled by default. One can enable it by using</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> rm -rf\
    \ <span class=\"pl-k\">*</span><span class=\"pl-k\">;</span> cmake -DHIOP_WITH_KRON_REDUCTION=ON\
    \ -DUMFPACK_DIR=/Users/petra1/work/installs/SuiteSparse-5.7.1 -DMETIS_DIR=/Users/petra1/work/installs/metis-4.0.3\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>Metis is usually detected automatically and needs\
    \ not be specified under normal circumstances.</p>\n<p>UMFPACK (part of SuiteSparse)\
    \ and METIS need to be provided as shown above.</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Interfacing with HiOp</h1><a id=\"user-content-interfacing-with-hiop\"\
    \ class=\"anchor\" aria-label=\"Permalink: Interfacing with HiOp\" href=\"#interfacing-with-hiop\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>HiOp supports three types of optimization problems, each with a separate input\
    \ formats in the form of the C++ interfaces <code>hiopInterfaceDenseConstraints</code>,<code>hiopInterfaceSparse</code>\
    \ and <code>hiopInterfaceMDS</code>. These interfaces are specified in <a href=\"\
    src/Interface/hiopInterface.hpp\">hiopInterface.hpp</a> and documented and discussed\
    \ as well in the <a href=\"doc/hiop_usermanual.pdf\">user manual</a>.</p>\n<p><em><code>hiopInterfaceDenseConstraints</code>\
    \ interface</em> supports NLPs with <strong>billions</strong> of variables with\
    \ and without bounds but only limited number (&lt;100) of general, equality and\
    \ inequality constraints. The underlying algorithm is a limited-memory quasi-Newton\
    \ interior-point method and generally scales well computationally (but it may\
    \ not algorithmically) on thousands of cores. This interface uses MPI for parallelization</p>\n\
    <p><em><code>hiopInterfaceSparse</code> interface</em> supports general sparse\
    \ and large-scale NLPs. This functionality is similar to that of the state-of-the-art\
    \ <a href=\"https://github.com/coin-or/Ipopt\">Ipopt</a> (without being as robust\
    \ and flexible as Ipopt is). Acceleration for this class of problems can be achieved\
    \ via OpenMP or CUDA, however, this is work in progress and you are encouraged\
    \ to contact HiOp's developers for up-to-date information.</p>\n<p><em><code>hiopInterfaceMDS</code>\
    \ interface</em> supports mixed dense-sparse NLPs and achives parallelization\
    \ using GPUs and RAJA portability abstraction layer.</p>\n<p>More information\
    \ on the HiOp interfaces are <a href=\"src/Interface/README.md\">here</a>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Running HiOp tests\
    \ and applications</h2><a id=\"user-content-running-hiop-tests-and-applications\"\
    \ class=\"anchor\" aria-label=\"Permalink: Running HiOp tests and applications\"\
    \ href=\"#running-hiop-tests-and-applications\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>HiOp is using NVBlas library when\
    \ built with CUDA support. If you don't specify\nlocation of the <code>nvblas.conf</code>\
    \ configuration file, you may get an annoying\nwarnings. HiOp provides default\
    \ <code>nvblas.conf</code> file and installs it at the same\nlocation as HiOp\
    \ libraries. To use it, set environment variable as</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$ <span class=\"pl-k\">export</span> NVBLAS_CONFIG_FILE=<span\
    \ class=\"pl-k\">&lt;</span>hiop install dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n\
    <p>or, if you are using C-shell, as</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ setenv NVBLAS_CONFIG_FILE <span class=\"pl-k\">&lt;</span>hiop install\
    \ dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Existing issues</h2><a id=\"\
    user-content-existing-issues\" class=\"anchor\" aria-label=\"Permalink: Existing\
    \ issues\" href=\"#existing-issues\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>Users are highly encouraged to report any\
    \ issues they found from using HiOp.\nOne known issue is that there is some minor\
    \ inconsistence between HiOp and linear package STRUMPACK.\nWhen STRUMPACK is\
    \ compiled with MPI (and Scalapack), user must set flag <code>HIOP_USE_MPI</code>\
    \ to <code>ON</code> when compiling HiOp.\nOtherwise HiOp won't load MPI module\
    \ and will return an error when links to STRUMPACK, since the later one requires\
    \ a valid MPI module.\nSimilarly, if both Magma and STRUMPACK are linked to HiOp,\
    \ user must guarantee the all the packages are compiled by the same CUDA compiler.\n\
    User can check other issues and their existing status from <a href=\"https://github.com/LLNL/hiop\"\
    >https://github.com/LLNL/hiop</a></p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Acknowledgments</h2><a id=\"user-content-acknowledgments\" class=\"\
    anchor\" aria-label=\"Permalink: Acknowledgments\" href=\"#acknowledgments\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>HiOp\
    \ has been developed under the financial support of:</p>\n<ul>\n<li>Department\
    \ of Energy, Office of Advanced Scientific Computing Research (ASCR): Exascale\
    \ Computing Program (ECP) and Applied Math Program.</li>\n<li>Department of Energy,\
    \ Advanced Research Projects Agency-Energy (ARPA\u2011E)</li>\n<li>Lawrence Livermore\
    \ National Laboratory Institutional Scientific Capability Portfolio (ISCP)</li>\n\
    <li>Lawrence Livermore National Laboratory, through the LDRD program</li>\n</ul>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Contributors</h1><a\
    \ id=\"user-content-contributors\" class=\"anchor\" aria-label=\"Permalink: Contributors\"\
    \ href=\"#contributors\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>HiOp is written by Cosmin G. Petra (<a href=\"mailto:petra1@llnl.gov\"\
    >petra1@llnl.gov</a>), Nai-Yuan Chiang (<a href=\"mailto:chiang7@llnl.gov\">chiang7@llnl.gov</a>),\
    \ and Jingyi \"Frank\" Wang (<a href=\"mailto:wang125@llnl.gov\">wang125@llnl.gov</a>)\
    \ from LLNL and has received important contributions from Asher Mancinelli (PNNL),\
    \ Slaven Peles (ORNL), Cameron Rutherford (PNNL), Jake K. Ryan (PNNL), and Michel\
    \ Schanen (ANL).</p>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Copyright</h1><a id=\"user-content-copyright\" class=\"anchor\" aria-label=\"\
    Permalink: Copyright\" href=\"#copyright\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Copyright (c) 2017-2021, Lawrence\
    \ Livermore National Security, LLC. All rights reserved. Produced at the Lawrence\
    \ Livermore National Laboratory. LLNL-CODE-742473. HiOp is free software; you\
    \ can modify it and/or redistribute it under the terms of the BSD 3-clause license.\
    \ See <a href=\"/COPYRIGHT\">COPYRIGHT</a> and <a href=\"/LICENSE\">LICENSE</a>\
    \ for complete copyright and license information.</p>\n"
  stargazers_count: 206
  subscribers_count: 17
  topics:
  - hpc
  - nonlinear-optimization
  - nonlinear-programming
  - nonlinear-programming-algorithms
  - interior-point-method
  - parallel-programming
  - mpi
  - bfgs
  - quasi-newton
  - constrained-optimization
  - solver
  - optimization
  - acopf
  - gpu-support
  - cuda
  - math-physics
  - radiuss
  - interior-point-optimizer
  - nonsmooth-optimization
  - rocm
  updated_at: 1717127452.0
LLNL/hubcast:
  data_format: 2
  description: An event driven synchronization application for bridging GitHub and
    GitLab
  filenames:
  - spack.yaml
  full_name: LLNL/hubcast
  latest_release: null
  readme: "<div align=\"center\">\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"logo/logo.svg\"><img\
    \ src=\"logo/logo.svg\" width=\"400\" alt=\"Hubcast logo\" style=\"max-width:\
    \ 100%;\"></a>\n<br clear=\"all\">\n</h1><a id=\"\" class=\"anchor\" aria-label=\"\
    Permalink: \" href=\"#\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><strong><a href=\"#features\">Features</a> \_ \u2022 \_\
    \ <a href=\"/docs/getting-started.md\">Getting Started</a> \_ \u2022 \_ <a href=\"\
    /docs/getting-started.md\">Config</a> \_ \u2022 \_ <a href=\"/docs/CONTRIBUTING.md\"\
    >Contributing</a> \_ \u2022 \_ <a href=\"https://github.com/LLNL/hubcast/releases\"\
    >Changelog</a></strong></p>\n</div>\n<p>Hubcast is an event driven synchronization\
    \ application for bridging GitHub and GitLab. It automates various workflow tasks\
    \ and handles jobs like:</p>\n<ul>\n<li>Syncing branches from GitHub to GitLab.</li>\n\
    <li>Reporting CI job statuses back to GitHub from GitLab Workflow Runs.</li>\n\
    </ul>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">License</h2><a\
    \ id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\"\
    \ href=\"#license\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Licensed under the Apache License, Version 2.0 (the \"\
    License\");\nyou may not use this file except in compliance with the License.\n\
    You may obtain a copy of the License at</p>\n<p><a href=\"http://www.apache.org/licenses/LICENSE-2.0\"\
    \ rel=\"nofollow\">http://www.apache.org/licenses/LICENSE-2.0</a></p>\n<p>Unless\
    \ required by applicable law or agreed to in writing, software\ndistributed under\
    \ the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS\
    \ OF ANY KIND, either express or implied.\nSee the License for the specific language\
    \ governing permissions and\nlimitations under the License.</p>\n<p>SPDX-License-Identifier:\
    \ Apache-2.0</p>\n<p>LLNL-CODE-847946</p>\n"
  stargazers_count: 7
  subscribers_count: 5
  topics:
  - ci
  - github-app
  - gitlab-ci
  updated_at: 1716254615.0
LLNL/radiuss-spack-configs:
  data_format: 2
  description: Shared spack configurations for RADIUSS projects
  filenames:
  - toss_4_x86_64_ib_cray/spack.yaml
  - toss_3_x86_64_ib/spack.yaml
  - darwin/spack.yaml
  full_name: LLNL/radiuss-spack-configs
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">RADIUSS Spack
    Configs</h1><a id="user-content-radiuss-spack-configs" class="anchor" aria-label="Permalink:
    RADIUSS Spack Configs" href="#radiuss-spack-configs"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The RADIUSS project promotes and supports key High Performance Computing (HPC)
    open-source software developed at the LLNL. These tools and libraries cover a
    wide range of features a team would need to develop a modern simulation code targeting
    HPC plaftorms.</p>

    <p>Radiuss Spack Configs allows project to share a set of compilers and packages
    configurations for several machines.</p>

    <div class="markdown-heading"><h2 class="heading-element">Getting Started</h2><a
    id="user-content-getting-started" class="anchor" aria-label="Permalink: Getting
    Started" href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This project may be used as a submodule.</p>

    <div class="markdown-heading"><h3 class="heading-element">Installing</h3><a id="user-content-installing"
    class="anchor" aria-label="Permalink: Installing" href="#installing"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This project requires no installation.</p>

    <div class="markdown-heading"><h2 class="heading-element">Contributing</h2><a
    id="user-content-contributing" class="anchor" aria-label="Permalink: Contributing"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Please read <a href="https://github.com/LLNL/radiuss-spack-configs/CONTRIBUTING.md">CONTRIBUTING.md</a>
    for details on our code of conduct, and the process for submitting pull requests
    to us.</p>

    <div class="markdown-heading"><h2 class="heading-element">Versioning</h2><a id="user-content-versioning"
    class="anchor" aria-label="Permalink: Versioning" href="#versioning"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h3 class="heading-element">Tags nomenclature:</h3><a
    id="user-content-tags-nomenclature" class="anchor" aria-label="Permalink: Tags
    nomenclature:" href="#tags-nomenclature"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>Tags reflect the RAJA and Umpire latest release RADIUSS Spack Configs supports,
    together with the Spack reference that was used for vetting.

    We issue a tag as soon as one of the two parameter changes for the vetting of
    the main branch.

    We recommend using the same Spack as newer or older versions may not be compatible
    out of the box.</p>

    <div class="markdown-heading"><h2 class="heading-element">Authors</h2><a id="user-content-authors"
    class="anchor" aria-label="Permalink: Authors" href="#authors"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Adrien M Bernede</p>

    <p>See also the list of <a href="https://github.com/LLNL/radiuss-spack-configs/contributors">contributors</a>
    who participated in this project.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a>
    file for details</p>

    <p>All new contributions must be made under the MIT License.</p>

    <p>See <a href="https://github.com/LLNL/radiuss-spack-configs/blob/master/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/radiuss-spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/radiuss-spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (MIT)</p>

    <p>LLNL-CODE-793462</p>

    <div class="markdown-heading"><h2 class="heading-element">Acknowledgments</h2><a
    id="user-content-acknowledgments" class="anchor" aria-label="Permalink: Acknowledgments"
    href="#acknowledgments"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    '
  stargazers_count: 1
  subscribers_count: 15
  topics: []
  updated_at: 1675189925.0
LLNL/serac:
  data_format: 2
  description: Serac is a high order nonlinear thermomechanical simulation code
  filenames:
  - scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/linux_ubuntu_22/spack.yaml
  - scripts/spack/configs/docker/ubuntu20/spack.yaml
  - scripts/spack/configs/toss_4_x86_64_ib/spack.yaml
  full_name: LLNL/serac
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element"><a target="_blank"
    rel="noopener noreferrer" href="/share/serac/logo/serac-logo-blue.png?raw=true"><img
    src="/share/serac/logo/serac-logo-blue.png?raw=true" width="150" alt="Serac" style="max-width:
    100%;"></a></h1><a id="" class="anchor" aria-label="Permalink: " href="#"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://dev.azure.com/llnl-serac/serac/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/037c40c18167c2f51c531cab7f2ecc11128fd35f9de4f86069791798bc097f0a/68747470733a2f2f6465762e617a7572652e636f6d2f6c6c6e6c2d73657261632f73657261632f5f617069732f6275696c642f7374617475732f4c4c4e4c2e73657261633f6272616e63684e616d653d646576656c6f70"
    alt="Build Status" data-canonical-src="https://dev.azure.com/llnl-serac/serac/_apis/build/status/LLNL.serac?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://serac.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00fb910871e6439ba9db142b3d74c89f026b9fcc43c7d2c2e3a8aba22f0f47f0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73657261632f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/serac/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/serac" rel="nofollow"><img src="https://camo.githubusercontent.com/6024e4752532a6f5e3c2922749432d9a05441d39d538e4817c32971a0b65cac8/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f73657261632f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d444f344b464d504e4d30"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/serac/branch/develop/graph/badge.svg?token=DO4KFMPNM0"
    style="max-width: 100%;"></a>

    <a href="./LICENSE"><img src="https://camo.githubusercontent.com/46ab19c2c0af8a73620c60806fe8512ebe91f6db426ef8cf0855c60f04c4e5dd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/license-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>Serac is a 3D implicit nonlinear thermal-structural simulation code. Its primary
    purpose is to investigate multiphysics

    abstraction strategies and implicit finite element-based algorithm development
    for emerging computing architectures.

    It also serves as a proxy-app for LLNL''s Smith code and heavily leverages the
    <a href="https://mfem.org/" rel="nofollow">MFEM finite element library</a>.</p>

    <blockquote>

    <p>This project is under heavy development and is currently a pre-alpha release.
    Functionality and interfaces may change rapidly

    as development progresses.</p>

    </blockquote>

    <div class="markdown-heading"><h2 class="heading-element">Documentation</h2><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Build, run, and design documentation can be found at <a href="https://serac.readthedocs.io"
    rel="nofollow">readthedocs</a>.</p>

    <p>Source documentation can be found <a href="https://serac.readthedocs.io/en/latest/doxygen/html/index.html"
    rel="nofollow">here</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Contributions</h2><a
    id="user-content-contributions" class="anchor" aria-label="Permalink: Contributions"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>We welcome all kinds of contributions: new features, bug fixes, and documentation
    edits.</p>

    <p>For more information, see the <a href="./CONTRIBUTING.md">contributing guide</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Copyright (c) 2019-2024, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Serac project are retained by contributors.

    No copyright assignment is required to contribute to Serac.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution<br>

    <code>LLNL-CODE-805541</code></p>

    <div class="markdown-heading"><h2 class="heading-element">SPDX usage</h2><a id="user-content-spdx-usage"
    class="anchor" aria-label="Permalink: SPDX usage" href="#spdx-usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">External Packages</h2><a
    id="user-content-external-packages" class="anchor" aria-label="Permalink: External
    Packages" href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Serac bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: Axom<br>

    PackageHomePage: <a href="https://github.com/LLNL/axom">https://github.com/LLNL/axom</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: MFEM<br>

    PackageHomePage: <a href="https://github.com/mfem/mfem">https://github.com/mfem/mfem</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 169
  subscribers_count: 13
  topics:
  - math-physics
  - finite-elements
  - proxy-application
  - simulation
  - cpp
  updated_at: 1717192463.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/spack-nightly/int32-double/spack.yaml
  - docker/sundials-ci/spack-nightly/int64-double/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int64-single/spack.yaml
  full_name: LLNL/sundials
  latest_release: v7.0.0
  readme: '<div class="markdown-heading"><h1 class="heading-element">SUNDIALS: SUite
    of Nonlinear and DIfferential/ALgebraic equation Solvers</h1><a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" aria-label="Permalink: SUNDIALS: SUite of Nonlinear and DIfferential/ALgebraic
    equation Solvers" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h3 class="heading-element">Version 7.0.0 (Feb 2024)</h3><a
    id="user-content-version-700-feb-2024" class="anchor" aria-label="Permalink: Version
    7.0.0 (Feb 2024)" href="#version-700-feb-2024"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form

    $$M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form

    $$y'' = f(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form

    $$y'' = f(t,y,p), \quad y(t_0) = y_0(p)$$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form

    $$F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0''$$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form

    $$F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p)$$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form

    $$F(u) = 0 \quad \text{or} \quad G(u) = u$$</p>

    </li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Installation</h2><a
    id="user-content-installation" class="anchor" aria-label="Permalink: Installation"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <div class="markdown-heading"><h2 class="heading-element">Support</h2><a id="user-content-support"
    class="anchor" aria-label="Permalink: Support" href="#support"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Contributing</h2><a
    id="user-content-contributing" class="anchor" aria-label="Permalink: Contributing"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <div class="markdown-heading"><h2 class="heading-element">Citing</h2><a id="user-content-citing"
    class="anchor" aria-label="Permalink: Citing" href="#citing"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <div class="markdown-heading"><h2 class="heading-element">Authors</h2><a id="user-content-authors"
    class="anchor" aria-label="Permalink: Authors" href="#authors"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Yu Pan, Slaven Peles, Cosmin Petra, Steven B. Roberts, H. Hunter Schwartz,

    Jean M. Sexton, Dan Shumaker, Steve G. Smith, Shahbaj Sohal, Allan G. Taylor,

    Hilari C. Tiedeman, Chris White, Ting Yan, and Ulrike M. Yang.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 469
  subscribers_count: 35
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1716558052.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 23.09/0.21.0/spack.yaml
  - 22.08/0.18.1/spack.yaml
  - 22.08/0.19.0/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Spack configuration
    files for LUMI</h1><a id="user-content-spack-configuration-files-for-lumi" class="anchor"
    aria-label="Permalink: Spack configuration files for LUMI" href="#spack-configuration-files-for-lumi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1675956191.0
MeteoSwiss/meteodata-lab:
  data_format: 2
  description: Model data processing framework
  filenames:
  - spack-env/spack.yaml
  full_name: MeteoSwiss/meteodata-lab
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">meteodata-lab</h1><a
    id="user-content-meteodata-lab" class="anchor" aria-label="Permalink: meteodata-lab"
    href="#meteodata-lab"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>A model data processing framework based on xarray.</p>

    <p><strong>DISCLAIMER</strong></p>

    <blockquote>

    <p>[!WARNING]

    This project is BETA and will be experimental for the forseable future. Interfaces
    and functionality are likely to change, and the project itself may be scrapped.
    Do not use this software in any project/software that is operational.</p>

    </blockquote>

    <div class="markdown-heading"><h2 class="heading-element">Install</h2><a id="user-content-install"
    class="anchor" aria-label="Permalink: Install" href="#install"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Once you created or cloned this repository, make sure the installation is running
    properly. Install the package dependencies with the provided script <code>setup_env.sh</code>.

    Check available options with</p>

    <div class="highlight highlight-source-shell"><pre>tools/setup_env.sh -h</pre></div>

    <p>We distinguish pinned installations based on exported (reproducible) environments
    and free installations where the installation

    is based on top-level dependencies listed in <code>requirements/requirements.yaml</code>.
    If you start developing, you might want to do an unpinned installation and export
    the environment:</p>

    <div class="highlight highlight-source-shell"><pre>tools/setup_env.sh -u -e -n
    <span class="pl-k">&lt;</span>package_env_name<span class="pl-k">&gt;</span></pre></div>

    <p><em>Hint</em>: If you are the package administrator, it is a good idea to understand
    what this script does, you can do everything manually with <code>conda</code>
    instructions.</p>

    <p><em>Hint</em>: Use the flag <code>-m</code> to speed up the installation using
    mamba. Of course you will have to install mamba first we recommend to install
    mamba into your base

    environment <code>conda install -c conda-forge mamba</code>. If you install mamba
    in another (maybe dedicated) environment, environments installed with mamba will
    be located

    in <code>&lt;miniconda_root_dir&gt;/envs/mamba/envs</code>, which is not very
    practical.</p>

    <p>The package itself is installed with <code>pip</code>. For development, install
    in editable mode:</p>

    <div class="highlight highlight-source-shell"><pre>conda activate <span class="pl-k">&lt;</span>package_env_name<span
    class="pl-k">&gt;</span>

    pip install --editable <span class="pl-c1">.</span></pre></div>

    <p><em>Warning:</em> Make sure you use the right pip, i.e. the one from the installed
    conda environment (<code>which pip</code> should point to something like <code>path/to/miniconda/envs/&lt;package_env_name&gt;/bin/pip</code>).</p>

    <p>Once your package is installed, run the tests by typing:</p>

    <pre><code>conda activate &lt;package_env_name&gt;

    pytest

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Credits</h2><a id="user-content-credits"
    class="anchor" aria-label="Permalink: Credits" href="#credits"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This package was created with <a href="https://github.com/copier-org/copier"><code>copier</code></a>
    and the <a href="https://meteoswiss-apn.github.io/mch-python-blueprint/" rel="nofollow"><code>MeteoSwiss-APN/mch-python-blueprint</code></a>
    project template.</p>

    '
  stargazers_count: 3
  subscribers_count: 4
  topics:
  - numericalweatherpredictions
  updated_at: 1717051771.0
MeteoSwiss/nwp-fdb-polytope-demo:
  data_format: 2
  description: Example notebooks for Polytope and FDB data access and processing on
    CSCS or remotely.
  filenames:
  - spack-env/spack.yaml
  full_name: MeteoSwiss/nwp-fdb-polytope-demo
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">FDB and Polytope\
    \ model data access and processing using meteodata-lab, example notebooks</h1><a\
    \ id=\"user-content-fdb-and-polytope-model-data-access-and-processing-using-meteodata-lab-example-notebooks\"\
    \ class=\"anchor\" aria-label=\"Permalink: FDB and Polytope model data access\
    \ and processing using meteodata-lab, example notebooks\" href=\"#fdb-and-polytope-model-data-access-and-processing-using-meteodata-lab-example-notebooks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>This repository contains all that is required to install and run various Jupyter\
    \ notebooks which demonstrate the simplified access to model data via <a href=\"\
    https://github.com/ecmwf/fdb\">FDB</a>, the <a href=\"https://github.com/ecmwf/polytope-server\"\
    >Polytope server</a> and the <a href=\"https://github.com/ecmwf/polytope\">Polytope\
    \ library</a> (ECMWF), and then the subsequent post-processing via a data processing\
    \ framework <a href=\"https://github.com/MeteoSwiss/meteodata-lab\">meteodata-lab</a>\
    \ (in development). The following use cases are covered by the notebooks:</p>\n\
    <ul>\n<li>Retrieving a specified selection of GRIB fields into an xarray object\
    \ and processing with meteorological operators.</li>\n<li>Remotely retrieving\
    \ a very reduced subset of GRIB fields, eg just a few grid points, via the Polytope\
    \ algorithm, to create a timeseries over an extended period.</li>\n<li>Writing\
    \ GRIB fields data back to FDB having processed the model data at CSCS.</li>\n\
    </ul>\n<p>The notebooks for the demo can be found in the directory <a href=\"\
    notebooks\">notebooks</a>.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Jupyter Notebooks</h2><a id=\"user-content-jupyter-notebooks\" class=\"anchor\"\
    \ aria-label=\"Permalink: Jupyter Notebooks\" href=\"#jupyter-notebooks\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Notebooks\
    \ to run from CSCS (Balfrin/Eiger):</p>\n<ul>\n<li>1_Data_Retrieval_from_FDB_Preprocessing</li>\n\
    <li>2_Precompute_and_Store_Echotop_to_FDB</li>\n</ul>\n<p>Notebooks to run from\
    \ the LabVM:</p>\n<ul>\n<li>3_Retrieve_Echotop_and_Regrid</li>\n<li>4_Location_and_TimeSeries_Access</li>\n\
    </ul>\n<blockquote>\n<p>[!WARNING]\nNote that the FDB remote server is currently\
    \ deployed with minimal resources and is thus not expected to handle heavy load\
    \ at this time.\nIf you run the notebooks and experience timeouts or other issues,\
    \ please contact either <a href=\"mailto:christian.kanesan@meteoswiss.ch\">christian.kanesan@meteoswiss.ch</a>\
    \ or <a href=\"mailto:victoria.cherkas@meteoswiss.ch\">victoria.cherkas@meteoswiss.ch</a>\
    \ who will try to help.</p>\n</blockquote>\n<p><strong>Forecasts available in\
    \ FDB</strong></p>\n<blockquote>\n<p>[!NOTE]\nThe remote FDB server references\
    \ an instance of FDB that normally contains <strong>only the two latest forecasts</strong>.\
    \ This means the FDB requests in the notebooks should usually use date = today\
    \ and time as  either 0000, 0300, 0600, 0900 etc. given the forecasts are every\
    \ 3 hour). The data is usually available in the FDB a couple of hours after the\
    \ forecast start time. If the FDB returns no data, contact <a href=\"mailto:victoria.cherkas@meteoswiss.ch\"\
    >victoria.cherkas@meteoswiss.ch</a> to enquire about which data is currently archived\
    \ in the FDB.</p>\n</blockquote>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">Instructions</h1><a id=\"user-content-instructions\" class=\"\
    anchor\" aria-label=\"Permalink: Instructions\" href=\"#instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>To use the Jupyter\
    \ notebooks you have the following two options regarding the runtime dependencies\
    \ and the jupyter server:</p>\n<ol>\n<li>Jupyter server on the lab-vm or at CSCS\
    \ (Balfrin/Eiger) and runtime dependencies in a container</li>\n<li>Both the jupyter\
    \ server and the runtime dependencies in a container (LabVM only)</li>\n</ol>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Jupyter server on\
    \ the Lab-VM or at CSCS (Balfrin/Eiger)</h2><a id=\"user-content-jupyter-server-on-the-lab-vm-or-at-cscs-balfrineiger\"\
    \ class=\"anchor\" aria-label=\"Permalink: Jupyter server on the Lab-VM or at\
    \ CSCS (Balfrin/Eiger)\" href=\"#jupyter-server-on-the-lab-vm-or-at-cscs-balfrineiger\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h4 class=\"heading-element\">LabVM</h4><a id=\"\
    user-content-labvm\" class=\"anchor\" aria-label=\"Permalink: LabVM\" href=\"\
    #labvm\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>With this approach you define a kernel definiton in your jupyter server with\
    \ a reference to the container.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sudo apt install pipx\n<span class=\"pl-k\">export</span> REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\n\
    pipx install jupyterlab\n\n./host/install_kernel.sh</pre></div>\n<p>Connect to\
    \ the jupyter server <br></p>\n<ul>\n<li>\n<strong>from VSCode:</strong> <br>\n\
    Open the notebook and select the <code>polytope-demo</code> kernel in \"Select\
    \ Kernel\" -&gt; \"Select another Kernel...\" -&gt; \"Jupyter Kernel...\" <br>\n\
    </li>\n<li>\n<strong>from your browser:</strong>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pipx run jupyter lab --port 8080</pre></div>\nOpen the URL given in the\
    \ code and select the <code>polytope-demo</code> kernel.</li>\n</ul>\n<div class=\"\
    markdown-heading\"><h4 class=\"heading-element\">CSCS (Balfrin/Eiger)</h4><a id=\"\
    user-content-cscs-balfrineiger\" class=\"anchor\" aria-label=\"Permalink: CSCS\
    \ (Balfrin/Eiger)\" href=\"#cscs-balfrineiger\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Setup spack for the machine and build\
    \ FDB.</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack env activate\
    \ -p spack-env\nspack install --no-checksum</pre></div>\n<p>Setup the python environment.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>conda env create -n demo\
    \ -f environment.yaml\nconda activate demo\ngit clone -b mars-levtype-echotop-2\
    \ https://github.com/cfkanesan/eccodes-cosmo-resources.git <span class=\"pl-smi\"\
    >$CONDA_PREFIX</span>/share/eccodes-cosmo-resources\npip install jupyterlab\n\
    python -m jupyter lab</pre></div>\n<p>Use VSCode to forward the port that is binded\
    \ to the jupyter lab server to your local machine and open the link in the jupyter\
    \ lab server logs.\nCtrl-C once to show the link again.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Jupyter server in a container (LabVM only)</h2><a\
    \ id=\"user-content-jupyter-server-in-a-container-labvm-only\" class=\"anchor\"\
    \ aria-label=\"Permalink: Jupyter server in a container (LabVM only)\" href=\"\
    #jupyter-server-in-a-container-labvm-only\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>With this approach you have both\
    \ the Jupyter server and the runtime dependencies in a container.</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>podman run \\\n  -e https_proxy=<span\
    \ class=\"pl-smi\">$https_proxy</span> \\\n  -e REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\
    \ \\\n  -e SSL_CERT_DIR=/etc/ssl/certs/ \\\n  --network=host \\\n  --rm \\\n \
    \ dockerhub.apps.cp.meteoswiss.ch/numericalweatherpredictions/polytope/demo/notebook:<span\
    \ class=\"pl-k\">&lt;</span>TAG<span class=\"pl-k\">&gt;</span></pre></div>\n\
    <p><code>&lt;TAG&gt;</code>:The current container tag can be retrieved from: <a\
    \ href=\"https://nexus.meteoswiss.ch/nexus/service/rest/repository/browse/docker-all/v2/numericalweatherpredictions/polytope/demo/notebook/tags/\"\
    \ rel=\"nofollow\">https://nexus.meteoswiss.ch/nexus/service/rest/repository/browse/docker-all/v2/numericalweatherpredictions/polytope/demo/notebook/tags/</a></p>\n\
    <p>Afterwards connect to the external Jupyter server from the notebook with the\
    \ url from container log. Click \"Select Kernel\" -&gt; \"Existing Jupyter Server...\"\
    \ and then paste the url form the container log.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer\" href=\"./host/vscode_remote_jupyter-server.png\"\
    ><img src=\"./host/vscode_remote_jupyter-server.png\" alt=\"Exisiting Jupyter\
    \ Server...\" style=\"max-width: 100%;\"></a></p>\n<blockquote>\n<p>[!NOTE]\n\
    With VSCode, you need to have the <code>Jupyter</code> VSCode extension (<a href=\"\
    https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter\" rel=\"\
    nofollow\">https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter</a>)\
    \ insalled.</p>\n</blockquote>\n"
  stargazers_count: 0
  subscribers_count: 5
  topics:
  - numericalweatherpredictions
  updated_at: 1716037549.0
NCAR/ncar-spack:
  data_format: 2
  description: NCAR supercomputer user software installed and maintained using Spack
  filenames:
  - clusters/common/spack.yaml
  - clusters/casper/spack.yaml
  - clusters/test/spack.yaml
  full_name: NCAR/ncar-spack
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">ncar-spack</h1><a\
    \ id=\"user-content-ncar-spack\" class=\"anchor\" aria-label=\"Permalink: ncar-spack\"\
    \ href=\"#ncar-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >What is ncar-spack?</h2><a id=\"user-content-what-is-ncar-spack\" class=\"anchor\"\
    \ aria-label=\"Permalink: What is ncar-spack?\" href=\"#what-is-ncar-spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>This\
    \ repository contains cluster configurations for NCAR HPC software stacks, a deployment\
    \ script, and helper scripts that get installed into a cluster deployment to facilitate\
    \ reproducible and consistent package management across the consulting team.</p>\n\
    <p>It is also important to note what this repository is <strong>not</strong>.\
    \ It is not a fork of Spack itself - though a cluster <em>should</em> use the\
    \ CSG Spack fork. It is also not for tracking a production cluster deployment.\
    \ Rather, this repository contains the recipe and the tools for starting a deployment,\
    \ which is then tracked in its own repo!</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Getting started</h2><a id=\"user-content-getting-started\"\
    \ class=\"anchor\" aria-label=\"Permalink: Getting started\" href=\"#getting-started\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The following instructions describe cloning this repository and starting a\
    \ new cluster deployment. If you want to know how to install a package into an\
    \ existing deployment, create a new cluster recipe, or update a cluster recipe\
    \ in this repository from changes made in production, see the appropriate section\
    \ below.</p>\n<p>To get started, simply clone this repository either as yourself\
    \ or as <em>csgteam</em>. If you plan to produce a public production cluster deployment,\
    \ you will need to run as <em>csgteam</em>.</p>\n<pre><code>git clone git@github.com:NCAR/ncar-spack.git\n\
    </code></pre>\n<p><em>The clone command above assumes SSH-key usage!</em></p>\n\
    <div class=\"markdown-heading\"><h4 class=\"heading-element\">Vim users: YAML\
    \ configuration</h4><a id=\"user-content-vim-users-yaml-configuration\" class=\"\
    anchor\" aria-label=\"Permalink: Vim users: YAML configuration\" href=\"#vim-users-yaml-configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Since Spack will output YAML lines with two-space indentation, the following\
    \ Vim settings are recommended:</p>\n<pre><code>$ cat ~/.vim/after/ftplugin/yaml.vim\n\
    setlocal shiftwidth=2\nsetlocal tabstop=2\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Deploying a cluster from scratch</h2><a id=\"user-content-deploying-a-cluster-from-scratch\"\
    \ class=\"anchor\" aria-label=\"Permalink: Deploying a cluster from scratch\"\
    \ href=\"#deploying-a-cluster-from-scratch\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Cluster definitions are contained\
    \ in the <code>clusters</code> subdirectory and typically contain the following\
    \ components:</p>\n<pre><code>clusters/\n\u251C\u2500\u2500 casper\n\u2502   \u251C\
    \u2500\u2500 constraints.cfg - external packages, and packages required to use\
    \ the system GCC\n\u2502   \u251C\u2500\u2500 main.cfg        - top-level path,\
    \ name, and version settings for the cluster deployment\n\u2502   \u251C\u2500\
    \u2500 packages.cfg    - an inventory of packages to be built upon deployment\
    \ (and beyond)\n\u2502   \u251C\u2500\u2500 postprocess     - a bash script that\
    \ runs last and does cluster prep that Spack cannot\n\u2502   \u251C\u2500\u2500\
    \ repos.cfg       - any custom package repositories to include (i.e. ncar.hpcd\
    \ recipes)\n\u2502   \u2514\u2500\u2500 spack.yaml      - the Spack environment\
    \ template that will become the cluster stack\n...\n</code></pre>\n<p>Remember,\
    \ these are simply templates! To generate a cluster deployment from one of these\
    \ recipes, simply run the <code>deploy</code> script in the top-level directory.\
    \ For example:</p>\n<pre><code>./deploy [--production] [--no-pkgs] casper\n</code></pre>\n\
    <p>This command will clone csg-spack-fork and check out the branch specified in\
    \ the cluster's <strong>main.cfg</strong> (or use the <code>ncar-mods</code> branch\
    \ if left blank), copy the cluster recipe template and replace placeholders with\
    \ proper paths and settings, set up a build cache mirror if one does not already\
    \ exist, and (<em>if <code>--no-pkgs</code> is not set</em>) will build the packages\
    \ specified in <strong>packages.cfg</strong>.</p>\n<p>The <code>--production</code>\
    \ flag can only be specified when running as <em>csgteam</em>. Without this flag,\
    \ a <em>test</em> deployment will be created at the location configured in the\
    \ cluster definition (probably your scratch directory). Doing a test deployment\
    \ can be a good way to learn how this all works without breaking things, and is\
    \ recommended! \U0001F44D</p>\n<blockquote>\n<p><em>Keep in mind that changes\
    \ made after you deploy a cluster will cause divergence from the recipe contained\
    \ in this repo. This is expected, but if you wish to propagate those changes to\
    \ a new version of the deployment, you should merge them into the recipe and push\
    \ the changes to ncar-spack (see below)!</em></p>\n</blockquote>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Installing a new package</h2><a\
    \ id=\"user-content-installing-a-new-package\" class=\"anchor\" aria-label=\"\
    Permalink: Installing a new package\" href=\"#installing-a-new-package\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>As\
    \ new versions of popular libraries (e.g., <em>netcdf</em>) are released, and\
    \ users request new packages, consultants will need to augment cluster deployments.\
    \ All of the tools to do this robustly are provided in a cluster deployment. Here,\
    \ we will run through an example for a production install, and so these steps\
    \ assume working as <em>csgteam</em>.</p>\n<p>First, a word about how the deployment\
    \ is structured. There should exist one Spack clone, and two Spack environments:\
    \ a <em>build</em> environment and a <em>public</em> environment. The build environment\
    \ is what you will interact with. Packages are build from source in the <em>build</em>\
    \ environment, and any changes should not be visible to users. Only when you are\
    \ happy with your changes in the <em>build</em> environment should you <code>publish</code>\
    \ them into the <em>public</em> environment.</p>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Environment prep: <code>clean_bash</code> and <code>spacktivate</code>\n\
    </h3><a id=\"user-content-environment-prep-clean_bash-and-spacktivate\" class=\"\
    anchor\" aria-label=\"Permalink: Environment prep: clean_bash and spacktivate\"\
    \ href=\"#environment-prep-clean_bash-and-spacktivate\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Before doing anything with\
    \ a cluster deployment, you should first launch a clean bash shell that has been\
    \ scrubbed of personal settings and modules. Since this step is fundamental to\
    \ using <em>ncar-spack</em>, a script called <code>clean_bash</code> is provided\
    \ in the csg-spack-fork to do this for you. The script will also initialize Spack\
    \ to run in your environment, and change your directory to the <em>build</em>\
    \ environment.</p>\n<p>The script can be found in the <code>bin</code> directory\
    \ of the clone Spack, and it is also typically configured to run as a shell function\
    \ when you are <em>csgteam</em> (via <strong>.bashrc</strong> settings).</p>\n\
    <p>Once you are in a sanitized bash shell, you can \"activate\" the <em>build</em>\
    \ environment. This step is important, because otherwise Spack will make decisions\
    \ based on the configuration in the Spack clone settings directory, rather than\
    \ our environment settings contained in <strong>spack.yaml</strong>.</p>\n<p><strong>For\
    \ example:</strong></p>\n<pre><code>clean_bash\nspacktivate -p .\n</code></pre>\n\
    <p>Since <code>clean_bash</code> places you in the <em>build</em> directory, you\
    \ can use <code>.</code> to indicate the environment path. The <code>-p</code>\
    \ option provides a nice prompt decorator indicating the build environment is\
    \ active.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\">Updating\
    \ the <em>builtin</em> repo to get new package versions</h3><a id=\"user-content-updating-the-builtin-repo-to-get-new-package-versions\"\
    \ class=\"anchor\" aria-label=\"Permalink: Updating the builtin repo to get new\
    \ package versions\" href=\"#updating-the-builtin-repo-to-get-new-package-versions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Unfortunately, some terminology is overloaded here. In addition to Spack itself\
    \ being a Git repository, Spack stores its package recipes in a package repository.\
    \ The default repo is called <em>builtin</em>, and is contained with Spack itself\
    \ in the Spack Git repo. The problem is that checking out a newer version of Spack\
    \ or its <em>builtin</em> repo will update many things - including the package\
    \ API and package recipes. This can cause packages to concretize differently and\
    \ reduce reproducibility, and in some cases can even break the whole deployment.</p>\n\
    <p>\U0001F6A8 <strong>Updating the entire Spack clone should be avoided - consider\
    \ this a scenario for creating a new deployment!</strong> \U0001F6A8</p>\n<p>So\
    \ let's say a user wants the latest and greatest version of a package, and the\
    \ version you see provided by our Spack clone is older (use <code>spack info &lt;package&gt;</code>\
    \ to check versions). In this scenario, aim for the least invasive changes possible.\
    \ Typically, this means checking out only the desired package from the main Spack\
    \ upstream. The <code>deploy</code> script will configure the cloned Spack to\
    \ have an upstream remote to the main Spack repo.</p>\n<div class=\"markdown-heading\"\
    ><h4 class=\"heading-element\">Example: Installing the latest ESMF</h4><a id=\"\
    user-content-example-installing-the-latest-esmf\" class=\"anchor\" aria-label=\"\
    Permalink: Example: Installing the latest ESMF\" href=\"#example-installing-the-latest-esmf\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>A user wants ESMF 8.6.0, but the deployed Spack clone only provides up to 8.5.2.\
    \ Here is how you would obtain a newer version:</p>\n<pre><code>cd $SPACK_ROOT/var/spack/repos/builtin/packages\n\
    git fetch upstream develop\ngit checkout upstream/develop -- esmf\ncd $SPACK_ENV\n\
    </code></pre>\n<p>These commands will only check out the updated ESMF package\
    \ recipe (including the <strong>package.py</strong> and any new/modified patches).\
    \ Note that sometimes you will need to update dependencies too if your package\
    \ has changes that are incompatible with the current dependency recipe. But aim\
    \ for the least number of changes possible to get a successful build. And if the\
    \ version the user wants is provided already (or they don't care which version),\
    \ then great, skip this section!</p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Configuring an optimal package build</h3><a id=\"user-content-configuring-an-optimal-package-build\"\
    \ class=\"anchor\" aria-label=\"Permalink: Configuring an optimal package build\"\
    \ href=\"#configuring-an-optimal-package-build\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Before installing any package, you\
    \ should always run these two commands:</p>\n<ol>\n<li>\n<code>spack info &lt;spec&gt;</code>\
    \ - tells you which versions are availabe and which variants can be used to modify\
    \ how the package will be built</li>\n<li>\n<code>spack spec -I -l &lt;spec&gt;</code>\
    \ - shows you exactly how the package will be built as currently configured, including\
    \ the dependencies Spack will use; the <code>-I</code> flag will decorate the\
    \ output with an indicator telling you whether the package is currently installed\
    \ <code>[+]</code>, an external <code>[e]</code>, or needs to be installed <code>[-]</code>.</li>\n\
    </ol>\n<p>First, think about which variants you will need to configure to meet\
    \ the user's request. Also, consider whether the package should use the system\
    \ compiler or be built with our <em>module-loadable</em> compilers. It typically\
    \ makes sense to use the system compiler for lower level packages that get used\
    \ as dependencies often like <em>python</em> and <em>qt</em>. On the other hand,\
    \ if a package depends on MPI you will almost certainly want to built it using\
    \ the module compilers.</p>\n<p>The package build can be configured either in\
    \ the <em>spec</em> or specifying preferences and requirements in the <strong>spack.yaml</strong>.\
    \ I prefer the latter, when possible, as these settings will often influence how\
    \ the package gets used as dependencies, and will also help narrow the behavior\
    \ if a user wants to use our deployment as a Spack <em>upstream</em>.</p>\n<p>If\
    \ you wish to constrain any uninstalled dependencies of your package to use the\
    \ system compiler, add them to the <strong>constraints.cfg</strong> file in the\
    \ <em>build</em> environment and then run <code>bin/add_constraints</code>.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Building the package</h3><a\
    \ id=\"user-content-building-the-package\" class=\"anchor\" aria-label=\"Permalink:\
    \ Building the package\" href=\"#building-the-package\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Once you are happy with\
    \ the build configuration and have implemented any desired constraints/preferences/requirements,\
    \ you can install the package into the build environment. You <em>could</em> do\
    \ this with the following Spack command:</p>\n<pre><code>spack install --add &lt;spec&gt;\n\
    </code></pre>\n<p>However, this method will not span multiple compilers/MPIs and\
    \ also does not log who performed the install. Instead, a helper script is provided\
    \ to make complex installs easier (and put logs in an easy to find location).</p>\n\
    <p>To install the package, add the <code>&lt;spec&gt;</code> into the <strong>packages.cfg</strong>\
    \ file in an appropriate subsection - packages can be one of the following:</p>\n\
    <ul>\n<li>\n<strong>singleton</strong> - only a single configuration of this package\
    \ is installed</li>\n<li>\n<strong>cdep</strong> - the package will be installed\
    \ for every non-system compiler defined in <strong>packages.cfg</strong>\n</li>\n\
    <li>\n<strong>mdep</strong> - the package will be installed for the matrix of\
    \ compilers and MPIs defined in this file</li>\n</ul>\n<p>Eventual user access\
    \ to the package can be configured via the <code>access</code> tag. By default,\
    \ a new package will produce an environment module that can be loaded. However,\
    \ you can configure the package to appear in the <em>view</em> instead using <code>access=view</code>.\
    \ Any package in the <em>view</em> will be in the user environment by default\
    \ when the <strong>ncarenv</strong> module is loaded, as if it were a system package\
    \ installed using zypper/yum/apt-get.</p>\n<p>There are many additional specifications\
    \ that can be set on sections and individual packages in this configuration file.\
    \ See existing listings for inspiration (<em>full documentation TBD</em>).</p>\n\
    <blockquote>\n<p><em>Note that compilers and MPIs installed into the <strong>spack.yaml</strong>\
    \ but not listed in <strong>packages.cfg</strong> will NOT be used for cdep and\
    \ mdep  sections. This is another useful feature of using <strong>packages.cfg</strong>\
    \ - think of it a record of the \"actively updated\" compiler and MPI stacks,\
    \ while <strong>spack.yaml</strong> contains both active and inactive/deprecated\
    \ versions.</em></p>\n</blockquote>\n<p>Once you have added the package <code>&lt;spec&gt;</code>\
    \ to <strong>packages.cfg</strong>, you can begin the source builds by running\
    \ <code>bin/install_packages</code>. If all goes well, this should install the\
    \ package(s) and any necessary dependencies into the <em>build</em> environment.\
    \ If something goes wrong, ask colleagues in <strong>#spack</strong> on the <strong>hpc-ucar</strong>\
    \ Slack. \U0001F4AC</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Testing the package</h3><a id=\"user-content-testing-the-package\" class=\"anchor\"\
    \ aria-label=\"Permalink: Testing the package\" href=\"#testing-the-package\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Once you have successfully built the package, you should run the following\
    \ additional steps to prepare the build environment for testing:</p>\n<pre><code>spack\
    \ module lmod refresh -y\nbin/postprocess\n</code></pre>\n<p>Even if your package\
    \ does not produce a new environment module, it is good to run these commands\
    \ to get a sense of how the production environment will look to users. Once this\
    \ is ready, you can use a helper script to switch your environment from the default\
    \ (production <em>public</em>) to the build stack:</p>\n<pre><code>bin/use_modules[.csh]\n\
    </code></pre>\n<p>You should see your package binaries/libraries/headers either\
    \ in the default environment (if set to exist in the <em>view</em>) or in the\
    \ module listing from <code>module avail</code>. At this point, do whatever testing\
    \ you need to do to ensure the package seems robust. <strong>You can also ask\
    \ the user to run <code>use_modules</code> and they can provide you feedback,\
    \ before you ever make the package available to other users!</strong></p>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Publishing the package</h3><a\
    \ id=\"user-content-publishing-the-package\" class=\"anchor\" aria-label=\"Permalink:\
    \ Publishing the package\" href=\"#publishing-the-package\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Finally, assuming\
    \ all goes well to this point and testing was a success, you can publish the changes\
    \ from the <em>build</em> environment to the <em>public</em> environment. A helper\
    \ script should handle all of this for you.</p>\n<p>\U0001F6A8 <strong>You should\
    \ rarely, if ever, need to manually make changes to the public environment!</strong>\
    \ \U0001F6A8</p>\n<p>All published changes get committed and pushed to a GitHub\
    \ repo (if this is a production deployment) called <code>spack-&lt;cluster&gt;</code>\
    \ . This repo is publicly visible and can be used by the community to report bugs\
    \ and request new packages. Thus, the publish script expects one argument - a\
    \ commit message.</p>\n<pre><code>bin/publish \"Installed latest emacs for benkirk\
    \ in #4\"\n</code></pre>\n<p>The <code>publish</code> script will describe all\
    \ of the changes it makes, including package installs, <strong>spack.yaml</strong>\
    \ changes,  refreshing the module tree, and postprocessing.</p>\n<div class=\"\
    markdown-heading\"><h4 class=\"heading-element\">What if something went wrong?</h4><a\
    \ id=\"user-content-what-if-something-went-wrong\" class=\"anchor\" aria-label=\"\
    Permalink: What if something went wrong?\" href=\"#what-if-something-went-wrong\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Spack is finnicky and it is rather easy to get in a pickle, but <em>most</em>\
    \ situations are recoverable if addressed early. If you are unsure about what\
    \ to do, please ask for help in our <strong>hpc-ucar #spack</strong> Slack channel!</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Updating a cluster\
    \ definition with production changes</h2><a id=\"user-content-updating-a-cluster-definition-with-production-changes\"\
    \ class=\"anchor\" aria-label=\"Permalink: Updating a cluster definition with\
    \ production changes\" href=\"#updating-a-cluster-definition-with-production-changes\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>TODO: document when and how to do this</p>\n"
  stargazers_count: 2
  subscribers_count: 9
  topics: []
  updated_at: 1715613715.0
NCAR/spack-casper:
  data_format: 2
  description: Spack production user software stack on the Casper system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-casper
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">NCAR Spack Deployment</h1><a
    id="user-content-ncar-spack-deployment" class="anchor" aria-label="Permalink:
    NCAR Spack Deployment" href="#ncar-spack-deployment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>casper</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Sun Oct 29 16:46:01 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>f18d293b1ca60227bc1b9147ac97b664d212f7ef</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.10</td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/casper/23.10</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/casper/23.10/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 0
  subscribers_count: 9
  topics: []
  updated_at: 1717089150.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">NCAR Spack Deployment</h1><a
    id="user-content-ncar-spack-deployment" class="anchor" aria-label="Permalink:
    NCAR Spack Deployment" href="#ncar-spack-deployment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Thu Mar 30 18:51:24 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fd3fc5c8cd67abe692e5e38bae52f29fb32700a3</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.04</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/23.04</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/23.04/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 4
  subscribers_count: 13
  topics: []
  updated_at: 1705084500.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-v0.22/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-23.08/gcc/spack.yaml
  - spack-configs/perlmutter-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/data/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/math-libs/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/math-libs/spack.yaml
  - spack-configs/perlmutter-e4s-23.08/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/tools/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Spack Infrastructure</h1><a\
    \ id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-label=\"Permalink:\
    \ Spack Infrastructure\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>The Spack Infrastructure\
    \ Project makes use of <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"\
    nofollow\">spack package manager</a> to install spack software stack on NERSC\
    \ systems. This project contains spack configuration (<code>spack.yaml</code>)\
    \ required to build the spack stacks. The spack stack is based on <a href=\"https://e4s.io/\"\
    \ rel=\"nofollow\">Extreme-Scale Scientific Software Stack</a> (E4S) where we\
    \ install spack packages provided by E4S and use the recommended spack branch.\
    \ We leverage <a href=\"https://docs.gitlab.com/ee/ci/\" rel=\"nofollow\">Gitlab\
    \ CI</a> to automate deployment to ensure reproducible and automated builds. For\
    \ more details about this project you can see the documentation at <a href=\"\
    https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Software Deployment\
    \ Overview</h2><a id=\"user-content-software-deployment-overview\" class=\"anchor\"\
    \ aria-label=\"Permalink: Software Deployment Overview\" href=\"#software-deployment-overview\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The software deployment consist of the following steps</p>\n<ol>\n<li>Acquire\
    \ Spack Configuration from E4S project <a href=\"https://github.com/E4S-Project/e4s\"\
    >https://github.com/E4S-Project/e4s</a>\n</li>\n<li>Create one or more spack configuration\
    \ files (spack.yaml) with list of E4S packages and integrate spack configuration\
    \ for NERSC system</li>\n<li>Create a Gitlab Job to trigger the pipeline for TDS\
    \ and Deployment system</li>\n<li>Create a Modulefile as entry point to stack</li>\n\
    <li>Write User Documentation</li>\n<li>Share spack configuration with open-source\
    \ community</li>\n<li>Send announcement to all NERSC users</li>\n</ol>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Step 1: Acquire Spack Configuration</h3><a\
    \ id=\"user-content-step-1-acquire-spack-configuration\" class=\"anchor\" aria-label=\"\
    Permalink: Step 1: Acquire Spack Configuration\" href=\"#step-1-acquire-spack-configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>At NERSC, we plan our software deployment with E4S releases which is typically\
    \ every 3 months however we perform deployment every 6 months. Once E4S has released\
    \ the spack configuration we acquire the spack configuration which is typically\
    \ found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >https://github.com/E4S-Project/e4s/tree/master/environments</a>. We also acquire\
    \ the spack <a href=\"https://github.com/spack/spack/branches\">branch</a> used\
    \ by E4S team as our baseline, this would be documented in the release notes.\
    \ The name of branch map to the E4S version so version 23.05 will have a branch\
    \ <a href=\"https://github.com/spack/spack/tree/e4s-23.05\">e4s-23.05</a>.</p>\n\
    <p>Next, we copy the packages into our project and create the spack configuration</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 2: Create Spack\
    \ Configuration</h3><a id=\"user-content-step-2-create-spack-configuration\" class=\"\
    anchor\" aria-label=\"Permalink: Step 2: Create Spack Configuration\" href=\"\
    #step-2-create-spack-configuration\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>In this step we create the spack configuration.\
    \ First we create a sub-directory in <em>spack-configs</em> with the naming convention\
    \ to distinguish E4S version. This typically includes the\nname of the system\
    \ such as <code>cori</code> or <code>perlmutter</code> followed by name of e4s\
    \ version such as <code>e4s-23.05</code>.</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">tree -L 1 spack-configs</span>\n<span class=\"pl-c1\"\
    >spack-configs</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-20.10</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-21.02</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 cori-e4s-21.05</span>\n<span class=\"pl-c1\">\u251C\
    \u2500\u2500 cori-e4s-22.02</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-21.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.05</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\"\
    >\u251C\u2500\u2500 perlmutter-e4s-23.05</span>\n<span class=\"pl-c1\">\u251C\u2500\
    \u2500 perlmutter-spack-develop</span>\n<span class=\"pl-c1\">\u2514\u2500\u2500\
    \ perlmutter-user-spack</span>\n\n<span class=\"pl-c1\">10 directories, 0 files</span></pre></div>\n\
    <p>Inside one of the stacks, you will see several sub-directories that are used\
    \ for defining a sub-stack. These sub-stacks correspond to <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">spack environments</a>. The <code>prod</code> directory is\
    \ used for production deployment to install from the buildcache.</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">tree -L\
    \ 3 spack-configs/perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\">spack-configs/perlmutter-e4s-22.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cce</span>\n<span class=\"pl-c1\">\u2502\
    \_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500\
    \ cuda</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 definitions.yaml</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"\
    pl-c1\">\u2514\u2500\u2500 prod</span>\n<span class=\"pl-c1\">    \u251C\u2500\
    \u2500 cce</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">    \u251C\u2500\u2500 cuda</span>\n<span class=\"pl-c1\"\
    >    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\"> \
    \   \u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">    \u2514\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">        \u2514\u2500\u2500 spack.yaml</span>\n\n<span class=\"\
    pl-c1\">9 directories, 9 files</span></pre></div>\n<p>We create a special file\
    \ named <code>definitions.yaml</code> that is used for declaring definitions that\
    \ is referenced in <code>spack.yaml</code>. This file is appended to all spack\
    \ configuration. We do this\nto ensure all specs are defined in one place.</p>\n\
    <p>During this step, we will create the spack configuration and specify our preferred\
    \ compilers and package preference. We install software in buildcache so it can\
    \ be relocated to production path. In order to accomplish this task, we use <a\
    \ href=\"https://spack.readthedocs.io/en/latest/pipelines.html\" rel=\"nofollow\"\
    >spack pipelines</a> that uses <code>spack ci generate</code> and <code>spack\
    \ ci rebuild</code> to perform parallel pipeline execution. During this step,\
    \ we determine which packages to install from E4S and add our own packages to\
    \ comply with our site preference.</p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Step 3: Create Gitlab Job for Automation</h3><a id=\"user-content-step-3-create-gitlab-job-for-automation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 3: Create Gitlab Job for Automation\"\
    \ href=\"#step-3-create-gitlab-job-for-automation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Once spack configuration\
    \ is written, we create a gitlab job to trigger the pipeline. This can be done\
    \ by specifying a job in <a href=\"https://github.com/NERSC/spack-infrastructure/blob/main/.gitlab-ci.yml\"\
    >.gitlab-ci.yml</a>.</p>\n<p>The gitlab job can be triggered through <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\" rel=\"\
    nofollow\">scheduled pipelines</a>, <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web-interface</a>, or merge request to the project. A typical\
    \ gitlab job will look something like this. Shown below is for E4S 23.05 generate\
    \ job. We make use of gitlab feature named <a href=\"https://docs.gitlab.com/ee/ci/yaml/index.html#extends\"\
    \ rel=\"nofollow\">extends</a> which allows us to reuse configuration. The <code>spack\
    \ ci generate</code> command will be the same for each substack. There is two\
    \ jobs, first is the generate step performed by <code>spack ci generate</code>\
    \ and this triggers the downstream job created by spack.</p>\n<div class=\"highlight\
    \ highlight-source-yaml\"><pre><span class=\"pl-ent\">.perlmutter-e4s-23.05-generate</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">generate</span>\n\
    \  <span class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    ]</span>\n  <span class=\"pl-ent\">tags</span>: <span class=\"pl-s\">[perlmutter-e4s]</span>\n\
    \  <span class=\"pl-ent\">interruptible</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">allow_failure</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">rules</span>:\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"schedule\" || $CI_PIPELINE_SOURCE\
    \ == \"web\") &amp;&amp; ($PIPELINE_NAME == \"PERLMUTTER_E4S_23.05\")</span>\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"merge_request_event\")</span>\n      <span class=\"pl-ent\">changes</span>:\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/$STACK_NAME/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">before_script</span>:\n    <span class=\"pl-s\">- *copy_perlmutter_settings</span>\n\
    \    <span class=\"pl-s\">- *startup_modules</span>\n  <span class=\"pl-ent\"\
    >script</span>:\n    <span class=\"pl-s\">- *e4s_23_05_setup </span>\n    - <span\
    \ class=\"pl-s\">cd $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/$STACK_NAME</span>\n\
    \    - <span class=\"pl-s\">cat $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/definitions.yaml\
    \ &gt;&gt; spack.yaml</span>\n    - <span class=\"pl-s\">spack env activate --without-view\
    \  .</span>\n    - <span class=\"pl-s\">spack env st</span>\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>- spack -d concretize -f | tee $CI_PROJECT_DIR/concretize.log\
    \    </span>\n    - <span class=\"pl-s\">spack -d ci generate --check-index-only\
    \ --artifacts-root \"$CI_PROJECT_DIR/jobs_scratch_dir\" --output-file \"${CI_PROJECT_DIR}/jobs_scratch_dir/pipeline.yml\"\
    </span>\n  <span class=\"pl-ent\">artifacts</span>: \n    <span class=\"pl-ent\"\
    >paths</span>:\n    - <span class=\"pl-s\">${CI_PROJECT_DIR}/jobs_scratch_dir</span>\n\
    \n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-generate</span>:\n  <span\
    \ class=\"pl-ent\">extends</span>: <span class=\"pl-s\">.perlmutter-e4s-23.05-generate</span>\n\
    \  <span class=\"pl-ent\">variables</span>:\n    <span class=\"pl-ent\">STACK_NAME</span>:\
    \ <span class=\"pl-s\">cce</span>\n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-build</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">build</span>\n  <span\
    \ class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    , \"perlmutter-e4s-23.05-cce-generate\"]</span>\n  <span class=\"pl-ent\">allow_failure</span>:\
    \ <span class=\"pl-c1\">true</span>\n  <span class=\"pl-ent\">rules</span>:\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"schedule\" || $CI_PIPELINE_SOURCE == \"web\") &amp;&amp; ($PIPELINE_NAME\
    \ == \"PERLMUTTER_E4S_23.05\")</span>\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"merge_request_event\")</span>\n\
    \      <span class=\"pl-ent\">changes</span>:\n      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/cce/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">trigger</span>:\n    <span class=\"pl-ent\">include</span>:\n\
    \      - <span class=\"pl-ent\">artifact</span>: <span class=\"pl-s\">jobs_scratch_dir/pipeline.yml</span>\n\
    \        <span class=\"pl-ent\">job</span>: <span class=\"pl-s\">perlmutter-e4s-23.05-cce-generate</span>\n\
    \    <span class=\"pl-ent\">strategy</span>: <span class=\"pl-s\">depend</span></pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 4: Create Modulefile</h3><a\
    \ id=\"user-content-step-4-create-modulefile\" class=\"anchor\" aria-label=\"\
    Permalink: Step 4: Create Modulefile\" href=\"#step-4-create-modulefile\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>In\
    \ this step, we create a modulefile as entry point to software stack and setup\
    \ <code>spack</code>. We do not create spack generated modules for spack packages,\
    \ instead one is expected to use <code>spack load</code>.  Shown below are the\
    \ modulefiles available on NERSC system, they are typically called <code>e4s/&lt;version&gt;</code>\
    \ with a symbolic link to module <code>spack/e4s-&lt;version&gt;</code></p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml -t av e4s</span>\n<span\
    \ class=\"pl-c1\">/global/common/software/nersc/pm-2022.12.0/extra_modulefiles:</span>\n\
    <span class=\"pl-c1\">e4s/22.05</span>\n<span class=\"pl-c1\">e4s/22.11</span>\n\
    <span class=\"pl-c1\">spack/e4s-22.05</span>\n<span class=\"pl-c1\">spack/e4s-22.11</span></pre></div>\n\
    <p>Shown below is the content of our modulefile, the setup is subject to change</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml --raw show e4s</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">   /global/common/software/nersc/pm-2022.12.0/extra_modulefiles/e4s/22.11.lua:</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">whatis([[</span>\n<span class=\"pl-c1\">        The Extreme-scale\
    \ Scientific Software Stack (E4S) is a collection of open source software packages\
    \ for running scientific applications on high-performance computing (HPC) platforms.</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n<span class=\"pl-c1\">help([[ The Extreme-scale\
    \ Scientific Software Stack (E4S) is a community effort to provide open source\
    \ software packages for developing, deploying and running scientific applications\
    \ on high-performance computing (HPC) platforms. E4S provides from-source builds\
    \ and containers of a broad collection of HPC software packages.</span>\n\n<span\
    \ class=\"pl-c1\">References:</span>\n<span class=\"pl-c1\">  - E4S User Docs:\
    \ https://e4s.readthedocs.io/en/latest/index.html</span>\n<span class=\"pl-c1\"\
    >  - E4S 22.11 Docs: https://docs.nersc.gov/applications/e4s/perlmutter/22.11/</span>\n\
    <span class=\"pl-c1\">  - E4S Homepage: https://e4s-project.github.io/</span>\n\
    <span class=\"pl-c1\">  - E4S GitHub: https://github.com/E4S-Project/e4s</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n\n<span class=\"pl-c1\">local root =\
    \ \"/global/common/software/spackecp/perlmutter/e4s-22.11/default/spack\"</span>\n\
    \n<span class=\"pl-c1\">setenv(\"SPACK_GNUPGHOME\", pathJoin(os.getenv(\"HOME\"\
    ), \".gnupg\"))</span>\n<span class=\"pl-c1\">setenv(\"SPACK_SYSTEM_CONFIG_PATH\"\
    , \"/global/common/software/spackecp/perlmutter/spack_settings\")</span>\n<span\
    \ class=\"pl-c1\">-- setup spack shell functionality</span>\n<span class=\"pl-c1\"\
    >local shell = myShellType()</span>\n<span class=\"pl-c1\">if (mode() == \"load\"\
    ) then</span>\n<span class=\"pl-c1\">    local spack_setup = ''</span>\n<span\
    \ class=\"pl-c1\">    if (shell == \"sh\" or shell == \"bash\" or shell == \"\
    zsh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.sh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"csh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.csh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"fish\")  then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.fish\")</span>\n<span class=\"pl-c1\">    end</span>\n\
    \n<span class=\"pl-c1\">    -- If we are unable to find spack setup script let's\
    \ terminate now.</span>\n<span class=\"pl-c1\">    if not isFile(spack_setup)\
    \ then</span>\n<span class=\"pl-c1\">        LmodError(\"Unable to find spack\
    \ setup script \" .. spack_setup .. \"\\n\")</span>\n<span class=\"pl-c1\">  \
    \  end</span>\n\n<span class=\"pl-c1\">    execute{cmd=\"source \" .. spack_setup,\
    \ modeA={\"load\"}}</span>\n\n<span class=\"pl-c1\">    LmodMessage([[</span>\n\
    <span class=\"pl-c1\">    _______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">     The Extreme-Scale Scientific Software Stack (E4S) is\
    \ accessible via the Spack package manager.</span>\n\n<span class=\"pl-c1\"> \
    \    In order to access the production stack, you will need to load a spack environment.\
    \ Here are some tips to get started:</span>\n\n\n<span class=\"pl-c1\">     'spack\
    \ env list' - List all Spack environments</span>\n<span class=\"pl-c1\">     'spack\
    \ env activate gcc' - Activate the \"gcc\" Spack environment</span>\n<span class=\"\
    pl-c1\">     'spack env status' - Display the active Spack environment</span>\n\
    <span class=\"pl-c1\">     'spack load amrex' - Load the \"amrex\" Spack package\
    \ into your user environment</span>\n\n<span class=\"pl-c1\">     For additional\
    \ support, please refer to the following references:</span>\n\n<span class=\"\
    pl-c1\">       NERSC E4S Documentation: https://docs.nersc.gov/applications/e4s/</span>\n\
    <span class=\"pl-c1\">       E4S Documentation: https://e4s.readthedocs.io</span>\n\
    <span class=\"pl-c1\">       Spack Documentation: https://spack.readthedocs.io/en/latest/</span>\n\
    <span class=\"pl-c1\">       Spack Slack: https://spackpm.slack.com</span>\n\n\
    <span class=\"pl-c1\">    ______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">    ]])</span>\n<span class=\"pl-c1\">-- To remove spack\
    \ from shell we need to remove a few environment variables, alias and remove $SPACK_ROOT/bin\
    \ from $PATH</span>\n<span class=\"pl-c1\">elseif (mode() == \"unload\" or mode()\
    \ == \"purge\") then</span>\n<span class=\"pl-c1\">    if (shell == \"sh\" or\
    \ shell == \"bash\" or shell == \"zsh\") then</span>\n<span class=\"pl-c1\"> \
    \     execute{cmd=\"unset SPACK_ENV\",modeA={\"unload\"}}</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unset SPACK_ROOT\",modeA={\"unload\"}}</span>\n<span\
    \ class=\"pl-c1\">      execute{cmd=\"unset -f spack\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">    elseif (shell == \"csh\") then</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unsetenv SPACK_ENV\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">      execute{cmd=\"unsetenv SPACK_ROOT\",modeA={\"unload\"\
    }}</span>\n<span class=\"pl-c1\">      execute{cmd=\"unalias spack\",modeA={\"\
    unload\"}}</span>\n<span class=\"pl-c1\">    end</span>\n\n<span class=\"pl-c1\"\
    >    -- Need to remove $SPACK_ROOT/bin from $PATH which removes the 'spack' command</span>\n\
    <span class=\"pl-c1\">    remove_path(\"PATH\", pathJoin(root, \"bin\"))</span>\n\
    \n<span class=\"pl-c1\">    -- Remove alias spacktivate. Need to pipe to /dev/null\
    \ as invalid alias can report error to stderr</span>\n<span class=\"pl-c1\"> \
    \   execute{cmd=\"unalias spacktivate &gt; /dev/null\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">end</span></pre></div>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Step 5: User Documentation</h3><a id=\"user-content-step-5-user-documentation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 5: User Documentation\" href=\"\
    #step-5-user-documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>User documentation is fundamental to help assist users\
    \ with using E4S at NERSC. We document every E4S release with its <em>Release\
    \ Date</em> and <em>End of Support</em> date along with a documentation page outlining\
    \ the software stack. Our E4S documentation is available at <a href=\"https://docs.nersc.gov/applications/e4s/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/</a>. The release date\
    \ is when documentation is live. We perform this action in conjunction with release\
    \ of modulefile so that user gain access to software stack.</p>\n<p>Upon completion\
    \ of this task, we are ready to make announcement to our NERSC users</p>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Step 6: Sharing spack\
    \ configuration with open-source community</h3><a id=\"user-content-step-6-sharing-spack-configuration-with-open-source-community\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 6: Sharing spack configuration\
    \ with open-source community\" href=\"#step-6-sharing-spack-configuration-with-open-source-community\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>In this step, we share our spack configuration with open-source community that\
    \ may benefit the wider community. We share our spack configuration at <a href=\"\
    https://github.com/spack/spack-configs\">https://github.com/spack/spack-configs</a>.\
    \ In addition, we update the <a href=\"https://e4s.readthedocs.io/en/latest/facility_e4s.html\"\
    \ rel=\"nofollow\">E4S Facility Dashboard</a> that shows all the E4S deployments\
    \ across all the facilities.</p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Step 7: Public Announcement</h3><a id=\"user-content-step-7-public-announcement\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 7: Public Announcement\" href=\"\
    #step-7-public-announcement\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>This is the final step of the deployment process, where\
    \ we make a public announcement in NERSC weekly email, along with various slack\
    \ channels such as Nersc User Group (NUG), Spack, ECP and E4S slack.</p>\n<div\
    \ class=\"markdown-heading\"><h2 class=\"heading-element\">Current Challenges</h2><a\
    \ id=\"user-content-current-challenges\" class=\"anchor\" aria-label=\"Permalink:\
    \ Current Challenges\" href=\"#current-challenges\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>There are several challenges\
    \ with building spack stack at NERSC which can be summarized as follows</p>\n\
    <ul>\n<li>\n<p><strong>System OS + Cray Programming Environment (CPE) changes</strong>:\
    \ A system upgrade such as change to <code>glibc</code> or upgrades in CPE can\
    \ lead to full software stack rebuild, especially if you have external packages\
    \ set for packages like <code>cray-mpich</code>, <code>cray-libsci</code> which\
    \ generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Contact</h2><a id=\"\
    user-content-contact\" class=\"anchor\" aria-label=\"Permalink: Contact\" href=\"\
    #contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li>Shahzeb Siddiqui - <a href=\"mailto:shahzebsiddiqui@lbl.gov\"\
    >shahzebsiddiqui@lbl.gov</a>\n</li>\n<li>Erik Palmer - <a href=\"mailto:epalmer@lbl.gov\"\
    >epalmer@lbl.gov</a>\n</li>\n<li>Justin Cook - <a href=\"mailto:JSCook@lbl.gov\"\
    >JSCook@lbl.gov</a>\n</li>\n<li>E4S Team: Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>), Christopher Peyralans (<a href=\"mailto:lpeyrala@uoregon.edu\"\
    >lpeyrala@uoregon.edu</a>), Wyatt Spear (<a href=\"mailto:wspear@cs.uoregon.edu\"\
    >wspear@cs.uoregon.edu</a>), Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\"\
    >nchaimov@paratools.com</a>)</li>\n</ul>\n"
  stargazers_count: 9
  subscribers_count: 14
  topics: []
  updated_at: 1716504734.0
NERSC/timemory:
  data_format: 2
  description: 'Modular C++ Toolkit for Performance Analysis and Logging. Profiling
    API and Tools for C, C++, CUDA, Fortran, and Python. The C++ template API is essentially
    a framework to creating tools: it is designed to provide a unifying interface
    for recording various performance measurements alongside data logging and interfaces
    to other tools.'
  filenames:
  - docker/cpu/spack.yaml
  - docker/gpu/spack.yaml
  full_name: NERSC/timemory
  latest_release: v3.2.3
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">timemory</h1><a\
    \ id=\"user-content-timemory\" class=\"anchor\" aria-label=\"Permalink: timemory\"\
    \ href=\"#timemory\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Timing + Memory + Hardware Counter Utilities for C / C++ / CUDA / Python</h2><a\
    \ id=\"user-content-timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    \ class=\"anchor\" aria-label=\"Permalink: Timing + Memory + Hardware Counter\
    \ Utilities for C / C++ / CUDA / Python\" href=\"#timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a href=\"https://travis-ci.org/NERSC/timemory\" rel=\"nofollow\"><img src=\"\
    https://camo.githubusercontent.com/e771c5877a01c9ad3c5f9ac404fafcbb19d8f1647e63f72448851af6753c1d9c/68747470733a2f2f7472617669732d63692e6f72672f4e455253432f74696d656d6f72792e7376673f6272616e63683d6d6173746572\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/NERSC/timemory.svg?branch=master\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/jrmadsen/timemory/branch/master\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/310167bff27e3bfcff0843c04e63901359e8ed7672b1dabbe55d9fb4378d3ba7/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38786b37326f6f7477736566693863312f6272616e63682f6d61737465723f7376673d74727565\"\
    \ alt=\"Build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/8xk72ootwsefi8c1/branch/master?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/NERSC/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d4fac988b58c397453b2f2631379b0e47366ef6750df318103caabf9b65ca0c/68747470733a2f2f636f6465636f762e696f2f67682f4e455253432f74696d656d6f72792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/NERSC/timemory/branch/master/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/NERSC/timemory\"\
    >timemory on GitHub (Source code)</a></p>\n<p><a href=\"https://timemory.readthedocs.io\"\
    \ rel=\"nofollow\">timemory General Documentation (ReadTheDocs)</a></p>\n<p><a\
    \ href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\
    >timemory Source Code Documentation (Doxygen)</a></p>\n<p><a href=\"https://cdash.nersc.gov/index.php?project=TiMemory\"\
    \ rel=\"nofollow\">timemory Testing Dashboard (CDash)</a></p>\n<p><a href=\"https://github.com/NERSC/timemory-tutorials\"\
    >timemory Tutorials</a></p>\n<ul>\n<li>\n<p><a href=\"https://www.youtube.com/watch?v=K1Pazcw7zVo\"\
    \ rel=\"nofollow\">ECP 2021 Tutorial Day 1 (YouTube)</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://www.youtube.com/watch?v=-zIpZDiwrmI\" rel=\"nofollow\">ECP 2021\
    \ Tutorial Day 2 (YouTube)</a></p>\n</li>\n</ul>\n<p><a href=\"https://github.com/NERSC/timemory/wiki\"\
    >timemory Wiki</a></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>GitHub</td>\n<td><code>git clone https://github.com/NERSC/timemory.git</code></td>\n\
    </tr>\n<tr>\n<td>PyPi</td>\n<td><code>pip install timemory</code></td>\n</tr>\n\
    <tr>\n<td>Spack</td>\n<td><code>spack install timemory</code></td>\n</tr>\n<tr>\n\
    <td>conda-forge</td>\n<td><code>conda install -c conda-forge timemory</code></td>\n\
    </tr>\n<tr>\n<td></td>\n<td><a href=\"https://anaconda.org/conda-forge/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/13d88311b8a3ad78d2eef315c0144a27a104d75e9a610a215d6fc1251318275d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265636970652d74696d656d6f72792d677265656e2e737667\"\
    \ alt=\"Conda Recipe\" data-canonical-src=\"https://img.shields.io/badge/recipe-timemory-green.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/533b6f62d054e5318ac8873adf8b287aee649fa0b56ac1c1de77b09f4e00b2aa/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/bafca219a0c269a4ab94502e87e4a06788840125f4b0bf838158aaf5eb141c18/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/978fa080053b7937c5fb17a7bd59e5be69923086146a430e861f1dda4cb0eb9e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f706e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/conda/pn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"></a></td>\n</tr>\n</tbody>\n</table>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Purpose</h2><a id=\"user-content-purpose\"\
    \ class=\"anchor\" aria-label=\"Permalink: Purpose\" href=\"#purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>The goal of timemory\
    \ is to create an open-source performance measurement and analyis package\nwith\
    \ modular and reusable components which can be used to adapt to any existing C/C++\n\
    performance measurement and analysis API and is arbitrarily extendable by users\
    \ within their\napplication.\nTimemory is not just another profiling tool, it\
    \ is a profling <em>toolkit</em> which streamlines building custom\nprofiling\
    \ tools through modularity and then utilizes the toolkit to provides several pre-built\
    \ tools.</p>\n<p>In other words, timemory provides many pre-built tools, libraries,\
    \ and interfaces but, due to it's modularity,\ncodes can re-use only individual\
    \ pieces -- such as the classes for measuring different timing intervals, memory\
    \ usage,\nand hardware counters -- without the timemory \"runtime management\"\
    .</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Building\
    \ and Installing</h2><a id=\"user-content-building-and-installing\" class=\"anchor\"\
    \ aria-label=\"Permalink: Building and Installing\" href=\"#building-and-installing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Timemory uses a standard CMake installation.\nSeveral installation examples\
    \ can be found in the <a href=\"https://github.com/NERSC/timemory/wiki/Installation-Examples\"\
    >Wiki</a>. See the <a href=\"https://timemory.readthedocs.io/en/develop/installation.html\"\
    \ rel=\"nofollow\">installation documentation</a> for detailed information on\
    \ the CMake options.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Documentation</h2><a id=\"user-content-documentation\" class=\"anchor\" aria-label=\"\
    Permalink: Documentation\" href=\"#documentation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>The full documentation\
    \ is available at <a href=\"https://timemory.readthedocs.io\" rel=\"nofollow\"\
    >timemory.readthedocs.io</a>.\nDetailed source documentation is provided in the\
    \ <a href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\
    >doygen</a>\nsection of the full documentation.\nTutorials are available in the\
    \ <a href=\"https://github.com/NERSC/timemory-tutorials\">github.com/NERSC/timemory-tutorials</a>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Overview</h2><a\
    \ id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\"\
    \ href=\"#overview\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><strong><em>The primary objective of the timemory is the\
    \ development of a common framework for binding together software\nmonitoring\
    \ code (i.e. performance analysis, debugging, logging) into a compact and highly-efficient\
    \ interface.</em></strong></p>\n<p>Timemory arose out of the need for a universal\
    \ adapator kit for the various APIs provided several existing tools\nand a straight-forward\
    \ and intuitive method for creating new tools. Timemory makes it possible to bundle\n\
    together deterministic performance measurements, statistical performance\nmeasurements\
    \ (i.e. sampling), debug messages, data logging, and data validation into the\
    \ same interface for\ncustom application-specific software monitoring interfaces,\
    \ easily building tools like <code>time</code>,\n<code>netstat</code>, instrumentation\
    \ profilers, sampling profilers, and writing implementations for MPI-P, MPI-T,\
    \ OMPT,\nKokkosP, etc. Furthermore, timemory can forward its markers to several\
    \ third-party profilers such as\n<a href=\"https://github.com/RRZE-HPC/likwid\"\
    >LIKWID</a>, <a href=\"https://github.com/LLNL/Caliper\">Caliper</a>,\n<a href=\"\
    https://www.cs.uoregon.edu/research/tau/home.php\" rel=\"nofollow\">TAU</a>, <a\
    \ href=\"https://github.com/gperftools/gperftools\">gperftools</a>,\n<a href=\"\
    https://perfetto.dev/docs/\" rel=\"nofollow\">Perfetto</a>, VTune, Allinea-MAP,\
    \ CrayPAT, Nsight-Systems, Nsight-Compute, and NVProf.</p>\n<p>Timemory provides\
    \ a front-end <a href=\"https://timemory.readthedocs.io/en/develop/api/library.html\"\
    \ rel=\"nofollow\">C/C++/Fortran API</a>\nand <a href=\"https://timemory.readthedocs.io/en/develop/api/python.html\"\
    \ rel=\"nofollow\">Python API</a> which allows arbitrary selection\nof 50+ different\
    \ components from timers to hardware counters to interfaces with third-party tools.\
    \ This is all\nbuilt generically from the toolkit API with type-safe bundles of\
    \ tools such as:\n<code>component_tuple&lt;wall_clock, papi_vector, nvtx_marker,\
    \ user_bundle&gt;</code>\nwhere <code>wall_clock</code> is a wall-clock timer,\n\
    <code>papi_vector</code> is a handle for hardware counters,\n<code>nvxt_marker</code>\
    \ creates notations in the NVIDIA CUDA profilers, and\n<code>user_bundle</code>\
    \ is a generic component which downstream users can insert more components into\
    \ at runtime.</p>\n<p>Performance measurement components written with timemory\
    \ are arbitrarily scalable up to any number of threads and\nprocesses and fully\
    \ support intermixing different measurements at different locations within the\
    \ program -- this\nuniquely enables timemory to be deployed to collect performance\
    \ data at scale in HPC because highly detailed collection can\noccur at specific\
    \ locations within the program where ubiquitous collection would simulatenously\
    \ degrade performance\nsignificantly and require a prohibitive amount of memory.</p>\n\
    <p>Timemory can be used as a backend to bundle instrumentation and sampling tools\
    \ together, support serialization to JSON/XML,\nand provide statistics among other\
    \ uses. It can also be utilized as a front-end to invoke\ncustom instrumentation\
    \ and sampling tools. Timemory uses the abstract term \"component\" for a structure\n\
    which encapsulates some performance analysis operation. The structure might encapsulate\
    \ function\ncalls to another tool, record timestamps for timing, log values provided\
    \ by the application,\nprovide a operator for replacing a function in the code\
    \ dynamically, audit the incoming arguments\nand/or outgoing return value from\
    \ function, or just provide stubs which can be overloaded by the linker.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Visualization and\
    \ Analysis</h3><a id=\"user-content-visualization-and-analysis\" class=\"anchor\"\
    \ aria-label=\"Permalink: Visualization and Analysis\" href=\"#visualization-and-analysis\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The native output format of timemory is JSON and text; other output formats\
    \ such as XML are also supported.\nThe text format is intended to be human readable.\
    \ The JSON data\nis intended for analysis and comes in two flavors: hierarchical\
    \ and flat. Basic plotting capabilities are\navailable via <code>timemory-plotting</code>\
    \ but users are highly encouraged to use <a href=\"https://github.com/hatchet/hatchet\"\
    >hatchet</a>\nfor analyzing the heirarchical JSON data in pandas dataframes. <a\
    \ href=\"https://github.com/hatchet/hatchet\">Hatchet</a> supports\nfiltering,\
    \ unions, addition, subtractions, output to <code>dot</code> and flamegraph formats,\
    \ and an interactive Jupyter notebook.\nAt present, timemory supports 45+ metric\
    \ types for analysis in Hatchet.</p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Categories</h3><a id=\"user-content-categories\" class=\"anchor\"\
    \ aria-label=\"Permalink: Categories\" href=\"#categories\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>There are 4 primary\
    \ categories in timemory: components, operations, bundlers, and storage. Components\
    \ provide\nthe specifics of how to perform a particular behavior, operations provide\
    \ the scaffold for requesting that\na component perform an operation in complex\
    \ scenarios, bundlers group components into a single generic handle,\nand storage\
    \ manages data collection over the lifetime of the application. When all four\
    \ categories are combined,\ntimemory effectively resembles a standard performance\
    \ analysis tool which passively collects data and provides\nreports and analysis\
    \ at the termination of the application. Timemory, however, makes it <em>very\
    \ easy</em> to subtract\nstorage from the equation and, in doing so, transforms\
    \ timemory into a toolkit for customized data collection.</p>\n<ol>\n<li>\n<strong><em>Components</em></strong>\n\
    <ul>\n<li>Individual classes which encapsulate one or more measurement, analysis,\
    \ logging, or third-party library action(s)</li>\n<li>Any data specific to one\
    \ instance of performing the action is stored within the instance of the class</li>\n\
    <li>Any configuration data specific to that type is typically stored within static\
    \ member functions which return a reference to the configuration data</li>\n<li>These\
    \ classes are designed to support direct usage within other tools, libraries,\
    \ etc.</li>\n<li>Examples include:\n<ul>\n<li>\n<code>tim::component::wall_clock</code>\
    \ : a simple wall-clock timer</li>\n<li>\n<code>tim::component::vtune_profiler</code>\
    \ : a simple component which turns the VTune Profiler on and off (when VTune is\
    \ actively profiling application)</li>\n<li>\n<code>tim::component::data_tracker_integer</code>\
    \ : associates an integer values with a label as the application executes (e.g.\
    \ number of loop iterations used somewhere)</li>\n<li>\n<code>tim::component::papi_vector</code>\
    \ : uses the PAPI library to collect hardware-counters values</li>\n<li>\n<code>tim::component::user_bundle</code>\
    \ : encapsulates an array of components which the user can dynamically manipulate\
    \ during runtime</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Operations</em></strong>\n\
    <ul>\n<li>Templated classes whose primary purpose is to provide the implementation\
    \ for performing some action on a component, e.g. <code>tim::operation::start&lt;wall_clock&gt;</code>\
    \ will attempt to call the <code>start()</code> member function on a <code>wall_clock</code>\
    \ component instance</li>\n<li>Default implementations generally have one or two\
    \ public functions: a constructor and/or a function call operator\n<ul>\n<li>These\
    \ generally accept any/all arguments and use SFINAE to determine whether the operation\
    \ can be performed with or without the given arguments (i.e. does <code>wall_clock</code>\
    \ have a <code>store(int)</code> function? <code>store()</code>?)</li>\n</ul>\n\
    </li>\n<li>Operations are (generally) not directly utilized by the user and are\
    \ typically optimized out of the binary</li>\n<li>Examples include:\n<ul>\n<li>\n\
    <code>tim::operation::start</code> : instruct a component to start collection</li>\n\
    <li>\n<code>tim::operation::sample</code> : instruct a component to take individual\
    \ measurement</li>\n<li>\n<code>tim::operation::derive</code> : extra data from\
    \ other components if it is available</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n\
    <strong><em>Bundlers</em></strong>\n<ul>\n<li>Provide a generic handle for multiple\
    \ components</li>\n<li>Member functions generally accept any/all arguments and\
    \ use operations classes to correctly to handle differences between different\
    \ capabilities of the components it is bundling</li>\n<li>Examples include:\n\
    <ul>\n<li><code>tim::auto_tuple</code></li>\n<li><code>tim::component_tuple</code></li>\n\
    <li><code>tim::component_list</code></li>\n<li><code>tim::lightweight_tuple</code></li>\n\
    </ul>\n</li>\n<li>Various flavors provide different implicit behaviors and allocate\
    \ memory differently\n<ul>\n<li>\n<code>auto_tuple</code> starts all components\
    \ when constructed and stops all components when destructed whereas <code>component_tuple</code>\
    \ requires an explicit start</li>\n<li>\n<code>component_tuple</code> allocates\
    \ all components on the stack and components are \"always on\" whereas <code>component_list</code>\
    \ allocates components on the heap and thus components can be activated/deactivated\
    \ at runtime</li>\n<li>\n<code>lightweight_tuple</code> does not implicitly perform\
    \ any expensive actions, such as call-stack tracking in \"Storage\"</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>\n<strong><em>Storage</em></strong>\n<ul>\n<li>Provides\
    \ persistent storage for multiple instances of components over the lifetime of\
    \ a thread in the application</li>\n<li>Responsible for maintaining the hierarchy\
    \ and order of component measurements, i.e. call-stack tracking</li>\n<li>Responsible\
    \ for combining component data from multiple threads and/or processes and outputting\
    \ the results</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: <code>tim::lightweight_tuple</code>\
    \ is the recommended bundle for those seeking to use timemory as a toolkit for\
    \ implementing custom tools and interfaces</p>\n</blockquote>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Features</h2><a id=\"user-content-features\" class=\"\
    anchor\" aria-label=\"Permalink: Features\" href=\"#features\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<ul>\n<li>C++ Template\
    \ API\n<ul>\n<li>Modular and fully-customizable</li>\n<li>Adheres to C++ standard\
    \ template library paradigm of \"you don't pay for what you don't use\"</li>\n\
    <li>Simplifies and facilitates creation and implementation of performance measurement\
    \ tools\n<ul>\n<li>Create your own instrumentation profiler</li>\n<li>Create your\
    \ own instrumentation library</li>\n<li>Create your own sampling profiler</li>\n\
    <li>Create your own sampling library</li>\n<li>Create your own execution wrappers</li>\n\
    <li>Supplement timemory-provided tools with your own custom component(s)</li>\n\
    <li>Thread-safe data aggregation</li>\n<li>Aggregate collection over multiple\
    \ processes (MPI and UPC++ support)</li>\n<li>Serialization to text, JSON, XML</li>\n\
    </ul>\n</li>\n<li>Components are composable with other components</li>\n<li>Variadic\
    \ component bundlers which maintain complete type-safety\n<ul>\n<li>Components\
    \ can be bundled together into a single handle without abstractions</li>\n</ul>\n\
    </li>\n<li>Components can store data in any valid C++ data type</li>\n<li>Components\
    \ can return data in any valid C++ data type</li>\n</ul>\n</li>\n<li>C / C++ /\
    \ CUDA / Fortran Library API\n<ul>\n<li>Straight-forward collection of functions\
    \ and macros for creating built-in performance analysis to your code</li>\n<li>Component\
    \ collection can be arbitrarily inter-mixed\n<ul>\n<li>E.g. collect \"A\" and\
    \ \"B\" in one region, \"A\" and \"C\" in another region</li>\n</ul>\n</li>\n\
    <li>Component collection can be dynamically manipulated at runtime\n<ul>\n<li>E.g.\
    \ add/remove \"A\" at any point, on any thread, on any process</li>\n</ul>\n</li>\n\
    </ul>\n</li>\n<li>Python API\n<ul>\n<li>Decorators and context-managers for functions\
    \ or regions in code</li>\n<li>Python function profiling</li>\n<li>Python line-by-line\
    \ profiling</li>\n<li>Every component in <code>timemory-avail</code> is provided\
    \ as a stand-alone Python class\n<ul>\n<li>Provide low-overhead measurements for\
    \ building your own Python profiling tools</li>\n</ul>\n</li>\n</ul>\n</li>\n\
    <li>Python Analysis via <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\"\
    >pandas</a>\n</li>\n<li>Command-line Tools\n<ul>\n<li>\n<a href=\"source/tools/timemory-avail/README.md\"\
    >timemory-avail</a>\n<ul>\n<li>Provides available components, settings, and hardware\
    \ counters</li>\n<li>Quick API reference tool</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timem/README.md\">timem</a> (UNIX)\n<ul>\n<li>Extended version of\
    \ UNIX <code>time</code> command-line tool that includes additional information\
    \ on memory usage, context switches, and hardware counters</li>\n<li>Support collecting\
    \ hardware counters (Linux-only, requires PAPI)</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timemory-run/README.md\">timemory-run</a> (Linux)\n<ul>\n<li>Dynamic\
    \ instrumentation profiling tool</li>\n<li>Supports runtime instrumentation and\
    \ binary re-writing</li>\n</ul>\n</li>\n<li>\n<a href=\"source/tools/timemory-nvml/README.md\"\
    >timemory-nvml</a>\n<ul>\n<li>Data collection similar to <code>nvidia-smi</code>\n\
    </li>\n</ul>\n</li>\n<li>\n<code>timemory-python-profiler</code>\n<ul>\n<li>Python\
    \ function profiler supporting all timemory components</li>\n<li><code>from timemory.profiler\
    \ import Profile</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-trace</code>\n\
    <ul>\n<li>Python line-by-line profiler supporting all timemory components</li>\n\
    <li><code>from timemory.trace import Trace</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-line-profiler</code>\n\
    <ul>\n<li>Python line-by-line profiler based on <a href=\"https://pypi.org/project/line-profiler/\"\
    \ rel=\"nofollow\">line-profiler</a> package</li>\n<li>Extended to use components:\
    \ cpu-clock, memory-usage, context-switches, etc. (all components which collect\
    \ scalar values)</li>\n<li><code>from timemory.line_profiler import LineProfiler</code></li>\n\
    </ul>\n</li>\n</ul>\n</li>\n<li>Instrumentation Libraries\n<ul>\n<li>\n<a href=\"\
    source/tools/timemory-mpip/README.md\">timemory-mpip</a>: MPI Profiling Library\
    \ (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ncclp/README.md\">timemory-ncclp</a>:\
    \ NCCL Profiling Library (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ompt/README.md\"\
    >timemory-ompt</a>: OpenMP Profiling Library</li>\n<li>\n<a href=\"source/tools/timemory-compiler-instrument/README.md\"\
    >timemory-compiler-instrument</a>: Compiler instrumentation Library</li>\n<li>\n\
    <a href=\"source/tools/kokkos-connector/README.md\">kokkos-connector</a>: Kokkos\
    \ Profiling Libraries</li>\n</ul>\n</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Samples</h2><a id=\"user-content-samples\" class=\"\
    anchor\" aria-label=\"Permalink: Samples\" href=\"#samples\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Various macros are\
    \ defined for C in <a href=\"source/timemory/timemory.h\">source/timemory/compat/timemory_c.h</a>\n\
    and <a href=\"source/timemory/variadic/macros.hpp\">source/timemory/variadic/macros.hpp</a>.\
    \ Numerous samples of\ntheir usage can be found in the examples.</p>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Sample C++ Template API</h3><a\
    \ id=\"user-content-sample-c-template-api\" class=\"anchor\" aria-label=\"Permalink:\
    \ Sample C++ Template API\" href=\"#sample-c-template-api\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"highlight\
    \ highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>timemory/timemory.hpp<span class=\"pl-pds\"\
    >\"</span></span>\n\n<span class=\"pl-k\">namespace</span> <span class=\"pl-en\"\
    >comp</span> <span class=\"pl-k\">=</span> tim::component;\n<span class=\"pl-k\"\
    >using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">tim</span><span\
    \ class=\"pl-k\">;</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ specific set of components</span>\n<span class=\"pl-k\">using</span> <span class=\"\
    pl-c1\">specific_t</span> = component_tuple&lt;comp::wall_clock, comp::cpu_clock&gt;;\n\
    <span class=\"pl-k\">using</span> <span class=\"pl-c1\">generic_t</span>  = component_tuple&lt;comp::user_global_bundle&gt;;\n\
    \n<span class=\"pl-k\">int</span>\n<span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span>** argv)\n{\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> configure default settings</span>\n\
    \    <span class=\"pl-c1\">settings::flat_profile</span>() = <span class=\"pl-c1\"\
    >true</span>;\n    <span class=\"pl-c1\">settings::timing_units</span>() = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span class=\"pl-pds\">\"\
    </span></span>;\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> initialize\
    \ with cmd-line</span>\n    <span class=\"pl-c1\">timemory_init</span>(argc, argv);\n\
    \    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> add argparse support</span>\n\
    \    <span class=\"pl-c1\">timemory_argparse</span>(&amp;argc, &amp;argv);\n\n\
    \    <span class=\"pl-c\"><span class=\"pl-c\">//</span> create a region \"main\"\
    </span>\n    <span class=\"pl-c1\">specific_t</span> m{ <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span> };\n \
    \   m.<span class=\"pl-c1\">start</span>();\n    m.<span class=\"pl-c1\">stop</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">settings::enabled</span>() = <span\
    \ class=\"pl-c1\">false</span>;\n    <span class=\"pl-c1\">specific_t</span> h{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden<span class=\"pl-pds\"\
    >\"</span></span> };\n    h.<span class=\"pl-c1\">start</span>().<span class=\"\
    pl-c1\">stop</span>();\n    <span class=\"pl-c1\">settings::enabled</span>() =\
    \ <span class=\"pl-c1\">true</span>;\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Add peak_rss component to specific_t</span>\n    mpl::<span class=\"\
    pl-c1\">push_back_t</span>&lt;<span class=\"pl-c1\">specific_t</span>, comp::peak_rss&gt;\
    \ wprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>with peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n    \n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> create region collecting only peak_rss</span>\n    component_tuple&lt;comp::peak_rss&gt;\
    \ oprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>only peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> convert component_tuple to a type that starts/stops upon construction/destruction</span>\n\
    \    {\n        scope::config _scope{};\n        <span class=\"pl-k\">if</span>(<span\
    \ class=\"pl-c1\">true</span>)  _scope += scope::flat{};\n        <span class=\"\
    pl-k\">if</span>(<span class=\"pl-c1\">false</span>) _scope += scope::timeline{};\n\
    \        <span class=\"pl-c1\">convert_t</span>&lt;<span class=\"pl-c1\">specific_t</span>,\
    \ auto_tuple&lt;&gt;&gt; scoped{ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>scoped start/stop + flat<span class=\"pl-pds\">\"</span></span>, _scope\
    \ };\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> will yield auto_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;</span>\n    }\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of strings</span>\n    runtime::configure&lt;comp::user_global_bundle&gt;({\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> });\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of enumeration ids</span>\n\
    \    runtime::configure&lt;comp::user_global_bundle&gt;({ TIMEMORY_WALL_CLOCK,\
    \ TIMEMORY_CPU_CLOCK });\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ configure the generic bundle via component instances</span>\n    comp::user_global_bundle::configure&lt;comp::page_rss,\
    \ comp::papi_vector&gt;();\n    \n    <span class=\"pl-c1\">generic_t</span> g{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>generic<span class=\"pl-pds\"\
    >\"</span></span>, quirk::config&lt;quirk::auto_start&gt;{} };\n    g.<span class=\"\
    pl-c1\">stop</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Sample C / C++ Library\
    \ API</h3><a id=\"user-content-sample-c--c-library-api\" class=\"anchor\" aria-label=\"\
    Permalink: Sample C / C++ Library API\" href=\"#sample-c--c-library-api\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<div\
    \ class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/library.h<span\
    \ class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/timemory.h<span class=\"\
    pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">int</span>\n<span class=\"pl-en\"\
    >main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span>**\
    \ argv)\n{\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> configure\
    \ settings</span>\n    <span class=\"pl-k\">int</span> overwrite       = <span\
    \ class=\"pl-c1\">0</span>;\n    <span class=\"pl-k\">int</span> update_settings\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> default to flat-profile</span>\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_FLAT_PROFILE<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> force timing units</span>\n    overwrite\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_TIMING_UNITS<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> initialize with cmd-line</span>\n\
    \    <span class=\"pl-c1\">timemory_init_library</span>(argc, argv);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> check if inited, init with name</span>\n\
    \    <span class=\"pl-k\">if</span>(!<span class=\"pl-c1\">timemory_library_is_initialized</span>())\n\
    \        <span class=\"pl-c1\">timemory_named_init_library</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>ex-c<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> define the default set\
    \ of components</span>\n    <span class=\"pl-c1\">timemory_set_default</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock, cpu_clock<span class=\"\
    pl-pds\">\"</span></span>);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ create a region \"main\"</span>\n    <span class=\"pl-c1\">timemory_push_region</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>);\n    <span class=\"pl-c1\">timemory_pop_region</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">timemory_pause</span>();\n    <span\
    \ class=\"pl-c1\">timemory_push_region</span>(<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_pop_region</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_resume</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> Add/remove component(s) to the current set of components</span>\n \
    \   <span class=\"pl-c1\">timemory_add_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_remove_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> get an identifier for\
    \ a region and end it</span>\n    <span class=\"pl-c1\">uint64_t</span> idx =\
    \ <span class=\"pl-c1\">timemory_get_begin_record</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> assign an existing identifier for a region</span>\n\
    \    <span class=\"pl-c1\">timemory_begin_record</span>(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>indexed/2<span class=\"pl-pds\">\"</span></span>,\
    \ &amp;idx);\n    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n \
    \   <span class=\"pl-c\"><span class=\"pl-c\">//</span> create region collecting\
    \ a specific set of data</span>\n    <span class=\"pl-c1\">timemory_begin_record_enum</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>enum<span class=\"pl-pds\">\"\
    </span></span>, &amp;idx, TIMEMORY_PEAK_RSS, TIMEMORY_COMPONENTS_END);\n    <span\
    \ class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"pl-c1\"\
    >timemory_begin_record_types</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>types<span class=\"pl-pds\">\"</span></span>, &amp;idx, <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> replace current set of components and then\
    \ restore previous set</span>\n    <span class=\"pl-c1\">timemory_push_components</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\"\
    >\"</span></span>);\n    <span class=\"pl-c1\">timemory_pop_components</span>();\n\
    \n    <span class=\"pl-c1\">timemory_push_components_enum</span>(<span class=\"\
    pl-c1\">2</span>, TIMEMORY_WALL_CLOCK, TIMEMORY_CPU_CLOCK);\n    <span class=\"\
    pl-c1\">timemory_pop_components</span>();\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize_library</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Sample Fortran API</h3><a\
    \ id=\"user-content-sample-fortran-api\" class=\"anchor\" aria-label=\"Permalink:\
    \ Sample Fortran API\" href=\"#sample-fortran-api\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<div class=\"highlight highlight-source-fortran\"\
    ><pre><span class=\"pl-k\">program</span> fortran_example\n    use timemory\n\
    \    use iso_c_binding, only : C_INT64_T\n    <span class=\"pl-k\">implicit none</span>\n\
    \    <span class=\"pl-k\">integer</span>(C_INT64_T) <span class=\"pl-k\">::</span>\
    \ idx\n\n    ! initialize with explicit name\n    <span class=\"pl-k\">call</span>\
    \ timemory_init_library(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ex-fortran<span\
    \ class=\"pl-pds\">\"</span></span>)\n\n    ! initialize with name extracted from\
    \ get_command_argument(<span class=\"pl-c1\">0</span>, ...)\n    ! <span class=\"\
    pl-k\">call</span> timemory_init_library(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-pds\">\"</span></span>)\n\n    ! define the default\
    \ set of components\n    <span class=\"pl-k\">call</span> timemory_set_default(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock, cpu_clock<span class=\"\
    pl-pds\">\"</span></span>)\n\n    ! Start region <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>\n    <span class=\"\
    pl-k\">call</span> timemory_push_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>main<span class=\"pl-pds\">\"</span></span>)\n\n    ! Add peak_rss <span\
    \ class=\"pl-k\">to</span> the current set of components\n    <span class=\"pl-k\"\
    >call</span> timemory_add_components(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>)\n\n    ! Nested region\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\"\
    >\"</span></span> nested under <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>main<span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-k\">call</span>\
    \ timemory_push_region(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span>)\n\n    ! End the <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span> region\n\
    \    <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! remove peak_rss\n    <span class=\"pl-k\">call</span> timemory_remove_components(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\"\
    >\"</span></span>)\n\n    ! begin a region and get an identifier\n    idx <span\
    \ class=\"pl-k\">=</span> timemory_get_begin_record(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span>)\n\n\
    \    ! replace current set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_push_components(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span\
    \ class=\"pl-pds\">\"</span></span>)\n\n    ! Nested region <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span>\
    \ with only page_rss components\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner (pushed)<span class=\"\
    pl-pds\">\"</span></span>)\n\n    ! <span class=\"pl-k\">Stop</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span>\
    \ region with only page_rss components\n    <span class=\"pl-k\">call</span> timemory_pop_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner (pushed)<span class=\"\
    pl-pds\">\"</span></span>)\n\n    ! restore previous set of components\n    <span\
    \ class=\"pl-k\">call</span> timemory_pop_components()\n\n    ! end the <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>indexed<span class=\"pl-pds\"\
    >\"</span></span> region\n    <span class=\"pl-k\">call</span> timemory_end_record(idx)\n\
    \n    ! End <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"\
    pl-pds\">\"</span></span>\n    <span class=\"pl-k\">call</span> timemory_pop_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! Output the results\n    <span class=\"pl-k\">call</span>\
    \ timemory_finalize_library()\n\n<span class=\"pl-k\">end program</span> fortran_example</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Sample Python API</h3><a\
    \ id=\"user-content-sample-python-api\" class=\"anchor\" aria-label=\"Permalink:\
    \ Sample Python API\" href=\"#sample-python-api\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"><h4\
    \ class=\"heading-element\">Decorator</h4><a id=\"user-content-decorator\" class=\"\
    anchor\" aria-label=\"Permalink: Decorator\" href=\"#decorator\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">timemory</span>.<span class=\"pl-s1\">bundle</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-s1\">marker</span>\n\n<span class=\"pl-en\">@<span\
    \ class=\"pl-en\">marker</span>([<span class=\"pl-s\">\"cpu_clock\"</span>, <span\
    \ class=\"pl-s\">\"peak_rss\"</span>])</span>\n<span class=\"pl-k\">def</span>\
    \ <span class=\"pl-en\">foo</span>():\n    <span class=\"pl-k\">pass</span></pre></div>\n\
    <div class=\"markdown-heading\"><h4 class=\"heading-element\">Context Manager</h4><a\
    \ id=\"user-content-context-manager\" class=\"anchor\" aria-label=\"Permalink:\
    \ Context Manager\" href=\"#context-manager\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">from</span> <span class=\"pl-s1\">timemory</span>.<span\
    \ class=\"pl-s1\">profiler</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-s1\">profile</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\"\
    >bar</span>():\n    <span class=\"pl-k\">with</span> <span class=\"pl-en\">profile</span>([<span\
    \ class=\"pl-s\">\"wall_clock\"</span>, <span class=\"pl-s\">\"cpu_util\"</span>]):\n\
    \        <span class=\"pl-en\">foo</span>()</pre></div>\n<div class=\"markdown-heading\"\
    ><h4 class=\"heading-element\">Individual Components</h4><a id=\"user-content-individual-components\"\
    \ class=\"anchor\" aria-label=\"Permalink: Individual Components\" href=\"#individual-components\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">component</span>\
    \ <span class=\"pl-k\">import</span> <span class=\"pl-v\">WallClock</span>\n\n\
    <span class=\"pl-k\">def</span> <span class=\"pl-en\">spam</span>():\n\n    <span\
    \ class=\"pl-s1\">wc</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >WallClock</span>(<span class=\"pl-s\">\"spam\"</span>)\n    <span class=\"pl-s1\"\
    >wc</span>.<span class=\"pl-en\">start</span>()\n\n    <span class=\"pl-en\">bar</span>()\n\
    \n    <span class=\"pl-s1\">wc</span>.<span class=\"pl-en\">stop</span>()\n  \
    \  <span class=\"pl-s1\">data</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">wc</span>.<span class=\"pl-en\">get</span>()\n    <span class=\"pl-en\"\
    >print</span>(<span class=\"pl-s1\">data</span>)</pre></div>\n<div class=\"markdown-heading\"\
    ><h4 class=\"heading-element\">Argparse Support</h4><a id=\"user-content-argparse-support\"\
    \ class=\"anchor\" aria-label=\"Permalink: Argparse Support\" href=\"#argparse-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">argparse</span>\n\n<span class=\"pl-s1\">parser</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">argparse</span>.<span class=\"\
    pl-v\">ArgumentParser</span>(<span class=\"pl-s\">\"example\"</span>)\n<span class=\"\
    pl-c\"># ...</span>\n<span class=\"pl-s1\">timemory</span>.<span class=\"pl-en\"\
    >add_arguments</span>(<span class=\"pl-s1\">parser</span>)\n\n<span class=\"pl-s1\"\
    >args</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">parser</span>.<span\
    \ class=\"pl-en\">parse_args</span>()</pre></div>\n<div class=\"markdown-heading\"\
    ><h4 class=\"heading-element\">Component Storage</h4><a id=\"user-content-component-storage\"\
    \ class=\"anchor\" aria-label=\"Permalink: Component Storage\" href=\"#component-storage\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">storage</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-v\">WallClockStorage</span>\n\n\
    <span class=\"pl-c\"># data for current rank</span>\n<span class=\"pl-s1\">data</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">get</span>()\n<span class=\"pl-c\"># combined data on rank zero\
    \ but all ranks must call it</span>\n<span class=\"pl-s1\">dmp_data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">dmp_get</span>()</pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Versioning</h2><a id=\"user-content-versioning\"\
    \ class=\"anchor\" aria-label=\"Permalink: Versioning\" href=\"#versioning\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Timemory\
    \ originated as a very simple tool for recording timing and memory measurements\
    \ (hence the name) in C, C++, and Python and only supported\nthree modes prior\
    \ to the 3.0.0 release: a fixed set of timers, a pair of memory measurements,\
    \ and the combination of the two.\n<strong>Prior to the 3.0.0 release, timemory\
    \ was almost completely rewritten from scratch</strong> with the sole exceptions\
    \ of some C/C++ macro, e.g.\n<code>TIMEMORY_AUTO_TIMER</code>, and some Python\
    \ decorators and context-manager, e.g. <code>timemory.util.auto_timer</code>,\
    \ whose behavior were\nable to be fully replicated in the new release. Thus, while\
    \ it may appear that timemory is a mature project at v3.0+, it\nis essentially\
    \ still in it's first major release.</p>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Citing timemory</h2><a id=\"user-content-citing-timemory\"\
    \ class=\"anchor\" aria-label=\"Permalink: Citing timemory\" href=\"#citing-timemory\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>To reference timemory in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Madsen, J.R. et al. (2020) Timemory: Modular Performance Analysis for\
    \ HPC. In: Sadayappan P., Chamberlain B., Juckeland G., Ltaief H. (eds) High Performance\
    \ Computing. ISC High Performance 2020. Lecture Notes in Computer Science, vol\
    \ 12151. Springer, Cham</li>\n</ul>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Additional Information</h2><a id=\"user-content-additional-information\"\
    \ class=\"anchor\" aria-label=\"Permalink: Additional Information\" href=\"#additional-information\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>For more information, refer to the <a href=\"https://timemory.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n"
  stargazers_count: 347
  subscribers_count: 16
  topics:
  - python
  - cpp
  - cplusplus
  - performance
  - c
  - cross-platform
  - cross-language
  - memory-measurements
  - mpi
  - cuda
  - papi
  - hardware-counters
  - analysis
  - roofline
  - performance-measurement
  - instrumentation-api
  - gotcha
  - cupti
  - modular-design
  updated_at: 1716407092.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">GSI-Utils</h1><a
    id="user-content-gsi-utils" class="anchor" aria-label="Permalink: GSI-Utils" href="#gsi-utils"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1717123565.0
NOAA-EMC/NCEPLIBS-bufr:
  data_format: 2
  description: The NCEPLIBS-bufr library contains routines and utilites for working
    with the WMO BUFR format.
  filenames:
  - spack/spack.yaml
  full_name: NOAA-EMC/NCEPLIBS-bufr
  latest_release: v12.0.1
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/NOAA-EMC/NCEPLIBS-bufr/workflows/Build%20and%20Test/badge.svg"><img
    src="https://github.com/NOAA-EMC/NCEPLIBS-bufr/workflows/Build%20and%20Test/badge.svg"
    alt="Status" style="max-width: 100%;"></a></p>

    <div class="markdown-heading"><h2 class="heading-element">NCEPLIBS-bufr library</h2><a
    id="user-content-nceplibs-bufr-library" class="anchor" aria-label="Permalink:
    NCEPLIBS-bufr library" href="#nceplibs-bufr-library"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The NCEPLIBS-bufr library contains routines and utilites for working

    with the <a href="https://library.wmo.int/index.php?lvl=notice_display&amp;id=10684#.Y70OSNLMJH7"
    rel="nofollow">WMO

    BUFR</a>

    format. It is part of the

    <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> project.</p>

    <p>For full documentation of the library, see <a href="https://noaa-emc.github.io/NCEPLIBS-bufr/"
    rel="nofollow">https://noaa-emc.github.io/NCEPLIBS-bufr/</a>.</p>

    <p>NCEPLIBS-bufr is used by numerous other projects including:</p>

    <ul>

    <li>

    <a href="https://github.com/NOAA-EMC/gfs-utils">gfs-utils</a> from NOAA''s global

    workflow.</li>

    <li>NCAR''s <a href="https://ral.ucar.edu/solutions/products/gridpoint-statistical-interpolation-gsi"
    rel="nofollow">Gridpoint Statistical Interpolation

    (GSI)</a>.</li>

    <li>

    <a href="https://github.com/NOAA-EMC/obsproc">obsproc</a> in the <a href="https://nomads.ncep.noaa.gov/"
    rel="nofollow">NOAA

    Operational Model Archive and Distribution System (NOMADS)</a>.</li>

    <li>

    <a href="https://github.com/NOAA-EMC/prepobs">prepobs</a> from the <a href="https://www.nco.ncep.noaa.gov/pmb/prod_overview/"
    rel="nofollow">The NCEP Production Suite</a>.</li>

    <li>

    <a href="https://github.com/NOAA-EMC/bufr-dump">bufr-dump</a> which is run by

    all of the NOAA model data assimilation systems when it''s time to

    collect data for use in the analyses.</li>

    <li>the <a href="https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast"
    rel="nofollow">Global Ensemble Forecast

    System(GEFS)</a>.</li>

    <li>the <a href="https://rapidrefresh.noaa.gov/hrrr/" rel="nofollow">High-Resolution
    Rapid Refresh model

    (HRRR)</a>.</li>

    <li>NOAA''s <a href="https://rapidrefresh.noaa.gov/" rel="nofollow">Rapid Refresh
    (RAP)</a> assimilation/modeling system.</li>

    </ul>

    <p>To submit bug reports, feature requests, or other code-related issues including
    installation and usage questions, please create a <a href="https://github.com/NOAA-EMC/NCEPLIBS-bufr/issues">GitHub
    issue</a>. For general NCEPLIBS inquiries, contact <a href="mailto:edward.hartnett@noaa.gov">Edward
    Hartnett</a> (secondary point of contact <a href="mailto:alexander.richert@noaa.gov">Alex
    Richert</a>).</p>

    <div class="markdown-heading"><h2 class="heading-element">Authors</h2><a id="user-content-authors"
    class="anchor" aria-label="Permalink: Authors" href="#authors"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Jack Woollen, Jeff Ator, Dennis Keyser, Stacey Bender, Diane Stokes, Edward
    Hartnett,

    Jeff Whitaker, Rahul Mahajan, Alex Richert, Ron McLaren, and Dom Heinzeller.</p>

    <p>Code manager: <a href="mailto:jeff.ator@noaa.gov">Jeff Ator</a></p>

    <div class="markdown-heading"><h2 class="heading-element">How to Build and Install</h2><a
    id="user-content-how-to-build-and-install" class="anchor" aria-label="Permalink:
    How to Build and Install" href="#how-to-build-and-install"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Download tarball from

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-bufr/releases">Releases</a> and

    unpack.</p>

    <pre>mkdir build &amp;&amp; cd build

    cmake -DCMAKE_INSTALL_PREFIX=path1 -DMASTER_TABLE_DIR=path2 ..

    make -j4

    ctest

    make install

    </pre>

    <p>Both <code>path1</code> and <code>path2</code> may be full or relative pathnames

    on the system, up to a maximum of 90 characters each.</p>

    <p>Installation of the library and utilities will be under <code>path1</code>.

    Installation of the master BUFR tables will be under <code>path2</code>, or

    under <code>path1</code> if <code>-DMASTER_TABLE_DIR=path2</code> is omitted

    from the above cmake command.</p>

    <p>If Python interoperability is desired, <code>-DENABLE_PYTHON=ON</code> can
    also

    be added to the above cmake command.  However, version 3 of Python

    must be installed and available on the system.</p>

    <div class="markdown-heading"><h2 class="heading-element">References</h2><a id="user-content-references"
    class="anchor" aria-label="Permalink: References" href="#references"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Hartnett, E., Ator, J, Lei, H., Richert, A., Woollen, J., King, A.,

    Hartnett, A., <a href="https://www.researchgate.net/publication/376390180_NCEPLIBS_GRIB_and_BUFR_Libraries_Maintaining_and_Modernizing_NOAA''s_Libraries_for_WMO_Data_Formats"
    rel="nofollow">NCEPLIBS GRIB and BUFR Libraries: Maintaining and

    Modernizing NOAA''s Libraries for WMO Data

    Formats</a>,

    American Geophysical Union (AGU) 2023. (See also

    <a href="https://www.researchgate.net/publication/376582005_Poster_-_IN51B-0416_NCEPLIBS_GRIB_and_BUFR_Libraries_Maintaining_and_Modernizing_NOAA''s_Libraries_for_WMO_Data_Formats"
    rel="nofollow">poster</a>).</p>

    <div class="markdown-heading"><h2 class="heading-element">Disclaimer</h2><a id="user-content-disclaimer"
    class="anchor" aria-label="Permalink: Disclaimer" href="#disclaimer"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 39
  subscribers_count: 5
  topics:
  - bufr
  updated_at: 1717059271.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: upp-srw-v2.2.0
  readme: '<div class="markdown-heading"><h1 class="heading-element">Unified Post
    Processor (UPP)</h1><a id="user-content-unified-post-processor-upp" class="anchor"
    aria-label="Permalink: Unified Post Processor (UPP)" href="#unified-post-processor-upp"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High-Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecast System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Analysis and

    Forecast System (HAFS), and the Medium-Range Weather (MRW) and Short-

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model-derived brightness
    temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages or for

    further downstream post-processing, e.g., statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">User Support</h2><a
    id="user-content-user-support" class="anchor" aria-label="Permalink: User Support"
    href="#user-support"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Support for the UFS UPP is provided through <a href="https://github.com/NOAA-EMC/UPP/discussions">GitHub
    Discussions</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Documentation</h2><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>User Guide for latest standalone public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Developer Information</h2><a
    id="user-content-developer-information" class="anchor" aria-label="Permalink:
    Developer Information" href="#developer-information"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Please review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Authors</h2><a id="user-content-authors"
    class="anchor" aria-label="Permalink: Authors" href="#authors"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Fernando Andrade-Maldonado</p>

    <div class="markdown-heading"><h2 class="heading-element">Prerequisites</h2><a
    id="user-content-prerequisites" class="anchor" aria-label="Permalink: Prerequisites"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The UPP requires certain NCEPLIBS packages to be installed via the

    spack-stack project. For instructions on installing these packages as a

    bundle via spack-stack, see: <a href="https://spack-stack.readthedocs.io/en/latest/"
    rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a>.

    The <code>UPP/modulefiles</code> directory indicates which package versions are

    used and supported on Level 1 systems.</p>

    <p>Required NCEPLIBS packages:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf">netcdf</a></li>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">zlib</a></li>

    <li><a href="https://github.com/HDFGroup/hdf5">hdf5</a></li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Building</h2><a id="user-content-building"
    class="anchor" aria-label="Permalink: Building" href="#building"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <div class="markdown-heading"><h2 class="heading-element">Disclaimer</h2><a id="user-content-disclaimer"
    class="anchor" aria-label="Permalink: Disclaimer" href="#disclaimer"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <div class="markdown-heading"><h2 class="heading-element">UPP Terms of Use Notice</h2><a
    id="user-content-upp-terms-of-use-notice" class="anchor" aria-label="Permalink:
    UPP Terms of Use Notice" href="#upp-terms-of-use-notice"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The UPP Terms of Use Notice is available at: <a href="https://github.com/NOAA-EMC/UPP/wiki/UPP-Terms-of-Use-Notice">https://github.com/NOAA-EMC/UPP/wiki/UPP-Terms-of-Use-Notice</a></p>

    '
  stargazers_count: 31
  subscribers_count: 14
  topics: []
  updated_at: 1717015884.0
NOAA-EMC/fv3atm:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/fv3atm
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">fv3atm</h1><a
    id="user-content-fv3atm" class="anchor" aria-label="Permalink: fv3atm" href="#fv3atm"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This repository contains a driver and key subcomponents of the

    atmospheric component of the NOAA''s <a href="https://ufscommunity.org/" rel="nofollow">Unified
    Forecast System

    (UFS)</a> weather model.</p>

    <p>The subcomponents include:</p>

    <ul>

    <li>The Finite-Volume Cubed-Sphere (FV3) dynamical core, originally

    from the <a href="https://www.gfdl.noaa.gov/" rel="nofollow">Geophysical Fluid
    Dynamics

    Laboratory</a>.</li>

    <li>The Common Community Physics Package (CCPP) supported by the

    <a href="https://dtcenter.org/community-code/common-community-physics-package-ccpp"
    rel="nofollow">Developmental Testbed Center

    (DTC)</a>,

    including:

    <ul>

    <li>

    <a href="https://github.com/NCAR/ccpp-framework">CCPP Framework</a>.</li>

    <li><a href="https://github.com/NCAR/ccpp-physics">CCPP Physics</a></li>

    </ul>

    </li>

    <li>wrapper code to call <a href="https://stochastic-physics.readthedocs.io/en/latest/"
    rel="nofollow">UFS stochastic

    physics</a>

    </li>

    <li>The io code handles netCDF I/O.</li>

    <li>The cpl coupler code connects the different components and allows

    them to communicate.</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Prerequisites</h2><a
    id="user-content-prerequisites" class="anchor" aria-label="Permalink: Prerequisites"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This package requires the following

    <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> packages:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    </ul>

    <p>If the INLINE_POST cmake variable is set, the upp library will be

    needed:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/EMC_post">Unified Post Processing Library</a></li>

    </ul>

    <p>This package also requires the following external packages:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c Library</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran Library</a></li>

    <li><a href="https://github.com/esmf-org/esmf">ESMF</a></li>

    <li><a href="https://github.com/NOAA-GFDL/FMS">GFDL''s Flexible Modeling System</a></li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Obtaining fv3atm</h2><a
    id="user-content-obtaining-fv3atm" class="anchor" aria-label="Permalink: Obtaining
    fv3atm" href="#obtaining-fv3atm"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>To obtain fv3atm, clone the git repository, and update the submodules:</p>

    <pre><code>git clone https://github.com/NOAA-EMC/fv3atm.git

    cd fv3atm

    git submodule update --init --recursive

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Disclaimer</h2><a id="user-content-disclaimer"
    class="anchor" aria-label="Permalink: Disclaimer" href="#disclaimer"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 28
  subscribers_count: 24
  topics:
  - numerical-weather-prediction
  - nwp
  - weather
  updated_at: 1716924744.0
NOAA-GFDL/HPC-ME:
  data_format: 2
  description: null
  filenames:
  - ci/fms-gnu/spack.yaml
  full_name: NOAA-GFDL/HPC-ME
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">HPC-ME: HPC Portable
    Containers for Model Environments</h1><a id="user-content-hpc-me-hpc-portable-containers-for-model-environments"
    class="anchor" aria-label="Permalink: HPC-ME: HPC Portable Containers for Model
    Environments" href="#hpc-me-hpc-portable-containers-for-model-environments"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">Contents</h2><a id="user-content-contents"
    class="anchor" aria-label="Permalink: Contents" href="#contents"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li><a href="#what-is-hpc-me">What is HPC-ME</a></li>

    <li><a href="#list-of-current-compilers">List of current compilers/MPI/OS</a></li>

    <li><a href="#list-of-current-libraries">List of current libraries</a></li>

    <li><a href="#how-to-build">How to build</a></li>

    <li><a href="#how-to-use">How to use</a></li>

    <li><a href="#gfdl-example">GFDL example</a></li>

    <li><a href="#planned-improvements">Planned improvements</a></li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">What is HPC-ME</h2><a
    id="user-content-what-is-hpc-me" class="anchor" aria-label="Permalink: What is
    HPC-ME" href="#what-is-hpc-me"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>HPC Portable Container - Model Environments is a set of Dockerfiles, Singularity
    Definition files, and containers to provide portable model environments for scientific
    applications that require the same set of libraries.  The ultimate goal is to
    have a community-based list of libraries that are needed for compiling, executing,
    and post-processing earth science models.  We all use many of the same underlying
    libraries, and by working together we can agree upon a community-based approach
    to making container usage as standardized as possible.</p>

    <div class="markdown-heading"><h2 class="heading-element">List of current compilers/MPI/OS</h2><a
    id="user-content-list-of-current-compilersmpios" class="anchor" aria-label="Permalink:
    List of current compilers/MPI/OS" href="#list-of-current-compilersmpios"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>For each container, there is a full version that contains the programming environment
    and a smaller runtime environment that can be used to run compiled executables.
    (The runtime container definition files will be added soon.)

    #- <a href="Dockerfile_gnu_ubuntu20.04">gcc 8/mpich/ubuntu 20.04</a></p>

    <ul>

    <li><a href="Dockerfile_gnu_rhel8">gcc 8/mpich/RHEL8</a></li>

    <li>

    <a href="Dockerfile_intel_ubuntu18.04">intel oneAPI 2022.1/mpich(impi)/ubuntu
    18.04</a>

    #- <a href="Dockerfile_intel_centos8">intel oneAPI 2021.4/mpich(impi)/centos 8</a>

    </li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">List of current libraries</h2><a
    id="user-content-list-of-current-libraries" class="anchor" aria-label="Permalink:
    List of current libraries" href="#list-of-current-libraries"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This is the current list of most of the libraries used in the HPC-ME containers
    (We are trying to keep this up-to-date).

    The complete list should be found in the respective YAML file.</p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#automake"
    rel="nofollow">automake@1.16.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bacio" rel="nofollow">bacio@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#berkeley-db"
    rel="nofollow">berkeley-db@18.1.40</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bison" rel="nofollow">bison@3.7.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bzip2" rel="nofollow">bzip2@1.0.8</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cmake" rel="nofollow">cmake@3.21.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#crtm" rel="nofollow">crtm@2.3.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#curl" rel="nofollow">curl@7.78.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#diffutils"
    rel="nofollow">diffutils@3.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#esmf" rel="nofollow">esmf@8.1.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#expat" rel="nofollow">expat@2.4.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2" rel="nofollow">g2@3.4.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2tmpl"
    rel="nofollow">g2tmpl@1.10.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gdbm" rel="nofollow">gdbm@1.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gsl" rel="nofollow">gsl@2.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#hdf5" rel="nofollow">hdf5@1.10.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip" rel="nofollow">ip@3.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip2" rel="nofollow">ip2@1.1.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#jasper"
    rel="nofollow">jasper@2.0.32</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libbsd"
    rel="nofollow">libbsd@0.11.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libiconv"
    rel="nofollow">libiconv@1.16</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libjpeg-turbo"
    rel="nofollow">libjpeg-turbo@2.1.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libmd" rel="nofollow">libmd@1.0.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libpng"
    rel="nofollow">libpng@1.6.37</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libsigsegv"
    rel="nofollow">libsigsegv@2.13</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libtool"
    rel="nofollow">libtool@2.4.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libxml2"
    rel="nofollow">libxml2@2.9.12</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libyaml"
    rel="nofollow">libyaml@0.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#lmod" rel="nofollow">lmod@8.5.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#m4" rel="nofollow">m4@1.4.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nasm" rel="nofollow">nasm@2.15.05</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nccmp" rel="nofollow">nccmp@1.8.6.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nco" rel="nofollow">nco@4.7.9</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ncurses"
    rel="nofollow">ncurses@6.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nemsio"
    rel="nofollow">nemsio@2.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-c"
    rel="nofollow">netcdf-c@4.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-fortran"
    rel="nofollow">netcdf-fortran@4.5.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#numactl"
    rel="nofollow">numactl@2.0.14</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#openssl"
    rel="nofollow">openssl@1.1.1m</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#parallel-netcdf"
    rel="nofollow">parallel-netcdf@1.12.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#perl" rel="nofollow">perl@5.34.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#pkgconf"
    rel="nofollow">pkgconf@1.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#readline"
    rel="nofollow">readline@8.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sfcio" rel="nofollow">sfcio@1.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sigio" rel="nofollow">sigio@2.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sp" rel="nofollow">sp@2.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#udunits"
    rel="nofollow">udunits@2.2.28</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3emc" rel="nofollow">w3emc@2.9.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3nco" rel="nofollow">w3nco@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#wrf-io"
    rel="nofollow">wrf-io@1.2.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xerces-c"
    rel="nofollow">xerces-c@3.2.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xz" rel="nofollow">xz@5.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#zlib" rel="nofollow">zlib@1.2.11</a></li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">How to build</h2><a
    id="user-content-how-to-build" class="anchor" aria-label="Permalink: How to build"
    href="#how-to-build"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><strong>We plan to make this step optional soon.</strong> In order to build
    the Docker images, you will need access to a computer with root-like access, and
    either docker or singularity installed. If you do not have root-like access to
    a suitable machine, you can still run images that were already created (e.g. on
    Docker hub), and we plan on hosting runnable Docker images along with the Dockerfiles
    in this repository soon. If you have root-like access and docker, start by choosing
    one of the currently supported model environments from the list above. Then build
    the Docker container from the Dockerfile using docker build; for example, to build
    the gcc8/mpich/ubuntu18 container:</p>

    <pre><code>docker build --file Dockerfile_gnu_ubuntu20.04 . --tag hpc-me.ubuntu.gnu

    </code></pre>

    <p>The build process takes approximately 2-3 hours, as the packages are downloaded
    and compiled using Spack. After a successful build, you will see that the image
    was built and tagged successfully:</p>

    <pre><code>Successfully built 90a878af77b4

    Successfully tagged hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>Then, you may run the container using docker or singularity on the same host.
    To run the image on a different machine, pushing the image to Docker Hub is recommended.
    Note that you will need a DockerHub account to do this (replace USER with your
    Docker user ID in the examples below). For example:</p>

    <pre><code>docker tag hpc-me.rhel8.gnu USER/hpc-me.rhel8.gnu

    docker login

    docker push USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">How to use</h2><a id="user-content-how-to-use"
    class="anchor" aria-label="Permalink: How to use" href="#how-to-use"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>We plan to make improvements on this process. Also, while we plan on making
    Docker images available on the GitHub container registry, currently you must build
    the images yourself. Please start with the <a href="#how-to-build">Build instructions</a>
    to generate a Docker image with your desired OS/compiler HPC-ME environment. Then
    you may run the container using docker or singularity; singularity is more likely
    than docker to be available on HPC environments.</p>

    <p>The usage documentation consists of some general notes on serial/parallel usage,
    files inside and outside the container, downloading the containers, and then specific
    usage scenarios:</p>

    <ul>

    <li><a href="#serial-applications-using-docker">Serial applications using docker</a></li>

    <li><a href="#serial-applications-using-singularity">Serial applications using
    singularity</a></li>

    <li><a href="#parallel-applications-using-singularity">Parallel applications using
    singularity</a></li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">Serial and parallel
    usage</h3><a id="user-content-serial-and-parallel-usage" class="anchor" aria-label="Permalink:
    Serial and parallel usage" href="#serial-and-parallel-usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>HPC-ME containers are intended for both serial and parallel applications. Serial
    applications include compiling model executables, generating input grids, and
    post-processing model output. Earth system, climate, and weather models require
    parallelism to run efficiently, and use one of the Message Passage Interface (MPI)
    implementations OpenMPI, Intel MPI, or mpich. GCC-based HPC-ME containers use
    the mpich-based MPI library, which is widely available on most HPC sites, and
    the Intel-based containers contain both mpich and Intel MPI.</p>

    <div class="markdown-heading"><h3 class="heading-element">Notes on filesystems
    and writing files</h3><a id="user-content-notes-on-filesystems-and-writing-files"
    class="anchor" aria-label="Permalink: Notes on filesystems and writing files"
    href="#notes-on-filesystems-and-writing-files"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>We recommend not saving or modifying files within the environment container,
    and instead create and modify files on your regular filesystem. To do this, you
    will need to connect your filesystem to your container using bind mounts.</p>

    <div class="markdown-heading"><h3 class="heading-element">Downloading containers
    and managing images on the filesystem</h3><a id="user-content-downloading-containers-and-managing-images-on-the-filesystem"
    class="anchor" aria-label="Permalink: Downloading containers and managing images
    on the filesystem" href="#downloading-containers-and-managing-images-on-the-filesystem"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Once you have pushed your images to DockerHub, you will need to download them
    before using. In the examples below, replace USER with your Docker Hub ID. If
    using docker,</p>

    <pre><code>docker pull USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity,</p>

    <pre><code>singularity pull docker://USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity, the image file (SIF format) is saved to the current working
    directory</p>

    <pre><code>&gt; ls *.sif

    -rwxr-xr-x 532M Dec 10 16:09 hpc-me.rhel8.gnu_latest.sif*

    </code></pre>

    <p>If using docker, the downloaded image is handled by the central docker service.</p>

    <div class="markdown-heading"><h3 class="heading-element">Serial applications
    using docker</h3><a id="user-content-serial-applications-using-docker" class="anchor"
    aria-label="Permalink: Serial applications using docker" href="#serial-applications-using-docker"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>You may activate an interactive shell within the desired HPC-ME container using
    docker. After running the container, the compilers and tools available within
    the container will be accessible in your PATH; e.g.</p>

    <pre><code>&gt; docker run -it hpc-me.rhel8.gnu:latest


    [root@0d2cf64e1175 /]# which nf-config

    /opt/view/bin/nf-config


    [root@0d2cf64e1175 /]# nf-config --version

    netCDF-Fortran 4.5.3


    [root@0d2cf64e1175 /]# nf-config --cflags

    -I/opt/software/linux-rhel8-x86_64/gcc-8.4.1/netcdf-fortran-4.5.3-g5qfkdlp36unt2s4j4wyrc6heh2sa64n/include

    </code></pre>

    <div class="markdown-heading"><h3 class="heading-element">Serial applications
    using singularity</h3><a id="user-content-serial-applications-using-singularity"
    class="anchor" aria-label="Permalink: Serial applications using singularity" href="#serial-applications-using-singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Singularity can run Docker images and is more likely to be available on HPC
    environments. As with docker run, the HPC-ME tools and compilers are available
    in the shell, somewhat similar to loading a set of Environment Modules prepared
    by site administrators.</p>

    <pre><code>&gt;singularity run hpc-me.rhel8.gnu_latest.sif


    Singularity&gt; which nf-config

    /opt/view/bin/nf-config


    Singularity&gt; nf-config --version

    netCDF-Fortran 4.5.3

    </code></pre>

    <div class="markdown-heading"><h3 class="heading-element">Parallel applications
    using singularity</h3><a id="user-content-parallel-applications-using-singularity"
    class="anchor" aria-label="Permalink: Parallel applications using singularity"
    href="#parallel-applications-using-singularity"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>HPC-ME containers can provide the runtime environment for MPI applications.
    For instance, one could compile an MPI application using the instructions above
    using one of the HPC-ME development containers; and then run the application using
    the corresponding runtime HPC-ME container.</p>

    <p>Please note that we are continuing to improve the usability of HPC-ME containers
    as well as provide more usage examples.</p>

    <p>Usually, GFDL climate models are run on gaea by submitting a runscript to the
    Slurm scheduler. The runscript loads needed runtime Environment Modules, prepares
    input directories and files, and executes the MPI executable using srun. The HPC-ME
    containers provide the necessary runtime environment, obviating the need for loading
    Environment Modules. Currently, our approach for using the HPC-ME containers is
    as follows:</p>

    <ol>

    <li>Create a new container, starting with the desired HPC-ME runtime container</li>

    <li>Add the MPI-compiled executable to the container filesystem</li>

    <li>Set the MPI-compiled executable to as the container''s command (so that when
    the container is run the MPI executable within the container runs)</li>

    <li>Run the singularity container SIF file using srun within the runscript, replacing
    the traditional MPI executable.</li>

    </ol>

    <ul>

    <li>Replace "srun executable.x" with "srun singularity run container.SIF"</li>

    <li>Add --mpi=pmi2 to the srun call, which connects the system MPI to the container
    MPI to the singularity run call</li>

    <li>Bind the working directory so that the container has access to the input files
    and can write output files (singularity run -B=/path/to/workdir)</li>

    </ul>

    <ol start="5">

    <li>Submit the modified runscript to the scheduler</li>

    </ol>

    <p>We plan to provide more examples and usage scenarios, such as using the HPC-ME
    containers as-is (i.e. not creating a new container as described above)</p>

    <div class="markdown-heading"><h2 class="heading-element">GFDL example</h2><a
    id="user-content-gfdl-example" class="anchor" aria-label="Permalink: GFDL example"
    href="#gfdl-example"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>An example of using an HPC-ME container with the GFDL FRE workflow can be found
    <a href="GFDL_EXAMPLE.md">here</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Planned improvements</h2><a
    id="user-content-planned-improvements" class="anchor" aria-label="Permalink: Planned
    improvements" href="#planned-improvements"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>HPC-ME is a work in progress under active development, so please check back
    or follow the repository for more updates.</p>

    <div class="markdown-heading"><h3 class="heading-element">Build cache</h3><a id="user-content-build-cache"
    class="anchor" aria-label="Permalink: Build cache" href="#build-cache"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>We are working to create a build cache for the libraries listed so that building
    the containers is quick and easy.</p>

    <div class="markdown-heading"><h3 class="heading-element">Github container registry</h3><a
    id="user-content-github-container-registry" class="anchor" aria-label="Permalink:
    Github container registry" href="#github-container-registry"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>We are working to add CI capability to this repository, so that the containers
    will be automatically built and stored in the github container registry. This
    will make building unnecessary for most cases, though users may build the containers
    themselves if they wish (e.g. for custom modifications).</p>

    <div class="markdown-heading"><h3 class="heading-element">More usage examples
    and documentation, especially for MPI applications</h3><a id="user-content-more-usage-examples-and-documentation-especially-for-mpi-applications"
    class="anchor" aria-label="Permalink: More usage examples and documentation, especially
    for MPI applications" href="#more-usage-examples-and-documentation-especially-for-mpi-applications"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>We are still learning how to best use the HPC-ME containers with MPI appliations,
    so please check back.</p>

    <div class="markdown-heading"><h3 class="heading-element">Disclaimer</h3><a id="user-content-disclaimer"
    class="anchor" aria-label="Permalink: Disclaimer" href="#disclaimer"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    <p>This project code is made available through GitHub but is managed by NOAA-GFDL

    at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 3
  subscribers_count: 7
  topics: []
  updated_at: 1714755517.0
ORNL/ReSolve:
  data_format: 2
  description: Library of GPU-resident linear solvers
  filenames:
  - buildsystem/spack/ascent/spack.yaml
  - buildsystem/spack/crusher/spack.yaml
  - buildsystem/spack/incline/spack.yaml
  full_name: ORNL/ReSolve
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">ReSolve</h1><a\
    \ id=\"user-content-resolve\" class=\"anchor\" aria-label=\"Permalink: ReSolve\"\
    \ href=\"#resolve\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>ReSolve is a library of GPU-resident linear solvers. It\
    \ contains iterative and direct solvers designed to run on NVIDIA and AMD GPUs,\
    \ as well as on CPU devices.</p>\n<p>The User Guide and developer's documentation\
    \ is available <a href=\"https://resolve.readthedocs.io/\" rel=\"nofollow\">online</a>,\n\
    including Doxygen-generated <a href=\"https://resolve.readthedocs.io/en/develop/doxygen/html/index.html\"\
    \ rel=\"nofollow\">source code documentation</a>.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Getting started</h2><a id=\"user-content-getting-started\"\
    \ class=\"anchor\" aria-label=\"Permalink: Getting started\" href=\"#getting-started\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Dependencies:</p>\n<ul>\n<li>KLU, AMD and COLAMD libraries from SuiteSparse\
    \ &gt;= 5.0</li>\n<li>CMake &gt;= 3.22</li>\n<li>CUDA &gt;= 11.4 (optional)</li>\n\
    <li>HIP/ROCm &gt;= 5.6 (optional)</li>\n</ul>\n<p>To build it:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$ git clone https://github.com/ORNL/ReSolve.git\n\
    $ mkdir build <span class=\"pl-k\">&amp;&amp;</span> <span class=\"pl-c1\">cd</span>\
    \ build\n$ cmake ../ReSolve\n$ make</pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">To install the library</h2><a id=\"user-content-to-install-the-library\"\
    \ class=\"anchor\" aria-label=\"Permalink: To install the library\" href=\"#to-install-the-library\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>In the directory where you built the library run</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$ make install</pre></div>\n<p>To change the install\
    \ location please use the CMAkePresets.json file as mentioned in <a href=\"#test-and-deploy\"\
    >test and deploy</a></p>\n<p>To run it, download <a href=\"https://github.com/NREL/opf_matrices/tree/master/acopf/activsg10k\"\
    >test linear systems</a> and then edit script <a href=\"runResolve\"><code>runResolve</code></a>\
    \ to match locations of your linear systems and binary installation. The script\
    \ will emulate nonlinear solver calling the linear solver repeatedly.</p>\n<div\
    \ class=\"markdown-heading\"><h2 class=\"heading-element\">To use the ReSolve\
    \ library in your own project</h2><a id=\"user-content-to-use-the-resolve-library-in-your-own-project\"\
    \ class=\"anchor\" aria-label=\"Permalink: To use the ReSolve library in your\
    \ own project\" href=\"#to-use-the-resolve-library-in-your-own-project\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Make\
    \ sure Resolve library is installed (see above)</p>\n<p>Below is an example CMakeList.txt\
    \ file to use ReSolve library in your project</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">cmake_minimum_required</span>(<span class=\"pl-k\"\
    >VERSION</span> 3.20)\n<span class=\"pl-c1\">project</span>(my_app <span class=\"\
    pl-k\">LANGUAGES</span> CXX)\n\n<span class=\"pl-c1\">find_package</span>(ReSolve\
    \ <span class=\"pl-k\">CONFIG</span> \n  <span class=\"pl-k\">PATHS</span> <span\
    \ class=\"pl-smi\">${ReSolve_DIR}</span> <span class=\"pl-smi\">${ReSolve_DIR}</span>/share/resolve/cmake\n\
    \  <span class=\"pl-k\">ENV</span> <span class=\"pl-k\">LD_LIBRARY_PATH</span>\
    \ <span class=\"pl-k\">ENV</span> DYLD_LIBRARY_PATH\n  <span class=\"pl-k\">REQUIRED</span>)\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Build your executable </span>\n\
    <span class=\"pl-c1\">add_executable</span>(my_app my_app.cpp)\n<span class=\"\
    pl-c1\">target_link_libraries</span>(my_app <span class=\"pl-k\">PRIVATE</span>\
    \ ReSolve::ReSolve)</pre></div>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Contributing</h2><a id=\"user-content-contributing\" class=\"\
    anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>For all contributions\
    \ to ReSolve please follow the <a href=\"CONTRIBUTING.md\">developer guidelines</a></p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Test and Deploy</h2><a\
    \ id=\"user-content-test-and-deploy\" class=\"anchor\" aria-label=\"Permalink:\
    \ Test and Deploy\" href=\"#test-and-deploy\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>ReSolve as a library is tested every\
    \ merge request via Gitlab pipelines that execute various library tests including\
    \ a test of ReSolve being consumed as package within an external project as mentioned\
    \ in <a href=\"#to-use-the-resolve-library-in-your-own-project\">Using ReSolve\
    \ in your own Project</a></p>\n<p>To test your own install of ReSolve simply run\
    \ from your ReSolve build directory</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ make <span class=\"pl-c1\">test</span></pre></div>\n<p>After you <code>make\
    \ install</code> you can test your installation by running</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$ make test_install</pre></div>\n<p>from\
    \ your build directory.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Important Notes</h3><a id=\"user-content-important-notes\" class=\"anchor\" aria-label=\"\
    Permalink: Important Notes\" href=\"#important-notes\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>You can find default Cmake\
    \ Configurations in the CMakePresets.json file, which allows for easy switching\
    \ between different CMake Configs. To create your own CMake Configuration we encourage\
    \ you to utlize a CmakeUserPresets.json file. To learn more about cmake-presets\
    \ please checkout the cmake <a href=\"https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html\"\
    \ rel=\"nofollow\">docs</a></p>\n<p>For example if you wanted to build and install\
    \ ReSolve on a High Performance Computing Cluster such as PNNL's Deception or\
    \ ORNL's Ascent we encourage you to utilize our cluster preset. Using this preset\
    \ will set CMAKE_INSTALL_PREFIX to an install folder. To use this preset simply\
    \ call the preset flag in the cmake build step.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -B build --preset cluster</pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Support</h2><a id=\"user-content-support\" class=\"\
    anchor\" aria-label=\"Permalink: Support\" href=\"#support\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>For technical questions\
    \ or to report a bug please submit a <a href=\"https://github.com/ORNL/ReSolve/issues\"\
    >GitHub issue</a>.\nFor non-technical issues please contact Kasia \u015Awirydowicz\
    \ <a href=\"mailto:kasia.swirydowicz@pnnl.gov\">kasia.swirydowicz@pnnl.gov</a>\
    \ or Slaven Peles <a href=\"mailto:peless@ornl.gov\">peless@ornl.gov</a>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Authors and acknowledgment</h2><a\
    \ id=\"user-content-authors-and-acknowledgment\" class=\"anchor\" aria-label=\"\
    Permalink: Authors and acknowledgment\" href=\"#authors-and-acknowledgment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Primary\
    \ authors of this project are Kasia \u015Awirydowicz and Slaven Peles.</p>\n<p>ReSolve\
    \ project would not be possible without significant contributions from (in alphabetic\
    \ order):</p>\n<ul>\n<li>Maksudul Alam</li>\n<li>Ryan Danehy</li>\n<li>Nicholson\
    \ Koukpaizan</li>\n<li>Jaelyn Litzinger</li>\n<li>Phil Roth</li>\n<li>Cameron\
    \ Rutherford</li>\n</ul>\n<p>Development of this code was supported by the Exascale\
    \ Computing Project (ECP), Project Number: 17-SC-20-SC,\na collaborative effort\
    \ of two DOE organizations\u2014the Office of Science and the National Nuclear\
    \ Security\nAdministration\u2014responsible for the planning and preparation of\
    \ a capable exascale ecosystem\u2014including software,\napplications, hardware,\
    \ advanced system engineering, and early testbed platforms\u2014to support the\
    \ nation's exascale\ncomputing imperative.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">License</h2><a id=\"user-content-license\" class=\"\
    anchor\" aria-label=\"Permalink: License\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Copyright \xA9 2023,\
    \ UT-Battelle, LLC, and Battelle Memorial Institute.</p>\n<p>ReSolve is a free\
    \ software distributed under a BSD-style license. See the\n<a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> files for details. All new\ncontributions\
    \ to ReSolve must be made under the smae licensing terms.</p>\n<p><strong>Please\
    \ Note</strong> If you are using ReSolve with any third party libraries linked\n\
    in (e.g., KLU), be sure to review the respective license of the package as that\n\
    license may have more restrictive terms than the ReSolve license.</p>\n"
  stargazers_count: 48
  subscribers_count: 8
  topics: []
  updated_at: 1709671788.0
PawseySC/hpc-container-training:
  data_format: 2
  description: 'Training material on using containers in an HPC setting. '
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/hpc-container-training
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Readme</h1><a
    id="user-content-readme" class="anchor" aria-label="Permalink: Readme" href="#readme"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    '
  stargazers_count: 5
  subscribers_count: 5
  topics:
  - docker
  - singularity
  - hpc
  - pawsey
  - training-materials
  updated_at: 1711687834.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Automated deployment system for the scientific software stack in use
    at Pawsey
  filenames:
  - systems/setonix/environments/wrf/spack.yaml
  - systems/setonix/environments/cray_s3_clients/spack.yaml
  - systems/setonix/environments/bench/spack.yaml
  - systems/setonix/environments/cray_devel/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Pawsey Spack
    Configuration</h1><a id="user-content-pawsey-spack-configuration" class="anchor"
    aria-label="Permalink: Pawsey Spack Configuration" href="#pawsey-spack-configuration"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <div class="markdown-heading"><h2 class="heading-element">Installation</h2><a
    id="user-content-installation" class="anchor" aria-label="Permalink: Installation"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_TAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <div class="markdown-heading"><h3 class="heading-element">Singularity</h3><a id="user-content-singularity"
    class="anchor" aria-label="Permalink: Singularity" href="#singularity"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <div class="markdown-heading"><h3 class="heading-element">Software stack modulefile</h3><a
    id="user-content-software-stack-modulefile" class="anchor" aria-label="Permalink:
    Software stack modulefile" href="#software-stack-modulefile"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Repository structure</h2><a
    id="user-content-repository-structure" class="anchor" aria-label="Permalink: Repository
    structure" href="#repository-structure"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <div class="markdown-heading"><h2 class="heading-element">The <code>scripts</code>
    directory</h2><a id="user-content-the-scripts-directory" class="anchor" aria-label="Permalink:
    The scripts directory" href="#the-scripts-directory"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">The <code>systems/&lt;system&gt;</code>
    directory</h2><a id="user-content-the-systemssystem-directory" class="anchor"
    aria-label="Permalink: The systems/&lt;system&gt; directory" href="#the-systemssystem-directory"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Notes</h2><a id="user-content-notes"
    class="anchor" aria-label="Permalink: Notes" href="#notes"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h3 class="heading-element">Module categories in
    use</h3><a id="user-content-module-categories-in-use" class="anchor" aria-label="Permalink:
    Module categories in use" href="#module-categories-in-use"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">Testing Modules</h3><a
    id="user-content-testing-modules" class="anchor" aria-label="Permalink: Testing
    Modules" href="#testing-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 1
  subscribers_count: 10
  topics: []
  updated_at: 1708834244.0
RMeli/my-spack:
  data_format: 2
  description: Spack environments
  filenames:
  - envs/local/dlaf/mkl-mt-mpich-cuda-scalapack-pika/spack.yaml
  - envs/local/cp2k-dlaf/openblas-mpich/spack.yaml
  - envs/alps/dlaf/oneapi-mt/spack.yaml
  - envs/local/cp2k-dlaf/dlafort-scalapack/spack.yaml
  - envs/local/dlaf/mkl-mt-mpich/spack.yaml
  - envs/alps/sirius/cuda/spack.yaml
  - envs/local/cp2k/openblas-cuda/spack.yaml
  - envs/local/cp2k-dlaf/mkl-mt-mpich/spack.yaml
  - envs/alps/sirius/cpu/spack.yaml
  - envs/alps/cp2k/cpu/openblas/spack.yaml
  - envs/local/cp2k-dlaf/mkl-mt-mpich-cuda/spack.yaml
  full_name: RMeli/my-spack
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">My Spack</h1><a
    id="user-content-my-spack" class="anchor" aria-label="Permalink: My Spack" href="#my-spack"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Spack-related stuff for @RMeli.</p>

    <div class="markdown-heading"><h2 class="heading-element">Package Repository</h2><a
    id="user-content-package-repository" class="anchor" aria-label="Permalink: Package
    Repository" href="#package-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p><a href="https://spack.readthedocs.io/en/latest/repositories.html" rel="nofollow">Spack
    Package Repositories</a></p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1716897543.0
SC-SGS/CPPuddle:
  data_format: 2
  description: Utility library to handle small, reusable pools of both device memory
    buffers (via allocators) and device executors (with multiple scheduling policies).
  filenames:
  - spack.yaml
  full_name: SC-SGS/CPPuddle
  latest_release: v0.3.1
  readme: "<div class=\"markdown-heading\"><h3 class=\"heading-element\">CPPuddle</h3><a\
    \ id=\"user-content-cppuddle\" class=\"anchor\" aria-label=\"Permalink: CPPuddle\"\
    \ href=\"#cppuddle\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a href=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml\"\
    ><img src=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml/badge.svg\"\
    \ alt=\"ctest\" style=\"max-width: 100%;\"></a>\n<a href=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/view/Octo-Tiger%20and%20Dependencies/job/CPPuddle/job/master/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fb52bcf1fb6b241adb67e33da2e2093e2f6e3569a3f400b53f7b8f65bd12958/68747470733a2f2f73696d7367732e696e666f726d6174696b2e756e692d7374757474676172742e64652f6a656e6b696e732f6275696c645374617475732f69636f6e3f6a6f623d4350507564646c652532466d617374657226636f6e6669673d616c6c6275696c6473\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=CPPuddle%2Fmaster&amp;config=allbuilds\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h4 class=\"\
    heading-element\">Purpose</h4><a id=\"user-content-purpose\" class=\"anchor\"\
    \ aria-label=\"Permalink: Purpose\" href=\"#purpose\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>This repository was initially\
    \ created to explore how to best use HPX and Kokkos together!\nFor fine-grained\
    \ GPU tasks, we needed a way to avoid excessive allocations of one-usage GPU buffers\
    \ (as allocations block the device for all streams) and creation/deletion of GPU\
    \ executors (as those are usually tied to a stream which is expensive to create\
    \ as well).</p>\n<p>We currently test/use CPPuddle in <a href=\"https://github.com/STEllAR-GROUP/octotiger\"\
    >Octo-Tiger</a>, together with <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\
    >HPX-Kokkos</a>.\nIn this use-case, allocating GPU buffers for all sub-grids in\
    \ advance would have wasted a lot of memory. On the other hand, unified memory\
    \ would have caused unnecessary GPU to CPU page migrations (as the old input data\
    \ gets overwritten anyway). Allocating buffers on-the-fly would have blocked the\
    \ device. Hence, we currently test this buffer management solution!</p>\n<div\
    \ class=\"markdown-heading\"><h4 class=\"heading-element\">Tools provided by this\
    \ repository</h4><a id=\"user-content-tools-provided-by-this-repository\" class=\"\
    anchor\" aria-label=\"Permalink: Tools provided by this repository\" href=\"#tools-provided-by-this-repository\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>Allocators that reuse previousely allocated buffers if available (works\
    \ with normal heap memory, pinned memory, aligned memory, CUDA/HIP device memory,\
    \ and Kokkos Views). Note that separate buffers do not coexist on a single chunk\
    \ of continuous memory, but use different allocations.</li>\n<li>Executor pools\
    \ and various scheduling policies (round robin, priority queue, multi-gpu), which\
    \ rely on reference counting to gauge the current load of a executor instead of\
    \ querying the device itself. Tested with CUDA, HIP and Kokkos executors provided\
    \ by HPX / HPX-Kokkos.</li>\n<li>Special Executors/Allocators for on-the-fly work\
    \ GPU aggregation (using HPX).</li>\n</ul>\n<p>The documentation of the current\
    \ master branch is available <a href=\"https://sc-sgs.github.io/CPPuddle/\" rel=\"\
    nofollow\">here</a>. In particular, the public functionality for the memory recycling\
    \ in available in the namespace <a href=\"https://sc-sgs.github.io/CPPuddle/namespacecppuddle_1_1memory__recycling.html\"\
    \ rel=\"nofollow\">memory_recycling</a>, for the executor pools it is available\
    \ in the namespace <a href=\"https://sc-sgs.github.io/CPPuddle/namespacecppuddle_1_1executor__recycling.html\"\
    \ rel=\"nofollow\">executor_recycling</a> and the work aggregation (kernel fusion)\
    \ functionality is available in the namespace <a href=\"https://sc-sgs.github.io/CPPuddle/namespacecppuddle_1_1kernel__aggregation.html\"\
    \ rel=\"nofollow\">work_aggregation</a>.</p>\n<div class=\"markdown-heading\"\
    ><h4 class=\"heading-element\">Requirements</h4><a id=\"user-content-requirements\"\
    \ class=\"anchor\" aria-label=\"Permalink: Requirements\" href=\"#requirements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>C++17</li>\n<li>CMake (&gt;= 3.16)</li>\n<li>Optional (for the header-only\
    \ utilities / test): CUDA, Boost, <a href=\"https://github.com/STEllAR-GROUP/hpx\"\
    >HPX</a>, <a href=\"https://github.com/kokkos/kokkos\">Kokkos</a>, <a href=\"\
    https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>\n</li>\n</ul>\n<p>The\
    \ submodules can be used to obtain the optional dependencies which are required\
    \ for testing the header-only utilities. If these tests are not required, the\
    \ submodule (and the respective buildscripts in /scripts) can be ignored safely.</p>\n\
    <div class=\"markdown-heading\"><h4 class=\"heading-element\">Build / Install</h4><a\
    \ id=\"user-content-build--install\" class=\"anchor\" aria-label=\"Permalink:\
    \ Build / Install\" href=\"#build--install\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<ul>\n<li>\n<p>A spack package for CPPuddle\
    \ is available in the <a href=\"https://github.com/G-071/octotiger-spack\">octotiger-spack\
    \ repository</a></p>\n</li>\n<li>\n<p>Basic CMake build</p>\n</li>\n</ul>\n<pre><code>\
    \  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle\
    \ -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF                     \
    \                                        \n  cmake --build /path/to/build --target\
    \ install  \n</code></pre>\n<p>If installed correctly, CPPuddle can be used in\
    \ other CMake-based projects via</p>\n<pre><code>find_package(CPPuddle REQUIRED)\n\
    </code></pre>\n<ul>\n<li>Recommended CMake build:</li>\n</ul>\n<pre><code>  cmake\
    \ -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle\
    \ -DCPPUDDLE_WITH_HPX=ON -DCPPUDDLE_WITH_HPX_AWARE_ALLOCATORS=ON -DCPPUDDLE_WITH_TESTS=OFF\
    \ -DCPPUDDLE_WITH_COUNTERS=OFF                                               \
    \              \n</code></pre>\n"
  stargazers_count: 7
  subscribers_count: 5
  topics: []
  updated_at: 1717275053.0
SCOREC/centos7-spack-config:
  data_format: 2
  description: spack config for erp cluster
  filenames:
  - v0190_gcc910/spack.yaml
  - v0201_1/spack.yaml
  full_name: SCOREC/centos7-spack-config
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">centos7-spack-config</h1><a
    id="user-content-centos7-spack-config" class="anchor" aria-label="Permalink: centos7-spack-config"
    href="#centos7-spack-config"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>centos7 spack configuration and scripts</p>

    <div class="markdown-heading"><h2 class="heading-element">contents</h2><a id="user-content-contents"
    class="anchor" aria-label="Permalink: contents" href="#contents"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>compilers.yaml - compiler list

    config.yaml - global config

    install.sh - package installation commands

    modules.yaml - hierarchical layout for lua modules

    packages.yaml - system installed packages

    README.md - this file

    setupSpack.sh - env needed for executing spack commands</p>

    '
  stargazers_count: 1
  subscribers_count: 6
  topics: []
  updated_at: 1696768501.0
SCOREC/dcs-spack-config:
  data_format: 2
  description: Spack config for CCI DCS (AiMOS) system
  filenames:
  - rhel8NvhpcWdmapp/spack.yaml
  full_name: SCOREC/dcs-spack-config
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">dcs-spack-config</h1><a
    id="user-content-dcs-spack-config" class="anchor" aria-label="Permalink: dcs-spack-config"
    href="#dcs-spack-config"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies

    with the IBM XL compilers and Spectrum-MPI.</p>

    <div class="markdown-heading"><h2 class="heading-element">contents</h2><a id="user-content-contents"
    class="anchor" aria-label="Permalink: contents" href="#contents"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>compilers.yaml - compiler list</p>

    <p>config.yaml - global config</p>

    <p>install.sh - package installation commands</p>

    <p>modules.yaml - hierarchical layout for lua modules</p>

    <p>packages.yaml - system installed packages</p>

    <p>README.md - this file</p>

    <p>setupSpack.sh - env needed for executing spack commands</p>

    <p>spack.yaml - list of packages to install</p>

    <div class="markdown-heading"><h2 class="heading-element">setup</h2><a id="user-content-setup"
    class="anchor" aria-label="Permalink: setup" href="#setup"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <pre><code>git clone git@github.com:spack/spack.git spack

    cd !$

    git checkout v0.13.3

    # add the simmetrix-simmodsuite package from the develop branch

    git cherry-pick 5ddf5e2

    # create the environment

    spack env create v0133

    spack env activate v0133

    # copy the yaml files into the v0133

    cp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.

    # copy the compiler yaml file into the spack etc dir

    cp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">install cmake</h2><a
    id="user-content-install-cmake" class="anchor" aria-label="Permalink: install
    cmake" href="#install-cmake"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The bootstrap step of the cmake install fails with the XL compilers.  I

    installed it manually outside of the environment with spack and gcc4.8.5</p>

    <pre><code>spack install cmake%gcc@4.8.5_rhel7

    </code></pre>

    <p>Then added the path to <code>packages.yaml</code>.</p>

    <div class="markdown-heading"><h2 class="heading-element">resuming work in an
    environment</h2><a id="user-content-resuming-work-in-an-environment" class="anchor"
    aria-label="Permalink: resuming work in an environment" href="#resuming-work-in-an-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh

    spack env activate v0133

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633029356.0
SCOREC/pcms:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: SCOREC/pcms
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">PCMS: Parallel
    Coupler For Multimodel Simulations</h1><a id="user-content-pcms-parallel-coupler-for-multimodel-simulations"
    class="anchor" aria-label="Permalink: PCMS: Parallel Coupler For Multimodel Simulations"
    href="#pcms-parallel-coupler-for-multimodel-simulations"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Adios2-based xgc_coupler for XGC and GENE</p>

    <div class="markdown-heading"><h2 class="heading-element">Dependencies</h2><a
    id="user-content-dependencies" class="anchor" aria-label="Permalink: Dependencies"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>CMake 3.19+</li>

    <li>MPI</li>

    <li>FFTW 3.3.8+</li>

    <li>redev 3.0.0+ (<a href="https://github.com/SCOREC/redev">https://github.com/SCOREC/redev</a>)</li>

    <li>Omega_h 10.2.0+ with MPI enabled (<a href="https://github.com/SCOREC/omega_h">https://github.com/SCOREC/omega_h</a>)</li>

    <li>Catch2 2.* (for unit tests) (<a href="https://github.com/catchorg/Catch2/tree/v2.13.8">https://github.com/catchorg/Catch2/tree/v2.13.8</a>)</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Build Instructions</h2><a
    id="user-content-build-instructions" class="anchor" aria-label="Permalink: Build
    Instructions" href="#build-instructions"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">Build with modules</h2><a
    id="user-content-build-with-modules" class="anchor" aria-label="Permalink: Build
    with modules" href="#build-with-modules"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>SCOREC Rhel7 environment</p>

    <pre><code>module unuse /opt/scorec/spack/lmod/linux-rhel7-x86_64/Core

    module use /opt/scorec/spack/v0154_2/lmod/linux-rhel7-x86_64/Core

    module load \

    gcc/10.1.0 \

    mpich \

    cmake/3.20.0 \

    fftw \

    gdb

    </code></pre>

    <p>Build, install, and test</p>

    <pre><code>git clone git@github.com:SCOREC/wdmapp_testcases.git #test data

    git clone git@github.com:SCOREC/wdmapp_coupling.git


    cmake -S wdmapp_coupling -B buildWdmCpl \

    -Dredev_ROOT=/path/to/redev/install \

    -DOmega_h_ROOT=/path/to/omegah/install \

    -DCMAKE_INSTALL_PREFIX=$PWD/buildWdmCpl/install \

    -DPCMS_TEST_DATA_DIR=$PWD/wdmapp_testcases \

    -DCatch2_ROOT=/path/to/catch2/install


    cmake --build buildWdmCpl --target install


    ctest --test-dir buildWdmCpl --output-on-failure

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Spack based build</h2><a
    id="user-content-spack-based-build" class="anchor" aria-label="Permalink: Spack
    based build" href="#spack-based-build"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <ol>

    <li>

    <p>Install spack</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">mkdir
    /lore/<span class="pl-smi">$USER</span>/spack</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> /lore/<span class="pl-smi">$USER</span>/spack</span>

    $ <span class="pl-s1">git clone -c feature.manyFiles=true -b releases/v0.20 https://github.com/spack/spack.git</span>

    $ <span class="pl-s1"><span class="pl-c1">.</span> spack/share/spack/setup-env.sh</span></pre></div>

    <p>We can also add the spack setup line into the <code>~/.bashrc</code> with `echo
    ". spack/share/spack/setup-env.sh" &gt;&gt; ~/.bashrc". This will load the spack
    setup script every time we start our terminal session.</p>

    </li>

    <li>

    <p>Get PCMS spack repo

    The following commands will add the pcms recipe files to spack. They are not currently
    installed inthe upstream spack repository.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">git
    clone https://github.com/jacobmerson/pcms-spack.git</span>

    $ <span class="pl-s1">spack repo add pcms-spack/pcms</span></pre></div>

    </li>

    <li>

    <p>Add Spack binary mirror

    Addding the binary mirrors will avoid some compilation by downloading prebuilt
    binaries when available.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">spack
    mirror add v0.20.1 https://binaries.spack.io/v0.20.1</span>

    $ <span class="pl-s1">spack buildcache keys --install --trust</span></pre></div>

    </li>

    <li>

    <p>Install PCMS repo</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">mkdir
    /lore/<span class="pl-smi">$USER</span>/pcms-coupler</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> /lore/<span class="pl-smi">$USER</span>/pcms-coupler</span>

    $ <span class="pl-s1">git clone -b pcms-spack https://github.com/jacobmerson/pcms</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> pcms/spack</span>

    $ <span class="pl-s1">spack env create -d env spack.yaml</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> env</span>

    $ <span class="pl-s1">spack env activate <span class="pl-c1">.</span></span>

    $ <span class="pl-s1">spack install</span></pre></div>

    </li>

    </ol>

    <p>At this point hopefully, spack will now install all of the relavant dependencies
    and a baseline build of PCMS. The default environment has PCMS in develop mode.
    To modify and recompile PCMS you can modify the code and rerun <code>spack install</code>.</p>

    <div class="markdown-heading"><h3 class="heading-element">BUILD TODO</h3><a id="user-content-build-todo"
    class="anchor" aria-label="Permalink: BUILD TODO" href="#build-todo"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>create a spack environment that''s part of this project that can build the
    whole stack.

    most of the pieces are in place for this, but it will require createing a package
    for redev

    and of the SCOREC version of Omega_h

    <ul>

    <li>scorec version 10.1.0 of Omega_h is in spack@develop

    <a href="https://github.com/spack/spack/blob/8ddaa08ed2aacb4b5e587a33c625492cbdd4886e/var/spack/repos/builtin/packages/omega-h/package.py#L21">https://github.com/spack/spack/blob/8ddaa08ed2aacb4b5e587a33c625492cbdd4886e/var/spack/repos/builtin/packages/omega-h/package.py#L21</a>

    </li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 2
  subscribers_count: 19
  topics: []
  updated_at: 1681842553.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.13.2/spack.yaml
  - v0.20.1/v4/spack.yaml
  - v0.15.4/spack.yaml
  - v0.20.1/v1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">setup on\
    \ SCOREC</h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-label=\"\
    Permalink: setup on SCOREC\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">rhel7-spack-config</h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-label=\"Permalink: rhel7-spack-config\" href=\"#rhel7-spack-config\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>rhel7 spack configuration and scripts</p>\n<p>The <code>install.sh</code> script\
    \ maintained in this repo is for documentation purposes (e.g., in case we had\
    \ to reinstall the entire stack from scratch) and should not be executed as it\
    \ will not use all of our existing package installs.  More discussion of package\
    \ installation is below.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >useful commands</h2><a id=\"user-content-useful-commands\" class=\"anchor\" aria-label=\"\
    Permalink: useful commands\" href=\"#useful-commands\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>regenerate lmod module\
    \ tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">installing new packages</h2><a\
    \ id=\"user-content-installing-new-packages\" class=\"anchor\" aria-label=\"Permalink:\
    \ installing new packages\" href=\"#installing-new-packages\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Our spack repo is\
    \ tracking the master spack branch.  Spack package updates could result in additional\
    \ installation of packages with little or no package source code changes.  These\
    \ additional installs can be avoided when installing new packages by first examining\
    \ the output of the <code>spack spec -I</code> command.  If a utility/infrastructure\
    \ level package, such as cmake or mpich, is marked with a <code>[+]</code> symbol\
    \ in the leftmost column then it means that the existing install will be used.\
    \  If spack does not default to using the existing install you can append the\
    \ hash of the package to the spec command.</p>\n<p>For example, lets see what\
    \ happens when we ask for a pumi install using gcc 7.3.0</p>\n<pre><code>$ spack\
    \ spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">contents</h2><a\
    \ id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: contents\"\
    \ href=\"#contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>compilers.yaml - compiler list\nconfig.yaml - global config\n\
    install.sh - package installation commands\nmodules.yaml - hierarchical layout\
    \ for lua modules\npackages.yaml - system installed packages\nREADME.md - this\
    \ file\nsetupSpack.sh - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1683174256.0
SCOREC/rhel9-spack-config:
  data_format: 2
  description: RHEL9 spack configuration files
  filenames:
  - v0.20.1_4/spack.yaml
  full_name: SCOREC/rhel9-spack-config
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">rhel9-spack-config</h1><a
    id="user-content-rhel9-spack-config" class="anchor" aria-label="Permalink: rhel9-spack-config"
    href="#rhel9-spack-config"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>RHEL9 spack configuration files</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1716340967.0
TauferLab/Src_DYAD_UCX_Perftest:
  data_format: 2
  description: null
  filenames:
  - spack_env/spack.yaml
  full_name: TauferLab/Src_DYAD_UCX_Perftest
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">DYAD UCX Perftest</h1><a
    id="user-content-dyad-ucx-perftest" class="anchor" aria-label="Permalink: DYAD
    UCX Perftest" href="#dyad-ucx-perftest"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>This repo contains a testbed performance tester for the integration of UCX
    into DYAD.

    It provides us an easy-to-edit codebase for testing implementations and configurations
    of the integration.</p>

    <div class="markdown-heading"><h2 class="heading-element">Installing Dependencies</h2><a
    id="user-content-installing-dependencies" class="anchor" aria-label="Permalink:
    Installing Dependencies" href="#installing-dependencies"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Most of the performance tester''s dependencies are provided as git submodules.
    So, the first step to installing

    the tester''s dependencies is to run:</p>

    <div class="highlight highlight-source-shell"><pre>$ git submodule update --init
    --recursive</pre></div>

    <p>However, there are a few dependencies that are not submodules. For these, a
    <code>spack.yaml</code> file has been provided

    to allow the rest of the dependencies to be easily built.</p>

    <p>Finally, there are a couple of optional Python dependencies needed to run the
    code in the <code>analysis</code> directory.

    These dependencies can be installed using the Conda environment file (<code>environment.yml</code>)
    provided in the root of the repo.</p>

    <div class="markdown-heading"><h2 class="heading-element">Building the Performance
    Tester</h2><a id="user-content-building-the-performance-tester" class="anchor"
    aria-label="Permalink: Building the Performance Tester" href="#building-the-performance-tester"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The performance tester uses a standard CMake build and install process. So,
    the tester can be built and installed using:</p>

    <div class="highlight highlight-source-shell"><pre>$ mkdir build

    $ <span class="pl-c1">cd</span> build

    $ cmake -DCMAKE_INSTALL_PREFIX=<span class="pl-k">&lt;</span>install prefix<span
    class="pl-k">&gt;</span> ..

    $ make [-j]

    $ make install</pre></div>

    <div class="markdown-heading"><h2 class="heading-element">Running the Performance
    Tester</h2><a id="user-content-running-the-performance-tester" class="anchor"
    aria-label="Permalink: Running the Performance Tester" href="#running-the-performance-tester"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The performance tester executable (<code>dyad_ucx_perftest</code>) mimics the
    client-server design of DYAD.</p>

    <p>To run the tester, first, use the scheduler on your system to get a two node
    allocation. One node will

    be used to run the server, while the other node is used to run the client.</p>

    <p>To launch the server on the first node, run:</p>

    <div class="highlight highlight-source-shell"><pre>$ ./dyad_ucx_perftest <span
    class="pl-k">&lt;</span>mode<span class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>ip_addr<span
    class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>data_size<span class="pl-k">&gt;</span>
    -s</pre></div>

    <p>In the above command, <code>mode</code> can be one of the following:</p>

    <ul>

    <li>

    <code>tag</code>: use tag-matching send/recv from UCX</li>

    </ul>

    <p>Additionally, <code>ip_addr</code> is the IP address and port to be used by
    the server. Finally, <code>data_size</code> is the size

    of data to be transferred in bytes.</p>

    <p>After launching the server, launch the client on the other node using:</p>

    <div class="highlight highlight-source-shell"><pre>$ ./dyad_ucx_perftest <span
    class="pl-k">&lt;</span>mode<span class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>ip_addr<span
    class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>data_size<span class="pl-k">&gt;</span>
    -n <span class="pl-k">&lt;</span>num_iters<span class="pl-k">&gt;</span></pre></div>

    <p>The three positional arguments passed to the client invocation of <code>dyad_ucx_perftest</code>
    should be the same

    as the ones passed to the server. The additional <code>num_iters</code> argumennt
    specifies the number of iterations

    the client should run for. This is equivalent to the number of data transfers
    that will occur.</p>

    <div class="markdown-heading"><h2 class="heading-element">Profiling/Tracing the
    Run with Caliper</h2><a id="user-content-profilingtracing-the-run-with-caliper"
    class="anchor" aria-label="Permalink: Profiling/Tracing the Run with Caliper"
    href="#profilingtracing-the-run-with-caliper"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>To evaluate the performance of the UCX integration, this tester is annotated
    with Caliper. To enable the Caliper

    annotations at runtime, a Caliper configuration must be provided via the <code>CALI_CONFIG</code>
    environment variable.

    The recommended minimum configuration is:</p>

    <div class="highlight highlight-source-shell"><pre>CALI_CONFIG=<span class="pl-s"><span
    class="pl-pds">"</span>event-trace,output=&lt;client | server&gt;.cali</span></pre></div>

    <p>This configuration will generate a Caliper trace of the client or server and
    dump the results into <code>client.cali</code>

    or <code>server.cali</code>, depending on the value passed to <code>output</code>.
    Additional configuration options can be found

    in the <a href="https://software.llnl.gov/Caliper/BuiltinConfigurations.html"
    rel="nofollow">Caliper docs</a>.</p>

    <p>To analyze this profile/trace data, a playground Jupyter notebook is provided
    in the <code>analysis</code> directory.

    This notebook leverages LLNL''s <a href="https://thicket.readthedocs.io/en/latest/"
    rel="nofollow">Thicket tool</a> for analysis of the profiles/traces.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1701372320.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/runner/_archived/ubuntu22.04-amd64-oneapi-2023.2.1/spack.yaml
  - docker-recipes/runner/ubuntu24.04-arm64-gcc-13.2/spack.yaml
  - docker-recipes/runner/_archived/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/_archived/ubuntu22.04-amd64-oneapi-2024.0.0/spack.yaml
  - docker-recipes/runner/_archived/ubuntu20.04-x86_64-gcc-11.2/spack.yaml
  - docker-recipes/runner/_archived/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/archived/rhel7-runner-x86_64/spack.yaml
  - docker-recipes/runner/_archived/ubuntu20.04-x86_64-gcc-11.4-spack/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/archived/special/superlu-sc/spack.yaml
  - docker-recipes/runner/ubuntu24.04-amd64-gcc-13.2/spack.yaml
  - docker-recipes/runner/alinux2023-arm64-gcc-11.4/spack.yaml
  - docker-recipes/runner/_archived/ubuntu20.04-amd64-clang-16/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 18
  subscribers_count: 7
  topics: []
  updated_at: 1713540039.0
ai2cm/fv3net:
  data_format: 2
  description: explore the FV3 data for parameterization
  filenames:
  - docker/ufs_utils/spack.yaml
  full_name: ai2cm/fv3net
  latest_release: release/cyclegan_initial
  readme: '<div class="markdown-heading"><h1 class="heading-element">fv3net</h1><a
    id="user-content-fv3net" class="anchor" aria-label="Permalink: fv3net" href="#fv3net"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://circleci.com/gh/ai2cm/fv3net/tree/master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/b3e080c75d8b7187fbfaeb6a0e44426f4b4ce818305d3917a4334f4e5970b14c/68747470733a2f2f636972636c6563692e636f6d2f67682f616932636d2f6676336e65742f747265652f6d61737465722e7376673f7374796c653d737667"
    alt="CircleCI" data-canonical-src="https://circleci.com/gh/ai2cm/fv3net/tree/master.svg?style=svg"
    style="max-width: 100%;"></a></p>

    <p>Improving the GFDL FV3 model physics with machine learning. See the <a href="https://vulcanclimatemodeling.com/docs/fv3net/"
    rel="nofollow">documentation</a> for more information on using this suite of tools.</p>

    <p>Disclaimer: This is a work in progress.</p>

    '
  stargazers_count: 16
  subscribers_count: 11
  topics: []
  updated_at: 1712113720.0
alec-glisman/Simulation-Two-Chain-PAA:
  data_format: 2
  description: Simulate interactions between two fully-charged PAA chains with varying
    amounts of CaCl2 added
  filenames:
  - software/requirements/spack/spack.yaml
  full_name: alec-glisman/Simulation-Two-Chain-PAA
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Simulation\
    \ Two Chain PAA</h1><a id=\"user-content-simulation-two-chain-paa\" class=\"anchor\"\
    \ aria-label=\"Permalink: Simulation Two Chain PAA\" href=\"#simulation-two-chain-paa\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><strong>Summary:</strong> PLUMED-patched GROMACS molecular dynamics simulations\
    \ repository used for studying the multi-valent ion mediated interactions between\
    \ two polyanions.<br>\n<strong>Authors:</strong> <a href=\"https://github.com/alec-glisman\"\
    >Alec Glisman</a>, <a href=\"https://github.com/sritejamantha\">Sriteja Mantha</a><br>\n\
    <strong>GitHub actions:</strong>\n<a href=\"https://github.com/alec-glisman/Simulation-Two-Chain-PAA/actions/workflows/code-linting.yml\"\
    ><img src=\"https://github.com/alec-glisman/Simulation-Two-Chain-PAA/actions/workflows/code-linting.yml/badge.svg\"\
    \ alt=\"Linting\" style=\"max-width: 100%;\"></a><br>\n<strong>Third-party services:</strong>\n\
    <a href=\"https://wakatime.com/badge/github/alec-glisman/gromacs\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/a8ec8d5b31066076b6c84091c24462d94a35caf7c07a73038ec3b54b9a94d123/68747470733a2f2f77616b6174696d652e636f6d2f62616467652f6769746875622f616c65632d676c69736d616e2f67726f6d6163732e737667\"\
    \ alt=\"wakatime\" data-canonical-src=\"https://wakatime.com/badge/github/alec-glisman/gromacs.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Project structure</h2><a id=\"user-content-project-structure\"\
    \ class=\"anchor\" aria-label=\"Permalink: Project structure\" href=\"#project-structure\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Each subdirectory contains its own <code>README.md</code> file with more detailed\
    \ information about the project.\nWe present a brief summary of each subdirectory\
    \ below, but strongly recommend that users read the other documentation for a\
    \ better idea of how to use the code.</p>\n<p>The project contains many configuration\
    \ and styling files for various tools, including:</p>\n<ul>\n<li>\n<a href=\"\
    ./.github/READ.md\"><code>.github/</code></a>: GitHub workflows and issue templates\
    \ directory.</li>\n<li>\n<a href=\"./.vscode/README.md\"><code>.vscode/</code></a>:\
    \ Visual Studio Code editor settings and configuration directory.</li>\n<li>\n\
    <code>.clang-format</code>: Clang-format configuration file for C++ code.</li>\n\
    <li>\n<code>.pylintrc</code>: Pylint configuration file for Python code.</li>\n\
    <li>\n<code>.shellcheckrc</code>: ShellCheck configuration file for shell scripts.</li>\n\
    <li>\n<code>.wakatime-project</code>: Wakatime configuration file for time tracking.</li>\n\
    <li>\n<code>CITATIONS.md</code>: List of citations for the project.</li>\n<li>\n\
    <code>LICENSE</code>: Project license file.</li>\n</ul>\n<p>The molecular dynamics\
    \ simulations are contained in the following subdirectories:</p>\n<ul>\n<li>\n\
    <a href=\"./data/README.md\"><code>data</code></a>: Data files output from simulation.</li>\n\
    <li>\n<a href=\"./force-field/README.md\"><code>force-fields</code></a>: Force\
    \ fields in GROMACS format used to model various system components.</li>\n<li>\n\
    <a href=\"./intial-structure/README.md\"><code>initial-structure</code></a>: Energy\
    \ minimized initial structures for polyelectrolytes and crystalline lattices.</li>\n\
    <li>\n<a href=\"./parameters/README.md\"><code>parameters</code></a>: GROMACS\
    \ mdp parameter files and simulation pipeline input variables.</li>\n<li>\n<a\
    \ href=\"./python/README.md\"><code>python</code></a>: Helper Python scripts called\
    \ by the simulation pipeline.</li>\n<li>\n<a href=\"./scripts/README.md\"><code>scripts</code></a>:\
    \ Bash scripts used to run simulations and analyze data output using GROMACS and\
    \ PLUMED command line interface tools.</li>\n<li>\n<a href=\"./software/README.md\"\
    ><code>software</code></a>: GROMACS and PLUMED source code and build scripts as\
    \ well as environment configuration files.</li>\n<li>\n<a href=\"./submission/README.md\"\
    ><code>submission</code></a>: Slurm job submission scripts used to run simulations\
    \ on the group's HPC cluster.</li>\n</ul>\n<div class=\"markdown-heading\"><h3\
    \ class=\"heading-element\">Configuration</h3><a id=\"user-content-configuration\"\
    \ class=\"anchor\" aria-label=\"Permalink: Configuration\" href=\"#configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Various formatting files are included (<code>.clang-format</code>, <code>.pylintrc</code>,\
    \ and <code>.shelcheckrc</code>) to ensure consistent code formatting and style.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Software and environment</h2><a\
    \ id=\"user-content-software-and-environment\" class=\"anchor\" aria-label=\"\
    Permalink: Software and environment\" href=\"#software-and-environment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Further\
    \ information on exact software versions can be found in the <code>software</code>\
    \ directory's <a href=\"software/README.md\"><code>README.md</code></a> file.\n\
    We run our simulations using</p>\n<ul>\n<li>Bash 5.1.16</li>\n<li>CMake 3.22.1</li>\n\
    <li>CUDA 11.8</li>\n<li>GCC 10.4.0</li>\n<li>Gromacs 2022.3 (Plumed patched and\
    \ user patched <code>share/top/residuetypes.dat</code>)</li>\n<li>Plumed 2.8.1</li>\n\
    <li>Packmol 20.010</li>\n<li>Python 3.10.6</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Nomenclature</h2><a id=\"user-content-nomenclature\"\
    \ class=\"anchor\" aria-label=\"Permalink: Nomenclature\" href=\"#nomenclature\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Chemistry</h3><a\
    \ id=\"user-content-chemistry\" class=\"anchor\" aria-label=\"Permalink: Chemistry\"\
    \ href=\"#chemistry\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<ul>\n<li>Acr: Acrylic acid</li>\n<li>P: Poly, as in polymer</li>\n\
    <li>mer: Monomer</li>\n</ul>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Numerical</h3><a id=\"user-content-numerical\" class=\"anchor\" aria-label=\"\
    Permalink: Numerical\" href=\"#numerical\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<ul>\n<li>EM: Energy minimization</li>\n\
    </ul>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\">Statistical\
    \ mechanics</h3><a id=\"user-content-statistical-mechanics\" class=\"anchor\"\
    \ aria-label=\"Permalink: Statistical mechanics\" href=\"#statistical-mechanics\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>NVE: Microcanonical ensemble</li>\n<li>NVT: Canonical ensemble</li>\n\
    <li>NPT: Isothermal\u2013isobaric ensemble</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics:
  - gromacs
  - molecular-dynamics
  - plumed
  - polymer
  - shell-script
  updated_at: 1708562259.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent7/python_376/spack.yaml
  - cent8/envs/avx/rproject/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">SPACK Environments</h1><a
    id="user-content-spack-environments" class="anchor" aria-label="Permalink: SPACK
    Environments" href="#spack-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <div class="markdown-heading"><h2 class="heading-element">Software deployment
    for CentOS 8.x</h2><a id="user-content-software-deployment-for-centos-8x" class="anchor"
    aria-label="Permalink: Software deployment for CentOS 8.x" href="#software-deployment-for-centos-8x"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <div class="markdown-heading"><h3 class="heading-element">Compilers</h3><a id="user-content-compilers"
    class="anchor" aria-label="Permalink: Compilers" href="#compilers"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <div class="markdown-heading"><h3 class="heading-element">LU Software</h3><a id="user-content-lu-software"
    class="anchor" aria-label="Permalink: LU Software" href="#lu-software"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <div class="markdown-heading"><h4 class="heading-element">Available Environments</h4><a
    id="user-content-available-environments" class="anchor" aria-label="Permalink:
    Available Environments" href="#available-environments"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h5 class="heading-element">solhawk</h5><a id="user-content-solhawk"
    class="anchor" aria-label="Permalink: solhawk" href="#solhawk"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <div class="markdown-heading"><h4 class="heading-element">avx/avx2/avx512</h4><a
    id="user-content-avxavx2avx512" class="anchor" aria-label="Permalink: avx/avx2/avx512"
    href="#avxavx2avx512"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <div class="markdown-heading"><h4 class="heading-element">Python and R packages</h4><a
    id="user-content-python-and-r-packages" class="anchor" aria-label="Permalink:
    Python and R packages" href="#python-and-r-packages"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <div class="markdown-heading"><h4 class="heading-element">x86_64</h4><a id="user-content-x86_64"
    class="anchor" aria-label="Permalink: x86_64" href="#x86_64"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <div class="markdown-heading"><h2 class="heading-element">CentOS 7.x software</h2><a
    id="user-content-centos-7x-software" class="anchor" aria-label="Permalink: CentOS
    7.x software" href="#centos-7x-software"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657632897.0
aminaramoon/config:
  data_format: 2
  description: null
  filenames:
  - packages/spack.yaml
  full_name: aminaramoon/config
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1673135222.0
aparnasasidharan2017/H5Apps:
  data_format: 2
  description: null
  filenames:
  - openpmd/.github/ci/spack-envs/clang14_py311_nompi_h5_ad1_ad2/spack.yaml
  full_name: aparnasasidharan2017/H5Apps
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1705613269.0
apt-sim/AdePT:
  data_format: 2
  description: Accelerated demonstrator of electromagnetic Particle Transport
  filenames:
  - scripts/spack.yaml
  full_name: apt-sim/AdePT
  latest_release: null
  readme: "\n<div class=\"markdown-heading\"><h1 class=\"heading-element\">AdePT</h1><a\
    \ id=\"user-content-adept\" class=\"anchor\" aria-label=\"Permalink: AdePT\" href=\"\
    #adept\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Accelerated demonstrator of electromagnetic Particle Transport</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Build Requirements</h2><a id=\"\
    user-content-build-requirements\" class=\"anchor\" aria-label=\"Permalink: Build\
    \ Requirements\" href=\"#build-requirements\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>The following packages are a required\
    \ to build and run:</p>\n<ul>\n<li>CMake &gt;= 3.18</li>\n<li>C/C++ Compiler with\
    \ C++14 support</li>\n<li>CUDA Toolkit (tested 10.1, min version TBD)</li>\n<li>VecCore\
    \ <a href=\"https://github.com/root-project/veccore\">library</a> 0.7.0 (recommended,\
    \ but older versions &gt;= 0.5.0 also work)</li>\n<li>VecGeom <a href=\"https://gitlab.cern.ch/VecGeom/VecGeom\"\
    \ rel=\"nofollow\">library</a> &gt;= 1.1.20</li>\n<li>G4HepEM <a href=\"https://github.com/mnovak42/g4hepem\"\
    >library</a>\n</li>\n</ul>\n<p>A suitable environment may be set up either from\
    \ CVMFS (requires the sft.cern.ch and projects.cern.ch repos\nto be available\
    \ on the local system):</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\">source</span> /cvmfs/sft.cern.ch/lcg/views/devAdePT/latest/x86_64-centos7-gcc11-opt/setup.sh</span></pre></div>\n\
    <p>or from the supplied <a href=\"https://spack.io\" rel=\"nofollow\">spack</a>\
    \ environment file:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack env create adept-spack ./scripts/spack.yaml</span>\n\
    $ <span class=\"pl-s1\">spack -e adept-spack concretize -f</span>\n$ <span class=\"\
    pl-s1\">spack -e adept-spack install</span>\n<span class=\"pl-c1\">...</span>\n\
    $ <span class=\"pl-s1\">spack env activate -p adept-spack</span></pre></div>\n\
    <p>Note that the above assumes your spack configuration defaults to use a suitable\
    \ C++ compiler and has\n<code>cuda_arch</code> set appropriately for the hardware\
    \ you will be running on.</p>\n<p>You can also build the packages manually as\
    \ follows. To configure and build VecCore, simply run:</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">cmake -S. -B./veccore-build\
    \ -DCMAKE_INSTALL_PREFIX=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;path_to_veccore_installation&gt;<span\
    \ class=\"pl-pds\">\"</span></span></span>\n$ <span class=\"pl-s1\">cmake --build\
    \ ./veccore-build --target install</span></pre></div>\n<p>Add your CUDA installation\
    \ to the PATH and LD_LIBRARY_PATH environment variables, as in:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"\
    pl-k\">export</span> PATH=<span class=\"pl-smi\">${PATH}</span>:/usr/local/cuda/bin</span>\n\
    $ <span class=\"pl-s1\"><span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span\
    \ class=\"pl-smi\">${LD_LIBRARY_PATH}</span>:/usr/local/cuda/lib64</span></pre></div>\n\
    <p>Find the CUDA architecture for the target GPU. If you installed the CUDA demo\
    \ suite, the fastest way is to use the deviceQuery executable from <code>extras/demo_suite</code>.\
    \ This lists the CUDA capability for all installed GPUs, remember the value for\
    \ your target:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$\
    \ <span class=\"pl-s1\">/usr/local/cuda/extras/demo_suite/deviceQuery</span>\n\
    <span class=\"pl-c1\">Device 0: \"GeForce RTX 2080 SUPER\"</span>\n<span class=\"\
    pl-c1\">  CUDA Capability Major/Minor version number:    7.5 (cuda_architecture=75)</span>\n\
    <span class=\"pl-c1\">...</span>\n<span class=\"pl-c1\">Device 1: \"Quadro K4200\"\
    </span>\n<span class=\"pl-c1\">  CUDA Capability Major/Minor version number: \
    \   3.0 (cuda_architecture=30)</span></pre></div>\n<p>To configure and build VecGeom,\
    \ use the configuration options below, using as &lt;cuda_architecture&gt; the\
    \ value from the step above:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">cmake -S. -B./vecgeom-build \\</span>\n<span class=\"\
    pl-c1\">  -DCMAKE_INSTALL_PREFIX=\"&lt;path_to_vecgeom_installation&gt;\" \\</span>\n\
    <span class=\"pl-c1\">  -DCMAKE_PREFIX_PATH=\"&lt;path_to_veccore_installation&gt;\"\
    \ \\</span>\n<span class=\"pl-c1\">  -DVECGEOM_ENABLE_CUDA=ON \\</span>\n<span\
    \ class=\"pl-c1\">  -DVECGEOM_GDML=ON \\</span>\n<span class=\"pl-c1\">  -DBACKEND=Scalar\
    \ \\</span>\n<span class=\"pl-c1\">  -DCMAKE_CUDA_ARCHITECTURES=&lt;cuda_architecture&gt;\
    \ \\</span>\n<span class=\"pl-c1\">  -DVECGEOM_USE_NAVINDEX=ON \\</span>\n<span\
    \ class=\"pl-c1\">  -DCMAKE_BUILD_TYPE=Release</span>\n$ <span class=\"pl-s1\"\
    >cmake --build ./vecgeom-build --target install -- -j6 <span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span>## build using 6 threads and install</span></span></pre></div>\n\
    <p>To configure and build G4HepEM, use the configuration options below:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >cmake -S. -B./g4hepem-build \\</span>\n<span class=\"pl-c1\">  -DCMAKE_INSTALL_PREFIX=\"\
    &lt;path_to_g4hepem_installation&gt;\" \\</span>\n<span class=\"pl-c1\">  -DCMAKE_PREFIX_PATH=\"\
    &lt;path_to_geant4_installation&gt;\" \\</span>\n<span class=\"pl-c1\">  -DG4HepEm_CUDA_BUILD=ON</span>\n\
    $ <span class=\"pl-s1\">cmake --build ./g4hepem-build --target install -- -j6\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span>## build using 6 threads and\
    \ install</span></span></pre></div>\n<p>To configure AdePT, simply run:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >cmake -S. -B./adept-build <span class=\"pl-k\">&lt;</span>otherargs<span class=\"\
    pl-k\">&gt;</span></span></pre></div>\n<p>As  one needs to provide the paths to\
    \ the dependence libraries VecCore, VecGeom and G4HepEM</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre><span class=\"pl-c1\">   -DCMAKE_PREFIX_PATH=\"\
    &lt;path_to_veccore_installation&gt;;&lt;path_to_vecgeom_installation&gt;;&lt;path_to_g4hepem_installation&gt;\"\
    \ \\</span>\n<span class=\"pl-c1\">   -DCMAKE_CUDA_ARCHITECTURES=&lt;cuda_architecture&gt;\
    \ \\</span>\n<span class=\"pl-c1\">   -DCMAKE_BUILD_TYPE=Release</span></pre></div>\n\
    <p>To build, run:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$\
    \ <span class=\"pl-s1\">cmake --build ./adept-build -- -j6 <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>## build using 6 threads</span></span></pre></div>\n\
    <p>The provided examples and tests can be run from the build directory:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    ><span class=\"pl-c1\">cd</span> adept-build</span>\n$ <span class=\"pl-s1\">CUDA_VISIBLE_DEVICES=0\
    \ BuildProducts/bin/<span class=\"pl-k\">&lt;</span>executable<span class=\"pl-k\"\
    >&gt;</span>   <span class=\"pl-c\"><span class=\"pl-c\">#</span>## use the device\
    \ number matching the selected &lt;cuda_architecture&gt;</span></span></pre></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Including AdePT\
    \ in other CMake projects</h2><a id=\"user-content-including-adept-in-other-cmake-projects\"\
    \ class=\"anchor\" aria-label=\"Permalink: Including AdePT in other CMake projects\"\
    \ href=\"#including-adept-in-other-cmake-projects\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>In order to include AdePT\
    \ in a separate project we need to run:</p>\n<pre><code>find_package(AdePT)\n\
    </code></pre>\n<p>Which has the same dependencies as before (VecGeom, VecCore\
    \ and G4HepEM).</p>\n<p>Then, for the targets using AdePT:</p>\n<pre><code>target_include_directories(example_target\
    \ &lt;SCOPE&gt; \n                          &lt;TARGET INCLUDE DIRECTORIES&gt;\n\
    \                          ${AdePT_INCLUDE_DIRS})\n\ntarget_link_libraries(example_target\
    \ &lt;SCOPE&gt;\n                      &lt;TARGET LINK LIBRARIES&gt;\n       \
    \               ${AdePT_LIBRARIES})\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Copyright</h2><a id=\"user-content-copyright\"\
    \ class=\"anchor\" aria-label=\"Permalink: Copyright\" href=\"#copyright\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>AdePT\
    \ code is Copyright (C) CERN, 2020, for the benefit of the AdePT project.\nAny\
    \ other code in the project has (C) and license terms clearly indicated.</p>\n\
    <p>Contributions of all authors to AdePT and their institutes are acknowledged\
    \ in\nthe <code>AUTHORS.md</code> file.</p>\n"
  stargazers_count: 24
  subscribers_count: 10
  topics: []
  updated_at: 1717056041.0
boutproject/BOUT-configs:
  data_format: 2
  description: Configuration scripts for BOUT++
  filenames:
  - lassen/spack_env/bout_petsc_with_hypre/spack.yaml
  - lassen/spack_env/bout/spack.yaml
  full_name: boutproject/BOUT-configs
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Configuration\
    \ scripts</h1><a id=\"user-content-configuration-scripts\" class=\"anchor\" aria-label=\"\
    Permalink: Configuration scripts\" href=\"#configuration-scripts\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>This repo contains\
    \ scripts to setup the environment and provide build\nconfigurations for BOUT++\
    \ on deployment machines.</p>\n<p>There is one sub-directory for each machine\
    \ (\"cori\", \"lassen\", \"perlmutter\").\nSee the README of each sub-directory\
    \ for machine specific instructions.</p>\n<p>The repo includes <code>spack</code>\
    \ (release v0.21.1) as a submodule, used to create\nreproducible, self-contained\
    \ environments on different machines.</p>\n<p>\U0001F6A7 This repo is under active\
    \ development, <code>perlmutter</code> configuration\nis in a stable state, other\
    \ machines are under update.\nIssues and PRs to <code>main</code> are welcome.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Usage</h2><a id=\"\
    user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Clone the repo and initialize submodules</p>\n<pre><code>git clone --recurse-submodules\
    \ https://github.com/boutproject/BOUT-configs.git\n</code></pre>\n<p>Enter the\
    \ machine sub-directory desired and follow the instructions.\nTypical usage is\
    \ to <code>source setup-env.sh</code> to activate the spack enviroment,\nwhich\
    \ will install any needed software dependencies through <code>spack</code>, and\n\
    configure BOUT++ using either scripts under the machine's <code>scripts</code>\
    \ directory\nor with the user's own configuration.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Contact</h2><a id=\"user-content-contact\" class=\"\
    anchor\" aria-label=\"Permalink: Contact\" href=\"#contact\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Feel free to contact\
    \ Giorgis Georgakoudis <a href=\"mailto:georgakoudis1@llnl.gov\">georgakoudis1@llnl.gov</a>\
    \ for comments,\nsuggestions, or questions.</p>\n"
  stargazers_count: 3
  subscribers_count: 19
  topics: []
  updated_at: 1713918248.0
buildtesters/buildtest:
  data_format: 2
  description: HPC System and Software Testing Framework
  filenames:
  - examples/spack/example/spack.yaml
  full_name: buildtesters/buildtest
  latest_release: v2.0
  stargazers_count: 65
  subscribers_count: 7
  topics:
  - test-automation
  - testing-framework
  - yaml
  - system-testing
  - hpc
  - json-schema
  - buildtest
  updated_at: 1716557795.0
celeritas-project/celeritas:
  data_format: 2
  description: Celeritas is a new Monte Carlo transport code designed to accelerate
    scientific discovery in high energy physics by improving detector simulation throughput
    and energy efficiency using GPUs.
  filenames:
  - scripts/spack.yaml
  - scripts/ci/spack.yaml
  full_name: celeritas-project/celeritas
  latest_release: v0.4.3
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Celeritas</h1><a\
    \ id=\"user-content-celeritas\" class=\"anchor\" aria-label=\"Permalink: Celeritas\"\
    \ href=\"#celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The Celeritas project implements HEP detector physics on\
    \ GPU accelerator\nhardware with the ultimate goal of supporting the massive computational\n\
    requirements of the <a href=\"https://home.cern/science/accelerators/high-luminosity-lhc\"\
    \ rel=\"nofollow\">HL-LHC upgrade</a>.</p>\n<div class=\"markdown-heading\"><h1\
    \ class=\"heading-element\">Documentation</h1><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Most of the Celeritas documentation is readable through the codebase through\
    \ a\ncombination of <a href=\"doc/index.rst\">static RST documentation</a> and\
    \ Doxygen-markup\ncomments in the source code itself. The full <a href=\"https://celeritas-project.github.io/celeritas/user/index.html\"\
    \ rel=\"nofollow\">Celeritas user\ndocumentation</a> (including selected code\
    \ documentation incorporated\nby Breathe) and the <a href=\"https://celeritas-project.github.io/celeritas/dev/index.html\"\
    \ rel=\"nofollow\">Celeritas code documentation</a> are mirrored on\nour GitHub\
    \ pages site. You can generate these yourself (if the necessary\nprerequisites\
    \ are installed) by\nsetting the <code>CELERITAS_BUILD_DOCS=ON</code> configuration\
    \ option and running <code>ninja doc</code> (user) or <code>ninja doxygen</code>\
    \ (developer). A continuously updated version of\nthe <a href=\"https://celeritas.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">static Celeritas user documentation</a> (without API documentation)\
    \ is\nhosted on <code>readthedocs.io</code>.</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Installation for applications</h1><a id=\"user-content-installation-for-applications\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation for applications\" href=\"\
    #installation-for-applications\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The easiest way to install Celeritas as a library/app is\
    \ with Spack:</p>\n<ul>\n<li>Follow the first two steps above to install <a href=\"\
    https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"nofollow\"\
    >Spack</a> and set up its CUDA usage.</li>\n<li>Install Celeritas with <code>spack\
    \ install celeritas</code>\n</li>\n<li>Use <code>spack load celeritas</code> to\
    \ add the installation to your <code>PATH</code>.</li>\n</ul>\n<p>Then see the\
    \ \"Downstream usage as a library\" section of the <a href=\"doc/main/installation.rst\"\
    >installation\ndocumentation</a> for how to use Celeritas in your application\
    \ or framework.</p>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Installation for developers</h1><a id=\"user-content-installation-for-developers\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation for developers\" href=\"\
    #installation-for-developers\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Since Celeritas is still under heavy development and is\
    \ not yet full-featured\nfor downstream integration, you are likely installing\
    \ it for development\npurposes. The <a href=\"doc/main/installation.rst\">installation\
    \ documentation</a> has a\ncomplete description of the code's dependencies and\
    \ installation process for\ndevelopment.</p>\n<p>As an example, if you have the\
    \ <a href=\"https://github.com/spack/spack\">Spack</a> package manager\ninstalled\
    \ and want to do development on a CUDA system with Volta-class graphics\ncards,\
    \ execute the following steps from within the cloned Celeritas source\ndirectory:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre># <span class=\"pl-s1\"\
    >Set up CUDA (optional)</span>\n$ <span class=\"pl-s1\">spack external find cuda</span>\n\
    # <span class=\"pl-s1\">Install celeritas dependencies</span>\n$ <span class=\"\
    pl-s1\">spack env create celeritas scripts/spack.yaml</span>\n$ <span class=\"\
    pl-s1\">spack env activate celeritas</span>\n$ <span class=\"pl-s1\">spack config\
    \ add packages:all:variants:<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cxxstd=17\
    \ +cuda cuda_arch=70<span class=\"pl-pds\">\"</span></span></span>\n$ <span class=\"\
    pl-s1\">spack install</span>\n# <span class=\"pl-s1\">Configure, build, and <span\
    \ class=\"pl-c1\">test</span></span>\n$ <span class=\"pl-s1\">./build.sh base</span></pre></div>\n\
    <p>If you don't use Spack but have all the dependencies you want (Geant4,\ngoogletest,\
    \ VecGeom, etc.) in your <code>CMAKE_PREFIX_PATH</code>, you can configure and\n\
    build Celeritas as you would any other project:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">mkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build</span>\n$ <span class=\"pl-s1\">cmake\
    \ ..</span>\n$ <span class=\"pl-s1\">make <span class=\"pl-k\">&amp;&amp;</span>\
    \ ctest</span></pre></div>\n<p>Celeritas guarantees full compatibility and correctness\
    \ only on the\ncombinations of compilers and dependencies tested under continuous\
    \ integration:</p>\n<ul>\n<li>Compilers:\n<ul>\n<li>GCC 8.4, 12.3</li>\n<li>Clang\
    \ 10.0, 15.0</li>\n<li>GCC 11.3 + NVCC 11.8</li>\n<li>HIP-Clang 15.0</li>\n</ul>\n\
    </li>\n<li>Dependencies:\n<ul>\n<li>Geant4 11.0.3</li>\n<li>VecGeom 1.2.5</li>\n\
    </ul>\n</li>\n</ul>\n<p>Partial compatibility and correctness is available for\
    \ an extended range of\nGeant4:</p>\n<ul>\n<li>10.5-10.7: no support for tracking\
    \ manager offload</li>\n<li>11.0: no support for fast simulation offload</li>\n\
    <li>11.1-11.2: [no support for default Rayleigh scattering cross section](see\n\
    <a href=\"https://github.com/celeritas-project/celeritas/issues/1091\">https://github.com/celeritas-project/celeritas/issues/1091</a>)</li>\n\
    </ul>\n<p>Since we compile with extra warning flags and avoid non-portable code,\
    \ most\nother compilers <em>should</em> work.\nThe full set of configurations\
    \ is viewable on CI platforms (<a href=\"https://cloud.cees.ornl.gov/jenkins-ci/job/celeritas/job/develop\"\
    \ rel=\"nofollow\">Jenkins</a> and <a href=\"https://github.com/celeritas-project/celeritas/actions\"\
    >GitHub Actions</a>).\nCompatibility fixes that do not cause newer versions to\
    \ fail are welcome.</p>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Development</h1><a id=\"user-content-development\" class=\"anchor\" aria-label=\"\
    Permalink: Development\" href=\"#development\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>See the <a href=\"CONTRIBUTING.rst\"\
    >contribution guide</a> for the contribution process,\n<a href=\"doc/appendix/development.rst\"\
    >the development guidelines</a> for further\ndetails on coding in Celeritas, and\
    \ <a href=\"doc/appendix/administration.rst\">the administration guidelines</a>\
    \ for community standards and roles.</p>\n<div class=\"markdown-heading\"><h1\
    \ class=\"heading-element\">Directory structure</h1><a id=\"user-content-directory-structure\"\
    \ class=\"anchor\" aria-label=\"Permalink: Directory structure\" href=\"#directory-structure\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <table>\n<thead>\n<tr>\n<th><strong>Directory</strong></th>\n<th><strong>Description</strong></th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>app</strong></td>\n<td>Source code\
    \ for installed executable applications</td>\n</tr>\n<tr>\n<td><strong>cmake</strong></td>\n\
    <td>Implementation code for CMake build configuration</td>\n</tr>\n<tr>\n<td><strong>doc</strong></td>\n\
    <td>Code documentation and manual</td>\n</tr>\n<tr>\n<td><strong>example</strong></td>\n\
    <td>Example applications and input files</td>\n</tr>\n<tr>\n<td><strong>interface</strong></td>\n\
    <td>Wrapper interfaces to Celeritas library functions</td>\n</tr>\n<tr>\n<td><strong>scripts</strong></td>\n\
    <td>Development and continuous integration helper scripts</td>\n</tr>\n<tr>\n\
    <td><strong>src</strong></td>\n<td>Library source code</td>\n</tr>\n<tr>\n<td><strong>test</strong></td>\n\
    <td>Unit tests</td>\n</tr>\n</tbody>\n</table>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Citing Celeritas</h1><a id=\"user-content-citing-celeritas\"\
    \ class=\"anchor\" aria-label=\"Permalink: Citing Celeritas\" href=\"#citing-celeritas\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>If using Celeritas in your work, we ask that you cite the code using its\n\
    <a href=\"https://www.osti.gov/doecode/biblio/94866\" rel=\"nofollow\">DOECode</a>\
    \ registration:</p>\n<blockquote>\n<p>Seth R. Johnson, Amanda Lund, Soon Yung\
    \ Jun, Stefano Tognini, Guilherme Lima, Paul Romano, Philippe Canal, Ben Morgan,\
    \ and Tom Evans. \u201CCeleritas,\u201D July 2022. <a href=\"https://doi.org/10.11578/dc.20221011.1\"\
    \ rel=\"nofollow\">https://doi.org/10.11578/dc.20221011.1</a>.</p>\n</blockquote>\n\
    <p>A continually evolving list of works authored by (or with content authored\
    \ by)\ncore team members is available in our <a href=\"doc/_static/celeritas.bib\"\
    >citation file</a>.</p>\n"
  stargazers_count: 55
  subscribers_count: 10
  topics:
  - hep
  - cuda
  - computational-physics
  - monte-carlo
  - detector-simulation
  - particle-transport
  updated_at: 1717100196.0
chipbuster/ljkdfhsgblkdsjhfglksdjfhg:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: chipbuster/ljkdfhsgblkdsjhfglksdjfhg
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">CMake-Template</h1><a\
    \ id=\"user-content-cmake-template\" class=\"anchor\" aria-label=\"Permalink:\
    \ CMake-Template\" href=\"#cmake-template\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Usage</h2><a id=\"user-content-usage\" class=\"anchor\"\
    \ aria-label=\"Permalink: Usage\" href=\"#usage\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"><h3\
    \ class=\"heading-element\">Install dependencies</h3><a id=\"user-content-install-dependencies\"\
    \ class=\"anchor\" aria-label=\"Permalink: Install dependencies\" href=\"#install-dependencies\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>cmake</li>\n<li>make</li>\n<li>llvm</li>\n<li>enzyme</li>\n</ul>\n<p>Using\
    \ spack:</p>\n<pre><code>spack env activate .\nspack install\n</code></pre>\n\
    <p>Using homebrew:</p>\n<pre><code>brew bundle install\n</code></pre>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Configure and build</h3><a id=\"\
    user-content-configure-and-build\" class=\"anchor\" aria-label=\"Permalink: Configure\
    \ and build\" href=\"#configure-and-build\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Configure the CMake project using\
    \ the version of Enzyme installed on the system:</p>\n<pre><code>mkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake\n</code></pre>\n<p>Configure the CMake project using\
    \ a custom Enzyme version:</p>\n<pre><code>mkdir build &amp;&amp; cd build\ncmake\
    \ -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1698092884.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">d-SEAMS</h1><a\
    \ id=\"user-content-d-seams\" class=\"anchor\" aria-label=\"Permalink: d-SEAMS\"\
    \ href=\"#d-seams\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><strong>Deferred Structural Elucidation Analysis for Molecular\
    \ Simulations</strong></p>\n<p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6c587786c40763574c1a811ef06e3c7aa93f0daacec04b672e12243c4b066847/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Citation</h1><a\
    \ id=\"user-content-citation\" class=\"anchor\" aria-label=\"Permalink: Citation\"\
    \ href=\"#citation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<ul>\n<li>\n<p>This has been published at the <a href=\"https://doi.org/10.1021/acs.jcim.0c00031\"\
    \ rel=\"nofollow\">Journal of Chemical Information and Modeling\n(JCIM)</a></p>\n\
    </li>\n<li>\n<p>You may also read <a href=\"https://arxiv.org/abs/1909.09830\"\
    \ rel=\"nofollow\">the preprint on arXiv</a></p>\n</li>\n</ul>\n<p>If you use\
    \ this software please cite the following:</p>\n<pre><code>Goswami, R., Goswami,\
    \ A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations. Journal of Chemical Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n\
    </code></pre>\n<p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<div class=\"\
    markdown-heading\"><h1 class=\"heading-element\">Compilation</h1><a id=\"user-content-compilation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Compilation\" href=\"#compilation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>We use a deterministic build system to generate both bug reports and uniform\n\
    usage statistics. This also handles the <code>lua</code> scripting engine.</p>\n\
    <p>\\note The lua functions are documented on the <a href=\"https://docs.dseams.info/md_markdown_luafunctions\"\
    \ rel=\"nofollow\">on the API Docs</a></p>\n<p>We also provide a <code>conda</code>\
    \ environment as a fallback, which is also recommended for MacOS users.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Build</h2><a id=\"\
    user-content-build\" class=\"anchor\" aria-label=\"Permalink: Build\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Conda (working now)</h3><a\
    \ id=\"user-content-conda-working-now\" class=\"anchor\" aria-label=\"Permalink:\
    \ Conda (working now)\" href=\"#conda-working-now\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Although we strongly suggest\
    \ using <code>nix</code>, for MacOS systems, the following\ninstructions may be\
    \ more suitable. We will assume the presence of <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\"\
    \ rel=\"nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-k\">~</span>/seams-core\n\
    micromamba create -f environment.yml\nmicromamba activate dseams\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Now the installation can proceed.</p>\n<p>\\note\
    \ we do not install <code>lua-luafilesystem</code> within the <code>conda</code>\
    \ environment because it is outdated on <code>osx</code></p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>mkdir build\n<span class=\"pl-c1\">cd</span> build\n\
    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span\
    \ class=\"pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake\
    \ install\n<span class=\"pl-smi\">$CONDA_PREFIX</span>/bin/yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Spack (not working at the moment)</h3><a\
    \ id=\"user-content-spack-not-working-at-the-moment\" class=\"anchor\" aria-label=\"\
    Permalink: Spack (not working at the moment)\" href=\"#spack-not-working-at-the-moment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Manually this can be done in a painful way as follows:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack install eigen@3.3.9 lua@5.2\nspack install\
    \ catch2 fmt yaml-cpp openblas boost cmake ninja meson\nspack load catch2 fmt\
    \ yaml-cpp openblas boost cmake ninja meson eigen@3.3.9 lua@5.2\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span\
    \ class=\"pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> After loading the packages</span>\nluarocks install luafilesystem</pre></div>\n\
    <p>Now we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Nix (not working at the moment)</h3><a id=\"user-content-nix-not-working-at-the-moment\"\
    \ class=\"anchor\" aria-label=\"Permalink: Nix (not working at the moment)\" href=\"\
    #nix-not-working-at-the-moment\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Since this project is built with <code>nix</code>, we can\
    \ simply do the following from the\nroot directory (longer method):</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Make sure there are no artifacts</span>\nrm -rf build\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> This will take a long time the first time\
    \ as it builds the dependencies</span>\nnix-build <span class=\"pl-c1\">.</span>\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\nnix-env -if\
    \ <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run the\
    \ command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n<p>A\
    \ faster method of building the software is by using the <a href=\"https://dseams.cachix.org/\"\
    \ rel=\"nofollow\">cachix binary cache</a> as shown:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install cachix</span>\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Use the binary cache</span>\n\
    cachix use dseams\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with\
    \ the cache than building from scratch</span>\nnix-build <span class=\"pl-c1\"\
    >.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Usage</h3><a id=\"\
    user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Having installed the <code>yodaStruct</code> binary and library, we can now\
    \ use it.</p>\n<div class=\"highlight highlight-source-shell\"><pre>yodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>\\note The paths in the <code>.yml</code>\
    \ should be <strong>relative to the folder from which the binary is called</strong>.</p>\n\
    <p>If you're confused about how to handle the relative paths, run the command\
    \ <code>yodaStruct -c lua_inputs/config.yml</code> in the top-level directory,\
    \ and set the paths relative to the top-level directory. This is the convention\
    \ used in the examples as well.</p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Language Server Support</h3><a id=\"user-content-language-server-support\"\
    \ class=\"anchor\" aria-label=\"Permalink: Language Server Support\" href=\"#language-server-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>To generate a <code>compile_commands.json</code> file for working with a language\
    \ server\nlike <a href=\"https://github.com/MaskRay/ccls\">ccls</a> use the following\
    \ commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\nnix-shell --pure\n\
    mkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span class=\"pl-c1\">cd</span>\
    \ build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES ../\n\
    cp compile_commands.json ../</pre></div>\n<p>Note that there is no need to actually\
    \ compile the project if you simply need to\nget the compiler database for the\
    \ language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Development</h2><a\
    \ id=\"user-content-development\" class=\"anchor\" aria-label=\"Permalink: Development\"\
    \ href=\"#development\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>We can simply use the <code>nix</code> environment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> From the project root</span>\nnix-shell --pure</pre></div>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Running</h1><a id=\"\
    user-content-running\" class=\"anchor\" aria-label=\"Permalink: Running\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>This is built completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install\
    \ systemwide\nnix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply\
    \ install the software, and ensure that <code>input/</code> is a child directory.</p>\n\
    <pre lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Tests</h2><a id=\"user-content-tests\" class=\"\
    anchor\" aria-label=\"Permalink: Tests\" href=\"#tests\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Apart from the <a\
    \ href=\"https://docs.dseams.info/pages.html\" rel=\"nofollow\">examples</a>,\
    \ the test-suite\ncan be run with the <code>yodaStruct_test</code> binary, which\
    \ will drop into the\n<code>nix</code> environment before building and executing\
    \ <code>gdb</code>:</p>\n<pre lang=\"{bash}\"><code># Just run this\n./testBuild.sh\n\
    # At this point the binary and library are copied into the root\n# One might,\
    \ in a foolhardy attempt, use gdb at this point\n# Here be dragons :)\n# USE NIX\n\
    # Anyway\ngdb --args ./yodaStruct -c lua_inputs/config.yml\n# quit gdb with quit\n\
    # Go run the test binary\ncd shellBuild\n./yodaStruct_test\n</code></pre>\n<p>Do\
    \ note that the regular installation via <code>nix-env</code> runs the tests before\
    \ the installation</p>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Developer Documentation</h1><a id=\"user-content-developer-documentation\" class=\"\
    anchor\" aria-label=\"Permalink: Developer Documentation\" href=\"#developer-documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    \n<p>While developing, it is sometimes expedient to update the packages used.\
    \ It is\nthen useful to note that we use <a href=\"https://github.com/nmattia/niv/\"\
    >niv</a> to handle our pinned packages (apart from\nthe ones built from Github).\
    \ Thus, one might need, say:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>niv update nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with\
    \ nix:</p>\n<div class=\"highlight highlight-source-shell\"><pre>nix-build <span\
    \ class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Outputs are in ./result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ If you get a CMake error</span>\nrm -rf build\nnix-store --delete /nix/store/<span\
    \ class=\"pl-smi\">$whatever</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> $whatever is the derivation complaining</span>\nnix-collect-garbage\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> then try again [worst case\
    \ scenario]</span></pre></div>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Leaks and performance</h2><a id=\"user-content-leaks-and-performance\" class=\"\
    anchor\" aria-label=\"Permalink: Leaks and performance\" href=\"#leaks-and-performance\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>While testing for leaks, use <code>clang</code> (for\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\"\
    >AddressSanitizer</a>\nand\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Overview</h1><a id=\"user-content-overview\" class=\"\
    anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>As of Mon Jan 20 15:57:18\
    \ 2020, the lines of code calculated by\n<a href=\"http://cloc.sourceforge.net/\"\
    \ rel=\"nofollow\">cloc</a> are as follows:</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"><img src=\"images/cloc-2020-01-20_15-56.png\"\
    \ alt=\"Cloc Lines\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Contributing</h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Please ensure that all contributions are formatted according to the\n<a href=\"\
    ./clang-format\">clang-format</a> configuration file.</p>\n<p>Specifically, consider\
    \ using the following:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\"\
    >Sublime Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"\
    https://github.com/lassik/emacs-format-all-the-code\">format-all</a> for Emacs</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\">vim-clang-format</a>\
    \ for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Commit Hook</h2><a\
    \ id=\"user-content-commit-hook\" class=\"anchor\" aria-label=\"Permalink: Commit\
    \ Hook\" href=\"#commit-hook\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Note that we expect compliance with the <code>clang-format</code>\
    \ as mentioned above, and this may be enforced by using the provided scripts for\
    \ a pre-commit hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Development Builds</h2><a id=\"user-content-development-builds\"\
    \ class=\"anchor\" aria-label=\"Permalink: Development Builds\" href=\"#development-builds\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The general idea is to drop into an interactive shell with the dependencies\
    \ and then use <code>cmake</code> as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>nix-shell --pure --run bash --show-trace --verbose\n<span class=\"pl-c1\"\
    >cd</span> build\ncmake .. -DCMAKE_BUILD_TYPE=Debug -DNO_WARN=TRUE \\\n -DFIND_EIGEN=TRUE\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n -G <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Ninja<span class=\"pl-pds\">\"</span></span>\nninja\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Test</span>\n<span class=\"pl-c1\">cd</span>\
    \ ../\nyodaStruct -c lua_inputs/config.yml\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Debug</span>\ngdb --args yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>To load debugging symbols from the shared library, when you are inside <code>gdb</code>\
    \ (from the top-level directory, for instance), use the following command:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>add-symbol-file build/libyodaLib.so</pre></div>\n\
    <p>Then you can set breakpoints in the C++ code; for instance:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>b seams_input.cpp:408</pre></div>\n<div\
    \ class=\"markdown-heading\"><h1 class=\"heading-element\">Acknowledgements</h1><a\
    \ id=\"user-content-acknowledgements\" class=\"anchor\" aria-label=\"Permalink:\
    \ Acknowledgements\" href=\"#acknowledgements\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>The following tools are used in this\
    \ project:</p>\n<ul>\n<li>\n<a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>\
    \ for compilation (<a href=\"https://github.com/cginternals/cmake-init\">cmake-init</a>\
    \ was used as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\" rel=\"\
    nofollow\">Clang</a> because it is more descriptive with better tools</li>\n<li>\n\
    <a href=\"https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the developer\
    \ API</li>\n<li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\" rel=\"\
    nofollow\">clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"https://github.com/barisione/clang-format-hooks\"\
    >clang-format-hooks</a> for <code>git</code> hooks to enforce formatting</li>\n\
    </ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\" rel=\"nofollow\">lua</a> for\
    \ the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\" rel=\"nofollow\"\
    >yaml</a> for the configuration</li>\n</ul>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Third Party Libraries</h2><a id=\"user-content-third-party-libraries\"\
    \ class=\"anchor\" aria-label=\"Permalink: Third Party Libraries\" href=\"#third-party-libraries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n<li>\n<a href=\"https://github.com/renatoGarcia/icecream-cpp\"\
    >icecream-cpp</a> for pretty-printing and debugging</li>\n</ul>\n"
  stargazers_count: 34
  subscribers_count: 5
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1714630276.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - hmmer-amd/spack.yaml
  - quantum-espresso-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Benchmark Containers</h1><a
    id="user-content-benchmark-containers" class="anchor" aria-label="Permalink: Benchmark
    Containers" href="#benchmark-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
eflows4hpc/workflow-registry:
  data_format: 2
  description: Registry to store workflow descriptions
  filenames:
  - minimal_workflow/wordcount/spack.yaml
  - kaust/exageostat/spack.yaml
  full_name: eflows4hpc/workflow-registry
  latest_release: 2nd_stack_release
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Workflow\
    \ Registry</h1><a id=\"user-content-workflow-registry\" class=\"anchor\" aria-label=\"\
    Permalink: Workflow Registry\" href=\"#workflow-registry\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>This is a repository\
    \ to store the Workflow descriptions using the eFlows4HPC methodology. This description\
    \ consist of at least the TOSCA description of the worklfow, the code of the their\
    \ different steps and their required software per step.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Repository structure</h2><a id=\"user-content-repository-structure\"\
    \ class=\"anchor\" aria-label=\"Permalink: Repository structure\" href=\"#repository-structure\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Workflow descriptions have to be included inside this repository according\
    \ to the following structure.</p>\n<pre><code>workflow-registry\n  |- workflow_1\n\
    \  |    |- tosca\n  |    |    |- types.yml               TOSCA description of\
    \ the different components involved in the workflow\n  |    |       ... \n  |\
    \    |- step_1\n  |    |    |- eflows4hpc.yml          Sofware requirements for\
    \ this workflow step. It can include apt pip and Spack specifications \n  |  \
    \  |    |- src                     PyCOMPSs code of the workflow step\n  |   \
    \ |       ...\n  |    |- step_2\n  |         ....\n  |- workflow_2           \
    \                     \n  |\t...\n\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Including new Workflows</h2><a id=\"user-content-including-new-workflows\"\
    \ class=\"anchor\" aria-label=\"Permalink: Including new Workflows\" href=\"#including-new-workflows\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>To include new workflows in the repository, first create a new fork of the\
    \ repository and  include a new folder for the workflow with a subfolder for the\
    \ TOSCA description and the different workflow steps. Finally, create a pull request\
    \ with the new workflow description. This pull request will be reviewed and included\
    \ in the repository.</p>\n"
  stargazers_count: 4
  subscribers_count: 9
  topics: []
  updated_at: 1711452398.0
eic/containers:
  data_format: 2
  description: Container building infrastructure (mirror of https://eicweb.phy.anl.gov/containers/eic_container)
  filenames:
  - spack-environment/prod/spack.yaml
  - spack-environment/cuda/spack.yaml
  - spack-environment/xl/spack.yaml
  full_name: eic/containers
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">EIC software
    environment container</h1><a id="user-content-eic-software-environment-container"
    class="anchor" aria-label="Permalink: EIC software environment container" href="#eic-software-environment-container"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>For installation instructions of <code>eic-shell</code>, see <a href="https://github.com/eic/eic-shell">https://github.com/eic/eic-shell</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 50
  topics: []
  updated_at: 1717043585.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - env-bipp-izar/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">ska-spack-env</h1><a
    id="user-content-ska-spack-env" class="anchor" aria-label="Permalink: ska-spack-env"
    href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
epfl-scitas/spack-sdploy:
  data_format: 2
  description: Toolset to deploy software stacks
  filenames:
  - samples/spack.yaml
  full_name: epfl-scitas/spack-sdploy
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">spack-sdploy</h1><a\
    \ id=\"user-content-spack-sdploy\" class=\"anchor\" aria-label=\"Permalink: spack-sdploy\"\
    \ href=\"#spack-sdploy\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Spack extension for automatic package configuration and\
    \ deployment.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >How to install</h2><a id=\"user-content-how-to-install\" class=\"anchor\" aria-label=\"\
    Permalink: How to install\" href=\"#how-to-install\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>You can try out this Spack\
    \ extension be executing 4 easy steps:</p>\n<ul>\n<li>Set up and activate a local\
    \ python environment</li>\n<li>Set up and activate <code>spack</code>\n</li>\n\
    <li>Install <code>spack-sdploy</code> dependencies</li>\n<li>Clone and configure\
    \ spack-sdploy</li>\n</ul>\n<p>This 4 steps are now detailed in the next section.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step-by-step installation</h3><a\
    \ id=\"user-content-step-by-step-installation\" class=\"anchor\" aria-label=\"\
    Permalink: Step-by-step installation\" href=\"#step-by-step-installation\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Just\
    \ for a matter of completeness, all the steps needed get up and running with\n\
    spack-sdploy extension will be covered, which can be a bit pedantic.</p>\n<div\
    \ class=\"markdown-heading\"><h4 class=\"heading-element\">Set up and activate\
    \ a local python environment</h4><a id=\"user-content-set-up-and-activate-a-local-python-environment\"\
    \ class=\"anchor\" aria-label=\"Permalink: Set up and activate a local python\
    \ environment\" href=\"#set-up-and-activate-a-local-python-environment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>It\
    \ is recommended that a Python environment be used to support sdploy. This same\n\
    Python can also be used to run Spack.</p>\n<pre><code>python3 -m venv &lt;path-to-environment-directory&gt;\n\
    . &lt;path-to-environment-directory&gt;/bin/activate\n</code></pre>\n<p>For more\
    \ information on how to create a virtual environment in Python refer to\nthe PEP\
    \ 405 \u2013 Python Virtual Environments documentation.</p>\n<div class=\"markdown-heading\"\
    ><h4 class=\"heading-element\">Set up and activate Spack</h4><a id=\"user-content-set-up-and-activate-spack\"\
    \ class=\"anchor\" aria-label=\"Permalink: Set up and activate Spack\" href=\"\
    #set-up-and-activate-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">Spack documentation</a>\non how to install Spack. For sake\
    \ of completeness, we copy paste the commands here:</p>\n<pre><code>git clone\
    \ -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n\
    </code></pre>\n<div class=\"markdown-heading\"><h4 class=\"heading-element\">Install\
    \ <code>spack-sdploy</code> dependencies</h4><a id=\"user-content-install-spack-sdploy-dependencies\"\
    \ class=\"anchor\" aria-label=\"Permalink: Install spack-sdploy dependencies\"\
    \ href=\"#install-spack-sdploy-dependencies\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Up to now the only dependency of\
    \ spack-sdploy if jinja2. Once you have activated\nPython environment, you can\
    \ simply use pip to install the packages.</p>\n<pre><code>pip install jinja2\n\
    </code></pre>\n<div class=\"markdown-heading\"><h4 class=\"heading-element\">Clone\
    \ and configure spack-sdploy</h4><a id=\"user-content-clone-and-configure-spack-sdploy\"\
    \ class=\"anchor\" aria-label=\"Permalink: Clone and configure spack-sdploy\"\
    \ href=\"#clone-and-configure-spack-sdploy\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<pre><code>git clone git@github.com:epfl-scitas/spack-sdploy\n\
    </code></pre>\n<p>To activate the spack-sdploy extension you must add it to the\
    \ config.yaml. If\nyou already have another Spack installation and just want to\
    \ try out\nspack-sdploy may very well create a temporary directory to store the\n\
    configuration and then use the SPACK_USER_CONFIG_PATH variable to point this new\n\
    directory.</p>\n<pre><code>mkdir temporary_config\nexport SPACK_USER_CONFIG_PATH=/path/to/temporary_config\n\
    </code></pre>\n<p>and then, inside the temporary_config directory, write a config.yaml\
    \ file with\nthe following contents:</p>\n<pre><code>config:\n  extensions:\n\
    \  - /path/to/spack-sdploy\n</code></pre>\n<p>Be sure you do not change the spack-dploy\
    \ directory. Spack forces the extensions\nto follow strict rules. Please see the\n\
    <a href=\"https://spack.readthedocs.io/en/latest/extensions.html\" rel=\"nofollow\"\
    >Spack Extensions</a>\ndocumentation for more details about this subject. At this\
    \ point you should now\nbe able to call <code>spack -h</code> and see the new\
    \ Spack commands deployed by the\nspack-sdploy extension.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">How to use</h2><a id=\"user-content-how-to-use\"\
    \ class=\"anchor\" aria-label=\"Permalink: How to use\" href=\"#how-to-use\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>At\
    \ the present time, spack-sdploy will add 2 commands to your already existing\n\
    Spack commands. These commandes are:</p>\n<pre><code>spack write-spack-yaml\n\
    spack write-packages-yaml\n</code></pre>\n<p>In the future we may change the names\
    \ of these commands, but for now lets just\nimagine these are short and easy to\
    \ type commands.</p>\n<p>As you may have guessed it (if you haven't that's ok),\
    \ write-spack-yaml will\nwrite the spack.yaml file and write-packages-yaml will\
    \ write the packages.yaml\nfile. Of course, Spack does not (yet!) guess what you\
    \ may want to install and\nfor that purpose, both these commands will read all\
    \ the specs you want in your\nspack.yaml file by reading another file you have\
    \ previously written and which\nwe call by stack.yaml.</p>\n<p>For the time being,\
    \ spack-sdploy already comes with a dummy stack.yaml so we can\nget started using\
    \ the new commands.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >write-spack-yaml</h2><a id=\"user-content-write-spack-yaml\" class=\"anchor\"\
    \ aria-label=\"Permalink: write-spack-yaml\" href=\"#write-spack-yaml\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<pre><code>spack\
    \ write-spack-yaml\n</code></pre>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">write-packages-yaml</h2><a id=\"user-content-write-packages-yaml\"\
    \ class=\"anchor\" aria-label=\"Permalink: write-packages-yaml\" href=\"#write-packages-yaml\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>spack write-packages-yaml\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">write-activate-list</h2><a id=\"user-content-write-activate-list\"\
    \ class=\"anchor\" aria-label=\"Permalink: write-activate-list\" href=\"#write-activate-list\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>spack write-activate-list -p &lt;platform&gt; -s &lt;stack&gt;\n</code></pre>\n\
    <p>Write to file named <code>packages_to_activate</code> list of packages to activate,\
    \ using <code>spack activate &lt;package&gt;</code>. Packages are writen one per\
    \ line.</p>\n<p>Packages to activate can be marked in the stack file in two possible\
    \ ways: by adding the keyword <code>activate: true</code> in the metadata section\
    \ of a list of packages or by adding the keyword <code>activate: true</code> to\
    \ an individual package. Duplicates are removed.</p>\n"
  stargazers_count: 1
  subscribers_count: 8
  topics: []
  updated_at: 1716972836.0
esm-tools/esm_tools:
  data_format: 2
  description: Simple Infrastructure for Earth System Simulations
  filenames:
  - configs/spack_envs/albedo-spack.yaml
  full_name: esm-tools/esm_tools
  latest_release: v6.0.0
  stargazers_count: 24
  subscribers_count: 8
  topics: []
  updated_at: 1717232573.0
eth-cscs/spack-batteries-included:
  data_format: 2
  description: Installing spack without system dependencies
  filenames:
  - build/3_more_tools/spack.yaml
  full_name: eth-cscs/spack-batteries-included
  latest_release: develop
  readme: "<p><a href=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml\"\
    ><img src=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\"\
    \ alt=\"Update spack develop version\" style=\"max-width: 100%;\"></a></p>\n<div\
    \ class=\"markdown-heading\"><h1 class=\"heading-element\">\U0001F50B Spack with\
    \ batteries included (linux/x86_64)</h1><a id=\"user-content--spack-with-batteries-included-linuxx86_64\"\
    \ class=\"anchor\" aria-label=\"Permalink: \U0001F50B Spack with batteries included\
    \ (linux/x86_64)\" href=\"#-spack-with-batteries-included-linuxx86_64\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p><a\
    \ href=\"https://github.com/spack/spack\">Spack</a> is a package manager, and\
    \ package managers should be trivial to install.</p>\n<p>This repo offers a single,\
    \ static executable for Spack:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">wget -qO spack.x https://github.com/eth-cscs/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n\
    $ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x\
    \ install curl tls=mbedtls</span></pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">What version of Spack is shipped?</h2><a id=\"\
    user-content-what-version-of-spack-is-shipped\" class=\"anchor\" aria-label=\"\
    Permalink: What version of Spack is shipped?\" href=\"#what-version-of-spack-is-shipped\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The URL above gives you a rolling release of Spack's develop branch, which\
    \ is updated\nhourly. The exact commit SHA is included as a file and can be retrieved\
    \ like this:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$\
    \ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"pl-k\"\
    >&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints the\
    \ Spack commit sha]</span></pre></div>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Supported platforms</h2><a id=\"user-content-supported-platforms\"\
    \ class=\"anchor\" aria-label=\"Permalink: Supported platforms\" href=\"#supported-platforms\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n<li>Debian\
    \ 8 and above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and above</li>\n\
    <li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for Linux 2 with any\
    \ of the above distro's.</li>\n</ul>\n<p>The system dependencies are <code>glibc\
    \ 2.17</code> and above and optionally the <code>fusermount</code>\nexecutable.\
    \ If your system supports rootless containers it likely has <code>fusermount</code>\n\
    installed already!</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >How does it work?</h2><a id=\"user-content-how-does-it-work\" class=\"anchor\"\
    \ aria-label=\"Permalink: How does it work?\" href=\"#how-does-it-work\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p><code>spack.x</code>\
    \ consists of a modified version of the AppImage runtime concatenated\nwith a\
    \ big squashfs file which includes <code>binutils</code>, <code>bzip2</code>,\
    \ <code>clingo</code>, <code>curl</code>,\n<code>file</code>, <code>git</code>,\
    \ <code>gmake</code>, <code>gpg</code>, <code>gzip</code>, <code>openssl</code>,\
    \ <code>patch</code>, <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>,\
    \ <code>tar</code>, <code>unzip</code>, <code>xz</code>, <code>zstd</code> and\
    \ their dependencies.</p>\n<p>When you run <code>spack.x [args]</code> it will\
    \ use <code>fusermount</code> to\nmount this squashfs file in a temporary directory,\
    \ and then execute the\nentrypoint executable <a href=\"build/6_spack/spack\"\
    >spack</a>.</p>\n<p>The <code>spack</code> executable sets some environment variables\
    \ like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code> to the bin and lib\
    \ folders of the squashfs file, and then it\nexecutes <code>python3 spack_src/bin/spack\
    \ [args]</code>.</p>\n<p>When the command is done running, the runtime unmounts\
    \ the squashfs file again.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >My system doesn't allow me to use <code>fusermount</code>, what now?</h2><a id=\"\
    user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\" class=\"anchor\"\
    \ aria-label=\"Permalink: My system doesn't allow me to use fusermount, what now?\"\
    \ href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p><code>fusermount</code>\
    \ is used to mount a squashfs file included in the binary. If you\ndon't want\
    \ that, you can just extract it:</p>\n<pre><code>$ spack.x --squashfs-extract\n\
    $ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\
    </code></pre>\n<p>but working with the extracted <code>spack</code> folder can\
    \ come with a performance\npenalty on shared filesystems in HPC centers.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Differences and\
    \ improvements over AppImage runtime</h2><a id=\"user-content-differences-and-improvements-over-appimage-runtime\"\
    \ class=\"anchor\" aria-label=\"Permalink: Differences and improvements over AppImage\
    \ runtime\" href=\"#differences-and-improvements-over-appimage-runtime\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<ul>\n\
    <li>spack.x uses <code>zstd</code> for faster decompression;</li>\n<li>spack.x\
    \ itself is an entirely static binary;</li>\n<li>spack.x does not need to dlopen\
    \ libfuse.so.</li>\n</ul>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Troubleshooting</h2><a id=\"user-content-troubleshooting\" class=\"anchor\" aria-label=\"\
    Permalink: Troubleshooting\" href=\"#troubleshooting\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p><strong>immutability</strong>\
    \ The squashfs mountpoint is a readonly folder, meaning that\nspack can't write\
    \ to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard\
    \ directories, see <code>spack.x config blame config</code> for details.</p>\n\
    <p>Note, spack.x applies <a href=\"https://github.com/spack/spack/pull/20158/\"\
    >this patch</a>\nto ensure that log files are written to the <code>config:misc_cache</code>\
    \ folder.</p>\n<p><strong>openssl</strong>: By default spack.x uses <code>ca-certificates-mozilla</code>\
    \ for downloading\npackage sources over https. If you somehow need to use system\
    \ certificates,\nset <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAINFO</code>\
    \ or <code>SSL_CERT_FILE</code> and <code>GIT_SSL_CERT</code>.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Can I run spack.x inside a container?</h2><a\
    \ id=\"user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" aria-label=\"\
    Permalink: Can I run spack.x inside a container?\" href=\"#can-i-run-spackx-inside-a-container\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Yes, but please don't! Since <code>fusermount</code> is a setuid binary, you\
    \ will need to\nrun a privileged container, which is never a good idea.</p>\n\
    <p>The recommended way to run spack.x inside a container is to just extract it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >spack.x --squashfs-extract</span>\n$ <span class=\"pl-s1\">./spack/spack --version</span></pre></div>\n\
    <p>If you insist on running spack.x in Docker, this is one way to do it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >sudo docker run --privileged --device /dev/fuse -it -v <span class=\"pl-smi\"\
    >$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n# <span class=\"pl-s1\"\
    >apt update <span class=\"pl-k\">&amp;&amp;</span> apt install fuse <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n# <span\
    \ class=\"pl-s1\">spack.x --version</span></pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Running an executable shipped with spack.x directly</h2><a\
    \ id=\"user-content-running-an-executable-shipped-with-spackx-directly\" class=\"\
    anchor\" aria-label=\"Permalink: Running an executable shipped with spack.x directly\"\
    \ href=\"#running-an-executable-shipped-with-spackx-directly\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>If you want to run\
    \ an executable shipped with <code>spack.x</code> directly instead\nof invoking\
    \ spack (the default entrypoint), try this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x which python</span>\n<span\
    \ class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n\
    <hr>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">How do I build\
    \ spack.x myself?</h2><a id=\"user-content-how-do-i-build-spackx-myself\" class=\"\
    anchor\" aria-label=\"Permalink: How do I build spack.x myself?\" href=\"#how-do-i-build-spackx-myself\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Initially you may need docker to get a rootfs filesystem for centos 7.</p>\n\
    <p>Building goes like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">make rootfs-with-spack</span>\n<span class=\"pl-c1\"\
    >make</span></pre></div>\n<p>You'll find the output in</p>\n<pre><code>build/output\n\
    </code></pre>\n"
  stargazers_count: 25
  subscribers_count: 3
  topics:
  - spack
  - squashfs
  - libfuse
  updated_at: 1713141858.0
eugeneswalker/exawind-containers:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/exawind-containers
  latest_release: null
  readme: '<div class="markdown-heading"><h2 class="heading-element">Working with
    the Docker image (ecpe4s/exawind:latest)</h2><a id="user-content-working-with-the-docker-image-ecpe4sexawindlatest"
    class="anchor" aria-label="Permalink: Working with the Docker image (ecpe4s/exawind:latest)"
    href="#working-with-the-docker-image-ecpe4sexawindlatest"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ol>

    <li>Build the Docker image</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Launch a container from the image</li>

    </ol>

    <pre><code>$&gt; docker run -it --rm ecpe4s/exawind


    root@8df184bdac63:/# which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    root@8df184bdac63:/# which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Working with the Singularity
    image (exawind.sif)</h2><a id="user-content-working-with-the-singularity-image-exawindsif"
    class="anchor" aria-label="Permalink: Working with the Singularity image (exawind.sif)"
    href="#working-with-the-singularity-image-exawindsif"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ol>

    <li>Build the Docker image:</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Save the Docker image as a docker-archive</li>

    </ol>

    <pre><code>$&gt; docker save -o exawind.tar ecpe4s/exawind:latest

    </code></pre>

    <ol start="3">

    <li>Build the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./build-singularity-image.sh

    </code></pre>

    <ol start="4">

    <li>Run the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./exawind.sif


    Exawind Singularity&gt; which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    Exawind Singularity&gt; which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Run Selected ExaWind
    Regression Tests</h2><a id="user-content-run-selected-exawind-regression-tests"
    class="anchor" aria-label="Permalink: Run Selected ExaWind Regression Tests" href="#run-selected-exawind-regression-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ol>

    <li>

    <p>Launch a container using either the Docker or Singularity image (see above)</p>

    </li>

    <li>

    <p>Clone this repository in the newly launched container and run the tests (here
    illustrated with Singularity)</p>

    </li>

    </ol>

    <pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers
    ~/exawind-containers

    Exawind Singularity&gt; cd ~/exawind-containers/demo



    Exawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh

    PASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15



    Exawind Singularity&gt; ./run-nalu-wind-tests.sh

    PASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11

    PASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13

    ...



    Exawind Singularity&gt; ./run-amr-wind-tests.sh

    finished abl_bndry_output

    finished abl_godunov

    ...

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1626420401.0
eugeneswalker/llvm-containers:
  data_format: 2
  description: null
  filenames:
  - x86_64/spack.yaml
  - ppc64le/spack.yaml
  full_name: eugeneswalker/llvm-containers
  latest_release: null
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1615486265.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - oneapi/failures/spack.yaml
  - gnu/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675202595.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - cuda-12/spack.yaml
  - cuda-11/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">synergia2-containers</h1><a
    id="user-content-synergia2-containers" class="anchor" aria-label="Permalink: synergia2-containers"
    href="#synergia2-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1715182572.0
giordano/julia-on-fugaku:
  data_format: 2
  description: null
  filenames:
  - benchmarks/blas-axpy/spack-env/spack.yaml
  full_name: giordano/julia-on-fugaku
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Julia on\
    \ Fugaku (2022-07-23)</h1><a id=\"user-content-julia-on-fugaku-2022-07-23\" class=\"\
    anchor\" aria-label=\"Permalink: Julia on Fugaku (2022-07-23)\" href=\"#julia-on-fugaku-2022-07-23\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><em>Note: many links refer to internal documentation which is accessible only\
    \ to Fugaku users.</em></p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Read the paper</h2><a id=\"user-content-read-the-paper\" class=\"anchor\" aria-label=\"\
    Permalink: Read the paper\" href=\"#read-the-paper\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Benchmarks present in this\
    \ repository have been published in the paper <a href=\"https://doi.org/10.1109/CLUSTER51413.2022.00072\"\
    \ rel=\"nofollow\">Productivity meets\nPerformance: Julia on A64FX</a>, presented\
    \ at\nthe 2022 IEEE International Conference on Cluster Computing (CLUSTER22),\
    \ as part of the\n<a href=\"https://arm-hpc-user-group.github.io/eahpc-2022/\"\
    \ rel=\"nofollow\">Embracing Arm for High Performance Computing\nWorkshop</a>\
    \ (pre-print available on arXiv:\n<a href=\"https://arxiv.org/abs/2207.12762\"\
    \ rel=\"nofollow\"><code>2207.12762</code></a>).  See the <a href=\"./CITATION.bib\"\
    ><code>CITATION.bib</code></a>\nfile for a BibTeX entry to cite the paper.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Storage</h2><a id=\"\
    user-content-storage\" class=\"anchor\" aria-label=\"Permalink: Storage\" href=\"\
    #storage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Before doing anything on Fugaku, be aware that there are <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20220408_01\"\
    \ rel=\"nofollow\">tight\nlimits</a> on the size of (20 GiB)\nand the number of\
    \ inodes in (200k) your home directory.  If you use many Julia Pkg\nartifacts,\
    \ it's very likely you'll hit these limits.  You'll notice that you hit the limit\n\
    because any disk I/O operation will result in a <code>Disk quota exceeded</code>\
    \ error like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-e\">[user@fn01sv03 ~]</span>$ <span class=\"pl-s1\">touch\
    \ foo</span>\n<span class=\"pl-c1\">touch: cannot touch 'foo': Disk quota exceeded</span></pre></div>\n\
    <p>You can check the quota of your home directory with <code>accountd</code> for\
    \ the size, and <code>accountd -i</code> for the number of inodes.</p>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Using the data directory</h3><a\
    \ id=\"user-content-using-the-data-directory\" class=\"anchor\" aria-label=\"\
    Permalink: Using the data directory\" href=\"#using-the-data-directory\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>In\
    \ order to avoid clogging up the home directory you may want to move the Julia\
    \ depot to the\ndata directory:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>DATADIR=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/data/&lt;YOUR\
    \ GROUP&gt;/<span class=\"pl-smi\">${USER}</span><span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-k\">export</span> JULIA_DEPOT_PATH=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span><span class=\"pl-smi\">${DATADIR}</span>/julia-depot<span\
    \ class=\"pl-pds\">\"</span></span></pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Interactive usage</h2><a id=\"user-content-interactive-usage\"\
    \ class=\"anchor\" aria-label=\"Permalink: Interactive usage\" href=\"#interactive-usage\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The login nodes you access via <code>login.fugaku.r-ccs.riken.jp</code> (<a\
    \ href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/AccessToTheSystem/LoggingInToTheFugakuComputerWithLocalAccount.html\"\
    \ rel=\"nofollow\">connection\ninstructions</a>)\nhave Cascade Lake CPUs, so they\
    \ aren't much useful if you want to run an aarch64 Julia.</p>\n<p>You can <a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/Overview.html\"\
    \ rel=\"nofollow\">submit jobs to the\nqueue</a>\nto run Julia code on the A64FX\
    \ compute nodes, but this can be cumbersone if you need quick\nfeedback during\
    \ development or debugging.  You can also request an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/InteractiveJob.html\"\
    \ rel=\"nofollow\">interactive\nnode</a>,\nfor example with:</p>\n<pre><code>pjsub\
    \ --interact -L \"node=1\" -L \"rscgrp=int\" -L \"elapse=30:00\" --sparam \"wait-time=600\"\
    \ --mpi \"max-proc-per-node=4\"\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Available software</h2><a id=\"user-content-available-software\"\
    \ class=\"anchor\" aria-label=\"Permalink: Available software\" href=\"#available-software\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Fugaku uses the <a href=\"https://spack.io/\" rel=\"nofollow\">Spack package\
    \ manager</a>.  For more information about how\nto use it, see the <a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/FugakuSpackGuide/\"\
    \ rel=\"nofollow\">Fugaku Spack User\nGuide</a>.</p>\n<p>Note that Spack is installed\
    \ in <code>/vol0004</code>, this means that if your home directory isn't\nmounted\
    \ on this volume you will have to <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20211130_02\"\
    \ rel=\"nofollow\">explicitly request the\npartition</a> in your submission\n\
    job scripts or commands, for example by adding <code>-x PJM_LLIO_GFSCACHE=/vol0004</code>\
    \ to the\n<code>pjsub</code> command, or the line</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>PJM\
    \ -x PJM_LLIO_GFSCACHE=/vol0004</span></pre></div>\n<p>in a job script.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Using Julia on the\
    \ compute nodes</h2><a id=\"user-content-using-julia-on-the-compute-nodes\" class=\"\
    anchor\" aria-label=\"Permalink: Using Julia on the compute nodes\" href=\"#using-julia-on-the-compute-nodes\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>There is a Julia module built with Spack <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/UsingOSS/oss_e.html#packages-installed-on-the-compute-nodes\"\
    \ rel=\"nofollow\">available on the compute\nnodes</a>,\nbut as of this writing\
    \ (2022-07-23) the version of Julia provided is 1.6.3, so you may want\nto download\
    \ a more recent version from the <a href=\"https://julialang.org/downloads/\"\
    \ rel=\"nofollow\">official\nwebsite</a>.  Use the <code>aarch64</code> builds\
    \ for Glibc Linux,\npreferably <a href=\"https://julialang.org/downloads/#current_stable_release\"\
    \ rel=\"nofollow\">latest stable</a> or even\nthe <a href=\"https://julialang.org/downloads/nightlies/\"\
    \ rel=\"nofollow\">nightly build</a> if you feel confident.</p>\n<p>To enable\
    \ full vectorisation you may need to set the environment variable\n<code>JULIA_LLVM_ARGS=\"\
    -aarch64-sve-vector-bits-min=512\"</code>.  Example:\n<a href=\"https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\"\
    >https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623</a>. \
    \ However, note that\nare a couple of severe bugs when using 512-bit vectors:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/JuliaLang/julia/issues/44401\">https://github.com/JuliaLang/julia/issues/44401</a>\
    \ (may be an upstream LLVM bug:\n<a href=\"https://github.com/llvm/llvm-project/issues/53331\"\
    >https://github.com/llvm/llvm-project/issues/53331</a>)</li>\n<li>\n<a href=\"\
    https://github.com/JuliaLang/julia/issues/44263\">https://github.com/JuliaLang/julia/issues/44263</a>\
    \ (only in Julia v1.8+)</li>\n</ul>\n<p><em><strong>Note</strong></em>: Julia\
    \ v1.9, which is based on <a href=\"https://community.arm.com/arm-community-blogs/b/tools-software-ides-blog/posts/llvm-14\"\
    \ rel=\"nofollow\">LLVM\n14</a>,\nis able to natively autovectorise code for A64FX\
    \ <em>without</em> having to set\n<code>JULIA_LLVM_ARGS</code>, side stepping\
    \ the issues above altogether.</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">MPI.jl</h2><a id=\"user-content-mpijl\" class=\"anchor\" aria-label=\"\
    Permalink: MPI.jl\" href=\"#mpijl\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p><a href=\"https://github.com/JuliaParallel/MPI.jl\"\
    ><code>MPI.jl</code></a> with default JLL-provided MPICH works\nout of the box!\
    \  In order to\n<a href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\"\
    \ rel=\"nofollow\">configure</a> <code>MPI.jl</code> v0.19 to\nuse system-provided\
    \ Fujitsu MPI (based on OpenMPI) you have to specify the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/CompileCommands.html\"\
    \ rel=\"nofollow\">MPI C\ncompiler</a>\nfor A64FX with</p>\n<pre><code>julia --project\
    \ -e 'ENV[\"JULIA_MPI_BINARY\"]=\"system\"; ENV[\"JULIA_MPICC\"]=\"mpifcc\"; using\
    \ Pkg; Pkg.build(\"MPI\"; verbose=true)'\n</code></pre>\n<p><em><strong>Note #1</strong></em>:\
    \ <code>mpifcc</code> is available only on the compute nodes.  On the login nodes\
    \ that would be\n<code>mpifccpx</code>, but this is the cross compiler running\
    \ on Intel architecture, it's unlikely\nyou'll run an <code>aarch64</code> Julia\
    \ on there.  <a href=\"https://github.com/JuliaParallel/MPI.jl/issues/539\">Preliminary\n\
    tests</a> show that <code>MPI.jl</code> should work\nmostly fine with Fujitsu\
    \ MPI, but custom error handlers may not be available (read: trying\nto use them\
    \ causes segmentation faults).</p>\n<p><em><strong>Note #2</strong></em>: in <code>MPI.jl</code>\
    \ v0.20 Fujitsu MPI is a known ABI (it's the same as OpenMPI) and\nthere is nothing\
    \ special to do to configure it apart from <a href=\"https://juliaparallel.org/MPI.jl/dev/configuration/#Configuration-2\"\
    \ rel=\"nofollow\">choosing the system\nbinaries</a>.</p>\n<p><em><strong>Note\
    \ #3</strong></em>: we recommend using <code>MPI.jl</code>'s wrapper of <code>mpiexec</code>\
    \ to run MPI applications\nwith Julia:\n<a href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Julia-wrapper-for-mpiexec\"\
    \ rel=\"nofollow\"><code>mpiexecjl</code></a>.</p>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">File system latency</h3><a id=\"user-content-file-system-latency\"\
    \ class=\"anchor\" aria-label=\"Permalink: File system latency\" href=\"#file-system-latency\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Fugaku has an advanced system to handle <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/index.html\"\
    \ rel=\"nofollow\">parallel file system\nlatency</a>.\nIn order.  In order to\
    \ speed up parallel applications run through MPI you may want to\ndistribute it\
    \ to the cache area of the second-layer storage on the first-layer storage using\n\
    <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/TheSecondLayerStrage.html#common-file-distribution-function-llio-transfer\"\
    \ rel=\"nofollow\"><code>llio_transfer</code></a>.\nIn particular, if you're using\
    \ Julia, you likely want to distribute the <code>julia</code> executable\nitself\
    \ together with its installation bundle.</p>\n<p>For example, assuming that you\
    \ are using the official binaries from the website, instead of\nthe Julia module\
    \ provided by Spack, you can do the following:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Directory for log of\
    \ `llio_transfer` and its wrapper `dir_transfer`</span>\nLOGDIR=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${TMPDIR}</span>/log<span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Create the log directory if necessary</span>\nmkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Get directory where Julia is placed</span>\nJL_BUNDLE=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>dirname <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>julia --startup-file=no\
    \ -O0 --compile=min -e <span class=\"pl-s\"><span class=\"pl-pds\">'</span>print(Sys.BINDIR)<span\
    \ class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span><span\
    \ class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Move Julia installation to\
    \ fast LLIO directory</span>\n/home/system/tool/dir_transfer -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Do not write\
    \ empty stdout/stderr files for MPI processes.</span>\n<span class=\"pl-k\">export</span>\
    \ PLE_MPI_STD_EMPTYFILE=off\n\nmpiexecjl --project=. -np ... julia ...\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Remove Julia installation directory\
    \ from the cache.</span>\n/home/system/tool/dir_transfer -p -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span></pre></div>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Reverse engineering Fujitsu compiler using LLVM output</h2><a id=\"user-content-reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    \ class=\"anchor\" aria-label=\"Permalink: Reverse engineering Fujitsu compiler\
    \ using LLVM output\" href=\"#reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The Fujitsu compiler has <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/C/modeTradAndClangC.html\"\
    \ rel=\"nofollow\">two operation\nmodes</a>:\n\"trad\" (for \"traditional\") and\
    \ \"clang\" (enabled by the flag <code>-Nclang</code>).  In clang mode it's\n\
    based on LLVM (version 7 at the moment).  This means you can get it to emit LLVM\
    \ IR with\n<code>-emit-llvm</code>.  For example, with</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\"\
    >echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>int main(){}<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> fcc -Nclang -x\
    \ c - -S -emit-llvm -o -</span></pre></div>\n<p>you get</p>\n<div class=\"highlight\
    \ highlight-source-llvm\"><pre><span class=\"pl-c\">; ModuleID = '-'</span>\n\
    source_filename = <span class=\"pl-s\">\"-\"</span>\n<span class=\"pl-k\">target</span>\
    \ <span class=\"pl-k\">datalayout</span> = <span class=\"pl-s\">\"e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128\"\
    </span>\n<span class=\"pl-k\">target</span> <span class=\"pl-k\">triple</span>\
    \ = <span class=\"pl-s\">\"aarch64-unknown-linux-gnu\"</span>\n\n<span class=\"\
    pl-c\">; Function Attrs: norecurse nounwind readnone uwtable</span>\n<span class=\"\
    pl-k\">define</span> dso_local <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">@main</span>() <span class=\"pl-k\">local_unnamed_addr</span> #<span class=\"\
    pl-c1\">0</span> <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!8</span>\
    \ {\n  <span class=\"pl-k\">ret</span> <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!11</span>\n\
    }\n\n<span class=\"pl-k\">attributes</span> #<span class=\"pl-c1\">0</span> =\
    \ { <span class=\"pl-k\">norecurse</span> <span class=\"pl-k\">nounwind</span>\
    \ <span class=\"pl-k\">readnone</span> <span class=\"pl-k\">uwtable</span> <span\
    \ class=\"pl-s\">\"correctly-rounded-divide-sqrt-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"disable-tail-calls\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"less-precise-fpmad\"\
    </span>=<span class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim\"\
    </span>=<span class=\"pl-s\">\"true\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim-non-leaf\"\
    </span> <span class=\"pl-s\">\"no-infs-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"no-jump-tables\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> <span class=\"pl-s\">\"no-nans-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-signed-zeros-fp-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-trapping-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"stack-protector-buffer-size\"\
    </span>=<span class=\"pl-s\">\"8\"</span> <span class=\"pl-s\">\"target-cpu\"\
    </span>=<span class=\"pl-s\">\"a64fx\"</span> <span class=\"pl-s\">\"target-features\"\
    </span>=<span class=\"pl-s\">\"+crc,+crypto,+fp-armv8,+lse,+neon,+ras,+rdm,+sve,+v8.2a\"\
    </span> <span class=\"pl-s\">\"unsafe-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"use-soft-float\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> }\n\n<span class=\"pl-v\">!llvm.dbg.cu</span> = !{<span class=\"\
    pl-v\">!0</span>}\n<span class=\"pl-v\">!llvm.module.flags</span> = !{<span class=\"\
    pl-v\">!3</span>, <span class=\"pl-v\">!4</span>, <span class=\"pl-v\">!5</span>}\n\
    <span class=\"pl-v\">!llvm.ident</span> = !{<span class=\"pl-v\">!6</span>}\n\
    <span class=\"pl-v\">!llvm.compinfo</span> = !{<span class=\"pl-v\">!7</span>}\n\
    \n<span class=\"pl-v\">!0</span> = distinct <span class=\"pl-v\">!DICompileUnit</span>(language:\
    \ DW_LANG_C99, file: <span class=\"pl-v\">!1</span>, producer: <span class=\"\
    pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on\
    \ LLVM 7.1.0)\"</span>, isOptimized: <span class=\"pl-k\">true</span>, runtimeVersion:\
    \ <span class=\"pl-c1\">0</span>, emissionKind: LineTablesOnly, enums: <span class=\"\
    pl-v\">!2</span>)\n<span class=\"pl-v\">!1</span> = <span class=\"pl-v\">!DIFile</span>(filename:\
    \ <span class=\"pl-s\">\"-\"</span>, directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"\
    </span>)\n<span class=\"pl-v\">!2</span> = !{}\n<span class=\"pl-v\">!3</span>\
    \ = !{<span class=\"pl-k\">i32</span> <span class=\"pl-c1\">2</span>, !<span class=\"\
    pl-s\">\"Dwarf Version\"</span>, <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">4</span>}\n<span class=\"pl-v\">!4</span> = !{<span class=\"pl-k\">i32</span>\
    \ <span class=\"pl-c1\">2</span>, !<span class=\"pl-s\">\"Debug Info Version\"\
    </span>, <span class=\"pl-k\">i32</span> <span class=\"pl-c1\">3</span>}\n<span\
    \ class=\"pl-v\">!5</span> = !{<span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">1</span>, !<span class=\"pl-s\">\"wchar_size\"</span>, <span class=\"\
    pl-k\">i32</span> <span class=\"pl-c1\">4</span>}\n<span class=\"pl-v\">!6</span>\
    \ = !{!<span class=\"pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021\
    \ 10:55:52) (based on LLVM 7.1.0)\"</span>}\n<span class=\"pl-v\">!7</span> =\
    \ !{!<span class=\"pl-s\">\"C::clang\"</span>}\n<span class=\"pl-v\">!8</span>\
    \ = distinct <span class=\"pl-v\">!DISubprogram</span>(name: <span class=\"pl-s\"\
    >\"main\"</span>, scope: <span class=\"pl-v\">!9</span>, file: <span class=\"\
    pl-v\">!9</span>, line: <span class=\"pl-c1\">1</span>, type: <span class=\"pl-v\"\
    >!10</span>, isLocal: <span class=\"pl-k\">false</span>, isDefinition: <span class=\"\
    pl-k\">true</span>, scopeLine: <span class=\"pl-c1\">1</span>, isOptimized: <span\
    \ class=\"pl-k\">true</span>, unit: <span class=\"pl-v\">!0</span>, retainedNodes:\
    \ <span class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!9</span> = <span class=\"\
    pl-v\">!DIFile</span>(filename: <span class=\"pl-s\">\"&lt;stdin&gt;\"</span>,\
    \ directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"</span>)\n<span class=\"\
    pl-v\">!10</span> = <span class=\"pl-v\">!DISubroutineType</span>(types: <span\
    \ class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!11</span> = <span class=\"\
    pl-v\">!DILocation</span>(line: <span class=\"pl-c1\">1</span>, column: <span\
    \ class=\"pl-c1\">12</span>, scope: <span class=\"pl-v\">!8</span>)</pre></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">SystemBenchmarks.jl</h2><a\
    \ id=\"user-content-systembenchmarksjl\" class=\"anchor\" aria-label=\"Permalink:\
    \ SystemBenchmarks.jl\" href=\"#systembenchmarksjl\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>I ran <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl\"\
    ><code>SystemBenchmarks.jl</code></a> on a\ncompute node.  Here are the results:\n\
    <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\"\
    >https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968</a>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">BLAS</h2><a id=\"\
    user-content-blas\" class=\"anchor\" aria-label=\"Permalink: BLAS\" href=\"#blas\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>OpenBLAS seems to have poor performance:</p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">2.589865257047898e10</span></pre></div>\n\
    <p>Up to v1.7, Julia uses OpenBLAS v0.3.17, which actually doesn't support A64FX\
    \ at all, so\nit's probably using the generic kernels.\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.19\"\
    ><code>v0.3.19</code></a> and\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.20\"\
    ><code>v0.3.20</code></a> improved support for\nthis chip, you can find a build\
    \ of 0.3.20 at\n<a href=\"https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\"\
    >https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz</a>,\n\
    but sadly there isn't a great performance improvement:</p>\n<div class=\"highlight\
    \ highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">lbt_forward</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>lib/libopenblas64_.so<span class=\"pl-pds\"\
    >\"</span></span>)\n<span class=\"pl-c1\">4856</span>\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.6362952057793587e10</span></pre></div>\n\
    <p>There is an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/Library/BLASLAPACKScaLAPACKLibrary.html#how-to-dynamically-load-and-use-blas-lapack-and-scalapack\"\
    \ rel=\"nofollow\">optimised\nBLAS</a>\nprovided by Fujitsu, with support for\
    \ SVE (with both LP64 and ILP64).  In order to use it,\ninstall <a href=\"https://github.com/giordano/FujitsuBLAS.jl\"\
    ><code>FujitsuBLAS.jl</code></a></p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ FujitsuBLAS, LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">get_config</span>()\nLinearAlgebra<span\
    \ class=\"pl-k\">.</span>BLAS<span class=\"pl-k\">.</span>LBTConfig\nLibraries<span\
    \ class=\"pl-k\">:</span>\n\u2514 [ILP64] libfjlapackexsve_ilp64<span class=\"\
    pl-k\">.</span>so\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">4.801227630694119e10</span></pre></div>\n\
    <p>The package <a href=\"https://github.com/carstenbauer/BLISBLAS.jl\"><code>BLISBLAS.jl</code></a>\
    \ similarly forwards\nBLAS calls to the <a href=\"https://github.com/flame/blis\"\
    >blis</a> library, which has optimised kernels\nfor A64FX.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Building Julia from source</h2><a\
    \ id=\"user-content-building-julia-from-source\" class=\"anchor\" aria-label=\"\
    Permalink: Building Julia from source\" href=\"#building-julia-from-source\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">with GCC</h3><a id=\"\
    user-content-with-gcc\" class=\"anchor\" aria-label=\"Permalink: with GCC\" href=\"\
    #with-gcc\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Building Julia from source with GCC (which is the default if you don't set\
    \ <code>CC</code> and <code>CXX</code>)\nworks fine, it's just <em>slow</em>:</p>\n\
    <pre><code>[...]\n    JULIA usr/lib/julia/corecompiler.ji\nCore.Compiler \u2500\
    \u2500\u2500\u2500 903.661 seconds\n[...]\nBase  \u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500271.257337 seconds\nArgTools \
    \ \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 50.348227 seconds\nArtifacts\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.193792 seconds\nBase64\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.057241\
    \ seconds\nCRC32c  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.097865 seconds\nFileWatching  \u2500\u2500\u2500\u2500\u2500  1.169747\
    \ seconds\nLibdl  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.026215 seconds\nLogging  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  0.411966 seconds\nMmap  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.972844 seconds\nNetworkOptions \
    \ \u2500\u2500\u2500  1.159094 seconds\nSHA  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.067851 seconds\nSerialization\
    \  \u2500\u2500\u2500\u2500  2.942512 seconds\nSockets  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.568797 seconds\nUnicode  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.814165 seconds\nDelimitedFiles \
    \ \u2500\u2500\u2500  1.121546 seconds\nLinearAlgebra  \u2500\u2500\u2500\u2500\
    109.560774 seconds\nMarkdown  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  7.977584 seconds\nPrintf  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  1.635409 seconds\nRandom  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 13.843395 seconds\nTar  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.146368 seconds\n\
    Dates  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 16.694863 seconds\nDistributed  \u2500\u2500\u2500\u2500\u2500\u2500  8.163152\
    \ seconds\nFuture  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.060472 seconds\nInteractiveUtils  \u2500  5.245523 seconds\nLibGit2\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 15.469061 seconds\n\
    Profile  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  5.399918\
    \ seconds\nSparseArrays  \u2500\u2500\u2500\u2500\u2500 42.660136 seconds\nUUIDs\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.165799\
    \ seconds\nREPL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500 40.149298 seconds\nSharedArrays  \u2500\u2500\u2500\u2500\u2500 \
    \ 5.476926 seconds\nStatistics  \u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.130843\
    \ seconds\nSuiteSparse  \u2500\u2500\u2500\u2500\u2500\u2500 16.849304 seconds\n\
    TOML  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.714203 seconds\nTest  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500  3.538098 seconds\nLibCURL  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.547585 seconds\nDownloads  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.657012 seconds\nPkg  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 54.053634 seconds\n\
    LazyArtifacts  \u2500\u2500\u2500\u2500  0.019103 seconds\nStdlibs total  \u2500\
    \u2500\u2500\u2500427.178257 seconds\nSysimage built. Summary:\nTotal \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 698.447219 seconds\nBase: \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500 271.257337 seconds 38.8372%\nStdlibs: \u2500\u2500\u2500\u2500\
    \ 427.178257 seconds 61.1611%\n[...]\nPrecompilation complete. Summary:\nTotal\
    \ \u2500\u2500\u2500\u2500\u2500\u2500\u2500 1274.714700 seconds\nGeneration \u2500\
    \u2500 886.445205 seconds 69.5407%\nExecution \u2500\u2500\u2500 388.269495 seconds\
    \ 30.4593%\n</code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >With Fujitsu compiler</h3><a id=\"user-content-with-fujitsu-compiler\" class=\"\
    anchor\" aria-label=\"Permalink: With Fujitsu compiler\" href=\"#with-fujitsu-compiler\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><em>For reference, the version used for the last build I attempted was\n<a\
    \ href=\"https://github.com/JuliaLang/julia/commit/1ad2396f05fa63a71e5842c814791cd7c7715100\"\
    ><code>1ad2396f</code></a></em></p>\n<p>Compiling Julia from source with the Fujitsu\
    \ compiler is complicated.  In particular, it's\nan absolute pain to use the Fujitsu\
    \ compiler in trad mode.  You can have some more luck with\nclang mode.</p>\n\
    <p>Preparation.  Create the <code>Make.user</code> file with this content (I'm\
    \ not sure this file is\nactually necessary when using Clang mode, but it definitely\
    \ is with trad mode):</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-k\">override</span> <span class=\"pl-smi\">ARCH</span>\
    \ := aarch64\n<span class=\"pl-k\">override</span> <span class=\"pl-smi\">BUILD_MACHINE</span>\
    \ := aarch64-unknown-linux-gnu</pre></div>\n<p>Then you can compile with (<code>-Nclang</code>\
    \ is to select clang mode)</p>\n<pre><code>make -j50 CC=\"fcc -Nclang\" CFLAGS=\"\
    -Kopenmp\" CXX=\"FCC -Nclang\" CXXFLAGS=\"-Kopenmp\"\n</code></pre>\n<p>The compiler\
    \ in trad mode doesn't define the macro <code>__SIZEOF_POINTER__</code>, so compilation\n\
    would fail in\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115</a>.\n\
    The solution is to set the macro <code>-D__SIZEOF_POINTER__=8</code> in the <code>CFLAGS</code>\
    \ (or just not use\ntrad mode).  Then, you may get errors like</p>\n<pre><code>/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2000:13:\
    \ error: initializer element is not a compile-time constant\n            jl_typename_type,\n\
    \            ^~~~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    /vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2025:43: error: initializer\
    \ element is not a compile-time constant\n    jl_typename_type-&gt;types = jl_svec(13,\
    \ jl_symbol_type, jl_any_type /*jl_module_type*/,\n                          \
    \                ^~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    </code></pre>\n<p>This is the compiler's fault, which is supposed to be able to\
    \ handle this, but you can just\ndelete the assertions at lines\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446</a>.</p>\n\
    <p>If you're lucky enough, with all these changes, you may be able to build <code>usr/bin/julia</code>.\n\
    Unfortunately, last time I tried, run this executable causes a segmentation fault\
    \ in\n<code>dl_init</code>:</p>\n<pre><code>(gdb) run\nStarting program: /vol0003/ra000019/a04463/repo/julia/julia\n\
    Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-151.el8.aarch64\n\
    [Thread debugging using libthread_db enabled]\nUsing host libthread_db library\
    \ \"/lib64/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation\
    \ fault.\n0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\n\
    Missing separate debuginfos, use: yum debuginfo-install FJSVxoslibmpg-2.0.0-25.14.1.el8.aarch64\
    \ elfutils-libelf-0.182-3.el8.aarch64\n(gdb) bt\n#0  0x000040000000def4 in _dl_init\
    \ () from /lib/ld-linux-aarch64.so.1\n#1  0x000040000020adb0 in _dl_catch_exception\
    \ () from /lib64/libc.so.6\n#2  0x00004000000125e4 in dl_open_worker () from /lib/ld-linux-aarch64.so.1\n\
    #3  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#4  0x0000400000011aa8\
    \ in _dl_open () from /lib/ld-linux-aarch64.so.1\n#5  0x0000400000091094 in dlopen_doit\
    \ () from /lib64/libdl.so.2\n#6  0x000040000020ad54 in _dl_catch_exception ()\
    \ from /lib64/libc.so.6\n#7  0x000040000020ae20 in _dl_catch_error () from /lib64/libc.so.6\n\
    #8  0x00004000000917f0 in _dlerror_run () from /lib64/libdl.so.2\n#9  0x0000400000091134\
    \ in dlopen@@GLIBC_2.17 () from /lib64/libdl.so.2\n#10 0x0000400000291f34 in load_library\
    \ (rel_path=0x400001e900c6 &lt;dep_libs+30&gt; \"libjulia-internal.so.1\", src_dir=&lt;optimized\
    \ out&gt;, err=1) at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:65\n\
    #11 0x0000400000291c78 in jl_load_libjulia_internal () at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:200\n\
    #12 0x000040000000de04 in call_init.part () from /lib/ld-linux-aarch64.so.1\n\
    #13 0x000040000000df08 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#14 0x0000400000001044\
    \ in _dl_start_user () from /lib/ld-linux-aarch64.so.1\nBacktrace stopped: previous\
    \ frame identical to this frame (corrupt stack?)\n</code></pre>\n"
  stargazers_count: 10
  subscribers_count: 2
  topics: []
  updated_at: 1690337110.0
goma/goma:
  data_format: 2
  description: A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport
  filenames:
  - spack.yaml
  full_name: goma/goma
  latest_release: v7.6.1
  readme: '<div class="markdown-heading"><h1 class="heading-element">Goma</h1><a id="user-content-goma"
    class="anchor" aria-label="Permalink: Goma" href="#goma"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport</p>

    <p>For more information see the <a href="https://www.gomafem.com" rel="nofollow">Goma
    website</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Documentation</h2><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Most of the documentation can be found at <a href="https://www.gomafem.com/documentation.html"
    rel="nofollow">https://www.gomafem.com/documentation.html</a></p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>See <a href="LICENSE">LICENSE</a> file.

    and are noted at the top of the cmake file.</p>

    <div class="markdown-heading"><h3 class="heading-element">Third party library
    licenses</h3><a id="user-content-third-party-library-licenses" class="anchor"
    aria-label="Permalink: Third party library licenses" href="#third-party-library-licenses"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h4 class="heading-element">CMake modules</h4><a
    id="user-content-cmake-modules" class="anchor" aria-label="Permalink: CMake modules"
    href="#cmake-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Some cmake modules under <code>cmake/</code> were modified from the Eigen library

    and are noted at the top of the cmake file.</p>

    <p>See licenses at <a href="https://gitlab.com/libeigen/eigen" rel="nofollow">https://gitlab.com/libeigen/eigen</a></p>

    <p>FindMETIS.cmake</p>

    <ul>

    <li>@copyright (c) 2009-2014 The University of Tennessee and The University</li>

    <li>

    <pre><code>                     of Tennessee Research Foundation.

    </code></pre>

    </li>

    <li>

    <pre><code>                     All rights reserved.

    </code></pre>

    </li>

    <li>@copyright (c) 2012-2014 Inria. All rights reserved.</li>

    <li>@copyright (c) 2012-2014 Bordeaux INP, CNRS (LaBRI UMR 5800), Inria, Univ.
    Bordeaux. All rights reserved.</li>

    </ul>

    <p>FindUMFPACK.cmake</p>

    <div class="markdown-heading"><h4 class="heading-element">nanoflann is included
    under the BSD license, please see <code>nanoflann.hpp</code>

    </h4><a id="user-content-nanoflann-is-included-under-the-bsd-license-please-see-nanoflannhpp"
    class="anchor" aria-label="Permalink: nanoflann is included under the BSD license,
    please see nanoflann.hpp" href="#nanoflann-is-included-under-the-bsd-license-please-see-nanoflannhpp"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>Copyright 2008-2009  Marius Muja (<a href="mailto:mariusm@cs.ubc.ca">mariusm@cs.ubc.ca</a>).
    All rights reserved.</li>

    <li>Copyright 2008-2009  David G. Lowe (<a href="mailto:lowe@cs.ubc.ca">lowe@cs.ubc.ca</a>).
    All rights reserved.</li>

    <li>Copyright 2011-2022  Jose Luis Blanco (<a href="mailto:joseluisblancoc@gmail.com">joseluisblancoc@gmail.com</a>).</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Major Changes</h2><a
    id="user-content-major-changes" class="anchor" aria-label="Permalink: Major Changes"
    href="#major-changes"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>See <a href="CHANGES.md">CHANGES.md</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Build Instructions</h2><a
    id="user-content-build-instructions" class="anchor" aria-label="Permalink: Build
    Instructions" href="#build-instructions"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>See <a href="BUILD.md">BUILD.md</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Spack package</h2><a
    id="user-content-spack-package" class="anchor" aria-label="Permalink: Spack package"
    href="#spack-package"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The Spack package manager <a href="https://spack.io/" rel="nofollow">https://spack.io</a>
    can be used to install

    Goma and all of Goma''s third party libraries</p>

    <p>Currently available on the <code>develop</code> branch of spack.</p>

    <p>Example for a bash-like shell:</p>

    <pre><code>git clone https://github.com/spack/spack.git

    . spack/share/spack/setup-env.sh

    spack install goma

    </code></pre>

    <p>For more information on build options see:</p>

    <pre><code>spack info goma

    </code></pre>

    <p>For more information on using spack see the <a href="https://spack.readthedocs.io/en/latest/"
    rel="nofollow">spack documentation</a>.</p>

    <div class="markdown-heading"><h2 class="heading-element">Third party libraries</h2><a
    id="user-content-third-party-libraries" class="anchor" aria-label="Permalink:
    Third party libraries" href="#third-party-libraries"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>Metis 5.1.0 (Optional)</li>

    <li>SEACAS 2022-01-27 (Required: Exodus and Aprepro)</li>

    <li>BLAS/LAPACK (Configured through Trilinos)</li>

    <li>Trilinos matrix solvers 13.0.1 and up (Required: AztecOO, Amesos, Epetra,
    TPL LAPACK; Optional: Stratimikos [with Teko, Ifpack, Belos, Tpetra])</li>

    <li>PETSc matrix solvers (KSP, PC)</li>

    <li>MUMPS 5.4.0 (through Trilinos or PETSc only)</li>

    <li>Superlu_dist 7.2.0 (through Trilinos or PETSc only, Trilinos requires parmetis
    build)</li>

    <li>UMFPACK, SuiteSparse 5.10.1 (Optional)</li>

    <li>ARPACK/arpack-ng 3.8.0 (Optional)</li>

    <li>sparse 1.4b (Optional)</li>

    <li>Catch2 (Optional testing)</li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">Run the tutorial</h3><a
    id="user-content-run-the-tutorial" class="anchor" aria-label="Permalink: Run the
    tutorial" href="#run-the-tutorial"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>To get started with Goma, use the following:</p>

    <ul>

    <li><a href="https://docs.gomafem.com/files/goma-beginners-tutorial.pdf" rel="nofollow">Tutorial
    instructions</a></li>

    <li><a href="https://docs.gomafem.com/files/goma_beginners_tutorial.tar.gz" rel="nofollow">Tutorial
    files tarball</a></li>

    </ul>

    '
  stargazers_count: 107
  subscribers_count: 26
  topics:
  - finite-elements
  - finite-element-analysis
  - simulation
  - parallel
  - multiphysics
  - fem
  - snl-applications
  updated_at: 1715913905.0
haampie/sirius-appimage:
  data_format: 2
  description: SIRIUS AppImage (using just the bare minimum)
  filenames:
  - libtree/spack.yaml
  full_name: haampie/sirius-appimage
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Creating\
    \ an AppImage from a spack environment</h1><a id=\"user-content-creating-an-appimage-from-a-spack-environment\"\
    \ class=\"anchor\" aria-label=\"Permalink: Creating an AppImage from a spack environment\"\
    \ href=\"#creating-an-appimage-from-a-spack-environment\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>HPC container runtimes\
    \ often use squashfs as an archive to store an image, which is then mounted on\
    \ compute nodes and made writeable using overlayfs where the top layer is a ramfs.\
    \ This trick gives good performance particularly on shared filesystems, since\
    \ the squashfs file is a single blob on the disk and has good caching behavior.</p>\n\
    <p>However, perfect isolation from the host system is not always possible, in\
    \ particular when vendor optimized libraries (e.g. cuda and mpi) have to be mounted\
    \ into the container, and the question is what the point of containers really\
    \ is if they still depend on the host system.</p>\n<p>Instead of using containers,\
    \ one can still deploy applications as a single self-contained blob on the filesystem\
    \ by using the AppImage runtime. The basic idea is to create an executable which\
    \ unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo\
    \ shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\"\
    >SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a>\
    \ and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\"\
    >AppImage runtime</a>.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Building</h2><a id=\"user-content-building\" class=\"anchor\" aria-label=\"Permalink:\
    \ Building\" href=\"#building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<div class=\"highlight highlight-text-shell-session\"><pre>$\
    \ <span class=\"pl-s1\">./build.sh</span></pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Running</h2><a id=\"user-content-running\" class=\"\
    anchor\" aria-label=\"Permalink: Running\" href=\"#running\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n\
    <span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git\
    \ hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    <span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\"\
    >build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time\
    \     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI\
    \ ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                 \
    \     : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\
    \n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n\
    <span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"\
    pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n\
    <span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"\
    pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"\
    pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n\
    <span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in\
    \ Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=\
    \   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double}\
    \ default value for APW linearization energies</span>\n<span class=\"pl-c1\">\
    \  --auto_enu allow search of APW linearization energies</span>\n<span class=\"\
    pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\"\
    >  --rel      use scalar-relativistic solver</span></pre></div>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Running on piz daint</h2><a id=\"\
    user-content-running-on-piz-daint\" class=\"anchor\" aria-label=\"Permalink: Running\
    \ on piz daint\" href=\"#running-on-piz-daint\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>For Piz Daint I've modified the <code>sirius/spack.yaml</code>\
    \ a bit so that it links against system libmpi.so (<code>^cray-mpich</code> that\
    \ is):</p>\n<pre><code>daint103 $ ./build.sh\n...\n\ndaint103 $ du -sh sirius.app\
    \ # binary size (includes compressed squashfs)\n26M\tsirius.app\n\ndaint103 $\
    \ ./sirius.app --appimage-extract # runtime allows you to extract\nsquashfs-root/AppRun\n\
    squashfs-root/usr\nsquashfs-root/usr/bin\nsquashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\n\
    squashfs-root/usr/lib\nsquashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\n\
    squashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n\
    ...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\
    \ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf\
    \ # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\n\
    srun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\n\
    input file does not exist\n===========================================================================================================\n\
    \                            #         Total          %   Parent %        Median\
    \           Min           Max\n-----------------------------------------------------------------------------------------------------------\n\
    sirius                      1       2.30 ms     100.00     100.00       2.30 ms\
    \       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms   \
    \   60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize\
    \        1     333.28 us      14.52      14.52     333.28 us     333.28 us   \
    \  333.28 us\n\n===========================================================================================================\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1616508538.0
hipdac-lab/SC23-AMRIC:
  data_format: 2
  description: 'Artifacts of SC''23 paper "AMRIC: A Novel In Situ Lossy Compression
    Framework for Efficient I/O in Adaptive Mesh Refinement Applications"'
  filenames:
  - warpx_directory/WarpX/Docs/spack.yaml
  full_name: hipdac-lab/SC23-AMRIC
  latest_release: v0.1.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">AMRIC: A\
    \ Novel In Situ Lossy Compression Framework for Efficient I/O in Adaptive Mesh\
    \ Refinement Applications</h1><a id=\"user-content-amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    \ class=\"anchor\" aria-label=\"Permalink: AMRIC: A Novel In Situ Lossy Compression\
    \ Framework for Efficient I/O in Adaptive Mesh Refinement Applications\" href=\"\
    #amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a href=\"https://zenodo.org/badge/latestdoi/658166802\" rel=\"nofollow\"><img\
    \ src=\"https://camo.githubusercontent.com/d0d2e976dd91e413f1525d14e8ca69f13f70ff17c5c7e104fd4bff574a3cd689/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3635383136363830322e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/658166802.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>AMRIC is a novel in-situ lossy compression framework\
    \ that leverages the HDF5 filter to enhance both I/O efficiency and compression\
    \ quality for Adaptive Mesh Refinement (AMR) applications. AMRIC was integrated\
    \ into the <a href=\"https://amrex-codes.github.io/amrex/\" rel=\"nofollow\">AMReX</a>\
    \ framework and evaluated on two real-world AMR applications, Nyx and WarpX.</p>\n\
    <p>While preparing the artifacts, we executed them on a single node from the Chameleon\
    \ Cloud, equipped with two Intel Xeon Gold 6242 CPUs and 192 GB of memory (specifically,\
    \ <code>compute_skylake</code> configuration). We recommend that reviewers also\
    \ use the Chameleon Cloud for artifact evaluation.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Method 1: Use Singularity Image (Recommended)</h2><a\
    \ id=\"user-content-method-1-use-singularity-image-recommended\" class=\"anchor\"\
    \ aria-label=\"Permalink: Method 1: Use Singularity Image (Recommended)\" href=\"\
    #method-1-use-singularity-image-recommended\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>The entire workflow takes approximately\
    \ 10 minutes to execute, including downloading container image and preparing environment\
    \ (3 mins), running WarpX simulation (3 mins), running Nyx simulation (3 mins),\
    \ and evaluating compression performance (1 min).</p>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Minimum system requirements</h3><a id=\"user-content-minimum-system-requirements\"\
    \ class=\"anchor\" aria-label=\"Permalink: Minimum system requirements\" href=\"\
    #minimum-system-requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>OS: Ubuntu (20.04 is recommended)</p>\n<p>Memory: &gt;=\
    \ 16 GB RAM</p>\n<p>Processor: &gt;= 8 cores</p>\n<p>Storage: &gt;= 32 GBs</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 1: Install\
    \ Singularity</h3><a id=\"user-content-step-1-install-singularity\" class=\"anchor\"\
    \ aria-label=\"Permalink: Step 1: Install Singularity\" href=\"#step-1-install-singularity\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Install <a href=\"https://singularity-tutorial.github.io/01-installation/\"\
    \ rel=\"nofollow\">Singularity</a></p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Step 2: Download the pre-built Singularity image file via gdown</h3><a\
    \ id=\"user-content-step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 2: Download the pre-built Singularity\
    \ image file via gdown\" href=\"#step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Press Enter after finishing.</p>\n<pre><code>sudo apt-get install python3-pip\n\
    sudo pip3 install gdown\ngdown https://drive.google.com/uc?id=14v_xUmET-HvCFO3LqmD4sNJL65jBcd0L&amp;export=download\n\
    </code></pre>\n<p>or via GitHub</p>\n<pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC-Image.git\n\
    cat SC23-AMRIC-Image/img/amric.sif-* &gt; amric.sif\n</code></pre>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\">Step 3: Build and run the image\
    \ file (need root privilege)</h3><a id=\"user-content-step-3-build-and-run-the-image-file-need-root-privilege\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 3: Build and run the image file\
    \ (need root privilege)\" href=\"#step-3-build-and-run-the-image-file-need-root-privilege\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>sudo singularity build --sandbox artiAmr amric.sif\nsudo singularity\
    \ shell --writable artiAmr\n</code></pre>\n<div class=\"markdown-heading\"><h3\
    \ class=\"heading-element\">Step 4: Set up environmental variables</h3><a id=\"\
    user-content-step-4-set-up-environmental-variables\" class=\"anchor\" aria-label=\"\
    Permalink: Step 4: Set up environmental variables\" href=\"#step-4-set-up-environmental-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>export OMPI_DIR=/opt/ompi \nexport OMPI_VERSION=4.1.1\nexport PATH=$OMPI_DIR/bin:$PATH\n\
    export LD_LIBRARY_PATH=$OMPI_DIR/lib:$LD_LIBRARY_PATH\nexport MANPATH=$OMPI_DIR/share/man:$MANPATH\n\
    export C_INCLUDE_PATH=/opt/ompi/include:$C_INCLUDE_PATH\nexport CPLUS_INCLUDE_PATH=/opt/ompi/include:$CPLUS_INCLUDE_PATH\n\
    export OMPI_ALLOW_RUN_AS_ROOT=1\nexport OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1\n</code></pre>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 5: Run WarpX\
    \ simulation with no compression, AMReX's original compression, and AMRIC</h3><a\
    \ id=\"user-content-step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 5: Run WarpX simulation with no\
    \ compression, AMReX's original compression, and AMRIC\" href=\"#step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd /home/wpx256/\n. bash.sh\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Step 6: Run NYX simulation with no compression,\
    \ AMReX's original compression, and AMRIC</h3><a id=\"user-content-step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 6: Run NYX simulation with no\
    \ compression, AMReX's original compression, and AMRIC\" href=\"#step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd /home/nyx128/\n. bash.sh\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Step 7: Evaluate WarpX's data quality and compression\
    \ ratio for original AMReX compression and our AMRIC</h3><a id=\"user-content-step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 7: Evaluate WarpX's data quality\
    \ and compression ratio for original AMReX compression and our AMRIC\" href=\"\
    #step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd /home/wpx256/diags/\n. decomp.sh &gt; temp.txt\n. qualityCR.sh\n\
    </code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\">Step\
    \ 8: Evaluate NYX's data quality and compression ratio for original AMReX compression\
    \ and our AMRIC</h3><a id=\"user-content-step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 8: Evaluate NYX's data quality\
    \ and compression ratio for original AMReX compression and our AMRIC\" href=\"\
    #step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd /home/nyx128/run/\n. decomp.sh &gt; temp.txt\n. qualityCR.sh\n</code></pre>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 9: Compare\
    \ I/O perf for baselines (i.e., no compression and ori AMReX compression) and\
    \ AMRIC in WarpX</h3><a id=\"user-content-step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 9: Compare I/O perf for baselines\
    \ (i.e., no compression and ori AMReX compression) and AMRIC in WarpX\" href=\"\
    #step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd /home/wpx256/otfile/\n. io.sh\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Step 10: Compare I/O performance between baselines\
    \ and AMRIC in NYX</h3><a id=\"user-content-step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 10: Compare I/O performance between\
    \ baselines and AMRIC in NYX\" href=\"#step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd /home/nyx128/otfile/\n. io.sh\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Method 2: Build From Source</h2><a id=\"user-content-method-2-build-from-source\"\
    \ class=\"anchor\" aria-label=\"Permalink: Method 2: Build From Source\" href=\"\
    #method-2-build-from-source\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Minimum system &amp; software libraries requirements</h3><a id=\"user-content-minimum-system--software-libraries-requirements\"\
    \ class=\"anchor\" aria-label=\"Permalink: Minimum system &amp; software libraries\
    \ requirements\" href=\"#minimum-system--software-libraries-requirements\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>OS:\
    \ Linux (Ubuntu is recommended)</p>\n<p>Memory: &gt;= 16 GB RAM</p>\n<p>Processor:\
    \ &gt;= 8 cores</p>\n<p>gcc/9.4.0 (or 9.3.0)</p>\n<p>cmake (&gt;= 3.23)</p>\n\
    <p>OpenMPI/4.1.1 (install scripts provided, or spectrum-mpi)</p>\n<p>python/3.8</p>\n\
    <p>hdf5/1.12.2 (install scripts provided)</p>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Step 1: Download AMRIC, checkpoint files, and set\
    \ up environmental variables (2 mins)</h3><a id=\"user-content-step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 1: Download AMRIC, checkpoint\
    \ files, and set up environmental variables (2 mins)\" href=\"#step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC.git\ncd SC23-AMRIC\n\
    export AMRIC_HOME=$(pwd)\necho \"# start of AMRIC env\" &gt;&gt; ~/.bashrc\necho\
    \ export AMRIC_HOME=$(pwd) &gt;&gt; ~/.bashrc\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Step 2: Load or install CMake and numpy. For example,\
    \ in Ubuntu</h3><a id=\"user-content-step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 2: Load or install CMake and numpy.\
    \ For example, in Ubuntu\" href=\"#step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>pip3 install numpy\nsudo snap install cmake --classic\n</code></pre>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 3: Load or\
    \ install OpenMPI. For example, in Ubuntu (7 mins)</h3><a id=\"user-content-step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 3: Load or install OpenMPI. For\
    \ example, in Ubuntu (7 mins)\" href=\"#step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>sudo bash openmpi.sh \n. mpi_env.sh\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">Step 4: Download and install the HDF5 library (4\
    \ mins)</h3><a id=\"user-content-step-4-download-and-install-the-hdf5-library-4-mins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 4: Download and install the HDF5\
    \ library (4 mins)\" href=\"#step-4-download-and-install-the-hdf5-library-4-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>. hdf5.sh\n</code></pre>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Step 5: Install optimized SZ3 compressor and H5Z-SZ3 compression\
    \ filter (5 mins)</h3><a id=\"user-content-step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 5: Install optimized SZ3 compressor\
    \ and H5Z-SZ3 compression filter (5 mins)\" href=\"#step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>. compressor.sh\n</code></pre>\n<div class=\"markdown-heading\"><h3\
    \ class=\"heading-element\">Step 6: Install AMReX and Nyx with AMRIC (8 mins)</h3><a\
    \ id=\"user-content-step-6-install-amrex-and-nyx-with-amric-8-mins\" class=\"\
    anchor\" aria-label=\"Permalink: Step 6: Install AMReX and Nyx with AMRIC (8 mins)\"\
    \ href=\"#step-6-install-amrex-and-nyx-with-amric-8-mins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<pre><code>. nyx.sh\n\
    </code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\">Step\
    \ 7: Install WarpX with AMRIC (9 mins)</h3><a id=\"user-content-step-7-install-warpx-with-amric-9-mins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 7: Install WarpX with AMRIC (9\
    \ mins)\" href=\"#step-7-install-warpx-with-amric-9-mins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<pre><code>. warpx.sh\n\
    </code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\">Step\
    \ 8: Download qcat (compression analysis tool, 1 min)</h3><a id=\"user-content-step-8-download-qcat-compression-analysis-tool-1-min\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 8: Download qcat (compression\
    \ analysis tool, 1 min)\" href=\"#step-8-download-qcat-compression-analysis-tool-1-min\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>. qcat.sh\n</code></pre>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Step 9: Run WarpX with no compression, AMReX\u2019s original\
    \ compression, and AMRIC (3 mins)</h3><a id=\"user-content-step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 9: Run WarpX with no compression,\
    \ AMReX\u2019s original compression, and AMRIC (3 mins)\" href=\"#step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd $AMRIC_HOME/warpx_directory/WarpX\n. runwarpx.sh\n</code></pre>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 10: Run NYX\
    \ with no compression, AMReX\u2019s original compression, and AMRIC (3 mins).</h3><a\
    \ id=\"user-content-step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 10: Run NYX with no compression,\
    \ AMReX\u2019s original compression, and AMRIC (3 mins).\" href=\"#step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density\n. runnyx.sh\n</code></pre>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Step 11: Evaluate WarpX\u2019\
    s data quality and compression ratio for original AMReX compression and our AMRIC.</h3><a\
    \ id=\"user-content-step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 11: Evaluate WarpX\u2019s data\
    \ quality and compression ratio for original AMReX compression and our AMRIC.\"\
    \ href=\"#step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/diags\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des-w\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss-w .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack-w\
    \ .\ncp $AMRIC_HOME/qcat/install/bin/compareData .\n. decomp.sh &gt; out.txt\n\
    . qualityCR.sh\n</code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Step 12: Evaluate NYX\u2019s data quality and compression ratio for original\
    \ AMReX compression and our AMRIC.</h3><a id=\"user-content-step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 12: Evaluate NYX\u2019s data quality\
    \ and compression ratio for original AMReX compression and our AMRIC.\" href=\"\
    #step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/run\ncp $AMRIC_HOME/qcat/install/bin/compareData\
    \ .\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack .\n. decomp.sh &gt;\
    \ out.txt\n. qualityCR.sh\n</code></pre>\n<div class=\"markdown-heading\"><h3\
    \ class=\"heading-element\">Step 13: Compare I/O performance between baselines\
    \ (i.e., no compression and ori AMReX compression) and AMRIC in WarpX.</h3><a\
    \ id=\"user-content-step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 13: Compare I/O performance between\
    \ baselines (i.e., no compression and ori AMReX compression) and AMRIC in WarpX.\"\
    \ href=\"#step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/otfile\n. io.sh\n</code></pre>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Step 14: Compare\
    \ I/O performance between baselines (i.e., no compression and ori AMReX compression)\
    \ and AMRIC in Nyx.</h3><a id=\"user-content-step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    \ class=\"anchor\" aria-label=\"Permalink: Step 14: Compare I/O performance between\
    \ baselines (i.e., no compression and ori AMReX compression) and AMRIC in Nyx.\"\
    \ href=\"#step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/otfile\n. io.sh\n</code></pre>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Expected Evaluation\
    \ Results</h2><a id=\"user-content-expected-evaluation-results\" class=\"anchor\"\
    \ aria-label=\"Permalink: Expected Evaluation Results\" href=\"#expected-evaluation-results\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">The expected results\
    \ for WarpX\u2019s data quality and compression ratio (method 1 step 6) are:</h3><a\
    \ id=\"user-content-the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    \ class=\"anchor\" aria-label=\"Permalink: The expected results for WarpX\u2019\
    s data quality and compression ratio (method 1 step 6) are:\" href=\"#the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>----- Data Quality for original AMReX Compression -----\nPSNR = 58.600102\n\
    ---------- Data Quality for AMRIC-SZ-L/R ----------\nPSNR = 61.749515\n----------\
    \ Data Quality for AMRIC-SZInterp ----------\nPSNR = 59.146966\n---------- CR\
    \ for original AMReX Compression ----------\nCR is: 14.62\n---------- CR for AMRIC-SZ-L/R\
    \ ----------\nCR is: 108.94\n---------- CR for AMRIC-SZInterp ----------\nCR is:\
    \ 131.41\n</code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >The expected results for Nyx\u2019s data quality and compression ratio (method\
    \ 1 step 7) are:</h3><a id=\"user-content-the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    \ class=\"anchor\" aria-label=\"Permalink: The expected results for Nyx\u2019\
    s data quality and compression ratio (method 1 step 7) are:\" href=\"#the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>----- Data Quality for original AMReX Compression -----\nPSNR = 61.977332\n\
    ---------- Data Quality for AMRIC-SZ_L/R ----------\nPSNR = 66.650492\n----------\
    \ Data Quality for AMRIC-SZInterp ----------\nPSNR = 66.566370\n---------- CR\
    \ for original AMReX Compression ----------\nCR is: 6.53\n---------- CR for AMRIC-SZ_L/R\
    \ ----------\nCR is: 13.08\n---------- CR for AMRIC-SZInterp ----------\nCR is:\
    \ 11.25\n</code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >The expected results for WarpX\u2019s I/O performance  (method 1 step 8) are:</h3><a\
    \ id=\"user-content-the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    \ class=\"anchor\" aria-label=\"Permalink: The expected results for WarpX\u2019\
    s I/O performance  (method 1 step 8) are:\" href=\"#the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>---------- Writing Time for No Compression ----------\n***** run 0\
    \ *****\nNo Compression Total time = 1.514 seconds\nNo Compression Preprocess\
    \ time = 0.216 seconds\nNo Compression writing time = 1.322 seconds\n...\n------------------------\
    \ END ------------------------\n------ Writing Time for original AMReX Compression\
    \ ------\n***** run 0 *****\noriginal AMReX Total time = 4.734 seconds\noriginal\
    \ AMReX Preprocess time = 0.189 seconds\noriginal AMReX Writing+Compression time\
    \ = 4.493 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 1.115 seconds\nAMRIC-SZ_L/R Preprocess time = 0.223 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.906 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 1.878 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.950 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.937 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\">The\
    \ expected results for Nyx\u2019s I/O performance  (method 1 step 9) are:</h3><a\
    \ id=\"user-content-the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    \ class=\"anchor\" aria-label=\"Permalink: The expected results for Nyx\u2019\
    s I/O performance  (method 1 step 9) are:\" href=\"#the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <pre><code>---------- Writing Time for No Compression ----------\n***** run 0\
    \ *****\nNo Compression Total time = 0.195 seconds\nNo Compression Preprocess\
    \ time = 0.016 seconds\nNo Compression writing time = 0.177 seconds\n...\n------------------------\
    \ END ------------------------\n----- Writing Time for original AMReX Compression\
    \ -----\n***** run 0 *****\noriginal AMReX Total time = 0.674 seconds\noriginal\
    \ AMReX Preprocess time = 0.020 seconds\noriginal AMReX Writing+Compression time\
    \ = 0.649 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 0.182 seconds\nAMRIC-SZ_L/R Preprocess time = 0.018 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.155 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 0.230 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.102 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.122 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n"
  stargazers_count: 4
  subscribers_count: 2
  topics: []
  updated_at: 1712865449.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/5819b92f1cc8b5c1ad3c32b04e570ab6fcd993dc8388e1821fb2d601ee2c653f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/f944e4986dcda6a59f77a14d6f503238e4811f8c4bfef8479068d13873036548/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Overview</h2><a id="user-content-overview"
    class="anchor" aria-label="Permalink: Overview" href="#overview"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Available modules</h2><a
    id="user-content-available-modules" class="anchor" aria-label="Permalink: Available
    modules" href="#available-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>ReconX</code> - provider of different reconstruction schemes</li>

    <li>

    <code>TOVSolverX</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Getting started</h2><a
    id="user-content-getting-started" class="anchor" aria-label="Permalink: Getting
    started" href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    <div class="markdown-heading"><h2 class="heading-element">Related talks and tutorials</h2><a
    id="user-content-related-talks-and-tutorials" class="anchor" aria-label="Permalink:
    Related talks and tutorials" href="#related-talks-and-tutorials"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>"<a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html" rel="nofollow">Using
    CarpetX: A Guide for Early Adopters</a>".

    Recorded seminar talk by Erik Schnetter, providing an overview of the current
    capabilities of CarpetX.</li>

    <li>"<a href="https://einsteintoolkit.github.io/et2022uidaho/lectures/38-Tutorial8/index.html"
    rel="nofollow">Tutorial: GPUs and the Einstein Toolkit</a>".

    Recorded tutorial by Lorenzo Ennoggi, Jay Kalinani and Federico Lopez Armengol
    during the North American Einstein Toolkit workshop 2022, presenting a brief overview
    on AsterX, followed by a hands-on session.</li>

    <li>"<a href="https://drive.google.com/file/d/1Z4i--W56mxeNIu598LQTpEEowX56FOoD/view?usp=sharing"
    rel="nofollow">AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes</a>".

    Slides based on the talk by Jay Kalinani at the APS April Meeting 2023.</li>

    </ul>

    '
  stargazers_count: 16
  subscribers_count: 11
  topics: []
  updated_at: 1716427462.0
jedwards4b/spackenvironments:
  data_format: 2
  description: my spack environments for software builds
  filenames:
  - esmfserialbld/spack.yaml
  - esmfbld/spack.yaml
  full_name: jedwards4b/spackenvironments
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664981968.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - rice/gpu/gpu.spack.yaml
  - anl/polaris/polaris.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1658934301.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/rhodes/utilities/spack.yaml
  - configs/eagle/software/spack.yaml
  - configs/eagle/compilers/spack.yaml
  - envs/exawind/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Spack configuration
    files and scripts for use on machines at NREL</h1><a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" aria-label="Permalink: Spack configuration files and scripts for
    use on machines at NREL" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666717629.0
js947/spack-docker-test:
  data_format: 2
  description: testing spack's containerize command
  filenames:
  - spack.yaml
  full_name: js947/spack-docker-test
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"><img
    src="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"
    alt="Build container" style="max-width: 100%;"></a></p>

    <div class="markdown-heading"><h1 class="heading-element">spack-docker-test</h1><a
    id="user-content-spack-docker-test" class="anchor" aria-label="Permalink: spack-docker-test"
    href="#spack-docker-test"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>testing spack''s containerize command</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1606954982.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/contrib-compilers/spack.yaml
  - environments/key4hep-ci/spack.yaml
  - environments/key4hep-release/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<div class="markdown-heading"><h1 class="heading-element">

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4hep software
    packaging</h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-label="Permalink: Spack package repo for Key4hep software
    packaging" href="#spack-package-repo-for-key4hep-software-packaging"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This repository holds a set of Spack recipes for key4hep software.</p>

    <p>Consult the the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep documentation
    website</a> and the

    <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack documentation</a>
    for more details.</p>

    <div class="markdown-heading"><h2 class="heading-element">Spack Versions</h2><a
    id="user-content-spack-versions" class="anchor" aria-label="Permalink: Spack Versions"
    href="#spack-versions"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The spack recipes in this repository should work with any recent version of

    spack (at least 0.20 is needed because they use the <code>require</code> keyword
    which was

    introduced in <a href="https://github.com/spack/spack/releases/tag/v0.20.0">spack

    0.20</a>). The nightlies are

    currently built against the commit of spack that is in the

    <a href="https://github.com/key4hep/key4hep-spack/blob/main/.latest-commit"><code>.latest-commit</code></a>

    file in this repository. From time to time the most recent commit is picked to

    get the latest version of the spack recipes. The commit of spack that was used

    to build a stack can be found in the file <code>.spack-commit</code> that is shipped
    with

    every stack on cvmfs.</p>

    <div class="markdown-heading"><h2 class="heading-element">Repository Contents</h2><a
    id="user-content-repository-contents" class="anchor" aria-label="Permalink: Repository
    Contents" href="#repository-contents"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the

    repository contains a collection of environments used to build the stack in

    <code>environments</code> and some scripts used for publishing on cvmfs and other
    utilities

    in <code>scripts</code>. The builds run in Gitlab CI runners and the workflows
    can be found

    in the file <code>.gitlab-ci.yml</code> in the <a href="https://gitlab.cern.ch/key4hep/k4-deploy"
    rel="nofollow">gitlab

    repository</a>.</p>

    <p>Additionally, the file <code>.latest-commit</code> contains the latest commit
    of Spack used

    for the recent builds, which is updated from time to time to keep up with the

    develop branch of Spack. In addition, the file <code>.cherry-pick</code> contains
    some

    fixes needed to build the stack. These can also be found in the file

    <code>.cherry-pick</code> that is shipped with every stack on cvmfs.</p>

    <div class="markdown-heading"><h2 class="heading-element">Central Installations</h2><a
    id="user-content-central-installations" class="anchor" aria-label="Permalink:
    Central Installations" href="#central-installations"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org</code>
    (for

    CentOS 7) and <code>/cvmfs/sw-nightlies.hsf.org</code> (for CentOS 7, AlmaLinux
    9 and

    Ubuntu) see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Requirements</h2><a
    id="user-content-requirements" class="anchor" aria-label="Permalink: Requirements"
    href="#requirements"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>To compile the key4hep stack some system packages are required; without these,

    the spack concretization or compilation can fail. The packages needed are an

    OpenGL implementation that can be installed:</p>

    <div class="highlight highlight-source-shell"><pre>yum install -y mesa-libGL mesa-libGL-devel
    mesa-libGLU mesa-libGLU-devel      <span class="pl-c"><span class="pl-c">#</span>
    Centos 7</span>

    apt install -y libgl1-mesa-glx libgl1-mesa-dev libglu1-mesa libglu1-mesa-dev  <span
    class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    dnf install -y mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel      <span
    class="pl-c"><span class="pl-c">#</span> AlmaLinux 9</span></pre></div>

    <p>The environments that make use of these libraries or headers expect them to
    be

    found under <code>/usr</code>, which is the typical location when they are installed

    system-wide (for example in <code>/usr/include</code> or <code>/usr/lib</code>).</p>

    <p>Alternatively, one can install

    <a href="https://gitlab.cern.ch/linuxsupport/rpms/HEP_OSlibs" rel="nofollow">HEP_OSlibs</a>,
    which will

    install the previous and more libraries.</p>

    <p>In addition, for Ubuntu and Alma 9 the compilers are picked up from the system,

    so, for example, building in an image without <code>gcc</code> or <code>glibc</code>
    won''t work. These

    commands should install most of the compilers and the development tools:</p>

    <div class="highlight highlight-source-shell"><pre>apt install -y build-essential
    gfortran                            <span class="pl-c"><span class="pl-c">#</span>
    Ubuntu</span>

    dnf groupinstall -y <span class="pl-s"><span class="pl-pds">"</span>Development
    Tools<span class="pl-pds">"</span></span> <span class="pl-k">&amp;&amp;</span>
    dnf install -y gfortran <span class="pl-c"><span class="pl-c">#</span> AlmaLinux
    9</span></pre></div>

    <p>Dockerfiles with the images that are used to build the key4hep stack can be

    found in <a href="https://github.com/key4hep/key4hep-images">https://github.com/key4hep/key4hep-images</a>.</p>

    '
  stargazers_count: 8
  subscribers_count: 10
  topics: []
  updated_at: 1716877868.0
lanl/CELLAR:
  data_format: 2
  description: The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based
    adaptive mesh refinement data structures and execution for parallel computing
    architectures.
  filenames:
  - spack/snow/spack.yaml
  - spack/ci/spack.yaml
  full_name: lanl/CELLAR
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">CELLAR  -  EAP
    Core</h1><a id="user-content-cellar-----eap-core" class="anchor" aria-label="Permalink:
    CELLAR  -  EAP Core" href="#cellar-----eap-core"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>CELLAR is a C++ project that forms the foundation of cell based AMR for applications</p>

    <p>It provides the following:</p>

    <ul>

    <li>AMR Mesh Datastructure</li>

    <li>AMR Mesh Reconstruction</li>

    <li>Communication Patterns</li>

    <li>C++ Error Handling and Tracing</li>

    <li>Performance Monitoring</li>

    <li>C++/Fortran Interop</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Building</h2><a id="user-content-building"
    class="anchor" aria-label="Permalink: Building" href="#building"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The easiest way to install dependencies is using <a href="https://spack.io"
    rel="nofollow">Spack</a>.

    After

    <a href="https://spack.readthedocs.io/en/latest/getting_started.html" rel="nofollow">installing
    Spack</a>,

    you can start build dependencies.</p>

    <p>The following instructions assume that you have Spack 0.13 or newer. You can
    check your

    Spack version like so:</p>

    <pre><code>$ spack --version

    0.13.0

    </code></pre>

    <p>First, add <a href="https://github.com/lanl/cellar-spack">lanl/cellar-spack</a>

    to your list of spack repos.</p>

    <p>Once you have the <code>lanl/cellar-spack</code> installed, then you can install
    all

    dependencies using

    <a href="https://spack.readthedocs.io/en/latest/tutorial_environments.html#" rel="nofollow">Spack
    environments</a>.

    You''ll need to use a modern-ish C++ compiler that supports C++14:</p>

    <pre><code>$ module load gcc/9.3.0

    $ spack compiler find

    $ cd path/to/eap-core

    </code></pre>

    <p>Then issue the following commands. This will build all of eap-core''s dependencies.:</p>

    <pre><code>$ spack env create -d spack/default

    $ spack env activate -d $PWD/spack/default

    $ spack install

    </code></pre>

    <p>Any time you open a new shell, you''ll need to re-activate the Spack environment:</p>

    <pre><code>$ spack env activate -d $PWD/spack/default

    </code></pre>

    <p>Now you''re ready to build eap-core. First configure the project using CMake:</p>

    <pre><code>mkdir build &amp;&amp; cd build

    cmake ..

    </code></pre>

    <p>And then build:</p>

    <pre><code>make -j

    </code></pre>

    <p>For snow, substitute in spack/snow in the above instructions in place of spack/default.
    If you need

    to change the environment use "spack env deactivate".</p>

    <div class="markdown-heading"><h2 class="heading-element">Contributing</h2><a
    id="user-content-contributing" class="anchor" aria-label="Permalink: Contributing"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Code contributors should read the <a href="DEVELOPERS.md">Developers Guide</a>
    prior to

    sending a pull request.</p>

    '
  stargazers_count: 3
  subscribers_count: 7
  topics: []
  updated_at: 1694614627.0
lanl/SICM:
  data_format: 2
  description: Simplified Interface to Complex Memory
  filenames:
  - spack.yaml
  full_name: lanl/SICM
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">SICM</h1><a id="user-content-sicm"
    class="anchor" aria-label="Permalink: SICM" href="#sicm"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Simplified Interface to Complex Memory</p>

    <p><a href="https://github.com/lanl/SICM/actions"><img src="https://github.com/lanl/SICM/actions/workflows/sicm.yml/badge.svg"
    alt="GitHub Actions" style="max-width: 100%;"></a></p>

    <div class="markdown-heading"><h2 class="heading-element">Introduction</h2><a
    id="user-content-introduction" class="anchor" aria-label="Permalink: Introduction"
    href="#introduction"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This project is split into two interfaces: <code>low</code> and <code>high</code>.</p>

    <p>The <code>low</code> interface provides a minimal interface for application
    wanting to

    manage their own memory on heterogeneous memory tiers. It also provides an

    arena allocator that application developers can use to create <code>jemalloc</code>
    arenas

    on different memory tiers and allocate to those tiers.</p>

    <p>The <code>high</code> interface attempts to automatically manage the memory
    tiers for the

    application. It provides an LLVM compiler pass (and compiler wrappers) to

    automatically transform applications to make the appropriate <code>high</code>
    interface

    calls, as well as a runtime library which provides profiling for the

    application.  The profiling is currently meant to be used offline; that is,

    after enabling the profiling for an application run, the results are printed

    out at the end of the run, and that information must be fed into a second run

    to make use of it. An online approach is planned.</p>

    <div class="markdown-heading"><h2 class="heading-element">Dependencies</h2><a
    id="user-content-dependencies" class="anchor" aria-label="Permalink: Dependencies"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The only dependencies that you will need for the low-level interface

    are <code>libnuma</code> and <code>jemalloc</code>. We require that <code>jemalloc</code>
    be

    configured with the <code>je_</code> prefix (using the <code>--with-jemalloc-prefix</code>
    flag).

    <code>CMake</code> will use <code>pkg-config</code> to find <code>jemalloc</code>.</p>

    <p>For the high-level interface, you need an installation of LLVM. LLVM 4.0 and

    later have been tested, although 3.9 may possibly work. For the profiling, you

    will also need an installation of <code>libpfm</code>, which is a small helper
    library for

    <code>perf</code> that is available on most distributions.</p>

    <p>Additionally, several other packages are required, and can be installed through
    a package manager:</p>

    <div class="markdown-heading"><h3 class="heading-element">Binaries</h3><a id="user-content-binaries"
    class="anchor" aria-label="Permalink: Binaries" href="#binaries"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>A modern C compiler</li>

    <li>A modern C++ compiler</li>

    <li>A modern Fortran compiler</li>

    <li>CMake 3.0+</li>

    <li>Make</li>

    <li>numactl</li>

    <li>automake + friends (if jemalloc needs to be built)</li>

    </ul>

    <div class="markdown-heading"><h3 class="heading-element">Development Libraries</h3><a
    id="user-content-development-libraries" class="anchor" aria-label="Permalink:
    Development Libraries" href="#development-libraries"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>These packages are usually named <code>lib*-dev</code> or <code>lib*-devel</code>:</p>

    <ul>

    <li>numa</li>

    </ul>

    <p>Additional packages are required for the high level interface:</p>

    <ul>

    <li>hwloc</li>

    <li>llvm</li>

    <li>omp (if OpenMP is not available by default on your compilers)</li>

    <li>pfm4</li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Compilation</h2><a id="user-content-compilation"
    class="anchor" aria-label="Permalink: Compilation" href="#compilation"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <pre><code>export PKG_CONFIG_PATH=&lt;jemalloc prefix&gt;/lib/pkgconfig:$PKG_CONFIG_PATH

    mkdir build

    cd build

    cmake .. -DCMAKE_INSTALL_PREFIX=&lt;prefix&gt;

    make

    make install

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Low-Level API</h2><a
    id="user-content-low-level-api" class="anchor" aria-label="Permalink: Low-Level
    API" href="#low-level-api"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_init</code></td>

    <td>Detects all memory devices on system, returns a list of them.</td>

    </tr>

    <tr>

    <td><code>sicm_fini</code></td>

    <td>Frees up a device list and associated SICM data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_find_device</code></td>

    <td>Return the first device that matches a given type and page size.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc</code></td>

    <td>Allocates to a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_free</code></td>

    <td>Frees memory on a device.</td>

    </tr>

    <tr>

    <td><code>sicm_can_place_exact</code></td>

    <td>Returns whether or not a device supports exact placement.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc_exact</code></td>

    <td>Allocate memory on a device with an exact base address.</td>

    </tr>

    <tr>

    <td><code>sicm_numa_id</code></td>

    <td>Returns the NUMA ID that a device is on.</td>

    </tr>

    <tr>

    <td><code>sicm_device_page_size</code></td>

    <td>Returns the page size of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_eq</code></td>

    <td>Returns if two devices are equal or not.</td>

    </tr>

    <tr>

    <td><code>sicm_move</code></td>

    <td>Moves memory from one device to another.</td>

    </tr>

    <tr>

    <td><code>sicm_pin</code></td>

    <td>Pin the current process to a device''s memory.</td>

    </tr>

    <tr>

    <td><code>sicm_capacity</code></td>

    <td>Returns the capacity of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_avail</code></td>

    <td>Returns the amount of memory available on a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_model_distance</code></td>

    <td>Returns the distance of a given memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_is_near</code></td>

    <td>Returns whether or not a given memory device is nearby the current NUMA node.</td>

    </tr>

    <tr>

    <td><code>sicm_latency</code></td>

    <td>Measures the latency of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear2</code></td>

    <td>Measures a memory device''s linear access bandwidth.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random2</code></td>

    <td>Measures random access bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear3</code></td>

    <td>Measures the linear bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random3</code></td>

    <td>Measures the random access bandwidth of a memory device.</td>

    </tr>

    </tbody>

    </table>

    <div class="markdown-heading"><h2 class="heading-element">Arena Allocator API</h2><a
    id="user-content-arena-allocator-api" class="anchor" aria-label="Permalink: Arena
    Allocator API" href="#arena-allocator-api"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_arenas_list</code></td>

    <td>List all arenas created in the arena allocator.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_create</code></td>

    <td>Create a new arena on the given device.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_destroy</code></td>

    <td>Frees up an arena, deleting all associated data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_default</code></td>

    <td>Sets an arena as the default for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_default</code></td>

    <td>Gets the default arena for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_device</code></td>

    <td>Gets the device for a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_device</code></td>

    <td>Sets the memory device for a given arena. Moves all allocated memory already
    allocated to the arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_size</code></td>

    <td>Gets the size of memory allocated to the given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc</code></td>

    <td>Allocate to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc_aligned</code></td>

    <td>Allocate aligned memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_realloc</code></td>

    <td>Resize allocated memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_lookup</code></td>

    <td>Returns which arena a given pointer belongs to.</td>

    </tr>

    </tbody>

    </table>

    <div class="markdown-heading"><h2 class="heading-element">High-Level Interface</h2><a
    id="user-content-high-level-interface" class="anchor" aria-label="Permalink: High-Level
    Interface" href="#high-level-interface"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>The high-level interface is normally used with the compiler wrappers located
    in

    <code>bin/</code>. Users should use these wrappers to compile their applications,
    and a

    compiler pass will automatically transform the code so that it calls the

    high-level interface with the appropriate arguments, including initialization,

    destruction, and the proper allocation functions. Assuming the high-level

    interface is linked to the application as a shared library, it automatically

    initializes itself.  All heap allocation routines are replaced by calls to

    <code>void* sh_alloc(int id, size_t sz)</code>, which associates an ID with a
    given

    allocation and allocates the memory into an arena with other allocations of

    that ID.</p>

    <div class="markdown-heading"><h2 class="heading-element">Programming Practices</h2><a
    id="user-content-programming-practices" class="anchor" aria-label="Permalink:
    Programming Practices" href="#programming-practices"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ol>

    <li>All blocks use curly braces

    <ul>

    <li>Even one-line blocks</li>

    </ul>

    </li>

    <li>Constants on the left side of <code>==</code>

    <ul>

    <li><code>if(NULL == foo) { ...</code></li>

    </ul>

    </li>

    <li>Functions with no arguments are <code>(void)</code>

    </li>

    <li>No C++-style comments in C code</li>

    <li>No GCC extensions except in GCC-only code</li>

    <li>No C++ code in libraries

    <ul>

    <li>Discouraged in components</li>

    </ul>

    </li>

    <li>Always define preprocessor macros

    <ul>

    <li>Define logicals to 0 or 1 (vs. define or not define)</li>

    <li>Use <code>#if FOO</code>, not <code>#ifdef FOO</code>

    </li>

    </ul>

    </li>

    </ol>

    '
  stargazers_count: 26
  subscribers_count: 24
  topics: []
  updated_at: 1702677503.0
laristra/ristra_spackages:
  data_format: 2
  description: 'A mirror of Ristra''s internal gitlab repository. '
  filenames:
  - env/broadwell/flecsalemm-deps/spack.yaml
  full_name: laristra/ristra_spackages
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Ristra Spackages</h1><a
    id="user-content-ristra-spackages" class="anchor" aria-label="Permalink: Ristra
    Spackages" href="#ristra-spackages"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This repository contains the custom spackage files for the repos in laristra
    family.</p>

    <div class="markdown-heading"><h2 class="heading-element">Basic Usage</h2><a id="user-content-basic-usage"
    class="anchor" aria-label="Permalink: Basic Usage" href="#basic-usage"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>We assume the user wish to work in the home directory and already have a spack
    instance setup.  The minimum required version of spack is 0.15.2.</p>

    <p>To get the content of this repo</p>

    <pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git

    </code></pre>

    <p>To use the custom spackage files with your spack</p>

    <pre><code>$ spack repo add ristra_spackages/spack-repo

    ==&gt; Added repo with namespace ''lanl_ristra''.


    $ spack repo list

    ==&gt; 2 package repositories.

    lanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo

    builtin            /home/&lt;user&gt;/spack/var/spack/repos/builtin

    </code></pre>

    <p>[Optional]

    To ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code>
    into your spack config folder</p>

    <pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/

    </code></pre>

    <p>Please see the <a href="https://spack.readthedocs.io/en/latest/configuration.html"
    rel="nofollow">Spack documentation</a> for more detailed info.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1649449003.0
lcompilers/lpython:
  data_format: 2
  description: Python compiler
  filenames:
  - spack.yaml
  full_name: lcompilers/lpython
  latest_release: v0.21.2
  readme: '<div class="markdown-heading"><h1 class="heading-element">LPython</h1><a
    id="user-content-lpython" class="anchor" aria-label="Permalink: LPython" href="#lpython"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>LPython is an ahead-of-time compiler for Python written in C++. It is currently
    in alpha

    stage and under heavy development. LPython works on Windows, macOS and Linux.</p>

    <p>Some of the goals of LPython include:</p>

    <ul>

    <li>Providing the best possible performance for numerical and array-oriented code.</li>

    <li>Ahead-of-Time, fast compilation to binaries, plus interactive usage (Jupyter
    notebook).</li>

    <li>Cross-platform support.</li>

    <li>Being able to compile a subset of Python yet be fully compatible with it.</li>

    <li>Transforming Python code to other programming languages like C++ and Fortran.</li>

    <li>Exploring design patterns so that LPython can eventually compile all Python
    code.</li>

    <li>Providing excellent user-friendly diagnostic messages: error, warnings, hints,
    notes, etc.</li>

    </ul>

    <p>among many more.</p>

    <div class="markdown-heading"><h1 class="heading-element">Sponsors</h1><a id="user-content-sponsors"
    class="anchor" aria-label="Permalink: Sponsors" href="#sponsors"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>LPython has been sponsored by <a href="https://www.gsitechnology.com/" rel="nofollow">GSI
    Technology</a>.

    Our summer students were sponsored by Google Summer of Code via Python Software

    Foundation. The intermediate representation and backends are shared with

    LFortran, see that project for a list of sponsors.</p>

    <div class="markdown-heading"><h1 class="heading-element">Installation</h1><a
    id="user-content-installation" class="anchor" aria-label="Permalink: Installation"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Follow the steps below to install and run LPython on Linux, Windows or macOS.</p>

    <div class="markdown-heading"><h2 class="heading-element">Prerequisites</h2><a
    id="user-content-prerequisites" class="anchor" aria-label="Permalink: Prerequisites"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>

    <div class="markdown-heading"><h3 class="heading-element">Install Conda</h3><a
    id="user-content-install-conda" class="anchor" aria-label="Permalink: Install
    Conda" href="#install-conda"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Follow the instructions provided <a href="https://github.com/conda-forge/miniforge/#download">here</a>
    to install Conda on your platform (Linux, macOS and Windows) using a conda-forge
    distribution called Miniforge.</p>

    <p>For Windows, these are additional requirements:</p>

    <ul>

    <li>Miniforge Prompt</li>

    <li>Visual Studio (with "Desktop Development with C++" workload)</li>

    </ul>

    </li>

    <li>

    <div class="markdown-heading"><h3 class="heading-element">Set up your system</h3><a
    id="user-content-set-up-your-system" class="anchor" aria-label="Permalink: Set
    up your system" href="#set-up-your-system"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <ul>

    <li>

    <p>Linux</p>

    <ul>

    <li>

    <p>Run the following command to install some global build dependencies:</p>

    <div class="highlight highlight-source-shell"><pre>sudo apt-get install build-essential
    binutils-dev clang zlib1g-dev</pre></div>

    </li>

    </ul>

    </li>

    <li>

    <p>Windows</p>

    <ul>

    <li>

    <p>Download and install <a href="https://visualstudio.microsoft.com/downloads/"
    rel="nofollow">Microsoft Visual Studio Community</a> for free.</p>

    </li>

    <li>

    <p>Run the Visual Studio Installer. Download and install the "Desktop Development
    with C++" workload which will install the Visual C++ Compiler (MSVC).</p>

    </li>

    <li>

    <p>Launch the Miniforge prompt from the Desktop. It is recommended to use MiniForge
    instead of Powershell as the main terminal to build and write code for LPython.
    In the MiniForge Prompt, initialize the MSVC compiler using the below command:</p>

    <div class="highlight highlight-source-shell"><pre>call <span class="pl-s"><span
    class="pl-pds">"</span>C:\Program Files\Microsoft Visual Studio\2022\Community\Common7\Tools\VsDevCmd<span
    class="pl-pds">"</span></span> -arch=x64</pre></div>

    <p>You can optionally test MSVC via:</p>

    <div class="highlight highlight-source-shell"><pre>cl /<span class="pl-k">?</span>

    link /<span class="pl-k">?</span></pre></div>

    <p>Both commands must print several pages of help text.</p>

    </li>

    </ul>

    </li>

    <li>

    <p>Windows with WSL</p>

    <ul>

    <li>

    <p>Install Miniforge Prompt and add it to path:</p>

    <div class="highlight highlight-source-shell"><pre>wget  https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh
    -O miniconda.sh

    bash miniconda.sh -b -p <span class="pl-smi">$HOME</span>/conda_root

    <span class="pl-k">export</span> PATH=<span class="pl-s"><span class="pl-pds">"</span><span
    class="pl-smi">$HOME</span>/conda_root/bin:<span class="pl-smi">$PATH</span><span
    class="pl-pds">"</span></span>

    conda init bash <span class="pl-c"><span class="pl-c">#</span> (shell name)</span></pre></div>

    </li>

    <li>

    <p>Open a new terminal window and run the following commands to install dependencies:</p>

    <div class="highlight highlight-source-shell"><pre>conda create -n lp -c conda-forge
    llvmdev=11.0.1 bison=3.4 re2c python cmake make toml clangdev git</pre></div>

    </li>

    <li>

    <p>Optionally, you can change the directory to a Windows location using <code>cd
    /mnt/[drive letter]/[windows location]</code>. For e.g. - <code>cd mnt/c/Users/name/source/repos/</code>.</p>

    </li>

    </ul>

    </li>

    </ul>

    </li>

    <li>

    <div class="markdown-heading"><h3 class="heading-element">Clone the LPython repository</h3><a
    id="user-content-clone-the-lpython-repository" class="anchor" aria-label="Permalink:
    Clone the LPython repository" href="#clone-the-lpython-repository"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Make sure you have <code>git</code> installed. Type the following command to
    clone the repository:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/lcompilers/lpython.git

    <span class="pl-c1">cd</span> lpython</pre></div>

    <p>You may also use GitHub Desktop to do the same.</p>

    </li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Building LPython</h2><a
    id="user-content-building-lpython" class="anchor" aria-label="Permalink: Building
    LPython" href="#building-lpython"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>

    <div class="markdown-heading"><h3 class="heading-element">Linux and macOS</h3><a
    id="user-content-linux-and-macos" class="anchor" aria-label="Permalink: Linux
    and macOS" href="#linux-and-macos"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>

    <p>Create a Conda environment:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_unix.yml

    conda activate lp</pre></div>

    </li>

    <li>

    <p>Generate the prerequisite files and build in Debug Mode:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    if you are developing on top of a forked repository; please run following command
    first</span>

    <span class="pl-c"><span class="pl-c">#</span> ./generate_default_tag.sh</span>



    ./build0.sh

    ./build1.sh</pre></div>

    </li>

    </ul>

    </li>

    <li>

    <div class="markdown-heading"><h3 class="heading-element">Windows</h3><a id="user-content-windows"
    class="anchor" aria-label="Permalink: Windows" href="#windows"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ul>

    <li>

    <p>Create a Conda environment using the pre-existing file:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_win.yml

    conda activate lp</pre></div>

    </li>

    <li>

    <p>Generate the prerequisite files and build in Release Mode:</p>

    <div class="highlight highlight-source-shell"><pre>call build0.bat

    call build1.bat</pre></div>

    </li>

    </ul>

    </li>

    <li>

    <div class="markdown-heading"><h3 class="heading-element">Windows with WSL</h3><a
    id="user-content-windows-with-wsl" class="anchor" aria-label="Permalink: Windows
    with WSL" href="#windows-with-wsl"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li>

    <p>Activate the Conda environment:</p>

    <div class="highlight highlight-source-shell"><pre>conda activate lp</pre></div>

    </li>

    <li>

    <p>Run the following commands to build the project:</p>

    <div class="highlight highlight-source-shell"><pre>./build0.sh

    cmake -DCMAKE_BUILD_TYPE=Debug -DWITH_LLVM=yes -DCMAKE_INSTALL_PREFIX=<span class="pl-s"><span
    class="pl-pds">`</span>pwd<span class="pl-pds">`</span></span>/inst .\

    make -j8</pre></div>

    </li>

    </ul>

    </li>

    </ul>

    <p>Check the <a href="./doc/src/installation.md">installation-docs</a> for more.</p>

    <div class="markdown-heading"><h2 class="heading-element">Contributing</h2><a
    id="user-content-contributing" class="anchor" aria-label="Permalink: Contributing"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>We welcome contributions from anyone, even if you are new to compilers or open
    source in general.

    It might sound daunting at first to contribute to a compiler, but do not worry,
    it is not that complicated.

    We will help you with any technical issues you face and provide support so your
    contribution gets merged.</p>

    <p>To contribute, submit a Pull Request (PR) against our repository at: <a href="https://github.com/lcompilers/lpython">https://github.com/lcompilers/lpython</a></p>

    <p>Do not forget to clean your history, see <a href="./doc/src/rebasing.md">example</a>.</p>

    <p>See the <a href="CONTRIBUTING.md">CONTRIBUTING</a> document for more information.</p>

    <div class="markdown-heading"><h2 class="heading-element">Found a bug?</h2><a
    id="user-content-found-a-bug" class="anchor" aria-label="Permalink: Found a bug?"
    href="#found-a-bug"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Please report any bugs you find at our issue tracker <a href="https://github.com/lcompilers/lpython/issues">here</a>.
    Or, even better, fork the repository on GitHub and create a Pull Request (PR).</p>

    <p>We welcome all changes, big or small. We will help you make a PR if you are
    new to git.</p>

    <p>If you have any questions or need help, please ask us at <a href="https://lfortran.zulipchat.com/"
    rel="nofollow">Zulip</a> or on our <a href="https://groups.io/g/lfortran" rel="nofollow">mailinglist</a>.</p>

    <div class="markdown-heading"><h1 class="heading-element">Star History</h1><a
    id="user-content-star-history" class="anchor" aria-label="Permalink: Star History"
    href="#star-history"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://star-history.com/#lcompilers/lpython&amp;Date" rel="nofollow"><img
    src="https://camo.githubusercontent.com/78c421eab5b4c6b49d5511402a66758420f313ca898a23fef0b6473f42f050d8/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c636f6d70696c6572732f6c707974686f6e26747970653d44617465"
    alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=lcompilers/lpython&amp;type=Date"
    style="max-width: 100%;"></a></p>

    '
  stargazers_count: 1358
  subscribers_count: 32
  topics:
  - compiler
  - high-performance
  - python
  updated_at: 1716912795.0
lezzidan/spack:
  data_format: 2
  description: Spack clone
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/aws-isc/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss-aws-aarch64/spack.yaml
  full_name: lezzidan/spack
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">\n<a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1><a id=\"user-content--spack\" class=\"\
    anchor\" aria-label=\"Permalink:  Spack\" href=\"#-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/70b0104a5a00f472f39f523bb50f576c7d5456c58b0068304f1ecd8e5054ae8c/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/build-containers.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/build-containers.yml/badge.svg\"\
    \ alt=\"Containers\" style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fca79013ca8059644742ad2936823670fa01342c0e60d57949ee69f693dccde3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/7d770c433d6198d89f8c1e2f187b904a9721d176259d0e97157337741cc8e837/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/code%20style-black-000000.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/e8580758c789c07a64e14287a71a75290dcddc6fee61b8a2e64f07bf7dca1ec9/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Documentation</h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Tutorial</h2><a\
    \ id=\"user-content-tutorial\" class=\"anchor\" aria-label=\"Permalink: Tutorial\"\
    \ href=\"#tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Community</h2><a\
    \ id=\"user-content-community\" class=\"anchor\" aria-label=\"Permalink: Community\"\
    \ href=\"#community\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Spack is an open source project.  Questions, discussion,\
    \ and\ncontributions are welcome. Contributions can be anything from new\npackages\
    \ to bugfixes, documentation, or even new core features.</p>\n<p>Resources:</p>\n\
    <ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<a href=\"\
    https://github.com/spack/spack/discussions\"><strong>Github Discussions</strong></a>:\
    \ not just for discussions, also Q&amp;A.</li>\n<li>\n<strong>Mailing list</strong>:\
    \ <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\">groups.google.com/d/forum/spack</a>\n\
    </li>\n<li>\n<strong>Twitter</strong>: <a href=\"https://twitter.com/spackpm\"\
    \ rel=\"nofollow\">@spackpm</a>. Be sure to\n<code>@mention</code> us!</li>\n\
    </ul>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Contributing</h2><a\
    \ id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\"\
    \ href=\"#contributing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Contributing to Spack is relatively easy.  Just send us\
    \ a\n<a href=\"https://help.github.com/articles/using-pull-requests/\">pull request</a>.\n\
    When you send your request, make <code>develop</code> the destination branch on\
    \ the\n<a href=\"https://github.com/spack/spack\">Spack repository</a>.</p>\n\
    <p>Your PR must pass Spack's unit tests and documentation tests, and must be\n\
    <a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"nofollow\">PEP 8</a>\
    \ compliant.  We enforce\nthese guidelines with our CI process. To run these tests\
    \ locally, and for\nhelpful tips on git, see our\n<a href=\"https://spack.readthedocs.io/en/latest/contribution_guide.html\"\
    \ rel=\"nofollow\">Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code>\
    \ branch has the latest contributions. Pull requests\nshould target <code>develop</code>,\
    \ and users who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Releases</h2><a\
    \ id=\"user-content-releases\" class=\"anchor\" aria-label=\"Permalink: Releases\"\
    \ href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>For multi-user site deployments or other use cases that\
    \ need very stable\nsoftware installations, we recommend using Spack's\n<a href=\"\
    https://github.com/spack/spack/releases\">stable releases</a>.</p>\n<p>Each Spack\
    \ release series also has a corresponding branch, e.g.\n<code>releases/v0.14</code>\
    \ has <code>0.14.x</code> versions of Spack, and <code>releases/v0.13</code> has\n\
    <code>0.13.x</code> versions. We backport important bug fixes to these branches\
    \ but\nwe do not advance the package versions or make other changes that would\n\
    change the way Spack concretizes dependencies within a release branch.\nSo, you\
    \ can base your Spack deployment on a release branch and <code>git pull</code>\n\
    to get fixes, without the package churn that comes with <code>develop</code>.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<p>See the <a href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\"\
    \ rel=\"nofollow\">docs on releases</a>\nfor more details.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Code of Conduct</h2><a id=\"\
    user-content-code-of-conduct\" class=\"anchor\" aria-label=\"Permalink: Code of\
    \ Conduct\" href=\"#code-of-conduct\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>Please note that Spack has a\n<a href=\"\
    .github/CODE_OF_CONDUCT.md\"><strong>Code of Conduct</strong></a>. By participating\
    \ in\nthe Spack community, you agree to abide by its rules.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Authors</h2><a id=\"user-content-authors\"\
    \ class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Many thanks go to\
    \ Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\">contributors</a>.</p>\n\
    <p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\">tgamblin@llnl.gov</a>.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Citing Spack</h3><a\
    \ id=\"user-content-citing-spack\" class=\"anchor\" aria-label=\"Permalink: Citing\
    \ Spack\" href=\"#citing-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>If you are referencing Spack in a publication, please cite\
    \ the following paper:</p>\n<ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael\
    \ R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de Supinski, and W. Scott\
    \ Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<p>On GitHub, you can copy\
    \ this citation in APA or BibTeX format via the \"Cite this repository\"\nbutton.\
    \ Or, see the comments in <code>CITATION.cff</code> for the raw BibTeX.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">License</h2><a id=\"\
    user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"\
    #license\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Spack is distributed under the terms of both the MIT license and the\nApache\
    \ License (Version 2.0). Users may choose either license, at their\noption.</p>\n\
    <p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n\
    <p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1684418839.0
lfortran/lfortran:
  data_format: 2
  description: Official main repository for LFortran
  filenames:
  - spack.yaml
  full_name: lfortran/lfortran
  latest_release: v0.36.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">LFortran</h1><a\
    \ id=\"user-content-lfortran\" class=\"anchor\" aria-label=\"Permalink: LFortran\"\
    \ href=\"#lfortran\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/f075ed3a1bcc7bc6d681d5b1b96c7235827bcfa73790e55a1c98bf969736b4e9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>LFortran is a modern open-source (BSD\
    \ licensed) interactive Fortran compiler\nbuilt on top of LLVM. It can execute\
    \ user's code interactively to allow\nexploratory work (much like Python, MATLAB\
    \ or Julia) as well as compile to\nbinaries with the goal to run user's code on\
    \ modern architectures such as\nmulti-core CPUs and GPUs.</p>\n<p>Website: <a\
    \ href=\"https://lfortran.org/\" rel=\"nofollow\">https://lfortran.org/</a></p>\n\
    <p>Try online: <a href=\"https://dev.lfortran.org/\" rel=\"nofollow\">https://dev.lfortran.org/</a></p>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Documentation</h1><a\
    \ id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\"\
    \ href=\"#documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>All documentation, installation instructions, motivation,\
    \ design, ... is\navailable at:</p>\n<p><a href=\"https://docs.lfortran.org/\"\
    \ rel=\"nofollow\">https://docs.lfortran.org/</a></p>\n<p>Which is generated using\
    \ the files in the <code>doc</code> directory.</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Development</h1><a id=\"user-content-development\"\
    \ class=\"anchor\" aria-label=\"Permalink: Development\" href=\"#development\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>We welcome all contributions.\nThe main development repository is at GitHub:</p>\n\
    <p><a href=\"https://github.com/lfortran/lfortran\">https://github.com/lfortran/lfortran</a></p>\n\
    <p>Please send Pull Requests (PRs) and open issues there.</p>\n<p>See the <a href=\"\
    CONTRIBUTING.md\">CONTRIBUTING</a> document for more information.</p>\n<p>Main\
    \ mailinglist:</p>\n<p><a href=\"https://groups.io/g/lfortran\" rel=\"nofollow\"\
    >https://groups.io/g/lfortran</a></p>\n<p>You can also chat with us on Zulip (<a\
    \ href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f075ed3a1bcc7bc6d681d5b1b96c7235827bcfa73790e55a1c98bf969736b4e9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a>).</p>\n<p>Note: We moved to the above GitHub\
    \ repository from GitLab on July 18, 2022.</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Donations</h1><a id=\"user-content-donations\"\
    \ class=\"anchor\" aria-label=\"Permalink: Donations\" href=\"#donations\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>You\
    \ can support LFortran's development by donating to NumFOCUS or Open\nCollective\
    \ as well as GitHub Sponsors:</p>\n<ul>\n<li><a href=\"https://numfocus.org/donate-to-lfortran\"\
    \ rel=\"nofollow\">https://numfocus.org/donate-to-lfortran</a></li>\n<li><a href=\"\
    https://opencollective.com/lfortran\" rel=\"nofollow\">https://opencollective.com/lfortran</a></li>\n\
    <li><a href=\"https://github.com/sponsors/lfortran\">https://github.com/sponsors/lfortran</a></li>\n\
    </ul>\n<p>All donations will be used strictly to fund LFortran development, by\
    \ supporting\ntasks such as paying developers to implement features, sprints,\
    \ improved\ndocumentation, fixing bugs, etc.</p>\n<p>The donations to LFortran\
    \ are managed by the NumFOCUS foundation. NumFOCUS is a\n501(c)3 non-profit foundation,\
    \ so if you are subject to US Tax law, your\ncontributions will be tax-deductible.</p>\n\
    <p>If you want to discuss another way to fund or help with the development, feel\n\
    free to contact Ond\u0159ej \u010Cert\xEDk (<a href=\"mailto:ondrej@certik.us\"\
    >ondrej@certik.us</a>).</p>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >Star History</h1><a id=\"user-content-star-history\" class=\"anchor\" aria-label=\"\
    Permalink: Star History\" href=\"#star-history\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p><a href=\"https://star-history.com/#lfortran/lfortran&amp;Date\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0d705c39c001391c1e1c00ee9eda910f1fcc337d43183467c2985974cbc2ad58/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c666f727472616e2f6c666f727472616e26747970653d44617465\"\
    \ alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=lfortran/lfortran&amp;type=Date\"\
    \ style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 883
  subscribers_count: 24
  topics:
  - fortran
  - interactive
  - compiler
  - library
  - repl
  - jupyter
  - jupyter-notebook
  - jupyter-kernels
  - fortran-compiler
  updated_at: 1717278419.0
mdorier/test-ssg-cori:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: mdorier/test-ssg-cori
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Building</h1><a
    id="user-content-building" class="anchor" aria-label="Permalink: Building" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Setup spack and sds-repo, clone this repository and <code>cd</code> in it,
    then:</p>

    <pre><code>spack env create ssg-test spack.yaml

    spack env activate ssg-test

    spack install

    spack env deactivate

    </code></pre>

    <p>Then to build the code:</p>

    <pre><code>export CRAYPE_LINK_TYPE=dynamic

    module swap PrgEnv-intel PrgEnv-gnu

    module swap gcc/8.3.0 gcc/9.3.0

    spack env activate ssg-test

    mkdir build

    cd build

    cmake ..

    make

    </code></pre>

    <div class="markdown-heading"><h1 class="heading-element">Running</h1><a id="user-content-running"
    class="anchor" aria-label="Permalink: Running" href="#running"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>From the <code>build</code> directory:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 128 ./test-server

    # one of the server will print "Credential: X", copy the X

    </code></pre>

    <p>In another terminal window, with current working directory set to <code>build</code>:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 1 ./test-client X # replace X with the copied value

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1614179535.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ORNL/Summit/spack.yaml
  - ANL/Aurora/spack.yaml
  - ANL/Sunspot/spack.yaml
  - ANL/Polaris/spack.yaml
  - ORNL/Crusher/spack.yaml
  - ORNL/Frontier/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Platform configurations
    for Mochi</h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-label="Permalink: Platform configurations for Mochi" href="#platform-configurations-for-mochi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <div class="markdown-heading"><h2 class="heading-element">Using spack.yaml files</h2><a
    id="user-content-using-spackyaml-files" class="anchor" aria-label="Permalink:
    Using spack.yaml files" href="#using-spackyaml-files"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Then, execute the following commands

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    $ spack env activate myenv

    $ spack repo add /where/you/cloned/mochi-spack-packages

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <div class="markdown-heading"><h2 class="heading-element">Contributing to this
    repository</h2><a id="user-content-contributing-to-this-repository" class="anchor"
    aria-label="Permalink: Contributing to this repository" href="#contributing-to-this-repository"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 4
  subscribers_count: 3
  topics: []
  updated_at: 1715795662.0
mochi-hpc/flamestore:
  data_format: 2
  description: Storage system for Deep Learning models designed using the Mochi components.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/flamestore
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">What is FlameStore?</h1><a
    id="user-content-what-is-flamestore" class="anchor" aria-label="Permalink: What
    is FlameStore?" href="#what-is-flamestore"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>FlameStore is a Mochi component to access Keras deep learning models

    and store them in various backends (right now: in memory, on a local

    file system, or on a composition of SDSKV and BAKE providers).</p>

    <p>FlameStore is developped by Matthieu Dorier (<a href="mailto:mdorier@anl.gov">mdorier@anl.gov</a>).

    More information on how to install and use is available

    <a href="https://xgitlab.cels.anl.gov/sds/flamestore/wikis/home" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1700115196.0
mochi-hpc/mochi-bake:
  data_format: 2
  description: A microservice (i.e., Mochi provider) for high performance bulk storage
    of raw data regions
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bake
  latest_release: v0.6.4
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Bake</h1><a\
    \ id=\"user-content-bake\" class=\"anchor\" aria-label=\"Permalink: Bake\" href=\"\
    #bake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Bake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage\
    \ of raw data regions.  Bake uses modular backends to store data\non persistent\
    \ memory, conventional file systems, or other storage media.</p>\n<p>See <a href=\"\
    https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a>\
    \ and\n<a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a>\
    \ for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively\
    \ to data storage.  Capabilities such as\nindexing, name spaces, and sharding\
    \ must be provided by other microservice\ncomponents.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Installation</h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The easiest way to install Bake is through spack:</p>\n<p><code>spack install\
    \ bake</code></p>\n<p>This will install BAKE and its dependencies.  Please refer\
    \ to the end of the\ndocument for manual compilation instructions.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Architecture</h2><a id=\"user-content-architecture\"\
    \ class=\"anchor\" aria-label=\"Permalink: Architecture\" href=\"#architecture\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Like most Mochi services, BAKE relies on a client/provider architecture.\n\
    A provider, identified by its <em>address</em> and <em>multiplex id</em>, manages\
    \ one or more\n<em>BAKE targets</em>, referenced externally by their <em>target\
    \ id</em>.</p>\n<p>A target can be thought of as a storage device.  This may be\
    \ (for example) a\nPMDK volume or a local file system.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Setting up a BAKE target</h2><a id=\"user-content-setting-up-a-bake-target\"\
    \ class=\"anchor\" aria-label=\"Permalink: Setting up a BAKE target\" href=\"\
    #setting-up-a-bake-target\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>BAKE requires the backend storage file to be created beforehand\
    \ using\n<code>bake-mkpool</code>. For instance:</p>\n<p><code>bake-mkpool -s\
    \ 500M /dev/shm/foo.dat</code></p>\n<p>creates a 500 MB file at <em>/dev/shm/foo.dat</em>\
    \ to be used by BAKE as a target.\nBake will use the <code>pmem</code> (persistent\
    \ memory) backend by default, which means\nthat the underlying file will memory\
    \ mapped for access usign the PMDK\nlibrary.  You can also providie an explicit\
    \ prefix (such as <code>file:</code> for the\nconventional file backend or <code>pmem:</code>\
    \ for the persistent memory backend) to\ndictate a specific target type.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Starting a daemon</h2><a\
    \ id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-label=\"Permalink:\
    \ Starting a daemon\" href=\"#starting-a-daemon\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>BAKE ships with a default daemon\
    \ program that can setup providers and attach\nto storage targets. This daemon\
    \ can be started as follows:</p>\n<p><code>bake-server-daemon [options] &lt;listen_address&gt;\
    \ &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n<p>The program takes\
    \ a set of options followed by an address at which to listen for\nincoming RPCs,\
    \ and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n\
    <p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234\
    \ /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n\
    <ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the\
    \ address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em>\
    \ or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates\
    \ that, if multiple BAKE targets are used (as above),\nthese targets should be\
    \ managed by multiple providers, accessible through\ndifferent multiplex ids 1,\
    \ 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage.\
    \ The <em>targets</em> mode indicates that a single provider should be used to\n\
    manage all the storage targets.</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Integrating Bake into a larger service</h2><a id=\"user-content-integrating-bake-into-a-larger-service\"\
    \ class=\"anchor\" aria-label=\"Permalink: Integrating Bake into a larger service\"\
    \ href=\"#integrating-bake-into-a-larger-service\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Bake is not intended to\
    \ be a standalone user-facing service.  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\"\
    \ rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for\
    \ guidance on how to\nintegrate it with other providers using Mochi's Bedrock\
    \ capability.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Client API example</h2><a id=\"user-content-client-api-example\" class=\"anchor\"\
    \ aria-label=\"Permalink: Client API example\" href=\"#client-api-example\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Data\
    \ is stored in <code>regions</code> within a <code>target</code> using explicit\
    \ create,\nwrite, and persist operations.  The caller cannot dictate the region\
    \ id\nthat will be used to reference a region; this identifier is generated\n\
    by Bake at creation time.  The region size must be specified at creation\ntime\
    \ as well; there is no mechanism for extending the size of an existing\nregion.</p>\n\
    <div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">#include</span>\
    \ <span class=\"pl-s\">&lt;bake-client.h&gt;</span>\n\n<span class=\"pl-smi\"\
    >int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">int</span>\
    \ <span class=\"pl-s1\">argc</span>, <span class=\"pl-smi\">char</span> <span\
    \ class=\"pl-c1\">*</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >argv</span>)\n{\n    <span class=\"pl-smi\">char</span> <span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">svr_addr_str</span>; <span class=\"pl-c\">// string\
    \ address of the BAKE server</span>\n    <span class=\"pl-smi\">hg_addr_t</span>\
    \ <span class=\"pl-s1\">svr_addr</span>; <span class=\"pl-c\">// Mercury address\
    \ of the BAKE server</span>\n    <span class=\"pl-smi\">margo_instance_id</span>\
    \ <span class=\"pl-s1\">mid</span>; <span class=\"pl-c\">// Margo instance id</span>\n\
    \    <span class=\"pl-smi\">bake_client_t</span> <span class=\"pl-s1\">bcl</span>;\
    \ <span class=\"pl-c\">// BAKE client</span>\n    <span class=\"pl-smi\">bake_provider_handle_t</span>\
    \ <span class=\"pl-s1\">bph</span>; <span class=\"pl-c\">// BAKE handle to provider</span>\n\
    \    <span class=\"pl-smi\">uint8_t</span> <span class=\"pl-s1\">mplex_id</span>;\
    \ <span class=\"pl-c\">// multiplex id of the provider</span>\n    <span class=\"\
    pl-smi\">uint32_t</span> <span class=\"pl-s1\">target_number</span>; <span class=\"\
    pl-c\">// target to use</span>\n    <span class=\"pl-smi\">bake_region_id_t</span>\
    \ <span class=\"pl-s1\">rid</span>; <span class=\"pl-c\">// BAKE region id handle</span>\n\
    \t<span class=\"pl-smi\">bake_target_id_t</span><span class=\"pl-c1\">*</span>\
    \ <span class=\"pl-s1\">bti</span>; <span class=\"pl-c\">// array of target ids</span>\n\
    \n\t<span class=\"pl-c\">/* ... setup variables ... */</span>\n\n\t<span class=\"\
    pl-c\">/* Initialize Margo */</span>\n\t<span class=\"pl-s1\">mid</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">margo_init</span>(..., <span\
    \ class=\"pl-c1\">MARGO_CLIENT_MODE</span>, <span class=\"pl-c1\">0</span>, <span\
    \ class=\"pl-c1\">-1</span>);\n\t<span class=\"pl-c\">/* Lookup the server */</span>\n\
    \t<span class=\"pl-en\">margo_addr_lookup</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr_str</span>, <span class=\"pl-c1\">&amp;</span><span\
    \ class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-c\">/* Creates the BAKE\
    \ client */</span>\n\t<span class=\"pl-en\">bake_client_init</span>(<span class=\"\
    pl-s1\">mid</span>, <span class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bcl</span>);\n\
    \t<span class=\"pl-c\">/* Creates the provider handle */</span>\n\t<span class=\"\
    pl-en\">bake_provider_handle_create</span>(<span class=\"pl-s1\">bcl</span>, <span\
    \ class=\"pl-s1\">svr_addr</span>, <span class=\"pl-s1\">mplex_id</span>, <span\
    \ class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bph</span>);\n\t<span class=\"\
    pl-c\">/* Asks the provider for up to target_number target ids */</span>\n\t<span\
    \ class=\"pl-smi\">uint32_t</span> <span class=\"pl-s1\">num_targets</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-c1\">0</span>;\n\t<span class=\"pl-s1\"\
    >bti</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">calloc</span>(<span\
    \ class=\"pl-s1\">num_targets</span>, <span class=\"pl-k\">sizeof</span>(<span\
    \ class=\"pl-c1\">*</span><span class=\"pl-s1\">bti</span>));\n\t<span class=\"\
    pl-en\">bake_probe</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >target_number</span>, <span class=\"pl-s1\">bti</span>, <span class=\"pl-c1\"\
    >&amp;</span><span class=\"pl-s1\">num_targets</span>);\n\t<span class=\"pl-k\"\
    >if</span>(<span class=\"pl-s1\">num_targets</span> <span class=\"pl-c1\">&lt;</span>\
    \ <span class=\"pl-s1\">target_number</span>) {\n\t\t<span class=\"pl-en\">fprintf</span>(<span\
    \ class=\"pl-s1\">stderr</span>, <span class=\"pl-s\">\"Error: provider has only\
    \ %d storage targets\\n\"</span>, <span class=\"pl-s1\">num_targets</span>);\n\
    \t}\n\t<span class=\"pl-c\">/* Create a region */</span>\n\t<span class=\"pl-smi\"\
    >size_t</span> <span class=\"pl-s1\">size</span> <span class=\"pl-c1\">=</span>\
    \ ...; <span class=\"pl-c\">// size of the region to create</span>\n\t<span class=\"\
    pl-en\">bake_create</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >bti</span>[<span class=\"pl-s1\">target_number</span><span class=\"pl-c1\">-</span><span\
    \ class=\"pl-c1\">1</span>], <span class=\"pl-s1\">size</span>, <span class=\"\
    pl-c1\">&amp;</span><span class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\"\
    >/* Write data into the region at offset 0 */</span>\n\t<span class=\"pl-smi\"\
    >char</span><span class=\"pl-c1\">*</span> <span class=\"pl-s1\">buf</span> <span\
    \ class=\"pl-c1\">=</span> ...;\n\t<span class=\"pl-en\">bake_write</span>(<span\
    \ class=\"pl-s1\">bph</span>, <span class=\"pl-s1\">rid</span>, <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-s1\">buf</span>, <span class=\"pl-s1\">size</span>);\n\
    \t<span class=\"pl-c\">/* Make all modifications persistent */</span>\n\t<span\
    \ class=\"pl-en\">bake_persist</span>(<span class=\"pl-s1\">bph</span>, <span\
    \ class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\">/* Release provider handle\
    \ */</span>\n\t<span class=\"pl-en\">bake_provider_handle_release</span>(<span\
    \ class=\"pl-s1\">bph</span>);\n\t<span class=\"pl-c\">/* Release BAKE client\
    \ */</span>\n\t<span class=\"pl-en\">bake_client_finalize</span>(<span class=\"\
    pl-s1\">bcl</span>);\n\t<span class=\"pl-c\">/* Cleanup Margo resources */</span>\n\
    \t<span class=\"pl-en\">margo_addr_free</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-en\">margo_finalize</span>(<span\
    \ class=\"pl-s1\">mid</span>);\n\t<span class=\"pl-k\">return</span> <span class=\"\
    pl-c1\">0</span>;\n}</pre></div>\n<p>Note that a <code>bake_region_id_t</code>\
    \ object is persistent.  It can be written\n(into a file or a socket) and stored\
    \ or sent to another program. These\nregion ids are what uniquely reference a\
    \ region within a given target.</p>\n<p>The rest of the client-side API can be\
    \ found in <code>bake-client.h</code>.</p>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Provider API</h2><a id=\"user-content-provider-api\"\
    \ class=\"anchor\" aria-label=\"Permalink: Provider API\" href=\"#provider-api\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The bake-server-daemon source is a good example of how to create providers\
    \ and\nattach storage targets to them. The provider-side API is located in\n<em>bake-server.h</em>,\
    \ and consists of mainly two functions:</p>\n<div class=\"highlight highlight-source-c\"\
    ><pre><span class=\"pl-smi\">int</span> <span class=\"pl-en\">bake_provider_register</span>(<span\
    \ class=\"pl-smi\">margo_instance_id</span>                     <span class=\"\
    pl-s1\">mid</span>,\n                           <span class=\"pl-smi\">uint16_t</span>\
    \                              <span class=\"pl-s1\">provider_id</span>,\n   \
    \                        <span class=\"pl-k\">const</span> <span class=\"pl-k\"\
    >struct</span> <span class=\"pl-smi\">bake_provider_init_info</span><span class=\"\
    pl-c1\">*</span> <span class=\"pl-s1\">args</span>,\n                        \
    \   <span class=\"pl-smi\">bake_provider_t</span><span class=\"pl-c1\">*</span>\
    \                      <span class=\"pl-s1\">provider</span>);</pre></div>\n<p>This\
    \ creates a provider at the given provider id using the specified margo\ninstance.\
    \  The <code>args</code> parameter can be used to modify default settings,\nincluding\
    \ passing in a fully specified json configuration block.  See\n<code>bake-server.h</code>\
    \ for details.</p>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"\
    pl-smi\">int</span> <span class=\"pl-en\">bake_provider_attach_target</span>(<span\
    \ class=\"pl-smi\">bake_provider_t</span>   <span class=\"pl-s1\">provider</span>,\n\
    \                                <span class=\"pl-k\">const</span> <span class=\"\
    pl-smi\">char</span><span class=\"pl-c1\">*</span>       <span class=\"pl-s1\"\
    >target_name</span>,\n                                <span class=\"pl-smi\">bake_target_id_t</span><span\
    \ class=\"pl-c1\">*</span> <span class=\"pl-s1\">target_id</span>);</pre></div>\n\
    <p>This makes the provider manage the given storage target.</p>\n<p>Other functions\
    \ are available to create and detach targets from a provider.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Generic Bake benchmark</h2><a\
    \ id=\"user-content-generic-bake-benchmark\" class=\"anchor\" aria-label=\"Permalink:\
    \ Generic Bake benchmark\" href=\"#generic-bake-benchmark\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>By using <code>--enable-benchmark</code>\
    \ when compiling Bake (or <code>+benchmark</code> when using Spack),\nyou will\
    \ build a <code>bake-benchmark</code> program that can be used as a configurable\
    \ benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure\
    \ Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n<p>The benchmark\
    \ is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a\
    \ server, while non-zero ranks act as clients. The server will not create\na Bake\
    \ target. The Bake target needs to be created (with <code>bake-makepool</code>)\
    \ beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing\
    \ the sequence\nof benchmarks to execute. An example of such a file is located\
    \ in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code>\
    \ array corresponds to a benchmark. The <code>type</code> field indicates\nthe\
    \ type of benchmark to execute. The <code>repetitions</code> field indicates how\
    \ many times the\nbenchmark should be repeated.</p>\n<p>The following table describes\
    \ each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n\
    <th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n\
    </tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to\
    \ the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n\
    <td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for\
    \ each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n\
    <td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's\
    \ buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n\
    <td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n\
    <td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions,\
    \ or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether\
    \ to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n\
    </tbody>\n</table>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Manual installation</h2><a id=\"user-content-manual-installation\" class=\"anchor\"\
    \ aria-label=\"Permalink: Manual installation\" href=\"#manual-installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>BAKE depends on the following libraries:</p>\n<ul>\n<li>uuid (install uuid-dev\
    \ package on ubuntu)</li>\n<li>PMDK (see instructions below)</li>\n<li>json-c</li>\n\
    <li>mochi-abt-io</li>\n<li>mochi-margo</li>\n</ul>\n<p>Bake will automatically\
    \ identify these dependencies at configure time using\npkg-config. To compile\
    \ BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n<li><code>mkdir build</code></li>\n\
    <li><code>cd build</code></li>\n<li><code>../configure --prefix=/home/carns/working/install</code></li>\n\
    <li><code>make</code></li>\n</ul>\n<p>If any dependencies are installed in a nonstandard\
    \ location, then\nmodify the configure step listed above to include the following\
    \ argument:</p>\n<ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1633975151.0
mochi-hpc/mochi-doc:
  data_format: 2
  description: Documentations and tutorials for Margo, Thallium, Argobots, Mercury,
    and other Mochi libraries.
  filenames:
  - code/spack.yaml
  full_name: mochi-hpc/mochi-doc
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"><img
    src="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"
    alt="build" style="max-width: 100%;"></a></p>

    <div class="markdown-heading"><h1 class="heading-element">Mochi documentation</h1><a
    id="user-content-mochi-documentation" class="anchor" aria-label="Permalink: Mochi
    documentation" href="#mochi-documentation"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>This repository contains a Sphinx-based documentation

    for the Mochi libraries: Margo, Thallium, Argobots, Mercury,

    ABT-IO, and SSG, as well as corresponding code examples.</p>

    <div class="markdown-heading"><h2 class="heading-element">Building the documentation</h2><a
    id="user-content-building-the-documentation" class="anchor" aria-label="Permalink:
    Building the documentation" href="#building-the-documentation"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>To build and/or contribute to this documentation, you must have a Sphinx and

    a few related extensions installed.  These can be installed as follows using

    Python''s <code>pip</code>.</p>

    <pre><code>pip install sphinx

    pip install sphinx_rtd_theme

    pip install sphinx_copybutton

    pip install recommonmark

    pip install breathe

    </code></pre>

    <p>Alternatively, those required packages may also be available in your

    platform''s primary package manager.  For example, in Ubuntu 23.04 you could

    do the following instead of using pip:</p>

    <pre><code>sudo apt install python3-breathe python3-recommonmark python3-sphinx-copybutton
    python3-sphinx-rtd-theme

    </code></pre>

    <p>You must also install the <code>doxygen</code> documentation system.  This
    is likely

    available in your platform''s primary package manager.  For example on Ubuntu:</p>

    <pre><code>sudo apt install doxygen

    </code></pre>

    <p>Once you have these dependencies installed, clone this

    repository and cd into it. You can change the documentation

    by editing the files in the source subdirectory (these files

    use the .rst format). You can build the documentation

    using the following command.</p>

    <pre><code>cd docs

    make html

    </code></pre>

    <p>And check the result by opening the <code>build/html/index.html</code> page

    that has been created in the docs directory.</p>

    <div class="markdown-heading"><h2 class="heading-element">Building the code examples</h2><a
    id="user-content-building-the-code-examples" class="anchor" aria-label="Permalink:
    Building the code examples" href="#building-the-code-examples"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>To build the code, you will need spack and the

    <a href="https://github.com/mochi-hpc/mochi-spack-packages">mochi repo</a> setup.</p>

    <pre><code>cd code

    spack env create mochi-doc-env spack.yaml

    spack env activate mochi-doc-env

    spack install

    mkdir build

    cd build

    cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc

    make

    </code></pre>

    '
  stargazers_count: 5
  subscribers_count: 4
  topics: []
  updated_at: 1702435305.0
mochi-hpc/mochi-margo:
  data_format: 2
  description: Argobots bindings for the Mercury RPC library
  filenames:
  - spack.yaml
  - tests/spack.yaml
  full_name: mochi-hpc/mochi-margo
  latest_release: v0.17.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Margo</h1><a\
    \ id=\"user-content-margo\" class=\"anchor\" aria-label=\"Permalink: Margo\" href=\"\
    #margo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    ><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/63edbba9af5581b48cff6c71aef12cfc175c44871f655aa8a767cc22df9b35f9/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings\
    \ to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\"\
    \ rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\n\
    library optimized for use in HPC environments.  Its native API presents a\ncallback-oriented\
    \ interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\"\
    \ rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n\
    <p>Margo combines Mercury and Argobots to simplify development of distributed\n\
    services.  Mercury operations are presented as conventional blocking\noperations,\
    \ and RPC handlers are presented as sequential threads.  This\nconfiguration enables\
    \ high degree of concurrency while hiding the\ncomplexity associated with asynchronous\
    \ communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends\
    \ callers after issuing a Mercury operation, and\nautomatically resumes them when\
    \ the operation completes.  This allows\nother concurrent user-level threads to\
    \ make progress while Mercury\noperations are in flight without consuming operating\
    \ system threads.\nThe goal of this design is to combine the performance advantages\
    \ of\nMercury's native event-driven execution model with the progamming\nsimplicity\
    \ of a multi-threaded execution model.</p>\n<p>A companion library called abt-io\
    \ provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\"\
    >https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should\
    \ be compatible with any Mercury network\ntransport (NA plugin).  The documentation\
    \ assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury\
    \ for\nsimplicity.  This plugin is only valid for communication between\nprocesses\
    \ on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\"\
    >Using Margo with other Mercury NA\nplugins</a> for information\non other configuration\
    \ options.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Spack</h2><a id=\"user-content-spack\" class=\"anchor\" aria-label=\"Permalink:\
    \ Spack\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The simplest way to install Margo is by installing the\
    \ \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"nofollow\"\
    >https://spack.io/</a>).</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Dependencies</h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"\
    Permalink: Dependencies\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<ul>\n<li>mercury  (git clone --recurse-submodules\
    \ <a href=\"https://github.com/mercury-hpc/mercury.git\">https://github.com/mercury-hpc/mercury.git</a>)</li>\n\
    <li>argobots (git clone <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n\
    </ul>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\">Recommended\
    \ Mercury build options</h3><a id=\"user-content-recommended-mercury-build-options\"\
    \ class=\"anchor\" aria-label=\"Permalink: Recommended Mercury build options\"\
    \ href=\"#recommended-mercury-build-options\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<ul>\n<li>Mercury must be compiled with\
    \ -DMERCURY_USE_BOOST_PP:BOOL=ON to enable the\nBoost preprocessor macros for\
    \ encoding.</li>\n<li>Mercury should be compiled with -DMERCURY_USE_SELF_FORWARD:BOOL=ON\
    \ in order to enable\nfast execution path for cases in which a Mercury service\
    \ is linked into the same\nexecutable as the client</li>\n</ul>\n<p>Example Mercury\
    \ compilation:</p>\n<pre><code>mkdir build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON\
    \ \\\n -DBUILD_TESTING:BOOL=ON -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install\
    \ \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Building</h2><a\
    \ id=\"user-content-building\" class=\"anchor\" aria-label=\"Permalink: Building\"\
    \ href=\"#building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install\
    \ \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"\
    -g -Wall\"\n</code></pre>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Running examples</h2><a id=\"user-content-running-examples\" class=\"anchor\"\
    \ aria-label=\"Permalink: Running examples\" href=\"#running-examples\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>The\
    \ examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example\
    \ client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]:\
    \ an example RPC definition</li>\n</ul>\n<p>The following example shows how to\
    \ execute them.  Note that when the server starts it will display the address\
    \ that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server\
    \ na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with\
    \ input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val:\
    \ 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client\
    \ na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3]\
    \ running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\n\
    Got response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n\
    <p>The client will issue 4 concurrent RPCs to the server and wait for them to\n\
    complete.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Running\
    \ tests</h2><a id=\"user-content-running-tests\" class=\"anchor\" aria-label=\"\
    Permalink: Running tests\" href=\"#running-tests\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p><code>make check</code></p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Using Margo with\
    \ the other NA plugins</h2><a id=\"user-content-using-margo-with-the-other-na-plugins\"\
    \ class=\"anchor\" aria-label=\"Permalink: Using Margo with the other NA plugins\"\
    \ href=\"#using-margo-with-the-other-na-plugins\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\"\
    \ rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible\
    \ with any Mercury transport and uses the same address\nformat.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Debugging</h2><a id=\"user-content-debugging\"\
    \ class=\"anchor\" aria-label=\"Permalink: Debugging\" href=\"#debugging\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>See\
    \ the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo debugging\n\
    features and strategies.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Design details</h2><a id=\"user-content-design-details\" class=\"anchor\" aria-label=\"\
    Permalink: Design details\" href=\"#design-details\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"doc/fig/margo-diagram.png\"><img src=\"doc/fig/margo-diagram.png\"\
    \ alt=\"Margo architecture\" style=\"max-width: 100%;\"></a></p>\n<p>Margo provides\
    \ Argobots-aware wrappers to common Mercury library functions\nlike HG_Forward(),\
    \ HG_Addr_lookup(), and HG_Bulk_transfer().  The wrappers\nhave the same arguments\
    \ as their native Mercury counterparts except that no\ncallback function is specified.\
    \  Each function blocks until the operation\nis complete.  The above diagram illustrates\
    \ a typical control flow.</p>\n<p>Margo launches a long-running user-level thread\
    \ internally to drive\nprogress on Mercury and execute Mercury callback functions\
    \ (labeled\n<code>__margo_progress()</code> above).  This thread can be assigned\
    \ to a\ndedicated Argobots execution stream (i.e., an operating system thread)\n\
    to drive network progress with a dedicated core.  Otherwise it will be\nautomatically\
    \ scheduled when the caller's execution stream is blocked\nwaiting for network\
    \ events as shown in the above diagram.</p>\n<p>Argobots eventual constructs are\
    \ used to suspend and resume user-level\nthreads while Mercury operations are\
    \ in flight.</p>\n<p>Margo allows several different threading/multicore configurations:</p>\n\
    <ul>\n<li>The progress loop can run on a dedicated operating system thread or\
    \ not</li>\n<li>Multiple Margo instances (and thus progress loops) can be\nexecuted\
    \ on different operating system threads</li>\n<li>(for servers) a single Margo\
    \ instance can launch RPC handlers\non different operating system threads</li>\n\
    </ul>\n"
  stargazers_count: 21
  subscribers_count: 10
  topics: []
  updated_at: 1716846293.0
mochi-hpc/mofka:
  data_format: 2
  description: Mochi-based distributed event-streaming service for HPC
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mofka
  latest_release: v0.0.5
  readme: '<p align="center">

    <a target="_blank" rel="noopener noreferrer" href="docs/_static/MofkaLogo-light.svg#gh-light-mode-only"><img
    src="docs/_static/MofkaLogo-light.svg#gh-light-mode-only" height="220" width="210"
    style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="docs/_static/MofkaLogo-dark.svg#gh-dark-mode-only"><img
    src="docs/_static/MofkaLogo-dark.svg#gh-dark-mode-only" height="220" width="210"
    style="max-width: 100%;"></a>

    </p>

    <p>Mofka is a streaming service for high-performance computing application.

    It relies on the <a href="https://wordpress.cels.anl.gov/mochi/" rel="nofollow">Mochi</a>
    toolbox of

    HPC software service components. Please refer to the <a href="https://mofka.readthedocs.io/"
    rel="nofollow">ReadTheDocs</a>

    for more information.</p>

    '
  stargazers_count: 3
  subscribers_count: 7
  topics: []
  updated_at: 1715797279.0
mochi-hpc/py-mochi-bake:
  data_format: 2
  description: Python wrapper for BAKE
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-bake
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633975348.0
mochi-hpc/py-mochi-s4m:
  data_format: 2
  description: Python library using Mochi to broadcast data
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-s4m
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Mochi S4M (Share
    for Me)</h1><a id="user-content-mochi-s4m-share-for-me" class="anchor" aria-label="Permalink:
    Mochi S4M (Share for Me)" href="#mochi-s4m-share-for-me"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This service provides a simple non-blocking broadcast/receive

    mechanism based on Mochi.</p>

    <div class="markdown-heading"><h2 class="heading-element">Installing</h2><a id="user-content-installing"
    class="anchor" aria-label="Permalink: Installing" href="#installing"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Make sure you have <a href="https://spack.io/" rel="nofollow">spack</a> installed
    and setup.

    If needed, install it and set it up as follows:</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>You then need to clone the <code>mochi-spack-packages</code> repository

    and make it available to spack:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Finally, you can install S4M as follows:</p>

    <pre><code>$ spack install py-mochi-s4m

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Using</h2><a id="user-content-using"
    class="anchor" aria-label="Permalink: Using" href="#using"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>S4M has a very simple API consisting of an <code>S4MService</code> class with

    two functions: <code>broadcast</code>, and <code>receive</code>. It requires mpi4py
    to

    bootstrap the set of processes. The <a href="test/test.py">test.py</a> file

    provides a comprehensive use case.</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1663070268.0
mochi-hpc/py-mochi-sonata:
  data_format: 2
  description: Python binding to the Mochi Sonata microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-sonata
  latest_release: null
  readme: '<p>Py-Sonata is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-sonata">Sonata
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975502.0
mochi-hpc/ycsb-cpp-interface:
  data_format: 2
  description: Mochi-based DB backends for the YCSB benchmark
  filenames:
  - spack.yaml
  full_name: mochi-hpc/ycsb-cpp-interface
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">YCSB C++\
    \ Interface</h1><a id=\"user-content-ycsb-c-interface\" class=\"anchor\" aria-label=\"\
    Permalink: YCSB C++ Interface\" href=\"#ycsb-c-interface\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p><a href=\"https://github.com/brianfrankcooper/YCSB\"\
    >YCSB</a> is one of the most popular Cloud\nstorage benchmark. However it is written\
    \ in Java, forcing databases implemented\nin other languages to provide a Java\
    \ wrapper. While <a href=\"https://github.com/ls4154/YCSB-cpp\">YCSC-cpp</a>\n\
    provides a reimplementation of YCSB in C++, to date it only supports three backends,\
    \ as\nopposed to 45 for the original YCSB.</p>\n<p><a href=\"https://github.com/mochi-hpc/ycsb-cpp-interface\"\
    >ycsb-cpp-interface</a>\ntakes a different approach from YCSB-cpp, providing a\
    \ Java/C++ library\nthat enables the use of C++ to write DB backends for YCSB.</p>\n\
    <p>ycsb-cpp-inteface works in a modular way, dynamically loading your C++ database\n\
    implementation from a library using a factory pattern.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Installing</h2><a id=\"user-content-installing\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installing\" href=\"#installing\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Building manually</h3><a\
    \ id=\"user-content-building-manually\" class=\"anchor\" aria-label=\"Permalink:\
    \ Building manually\" href=\"#building-manually\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>To build this repository from source,\
    \ you will first need to have\nits dependencies installed and findable by CMake.\
    \ These dependencies\ninclude:</p>\n<ul>\n<li>Java Development Kit (e.g., OpenJDK)</li>\n\
    <li>YCSB</li>\n<li>cmake</li>\n</ul>\n<p>Make sure to set the <code>JAVA_HOME</code>\
    \ environment variable\nto point to where your JDK is installed so that CMake\
    \ can find it.\nIt is recommended to install a distribution of YCSB, rather than\n\
    the source.</p>\n<p>You can then build the source contained in this repository\
    \ as follows.</p>\n<pre><code>$ mkdir build\n$ cd build\n$ cmake .. -DYCSB_ROOT=&lt;path/to/where/ycsb/is/installed&gt;\
    \ \\\n           -DCMAKE_INSTALL_PREFIX=&lt;install/prefix&gt;\n$ make\n</code></pre>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Installing using\
    \ Spack</h3><a id=\"user-content-installing-using-spack\" class=\"anchor\" aria-label=\"\
    Permalink: Installing using Spack\" href=\"#installing-using-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>You can install this\
    \ library using <a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a>.\nThe\
    \ <code>ycsb-cpp-interface</code> Spack package is available via the\n<a href=\"\
    https://github.com/mochi-hpc/mochi-spack-packages\">Mochi repository</a>,\nwhich\
    \ can be added to Spack as follows.</p>\n<pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git\n\
    $ spack repo add mochi-spack-packages\n</code></pre>\n<p>Once the <code>mochi-spack-packages</code>\
    \ repository has been made available to Spack,\nyou can install <code>ycsb-cpp-interface</code>\
    \ as follows.</p>\n<pre><code>$ spack install ycsb-cpp-interface\n</code></pre>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Testing</h2><a id=\"\
    user-content-testing\" class=\"anchor\" aria-label=\"Permalink: Testing\" href=\"\
    #testing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>If you have installed ycsb-cpp-interface with Spack, make sure that\nthe package\
    \ is loaded (<code>spack load ycsb-cpp-interface</code>), then you\ncan start\
    \ the CLI for testing, as follows.</p>\n<pre><code>ycsb-cpp-cli\n</code></pre>\n\
    <p>When building from source, the CLI is located in the <code>bin</code> subdirectory\n\
    of your build folder.</p>\n<p>You will end up in YCBS's CLI, with the YcsbDBClient\
    \ loaded as the\nDB backend, itself using a test implementation of an in-memory\
    \ database\nwith which you can interact (type <code>help</code> to see a list\
    \ of available commands).</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Writing your own C++ DB backend</h2><a id=\"user-content-writing-your-own-c-db-backend\"\
    \ class=\"anchor\" aria-label=\"Permalink: Writing your own C++ DB backend\" href=\"\
    #writing-your-own-c-db-backend\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>ycsb-cpp-interface provides a header file, <code>YCSBCppInterface.hpp</code>,\
    \ with\na <code>ycsb::DB</code> abstract class. To implement your own C++ backend\
    \ database,\nyou simply need to implement a child class of the <code>ycsb::DB</code>\
    \ class that\nimplements the required virtual functions. You may look at <a href=\"\
    src/TestDB.cpp\"></a>\nas an example of such an implementation. Note the use of\
    \ the\n<code>YCSB_CPP_REGISTER_DB_TYPE</code> macro after the class definition.\
    \ This macro\nmust be called in a .cpp file to associate the name of your backend\n\
    (e.g. <code>myawesomedb</code>) with the class name to use (e.g., <code>MyAwesomeDB</code>).</p>\n\
    <p>Once your database class is ready, compile it into a shared library\n(e.g.,\
    \ <code>libmyawesomedb.so</code>). Make sure the <code>LD_LIBRARY_PATH</code>\
    \ environment\nvariable contains the path to your dynamic library. You may then\
    \ test\nyour backend with the CLI as follows.</p>\n<pre><code>$ ycsb-cpp-cli -p\
    \ ycsb.cpp.library=libmyawesomedb.so -p ycsb.cpp.backend=myawesomedb\n</code></pre>\n\
    <p>The <code>ycsb.cpp.library</code> and <code>ycsb.cpp.backend</code> properties\
    \ are the only properties\nneeded by ycsb-cpp-interface. Any other properties\
    \ provided will be propagated\nto your database implementation in the form of\
    \ an <code>std::unordered_map&lt;std::string, std::string&gt;</code>.\nNote that\
    \ <code>ycsb.cpp.library</code> may accept a full path to your dynamic library,\n\
    if you don't want to change the <code>LD_LIBRARY_PATH</code> environment variable.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Running YCSB with\
    \ your C++ DB backend</h2><a id=\"user-content-running-ycsb-with-your-c-db-backend\"\
    \ class=\"anchor\" aria-label=\"Permalink: Running YCSB with your C++ DB backend\"\
    \ href=\"#running-ycsb-with-your-c-db-backend\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>ycsb-cpp-interface provides a convenience\
    \ script, <code>ycsb-cpp</code>, to run YCSB\nwith your own backend. It can be\
    \ used in a way similar to the original ycsb script,\nas follows.</p>\n<pre><code>$\
    \ ycsb-cpp load -p ycsb.cpp.library=libmyawesomedb.so -p ycsb.cpp.backend=myawesomedb\
    \ -P workloadfile\n$ ycsb-cpp run -p ycsb.cpp.library=libmyawesomedb.so -p ycsb.cpp.backend=myawesomedb\
    \ -P workloadfile\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1661162651.0
mpbelhorn/olcf-spack:
  data_format: 2
  description: Spack fork used on OLCF resources
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  full_name: mpbelhorn/olcf-spack
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">\n<a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1><a id=\"user-content--spack\" class=\"\
    anchor\" aria-label=\"Permalink:  Spack\" href=\"#-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions?query=workflow%3A%22macOS+builds+nightly%22\"\
    ><img src=\"https://github.com/spack/spack/workflows/macOS%20builds%20nightly/badge.svg?branch=develop\"\
    \ alt=\"macOS Builds (nightly)\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/70b0104a5a00f472f39f523bb50f576c7d5456c58b0068304f1ecd8e5054ae8c/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/fca79013ca8059644742ad2936823670fa01342c0e60d57949ee69f693dccde3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/e8580758c789c07a64e14287a71a75290dcddc6fee61b8a2e64f07bf7dca1ec9/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Documentation</h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Tutorial</h2><a\
    \ id=\"user-content-tutorial\" class=\"anchor\" aria-label=\"Permalink: Tutorial\"\
    \ href=\"#tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Community</h2><a\
    \ id=\"user-content-community\" class=\"anchor\" aria-label=\"Permalink: Community\"\
    \ href=\"#community\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Spack is an open source project.  Questions, discussion,\
    \ and\ncontributions are welcome. Contributions can be anything from new\npackages\
    \ to bugfixes, documentation, or even new core features.</p>\n<p>Resources:</p>\n\
    <ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<strong>Mailing\
    \ list</strong>: <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\"\
    >groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>: <a\
    \ href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Contributing</h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Contributing to Spack is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Releases</h2><a\
    \ id=\"user-content-releases\" class=\"anchor\" aria-label=\"Permalink: Releases\"\
    \ href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>For multi-user site deployments or other use cases that\
    \ need very stable\nsoftware installations, we recommend using Spack's\n<a href=\"\
    https://github.com/spack/spack/releases\">stable releases</a>.</p>\n<p>Each Spack\
    \ release series also has a corresponding branch, e.g.\n<code>releases/v0.14</code>\
    \ has <code>0.14.x</code> versions of Spack, and <code>releases/v0.13</code> has\n\
    <code>0.13.x</code> versions. We backport important bug fixes to these branches\
    \ but\nwe do not advance the package versions or make other changes that would\n\
    change the way Spack concretizes dependencies within a release branch.\nSo, you\
    \ can base your Spack deployment on a release branch and <code>git pull</code>\n\
    to get fixes, without the package churn that comes with <code>develop</code>.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<p>See the <a href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\"\
    \ rel=\"nofollow\">docs on releases</a>\nfor more details.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Code of Conduct</h2><a id=\"\
    user-content-code-of-conduct\" class=\"anchor\" aria-label=\"Permalink: Code of\
    \ Conduct\" href=\"#code-of-conduct\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>Please note that Spack has a\n<a href=\"\
    .github/CODE_OF_CONDUCT.md\"><strong>Code of Conduct</strong></a>. By participating\
    \ in\nthe Spack community, you agree to abide by its rules.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Authors</h2><a id=\"user-content-authors\"\
    \ class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Many thanks go to\
    \ Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\">contributors</a>.</p>\n\
    <p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\">tgamblin@llnl.gov</a>.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Citing Spack</h3><a\
    \ id=\"user-content-citing-spack\" class=\"anchor\" aria-label=\"Permalink: Citing\
    \ Spack\" href=\"#citing-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>If you are referencing Spack in a publication, please cite\
    \ the following paper:</p>\n<ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael\
    \ R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de Supinski, and W. Scott\
    \ Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">License</h2><a id=\"user-content-license\" class=\"\
    anchor\" aria-label=\"Permalink: License\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Spack is distributed\
    \ under the terms of both the MIT license and the\nApache License (Version 2.0).\
    \ Users may choose either license, at their\noption.</p>\n<p>All new contributions\
    \ must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"\
    https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n<a\
    \ href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1580743748.0
mpbelhorn/olcf-spack-environments:
  data_format: 2
  description: Spack environments for OLCF resources.
  filenames:
  - hosts/borg/envs/base/spack.yaml
  - hosts/ascent/envs/base-rh7/spack.yaml
  - hosts/summit/envs/base/spack.yaml
  - hosts/frontier/envs/base/spack.yaml
  - hosts/peak/envs/base/spack.yaml
  - hosts/ascent/envs/base/spack.yaml
  full_name: mpbelhorn/olcf-spack-environments
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">OLCF Spack Environments</h1><a
    id="user-content-olcf-spack-environments" class="anchor" aria-label="Permalink:
    OLCF Spack Environments" href="#olcf-spack-environments"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This repo contains the infrastructure and environment definitions to deploy

    site-provided software on OLCF resources via Spack environments.</p>

    <div class="markdown-heading"><h2 class="heading-element">Getting Started</h2><a
    id="user-content-getting-started" class="anchor" aria-label="Permalink: Getting
    Started" href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Clone this repo and it''s facility-modified spack fork somewhere on an OLCF

    filesystem:</p>

    <pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git

    </code></pre>

    <p>or</p>

    <pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments

    </code></pre>

    <p>Next, initialize spack and the build environment. This is done by calling</p>

    <pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base
    . ./init-facility-spack.sh

    </code></pre>

    <p>This will configure the spack build- and run-time environment build and install

    the facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this
    repo for the

    current machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both
    of these

    variables are optional. If omitted, each variable will take on their default

    values:</p>

    <pre><code>FACSPACK_MY_ENVS="/sw/${_THIS_HOST}/spack-envs"

    FACSPACK_ENV_NAME="base"

    </code></pre>

    <p>such that sourcing this script by itself</p>

    <pre><code>. ./init-facility-spack.sh

    </code></pre>

    <p>will setup the runtime shell environment to manipulate the production spack

    environment on the current system.</p>

    <p>This repo will always track at least one spack environment per machine named

    <code>base</code> which is the complete standard software environment used in
    production

    for that machine. Furthermore, only the user account with owner permissions on

    the production environment may be used to manipulate it in the default

    <code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent
    multiple

    users from concurrently modifying the production environment. Users may set an

    alternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using
    any

    tracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file
    in this repo.</p>

    <p>From these variables, a unique path per each environment name will be

    constructed:</p>

    <pre><code>FACSPACK_ENV="${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}"

    </code></pre>

    <p>The value of <code>${_THIS_HOST}</code> is determined automatically from the
    hostname on

    which the init script is being run. For each system and environment tracked in

    this repo that you wish to work on, ensure that the final expanded value of

    <code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>

    <p>Configuration paths in our <code>spack.yaml</code> environments that are not
    fixed to

    universal values are expressed in terms of relative paths to either the spack

    instance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.

    These paths are referenced in the <code>spack.yaml</code> files via environment
    variables

    set by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code>
    environment files to

    define portable and relocatable spack environments which can be re-deployed in

    arbitrary private locations by any users without needing to modify the

    environment file.</p>

    <p>The following variables are exported in Spack''s runtime environment by

    <code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code>
    the enviornment

    files tracked in this repo.</p>

    <ul>

    <li>

    <code>${FACSPACK_ENV}</code>:

    Path to where spack environment will be installed. Contains subdirs <code>opt</code>

    and <code>modules</code>.</li>

    <li>

    <code>${FACSPACK_ENV_MODULEROOT}</code>:

    Shortcut to <code>${FACSPACK_ENV}/modules</code> under which static and

    spack-generated modules are generated. Contains subdirectories <code>spack</code>,

    <code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static
    modulefiles

    respectively.</li>

    <li>

    <code>${FACSPACK_CONF_COMMON}</code>:

    Path to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>

    <li>

    <code>${FACSPACK_CONF_HOST}</code>:

    Path to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>

    </li>

    </ul>

    <p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>

    files which cannot de-reference environment variables. These affect</p>

    <ul>

    <li>Mirrors</li>

    <li>Extensions</li>

    </ul>

    <p>Spack does not internally expand environment variables in the configuration
    of

    these items so they must be expressed as hard-coded full path strings. The

    default values in this repo should point to permanent world-readable paths on

    the OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>

    <div class="markdown-heading"><h2 class="heading-element">Spack Fork</h2><a id="user-content-spack-fork"
    class="anchor" aria-label="Permalink: Spack Fork" href="#spack-fork"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The upstream development branch of spack is not used directly. Instead, the
    OLCF

    has implemented some customizations that are tracked in the "olcf-X.Y.Z"

    branches of a <a href="https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0">facility
    fork of spack</a>

    where <code>X.Y.Z</code> refers to the tagged release of upstream spack from which
    the

    OLCF-modified branch is forked.</p>

    '
  stargazers_count: 4
  subscribers_count: 2
  topics: []
  updated_at: 1704744678.0
nantes-m2-rps-exp/qqbar2mumu-2022:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: nantes-m2-rps-exp/qqbar2mumu-2022
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Projet exp\xE9\
    rimental - Production de quarkonia</h1><a id=\"user-content-projet-exp\xE9rimental---production-de-quarkonia\"\
    \ class=\"anchor\" aria-label=\"Permalink: Projet exp\xE9rimental - Production\
    \ de quarkonia\" href=\"#projet-exp\xE9rimental---production-de-quarkonia\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<blockquote>\n\
    <p>Ce d\xE9pot git h\xE9berge les fichiers n\xE9cessaires pour d\xE9marrer le\
    \ projet \"Production de quarkonia\" du Master 2 RPS de l'Universit\xE9 de Nantes.\
    \ Il est principalement \xE0 destination des \xE9tudiants qui r\xE9alisent ce\
    \ projet. Le \"vous\" ci-dessous s'adresse donc \xE0 ces \xE9tudiants.</p>\n</blockquote>\n\
    <p>Pour ce projet le language de programmation choisi est Python. Nous recommandons\
    \ de l'utiliser par le biais de <a href=\"https://jupyter.org\" rel=\"nofollow\"\
    >\"Notebooks Jupyter\"</a> qui permettent de m\xE9langer le code, la documentation\
    \ et les r\xE9sultats de l'ex\xE9cution du code.</p>\n<p>Jupyter est un outil\
    \ commun dans le domaine de la science des donn\xE9es. Il y a bien des fa\xE7\
    ons d'utiliser Jupyter et de nombreux tutoriels sont disponibles en ligne pour\
    \ aller plus loin, mais vous trouverez ci-dessous trois m\xE9thodes pour d\xE9\
    marrer :</p>\n<ol>\n<li>une <a href=\"conda/README.md\">m\xE9thode locale bas\xE9\
    e sur conda</a>\n</li>\n<li>une <a href=\"cloud/README.md\">m\xE9thode cloud</a>\n\
    </li>\n<li>une <a href=\"multipass/README.md\">m\xE9thode locale bas\xE9e sur\
    \ multipass</a>\n</li>\n</ol>\n<p>A noter que seule la troisi\xE8me m\xE9thode\
    \ permet, a priori, de r\xE9aliser toutes les t\xE2ches n\xE9cessaires \xE0 ce\
    \ projet, car elle offre des interfaces Python de paquets C++ d\xE9velopp\xE9\
    s sp\xE9cifiquement pour ce projet, alors que les deux premi\xE8res ne permettent\
    \ d'acc\xE9der qu'\xE0 des paquets Python \"g\xE9n\xE9riques\". Les deux premi\xE8\
    res m\xE9thodes permettent n\xE9anmoins de d\xE9marrer assez rapidement.</p>\n\
    <p>Pour ce projet, vous utiliserez \xE9galement <a href=\"https://git.com\" rel=\"\
    nofollow\">Git</a> et <a href=\"https://github.com\">GitHub</a>. Si ce n'est pas\
    \ d\xE9j\xE0 le cas, il vous faudra <a href=\"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\"\
    \ rel=\"nofollow\">installer git sur votre machine</a> et vous <a href=\"https://fr.wikihow.com/cr%C3%A9er-un-compte-sur-GitHub\"\
    \ rel=\"nofollow\">cr\xE9\xE9r un compte GitHub</a>.</p>\n<p>Comme pour Jupyter,\
    \ un nombre important de ressources documentaires et tutoriels sont disponibles\
    \ sur le net pour commencer avec git si c'est votre premi\xE8re approche ou encore\
    \ pour approfondir votre ma\xEEtrise de cet outil si vous le connaissez d\xE9\
    j\xE0 un peu.</p>\n<p>Vous trouverez dans le <a href=\"git/README.md\">document\
    \ <code>git/README.md</code></a> les commandes de base pour d\xE9marrer avec ce\
    \ d\xE9p\xF4t git en particulier.</p>\n<p>Une fois la premi\xE8re installation\
    \ r\xE9alis\xE9e, commencez par vous familiariser avec Jupyter en utilisant le\
    \ <a href=\"notebooks/muon-eta-distribution.ipynb\">notebook d'exemple</a></p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1667463557.0
noaa-oar-arl/nexus-spack-buildcache:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: noaa-oar-arl/nexus-spack-buildcache
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">nexus-spack-buildcache</h1><a
    id="user-content-nexus-spack-buildcache" class="anchor" aria-label="Permalink:
    nexus-spack-buildcache" href="#nexus-spack-buildcache"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Trying to <a href="https://github.com/spack/setup-spack?tab=readme-ov-file#example-caching-your-own-binaries-for-public-repositories">cache
    binaries for Spack</a>

    for EMSF built with Intel Classic (<code>ifort</code>, <code>icc</code>, ...).</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1715293522.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - linux-rhel8-zen3/baseline/spack.yaml
  - linux-sles15-zen2/spock/spack.yaml
  - linux-rhel8-ppc64le/summit/spack.yaml
  - linux-centos7-broadwell/or-slurm/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_environments.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Purpose</h2><a id="user-content-purpose"
    class="anchor" aria-label="Permalink: Purpose" href="#purpose"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 5
  subscribers_count: 19
  topics: []
  updated_at: 1705687927.0
openPMD/openPMD-api:
  data_format: 2
  description: ':floppy_disk: C++ & Python API for Scientific I/O'
  filenames:
  - spack.yaml
  - .github/ci/spack-envs/clang14_py311_nompi_h5_ad2/spack.yaml
  - .github/ci/spack-envs/clangtidy_nopy_ompi_h5_ad2/spack.yaml
  full_name: openPMD/openPMD-api
  latest_release: 0.15.2
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">C++ &amp;\
    \ Python API for Scientific I/O with openPMD</h1><a id=\"user-content-c--python-api-for-scientific-io-with-openpmd\"\
    \ class=\"anchor\" aria-label=\"Permalink: C++ &amp; Python API for Scientific\
    \ I/O with openPMD\" href=\"#c--python-api-for-scientific-io-with-openpmd\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p><a\
    \ href=\"https://github.com/openPMD/openPMD-standard/releases\"><img src=\"https://camo.githubusercontent.com/5d13f841c93684a76b33b3bfea77f0972f8d14291c5180eac269e1cad9dc341c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\"\
    \ alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d0fc2114159b7b68214de4f99a704161635ae9a5f2500903a0735598634331a5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/ff7083cc261bcd9f3693e400b5c5ab2bc0c7e24d7b0b456ffe7b34ee19af0e1f/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\"\
    \ alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"\
    https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"\
    max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/20a8ccdee703984a1e590f3213ce07587f7467115d7742291cd7d77b254707bf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b7df96f0665c4aeee252301c6cdaf28fa395ee36730464abaa93956ccf5544f4/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/66b24447775c3b5b6d1fb8a72efa1a837bd07012711189a76c944b2943a1d83b/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\"\
    \ alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a4d2f864cd8cc403a0a9af3b8a008fccdbe8b3476c8d39a02ecda3097212cdcb/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/502c10b6946e49f3d3a5758800dc5e01cb40a0c4cc5ea8bb17a9e2471c98e327/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f687ccda5d5e831448209e00847229d69a109d4d0c9d0f24ef2c19fd1c50fe7/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\"\
    \ alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c4197235edfc513c73649de993970af6f8067123ce78821c0249dd0c6747ed9c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\"\
    \ alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\
    ><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\"\
    \ alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5420d1b718d3805a368c5cd2a9c33e294819c7235e8e533d3b8f1b2b2bc6c4b4/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\"\
    \ alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5348e1f24701566268367aea654dee73cbea5ea91b3d94819085fd552dff34b5/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\"\
    \ alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD is an open meta-data schema\
    \ that provides meaning and self-description for data sets in science and engineering.\n\
    See <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a>\
    \ for details of this schema.</p>\n<p>This library provides a reference API for\
    \ openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable,\
    \ hierarchical file formats, this library implements various backends such as\
    \ HDF5, ADIOS2 and JSON.\nWriting &amp; reading through those backends and their\
    \ associated files are supported for serial and <a href=\"https://www.mpi-forum.org/docs/\"\
    \ rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Usage</h2><a id=\"user-content-usage\" class=\"\
    anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">C++</h3><a id=\"user-content-c\" class=\"anchor\"\
    \ aria-label=\"Permalink: C++\" href=\"#c\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p><a href=\"https://isocpp.org/\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/b4039af8871849eff8d3350af5ac6e8f02048d6dc71ce1e941b5ab9f219325ea/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\"\
    \ alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span>\
    \ s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span\
    \ class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"\
    pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>\
    \ &amp; [step, it] : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span>\
    \ &lt;&lt; step &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span\
    \ class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\"\
    >const</span> &amp; [name, mesh] : it.<span class=\"pl-smi\">meshes</span> ) {\n\
    \        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\
    \  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; name &lt;&lt; <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\"\
    >\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\"\
    >for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp;\
    \ val : mesh.<span class=\"pl-c1\">attributes</span>() )\n            std::cout\
    \ &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"\
    pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\
    \    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span>\
    \ <span class=\"pl-k\">const</span> &amp; [name, species] : it.<span class=\"\
    pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"\
    </span></span> &lt;&lt; name &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\"\
    >auto</span> <span class=\"pl-k\">const</span>&amp; val : species.<span class=\"\
    pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt;\
    \ val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Python</h3><a id=\"\
    user-content-python\" class=\"anchor\" aria-label=\"Permalink: Python\" href=\"\
    #python\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a href=\"https://www.python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e751dc39d18bc7613b561655f2f3551a2c999fc64fb85aeda826e0351492e168/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\"\
    \ alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span>\
    \ <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"\
    pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span\
    \ class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\"\
    >io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\
    \n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"\
    pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span\
    \ class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n  \
    \  <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\
    \n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span\
    \ class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n\
    \        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}'\
    \ attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\"\
    >k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"\
    pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span\
    \ class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span\
    \ class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"\
    pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"\
    pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n  \
    \          <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">More!</h3><a id=\"\
    user-content-more\" class=\"anchor\" aria-label=\"Permalink: More!\" href=\"#more\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Curious?\nOur manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\"\
    \ rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Dependencies</h2><a\
    \ id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\"\
    \ href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Required:</p>\n<ul>\n<li>CMake 3.15.0+</li>\n<li>C++17\
    \ capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx</li>\n\
    </ul>\n<p>Shipped internally in <code>share/openPMD/thirdParty/</code>:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> 2.13.10+\
    \ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\">BSL-1.0</a>)</li>\n\
    <li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> 2.11.1+ (<a\
    \ href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)</li>\n\
    <li>\n<a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a> 3.9.1+ (<a\
    \ href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\">MIT</a>)</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> 3.7.1+ (<a href=\"\
    https://github.com/ToruNiina/toml11/blob/master/LICENSE\">MIT</a>)</li>\n</ul>\n\
    <p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\"\
    \ rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\"\
    \ rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either\
    \ with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n\
    </ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python\
    \ 3.8 - 3.12</li>\n<li>pybind11 2.11.1+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py\
    \ 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n\
    <li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n<li>CUDA C++\
    \ (optional, currently used only in tests)</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Installation</h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/132ae648808a03cbf50ea3f9834f3e797f087ad259ebdc21b8d94804f9f57700/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fd019b54503cfc07bcb5b636086070bf8a09e73e1f88653a551cd3f47231df28/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/4c10ad19fca3dd28135f3b21f3e7a9950dad57fbb3d4c9f90d8d369aafd757e1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d5db8554037acd8a410130359282ed8e0ba8e5c6d4ec232b6898667459d763b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/33b82ea6e40ffa2127d4e4e0fcd64e8aa96692b222c51bf6f93e1996dac79b21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\"\
    \ alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our community loves to help each other.\n\
    Please <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\"\
    >report installation problems</a> in case you should get stuck.</p>\n<p>Choose\
    \ <em>one</em> of the install methods below to get started:</p>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\"><a href=\"https://spack.io\"\
    \ rel=\"nofollow\">Spack</a></h3><a id=\"user-content-spack\" class=\"anchor\"\
    \ aria-label=\"Permalink: Spack\" href=\"#spack\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/942d8d86fcbe5f3670631c12617a3d205a84acb9304609abfa364280d96d8588/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\"\
    \ alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/7b52f21df7ad363012112cd9c32c25dd554bd25cac3c84c92a04c6207274acd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b376c2ae3f321777bb8b0dd09bce8bf2340611f6c0eb2ce8207323e0fab04f20/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\"\
    \ alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \    +python -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack load\
    \ openpmd-api</pre></div>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    ><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a></h3><a id=\"user-content-conda\"\
    \ class=\"anchor\" aria-label=\"Permalink: Conda\" href=\"#conda\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p><a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6fe3005c57558bc59b43aa7228a48663428f0dd49c264d35af536f6d052b12b3/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6445f5e527792585ad3b382fce8128892407ba1bb5af6508af00abd8ccf08cfd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/502a7a44785416f67a8fb94dbc02547a993fb42195f308e821661c28319060ad/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \           OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\n\
    conda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\"><a href=\"https://brew.sh\"\
    \ rel=\"nofollow\">Brew</a></h3><a id=\"user-content-brew\" class=\"anchor\" aria-label=\"\
    Permalink: Brew\" href=\"#brew\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/5ef9bc9e32e5b1966642b44b62543b570d72da9d2583fea7b32cae6fce75495d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\"\
    \ alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7b52f21df7ad363012112cd9c32c25dd554bd25cac3c84c92a04c6207274acd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/d44878e96acfad216c259071aaeb3dc3a3abc44a9cdf5d12c5fce6d07e4c1762/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\"\
    \ alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<div class=\"\
    markdown-heading\"><h3 class=\"heading-element\"><a href=\"https://pypi.org\"\
    \ rel=\"nofollow\">PyPI</a></h3><a id=\"user-content-pypi\" class=\"anchor\" aria-label=\"\
    Permalink: PyPI\" href=\"#pypi\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a href=\"https://pypi.org/project/openPMD-api\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/9401a82878058d507a0199407fc2722229b0bf78eb31fdeaa054bd881d0bc769/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\"\
    \ alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6445f5e527792585ad3b382fce8128892407ba1bb5af6508af00abd8ccf08cfd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8feb288d963f4caa697d0b3b5182e71edbf4106ae4bcc66ce0dd1921cba5c6f6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\"\
    \ alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/24f7c205d4b2824ef9506cc27543baa4d040b9a7c0e91355d7da11fc17b74c17/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\"\
    \ alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9)\
    \ or on exotic processor architectures, this install method <em>compiles from\
    \ source</em> against the found installations of HDF5, ADIOS2, and/or MPI (in\
    \ system paths, from other package managers, or loaded via a module system, ...).</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> optional:                   --user</span>\npython3\
    \ -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n\
    <p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional:                                    --user</span>\npython3\
    \ -m pip install -U pip packaging setuptools wheel\npython3 -m pip install -U\
    \ cmake\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:      \
    \                                                             --user</span>\n\
    openPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n\
    <p>For some exotic architectures and compilers, you might need to disable a compiler\
    \ feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\"\
    \ rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter\
    \ linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                               \
    \                 --user</span>\npython3 -m pip install openpmd-api --no-binary\
    \ openpmd-api</pre></div>\n<p>Additional CMake options can be passed via individual\
    \ environment variables, which need to be prefixed with <code>openPMD_CMAKE_</code>.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">From Source</h3><a\
    \ id=\"user-content-from-source\" class=\"anchor\" aria-label=\"Permalink: From\
    \ Source\" href=\"#from-source\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\"><img src=\"\
    https://camo.githubusercontent.com/e35be8f08546231b86c7e9290cb559ec981380d6cb27512296820d120f233eeb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\"\
    \ alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD-api can also be built and installed\
    \ from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\
    \nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests,\
    \ with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which\
    \ python3)</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\"\
    >.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\n\
    ctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required\
    \ for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target\
    \ install</pre></div>\n<p>The following options can be added to the <code>cmake</code>\
    \ call to control features.\nCMake controls options with prefixed <code>-D</code>,\
    \ e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n\
    <td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n\
    <td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code\
    \ <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro\
    \ independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_INSTALL_RPATH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Add RPATHs to installed binaries</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n\
    <td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n\
    </table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n\
    <sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without\
    \ specific cause is highly discouraged</em></p>\n<p>Additionally, the following\
    \ libraries are shipped internally.\nThe following options allow to switch to\
    \ external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n\
    <th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.10+</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>pybind11</td>\n<td>2.11.1+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_TOML11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>toml11</td>\n<td>3.7.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this\
    \ will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and\
    \ installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code>\
    \ to the <code>cmake</code> command.\nYou can only build a static or a shared\
    \ library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\n\
    In order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code>\
    \ to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and\
    \ command line tools are built.\nIn order to skip building those, pass <code>OFF</code>\
    \ to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_CUDA_EXAMPLES</code></td>\n<td>ON/<strong>OFF</strong>\n\
    </td>\n<td>Use CUDA in examples</td>\n</tr>\n</tbody>\n</table>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Linking to your project</h2><a\
    \ id=\"user-content-linking-to-your-project\" class=\"anchor\" aria-label=\"Permalink:\
    \ Linking to your project\" href=\"#linking-to-your-project\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>The install will contain\
    \ header files and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">CMake</h3><a id=\"\
    user-content-cmake\" class=\"anchor\" aria-label=\"Permalink: CMake\" href=\"\
    #cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>If your project is using CMake for its build, one can conveniently use our\
    \ provided <code>openPMDConfig.cmake</code> package, which is installed alongside\
    \ the library.</p>\n<p>First set the following environment hint if openPMD-api\
    \ was <em>not</em> installed in a system path:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed\
    \ if installed outside of system paths</span>\n<span class=\"pl-k\">export</span>\
    \ CMAKE_PREFIX_PATH=<span class=\"pl-smi\">$HOME</span>/somepath:<span class=\"\
    pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n<p>Use the following lines in\
    \ your project's <code>CMakeLists.txt</code>:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> supports:           \
    \            COMPONENTS MPI NOMPI HDF5 ADIOS2</span>\n<span class=\"pl-c1\">find_package</span>(openPMD\
    \ 0.15.0 <span class=\"pl-k\">CONFIG</span>)\n\n<span class=\"pl-k\">if</span>(openPMD_FOUND)\n\
    \    <span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span class=\"\
    pl-k\">PRIVATE</span> openPMD::openPMD)\n<span class=\"pl-k\">endif</span>()</pre></div>\n\
    <p><em>Alternatively</em>, add the openPMD-api repository source directly to your\
    \ project and use it via:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">add_subdirectory</span>(<span class=\"pl-s\">\"path/to/source/of/openPMD-api\"\
    </span>)\n\n<span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span\
    \ class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n<p>For development\
    \ workflows, you can even automatically download and build openPMD-api from within\
    \ a depending CMake project.\nJust replace the <code>add_subdirectory</code> call\
    \ with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"\
    pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077\
    \ <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_SHARED_LIBS\
    \ <span class=\"pl-k\">OFF</span>)  <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> precedence over BUILD_SHARED_LIBS if needed</span>\n<span class=\"pl-c1\"\
    >set</span>(openPMD_INSTALL <span class=\"pl-k\">OFF</span>)            <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> or instead use:</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> set(openPMD_INSTALL ${BUILD_SHARED_LIBS})\
    \  # only install if used as a shared library</span>\n<span class=\"pl-c1\">set</span>(openPMD_USE_PYTHON\
    \ <span class=\"pl-k\">OFF</span>)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY\
    \ <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"</span>\n\
    \  GIT_TAG        <span class=\"pl-s\">\"0.15.0\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Manually</h3><a\
    \ id=\"user-content-manually\" class=\"anchor\" aria-label=\"Permalink: Manually\"\
    \ href=\"#manually\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>If your (Linux/OSX) project is build by calling the compiler\
    \ directly or uses a manually written <code>Makefile</code>, consider using our\
    \ <code>openPMD.pc</code> helper file for <code>pkg-config</code>, which are installed\
    \ alongside the library.</p>\n<p>First set the following environment hint if openPMD-api\
    \ was <em>not</em> installed in a system path:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed\
    \ if installed outside of system paths</span>\n<span class=\"pl-k\">export</span>\
    \ PKG_CONFIG_PATH=<span class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span\
    \ class=\"pl-smi\">$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and\
    \ compiler flags for your project are available via:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ switch to check if openPMD-api was build as static library</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> (via BUILD_SHARED_LIBS=OFF) or as shared\
    \ library (default)</span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config\
    \ --variable=static openPMD<span class=\"pl-pds\">)</span></span><span class=\"\
    pl-pds\">\"</span></span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>true<span class=\"pl-pds\">\"</span></span> ]\n\
    <span class=\"pl-k\">then</span>\n    pkg-config --libs --static openPMD\n   \
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib\
    \ -lopenPMD -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so\
    \ /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config\
    \ --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib\
    \ -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Author Contributions</h2><a\
    \ id=\"user-content-author-contributions\" class=\"anchor\" aria-label=\"Permalink:\
    \ Author Contributions\" href=\"#author-contributions\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>openPMD-api is developed\
    \ by many people.\nIt was initially started by the <a href=\"https://hzdr.de/crp\"\
    \ rel=\"nofollow\">Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\
    >libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\"\
    \ rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"\
    https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe\
    \ following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\
    >contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\"\
    >Axel Huebl (LBNL, previously HZDR)</a>:\nproject lead, releases, documentation,\
    \ automated CI/CD, Python bindings, Dask, installation &amp; packaging, prior\
    \ reference implementations</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\"\
    >Franz Poeschel (CASUS)</a>:\nJSON &amp; ADIOS2 backend, data staging/streaming,\
    \ reworked class design</li>\n<li>\n<a href=\"https://github.com/C0nsultant\"\
    >Fabian Koller (HZDR)</a>:\ninitial library design and implementation with HDF5\
    \ &amp; ADIOS1 backend</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu\
    \ (LBNL)</a>:\nnon-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n\
    </ul>\n<p>Maintained by the following research groups:</p>\n<ul>\n<li>\n<a href=\"\
    https://www.casus.science/casus/team/\" rel=\"nofollow\">Computational Radiation\
    \ Physics (CRD)</a> at CASUS/HZDR, led by <a href=\"https://github.com/bussmann\"\
    >Michael Bussmann</a>\n</li>\n<li>\n<a href=\"https://atap.lbl.gov/accelerator-modeling-program/\"\
    \ rel=\"nofollow\">Accelerator Modeling Program (AMP)</a> at LBNL, led by <a href=\"\
    https://github.com/jlvay\">Jean-Luc Vay</a>\n</li>\n<li>\n<a href=\"https://crd.lbl.gov/divisions/scidata/sdm/\"\
    \ rel=\"nofollow\">Scientific Data Management (SDM)</a> at LBNL, led by <a href=\"\
    https://github.com/john18\">Kesheng (John) Wu</a>\n</li>\n</ul>\n<p>Further thanks\
    \ go to improvements and contributions from:</p>\n<ul>\n<li>\n<a href=\"https://github.com/CFGrote\"\
    >Carsten Fortmann-Grote (EU XFEL GmbH, now MPI-EvolBio)</a>:\ndraft of our Python\
    \ unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\">Dominik\
    \ Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n\
    <li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\n\
    support on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\"\
    >James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"\
    https://github.com/psychocoderHPC\">Ren\xE9 Widera (HZDR)</a>:\ndesign improvements\
    \ for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\"\
    >Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n\
    <a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation\
    \ improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\xE9\
    mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n\
    <a href=\"https://github.com/LDAmorim\">L\xEDgia Diana Amorim (LBNL)</a>:\npackage\
    \ integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\"\
    >Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"\
    https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing,\
    \ documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\"\
    >Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"\
    https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask prototyping\
    \ &amp; ADIOS2 benchmarking</li>\n<li>\n<a href=\"https://github.com/jakirkham\"\
    >John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n<li>\n<a href=\"\
    https://github.com/eschnett\">Erik Schnetter (PITP)</a>:\nC++ API bug fixes</li>\n\
    <li>\n<a href=\"https://github.com/jeanbez\">Jean Luca Bez (LBNL)</a>:\nHDF5 performance\
    \ tuning</li>\n<li>\n<a href=\"https://github.com/bernhardmgruber\">Bernhard Manfred\
    \ Gruber (CERN)</a>:\nCMake fix for parallel HDF5</li>\n<li>\n<a href=\"https://github.com/DerNils-git\"\
    >Nils Schild (IPP)</a>:\nCMake improvements for subprojects</li>\n</ul>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Grants</h3><a id=\"\
    user-content-grants\" class=\"anchor\" aria-label=\"Permalink: Grants\" href=\"\
    #grants\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The openPMD-api authors acknowledge support via the following programs.\nSupported\
    \ by the CAMPA collaboration, a project of the U.S. Department of Energy, Office\
    \ of Science, Office of Advanced Scientific Computing Research and Office of High\
    \ Energy Physics, Scientific Discovery through Advanced Computing (SciDAC) program.\n\
    Previously supported by the Consortium for Advanced Modeling of Particles Accelerators\
    \ (CAMPA), funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\n\
    Supported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort\
    \ of two U.S. Department of Energy organizations (Office of Science and the National\
    \ Nuclear Security Administration).\nThis project has received funding from the\
    \ European Unions Horizon 2020 research and innovation programme under grant agreement\
    \ No 654220.\nThis work was partially funded by the Center of Advanced Systems\
    \ Understanding (CASUS), which is financed by Germany's Federal Ministry of Education\
    \ and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism\
    \ (SMWK) with tax funds on the basis of the budget approved by the Saxon State\
    \ Parliament.\nSupported by the HElmholtz Laser Plasma Metadata Initiative (HELPMI)\
    \ project (ZT-I-PF-3-066), funded by the \"Initiative and Networking Fund\" of\
    \ the Helmholtz Association in the framework of the \"Helmholtz Metadata Collaboration\"\
    \ project call 2022.</p>\n<div class=\"markdown-heading\"><h3 class=\"heading-element\"\
    >Transitive Contributions</h3><a id=\"user-content-transitive-contributions\"\
    \ class=\"anchor\" aria-label=\"Permalink: Transitive Contributions\" href=\"\
    #transitive-contributions\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>openPMD-api stands on the shoulders of giants and we are\
    \ grateful for the following projects included as direct dependencies:</p>\n<ul>\n\
    <li>\n<a href=\"https://github.com/ornladios/ADIOS2\">ADIOS2</a> by <a href=\"\
    https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky, N. Podhorszki, W.F.\
    \ Godoy (ORNL), team, collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"\
    https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\xFD</a> and <a href=\"\
    https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n\
    <li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a>\
    \ and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a>\
    \ by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"\
    https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> by <a href=\"\
    https://github.com/ToruNiina\">Toru Niina</a> and <a href=\"https://github.com/ToruNiina/toml11#Contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\"\
    >pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a>\
    \ and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n\
    </li>\n<li>all contributors to the evolution of modern C++ and early library preview\
    \ developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n\
    </li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a>\
    \ and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n\
    </li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"\
    nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\
    \ and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among\
    \ others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\"\
    >openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR,\
    \ now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\
    >contributors</a>\n</li>\n</ul>\n"
  stargazers_count: 133
  subscribers_count: 11
  topics:
  - openpmd
  - openscience
  - hdf5
  - adios
  - mpi
  - hpc
  - research
  - file-handling
  - python3
  - opendata
  - metadata
  - cpp17
  updated_at: 1717179269.0
player1537-playground/triple-r:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537-playground/triple-r
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1614701026.0
pnnl/ExaGO:
  data_format: 2
  description: High-performance power grid optimization for stochastic, security-constrained,
    and multi-period ACOPF problems.
  filenames:
  - buildsystem/spack/deception/spack.yaml
  - buildsystem/spack/summit/spack.yaml
  - buildsystem/spack/crusher/spack.yaml
  - buildsystem/spack/incline/spack.yaml
  - performance_analysis/spack.yaml
  - buildsystem/container/spack.yaml
  full_name: pnnl/ExaGO
  latest_release: v1.6.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">\n<b>Exa</b>scale\
    \ <b>G</b>rid <b>O</b>ptimization toolkit (ExaGO<sup>TM</sup>) <a href=\"https://github.com/pre-commit/pre-commit\"\
    ><img src=\"https://camo.githubusercontent.com/a8cba9888a55d8a038324b73da057a30a40f34b0eae64c2f93196d5d837df1bd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7072652d2d636f6d6d69742d656e61626c65642d627269676874677265656e3f6c6f676f3d7072652d636f6d6d6974\"\
    \ alt=\"pre-commit\" data-canonical-src=\"https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    \ alt=\"PNNL GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    \ alt=\"ORNL Ascent GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    \ alt=\"pre-commit GitHub Action\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    \ alt=\"Spack CPU Build\" style=\"max-width: 100%;\"></a>\n</h1><a id=\"user-content-exascale-grid-optimization-toolkit-exagotm-----\"\
    \ class=\"anchor\" aria-label=\"Permalink: Exascale Grid Optimization toolkit\
    \ (ExaGO) \" href=\"#exascale-grid-optimization-toolkit-exagotm-----\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer\" href=\"viz/images/network_gen_load_us.png\"><img\
    \ src=\"viz/images/network_gen_load_us.png\" style=\"max-width: 100%;\"></a></p>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/manual/figures/three_in_one.png\"\
    ><img src=\"docs/manual/figures/three_in_one.png\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>ExaGO<sup>TM</sup> is a package for solving large-scale  power grid\
    \ optimization problems on parallel and distributed architectures, particularly\
    \ targeted for exascale machines with heteregenous architectures (GPU). Combinations\
    \ of stochastic, contingency-constrained, multiperiod ACOPF problems can be solved\
    \ with ExaGO. The package is written in C/C++ with python bindings available for\
    \ python-based applications. An overview of the package is given on this page.\
    \ For extended information, including the modeling details and formulations, see\
    \ the <a href=\"docs/manual/manual.pdf\">ExaGO manual</a>.</p>\n<p>ExaGO<sup>TM</sup>\
    \ includes the following applications for solving different power grid optimization\
    \ problems:</p>\n<ul>\n<li>\n<a href=\"docs/web/opflow.md\">OPFLOW</a> solves\
    \ an AC optimal power flow either on CPU and GPU</li>\n<li>\n<a href=\"docs/web/tcopflow.md\"\
    >TCOPFLOW</a> solves a multi-period optimal power flow</li>\n<li>\n<a href=\"\
    docs/web/scopflow.md\">SCOPFLOW</a> solves a security-constrained (contingency-constrained)\
    \ optimal power. Both single-period and multi-period problems can be solved.</li>\n\
    <li>\n<a href=\"docs/web/sopflow.md\">SOPFLOW</a> solves a stochastic optimal\
    \ power flow with (optional) security constraints for single and multiple periods.</li>\n\
    </ul>\n<p>ExaGO<sup>TM</sup> applications are interfaced with the following optimization\
    \ solver packaages:</p>\n<ul>\n<li>\n<a href=\"https://github.com/coin-or/Ipopt\"\
    >Ipopt</a> is a popular optimization package for solving nonlinear optimization\
    \ problems that uses an interior-point algorithm.</li>\n<li>\n<a href=\"https://github.com/LLNL/hiop\"\
    >HiOp</a> is a HPC package for optimization. ExaGO interfaces with two of its\
    \ solvers -- a mixed sparse-dense interior-point solver (NewtonMDS) and a sparse\
    \ interior-point solver (HiOPSparse). NewtonMDS  allows execution of the optimization\
    \ either on CPU and GPU. The sparse HiOp solver is currently supported on CPU\
    \ only.</li>\n</ul>\n<p>Note that not all applications can utilize all solvers\
    \ yet. The following table lists the solver-application compatibility.</p>\n<table>\n\
    <thead>\n<tr>\n<th align=\"center\">Solver</th>\n<th align=\"center\">OPFLOW</th>\n\
    <th align=\"center\">TCOPFLOW</th>\n<th align=\"center\">SCOPLOW</th>\n<th align=\"\
    center\">SOPFLOW</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Ipopt</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\">Y</td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td align=\"center\">HiOp</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\"></td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<p>Additionally,\
    \ note that SCOPFLOW and SOPFLOW with HiOp solver use Ipopt to solve a portion\
    \ of the problem (base problem). So one must also configure with Ipopt when using\
    \ HiOp solver for these applications.</p>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Installing</h2><a id=\"user-content-installing\" class=\"\
    anchor\" aria-label=\"Permalink: Installing\" href=\"#installing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Details installation\
    \ instructions are given at <a href=\"./INSTALL.md\">INSTALL.md</a> for information\
    \ on acquiring, building and installing ExaGO.</p>\n<p>If you are a developer\
    \ with access to the project, we also provide public binaries that are generated\
    \ through our GitHub actions workflows documented in <a href=\".github/workflows/README.md\"\
    >README.md</a>, and with documentation about usage in the packages section of\
    \ our repository. Check out a short (&lt; 60s demo) of pulling down a version\
    \ of ExaGO:</p>\n<p><a href=\"https://asciinema.org/a/KCi5TmUXc6zWDj7JYHzfSFxmw\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/036a31e6b78284e2773e8c365f25415ca9f4d6c5bf012a91311694943e2c6cda/68747470733a2f2f61736369696e656d612e6f72672f612f4b436935546d555863367a57446a374a59487a665346786d772e706e67\"\
    \ alt=\"asciicast\" data-canonical-src=\"https://asciinema.org/a/KCi5TmUXc6zWDj7JYHzfSFxmw.png\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Developer Guide</h2><a id=\"user-content-developer-guide\" class=\"\
    anchor\" aria-label=\"Permalink: Developer Guide\" href=\"#developer-guide\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>You\
    \ can view the following helpful documentation sources:</p>\n<ul>\n<li>\n<a href=\"\
    docs/web/test_add.md\">test_add.md</a> markdown file for information on adding\
    \ tets (outdated)</li>\n<li>\n<a href=\"buildsystem/README.md\">README.md</a>\
    \ for our bash / spack buildsystem used in GitHub/GitLab CI/CD</li>\n<li>\n<a\
    \ href=\"buildsystem/spack/README.md\">README.md</a> for our spack specific build\
    \ scripts that support CI tcl modules on HPC target platforms</li>\n<li>\n<a href=\"\
    docs/devcontainer/README.md\">README.md</a> for our devcontianer configuration\
    \ information (codespace support coming soon)</li>\n<li>\n<a href=\"docs/exago_policy_compatibility.md\"\
    >exago_policy_compatiblility</a> for xSDK compatibility guidelines, and ways to\
    \ enforce compliance</li>\n<li>\n<a href=\"docs/python_bindings.md\">python_bindings.md</a>\
    \ for documentation about or Python bindings</li>\n<li>\n<a href=\"performance_analysis/README.md\"\
    >README.md</a> for information about profiling ExaGO with spack</li>\n<li>\n<a\
    \ href=\".github/workflows/README.md\">README.md</a> for details about our GitHub\
    \ actions</li>\n<li>\n<a href=\"docs/web/README.ci_clusters.md\">README.ci_clusters.md</a>\
    \ for CI cluster workflow documentation</li>\n<li>\n<a href=\"docs/web/README.summit.md\"\
    >README.summit.md</a> for ORNL's Summit specific configuration</li>\n</ul>\n<div\
    \ class=\"markdown-heading\"><h2 class=\"heading-element\">Vizualisation</h2><a\
    \ id=\"user-content-vizualisation\" class=\"anchor\" aria-label=\"Permalink: Vizualisation\"\
    \ href=\"#vizualisation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Our ChatGrid frontend deployed with React, PSQL and LangChain\
    \ has documentation in <a href=\"viz/README.md\">README.md</a> as well as a pdf\
    \ <a href=\"viz/README.pdf\">README.pdf</a> in the <code>viz</code> subdirectory.\
    \ Several of our tutorials install this through commands in Jupyter Notebooks\
    \ as well.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Usage</h2><a id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink:\
    \ Usage\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Instructions for executing the different ExaGO<sup>TM</sup>\
    \ applications is given below.</p>\n<ul>\n<li><a href=\"docs/web/opflow.md\">OPFLOW</a></li>\n\
    <li><a href=\"docs/web/tcopflow.md\">TCOPFLOW</a></li>\n<li><a href=\"docs/web/sopflow.md\"\
    >SOPFLOW</a></li>\n<li><a href=\"docs/web/scopflow.md\">SCOPFLOW</a></li>\n<li><a\
    \ href=\"docs/web/pflow.md\">PFLOW</a></li>\n</ul>\n<p>We also provide our user\
    \ manual as a pdf <a href=\"docs/manual/manual.pdf\">manual.pdf</a> -&gt; need\
    \ to update this regularly with CI / move to quarto docs.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Tutorials</h2><a id=\"user-content-tutorials\"\
    \ class=\"anchor\" aria-label=\"Permalink: Tutorials\" href=\"#tutorials\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<ul>\n\
    <li>If you are using a devcontainer with VSCode, the following tutorials are provided:\n\
    <ul>\n<li>\n<a href=\"docs/devcontainer/tutorial.ipynb\">tutorial.ipynb</a> for\
    \ basic configuration infromation and I/O</li>\n<li>\n<a href=\"docs/devcontainer/mpi4py-tutorial.ipynb\"\
    >mpi4py-tutorial.ipynb</a> for mpi4py pointers and best practices</li>\n<li>\n\
    <a href=\"docs/devcontainer/viz-tutorial.ipynb\">viz-tutorial.ipynb</a> for spinning\
    \ up our frontend visualization with ChatGrid integration</li>\n</ul>\n</li>\n\
    <li>Otherwise, you can check out our more in depth application tutorials in the\
    \ <code>tutorials</code>subdirectory:\n<ul>\n<li>\n<a href=\"tutorials/demo1.ipynb\"\
    >demo1.ipynb</a> run OPFLOW, SCOPFLOW and visualize your output</li>\n<li>\n<a\
    \ href=\"tutorials/demo2.ipynb\">demo2.ipynb</a> run SOPFLOW on many ranks using\
    \ MPI, and visualize outpu\n<ul>\n<li>TODO - add fixes from <code>mpi4py</code>\
    \ devcontainer example into this notebook to show working MPI workflow</li>\n\
    </ul>\n</li>\n</ul>\n</li>\n</ul>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Options</h3><a id=\"user-content-options\" class=\"anchor\"\
    \ aria-label=\"Permalink: Options\" href=\"#options\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Each application has a\
    \ different set of options that are described in depth in the usage notes. These\
    \ options can be passed optionally through an options file (<code>-optionsfile\
    \ &lt;option_file&gt;</code>), or directly on the command line.</p>\n<p>Since\
    \ options may be specified in more than one location (on the command line, and\
    \ through an options file), it is worth noting that the option specified on the\
    \ command line supersede those in the options file. For example, if <code>opflowoptions</code>\
    \ options file set the network file via the option <code>-netfile case9mod.m</code>,\
    \ the following behavior occurs:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> This uses case9mod.m</span>\n\
    ./opflow -optionsfile opflowoptions\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> This uses case118.m</span>\n./opflow -netfile case118.m -options_file\
    \ opflowoptions</pre></div>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Visualization (experimental)</h2><a id=\"user-content-visualization-experimental\"\
    \ class=\"anchor\" aria-label=\"Permalink: Visualization (experimental)\" href=\"\
    #visualization-experimental\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>ExaGO has an experimental visualization to display the\
    \ results of <code>OPFLOW</code> application on a map. See the <a href=\"viz/README.md\"\
    >visualization README</a> for more information.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Contributing</h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Please see <a href=\"docs/developer_guidelines.md\">the developer guidelines</a>\
    \ before attempting to contribute.\nFeel free to raise an issue or contact the\
    \ team if the guidelines are ambiguous or you have a particular question.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Authors</h2><a id=\"\
    user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"\
    #authors\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>Shrirang Abhyankar</li>\n<li>Slaven Peles</li>\n<li>Asher Mancinelli</li>\n\
    <li>Cameron Rutherford</li>\n<li>Bruce Palmer</li>\n<li>Jaelyn Litzinger</li>\n\
    <li>William Perkins</li>\n<li>Sayef Azad Sakin</li>\n<li>Joseph Macam</li>\n<li>Ryan\
    \ Danehy</li>\n<li>Nicholson Koukpaizan</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Acknowledgement</h2><a id=\"user-content-acknowledgement\"\
    \ class=\"anchor\" aria-label=\"Permalink: Acknowledgement\" href=\"#acknowledgement\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>This package is developed as a part of <a href=\"https://www.exascaleproject.org/research-project/exasgd/\"\
    \ rel=\"nofollow\">ExaSGD</a> project under the <a href=\"https://www.exascaleproject.org/\"\
    \ rel=\"nofollow\">Exascale computing project</a>.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Copyright</h2><a id=\"user-content-copyright\"\
    \ class=\"anchor\" aria-label=\"Permalink: Copyright\" href=\"#copyright\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Copyright\
    \ \xA9 2020, Battelle Memorial Institute.</p>\n<p>ExaGO<sup>TM</sup> is a free\
    \ software distributed under a BSD 2-clause license. You may reuse, modify, and\
    \ redistribute the software. See the <a href=\"LICENSE\">license</a> file for\
    \ details.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Disclaimer</h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-label=\"\
    Permalink: Disclaimer\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>This material was prepared as an\
    \ account of work sponsored by an agency of the United States Government.  Neither\
    \ the United States Government nor the United States Department of Energy, nor\
    \ Battelle, nor any of their employees, nor any jurisdiction or organization that\
    \ has cooperated in the development of these materials, makes any warranty, express\
    \ or implied, or assumes any legal liability or responsibility for the accuracy,\
    \ completeness, or usefulness or any information, apparatus, product, software,\
    \ or process disclosed, or represents that its use would not infringe privately\
    \ owned rights.\nReference herein to any specific commercial product, process,\
    \ or service by trade name, trademark, manufacturer, or otherwise does not necessarily\
    \ constitute or imply its endorsement, recommendation, or favoring by the United\
    \ States Government or any agency thereof, or Battelle Memorial Institute. The\
    \ views and opinions of authors expressed herein do not necessarily state or reflect\
    \ those of the United States Government or any agency thereof.</p>\n"
  stargazers_count: 56
  subscribers_count: 11
  topics: []
  updated_at: 1716854720.0
pranav-sivaraman/spack-repro:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: pranav-sivaraman/spack-repro
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1716574313.0
range3/pegasus-lm:
  data_format: 2
  description: null
  filenames:
  - spack/envs/pegasus/spack.yaml
  full_name: range3/pegasus-lm
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">range3/pegasus-lm</h1><a\
    \ id=\"user-content-range3pegasus-lm\" class=\"anchor\" aria-label=\"Permalink:\
    \ range3/pegasus-lm\" href=\"#range3pegasus-lm\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">setup</h2><a id=\"user-content-setup\" class=\"anchor\"\
    \ aria-label=\"Permalink: setup\" href=\"#setup\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>module load cuda/11.8.0\nmodule load cudnn/8.6.0/cuda11\nmodule load openmpi/4.1.4/gcc9.4.0-cuda11.8.0\n\
    python3 -m venv .venv\n<span class=\"pl-c1\">source</span> .venv/bin/activate\n\
    pip install -U pip\npip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu118\n\
    pip install neologdn \\\n  prefetch-generator \\\n  datasets \\\n  sentencepiece\
    \ \\\n  transformers \\\n  scikit-learn \\\n  evaluate \\\n  tensorboard \\\n\
    \  accelerate \\\n  git+https://github.com/huggingface/transformers</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678687089.0
range3/pmembench:
  data_format: 2
  description: Micro-benchmarks created using PMDK and Intel Optane DCPMM performance
    comparisons for all generations, including the very last persistent memory, 300
    series.
  filenames:
  - spack/envs/chris90/spack.yaml
  full_name: range3/pmembench
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">pmembench</h1><a
    id="user-content-pmembench" class="anchor" aria-label="Permalink: pmembench" href="#pmembench"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">pmem2bench</h2><a id="user-content-pmem2bench"
    class="anchor" aria-label="Permalink: pmem2bench" href="#pmem2bench"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p><a href="eval/README.md">Click here for an evaluation using the Intel Optane
    DCPMM 300/200/100 series!</a></p>

    <div class="markdown-heading"><h2 class="heading-element">pmemobjbench</h2><a
    id="user-content-pmemobjbench" class="anchor" aria-label="Permalink: pmemobjbench"
    href="#pmemobjbench"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1715927529.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">LibPressio</h1><a\
    \ id=\"user-content-libpressio\" class=\"anchor\" aria-label=\"Permalink: LibPressio\"\
    \ href=\"#libpressio\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><em>the stable version of this code is found at <a href=\"\
    https://github.com/CODARcode/libpressio\">at the CODARCode organization</a> it\
    \ is updated about anually</em></p>\n<p>Pressio is latin for compression.  LibPressio\
    \ is a C++ library with C compatible bindings to abstract between different lossless\
    \ and lossy compressors and their configurations.  It solves the problem of having\
    \ to having to write separate application level code for each lossy compressor\
    \ that is developed.  Instead, users write application level code using LibPressio,\
    \ and the library will make the correct underlying calls to the compressors. \
    \ It provides interfaces to represent data, compressors settings, and compressors.</p>\n\
    <p>Documentation for the <code>master</code> branch can be <a href=\"https://robertu94.github.io/libpressio/\"\
    \ rel=\"nofollow\">found here</a></p>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">Using LibPressio</h1><a id=\"user-content-using-libpressio\"\
    \ class=\"anchor\" aria-label=\"Permalink: Using LibPressio\" href=\"#using-libpressio\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Example using the CLI from <a href=\"https://github.com/robertu94/pressio-tools\"\
    ><code>pressio-tools</code></a>\nWe also have C, C++, Rust, Julia, and Python\
    \ bindings.</p>\n<div class=\"highlight highlight-source-shell\"><pre>pressio\
    \ -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Getting Started</h2><a id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"\
    Permalink: Getting Started\" href=\"#getting-started\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>After skimming the example,\
    \ LibPressio has 6 major headers that you will need to use:</p>\n<table>\n<thead>\n\
    <tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>pressio.h</code></td>\n\
    <td>Error reporting and aquiring handles to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Supported Compressors and Metrics</h2><a id=\"user-content-supported-compressors-and-metrics\"\
    \ class=\"anchor\" aria-label=\"Permalink: Supported Compressors and Metrics\"\
    \ href=\"#supported-compressors-and-metrics\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Libpressio provides a number of builtin\
    \ compressor and metrics modules.\nAll of these are <strong>disabled by default</strong>.\n\
    They can be enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code>\
    \ variable to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information\
    \ on writing a compressor plugin see <a href=\"docs/WritingACompressorPlugin.md\"\
    >Writing a Compressor Plugin</a>\nFor information on writing a metrics plugin\
    \ see <a href=\"docs/WritingAMetricsPlugin.md\">Writing a Metrics Plugin</a></p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Compressor Plugins</h3><a\
    \ id=\"user-content-compressor-plugins\" class=\"anchor\" aria-label=\"Permalink:\
    \ Compressor Plugins\" href=\"#compressor-plugins\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>1st party compressors plugins\
    \ can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the <a href=\"build/Compressors.md\"\
    >compressor settings page</a> for information on how to configure them.</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">Metrics Plugins</h3><a\
    \ id=\"user-content-metrics-plugins\" class=\"anchor\" aria-label=\"Permalink:\
    \ Metrics Plugins\" href=\"#metrics-plugins\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>1st party compressors plugins can\
    \ be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the <a href=\"build/Metrics.md\">metrics\
    \ results page</a> for information on what they produce</p>\n<div class=\"markdown-heading\"\
    ><h3 class=\"heading-element\">IO Plugins</h3><a id=\"user-content-io-plugins\"\
    \ class=\"anchor\" aria-label=\"Permalink: IO Plugins\" href=\"#io-plugins\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the <a href=\"build/IO.md\">io settings page</a>\
    \ for information on how to configure them</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Installation</h1><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Installing LibPressio\
    \ using Spack</h2><a id=\"user-content-installing-libpressio-using-spack\" class=\"\
    anchor\" aria-label=\"Permalink: Installing LibPressio using Spack\" href=\"#installing-libpressio-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\">spack</a>.\
    \  This example will install libpressio with only the SZ3 plugin.</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Doing a development build with spack</h2><a id=\"\
    user-content-doing-a-development-build-with-spack\" class=\"anchor\" aria-label=\"\
    Permalink: Doing a development build with spack\" href=\"#doing-a-development-build-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>The easiest way to do a development build of libpressio is to use Spack envionments.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> one time setup: create an envionment</span>\nspack env\
    \ create -d mydevenviroment\nspack env activate mydevenvionment\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> one time setup: tell spack to set LD_LIBRARY_PATH\
    \ with the spack envionment's library paths</span>\nspack config add modules:prefix_inspections:lib64:[LD_LIBRARY_PATH]\n\
    spack config add modules:prefix_inspections:lib:[LD_LIBRARY_PATH]\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> one time setup: install libpressio-tools\
    \ and checkout </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> libpressio\
    \ for development</span>\nspack add libpressio-tools\nspack develop libpressio@git.master\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compile and install (repeat\
    \ as needed)</span>\nspack install </pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Manual Installation</h2><a id=\"user-content-manual-installation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Manual Installation\" href=\"#manual-installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Libpressio unconditionally requires:</p>\n<ul>\n<li><code>cmake</code></li>\n\
    <li><code>pkg-config</code></li>\n<li><a href=\"https://github.com/robertu94/std_compat\"\
    ><code>std_compat</code></a></li>\n<li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code>\
    \ or later</li>\n<li>\n<code>clang-7.0.0</code> or later using either <code>libc++</code>\
    \ or <code>libstdc++</code>.  Beware that system libraries may need to be recompiled\
    \ with <code>libc++</code> if using <code>libc++</code>\n</li>\n</ul>\n</li>\n\
    </ul>\n<p>Dependency versions and optional dependencies are documented <a href=\"\
    https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Configuring LibPressio Manually</h2><a id=\"user-content-configuring-libpressio-manually\"\
    \ class=\"anchor\" aria-label=\"Permalink: Configuring LibPressio Manually\" href=\"\
    #configuring-libpressio-manually\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>LibPressio uses a fairly standard CMake\
    \ buildsystem.\nFor more information on <a href=\"https://robertu94.github.io/learning/cmake\"\
    \ rel=\"nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration\
    \ options for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\n\
    For information on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\"\
    >API Stability</h1><a id=\"user-content-api-stability\" class=\"anchor\" aria-label=\"\
    Permalink: API Stability\" href=\"#api-stability\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>Please refer to <a href=\"\
    docs/stability.md\">docs/stability.md</a>.</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">How to Contribute</h1><a id=\"user-content-how-to-contribute\"\
    \ class=\"anchor\" aria-label=\"Permalink: How to Contribute\" href=\"#how-to-contribute\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Please refer to <a href=\"CONTRIBUTORS.md\">CONTRIBUTORS.md</a> for a list\
    \ of contributors, sponsors, and contribution guidelines.</p>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">Bug Reports</h1><a id=\"user-content-bug-reports\"\
    \ class=\"anchor\" aria-label=\"Permalink: Bug Reports\" href=\"#bug-reports\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Please files bugs to the Github Issues page on the CODARCode libpressio repository.</p>\n\
    <p>Please read this post on <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\"\
    \ rel=\"nofollow\">how to file a good bug report</a>.\_ After reading this post,\
    \ please provide the following information specific to libpressio:</p>\n<ul>\n\
    <li>Your OS version and distribution information, usually this can be found in\
    \ <code>/etc/os-release</code>\n</li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n\
    </li>\n<li>the version of each of libpressio's dependencies listed in the README\
    \ that you have installed. Where possible, please provide the commit hashes.</li>\n\
    </ul>\n<div class=\"markdown-heading\"><h1 class=\"heading-element\">Citing LibPressio</h1><a\
    \ id=\"user-content-citing-libpressio\" class=\"anchor\" aria-label=\"Permalink:\
    \ Citing LibPressio\" href=\"#citing-libpressio\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>If you find LibPressio useful, please\
    \ cite this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n \
    \ title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n\
    \  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di,\
    \ Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on\
    \ Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n\
    \  year={2021},\n  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 23
  subscribers_count: 6
  topics: []
  updated_at: 1716225019.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">ROIBIN-SZ Experiments</h1><a
    id="user-content-roibin-sz-experiments" class="anchor" aria-label="Permalink:
    ROIBIN-SZ Experiments" href="#roibin-sz-experiments"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">System Information</h2><a
    id="user-content-system-information" class="anchor" aria-label="Permalink: System
    Information" href="#system-information"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <div class="markdown-heading"><h2 class="heading-element">Where is the implementation
    of ROIBIN-SZ3?</h2><a id="user-content-where-is-the-implementation-of-roibin-sz3"
    class="anchor" aria-label="Permalink: Where is the implementation of ROIBIN-SZ3?"
    href="#where-is-the-implementation-of-roibin-sz3"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <div class="markdown-heading"><h2 class="heading-element">Getting started</h2><a
    id="user-content-getting-started" class="anchor" aria-label="Permalink: Getting
    started" href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <div class="markdown-heading"><h3 class="heading-element">Obtaining Data</h3><a
    id="user-content-obtaining-data" class="anchor" aria-label="Permalink: Obtaining
    Data" href="#obtaining-data"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <div class="markdown-heading"><h3 class="heading-element">Quality Assessment</h3><a
    id="user-content-quality-assessment" class="anchor" aria-label="Permalink: Quality
    Assessment" href="#quality-assessment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <div class="markdown-heading"><h3 class="heading-element">Container Install (for
    ease of setup)</h3><a id="user-content-container-install-for-ease-of-setup" class="anchor"
    aria-label="Permalink: Container Install (for ease of setup)" href="#container-install-for-ease-of-setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <div class="markdown-heading"><h4 class="heading-element">Singularity</h4><a id="user-content-singularity"
    class="anchor" aria-label="Permalink: Singularity" href="#singularity"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <div class="markdown-heading"><h4 class="heading-element">Docker</h4><a id="user-content-docker"
    class="anchor" aria-label="Permalink: Docker" href="#docker"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <div class="markdown-heading"><h3 class="heading-element">Building the container</h3><a
    id="user-content-building-the-container" class="anchor" aria-label="Permalink:
    Building the container" href="#building-the-container"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <div class="markdown-heading"><h3 class="heading-element">Manual Install (for
    scale)</h3><a id="user-content-manual-install-for-scale" class="anchor" aria-label="Permalink:
    Manual Install (for scale)" href="#manual-install-for-scale"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <div class="markdown-heading"><h2 class="heading-element">Running the Experiments</h2><a
    id="user-content-running-the-experiments" class="anchor" aria-label="Permalink:
    Running the Experiments" href="#running-the-experiments"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <div class="markdown-heading"><h3 class="heading-element">Example Output</h3><a
    id="user-content-example-output" class="anchor" aria-label="Permalink: Example
    Output" href="#example-output"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <div class="markdown-heading"><h2 class="heading-element">Results for Figures</h2><a
    id="user-content-results-for-figures" class="anchor" aria-label="Permalink: Results
    for Figures" href="#results-for-figures"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1648861627.0
roblatham00/phonebook:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: roblatham00/phonebook
  latest_release: null
  readme: '<p>Your project "YP" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1682697472.0
rohankumardubey/libtree:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: rohankumardubey/libtree
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    ><img src=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    \ alt=\"Test\" style=\"max-width: 100%;\"></a>\n<a href=\"https://aur.archlinux.org/packages/libtree/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e22cad709c40ea40e72b03313e4a660481222a373c9217b71809265e991f747e/68747470733a2f2f696d672e736869656c64732e696f2f6175722f76657273696f6e2f6c6962747265653f6c6f676f3d417263682d4c696e7578\"\
    \ alt=\"AUR version\" data-canonical-src=\"https://img.shields.io/aur/version/libtree?logo=Arch-Linux\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">libtree</h1><a id=\"user-content-libtree\" class=\"anchor\"\
    \ aria-label=\"Permalink: libtree\" href=\"#libtree\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>A tool that:</p>\n<ul>\n\
    <li>\U0001F333 turns <code>ldd</code> into a tree</li>\n<li>\u261D\uFE0F explains\
    \ why shared libraries are found and why not</li>\n<li>\U0001F4E6 optionally deploys\
    \ executables and dependencies into a single directory</li>\n</ul>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"doc/screenshot.png\"><img src=\"doc/screenshot.png\"\
    \ alt=\"example\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Installation</h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Download the <a href=\"https://github.com/haampie/libtree/releases\"><strong>latest\
    \ release</strong></a> from Github.</p>\n<p><strong>Static executable</strong></p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>wget -qO libtree https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64\n\
    chmod +x libtree\n./libtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<p><strong>Static executable\
    \ + optional dependencies</strong></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>wget -qO libtree.tar.gz https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64.tar.gz\n\
    mkdir libtree\ntar -xf libtree.tar.gz -C libtree\n<span class=\"pl-k\">export</span>\
    \ PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$PWD</span>/libtree:<span class=\"pl-smi\">$PATH</span><span class=\"pl-pds\"\
    >\"</span></span>\nlibtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Deploying binaries + dependencies into a folder</h2><a\
    \ id=\"user-content-deploying-binaries--dependencies-into-a-folder\" class=\"\
    anchor\" aria-label=\"Permalink: Deploying binaries + dependencies into a folder\"\
    \ href=\"#deploying-binaries--dependencies-into-a-folder\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$ libtree <span class=\"pl-s\"><span class=\"\
    pl-pds\">$(</span>which man<span class=\"pl-pds\">)</span></span> -d man.bundle\
    \ --chrpath --strip\nman\n\u251C\u2500\u2500 libmandb-2.9.1.so [runpath]\n\u2502\
    \   \u251C\u2500\u2500 libman-2.9.1.so [runpath]\n\u2502   \u2502   \u251C\u2500\
    \u2500 libpipeline.so.1 [ld.so.conf]\n\u2502   \u2502   \u2514\u2500\u2500 libseccomp.so.2\
    \ [ld.so.conf]\n\u2502   \u2514\u2500\u2500 libgdbm.so.6 [ld.so.conf]\n\u251C\u2500\
    \u2500 libman-2.9.1.so (collapsed) [runpath]\n\u2514\u2500\u2500 libpipeline.so.1\
    \ (collapsed) [ld.so.conf]\n\nDeploying to <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>man.bundle/usr<span class=\"pl-pds\">\"</span></span>\n<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/bin/man<span class=\"pl-pds\"\
    >\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/bin/man<span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/man-db/libmandb-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libmandb-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/lib/man-db/libman-2.9.1.so<span class=\"pl-pds\">\"</span></span>\
    \ =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>man.bundle/usr/lib/libman-2.9.1.so<span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libpipeline.so.1.5.2<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1.5.2<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2<span class=\"pl-pds\"\
    >\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6<span class=\"pl-pds\"\
    >\"</span></span>\n\n$ tree man.bundle/\nman.bundle/\n\u2514\u2500\u2500 usr\n\
    \    \u251C\u2500\u2500 bin\n    \u2502\_\_ \u2514\u2500\u2500 man\n    \u2514\
    \u2500\u2500 lib\n        \u251C\u2500\u2500 libgdbm.so.6 -<span class=\"pl-k\"\
    >&gt;</span> libgdbm.so.6.0.0\n        \u251C\u2500\u2500 libgdbm.so.6.0.0\n \
    \       \u251C\u2500\u2500 libman-2.9.1.so\n        \u251C\u2500\u2500 libmandb-2.9.1.so\n\
    \        \u251C\u2500\u2500 libpipeline.so.1 -<span class=\"pl-k\">&gt;</span>\
    \ libpipeline.so.1.5.2\n        \u251C\u2500\u2500 libpipeline.so.1.5.2\n    \
    \    \u251C\u2500\u2500 libseccomp.so.2 -<span class=\"pl-k\">&gt;</span> libseccomp.so.2.5.1\n\
    \        \u2514\u2500\u2500 libseccomp.so.2.5.1\n\n3 directories, 9 files</pre></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Verbose output</h2><a\
    \ id=\"user-content-verbose-output\" class=\"anchor\" aria-label=\"Permalink:\
    \ Verbose output\" href=\"#verbose-output\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>By default certain standard depenendencies\
    \ are not shown. For more verbose output use</p>\n<ul>\n<li>\n<code>libtree -v\
    \ $(which man)</code> to show skipped libraries without their children</li>\n\
    <li>\n<code>libtree -a $(which apt-get)</code> to show the full recursive list\
    \ of libraries</li>\n</ul>\n<p>Use the <code>--path</code> or <code>-p</code>\
    \ flags to show paths rather than sonames:</p>\n<ul>\n<li><code>libtree -p $(which\
    \ tar)</code></li>\n</ul>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Changing search paths</h2><a id=\"user-content-changing-search-paths\" class=\"\
    anchor\" aria-label=\"Permalink: Changing search paths\" href=\"#changing-search-paths\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p><code>libtree</code> follows the rules of <code>ld.so</code> to locate libraries,\
    \ but does not use <code>ldconfig</code>'s\ncache. Instead it parses <code>/etc/ld.so.conf</code>\
    \ at runtime. In fact you can change the search\npath config by setting <code>--ldconf\
    \ mylibs.conf</code>. Search paths can be added as well via\n<code>LD_LIBRARY_PATH=\"\
    path1:path2:$LD_LIBRARY_PATH\" libtree ...</code>.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Building</h2><a id=\"user-content-building\" class=\"\
    anchor\" aria-label=\"Permalink: Building\" href=\"#building\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<ul>\n<li>\n<strong>From\
    \ source</strong>:\n<div class=\"highlight highlight-source-shell\"><pre>git clone\
    \ https://github.com/haampie/libtree.git\n<span class=\"pl-c1\">cd</span> libtree\n\
    mkdir build\n<span class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_PREFIX_PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/cxxopts;/path/to/elfio;/path/to/termcolor<span\
    \ class=\"pl-pds\">\"</span></span> ..\nmake -j\nmake install</pre></div>\n</li>\n\
    <li>\n<strong>Using <a href=\"https://github.com/spack/spack\">spack</a></strong>:\n\
    <pre><code>spack install libtree +chrpath +strip\nspack load libtree\n</code></pre>\n\
    </li>\n</ul>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\">Known\
    \ issues</h2><a id=\"user-content-known-issues\" class=\"anchor\" aria-label=\"\
    Permalink: Known issues\" href=\"#known-issues\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<ul>\n<li>When deploying libs with <code>libtree\
    \ app -d folder.bundle --chrpath</code>, the runpaths are only\nchanged when the\
    \ binaries already have an an rpath or runpath. This is a limitation of\n<code>chrpath</code>.\
    \ Another option is to use <code>patchelf</code> instead, but this tool is known\
    \ to break\nbinaries sometimes.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664232270.0
salotz/snailpacks:
  data_format: 2
  description: Spack repo for multimedia development
  filenames:
  - examples/c-embed-python/spack.yaml
  - examples/c-embed-chibi/spack.yaml
  full_name: salotz/snailpacks
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics:
  - spack
  - spack-repo
  - scopes-lang
  - multimedia
  - game-development
  - package-manager
  - development-environment
  updated_at: 1648089720.0
simonpintarelli/acclapack-tests:
  data_format: 2
  description: null
  filenames:
  - spack-envs/rocm/spack.yaml
  full_name: simonpintarelli/acclapack-tests
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667393188.0
simonpintarelli/nlcglib:
  data_format: 2
  description: Nonlinear CG methods for wave-function optimization in DFT
  filenames:
  - spack-envs/q-e-sirius-cpu-only/spack.yaml
  - spack-envs/q-e-sirius-lumi/spack.yaml
  full_name: simonpintarelli/nlcglib
  latest_release: v0.9.1
  stargazers_count: 6
  subscribers_count: 2
  topics: []
  updated_at: 1705083092.0
spack/gitlab-runners:
  data_format: 2
  description: Images used to run Gitlab pipelines in the cloud
  filenames:
  - spack.yaml
  full_name: spack/gitlab-runners
  latest_release: v2024-05-07
  readme: '<p>This repository contains images that are used to run Gitlab pipelines
    to validate PRs in Spack.</p>

    <p>The recipes have been modified from ones in: <a href="https://github.com/UO-OACISS/e4s">https://github.com/UO-OACISS/e4s</a></p>

    '
  stargazers_count: 3
  subscribers_count: 11
  topics: []
  updated_at: 1714405167.0
spack/localized-docs:
  data_format: 2
  description: Localized documentation for Spack
  filenames:
  - spack.yaml
  full_name: spack/localized-docs
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">Localized\
    \ Documentation for Spack</h1><a id=\"user-content-localized-documentation-for-spack\"\
    \ class=\"anchor\" aria-label=\"Permalink: Localized Documentation for Spack\"\
    \ href=\"#localized-documentation-for-spack\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>This repository contains translations\
    \ of <a href=\"/spack/spack\">Spack</a>'s\ndocumentation.  It implements the workflow\
    \ described in the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">Sphinx docs</a>.</p>\n<p>The instructions here describe how\
    \ you can contribute by:</p>\n<ol>\n<li>Adding to an existing translation, and</li>\n\
    <li>Creating a translation in a new language.</li>\n</ol>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Prerequisites</h2><a id=\"user-content-prerequisites\"\
    \ class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ol>\n<li>\n<p>First, init the <code>spack</code> submodule:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">git clone\
    \ https://github.com/spack/localized-docs</span>\n$ <span class=\"pl-s1\"><span\
    \ class=\"pl-c1\">cd</span> localized-docs</span>\n$ <span class=\"pl-s1\">git\
    \ submodule init</span>\n$ <span class=\"pl-s1\">git submodule update</span></pre></div>\n\
    </li>\n<li>\n<p>To use this repository you'll need Sphinx, some plugins for it,\
    \ and\n<code>gettext</code>.  To install these dependencies, using <code>pip</code>\
    \ and <code>brew</code>, you\ncan run:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">pip3 install -r requirements.txt</span>\n$ <span\
    \ class=\"pl-s1\">brew install gettext</span></pre></div>\n<p>Using Spack, you\
    \ can just take advantage of the <code>spack.yaml</code> file at\nthe root of\
    \ this repo:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span\
    \ class=\"pl-c1\">spack install</span>\n<span class=\"pl-c1\">spack env activate\
    \ .</span></pre></div>\n<p>This will install the tools you need and put them in\
    \ your <code>PATH</code>.</p>\n</li>\n</ol>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Adding to an existing translation</h2><a id=\"user-content-adding-to-an-existing-translation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Adding to an existing translation\"\
    \ href=\"#adding-to-an-existing-translation\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Translations in this repository are\
    \ stored in <code>.po</code> files under\n<code>translations</code>.  There is\
    \ one translation per languages, and each file is\nnamed according to its\n<a\
    \ href=\"https://www.gnu.org/software/gettext/manual/html_node/Language-Codes.html#Language-Codes\"\
    \ rel=\"nofollow\">ISO-639 language code</a>.\nSo, the Japanese translation data\
    \ for Spack is stored in\n<code>translations/ja.po</code>.</p>\n<p>If you want\
    \ to add to an existing translation, all you need to do is edit\nthe appropriate\
    \ <code>.po</code> file and add translated strings to it.  <code>.po</code> files\n\
    are comprised of <code>msgid</code>/<code>msgstr</code> pairs.  The <code>msgid</code>\
    \ corresponds to an\nEnglish string in the original documentation, and the <code>msgstr</code>\
    \ is its\ntranslation in the target language.  For example, for Japanese, the\n\
    translation of \"Basic Usage\" is stored like this:</p>\n<pre><code>#: ../spack/lib/spack/docs/basic_usage.rst:10\n\
    msgid \"Basic Usage\"\nmsgstr \"\u57FA\u672C\u7684\u306A\u4F7F\u3044\u65B9\"\n\
    </code></pre>\n<p>To add a translation:</p>\n<ol>\n<li>Update <code>msgstr</code>\
    \ elements in the appropriate <code>.po</code> files;</li>\n<li>Run <code>make</code>;</li>\n\
    <li>Commit the results;</li>\n<li>Submit a pull request so that we can merge your\
    \ changes.</li>\n</ol>\n<p>That's all!  Merged pull requests will automatically\
    \ trigger a rebuild of\nthe translated docs, and you should see your changes at\n\
    <a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\">spack.readthedocs.io</a>.</p>\n\
    <p>If you want to look at the documentation while you're editing it, running\n\
    <code>make</code> also generates per-language builds of the docs in <code>html/&lt;lang&gt;</code>.\n\
    So, to see the Japanese documentation, you can run <code>make</code> and open\n\
    <code>html/ja/index.html</code> in a local web browser.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Creating a new translation</h2><a id=\"user-content-creating-a-new-translation\"\
    \ class=\"anchor\" aria-label=\"Permalink: Creating a new translation\" href=\"\
    #creating-a-new-translation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>To create a new translation, add the language to the <code>languages</code>\
    \ list in\nthe <code>Makefile</code>.  For example, if the only language is Japanese\
    \ (<code>ja</code>) and\nyou want to add German (<code>de</code>), just add <code>de</code>:</p>\n\
    <div class=\"highlight highlight-source-makefile\"><pre><span class=\"pl-smi\"\
    >languages</span> = ja de</pre></div>\n<p>Running <code>make</code>, will create\
    \ files in <code>docs</code>, <code>locale</code>, and\n<code>translations</code>,\
    \ and <code>html</code>:</p>\n<pre><code>    translations/de.po          # German\
    \ translation file\n    translations/de.mo          # generated from de.po\n \
    \   locale/de/LC_MESSAGES/*.mo  # symlinks to translations/de.mo\n    docs/de/\
    \                    # a Sphinx build directory for German docs\n    html/de/\
    \                    # HTML built by Sphinx from docs/de\n</code></pre>\n<p>Add\
    \ everything <em>except</em> <code>html</code>, then commit. <code>html</code>\
    \ is ignored by default\n(see <code>.gitignore</code>), so you can just run this:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >git add <span class=\"pl-c1\">.</span></span>\n$ <span class=\"pl-s1\">git commit</span></pre></div>\n\
    <p>See instructions above for how to start translating.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Workflow</h2><a id=\"user-content-workflow\" class=\"\
    anchor\" aria-label=\"Permalink: Workflow\" href=\"#workflow\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>This repository implements\
    \ the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">workflow described here</a>.\nMost users will only need to\
    \ concern themselves with <code>translations/*.po</code>\nfiles, but we provide\
    \ a short summary here so that you can understand how\neverything works.</p>\n\
    <p>Translation is done as follows:</p>\n<ol>\n<li>\n<p>First, we use (or rather\
    \ Sphinx uses) the <code>gettext</code> tool to extract\nstrings to be translated\
    \ from each <code>.rst</code> document in the Spack\ndocumentation. This results\
    \ in a set of <code>.pot</code> files in\n<code>templates/*.pot</code>.  These\
    \ contain keys (<code>msgid</code>s) for unique strings,\nas well as their location\
    \ (file and line number) in the documentation.</p>\n</li>\n<li>\n<p>We merge the\
    \ <code>.pot</code> files into a single <code>merged.pot</code> file to eliminate\n\
    duplicate strings in multiple files.</p>\n</li>\n<li>\n<p><code>merged.pot</code>\
    \ is used to create an initial <code>translations/&lt;lang&gt;.po</code>\nfile.\
    \  Translations are added to <code>msgstr</code> fields in the <code>.po</code>\
    \ file.</p>\n</li>\n<li>\n<p>A single <code>translations/&lt;lang&gt;.mo</code>\
    \ file is generated from the <code>.po</code>\nfile. The <code>.mo</code> file\
    \ is in a special binary format.</p>\n</li>\n<li>\n<p>We generate symlinks in\
    \ <code>locale/&lt;lang&gt;/LC_MESSAGES/*.mo</code> that all\npoint back to the\
    \ single, unified <code>translations/&lt;lang&gt;.mo</code> file.  The\n<code>locale</code>\
    \ directory can then be used with Sphinx to build translated\ndocumentation.</p>\n\
    </li>\n</ol>\n<p>The top-level <code>Makefile</code> implements this workflow,\
    \ so you don't have to\nthink too much about it.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">License</h2><a id=\"user-content-license\" class=\"\
    anchor\" aria-label=\"Permalink: License\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>This repository is\
    \ part of Spack, which distributed under the terms of\nboth the MIT license and\
    \ the Apache License (Version 2.0). Users may\nchoose either license, at their\
    \ option.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0\n\
    licenses.</p>\n<p>See <a href=\"https://github.com/spack/localized-docs/blob/master/LICENSE-MIT\"\
    >LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/localized-docs//blob/master/LICENSE-APACHE\"\
    >LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/localized-docs/blob/master/COPYRIGHT\"\
    >COPYRIGHT</a>,\nand <a href=\"https://github.com/spack/localized-docs/blob/master/NOTICE\"\
    >NOTICE</a>\nfor details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-647188</p>\n"
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1621989548.0
spack/spack-ci-containers:
  data_format: 2
  description: Container recipes used by Spack for test purposes
  filenames:
  - clingo/spack.yaml
  full_name: spack/spack-ci-containers
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Spack CI containers</h1><a
    id="user-content-spack-ci-containers" class="anchor" aria-label="Permalink: Spack
    CI containers" href="#spack-ci-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>This repository contains recipes for containers that are

    used to test Spack under CI.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-ci-containers/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1621989328.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-23.05/nvhpc/spack.yaml
  - NREL/configs/rhodes/utilities/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/cce/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cce/spack.yaml
  - OLCF/frontier/spack.yaml
  - NERSC/perlmutter/spack-v0.22/cuda/spack.yaml
  - NREL/configs/eagle/compilers/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cuda/spack.yaml
  - NERSC/perlmutter/e4s-22.11/gcc/spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/Frank-Jupiter/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.08/spack.yaml
  - OLCF/summit/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - NERSC/perlmutter/e4s-22.11/cuda/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/nvhpc/spack.yaml
  - BOISESTATE/borah/environments/b4s/_spack.yaml
  - NERSC/perlmutter/e4s-23.08/gcc/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-23.08/nvhpc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/spack.yaml
  - NERSC/perlmutter/e4s-23.05/gcc/spack.yaml
  - NREL/configs/eagle/utilities/spack.yaml
  - NERSC/perlmutter/spack-v0.22/prod/gcc/spack.yaml
  - NERSC/cori/e4s-21.02/prod/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.05/spack.yaml
  - NREL/configs/eagle/software/spack.yaml
  - NREL/configs/rhodes/compilers/spack.yaml
  - NERSC/perlmutter/e4s-23.08/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-22.05/nvhpc/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Spack Configs</h1><a
    id="user-content-spack-configs" class="anchor" aria-label="Permalink: Spack Configs"
    href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 57
  subscribers_count: 31
  topics: []
  updated_at: 1716814998.0
spack/spack-tutorial:
  data_format: 2
  description: Standalone Spack Tutorial Repository
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial
  latest_release: sc23
  readme: '<div class="markdown-heading"><h1 class="heading-element">

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667"><img
    src="https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667"
    width="64" valign="middle" alt="Spack" data-canonical-src="https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg"
    style="max-width: 100%;"></a> Spack Tutorial</h1><a id="user-content--spack-tutorial"
    class="anchor" aria-label="Permalink:  Spack Tutorial" href="#-spack-tutorial"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p><a href="https://spack-tutorial.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/cc15a98bdbe77c2664a8d15480c99dd7372c06ce4afabe1571236cb260e94717/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2d7475746f7269616c2f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/spack-tutorial/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is a multi-platform package manager that builds and installs multiple
    versions and configurations of software. It works on Linux, macOS, and many supercomputers.
    Spack is non-destructive: installing a new version of a package does not break
    existing installations, so many configurations of the same package can coexist.</p>

    <p>This repository houses Spack''s <a href="https://spack-tutorial.readthedocs.io/en/latest/"
    rel="nofollow"><strong>hands-on tutorial</strong></a>, which is a subset of Spack''s
    <a href="https://spack.readthedocs.io/" rel="nofollow"><strong>full documentation</strong></a>
    (or you can run <code>spack help</code> or <code>spack help --all</code>).</p>

    <p>This tutorial covers basic to advanced usage, packaging, developer features,
    and large HPC deployments.  You can do all of the exercises on your own laptop
    using a Docker container. Feel free to use these materials to teach users at your
    organization about Spack.</p>

    <div class="markdown-heading"><h2 class="heading-element">Updating the tutorial</h2><a
    id="user-content-updating-the-tutorial" class="anchor" aria-label="Permalink:
    Updating the tutorial" href="#updating-the-tutorial"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <ol>

    <li>Create a new branch named for the event/milestone that corresponds to the
    new version you want to create.</li>

    <li>Upload screen shot of first slide (244px wide, .png) to <a href="https://github.com/spack/spack-tutorial/tree/master/tutorial/images">images
    directory</a> following existing file-naming convention.</li>

    <li>Upload PDF of slide deck to <a href="https://github.com/spack/spack-tutorial/tree/master/_static/slides">slides
    directory</a> following existing file-naming convention.</li>

    <li>Update <a href="https://github.com/spack/spack-tutorial/blob/master/index.rst">index.rst</a>
    with event name and date; full citation; and file paths for image and PDF.</li>

    <li>Update this README (lines 3 and 7) with link to new version''s URL.</li>

    <li>Build docs locally.</li>

    <li>Push changes to GitHub and active new tag/version on Read the Docs.</li>

    <li>Build new version on Read the Docs.</li>

    </ol>

    <div class="markdown-heading"><h2 class="heading-element">Updating the tutorial
    container</h2><a id="user-content-updating-the-tutorial-container" class="anchor"
    aria-label="Permalink: Updating the tutorial container" href="#updating-the-tutorial-container"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>The Spack tutorial container is automatically built from <a href="docker/Dockerfile">repository</a>
    by <a href=".github/workflows/containers.yaml">this GitHub action</a>. The latest
    version is available at</p>

    <pre><code>ghcr.io/spack/tutorial:latest

    </code></pre>

    <p>and is rebuilt on a schedule. It can also be <a href="https://github.com/spack/spack-tutorial/actions">triggered
    manually</a>.</p>

    <p>The tutorial image builds on top of the container image that runs in Spack
    CI, which is built in a different repository at <a href="https://github.com/spack/gitlab-runners/">spack/gitlab-runners</a></p>

    <div class="markdown-heading"><h2 class="heading-element">Automatically generating
    command ouputs</h2><a id="user-content-automatically-generating-command-ouputs"
    class="anchor" aria-label="Permalink: Automatically generating command ouputs"
    href="#automatically-generating-command-ouputs"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>The tutorial <code>rst</code> files include output from Spack commands. This
    process is automated, and it is

    recommended not to run commands manually.</p>

    <p><strong>Note:</strong> as a preliminary step, check your terminal width. All
    current outputs

    are generated on a fixed terminal width <strong>94</strong>; deviating from that
    can cause

    unnecessarily large diffs:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">tput
    cols</span>

    <span class="pl-c1">94</span></pre></div>

    <p>To regenerate the outputs, run:</p>

    <div class="highlight highlight-source-shell"><pre>make -C outputs -j <span class="pl-k">&lt;</span>N<span
    class="pl-k">&gt;</span></pre></div>

    <p>This runs each <code>outputs/&lt;section&gt;.sh</code> script in parallel in
    a container, and collects outputs in

    <code>outputs/raw/*</code>. When all complete succesfully, the outputs are post-processed
    and put in

    <code>outputs/</code>.</p>

    <p>In case you want to restrict to particular sections, or if you need to modify
    the container

    executable and flags, specify those as variables in <code>outputs/Make.user</code>:</p>

    <div class="highlight highlight-source-makefile"><pre><span class="pl-smi">sections</span>
    := basics scripting

    <span class="pl-smi">DOCKER</span> := sudo docker</pre></div>

    <ul>

    <li>

    <p><code>make</code> will regenerate the relevant outputs when <code>outputs/&lt;section&gt;.sh</code>
    files are modified.</p>

    </li>

    <li>

    <p>To start from scratch, run <code>make clean</code></p>

    </li>

    <li>

    <p><code>make run-&lt;tab&gt;</code> can also be used to regenerate a particular
    section, but notice it will only

    create raw outputs.</p>

    </li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Spack is distributed under the terms of both the MIT license and the Apache
    License (Version 2.0). Users may choose either license, at their option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack/blob/develop/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack/blob/develop/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack/blob/develop/NOTICE">NOTICE</a> for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 42
  subscribers_count: 36
  topics:
  - tutorial
  updated_at: 1717252194.0
spack/spack-tutorial-container:
  data_format: 2
  description: Dockerfile and artifacts (minus build cache) to create Spack tutorial
    container.
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial-container
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Spack Tutorial
    Container</h1><a id="user-content-spack-tutorial-container" class="anchor" aria-label="Permalink:
    Spack Tutorial Container" href="#spack-tutorial-container"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This repository contains a container image you can use to do the

    <a href="https://spack.readthedocs.io/en/latest/tutorial.html" rel="nofollow">Spack
    Tutorial</a>.

    It''s exactly like the AWS images we use when we give the tutorial at

    conferences.</p>

    <div class="markdown-heading"><h2 class="heading-element">License</h2><a id="user-content-license"
    class="anchor" aria-label="Permalink: License" href="#license"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 5
  subscribers_count: 9
  topics: []
  updated_at: 1716232519.0
sstsimulator/sst-spack:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: sstsimulator/sst-spack
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/27a2a2325cf0fa186b65c72ddc9d538f0bb36c7d521486221b8b7adbcf3e1180/687474703a2f2f7373742d73696d756c61746f722e6f72672f696d672f7373742d6c6f676f2d736d616c6c2e706e67\"\
    ><img src=\"https://camo.githubusercontent.com/27a2a2325cf0fa186b65c72ddc9d538f0bb36c7d521486221b8b7adbcf3e1180/687474703a2f2f7373742d73696d756c61746f722e6f72672f696d672f7373742d6c6f676f2d736d616c6c2e706e67\"\
    \ alt=\"SST\" data-canonical-src=\"http://sst-simulator.org/img/sst-logo-small.png\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h1 class=\"\
    heading-element\">Structural Simulation Toolkit (SST) Spack Packages</h1><a id=\"\
    user-content-structural-simulation-toolkit-sst-spack-packages\" class=\"anchor\"\
    \ aria-label=\"Permalink: Structural Simulation Toolkit (SST) Spack Packages\"\
    \ href=\"#structural-simulation-toolkit-sst-spack-packages\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<div class=\"markdown-heading\"\
    ><h4 class=\"heading-element\">Copyright (c) 2009-2023, National Technology and\
    \ Engineering Solutions of Sandia, LLC (NTESS)</h4><a id=\"user-content-copyright-c-2009-2023-national-technology-and-engineering-solutions-of-sandia-llc-ntess\"\
    \ class=\"anchor\" aria-label=\"Permalink: Copyright (c) 2009-2023, National Technology\
    \ and Engineering Solutions of Sandia, LLC (NTESS)\" href=\"#copyright-c-2009-2023-national-technology-and-engineering-solutions-of-sandia-llc-ntess\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Basic Usage</h2><a\
    \ id=\"user-content-basic-usage\" class=\"anchor\" aria-label=\"Permalink: Basic\
    \ Usage\" href=\"#basic-usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Make sure you have downloaded <a href=\"https://github.com/spack/spack\"\
    >Spack</a> and added it to your path.\nThe easiest way to do this is often (depending\
    \ on your SHELL):</p>\n<pre><code>&gt; source spack/share/spack/setup-env.sh\n\
    </code></pre>\n<p>To get the most up-to-date version of the SST Spack packages,\
    \ after downloading the sst-spack GitHub repository, you simply need to run</p>\n\
    <pre><code>&gt; spack repo add sst-spack/sst\n</code></pre>\n<p>To validate that\
    \ Spack now sees the repo with the SST packages, run:</p>\n<pre><code>&gt; spack\
    \ repo list\n</code></pre>\n<p>This should now list your newly downloaded Spack\
    \ repo.\nYou can display information about how to install the individual packages\
    \ with, e.g.:</p>\n<pre><code>&gt; spack info sst-core\n</code></pre>\n<p>This\
    \ will print all the information about variants and dependencies of the package.\n\
    For detailed instructions on how to use Spack, see the <a href=\"https://spack.readthedocs.io\"\
    \ rel=\"nofollow\">Owner's Manual</a>.</p>\n<p>A basic installation of a package\
    \ is done as:</p>\n<pre><code>&gt; spack install sst-core +pdes-mpi\n</code></pre>\n\
    <p>which tells Spack to install the core with PDES support using MPI.\nFor downstream\
    \ packages like sst-elements, sst-core and all dependencies will be automatically\
    \ installed.\nWe can visualize this with either <code>spack spec</code> or <code>spack\
    \ graph</code>, e.g.</p>\n<pre><code>&gt; spack spec sst-elements +pin +hybridsim\n\
    Input spec\n--------------------------------\nsst-elements+hybridsim+pin\n\nConcretized\n\
    --------------------------------\nsst-elements@master%gcc@7.4.0~dramsim2~goblin~hbm+hybridsim~nvdimmsim+pin~ramulator\
    \ arch=linux-centos7-haswell\n    ^autoconf@2.69%gcc@7.4.0 arch=linux-centos7-haswell\n\
    \    ^automake@1.16.1%gcc@7.4.0 arch=linux-centos7-haswell\n    ^dramsim2@2.2%gcc@7.4.0\
    \ arch=linux-centos7-haswell\n    ^hybridsim@2.0%gcc@7.4.0 patches=e266e00e3777feb1d9b3691f6a5a88d1d99c5aa0e0811fcf5461d55e0ac4a7bd\
    \ arch=linux-centos7-haswell\n        ^nvdimmsim@2.0%gcc@7.4.0 arch=linux-centos7-haswell\n\
    \    ^intel-pin@2.14%gcc@7.4.0 arch=linux-centos7-haswell\n    ^libtool@2.4.6%gcc@7.4.0\
    \ arch=linux-centos7-haswell\n    ^python@2.7%gcc@7.4.0+bz2+ctypes+dbm~debug+libxml2+lzma~nis~optimizations+pic+pyexpat+pythoncmd+readline+shared+sqlite3+ssl~tix~tkinter~ucs4~uuid+zlib\
    \ arch=linux-centos7-haswell\n    ^sst-core@master%gcc@7.4.0~hdf5+pdes-mpi~zlib~zoltan\
    \ arch=linux-centos7-haswell\n        ^openmpi@3.1.5%gcc@7.4.0~cuda+cxx_exceptions\
    \ fabrics=none ~java~legacylaunchers~memchecker~pmi schedulers=none ~sqlite3~thread_multiple+vt\
    \ arch=linux-centos7-haswell\n</code></pre>\n<p>This shows what will be installed\
    \ along with the specification of all the dependencies.\nIf any of the dependencies\
    \ are missing, Spack will download and install them.\nNote here that the default\
    \ compiler for this Spack is GCC 7.4.\nIf we wish to use a different compiler,\
    \ we can specify it as, e.g:</p>\n<pre><code>&gt; spack install sst-elements +pin\
    \ +hybridsim %clang@9.1.0\n</code></pre>\n<p>To make sure your desired compiler\
    \ is known to Spack, you can check:</p>\n<pre><code>&gt; spack compiler list\n\
    ==&gt; Available compilers\n-- clang centos7-x86_64 -----------------------------------------\n\
    clang@7.0.0\n\n-- gcc centos7-x86_64 -------------------------------------------\n\
    gcc@7.4.0  gcc@4.8.5\n</code></pre>\n<p>All compilers in the path are usually\
    \ located by running <code>spack compiler find</code> and automatically added.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Testing and Developing\
    \ with Spack</h2><a id=\"user-content-testing-and-developing-with-spack\" class=\"\
    anchor\" aria-label=\"Permalink: Testing and Developing with Spack\" href=\"#testing-and-developing-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Spack has historically been much more suited to <em>deployment</em> of mature\
    \ packages than active testing or developing.\nHowever, recent features have improved\
    \ support for development.\nFuture releases are likely to make this even easier\
    \ and incorporate Git integration.</p>\n<div class=\"markdown-heading\"><h3 class=\"\
    heading-element\">Testing</h3><a id=\"user-content-testing\" class=\"anchor\"\
    \ aria-label=\"Permalink: Testing\" href=\"#testing\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>A common pattern in testing\
    \ is validating a successful build of feature branches.\nSpack provides the <code>dev-build</code>\
    \ feature for building and installing from a custom source folder.\nFor example:</p>\n\
    <pre><code>&gt; git clone git@github.com:sstsimulator/sst-core.git -b devel src\n\
    &gt; spack dev-build -d src sst-core@devel +pdes-mpi\n</code></pre>\n<p>is equivalent\
    \ to just running</p>\n<pre><code>&gt; spack install sst-core@devel +pdes-mpi\n\
    </code></pre>\n<p>For validating a complete build of the \"core\" packages (sst-core,\
    \ sst-elements, sst-macro) with any combination of branches, one can simply run:</p>\n\
    <pre><code>&gt; git clone git@github.com:sstsimulator/sst-core.git -b feature-core\
    \ sst-core-src\n&gt; git clone git@github.com:sstsimulator/sst-macro.git -b devel\
    \ sst-macro-src\n&gt; git clone git@github.com:sstsimulator/sst-elements.git -b\
    \ feature-elems sst-elements-src\n&gt; spack dev-build -d sst-core-src sst-core@devel\
    \ core-variants... %compiler\n&gt; spack dev-build -d sst-macro-src sst-macro@devel\
    \ macro-variants... ^sst-core@devel core-variants... %compiler\n&gt; spack dev-build\
    \ -d sst-elements-src sst-elements@devel elem-variants... ^sst-core@devel core-variants...\
    \ %compiler\n</code></pre>\n<p>Here <code>%compiler</code> is a spec like <code>gcc@7.4.0</code>.\n\
    <code>core-variants...</code> is the desired sst-core spec like <code>+pdes-mpi\
    \ +zoltan</code>.\nNote the the <code>^</code> syntax used here to ensure that\
    \ sst-elements and sst-macro depend on a precise variant of sst-core.\nFor example:</p>\n\
    <pre><code>&gt; spack dev-build -d sst-macro-src sst-macro@devel +otf2 +core ^sst-core+pdes-mpi+zoltan\n\
    </code></pre>\n<p>Because we are doing feature branch testing, we use <code>@devel</code>\
    \ to build the branches as-if they were the <code>devel</code> branch.</p>\n<div\
    \ class=\"markdown-heading\"><h3 class=\"heading-element\">Developing</h3><a id=\"\
    user-content-developing\" class=\"anchor\" aria-label=\"Permalink: Developing\"\
    \ href=\"#developing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>The above commands will do a full build and install of\
    \ the packages.\nIf doing development, you may wish to merely set up a build environment.\n\
    This allows you to modify the source and re-build.\nIn this case, you can stop\
    \ after configuring:</p>\n<pre><code>&gt; spack dev-build -d sst-core-src -u configure\
    \ sst-core@devel +otf2 +core ^sst-core+pdes-mpi+zoltan\n</code></pre>\n<p>This\
    \ sets up a development environment for you in <code>sst-core-src</code>, which\
    \ you can use (Bash example shown):</p>\n<pre><code>&gt; cd sst-core-src\n&gt;\
    \ source spack-build-env.txt\n&gt; cd spack-build\n&gt; make\n</code></pre>\n\
    <p>Before sourcing the Spack development environment, you may wish to save your\
    \ current environment:</p>\n<pre><code>&gt; declare -px &gt; myenv.sh\n</code></pre>\n\
    <p>When done with Spack, you can then restore your original environment:</p>\n\
    <pre><code>source myenv.sh\n</code></pre>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Configuring Default Spack Packages</h2><a id=\"user-content-configuring-default-spack-packages\"\
    \ class=\"anchor\" aria-label=\"Permalink: Configuring Default Spack Packages\"\
    \ href=\"#configuring-default-spack-packages\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Spack assumes nothing is available\
    \ on your system, including even basic utilities like Perl and M4.\nThis leads\
    \ to Spack \"bootstrapping\" for each new install (and each compiler!) many, many\
    \ packages.\nIt is recommended to set up a <code>packages.yaml</code> file in\
    \ a <code>$HOME/.spack</code> folder that identifies your default local packages.\n\
    Below is an example file with the most important packages for efficient SST development:</p>\n\
    <pre><code>packages:\n zlib:\n  paths:\n    zlib: /usr\n  buildable: False\n libtool:\n\
    \  paths:\n   libtool@2.4.6: /opt/local\n  buildable: False\n cmake:\n  paths:\n\
    \   cmake@3.15: /opt/local\n  buildable: False\n pkg-config:\n  paths:\n   pkg-config:\
    \ /opt/local\n m4:\n  paths:\n    m4: /usr\n  buildable: False\n numactl:\n  paths:\n\
    \   numactl@2.0.12: /opt/local\n   buildable: False\n hwloc:\n  paths:\n   hwloc@2.0.2:\
    \ /usr\n   hwloc@1.11: /opt/local\n   buildable: False\n python:\n  paths:\n \
    \  python@2.7: /usr\n   python@3.6: /opt/local\n  variants: +shared\n  buildable:\
    \ False\n</code></pre>\n<p>The paths would need to be updated for your system.\n\
    If you <em>never</em> want Spack to re-build a library (which is often the case\
    \ for C libraries like hwloc),\nyou need the <code>buildable: False</code> entry.\n\
    In most cases a single version suffices, but you may need multiple versions to\
    \ resolve conflicts (as was the caes here for Python and hwloc).\nIn other cases,\
    \ you may need to identify the Spack variants supported by your local installation.\n\
    In this case, we had to inform Spack that our Python has shared libraries.\nWith\
    \ the <code>packages.yaml</code>, our Spack dependency graph for <code>spack graph\
    \ sst-core +pdes-mpi</code> is:</p>\n<pre><code>o  sst-core\n|\\\n| o  openmpi\n\
    | |\\\n| | |\\\n| o | |  zlib\n|  / /\no | |  python\n / /\n o |  numactl\n  /\n\
    \  o  hwloc\n</code></pre>\n<p>In this case, the only dependency Spack will build\
    \ is <code>openmpi</code> (recommended due to the compiler dependence).\nWithout\
    \ the <code>packages.yaml</code>, a huge dependency graph would be built:</p>\n\
    <pre><code>o  sst-core\n|\\\no |  python\n|\\ \\\n| |\\ \\\n| | |\\ \\\n| | |\
    \ |\\ \\\n| | | | |\\ \\\n| | | | | |\\ \\\n| | | | | | |\\ \\\n| | | | | | |\
    \ |\\ \\\n| | | | | | | | |\\ \\\n| | | | | | | | | |\\ \\\n| | | | | | | | |\
    \ | |\\ \\\n| | o | | | | | | | | | |  sqlite\n| |/| | | | | | | | | | |\n|/|\
    \ | | | | | | | | | | |\n| | |/ / / / / / / / / /\n| | | | o | | | | | | |  openssl\n\
    | |_|_|/| | | | | | | |\n|/| | | | | | | | | | |\n| | | | | | | | | | | o  openmpi\n\
    | |_|_|_|_|_|_|_|_|_|/|\n|/| | | | | | | | | | |\n| | | | | | | | | | | |\\\n\
    | | | | | | | | | | | | o  hwloc\n| | | | |_|_|_|_|_|_|_|/|\n| | | |/| | | | |\
    \ | | |/|\n| | | | | | | | | | | | |\\\n| | | | | | | o | | | | | |  gettext\n\
    | | |_|_|_|_|/| | | | | | |\n| |/| | | | |/| | | | | | |\n| | | | | |/| | | |\
    \ | | | |\n| | | | | | | |\\ \\ \\ \\ \\ \\ \\\n| | | | | | | | |\\ \\ \\ \\ \\\
    \ \\ \\\n| | | | | | | | | |_|_|_|_|/ /\n| | | | | | | | |/| | | | | |\n| | |\
    \ | | | | | | | |/ / / /\n| | | | | | | | | |/| | | |\n| | | | | | | | o | | |\
    \ | |  libxml2\n| |_|_|_|_|_|_|/| | | | | |\n|/| |_|_|_|_|_|/| | | | | |\n| |/|\
    \ | |_|_|_|/| | | | | |\n| | | |/| | | | | | | | | |\no | | | | | | | | | | |\
    \ | |  zlib\n / / / / / / / / / / / / /\n o | | | | | | | | | | | |  xz\n  / /\
    \ / / / / / / / / / /\n  | | | | | | | | | | | o  libpciaccess\n  | | |_|_|_|_|_|_|_|_|/|\n\
    \  | |/| | | | | | | | | |\n  | | | | | | | | | | | |\\\n  | | | | | | | | | |\
    \ | o |  util-macros\n  | | | | | | | | | | |  /\n  | | | | | o | | | | | |  tar\n\
    \  | | | | | |/ / / / / /\n  | | | | | | | | | o |  numactl\n  | | | | | | | |\
    \ | |\\|\n  | | | | | | | | | |\\ \\\n  | | | | | | | | | | |\\ \\\n  | | | |\
    \ | | | | | | o | |  automake\n  | | | |_|_|_|_|_|_|/| | |\n  | | |/| | | | |\
    \ | | | | |\n  | | | | | | | | | | |/ /\n  | | | | | | | | | | o |  autoconf\n\
    \  | | | |_|_|_|_|_|_|/| |\n  | | |/| | | | | | |/ /\n  | | o | | | | | | | |\
    \  perl\n  | | | |_|_|_|/ / / /\n  | | |/| | | | | | |\n  | | o | | | | | | |\
    \  gdbm\n  | |/ / / / / / / /\n  |/| | | | | | | |\n  o | | | | | | | |  readline\n\
    \  | |/ / / / / / /\n  |/| | | | | | |\n  o | | | | | | |  ncurses\n  |/ / / /\
    \ / / /\n  o | | | | | |  pkgconf\n   / / / / / /\n   | | | | | o  libtool\n \
    \  | | | | |/\n   | | | | o  m4\n   | | | | o  libsigsegv\n   | | | |\n   | |\
    \ o |  bzip2\n   | | o |  diffutils\n   | |/ /\n   | o |  libiconv\n   |  /\n\
    \   o |  libffi\n    /\n    o  expat\n    o  libbsd\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 14
  topics: []
  updated_at: 1701377450.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2024.05.11
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/2bb6ac78e5a9f4f688a6a066cc71b62012101802fcdb478e6e4c6b6ec75dc694/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/df0b1027d8e161884d7089c2577d4b43a35b394555a9517f5de6ae0e20bf7162/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d32302d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-20-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/de7c10d66458fb994d000e59113fb157d0c41aa4d814ea70d4372651c3b8681f/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f67726170682f62616467652e7376673f746f6b656e3d79794a33754250554532\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/graph/badge.svg?token=yyJ3uBPUE2\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2024.05.11\"\
    ><img src=\"https://camo.githubusercontent.com/011fe82b49dde7d8b13baa9d4be0b9a29fcaf307db8f5847c0593911b7f3e2e9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032342e30352e31312d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2024.05.11-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.11180072\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5c8c5c86bb812f5564868fe3524f977def0000fdfc8a80f2914be5764754176b/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e31313138303037322e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.11180072.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">What is SpECTRE?</h2><a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" aria-label=\"Permalink: What is SpECTRE?\" href=\"#what-is-spectre\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>SpECTRE is an open-source code for multi-scale, multi-physics problems\nin\
    \ astrophysics and gravitational physics. In the future, we hope that\nit can\
    \ be applied to problems across discipline boundaries in fluid\ndynamics, geoscience,\
    \ plasma physics, nuclear physics, and\nengineering. It runs at petascale and\
    \ is designed for future exascale\ncomputers.</p>\n<p>SpECTRE is being developed\
    \ in support of our collaborative Simulating\neXtreme Spacetimes (SXS) research\
    \ program into the multi-messenger\nastrophysics of neutron star mergers, core-collapse\
    \ supernovae, and\ngamma-ray bursts.</p>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Citing SpECTRE</h2><a id=\"user-content-citing-spectre\"\
    \ class=\"anchor\" aria-label=\"Permalink: Citing SpECTRE\" href=\"#citing-spectre\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Please cite SpECTRE in any publications that make use of its code or data.\
    \ Cite\nthe latest version that you use in your publication. The DOI for this\
    \ version\nis:</p>\n<ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.11180072\"\
    \ rel=\"nofollow\">10.5281/zenodo.11180072</a>\n</li>\n</ul>\n<p>You can cite\
    \ this BibTeX entry in your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"\
    ><pre><span class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and Nelli, Kyle C. and Armaza, Crist\\\
    'obal and Bonilla, Marceline S. and</span>\n<span class=\"pl-s\">H\\'ebert, Fran\\\
    c{c}ois and Kim, Yoonsoo and Kumar, Prayush and Lovelace,</span>\n<span class=\"\
    pl-s\">Geoffrey and Macedo, Alexandra and Moxon, Jordan and O'Shea, Eamonn and</span>\n\
    <span class=\"pl-s\">Pfeiffer, Harald P. and Scheel, Mark A. and Teukolsky, Saul\
    \ A. and Wittek,</span>\n<span class=\"pl-s\">Nikolas A. and others<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> = <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2024.05.11}<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span> = <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>2024.05.11<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">publisher</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Zenodo<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"\
    pl-s\">doi</span> = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>10.5281/zenodo.11180072<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>https://spectre-code.org<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">howpublished</span>\
    \ =\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.11180072}{10.5281/zenodo.11180072}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2024<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>5<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Viewing Documentation</h2><a\
    \ id=\"user-content-viewing-documentation\" class=\"anchor\" aria-label=\"Permalink:\
    \ Viewing Documentation\" href=\"#viewing-documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>The documentation\
    \ can be viewed at <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 148
  subscribers_count: 16
  topics: []
  updated_at: 1717249333.0
tachidok/scicellxx:
  data_format: 2
  description: SciCell++ is an object-oriented framework for the simulation of biological
    and physical phenomena modelled as continuous or discrete processes.
  filenames:
  - tools/development/docker_and_spack/01_build_docker_DEVEL_spack_INSTALLED/spack.yaml
  full_name: tachidok/scicellxx
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">SciCell++</h1><a\
    \ id=\"user-content-scicell\" class=\"anchor\" aria-label=\"Permalink: SciCell++\"\
    \ href=\"#scicell\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"\
    https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\"\
    ><img src=\"https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\"\
    \ alt=\"GitHub-master-push\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/tachidok/scicellxx\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/15085e6cd19024ba183f6fe807fc8dd08a9b7dad0fded85ae6d210c6112afbb7/68747470733a2f2f636f6465636f762e696f2f67682f7461636869646f6b2f73636963656c6c78782f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d4a41414f465353314951\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/tachidok/scicellxx/branch/master/graph/badge.svg?token=JAAOFSS1IQ\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://scicellxx.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/22f75450936ad85ef0788b62dad1bd261567b5b95cca261cf8891c80d969f353/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73636963656c6c78782f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/scicellxx/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a></p>\n<hr>\n<p>SciCell++ is an object-oriented\
    \ framework for the simulation of biological and physical phenomena modelled as\
    \ continuous or discrete processes.</p>\n<div class=\"markdown-heading\"><h2 class=\"\
    heading-element\">Table of Contents</h2><a id=\"user-content-table-of-contents\"\
    \ class=\"anchor\" aria-label=\"Permalink: Table of Contents\" href=\"#table-of-contents\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ol>\n<li><a href=\"#documentation\">Documentation</a></li>\n<li><a href=\"#featured_demos\"\
    >Featured demos</a></li>\n<li><a href=\"#how_to_contribute\">How to contribute</a></li>\n\
    <li><a href=\"#facts_and_curiosities\">Facts and curiosities</a></li>\n<li><a\
    \ href=\"#license\">License</a></li>\n</ol>\n<div class=\"markdown-heading\"><h2\
    \ class=\"heading-element\">Documentation <a name=\"user-content-documentation\"\
    ></a>\n</h2><a id=\"user-content-documentation-\" class=\"anchor\" aria-label=\"\
    Permalink: Documentation \" href=\"#documentation-\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>The full documentation\
    \ is\n<a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"\
    nofollow\">here</a>. You\nwill find installation instructions, demos, tutorials\
    \ and workflows to\nease your journey with SciCell++.</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Featured demos <a name=\"user-content-featured_demos\"\
    ></a>\n</h2><a id=\"user-content-featured-demos-\" class=\"anchor\" aria-label=\"\
    Permalink: Featured demos \" href=\"#featured-demos-\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<ul>\n<li>Interpolation</li>\n\
    <li>Linear solvers</li>\n<li>Matrices operations</li>\n<li>Newton's method</li>\n\
    <li>Solution of ODE's\n<ul>\n<li>Lotka-Volterra solved with different time steppers</li>\n\
    <li>N-body problem (only 3-body and 4-body)</li>\n<li>Explicit time steppers</li>\n\
    <li>Implicit time steppers (full implicit and <em>E(PC)^k E</em>\nimplementations)</li>\n\
    <li>Adaptive time steppers</li>\n</ul>\n</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">How to contribute <a name=\"user-content-how_to_contribute\"\
    ></a>\n</h2><a id=\"user-content-how-to-contribute-\" class=\"anchor\" aria-label=\"\
    Permalink: How to contribute \" href=\"#how-to-contribute-\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<p>Please check the\n\
    <a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\
    >constributions</a>\nsection in the documentation.</p>\n<div class=\"markdown-heading\"\
    ><h5 class=\"heading-element\">Optional</h5><a id=\"user-content-optional\" class=\"\
    anchor\" aria-label=\"Permalink: Optional\" href=\"#optional\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></div>\n<ul>\n<li>MPI support\
    \ for parallel features - <code>not currently supported</code>.</li>\n</ul>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Facts and curiosities\
    \ <a name=\"user-content-facts_and_curiosities\"></a>\n</h2><a id=\"user-content-facts-and-curiosities-\"\
    \ class=\"anchor\" aria-label=\"Permalink: Facts and curiosities \" href=\"#facts-and-curiosities-\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">How many developers\
    \ are currently working on this project?</h3><a id=\"user-content-how-many-developers-are-currently-working-on-this-project\"\
    \ class=\"anchor\" aria-label=\"Permalink: How many developers are currently working\
    \ on this project?\" href=\"#how-many-developers-are-currently-working-on-this-project\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>At Thursday, December/23, 2021 there is one and only one developer, me\n:no_mouth:\
    \ :envelope:</p>\n<p>\U0001F6A7 \U0001F6A7 \U0001F6A7 \U0001F6A7 \U0001F6A7</p>\n\
    <div class=\"markdown-heading\"><h3 class=\"heading-element\">When did this start?</h3><a\
    \ id=\"user-content-when-did-this-start\" class=\"anchor\" aria-label=\"Permalink:\
    \ When did this start?\" href=\"#when-did-this-start\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p>This project was initially\
    \ uploaded to GitHub on Friday, 11 March 2016\n:smile:</p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">License <a name=\"user-content-license\"></a>\n\
    </h2><a id=\"user-content-license-\" class=\"anchor\" aria-label=\"Permalink:\
    \ License \" href=\"#license-\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></div>\n<p>Licensed under the GNU GPLv3. A copy can be found on the\
    \ <a href=\"./LICENSE\">LICENSE</a> file.</p>\n"
  stargazers_count: 5
  subscribers_count: 2
  topics:
  - numerical-methods
  - parallel-programming
  - linear-algebra
  - equation-solver
  - object-oriented-programming
  - mesh-free-methods
  - computational-biology
  - cellular-automata
  updated_at: 1667944768.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - thetagpu/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">spack-envs</h1><a
    id="user-content-spack-envs" class="anchor" aria-label="Permalink: spack-envs"
    href="#spack-envs"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <div class="markdown-heading"><h2 class="heading-element">Locally</h2><a id="user-content-locally"
    class="anchor" aria-label="Permalink: Locally" href="#locally"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Using Fedora Asahi Remix 39, make sure that dev tools are installed on the
    system:</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">dnf
    group install "Development Tools"</span>

    <span class="pl-c1">dnf group install "Development Libraries"</span>

    <span class="pl-c1">dnf group install "C Development Tools and Libraries"</span>

    <span class="pl-c1">dnf install gcc-gfortran</span></pre></div>

    <p>Change the default configuration is needed:</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: $spack/opt/spack</span>

    <span class="pl-c1">build_stage: $spack/var/spack/stage</span></pre></div>

    <p>Activate the environment and install it:</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    env activate ~/Dev/spack-envs/local</span>

    <span class="pl-c1">spack install</span></pre></div>

    <div class="markdown-heading"><h3 class="heading-element">Last successful installations:</h3><a
    id="user-content-last-successful-installations" class="anchor" aria-label="Permalink:
    Last successful installations:" href="#last-successful-installations"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <table>

    <thead>

    <tr>

    <th>Date</th>

    <th>

    <code>spack-envs</code> commit</th>

    <th>Spack commit</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>2024-01-15</td>

    <td>``</td>

    <td></td>

    </tr>

    </tbody>

    </table>

    <div class="markdown-heading"><h2 class="heading-element">Grid5000</h2><a id="user-content-grid5000"
    class="anchor" aria-label="Permalink: Grid5000" href="#grid5000"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: /my-spack/spack</span>

    <span class="pl-c1">build_stage: /tmp/spack-stage</span></pre></div>

    <div class="markdown-heading"><h2 class="heading-element">Argonne National Lab</h2><a
    id="user-content-argonne-national-lab" class="anchor" aria-label="Permalink: Argonne
    National Lab" href="#argonne-national-lab"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></div>

    <p>Copy the relevant content of <code>.zshrc</code> into the frontend <code>.zshrc</code>.</p>

    <div class="markdown-heading"><h3 class="heading-element">Polaris</h3><a id="user-content-polaris"
    class="anchor" aria-label="Permalink: Polaris" href="#polaris"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>Once you are logged in on a compute node, activate the environment and install
    it:</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">use_polaris</span>

    <span class="pl-c1">spack env activate git/spack-envs/polaris</span>

    <span class="pl-c1">spack install</span></pre></div>

    <div class="markdown-heading"><h3 class="heading-element">Last successful installations:</h3><a
    id="user-content-last-successful-installations-1" class="anchor" aria-label="Permalink:
    Last successful installations:" href="#last-successful-installations-1"><span
    aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <table>

    <thead>

    <tr>

    <th>Date</th>

    <th>

    <code>spack-envs</code> commit</th>

    <th>

    <code>spack-packages</code> commit</th>

    <th>Spack commit</th>

    <th>Notes</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>2024-01-25</td>

    <td><code>20e8e7645baf8d424aa128810c416da5a91280f3</code></td>

    <td><code>ad655c13117b667a580af161788d9d85bef67d98</code></td>

    <td><code>d079aaa08336d7805fc0361669e1d16b8d5de4bf</code></td>

    <td>Contents of <code>spack-packages/packages/py-continuum/package.py</code> copied
    into <code>spack/var/spack/repos/builtin/packages/py-continuum/package.py</code>

    </td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics:
  - grid5000
  - alcf
  updated_at: 1716812971.0
tsukuba-hpcs/peanuts-playground:
  data_format: 2
  description: Artifact Evaluation Environment for PEANUTS
  filenames:
  - spack/envs/chris90/spack.yaml
  full_name: tsukuba-hpcs/peanuts-playground
  latest_release: null
  readme: "<div class=\"markdown-heading\"><h1 class=\"heading-element\">peanuts-playground</h1><a\
    \ id=\"user-content-peanuts-playground\" class=\"anchor\" aria-label=\"Permalink:\
    \ peanuts-playground\" href=\"#peanuts-playground\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></div>\n<p><a href=\"https://github.com/tsukuba-hpcs/peanuts-playground\"\
    >https://github.com/tsukuba-hpcs/peanuts-playground</a></p>\n<div class=\"markdown-heading\"\
    ><h2 class=\"heading-element\">Getting Started</h2><a id=\"user-content-getting-started\"\
    \ class=\"anchor\" aria-label=\"Permalink: Getting Started\" href=\"#getting-started\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>We have prepared a test environment for PEANUTS in a Docker container. While\
    \ actual persistent memory is not available, you can verify the operation of PEANUTS.\
    \ Using Docker Compose, we will build a virtual cluster consisting of four containers.\
    \ MPI can be utilized between containers using OpenMPI-peanuts.</p>\n<p>We are\
    \ testing with VSCode and the devcontainer extension, so please follow the steps\
    \ below to set up the environment:</p>\n<ol>\n<li>Install <a href=\"https://code.visualstudio.com/\"\
    \ rel=\"nofollow\">VSCode</a>\n</li>\n<li>Install Docker by referring to <a href=\"\
    https://code.visualstudio.com/docs/devcontainers/containers\" rel=\"nofollow\"\
    >Developing inside a Container</a>\n</li>\n<li>Install the <a href=\"https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack\"\
    \ rel=\"nofollow\">Remote Development</a> extension</li>\n</ol>\n<p>Next, clone\
    \ this repository, open it in VSCode, and build the devcontainer:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">git clone\
    \ --recursive git@github.com:tsukuba-hpcs/peanuts-playground.git</span>\n<span\
    \ class=\"pl-c1\">cd peanuts-playground</span>\n<span class=\"pl-c1\">code .</span></pre></div>\n\
    <p>Use the command palette to open the project in a container.<br>\n<code>&gt;\
    \ Dev Containers: Rebuild and Reopen in Container</code></p>\n<p>Once the container\
    \ starts, build PEANUTS with the following commands. We use spack for the installation\
    \ of PEANUTS. Additionally, Python modules are installed with Pip for later visualization.</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre># <span class=\"pl-s1\"\
    ><span class=\"pl-k\">in</span> the container peanuts-h1</span>\n\n<span class=\"\
    pl-c1\">python3 -m venv .venv</span>\n<span class=\"pl-c1\">source .venv/bin/activate</span>\n\
    <span class=\"pl-c1\">pip install -r requirements.txt</span>\n\n<span class=\"\
    pl-c1\">spack env create dev spack/envs/dev/spack.yaml</span>\n<span class=\"\
    pl-c1\">spack env activate dev</span>\n<span class=\"pl-c1\">spack concretize\
    \ -fU</span>\n<span class=\"pl-c1\">spack install</span></pre></div>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">Run Benchmarks</h2><a id=\"user-content-run-benchmarks\"\
    \ class=\"anchor\" aria-label=\"Permalink: Run Benchmarks\" href=\"#run-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>Once the <code>spack install</code> command is successfully completed, the\
    \ following tools will be installed:</p>\n<ul>\n<li>OpenMPI integrated with PEANUTS\
    \ (mpirun)</li>\n<li>Benchmarks:\n<ul>\n<li>ior</li>\n<li>rdbench</li>\n<li>h5bench_write\
    \ / h5bench_read</li>\n</ul>\n</li>\n</ul>\n<p>Using these tools, you can run\
    \ the benchmarks described in the PEANUTS paper. However, there are some limitations\
    \ in the container environment:</p>\n<ul>\n<li>Since persistent memory is not\
    \ available, we use the <code>/tmp/pseudo_pmem</code> file as a pseudo PMEM device.</li>\n\
    <li>When running with process per node (PPN) &gt; 1, <code>MPI_Win_create</code>\
    \ fails to register file-backed memory. Therefore, please run <code>mpirun</code>\
    \ with PPN=1.</li>\n</ul>\n<p>We have prepared scripts to run the benchmarks inside\
    \ the container:</p>\n<ul>\n<li><code>src/ior.sh</code></li>\n<li><code>src/rdbench.sh</code></li>\n\
    <li><code>src/h5bench.sh</code></li>\n</ul>\n<p>When executed, the results will\
    \ be output to the <code>raw/</code> directory.</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">cd src</span>\n<span class=\"pl-c1\">./ior.sh</span>\n\
    <span class=\"pl-c1\">./rdbench.sh</span>\n<span class=\"pl-c1\">./h5bench.sh</span></pre></div>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Plot Results</h2><a\
    \ id=\"user-content-plot-results\" class=\"anchor\" aria-label=\"Permalink: Plot\
    \ Results\" href=\"#plot-results\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></div>\n<p>We have also prepared Jupyter notebooks\
    \ to parse the logs in the <code>raw/</code> directory and create graphs:</p>\n\
    <ul>\n<li><code>src/ior.ipynb</code></li>\n<li><code>src/rdbench.ipynb</code></li>\n\
    <li><code>src/h5bench.ipynb</code></li>\n</ul>\n<p>The required pip modules are\
    \ installed in the <code>.venv/</code> directory. Open each Jupyter notebook,\
    \ select <code>.venv</code> from the <code>Select Kernel</code> option in the\
    \ upper right, and run the entire notebook.</p>\n<p>If the benchmark fails to\
    \ run, a corrupt results file may be generated and should be deleted.</p>\n<div\
    \ class=\"markdown-heading\"><h2 class=\"heading-element\">Install PEANUTS on\
    \ a Real Cluster</h2><a id=\"user-content-install-peanuts-on-a-real-cluster\"\
    \ class=\"anchor\" aria-label=\"Permalink: Install PEANUTS on a Real Cluster\"\
    \ href=\"#install-peanuts-on-a-real-cluster\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>In the PEANUTS paper, the Pegasus\
    \ supercomputer at the University of Tsukuba was utilized.\nHowever, Pegasus could\
    \ not provide accounts for Artifact Evaluation.\nInstead, we explain how to run\
    \ PEANUTS using the chris9x cluster owned by our laboratory.</p>\n<p>The chris9x\
    \ cluster consists of two nodes, chris90 and chris91,\nequipped with the second\
    \ generation of Intel Optane DCPMM and InfiniBand EDR.</p>\n<p>Perform the following\
    \ tasks by connecting to chris90 via ssh.\n(Sorry, git clone and build will take\
    \ a while due to poor NFS)</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre># <span class=\"pl-s1\">on chris9x cluster, use /shared/fish/<span class=\"\
    pl-smi\">$USER</span> instead of /home/<span class=\"pl-smi\">$USER</span></span>\n\
    <span class=\"pl-c1\">mkdir /shared/fish/$USER</span>\n<span class=\"pl-c1\">cd\
    \ /shared/fish/$USER</span>\n\n# <span class=\"pl-s1\">checkout</span>\n<span\
    \ class=\"pl-c1\">git clone --recursive git@github.com:tsukuba-hpcs/peanuts-playground.git</span>\n\
    <span class=\"pl-c1\">cd peanuts-playground</span>\n\n# <span class=\"pl-s1\"\
    >install python modules</span>\n<span class=\"pl-c1\">python3 -m venv .venv</span>\n\
    <span class=\"pl-c1\">source .venv/bin/activate</span>\n<span class=\"pl-c1\"\
    >pip install -r requirements.txt</span>\n\n# <span class=\"pl-s1\">prepre spack</span>\n\
    <span class=\"pl-c1\">source externals/spack/share/spack/setup-env.sh</span>\n\
    \n# <span class=\"pl-s1\">build PEANUTS and benckmarks and configuration tools\
    \ with spack</span>\n<span class=\"pl-c1\">spack repo add externals/spack-packages</span>\n\
    <span class=\"pl-c1\">spack env create peanuts spack/envs/chris90/spack.yaml</span>\n\
    <span class=\"pl-c1\">spack env activate peanuts</span>\n<span class=\"pl-c1\"\
    >spack concretize -fU</span>\n<span class=\"pl-c1\">spack install</span>\n\n#\
    \ <span class=\"pl-s1\">prepare interleaved devdax PMEM (requires root privilege)</span>\n\
    # <span class=\"pl-s1\">DEVDAX is prepared <span class=\"pl-k\">in</span> advance\
    \ by the administrator.</span>\n<span class=\"pl-c1\">sudo env PATH=$PATH ndctl\
    \ destroy-namespace all --force</span>\n<span class=\"pl-c1\">sudo env PATH=$PATH\
    \ ndctl create-namespace --mode=devdax</span>\n<span class=\"pl-c1\">sudo chmod\
    \ 666 /dev/dax0.0</span></pre></div>\n<p>In practice, the final preparation of\
    \ DEVDAX is done in advance with root privileges.</p>\n<p>Checking the PMEM device.</p>\n\
    <details><summary>ndctl list -ND (click here to show in details)</summary>\n<pre><code>$\
    \ ndctl list -NDu\n{\n  \"dimms\":[\n    {\n      \"dev\":\"nmem1\",\n      \"\
    id\":\"8089-a2-2106-000044f9\",\n      \"handle\":\"0x11\",\n      \"phys_id\"\
    :\"0x110c\",\n      \"security\":\"disabled\"\n    },\n    {\n      \"dev\":\"\
    nmem3\",\n      \"id\":\"8089-a2-2106-000041f5\",\n      \"handle\":\"0x111\"\
    ,\n      \"phys_id\":\"0x110e\",\n      \"security\":\"disabled\"\n    },\n  \
    \  {\n      \"dev\":\"nmem5\",\n      \"id\":\"8089-a2-2136-000039d0\",\n    \
    \  \"handle\":\"0x211\",\n      \"phys_id\":\"0x110d\",\n      \"security\":\"\
    disabled\"\n    },\n    {\n      \"dev\":\"nmem7\",\n      \"id\":\"8089-a2-2136-000032c1\"\
    ,\n      \"handle\":\"0x311\",\n      \"phys_id\":\"0x110f\",\n      \"security\"\
    :\"disabled\"\n    },\n    {\n      \"dev\":\"nmem0\",\n      \"id\":\"8089-a2-2106-000043e8\"\
    ,\n      \"handle\":\"0x1\",\n      \"phys_id\":\"0x1108\",\n      \"security\"\
    :\"disabled\"\n    },\n    {\n      \"dev\":\"nmem2\",\n      \"id\":\"8089-a2-2106-000044c8\"\
    ,\n      \"handle\":\"0x101\",\n      \"phys_id\":\"0x110a\",\n      \"security\"\
    :\"disabled\"\n    },\n    {\n      \"dev\":\"nmem4\",\n      \"id\":\"8089-a2-2136-0000387d\"\
    ,\n      \"handle\":\"0x201\",\n      \"phys_id\":\"0x1109\",\n      \"security\"\
    :\"disabled\"\n    },\n    {\n      \"dev\":\"nmem6\",\n      \"id\":\"8089-a2-2136-00003938\"\
    ,\n      \"handle\":\"0x301\",\n      \"phys_id\":\"0x110b\",\n      \"security\"\
    :\"disabled\"\n    }\n  ],\n  \"namespaces\":[\n    {\n      \"dev\":\"namespace0.0\"\
    ,\n      \"mode\":\"devdax\",\n      \"map\":\"dev\",\n      \"size\":\"992.25\
    \ GiB (1065.42 GB)\",\n      \"uuid\":\"1907bd57-f250-40ca-ad03-8ab614871f31\"\
    ,\n      \"chardev\":\"dax0.0\",\n      \"align\":2097152\n    }\n  ]\n}\n\n</code></pre>\n\
    </details>\n<p>We have an interleaved PMEM namespace with 8 DIMMs. total size\
    \ is 1 TB per node.</p>\n<div class=\"markdown-heading\"><h2 class=\"heading-element\"\
    >Run Benchmarks on a Real Cluster</h2><a id=\"user-content-run-benchmarks-on-a-real-cluster\"\
    \ class=\"anchor\" aria-label=\"Permalink: Run Benchmarks on a Real Cluster\"\
    \ href=\"#run-benchmarks-on-a-real-cluster\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>We have prepared scripts for running\
    \ benchmarks on the chris9x cluster with actual PMEM devices.</p>\n<ul>\n<li><code>src/ior-chris9x.sh</code></li>\n\
    <li><code>src/rdbench-chris9x.sh</code></li>\n<li><code>src/h5bench-chris9x.sh</code></li>\n\
    </ul>\n<p>These benchmark evaluations aim to reproduce the results presented in\
    \ the PEANUTS paper.\nIOR is described in Section 4.2, RDBench in Section 4.3,\
    \ and h5bench in Section 4.4.</p>\n<p>Before running, ensure that Spack is enabled.</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\"\
    >source externals/spack/share/spack/setup-env.sh</span>\n<span class=\"pl-c1\"\
    >cd src</span>\n<span class=\"pl-c1\">./ior-chris9x.sh</span>\n<span class=\"\
    pl-c1\">./rdbench-chris9x.sh</span>\n<span class=\"pl-c1\">./h5bench-chris9x.sh</span></pre></div>\n\
    <p>PEANUTS automatically maps <code>/dev/dax0.0</code> into the virtual address\
    \ space immediately after <code>MPI_Init()</code>\nand registers PMEM to the RDMA-capable\
    \ NIC with <code>MPI_Win_create()</code>.\nParameters can be passed to PEANUTS\
    \ through the mpirun runtime command,\nbut they are already set in the scripts\
    \ above.\nYou can check the settings in detail using the following command.</p>\n\
    <details><summary>ompi_info</summary>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">ompi_info --params hook peanuts --level 3</span>\n\
    <span class=\"pl-c1\">                MCA hook: peanuts (MCA v2.1.0, API v1.0.0,\
    \ Component v5.0.0)</span>\n<span class=\"pl-c1\">        MCA hook peanuts: ---------------------------------------------------</span>\n\
    <span class=\"pl-c1\">        MCA hook peanuts: parameter \"hook_peanuts_pmem_path\"\
    \ (current value:</span>\n<span class=\"pl-c1\">                          \"/dev/dax0.0\"\
    , data source: default, level: 3</span>\n<span class=\"pl-c1\">              \
    \            user/all, type: string)</span>\n<span class=\"pl-c1\">          \
    \                Path to the pmem device</span>\n<span class=\"pl-c1\">      \
    \  MCA hook peanuts: parameter \"hook_peanuts_pmem_size\" (current value:</span>\n\
    <span class=\"pl-c1\">                          \"0\", data source: default, level:\
    \ 3 user/all, type:</span>\n<span class=\"pl-c1\">                          size_t)</span>\n\
    <span class=\"pl-c1\">                          Size of the pmem device</span>\n\
    <span class=\"pl-c1\">        MCA hook peanuts: parameter \"hook_peanuts_save\"\
    \ (current value:</span>\n<span class=\"pl-c1\">                          \"true\"\
    , data source: default, level: 3 user/all,</span>\n<span class=\"pl-c1\">    \
    \                      type: bool)</span>\n<span class=\"pl-c1\">            \
    \              Save volatile state to the pmem</span>\n<span class=\"pl-c1\">\
    \                          Valid values: 0|f|false|disabled|no|n,</span>\n<span\
    \ class=\"pl-c1\">                          1|t|true|enabled|yes|y</span>\n<span\
    \ class=\"pl-c1\">        MCA hook peanuts: parameter \"hook_peanuts_load\" (current\
    \ value:</span>\n<span class=\"pl-c1\">                          \"false\", data\
    \ source: default, level: 3 user/all,</span>\n<span class=\"pl-c1\">         \
    \                 type: bool)</span>\n<span class=\"pl-c1\">                 \
    \         Load volatile state from the pmem</span>\n<span class=\"pl-c1\">   \
    \                       Valid values: 0|f|false|disabled|no|n,</span>\n<span class=\"\
    pl-c1\">                          1|t|true|enabled|yes|y</span>\n<span class=\"\
    pl-c1\">        MCA hook peanuts: parameter \"hook_peanuts_enable\" (current value:</span>\n\
    <span class=\"pl-c1\">                          \"true\", data source: default,\
    \ level: 3 user/all,</span>\n<span class=\"pl-c1\">                          type:\
    \ bool)</span>\n<span class=\"pl-c1\">                          Enable peanuts</span>\n\
    <span class=\"pl-c1\">                          Valid values: 0|f|false|disabled|no|n,</span>\n\
    <span class=\"pl-c1\">                          1|t|true|enabled|yes|y</span></pre></div>\n\
    </details>\n<p>If other users are using <code>/dev/dax0.0</code>, it cannot be\
    \ executed simultaneously.</p>\n<p>While IOR is run with various transfer sizes\
    \ in the paper,\nthe script executes it with a 32KiB transfer size.\nIf you want\
    \ to try other transfer sizes, uncomment the xfer_size_list variable in <code>ior-chris9x.sh</code>.</p>\n\
    <div class=\"markdown-heading\"><h2 class=\"heading-element\">Plot Results on\
    \ a Real Cluster</h2><a id=\"user-content-plot-results-on-a-real-cluster\" class=\"\
    anchor\" aria-label=\"Permalink: Plot Results on a Real Cluster\" href=\"#plot-results-on-a-real-cluster\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <p>You can visualize the results on the chris9x cluster. To do so, connect to\
    \ chris90 using VSCode with the Remote SSH extension. Alternatively, copy the\
    \ log files to your local machine using scp and run Jupyter Notebook within your\
    \ local devcontainer.</p>\n<p>Each graph title plotted in the Jupyter Notebook\
    \ indicates the corresponding figure in the PEANUTS paper.</p>\n<div class=\"\
    markdown-heading\"><h2 class=\"heading-element\">How to Validate and Verify the\
    \ Results</h2><a id=\"user-content-how-to-validate-and-verify-the-results\" class=\"\
    anchor\" aria-label=\"Permalink: How to Validate and Verify the Results\" href=\"\
    #how-to-validate-and-verify-the-results\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></div>\n<p>Preliminary experiments have measured\
    \ the parallel I/O performance of the PMEM devices on a single node of the chris9x\
    \ cluster.<br>\n<a href=\"https://github.com/range3/pmembench/blob/4db7408da4a5a5767c93657cc03cd933f3fac61c/eval/README.md\"\
    >range3/pmembench benchmark result</a></p>\n<p>For reference, we have placed sample\
    \ chris9x benchmark results in the raw-sample/ directory.\nThe initial state of\
    \ src/ior.ipynb, src/rdbench.ipynb, and src/h5bench.ipynb are visualizations of\
    \ these benchmark results.</p>\n<p>In more detail, please refer to overview.pdf.</p>\n\
    <div class=\"markdown-heading\"><h1 class=\"heading-element\">Differences from\
    \ PEANUTS paper</h1><a id=\"user-content-differences-from-peanuts-paper\" class=\"\
    anchor\" aria-label=\"Permalink: Differences from PEANUTS paper\" href=\"#differences-from-peanuts-paper\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n\
    <ul>\n<li>Pegasus supercomputer vs Chris9x</li>\n</ul>\n<table>\n<thead>\n<tr>\n\
    <th></th>\n<th>Pegasus</th>\n<th>Chris9x</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>PMEM</td>\n<td>Optane DCPMM 300 series</td>\n<td>Optane DCPMM 200 series</td>\n\
    </tr>\n<tr>\n<td>NETWORK</td>\n<td>InfiniBand HDR200</td>\n<td>InfiniBand EDR</td>\n\
    </tr>\n<tr>\n<td>CPU</td>\n<td>Xeon Platinum 8468, 2.1GHz 48 cores</td>\n<td>Xeon\
    \ Gold 6326, 2.90GHz 16 cores</td>\n</tr>\n<tr>\n<td>Node count</td>\n<td>100</td>\n\
    <td>2</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>RDBench could not evaluate weak\
    \ scaling on 2 nodes due to the limitations of the application, so I wrote a script\
    \ with strong scaling in chris9x.</li>\n</ul>\n<div class=\"markdown-heading\"\
    ><h1 class=\"heading-element\">References</h1><a id=\"user-content-references\"\
    \ class=\"anchor\" aria-label=\"Permalink: References\" href=\"#references\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></div>\n<ul>\n\
    <li><a href=\"https://github.com/tsukuba-hpcs/peanuts\">PEANUTS core libraies</a></li>\n\
    <li><a href=\"https://github.com/tsukuba-hpcs/ompi-peanuts\">OpenMPI with PEANUTS</a></li>\n\
    <li><a href=\"https://github.com/tsukuba-hpcs/spack-packages\">Spack packages\
    \ for installing PEANUTS</a></li>\n<li><a href=\"https://github.com/range3/pmembench\"\
    >Preliminary PMEM benchmark and evaluation</a></li>\n<li><a href=\"https://github.com/tsukuba-hpcs/mpiio-pmembb\"\
    >Repository for evaluation on the Pegasus supercomputer used in the paper, including\
    \ spack settings, benchmarks, job scripts, raw logs, and visualization scripts</a></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1715934434.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/karolina/bpmf-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-gpi/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1635166163.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/hpccf/farm/r-stack/spack.yaml
  - environments/hpccf/farm/core/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<div class="markdown-heading"><h1 class="heading-element">Spack @ UC Davis</h1><a
    id="user-content-spack--uc-davis" class="anchor" aria-label="Permalink: Spack
    @ UC Davis" href="#spack--uc-davis"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <div class="markdown-heading"><h2 class="heading-element">Spack repos and configs
    for UC Davis HPCCF Clusters</h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters"
    class="anchor" aria-label="Permalink: Spack repos and configs for UC Davis HPCCF
    Clusters" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></div>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 5
  topics: []
  updated_at: 1709600687.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - benchmarks/spack/isambard-phase3/milan/spack.yaml
  - benchmarks/spack/csd3-rocky8/sapphirerapids/spack.yaml
  - benchmarks/spack/csd3-rocky8/icelake/spack.yaml
  - benchmarks/spack/isambard-a64fx/compute-node/spack.yaml
  - benchmarks/spack/cosma8/compute-node/spack.yaml
  - benchmarks/spack/isambard-macs/rome/spack.yaml
  - benchmarks/spack/cosma7/rockport-openmpi-compute-node/spack.yaml
  - benchmarks/spack/isambard-phase3/instinct/spack.yaml
  - benchmarks/spack/isambard-xci/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: v1.0.1
  readme: '<p><a href="https://zenodo.org/doi/10.5281/zenodo.11144871" rel="nofollow"><img
    src="https://camo.githubusercontent.com/222ba5aa43f18e71a20b99a902e01b2eb1364162124f9ddf35c7ce3873a1ad58/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3338313039393135392e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/381099159.svg" style="max-width:
    100%;"></a></p>

    <div class="markdown-heading"><h1 class="heading-element">ExCALIBUR tests</h1><a
    id="user-content-excalibur-tests" class="anchor" aria-label="Permalink: ExCALIBUR
    tests" href="#excalibur-tests"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>Performance benchmarks and regression tests for the ExCALIBUR project.</p>

    <p>These benchmarks are based on a similar project by

    <a href="https://github.com/stackhpc/hpc-tests">StackHPC</a>.</p>

    <p>Feel free to add new benchmark applications or support new systems that are
    part of the

    ExCALIBUR benchmarking collaboration.</p>

    <p><em><strong>Note</strong>: at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>

    <div class="markdown-heading"><h2 class="heading-element">Documentation</h2><a
    id="user-content-documentation" class="anchor" aria-label="Permalink: Documentation"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <ul>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/install/" rel="nofollow">Installation</a></li>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/setup/" rel="nofollow">Configuration</a></li>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/use/" rel="nofollow">Usage</a></li>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/post-processing/"
    rel="nofollow">Post-processing</a></li>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/contributing/" rel="nofollow">Contributing</a></li>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/apps/" rel="nofollow">Supported
    benchmarks</a></li>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/systems/" rel="nofollow">Supported
    systems</a></li>

    <li><a href="https://ukri-excalibur.github.io/excalibur-tests/tutorial/tutorial/"
    rel="nofollow">ARCHER2 tutorial</a></li>

    </ul>

    <div class="markdown-heading"><h2 class="heading-element">Acknowledgements</h2><a
    id="user-content-acknowledgements" class="anchor" aria-label="Permalink: Acknowledgements"
    href="#acknowledgements"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>

    <p>This work was supported by the Engineering and Physical Sciences

    Research Council [EP/X031829/1].</p>

    <p>This work used the DiRAC@Durham facility managed by the Institute for Computational

    Cosmology on behalf of the STFC DiRAC HPC Facility (<a href="http://www.dirac.ac.uk"
    rel="nofollow">www.dirac.ac.uk</a>). The equipment

    was funded by BEIS capital funding via STFC capital grants ST/P002293/1, ST/R002371/1

    and ST/S002502/1, Durham University and STFC operations grant ST/R000832/1.

    DiRAC is part of the National e-Infrastructure.</p>

    <p>The main outcomes of this work were published in a <a href="https://dl.acm.org/doi/10.1145/3624062.3624133"
    rel="nofollow">paper</a> in the HPCTESTS workshop in SC23.</p>

    <p>This work was <a href="https://virtual.oxfordabstracts.com/#/event/4430/submission/74"
    rel="nofollow">presented in RSECon23</a>. A <a href="https://youtu.be/vpTD_tJqWOA?si=zl9sWvPEQYyPhJTV"
    rel="nofollow">recording of the talk</a> is available.</p>

    '
  stargazers_count: 17
  subscribers_count: 7
  topics: []
  updated_at: 1716472463.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-38/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: 24.1.0
  stargazers_count: 24
  subscribers_count: 6
  topics:
  - jupyter
  - ipython
  - ipython-widget
  - ipywidget
  - jupyter-notebook
  - jupyterhub
  - notebook
  updated_at: 1716722301.0
