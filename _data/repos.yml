Alpine-DAV/spack_configs:
  data_format: 2
  description: spack envs
  filenames:
  - envs/llnl/quartz/spack.yaml
  - envs/olcf/summit/spack.yaml
  - envs/alpinedav/ubuntu_18_cuda_10.1_devel/spack.yaml
  - envs/alpinedav/ubuntu_18_devel/spack.yaml
  - envs/llnl/pascal-cuda/spack.yaml
  full_name: Alpine-DAV/spack_configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack_configs" class="anchor" href="#spack_configs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack_configs</h1>

    <p>shared spack configs repo</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1639176281.0
ArjunaCluster/spack:
  data_format: 2
  description: Spack Repos and Configuration Files
  filenames:
  - environments/common/spack.yaml
  - environments/bootstrap/spack.yaml
  full_name: ArjunaCluster/spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1637623732.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/21.11/spack-x86_64.yaml
  - environments/21.11/spack-ppc64le.yaml
  - environments/21.08/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    \ target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width:100%;\"></a></p> \n<p><a href=\"\
    https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-e4s\" class=\"\
    anchor\" href=\"#e4s\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2>\n<a id=\"user-content-related-projects\"\
    \ class=\"anchor\" href=\"#related-projects\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Related Projects</h2>\n<ul>\n\
    <li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\">E4S-Project/E4S-Project.github.io</a>\
    \ - E4S Documentation repo that is hosted on <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-license\"\
    \ class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2>\n<a id=\"user-content-contact\" class=\"anchor\" href=\"\
    #contact\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 9
  subscribers_count: 7
  topics: []
  updated_at: 1647559436.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced electromagnetic Particle-In-Cell code.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '22.03'
  readme: '<h1>

    <a id="user-content-warpx" class="anchor" href="#warpx" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width:100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width:100%;"></a>

    <a href="https://warpx.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width:100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width:100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width:100%;"></a>

    <a href="https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667"
    alt="Gitter" data-canonical-src="https://badges.gitter.im/ECP-WarpX/community.svg"
    style="max-width:100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width:100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width:100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width:100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width:100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width:100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width:100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width:100%;"></a>

    <a href="https://doi.org/10.1016/j.parco.2021.102833" rel="nofollow"><img src="https://camo.githubusercontent.com/1f6ca17eba9f0dbca214c58a50e39d5e4d2c5513476e963147c57c7b9f40f378/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313031362f6a2e706172636f2e323032312e3130323833332d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1016/j.parco.2021.102833-blue.svg"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-overview" class="anchor" href="#overview" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced electromagnetic Particle-In-Cell code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our Gitter room at <a href="https://gitter.im/ECP-WarpX/community" rel="nofollow">https://gitter.im/ECP-WarpX/community</a></p>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 128
  subscribers_count: 14
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1647317081.0
ECP-WarpX/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/artemis
  latest_release: null
  readme: '<h1>

    <a id="user-content-artemis" class="anchor" href="#artemis" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2>

    <a id="user-content-overview" class="anchor" href="#overview" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a development
    fork of WarpX for modeling micromagnetics and electrodynamic waves in next-generation
    microelectornics.</p>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 4
  subscribers_count: 5
  topics: []
  updated_at: 1647461964.0
ECP-WarpX/impactx:
  data_format: 2
  description: 'ImpactX: the next generation of the IMPACT-Z beam dynamics code'
  filenames:
  - docs/spack.yaml
  full_name: ECP-WarpX/impactx
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-impactx\" class=\"anchor\" href=\"#impactx\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ImpactX</h1>\n<p><a href=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml\"\
    ><img src=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml/badge.svg\"\
    \ alt=\"CI Status\" style=\"max-width:100%;\"></a>\n<a href=\"https://impactx.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1090ab96071a0b6311590a818911f8b10c5d65e31760367fbaed373f8d727e03/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f696d70616374782f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/impactx/badge/?version=latest\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\"\
    \ alt=\"License ImpactX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\"\
    \ style=\"max-width:100%;\"></a><br>\n<a href=\"https://impactx.readthedocs.io/en/latest/install/users.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"\"><img src=\"https://camo.githubusercontent.com/f73e31a4b02d92a0ca047cdb719ffc50036fef98434ef1b7e5814fe3216a6d7b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646576656c6f706d656e742532307374617475732d7072652d2d616c7068612d6f72616e67652e737667\"\
    \ alt=\"Development Status\" data-canonical-src=\"https://img.shields.io/badge/development%20status-pre--alpha-orange.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://isocpp.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\"\
    \ alt=\"Language: C++17\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://python.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\"\
    \ alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>ImpactX: the next generation of the <a\
    \ href=\"https://github.com/impact-lbl/IMPACT-Z\">IMPACT-Z</a> code</p>\n<h2>\n\
    <a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Documentation</h2>\n<p>In order to learn how to install and run the\
    \ code, please see the online documentation:\n<a href=\"https://impactx.readthedocs.io\"\
    \ rel=\"nofollow\">https://impactx.readthedocs.io</a></p>\n<ul>\n<li>ImpactX Doxygen:\
    \ <a href=\"https://impactx.readthedocs.io/en/latest/_static/doxyhtml\" rel=\"\
    nofollow\">https://impactx.readthedocs.io/en/latest/_static/doxyhtml</a>\n</li>\n\
    <li>AMReX Doxygen: <a href=\"https://amrex-codes.github.io/amrex/doxygen\" rel=\"\
    nofollow\">https://amrex-codes.github.io/amrex/doxygen</a>\n</li>\n<li>WarpX Doxygen:\
    \ <a href=\"https://warpx.readthedocs.io/en/latest/_static/doxyhtml\" rel=\"nofollow\"\
    >https://warpx.readthedocs.io/en/latest/_static/doxyhtml</a>\n</li>\n</ul>\n<h2>\n\
    <a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n\
    <p><a href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\"\
    \ alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>Our workflow is described in <a href=\"\
    CONTRIBUTING.rst\">CONTRIBUTING.rst</a>.</p>\n<h2>\n<a id=\"user-content-developer-environment\"\
    \ class=\"anchor\" href=\"#developer-environment\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developer Environment</h2>\n\
    <p>Please prepare you local development environment as follows.\nPick <em>one</em>\
    \ of the methods below:</p>\n<h3>\n<a id=\"user-content-perlmutter-nersc\" class=\"\
    anchor\" href=\"#perlmutter-nersc\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Perlmutter (NERSC)</h3>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>ssh perlmutter-p1.nersc.gov</pre></div>\n\
    <p>Now <code>cd</code> to your ImpactX source directory.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>module load cmake/3.22.0\nmodule swap PrgEnv-nvidia\
    \ PrgEnv-gnu\nmodule load cudatoolkit\nmodule load cray-hdf5-parallel/1.12.0.7\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Python</span>\nmodule load\
    \ cray-python/3.9.4.2\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\">-d</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$HOME</span>/sw/perlmutter/venvs/impactx<span class=\"pl-pds\">\"</span></span>\
    \ ]\n<span class=\"pl-k\">then</span>\n  <span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx/bin/activate\n<span\
    \ class=\"pl-k\">else</span>\n  python3 -m pip install --user --upgrade pip\n\
    \  python3 -m pip install --user virtualenv\n  python3 -m venv <span class=\"\
    pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx\n  <span class=\"pl-c1\">source</span>\
    \ <span class=\"pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx/bin/activate\n\
    \n  python3 -m pip install --upgrade pip\n  MPICC=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>cc -target-accel=nvidia80 -shared<span class=\"pl-pds\">\"</span></span>\
    \ python3 -m pip install -U --no-cache-dir -v mpi4py\n  python3 -m pip install\
    \ -r requirements.txt\n<span class=\"pl-k\">fi</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> GPU-aware MPI</span>\n<span class=\"pl-k\">export</span>\
    \ MPICH_GPU_SUPPORT_ENABLED=1\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ necessary to use CUDA-Aware MPI and run a job</span>\n<span class=\"pl-k\">export</span>\
    \ CRAY_ACCEL_TARGET=nvidia80\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optimize CUDA compilation for A100</span>\n<span class=\"pl-k\">export</span>\
    \ AMREX_CUDA_ARCH=8.0\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compiler\
    \ environment hints</span>\n<span class=\"pl-k\">export</span> CC=<span class=\"\
    pl-s\"><span class=\"pl-pds\">$(</span>which gcc<span class=\"pl-pds\">)</span></span>\n\
    <span class=\"pl-k\">export</span> CXX=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>which g++<span class=\"pl-pds\">)</span></span>\n<span class=\"pl-k\"\
    >export</span> FC=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which gfortran<span\
    \ class=\"pl-pds\">)</span></span>\n<span class=\"pl-k\">export</span> CUDACXX=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">$(</span>which nvcc<span class=\"pl-pds\"\
    >)</span></span>\n<span class=\"pl-k\">export</span> CUDAHOSTCXX=<span class=\"\
    pl-s\"><span class=\"pl-pds\">$(</span>which g++<span class=\"pl-pds\">)</span></span></pre></div>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> configure</span>\ncmake -S <span class=\"pl-c1\">.</span>\
    \ -B build_perlmutter -DImpactX_COMPUTE=CUDA\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> compile</span>\ncmake --build build_perlmutter -j 10\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> test</span>\nsrun -N 1 --ntasks-per-node=4\
    \ -t 0:10:00 -C gpu -c 32 -G 4 --qos=debug -A m3906_g ctest --test-dir build_perlmutter\
    \ --output-on-failure\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> run</span>\n\
    <span class=\"pl-c1\">cd</span> build_perlmutter/bin\nsrun -N 1 --ntasks-per-node=4\
    \ -t 0:10:00 -C gpu -c 32 -G 4 --qos=debug -A m3906_g ./impactx ../../examples/fodo/input_fodo.in</pre></div>\n\
    <h3>\n<a id=\"user-content-cori-knl-nersc\" class=\"anchor\" href=\"#cori-knl-nersc\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Cori KNL (NERSC)</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>ssh cori.nersc.gov</pre></div>\n<p>Now <code>cd</code> to your ImpactX source\
    \ directory.</p>\n<div class=\"highlight highlight-source-shell\"><pre>module\
    \ swap craype-haswell craype-mic-knl\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule\
    \ load cmake/3.22.1\nmodule load cray-hdf5-parallel/1.10.5.2\nmodule load cray-fftw/3.3.8.10\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Python</span>\nmodule load\
    \ cray-python/3.9.7.1\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\">-d</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$HOME</span>/sw/knl/venvs/impactx<span class=\"pl-pds\">\"</span></span> ]\n\
    <span class=\"pl-k\">then</span>\n  <span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx/bin/activate\n<span class=\"\
    pl-k\">else</span>\n  python3 -m pip install --user --upgrade pip\n  python3 -m\
    \ pip install --user virtualenv\n  python3 -m venv <span class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx\n\
    \  <span class=\"pl-c1\">source</span> <span class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx/bin/activate\n\
    \n  python3 -m pip install --upgrade pip\n  MPICC=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>cc -shared<span class=\"pl-pds\">\"</span></span> python3 -m\
    \ pip install -U --no-cache-dir -v mpi4py\n  python3 -m pip install -r requirements.txt\n\
    <span class=\"pl-k\">fi</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ tune exactly for KNL sub-architecture</span>\n<span class=\"pl-k\">export</span>\
    \ CXXFLAGS=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-march=knl<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">export</span> CFLAGS=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>-march=knl<span class=\"pl-pds\"\
    >\"</span></span></pre></div>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> configure</span>\ncmake\
    \ -S <span class=\"pl-c1\">.</span> -B build_knl\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> compile</span>\ncmake --build build_knl -j 8\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> test</span>\nsrun -C knl -N 1 -t\
    \ 30 -q debug ctest --test-dir build_knl --output-on-failure\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> run</span>\n<span class=\"pl-c1\">cd</span>\
    \ build_knl/bin\nsrun -C knl -N 1 -t 30 -q debug ./impactx ../../examples/fodo/input_fodo.in</pre></div>\n\
    <h3>\n<a id=\"user-content-homebrew-macos\" class=\"anchor\" href=\"#homebrew-macos\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Homebrew (macOS)</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew update\nbrew install adios2      <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> for openPMD</span>\nbrew install ccache\nbrew install cmake\n\
    brew install fftw\nbrew install git\nbrew install hdf5-mpi    <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> for openPMD</span>\nbrew install libomp      <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for OpenMP</span>\nbrew install\
    \ pkg-config  <span class=\"pl-c\"><span class=\"pl-c\">#</span> for fftw</span>\n\
    brew install open-mpi</pre></div>\n<h3>\n<a id=\"user-content-apt-debianubuntu\"\
    \ class=\"anchor\" href=\"#apt-debianubuntu\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Apt (Debian/Ubuntu)</h3>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>sudo apt update\nsudo apt install\
    \ build-essential ccache cmake g++ git libfftw3-mpi-dev libfftw3-dev libhdf5-openmpi-dev\
    \ libopenmpi-dev pkg-config python3 python3-matplotlib python3-numpy python3-scipy</pre></div>\n\
    <h3>\n<a id=\"user-content-spack-linux\" class=\"anchor\" href=\"#spack-linux\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack (Linux)</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env create impactx-dev\nspack env activate impactx-dev\nspack add\
    \ adios2        <span class=\"pl-c\"><span class=\"pl-c\">#</span> for openPMD</span>\n\
    spack add ccache\nspack add cmake\nspack add fftw\nspack add hdf5          <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for openPMD</span>\nspack add mpi\n\
    spack add pkgconfig     <span class=\"pl-c\"><span class=\"pl-c\">#</span> for\
    \ fftw</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> OpenMP support\
    \ on macOS</span>\n[[ <span class=\"pl-smi\">$OSTYPE</span> <span class=\"pl-k\"\
    >==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>darwin<span class=\"\
    pl-pds\">'</span></span><span class=\"pl-k\">*</span> ]] <span class=\"pl-k\"\
    >&amp;&amp;</span> spack add llvm-openmp\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> optional:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ spack add cuda</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> spack\
    \ add python</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> spack\
    \ add py-pip</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> spack\
    \ add py-pandas</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> spack\
    \ add py-numpy</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> spack\
    \ add py-scipy</span>\n\nspack install</pre></div>\n<p>(in new terminals, re-activate\
    \ the environment with <code>spack env activate impactx-dev</code> again)</p>\n\
    <h3>\n<a id=\"user-content-conda-linuxmacoswindows\" class=\"anchor\" href=\"\
    #conda-linuxmacoswindows\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Conda (Linux/macOS/Windows)</h3>\n<div class=\"\
    highlight highlight-source-shell\"><pre>conda create -n impactx-dev -c conda-forge\
    \ adios2 ccache cmake compilers git hdf5 fftw matplotlib ninja numpy pandas scipy\n\
    conda activate impactx-dev\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ compile with -DImpactX_MPI=OFF</span></pre></div>\n<h2>\n<a id=\"user-content-get-the-source-code\"\
    \ class=\"anchor\" href=\"#get-the-source-code\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Get the Source Code</h2>\n<p>Before\
    \ you start, you will need a copy of the ImpactX source code:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>git clone git@github.com:ECP-WarpX/impactx.git\n\
    <span class=\"pl-c1\">cd</span> impactx</pre></div>\n<h2>\n<a id=\"user-content-compile\"\
    \ class=\"anchor\" href=\"#compile\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compile</h2>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ find dependencies &amp; configure</span>\ncmake -S <span class=\"pl-c1\">.</span>\
    \ -B build\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compile</span>\n\
    cmake --build build -j 4</pre></div>\n<p>That's all!\nImpactX binaries are now\
    \ in <code>build/bin/</code>.\nMost people execute these binaries directly or\
    \ copy them out.</p>\n<p>You can inspect and modify build options after running\
    \ <code>cmake -S . -B</code> build with either</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>ccmake build</pre></div>\n<p>or by adding arguments with <code>-D&lt;OPTION&gt;=&lt;VALUE&gt;</code>\
    \ to the first CMake call, e.g.:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DImpactX_COMPUTE=CUDA\
    \ -DImpactX_MPI=OFF</pre></div>\n<h2>\n<a id=\"user-content-run\" class=\"anchor\"\
    \ href=\"#run\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Run</h2>\n<p>An executable ImpactX binary with the\
    \ current compile-time options encoded in its file name will be created in <code>build/bin/</code>.</p>\n\
    <p>Additionally, a symbolic link named <code>impactx</code> can be found in that\
    \ directory, which points to the last built ImpactX executable.</p>\n<p>The command-line\
    \ syntax for this executable is:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">Usage: impactx &lt;inputs-file&gt; [some.overwritten.option=value]...</span>\n\
    \n<span class=\"pl-c1\">Mandatory arguments (remove the &lt;&gt;):</span>\n<span\
    \ class=\"pl-c1\">  inputs-file     the path to an input file; can be relative\
    \ to the current</span>\n<span class=\"pl-c1\">                  working directory\
    \ or absolute.</span>\n<span class=\"pl-c1\">                  Example: input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">Optional arguments (remove the []):</span>\n<span class=\"\
    pl-c1\">  options         this can overwrite any line in an inputs-file</span>\n\
    <span class=\"pl-c1\">                  Example: quad1.ds=0.5 sbend1.rc=1.5</span>\n\
    \n<span class=\"pl-c1\">Examples:</span>\n<span class=\"pl-c1\">  In the current\
    \ working directory, there is a file \"input_fodo.in\" and the</span>\n<span class=\"\
    pl-c1\">  \"impactx\" executable.</span>\n<span class=\"pl-c1\">  The line to\
    \ execute would look like this:</span>\n<span class=\"pl-c1\">    ./impactx input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">  In the current working directory, there is a file \"\
    input_fodo.in\" and the</span>\n<span class=\"pl-c1\">  executable \"impactx\"\
    \ is in a directory that is listed in the \"PATH\"</span>\n<span class=\"pl-c1\"\
    >  environment variable.</span>\n<span class=\"pl-c1\">  The line to execute would\
    \ look like this:</span>\n<span class=\"pl-c1\">    impactx input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">  In the current working directory, there is a file \"\
    input_fodo.in\" and the</span>\n<span class=\"pl-c1\">  \"impactx\" executable.\
    \ We want to voerwrite the segment length of the beamline</span>\n<span class=\"\
    pl-c1\">  element \"quad1\" that is already defined in it. We also want to change\
    \ the</span>\n<span class=\"pl-c1\">  radius of curvature of the bending magnet\
    \ \"sbend1\" to a different value than</span>\n<span class=\"pl-c1\">  in the\
    \ file \"input_fodo.in\".</span>\n<span class=\"pl-c1\">  The line to execute\
    \ would look like this:</span>\n<span class=\"pl-c1\">    ./impactx input_fodo.in\
    \ quad1.ds=0.5 sbend1.rc=1.5</span></pre></div>\n<h2>\n<a id=\"user-content-test\"\
    \ class=\"anchor\" href=\"#test\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Test</h2>\n<p>In order to run our\
    \ tests, you need to have a few Python packages installed:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">python3 -m\
    \ pip install -U pip setuptools wheel</span>\n<span class=\"pl-c1\">python3 -m\
    \ pip install -r requirements.txt</span></pre></div>\n<p>You can run all our tests\
    \ with:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span\
    \ class=\"pl-c1\">ctest --test-dir build --output-on-failure</span></pre></div>\n\
    <p>Further options:</p>\n<ul>\n<li>help: <code>ctest --test-dir build --help</code>\n\
    </li>\n<li>list all tests: <code>ctest --test-dir build -N</code>\n</li>\n<li>only\
    \ run tests that have \"FODO\" in their name: <code>ctest --test-dir build -R\
    \ FODO</code>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-acknowledgements\" class=\"\
    anchor\" href=\"#acknowledgements\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h2>\n<p>This\
    \ work was supported by the Laboratory Directed Research and Development Program\
    \ of Lawrence Berkeley National Laboratory under U.S. Department of Energy Contract\
    \ No. DE-AC02-05CH11231.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\"\
    \ href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>License</h2>\n<p>Copyright (c) 2021-2022, The Regents\
    \ of the University of California, through Lawrence Berkeley National Laboratory\
    \ (subject to receipt of any required approvals from the U.S. Dept. of Energy).\
    \ All rights reserved.</p>\n<p>If you have questions about your rights to use\
    \ or distribute this software, please contact Berkeley Lab's Intellectual Property\
    \ Office at <a href=\"mailto:IPO@lbl.gov\">IPO@lbl.gov</a>.</p>\n<p>This Software\
    \ was developed under funding from the U.S. Department of Energy and the U.S.\
    \ Government consequently retains certain rights. As such, the U.S. Government\
    \ has been granted for itself and others acting on its behalf a paid-up, nonexclusive,\
    \ irrevocable, worldwide license in the Software to reproduce, distribute copies\
    \ to the public, prepare derivative works, and perform publicly and display publicly,\
    \ and to permit others to do so.</p>\n"
  stargazers_count: 2
  subscribers_count: 5
  topics:
  - simulation
  - beam-dynamics
  - particle-in-cell
  - gpu
  - physics
  - pic
  - particle
  - accelerator
  - research
  updated_at: 1646955985.0
EnzymeAD/CMake-Template:
  data_format: 2
  description: A template for using Enzyme with CMake
  filenames:
  - spack.yaml
  full_name: EnzymeAD/CMake-Template
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-cmake-template\" class=\"anchor\" href=\"#cmake-template\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>CMake-Template</h1>\n<h2>\n<a id=\"user-content-usage\" class=\"anchor\"\
    \ href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Usage</h2>\n<h3>\n<a id=\"user-content-install-dependencies\"\
    \ class=\"anchor\" href=\"#install-dependencies\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Install dependencies</h3>\n<ul>\n\
    <li>cmake</li>\n<li>make</li>\n<li>llvm</li>\n<li>enzyme</li>\n</ul>\n<p>Using\
    \ spack:</p>\n<pre><code>spack env load .\nspack install\n</code></pre>\n<p>Using\
    \ homebrew:</p>\n<pre><code>brew bundle install\n</code></pre>\n<h3>\n<a id=\"\
    user-content-configure-and-build\" class=\"anchor\" href=\"#configure-and-build\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Configure and build</h3>\n<p>Configure the CMake project using the\
    \ version of Enzyme installed on the system:</p>\n<pre><code>mkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake\n</code></pre>\n<p>Configure the CMake project using\
    \ a custom Enzyme version:</p>\n<pre><code>mkdir build &amp;&amp; cd build\ncmake\
    \ -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics:
  - cmake
  - enzyme-ad
  updated_at: 1644417729.0
Exawind/exawind-builder:
  data_format: 2
  description: Scripts to help building Exawind codes on various systems
  filenames:
  - etc/spack/ornl-summit/spack-matrix.yaml
  full_name: Exawind/exawind-builder
  latest_release: v0.1.0
  readme: '<h1>

    <a id="user-content-exawind-code-builder" class="anchor" href="#exawind-code-builder"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ExaWind
    Code Builder</h1>

    <p><a href="https://exawind.github.io/exawind-builder" rel="nofollow">Documentation</a></p>

    <p>ExaWind Builder is a collection of bash scripts to configure and compile the

    codes used within the <a href="https://github.com/exawind">ExaWind</a> project
    on various

    high-performance computing (HPC) systems. The builder provides the following</p>

    <ul>

    <li>

    <p><strong>Platform configuration</strong>: Provides the minimal set of modules
    that must be

    loaded when compiling with different compilers and MPI libraries on different

    HPC systems.</p>

    </li>

    <li>

    <p><strong>Software configuration</strong>: Provides baseline CMake configuration
    that can be

    used to configure the various options when building a <em>project</em>, e.g.,

    enable/disable optional modules, automate specification of paths to various

    libraries, configure release vs. debug builds.</p>

    </li>

    <li>

    <p><strong>Build script generation</strong>: Generates an executable end-user
    script for a

    combination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>

    </li>

    <li>

    <p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific

    script that allows the user to recreate the exact environment used to build

    the codes during runtime.</p>

    </li>

    </ul>

    <p>The build scripts are intended for developers who might want to compile the

    codes with different configuration options, build different branches during

    their development cycle, or link to a different development version of a library

    that is currently not available in the standard installation on the system. Please
    see the

    <a href="https://exawind.github.io/exawind-builder" rel="nofollow">documentation</a>
    for

    details on how to use this to build ExaWind software.</p>

    <h2>

    <a id="user-content-installation-and-usage" class="anchor" href="#installation-and-usage"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation
    and usage</h2>

    <h3>

    <a id="user-content-using-exawind-builder-with-pre-installed-exawind-environment"
    class="anchor" href="#using-exawind-builder-with-pre-installed-exawind-environment"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    exawind-builder with pre-installed ExaWind environment</h3>

    <p>ExaWind Builder is already installed and setup on OLCF Summit, NREL

    Eagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly

    to using build scripts from the central installation. Please consult <a href="https://exawind.github.io/exawind-builder/basic.html#basic-usage"
    rel="nofollow">user

    manual</a> to

    learn how to use the scripts.</p>

    <h3>

    <a id="user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions"
    class="anchor" href="#bootstrapping-exawind-builder-with-pre-configured-system-definitions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bootstrapping
    exawind-builder with pre-configured system definitions</h3>

    <p>ExaWind builder has <a href="https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems"
    rel="nofollow">pre-built

    configurations</a>

    for several systems. On these systems you can use the <code>bootstrap</code> script
    to

    quickly get up and running. Please consult <a href="https://exawind.github.io/exawind-builder/installation.html"
    rel="nofollow">installation

    manual</a>. The

    relevant steps are shown below.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Download bootstrap script</span>

    curl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Make it executable</span>

    chmod a+x bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Execute bootstrap and provide system/compiler
    combination</span>

    ./bootstrap.sh -s [SYSTEM] -c [COMPILER]


    <span class="pl-c"><span class="pl-c">#</span> Examples</span>

    ./bootstrap.sh -s spack -c clang       <span class="pl-c"><span class="pl-c">#</span>
    On MacOS with homebrew</span>

    ./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system

    ./bootstrap.sh -s eagle -c gcc         <span class="pl-c"><span class="pl-c">#</span>
    NREL Eagle</span>

    ./bootstrap.sh -s cori -c intel        <span class="pl-c"><span class="pl-c">#</span>
    NERSC Cori</span>

    ./bootstrap.sh -s snl-ascicgpu -c gcc  <span class="pl-c"><span class="pl-c">#</span>
    SNL GPU development machine</span></pre></div>

    <h3>

    <a id="user-content-creating-new-system-configuration" class="anchor" href="#creating-new-system-configuration"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Creating
    new system configuration</h3>

    <p>You can add new system definitions to exawind-builder for use on new systems

    that are not used by ExaWind team. Please see <a href="https://exawind.github.io/exawind-builder/advanced.html"
    rel="nofollow">manual

    installation</a> and

    <a href="https://exawind.github.io/exawind-builder/newsys.html" rel="nofollow">adding
    a new system</a>

    sections in the user manual.</p>

    <h2>

    <a id="user-content-links" class="anchor" href="#links" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Links</h2>

    <ul>

    <li><a href="https://www.exawind.org" rel="nofollow">ExaWind</a></li>

    <li><a href="https://github.com/exawind">ExaWind GitHub Organization</a></li>

    <li><a href="https://a2e.energy.gov/about/hfm" rel="nofollow">A2e HFM</a></li>

    </ul>

    '
  stargazers_count: 3
  subscribers_count: 5
  topics:
  - cmake
  - build
  - exawind
  - hpc
  - exawind-builder
  updated_at: 1643028069.0
FTHPC/libpressio_tutorial:
  data_format: 2
  description: A Tutorial for LibPressio
  filenames:
  - spack.yaml
  full_name: FTHPC/libpressio_tutorial
  latest_release: null
  readme: '<h1>

    <a id="user-content-libpressio-tutorial" class="anchor" href="#libpressio-tutorial"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>LibPressio
    Tutorial</h1>

    <p>This repository contains a number of example applications to help you learn
    how

    to use LibPressio lossy compression.  The exercises are located in <code>exercises/</code>

    and have their own instructions in the README.md file.</p>

    <p>When cloning the repo, be sure to clone the submodules</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/FTHPC/libpressio_tutorial</pre></div>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1644688141.0
FluidNumerics/SELF:
  data_format: 2
  description: Spectral Element Library in Fortran
  filenames:
  - env/spack.yaml
  full_name: FluidNumerics/SELF
  latest_release: null
  readme: '<h1>

    <a id="user-content-spectral-element-libraries-in-fortran-self" class="anchor"
    href="#spectral-element-libraries-in-fortran-self" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Spectral Element Libraries in Fortran
    (SELF)</h1>

    <p>Copyright 2020-2022 Fluid Numerics LLC</p>

    <p><a href="https://self.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2cdea5d87038eae2bd52034d42848bdf0381c26e2ffe70a7a973e360004a19f6/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73656c662f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/self/badge/?version=latest"
    style="max-width:100%;"></a>

    <a href="https://codecov.io/gh/FluidNumerics/SELF" rel="nofollow"><img src="https://camo.githubusercontent.com/190632c16f2de9b4028909a9987ec0987590d74593c0133a6346d70373fb45ca/68747470733a2f2f636f6465636f762e696f2f67682f466c7569644e756d65726963732f53454c462f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d414b4b534c3543574b36"
    alt="codecov" data-canonical-src="https://codecov.io/gh/FluidNumerics/SELF/branch/main/graph/badge.svg?token=AKKSL5CWK6"
    style="max-width:100%;"></a>

    <a href="https://www.youtube.com/channel/UCW5e-TavOnw1AABGH-VMbRg?sub_confirmation=1"
    rel="nofollow"><img src="https://camo.githubusercontent.com/241f818a7c9fbbe538a27ae90073f54004dc794a7d2cab7ef50cb01c76e62cef/68747470733a2f2f696d672e736869656c64732e696f2f796f75747562652f6368616e6e656c2f73756273637269626572732f55435735652d5461764f6e773141414247482d564d6252673f7374796c653d736f6369616c"
    alt="Youtube" data-canonical-src="https://img.shields.io/youtube/channel/subscribers/UCW5e-TavOnw1AABGH-VMbRg?style=social"
    style="max-width:100%;"></a>

    <a href="https://www.reddit.com/r/FluidNumerics/" rel="nofollow"><img src="https://camo.githubusercontent.com/86acef9558f5e18573c4b9b4275d2eb6f59608130be921982dd5b0377650324a/68747470733a2f2f696d672e736869656c64732e696f2f7265646469742f7375627265646469742d73756273637269626572732f666c7569646e756d65726963733f7374796c653d736f6369616c"
    alt="Reddit" data-canonical-src="https://img.shields.io/reddit/subreddit-subscribers/fluidnumerics?style=social"
    style="max-width:100%;"></a></p>

    <p>SELF is licensed for use under the <a href="./LICENSE">Anti-Corporatist Software
    License</a>. For other licensure, reach out to <a href="mailto:support@fluidnumerics.com">support@fluidnumerics.com</a>.</p>

    <h2>

    <a id="user-content-about" class="anchor" href="#about" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>About</h2>

    <p>SELF is an object-oriented Fortran library that support the implementation
    of Spectral Element Methods for solving partial differential equations.</p>

    <p>The SELF API is designed based on the assumption that SEM developers and researchers
    need to be able to implement derivatives in 1-D and divergence, gradient, and
    curl in 2-D and 3-D on scalar, vector, and tensor functions using spectral collocation,
    continuous galerkin, and discontinuous galerkin spectral element methods. Additionally,
    as we enter the exascale era, we are currently faced with a zoo of compute hardware
    that is available. Because of this, SELF routines provide support for GPU acceleration
    through AMD''s HIP and support for multi-core, multi-node, and multi-GPU platforms
    with MPI.</p>

    <h2>

    <a id="user-content-support" class="anchor" href="#support" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <h3>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h3>

    <ul>

    <li><a href="https://fluidnumerics.github.io/SELF/ford/" rel="nofollow"><strong>API
    Documentation</strong></a></li>

    <li><a href="https://self.readthedocs.io/en/latest/" rel="nofollow"><strong>ReadTheDocs</strong>
    <em>(Work in Progress)</em></a></li>

    </ul>

    <h3>

    <a id="user-content-community" class="anchor" href="#community" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Community</h3>

    <h4>

    <a id="user-content-open-collective" class="anchor" href="#open-collective" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Open Collective</h4>

    <p>SELF is part of the Higher Order Methods Collective, which is fiscally hosted
    by <a href="https://www.waterchange.org" rel="nofollow">WATERCHaNGE</a>.

    You can keep track of updates and announcements for livestreams and training events
    at the <a href="https://opencollective.com/higher-order-methods" rel="nofollow">**Higher
    Order Methods Open Collective **</a>.</p>

    <p>You can support SELF and related educational activities focused on numerical
    analysis and higher order methods for solving conservation laws by contributing
    to the Open Collective.

    <a href="https://opencollective.com/higher-order-methods/contribute" rel="nofollow"><img
    src="https://github.com/opencollective/opencollective-images/raw/main/src/static/images/contribute.svg"
    alt="Open Collective" style="max-width:100%;"></a></p>

    <h3>

    <a id="user-content-maintainers" class="anchor" href="#maintainers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Maintainers</h3>

    <ul>

    <li><a href="https://fluidnumerics.com/people/joe-schoonover" rel="nofollow">Joseph
    Schoonover, Fluid Numerics LLC</a></li>

    <li>

    <strong>You</strong> Want to become a maintainer ? Reach out to <a href="mailto:support@fluidnumerics.com">support@fluidnumerics.com</a>

    </li>

    </ul>

    <p>If you''d like to contribute, see <a href="./CONTRIBUTING.md">CONTRIBUTING.md</a>
    to get started.</p>

    <p>If you need help, <a href="https://github.com/FluidNumerics/SELF/issues/new">open
    an issue</a></p>

    '
  stargazers_count: 16
  subscribers_count: 5
  topics:
  - spectral-element-method
  - gpu-acceleration
  - gpu-computing
  - hpc
  - pde-solver
  updated_at: 1647346747.0
Game4Move78/dotfiles:
  data_format: 2
  description: null
  filenames:
  - spack/spack/var/spack/environments/base/spack.yaml
  full_name: Game4Move78/dotfiles
  latest_release: null
  readme: '<h1>

    <a id="user-content-dotfiles" class="anchor" href="#dotfiles" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>dotfiles</h1>

    <p>Invoke <code>git submodule update --init --recursive</code> first to install
    submodules</p>

    <p>Example usage: <code>stow -R spacemacs</code></p>

    <h2>

    <a id="user-content-spack" class="anchor" href="#spack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack</h2>

    <p>Spack comes with a ~/.spackenv dotfile that needs to be sourced from your shell
    of choice</p>

    <p>From then to build the base environment you have to run</p>

    <pre><code>spack install -j$(nproc)

    </code></pre>

    <p>If zsh changes may only take effect after running <code>rehash</code></p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1638195529.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1639159950.0
LLNL/conduit:
  data_format: 2
  description: Simplified Data Exchange for HPC Simulations
  filenames:
  - scripts/uberenv_configs/old_configs/spack_envs/llnl/quartz/spack.yaml
  full_name: LLNL/conduit
  latest_release: v0.8.2
  readme: '<h1>

    <a id="user-content-conduit" class="anchor" href="#conduit" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Conduit</h1>

    <p><strong>Conduit: Simplified Data Exchange for HPC Simulations</strong></p>

    <p>Conduit is an open source project from Lawrence Livermore National Laboratory
    that provides an intuitive model for describing hierarchical scientific data in
    C++, C, Fortran, and Python. It is used for data coupling between packages in-core,
    serialization, and I/O tasks.</p>

    <p><a href="https://travis-ci.org/LLNL/conduit" rel="nofollow"><img src="https://camo.githubusercontent.com/478365930966f70f879ae04d59ea3f5c5888bee7d2a50e7e281dc1da3cf9aff1/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67"
    alt="Travis CI Build Status" data-canonical-src="https://travis-ci.org/LLNL/conduit.png"
    style="max-width:100%;"></a>

    <a href="https://ci.appveyor.com/project/cyrush/conduit" rel="nofollow"><img src="https://camo.githubusercontent.com/a0839e4a484ebb633a1c2ebcd90e345a176f5edc60e42f32636eefa9c3c79fad/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565"
    alt="Appveyor Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop&amp;svg=true"
    style="max-width:100%;"></a>

    <a href="https://coveralls.io/github/LLNL/conduit?branch=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/50b12c605f0f4bcc64b6db415dddf2de99c5e19a526d7bc53e45db45c95b2931/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop"
    style="max-width:100%;"></a>

    <a href="https://scan.coverity.com/projects/llnl-conduit" rel="nofollow"><img
    src="https://camo.githubusercontent.com/d4b204e42fe1ef30b166cdfd7cba043d5d74600b343aedd5e094a810b4c5c727/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31"
    alt="Static Analysis Status" data-canonical-src="https://scan.coverity.com/projects/8426/badge.svg?flat=1"
    style="max-width:100%;"></a></p>

    <h1>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>To get started building and using Conduit, check out the full documentation:</p>

    <p><a href="http://llnl-conduit.readthedocs.io/" rel="nofollow">http://llnl-conduit.readthedocs.io/</a></p>

    <h1>

    <a id="user-content-source-repo" class="anchor" href="#source-repo" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Repo</h1>

    <p>Conduit''s source is hosted on GitHub:</p>

    <p><a href="https://github.com/llnl/conduit">https://github.com/llnl/conduit</a></p>

    <h1>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h1>

    <p>Conduit is released under a BSD-style license - for detailed license info,
    refer to:</p>

    <p><a href="https://llnl-conduit.readthedocs.io/en/latest/licenses.html" rel="nofollow">https://llnl-conduit.readthedocs.io/en/latest/licenses.html</a></p>

    <p>or the following files in the Conduit source tree:</p>

    <ul>

    <li><a href="/LICENSE">LICENSE</a></li>

    <li><a href="/thirdparty_licenses.md">thirdparty_licenses.md</a></li>

    </ul>

    <h1>

    <a id="user-content-changelog" class="anchor" href="#changelog" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Changelog</h1>

    <ul>

    <li><a href="/CHANGELOG.md">Changelog</a></li>

    </ul>

    '
  stargazers_count: 113
  subscribers_count: 20
  topics:
  - hpc
  - scientific-computing
  - cpp
  - fortran
  - python
  - llnl
  - json
  - yaml
  - hdf5
  - radiuss
  - data-management
  updated_at: 1647037320.0
LLNL/radiuss-spack-testing:
  data_format: 2
  description: Gitlab CI automation of Spack testing with RADIUSS projects builds.
  filenames:
  - spack-environments/raja-suite/spack.yaml
  - spack-environments/radiuss/spack.yaml
  full_name: LLNL/radiuss-spack-testing
  latest_release: null
  readme: '<h1>

    <a id="user-content-radiuss-spack-testing" class="anchor" href="#radiuss-spack-testing"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>RADIUSS
    Spack Testing</h1>

    <p>The RADIUSS project promotes and supports key High Performance Computing (HPC)
    open-source software developed at the LLNL. These tools and libraries cover a
    wide range of features a team would need to develop a modern simulation code targeting
    HPC plaftorms.</p>

    <p>RADIUSS Spack Testing is a sub-project from the RADIUSS initiative providing
    a

    testing infrastructure to test Spack Packages automatically in GitLab while

    tracking changes in Spack.</p>

    <p>Access the <a href="https://radiuss-spack-testing.readthedocs.io/" rel="nofollow">documentation</a>.</p>

    <h2>

    <a id="user-content-getting-started" class="anchor" href="#getting-started" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Started</h2>

    <p>The primary goal of this repo is to be used in Gitlab. The Gitlab CI configuration
    is such that it will use Spack pipeline feature to generate and run a pipeline
    that builds one of the environments in the <code>spack-environments</code> directory.</p>

    <p>The specific environment to be built is controlled by the CI variable <code>ENV_NAME</code>.</p>

    <h3>

    <a id="user-content-installing" class="anchor" href="#installing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>This project requires no installation.</p>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Please read <a href="https://github.com/LLNL/radiuss-spack-testing/CONTRIBUTING.md">CONTRIBUTING.md</a>
    for details on our code of conduct, and the process for submitting pull requests
    to us.</p>

    <h2>

    <a id="user-content-versioning" class="anchor" href="#versioning" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Versioning</h2>

    <p>version: 1.0.0</p>

    <p>TODO: Not even sure how to handle versioning here.</p>

    <h2>

    <a id="user-content-authors" class="anchor" href="#authors" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Adrien M Bernede</p>

    <p>See also the list of <a href="https://github.com/LLNL/radiuss-spack-testing/contributors">contributors</a>
    who participated in this project.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a>
    file for details</p>

    <p>All new contributions must be made under the MIT License.</p>

    <p>See <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (MIT)</p>

    <p>LLNL-CODE-793462</p>

    <h2>

    <a id="user-content-acknowledgments" class="anchor" href="#acknowledgments" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgments</h2>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics:
  - radiuss
  updated_at: 1638908320.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/perlmutter-e4s-22.02/spack.yaml
  - spack-configs/cori-e4s-21.02/prod/spack.yaml
  - spack-configs/cori-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/spack.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/cori-e4s-21.02/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml
  - spack-configs/cori-e4s-21.05/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-spack-infrastructure\" class=\"anchor\" href=\"\
    #spack-infrastructure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file.</p>\n<h2>\n<a id=\"user-content-spack-configuration\"\
    \ class=\"anchor\" href=\"#spack-configuration\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack Configuration</h2>\n<p>The\
    \ spack configuration can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<table>\n<thead>\n<tr>\n<th>system</th>\n\
    <th>status</th>\n<th>PIPELINE_NAME</th>\n<th>description</th>\n<th>spack.yaml</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>Perlmutter</td>\n<td><strong>IN-PROGRESS</strong></td>\n\
    <td><code>PERLMUTTER_SPACK_DEVELOP</code></td>\n<td>This spack configuration is\
    \ based on <code>spack@develop</code> branch to see what packages can be built.\
    \ We expect this pipeline will fail and we are not expected to fix build failure.\
    \ The main purpose of this project is to build as many packages across all the\
    \ compilers, mpi, blas providers of interest and see what works. Since we don't\
    \ know which package works during deployment, we will leverage data from this\
    \ pipeline to make informed decision what packages should be picked with given\
    \ compilers. This pipeline is our development and we should use this to experiment\
    \ new compilers. Note that we won't hardcode versions for packages since we want\
    \ to build with latest release. However we will hardcode externals depending on\
    \ how system is configured.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>IN-PROGRESS</strong></td>\n<td><code>CORI_SPACK_DEVELOP</code></td>\n\
    <td>This spack configuration will build E4S stack using spack <code>develop</code>\
    \ branch on Cori.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-spack-develop/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-spack-develop/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>IN-PROGRESS</strong></td>\n<td><code>CORI_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on Cori using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Gerty</td>\n<td><strong>IN-PROGRESS</strong></td>\n<td><code>GERTY_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on gerty using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11_DEPLOY</code></td>\n\
    <td>This spack configuration is deployment configuration for E4S/21.11. For more\
    \ details on this stack see  <a href=\"https://docs.nersc.gov/applications/e4s/perlmutter/21.11/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/perlmutter/21.11/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11</code></td>\n\
    <td>This spack configuration is used for development for building E4S/21.11 using\
    \ scheduled pipeline.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Muller</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>MULLER_E4S_21.11</code></td>\n\
    <td>This spack configuration was used to build E4S/21.11 on Muller using scheduled\
    \ pipeline. Once e4s/21.11 was built on Muller we followed up with building the\
    \ same spack configuration on Perlmutter.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.05\
    \ spack stack based on <a href=\"https://github.com/spack/spack/tree/e4s-21.05\"\
    >e4s-21.05</a> branch of spack. This stack can be accessed via <code>module load\
    \ e4s/21.05</code>.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration used for deployment purposes, this can be accessed via <code>module\
    \ load e4s/21.02</code> on Cori. For more details see <a href=\"https://docs.nersc.gov/applications/e4s/cori/21.02/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/21.02/</a>\n</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration that push to buildcache.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration that push to build cache using <code>spack ci</code>.  This\
    \ project lives in <a href=\"https://software.nersc.gov/NERSC/e4s-2010\" rel=\"\
    nofollow\">https://software.nersc.gov/NERSC/e4s-2010</a> and configuration was\
    \ copied over here.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration for Cori used for deployment purpose. This stack can be\
    \ accessed via <code>module load e4s/20.10</code>. This is documented at <a href=\"\
    https://docs.nersc.gov/applications/e4s/cori/20.10/\" rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/20.10/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml</a></td>\n\
    </tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-running-ci-pipelines\" class=\"\
    anchor\" href=\"#running-ci-pipelines\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>.</p>\n<table>\n<thead>\n\
    <tr>\n<th>System</th>\n<th>Runner Name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n</tr>\n<tr>\n<td>cori</td>\n\
    <td><code>cori-e4s</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    </tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n</tr>\n</tbody>\n\
    </table>\n<p>The runner configuration files are located in <code>~/.gitlab-runner</code>\
    \ for user <strong>e4s</strong>.</p>\n<p>The production pipelines are triggered\
    \ via web-interface which requires approval from a project maintainer. Production\
    \ pipelines should be run when we need to do full redeployment of stack.</p>\n\
    <h2>\n<a id=\"user-content-troubleshooting-gitlab-runner\" class=\"anchor\" href=\"\
    #troubleshooting-gitlab-runner\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Troubleshooting gitlab runner</h2>\n\
    <p>You will need to login as <code>e4s</code> user via <code>collabsu</code> command.\
    \ This will prompt you for password which is your <strong>NERSC password</strong>\
    \ for your username not <strong>e4s</strong> user.</p>\n<pre><code>collabsu e4s\n\
    </code></pre>\n<p>Once you are logged in, you can login to the desired system\
    \ to restart the runner. You can check the runner status by navigating to <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\" rel=\"\
    nofollow\">Settings &gt; CI/CD &gt; Runners</a>. If gitlab runner is down you\
    \ will need to restart the runner which is located in <code>$HOME/cron</code>\
    \ directory for e4s user.</p>\n<p>For instance, to access muller you will need\
    \ to login to Cori/DTN nodes and run <code>ssh login.muller.nersc.gov</code>.</p>\n\
    <p>The <code>gitlab-runner</code> command should be accessible with e4s user.\
    \ To register a runner you can run <code>gitlab-runner register</code> and follow\
    \ the prompt. The runner configuration will be written to <code>~/.gitlab-runner/config.toml</code>\
    \ however we recommend you create a separate config.toml or copy the file to separate\
    \ file. For instance if you want to register a runner for muller you can set <code>gitlab-runner\
    \ register -c ~/.gitlab-runner/muller.config.toml</code> when registering the\
    \ runner and it will write the runner configuration to <code>~/.gitlab-runner/muller.config.toml</code>.\
    \ For more details regarding runner register please see <a href=\"https://docs.gitlab.com/runner/register/\"\
    \ rel=\"nofollow\">https://docs.gitlab.com/runner/register/</a></p>\n<p>To restart\
    \ a runner you can run the script based on runner type</p>\n<pre><code># restart\
    \ gerty runner\nbash $HOME/cron/restart-gerty.sh\n\n# restart muller runner\n\
    bash $HOME/cron/restart-muller.sh\n\n# restart perlmutter runner\nbash $HOME/cron/restart-perlmutter.sh\n\
    \n# restart cori runner\nbash $HOME/cron/restart-cori.sh\n</code></pre>\n<p>In\
    \ order to access gerty, you will need to login to data transfer node and then\
    \ login to gerty as follows</p>\n<pre><code>ssh dtn01.nersc.gov\ncollabsu e4s\n\
    ssh gerty\n</code></pre>\n<h2>\n<a id=\"user-content-current-challenges\" class=\"\
    anchor\" href=\"#current-challenges\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have externals set to packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2>\n<a id=\"user-content-contact\" class=\"anchor\" href=\"#contact\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 1
  subscribers_count: 15
  topics: []
  updated_at: 1646024620.0
NOAA-EMC/WW3:
  data_format: 2
  description: WAVEWATCH III
  filenames:
  - model/ci/spack.yaml
  full_name: NOAA-EMC/WW3
  latest_release: 6.07.1
  readme: "<h1>\n<a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ href=\"#the-wavewatch-iii-framework\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2>\n<a id=\"user-content-general-features\" class=\"anchor\" href=\"#general-features\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2>\n<a id=\"user-content-disclaimer\" class=\"anchor\" href=\"#disclaimer\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 169
  subscribers_count: 42
  topics: []
  updated_at: 1647383876.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/apps/nco-wcoss2/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-stack" class="anchor" href="#spack-stack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>spack-stack is a collaborative effort between the NOAA Environmental Modeling
    Center (EMC), the UCAR Joint Center for Satellite Data Assimilation (JCSDA), and
    the Earth Prediction Innovation Center (EPIC). spack-stack is designed to support
    the various applications of the supporting agencies such as the Unified Forecast
    System (UFS) or the Joint Effort for Data assimilation Integration (JEDI). The
    stack can be installed on a range of platforms, from Linux and macOS laptops to
    HPC systems, and comes pre-configured for many systems. Users can install the
    necessary packages for a particular application and later add the missing packages
    for another application without having to rebuild the entire stack.</p>

    <p><a href="https://github.com/spack/spack">spack</a> is a community-supported,
    multi-platform, Python-based package manager originally developed by the Lawrence
    Livermore National Laboratory (LLNL; <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager"
    rel="nofollow">https://computing.llnl.gov/projects/spack-hpc-package-manager</a>).
    It is provided as a submodule so that a stable version can be referenced. <a href="https://spack.readthedocs.io/en/latest/"
    rel="nofollow">See the Spack Documentation for more information</a></p>

    <p>spack-stack is mainly a collection of Spack configuration files, but provides
    a few Python scripts to simplify the installation process:</p>

    <ul>

    <li>

    <code>create-env.py</code> is provided to copy common, site-specific, and application-specific
    configuration files into a coherent Spack environment</li>

    <li>

    <code>meta_modules/setup_meta_modules.py</code> creates compiler, MPI and Python
    meta-modules for a convenient setup of a user environment using modules (currently
    lua only)</li>

    </ul>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>Kyle Gerheiser (@kgerheiser), NOAA-EMC</li>

    <li>Dom Heinzeller (@climbfuji), JCSDA</li>

    <li>not yet appointed, EPIC</li>

    </ul>

    <p>Ready-to-use spack-stack installations are available on the following platforms:</p>

    <table>

    <thead>

    <tr>

    <th>System</th>

    <th>Location</th>

    <th>Maintained by</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>unknown system</td>

    <td>unknown location</td>

    <td>unknown maintainer</td>

    </tr>

    </tbody>

    </table>

    <p>For questions or problems, please consult the currently open <a href="https://github.com/noaa-emc/spack-stack/issues">issues</a>
    and the <a href="https://github.com/noaa-emc/spack-stack/discussions">current
    and past discussions</a> first.</p>

    <p><strong>Note. spack-stack is in early development and not yet ready for use.
    Instructions may be incomplete or invalid.</strong></p>

    <h2>

    <a id="user-content-quickstart" class="anchor" href="#quickstart" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Quickstart</h2>

    <pre><code>git clone https://github.com/NOAA-EMC/spack-stack.git

    cd spack-stack


    # Ensure Python 3.7+ is available and the default before sourcing spack


    # Sources Spack from submodule and sets ${SPACK_STACK_DIR}

    source setup.sh


    # See a list of sites and apps

    ./create-env.py -h


    # Creates a pre-configured Spack environment in envs/&lt;app&gt;.&lt;site&gt;

    # Copies site-specific, application-specific, and common config files into the
    environment directory

    ./create-env.py --site hera --app jedi-fv3 --name jedi-fv3.hera


    # Activate the newly created environment

    # optional: decorate the command line prompt using -p

    spack env activate [-p] envs/jedi-fv3.hera


    # Optionally edit config files (spack.yaml, packages.yaml compilers.yaml, site.yaml)

    cd envs/jedi-fv3.hera

    emacs spack.yaml


    # Process the specs and install

    # note: both steps will take some time!

    spack concretize

    spack install


    # Create lua module files

    spack module lmod refresh


    # Create meta-modules for compiler, mpi, python

    ./meta_modules/setup_meta_modules.py

    </code></pre>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 1
  subscribers_count: 5
  topics: []
  updated_at: 1644294917.0
NOAA-GFDL/AM4:
  data_format: 2
  description: null
  filenames:
  - container/spack_intel_gfdl_model.yaml
  full_name: NOAA-GFDL/AM4
  latest_release: '2021.03'
  readme: '<h1>

    <a id="user-content-gfdl-am4-model" class="anchor" href="#gfdl-am4-model" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL AM4 Model</h1>

    <p><a href="https://zenodo.org/badge/latestdoi/102487636" rel="nofollow"><img
    src="https://camo.githubusercontent.com/878db836b9000fd7d9ff531257cade7343f3a3fdf8f764b5a7f1e8ef6ccc6abe/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3130323438373633362e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/102487636.svg" style="max-width:100%;"></a></p>

    <p>This repository includes the public release of the GFDL AM4 model

    code.  The AM4 model is described in the

    <a href="https://doi.org/10.1002/2017MS001208" rel="nofollow">two</a>

    <a href="https://doi.org/10.1002/2017MS001209" rel="nofollow">articles</a> published
    in the

    <a href="https://agupubs.onlinelibrary.wiley.com/journal/19422466" rel="nofollow">Journal
    of Advances in Modeling Earth Systems

    (JAMES)</a>.

    More information on the model and access to the output is available on

    the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">AM4
    data and code

    site</a> at the

    <a href="https://www.gfdl.noaa.gov" rel="nofollow">Geophysical Fluid Dynamics
    Laboratory

    (GFDL)</a>.</p>

    <p>The layout of this package includes the following directories:</p>

    <ul>

    <li>src - The source code for the AM4 model</li>

    <li>exec - The build directory with Makefiles for building the model executable</li>

    <li>run - Sample run script and updated files needed for running</li>

    <li>analysis - Sample analysis scripts</li>

    </ul>

    <h2>

    <a id="user-content-cloning-instructions" class="anchor" href="#cloning-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cloning
    Instructions</h2>

    <p>This repository uses <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"
    rel="nofollow">git

    submodules</a> to

    point to other repositories.  Thus, care should be taken when cloning,

    and updating the source to ensure all source.  To obtain all source,

    use the following git command</p>

    <pre><code>git clone --recursive https://github.com/NOAA-GFDL/AM4.git

    </code></pre>

    <p>The <code>--recursive</code> option to <code>git clone</code> instructs git
    to recursively

    clone all submodules.  In the event the repository was not cloned

    using the <code>--recursive</code> option, the following step must be taken to

    obtain all sources:</p>

    <pre><code># From within the AM4 parent directory

    git submodule update --init --recursive

    </code></pre>

    <h2>

    <a id="user-content-source-code" class="anchor" href="#source-code" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Code</h2>

    <p>All model source is contained in the <a href="src">src</a> directory.  GFDL

    tracks code using the git version control system.  This package

    includes a single version of the following GFDL model components.  The

    git hash listed corresponds to the commit hash in the internal GFDL

    git repository.</p>

    <table>

    <thead>

    <tr>

    <th>Component</th>

    <th>Commit Hash</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>atmos_drivers</td>

    <td>5ee95d6abf0879594551dd7e6635dff4004c4010</td>

    </tr>

    <tr>

    <td>atmos_param</td>

    <td>2e94acfd8621e85216bf822c395a8c3f15a511a5</td>

    </tr>

    <tr>

    <td>atmos_shared</td>

    <td>a557d4d7bab033ef1ad1d400a62fe07a97ccb477</td>

    </tr>

    <tr>

    <td>ice_param</td>

    <td>1553c8bc4f9a66791c89367b6f327147523155ed</td>

    </tr>

    <tr>

    <td>ice_sis</td>

    <td>ccc7328dcd79706dd5c17c8bab660222886fc80b</td>

    </tr>

    <tr>

    <td>land_lad2</td>

    <td>a220288ecb289bf9d793d051fc5076072874ce07</td>

    </tr>

    </tbody>

    </table>

    <p>The following components are available in the

    <a href="https://github.com/NOAA-GFDL">NOAA-GFDL</a> github organization:</p>

    <ul>

    <li><a href="https://github.com/NOAA-GFDL/MOM6">MOM6</a></li>

    <li><a href="https://github.com/NOAA-GFDL/coupler">coupler</a></li>

    <li>

    <a href="https://github.com/NOAA-GFDL/FMS">FMS</a> (as <a href="src/shared">shared</a>)</li>

    <li>

    <a href="https://github.com/NOAA-GFDL/GFDL_atmos_cubed_sphere">GFDL_atmos_cubed_sphere
    (tag AM4.0)</a> (as <a href="src/atmos_cubed_sphere">atmos_cubed_sphere</a>)</li>

    </ul>

    <h2>

    <a id="user-content-building-am4" class="anchor" href="#building-am4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building AM4</h2>

    <p>###Containers

    The <a href="container">container folder</a> provides example Dockerfiles and
    Signularity

    definition files to use to build AM4 containers using either GCC/GFORTAN or

    Intel oneAPI. There is a script that can be used to build the intel

    singularity containers, and the first step of this script can be used with the

    other GFDL climate models.</p>

    <h3>

    <a id="user-content-from-source" class="anchor" href="#from-source" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>From source</h3>

    <p>The <a href="exec">exec</a> directory contains Makefiles that can be used to

    build the AM4 executable.  These Makefiles were generated using the

    <a href="https://github.com/NOAA-GFDL/mkmf">Make Makefile (mkmf)</a> program.

    Included in the exec direcgtory is a sample make template file for the

    Intel compilers (<a href="exec/templates/intel.mk">intel.mk</a>).  This make

    template can be used on any system with a relatively recent version of

    the Intel compilers, the netCDF 4 library and the MPICH2 MPI library.

    Included in the <a href="exec/templates/intel.mk">intel.mk</a> file are

    additional settings that can be modified during the build.</p>

    <p>To run the default build (-O3 -msse2), go to the exec directory and

    enter the command</p>

    <pre><code>make

    </code></pre>

    <p>If you would like to change some of the compiler options, there are several
    different

    options to add to the make command.  For example</p>

    <pre><code>make ISA=-xhost BLD_TYPE=REPRO

    </code></pre>

    <p>will replace -msse with -xhost and -O3 with -O2.  The three options for

    <code>BLD_TYPE</code> are<br>

    <code>PROD</code> (-O3)<br>

    <code>REPRO</code> (-O2)<br>

    <code>DEBUG</code> (-O0 and other traps)<br>

    All of the make line options can be

    found in the <a href="exec/templates/intel.mk">intel.mk</a> file.</p>

    <h2>

    <a id="user-content-obtaining-the-input-data" class="anchor" href="#obtaining-the-input-data"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining
    the input data</h2>

    <p>The input data required for running the AM4 model can be found on

    <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">GFDL''s
    data

    portal</a> .</p>

    <p>The file <code>AM4.tar.gz</code> contains a configured run directory to run
    a

    sample experiment of the AM4 model.  Included in the tar file is a

    README.AM4_run with more instructions on how to configure the AM4 run

    directory.</p>

    <p>On Linux systems, the <code>wget</code> command is usually sufficient to download
    the data

    file:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz

    </code></pre>

    <p>To ensure the file downloaded is complete and not corrupted, download one of
    the two files:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sha256

    wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sig

    </code></pre>

    <p>and run the following command that corresponds to the signature file downloaded:</p>

    <pre><code>sha256sum -c AM4_run.tar.gz.sha256

    </code></pre>

    <pre><code>gpg --verify AM4_run.tar.gz.sig

    </code></pre>

    <h2>

    <a id="user-content-running-am4" class="anchor" href="#running-am4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running AM4</h2>

    <p>Included in the run directory is a sample run script for reference.

    To run the AM4 sample experiment, first download the data file

    mentioned in <a href="#obtaining-the-input-data">Obtaining the Input data</a>

    section.  Replace diag_table and input.nml in the top level of the

    untar''d directory with the corresponding files in the run directory

    of this repository. Modify the variables in the configuration section

    in the sample run script, and then run the script.</p>

    <p>The sample data and run script are configured to run on 216

    processors.  To run on a different number of processors, or modify the

    experiment, refer to the <code>README.AM4_run</code> file included in the AM4

    data tarball.</p>

    <p>Note: The <code>input.nml</code> file (found in the AM4 data tarball) contains

    Fortran namelists and namelist variables that modify, at run time, the

    model.  To learn more about the settings in the <code>input.nml</code> file,

    please refer to source code where the namelist/variable are defined.</p>

    <h2>

    <a id="user-content-analysis-scripts" class="anchor" href="#analysis-scripts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analysis
    Scripts</h2>

    <p>Some of the climate analysis scripts run at NOAA GFDL and used in the

    AM4 documentation papers are located in the analysis directory.

    Within each analysis suite, is a <a href="https://jupyter-notebook.readthedocs.io/en/stable/"
    rel="nofollow">jupyter

    notebook</a>, both

    readable and runnable from your local jupyter environment, provided

    all dependencies are installed.</p>

    <p>E.g.</p>

    <ul>

    <li><a href="analysis/cjs1/radiation_atmos_av_mon/radiation_atmos_av_mon.ipynb">Radiation
    processor</a></li>

    <li><a href="analysis/bw/bw_atmos_cru_ts_a1r/bw_atmos_monthly_cru_ts.1980-2014.ipynb">Long-term
    DJF seasonal mean</a></li>

    <li><a href="analysis/bw/bw_atmos_zm_atl_pac_a1r/bw_atmos_atl_pac.1980-2014.ipynb">Zonal_mean_zonal_wind_stress</a></li>

    <li><a href="analysis/pcmdimetrics/portraitPlot-AM4.AMIP.ipynb">PCMDI Metrics
    Portrait Plot</a></li>

    </ul>

    <h2>

    <a id="user-content-model-output-and-other-references" class="anchor" href="#model-output-and-other-references"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model
    output and Other References</h2>

    <p>Please refer to the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/"
    rel="nofollow">AM4 data and code

    site</a> for details

    about where to find model and OBS data used in the papers.</p>

    <p>For all analysis figures and pertaining data, please use the AM4

    documentation papers as the original reference.</p>

    <p>Please direct your questions and feedback to

    <a href="mailto:gfdl.climate.model.info@noaa.gov">gfdl.climate.model.info@noaa.gov</a></p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an ''as is'' basis and the user assumes responsibility for

    its use.  DOC has relinquished control of the information and no

    longer has responsibility to protect the integrity, confidentiality,

    or availability of the information.  Any claims against the Department

    of Commerce stemming from the use of its GitHub project will be

    governed by all applicable Federal law.  Any reference to specific

    commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply

    their endorsement, recommendation or favoring by the Department of

    Commerce.  The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <p>This project code is made available through GitHub but is managed by

    NOAA-GFDL at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 11
  subscribers_count: 7
  topics:
  - fortran
  - jupyter-notebook
  - shell-script
  - ncl
  updated_at: 1645229928.0
NOAA-GFDL/ESM4:
  data_format: 2
  description: null
  filenames:
  - container/spack_intel_gfdl_model.yaml
  full_name: NOAA-GFDL/ESM4
  latest_release: '2021.03'
  readme: '<h1>

    <a id="user-content-earth-system-model-4" class="anchor" href="#earth-system-model-4"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Earth
    System Model 4</h1>

    <h2>

    <a id="user-content-what-is-included" class="anchor" href="#what-is-included"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>What
    Is Included</h2>

    <ul>

    <li>[src]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/src">https://github.com/NOAA-GFDL/ESM4/tree/master/src</a>)
    source code for the ESM4 model (all code is in submodules)</li>

    <li>[exec]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/exec">https://github.com/NOAA-GFDL/ESM4/tree/master/exec</a>)
    Makefiles to compile the code</li>

    <li>[run]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/run">https://github.com/NOAA-GFDL/ESM4/tree/master/run</a>)
    Simple run script</li>

    </ul>

    <h2>

    <a id="user-content-cloning" class="anchor" href="#cloning" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Cloning</h2>

    <p>To clone the ESM4 model please use the recursive option</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive git@github.com:NOAA-GFDL/ESM4.git
    </pre></div>

    <p>or</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/NOAA-GFDL/ESM4.git</pre></div>

    <h2>

    <a id="user-content-compiling" class="anchor" href="#compiling" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compiling</h2>

    <h3>

    <a id="user-content-building-the-container" class="anchor" href="#building-the-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>The <a href="container">container folder</a> provides example Dockerfiles and
    Signularity

    definition files to use to build AM4 containers using either GCC/GFORTAN or

    Intel oneAPI. There is a script that can be used to build the intel

    singularity containers, and the first step of this script can be used with the

    other GFDL climate models.</p>

    <h3>

    <a id="user-content-building-from-source" class="anchor" href="#building-from-source"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    from source</h3>

    <p>This model was originally compiled and run with the intel16 compiler.

    It is recommended that you compile with an intel compiler.</p>

    <p>Compiling assumes that you have an intel compiler, MPI (impi, mpich,

    openmpi, etc), netcdf, and hdf5 in your LD_LIBRARY_PATH and LIBRARY_PATH.

    It is also assumed that nf-config and nc-config are in your path.

    If you work on a machine with modules, you may need to load these

    packages into your environment.</p>

    <p>Makefiles have been included in the

    <a href="https://github.com/NOAA-GFDL/ESM4/tree/master/exec">exec/</a> folder.

    There are several option for compiling, which can be found in the

    <a href="https://github.com/NOAA-GFDL/ESM4/blob/master/exec/templates/intel.mk">template/intel.mk</a>.<br>

    You may need to edit the template/intel.mk to update the compiler names

    or add any CPPDEF options specific for your system.

    The most common compile with optimizations on and with openmp would be</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    <span class="pl-c1">exec</span>

    make OPENMP=on</pre></div>

    <p>If you would like to compile with <em>-O2</em> instead of <em>-O3</em> do</p>

    <div class="highlight highlight-source-shell"><pre>make REPRO=on OPENMP=on</pre></div>

    <p>To compile with <em>-O0</em> and debug flags do</p>

    <div class="highlight highlight-source-shell"><pre>make BLD_TYPE=DEBUG OPENMP=on</pre></div>

    <p>Compiling with openMP is optional.</p>

    <p>Here are examples of how to compile the model on various systems:</p>

    <p>gaea (NOAA RDHPCS cray system)</p>

    <div class="highlight highlight-source-shell"><pre>module load intel

    module load cray-netcdf

    module load cray-hdf5

    git clone --recursive git@github.com:NOAA-GFDL/ESM4.git

    <span class="pl-c1">cd</span> ESM4/exec

    make MKL_LIBS=<span class="pl-s"><span class="pl-pds">"</span>none<span class="pl-pds">"</span></span>
    OPENMP=y</pre></div>

    <p>Compiling on orion (MSU)</p>

    <div class="highlight highlight-source-shell"><pre>module load intel impi netcdf
    hdf5

    <span class="pl-k">export</span> LIBRARY_PATH=<span class="pl-smi">${LIBRARY_PATH}</span>:<span
    class="pl-smi">${LD_LIBRARY_PATH}</span>

    git clone --recursive git@github.com:NOAA-GFDL/ESM4.git

    <span class="pl-c1">cd</span> ESM4/exec

    make OPENMP=on</pre></div>

    <h2>

    <a id="user-content-model-running" class="anchor" href="#model-running" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Model running</h2>

    <p>A work directory needed for running the model can be obtained from

    <a href="ftp://data1.gfdl.noaa.gov/users/ESM4/ESM4Documentation/GFDL-ESM4/inputData/ESM4_rundir.tar.gz"
    rel="nofollow">ftp://data1.gfdl.noaa.gov/users/ESM4/ESM4Documentation/GFDL-ESM4/inputData/ESM4_rundir.tar.gz</a></p>

    <p>The directory contains input.nml as the namelist, various input tables needed

    for running the model, and model input files in a folder called INPUT/.  There

    is also a directory named RESTART/ that should be empty at the beginning of

    each run.</p>

    <p>There is a skeleton of a run script named <a href="https://github.com/NOAA-GFDL/ESM4/blob/master/run/ESM4_run.sh">run/ESM4_run.sh</a>.  You
    must update this

    script to run the model.  Include a path to the work directory and the executable.

    You should also update the program you need to run the model on your system.  The

    default for this script is <code>srun</code>.</p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    '
  stargazers_count: 6
  subscribers_count: 5
  topics:
  - gfdl
  - ems
  - ems4
  - fms
  - climate
  - model
  - fortran
  updated_at: 1641768586.0
NOAA-GFDL/HPC-ME:
  data_format: 2
  description: null
  filenames:
  - apps/spack_intel_gfdl_model.yaml
  - spack_gnu.yaml
  - apps/spack_intel_ufs_model.yaml
  - spack_intel_ubuntu20.04_e4s.yaml
  - spack_intel_ubuntu.yaml
  full_name: NOAA-GFDL/HPC-ME
  latest_release: null
  readme: '<h1>

    <a id="user-content-hpc-me-hpc-portable-containers-for-model-environments" class="anchor"
    href="#hpc-me-hpc-portable-containers-for-model-environments" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPC-ME: HPC Portable
    Containers for Model Environments</h1>

    <h2>

    <a id="user-content-contents" class="anchor" href="#contents" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contents</h2>

    <ul>

    <li><a href="#what-is-hpc-me">What is HPC-ME</a></li>

    <li><a href="#list-of-current-compilers">List of current compilers/MPI/OS</a></li>

    <li><a href="#list-of-current-libraries">List of current libraries</a></li>

    <li><a href="#how-to-build">How to build</a></li>

    <li><a href="#how-to-use">How to use</a></li>

    <li><a href="#gfdl-example">GFDL example</a></li>

    <li><a href="#planned-improvements">Planned improvements</a></li>

    </ul>

    <h2>

    <a id="user-content-what-is-hpc-me" class="anchor" href="#what-is-hpc-me" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>What is HPC-ME</h2>

    <p>HPC Portable Container - Model Environments is a set of Dockerfiles, Singularity
    Definition files, and containers to provide portable model environments for scientific
    applications that require the same set of libraries.  The ultimate goal is to
    have a community-based list of libraries that are needed for compiling, executing,
    and post-processing earth science models.  We all use many of the same underlying
    libraries, and by working together we can agree upon a community-based approach
    to making container usage as standardized as possible.</p>

    <h2>

    <a id="user-content-list-of-current-compilersmpios" class="anchor" href="#list-of-current-compilersmpios"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>List
    of current compilers/MPI/OS</h2>

    <p>For each container, there is a full version that contains the programming environment
    and a smaller runtime environment that can be used to run compiled executables.
    (The runtime container definition files will be added soon.)

    #- <a href="Dockerfile_gnu_ubuntu20.04">gcc 8/mpich/ubuntu 20.04</a></p>

    <ul>

    <li><a href="Dockerfile_gnu_rhel8">gcc 8/mpich/RHEL8</a></li>

    <li>

    <a href="Dockerfile_intel_ubuntu18.04">intel oneAPI 2022.1/mpich(impi)/ubuntu
    18.04</a>

    #- <a href="Dockerfile_intel_centos8">intel oneAPI 2021.4/mpich(impi)/centos 8</a>

    </li>

    </ul>

    <h2>

    <a id="user-content-list-of-current-libraries" class="anchor" href="#list-of-current-libraries"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>List
    of current libraries</h2>

    <p>This is the current list of most of the libraries used in the HPC-ME containers
    (We are trying to keep this up-to-date).

    The complete lit should be found in the respective YAML file.</p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#automake"
    rel="nofollow">automake@1.16.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bacio" rel="nofollow">bacio@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#berkeley-db"
    rel="nofollow">berkeley-db@18.1.40</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bison" rel="nofollow">bison@3.7.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bzip2" rel="nofollow">bzip2@1.0.8</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cmake" rel="nofollow">cmake@3.21.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#crtm" rel="nofollow">crtm@2.3.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#curl" rel="nofollow">curl@7.78.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#diffutils"
    rel="nofollow">diffutils@3.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#esmf" rel="nofollow">esmf@8.1.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#expat" rel="nofollow">expat@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2" rel="nofollow">g2@3.4.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2tmpl"
    rel="nofollow">g2tmpl@1.10.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gdbm" rel="nofollow">gdbm@1.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gsl" rel="nofollow">gsl@2.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#hdf5" rel="nofollow">hdf5@1.10.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#intel-mpi"
    rel="nofollow">intel-mpi@2019.10.317</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip" rel="nofollow">ip@3.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip2" rel="nofollow">ip2@1.1.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#jasper"
    rel="nofollow">jasper@2.0.32</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libbsd"
    rel="nofollow">libbsd@0.11.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libiconv"
    rel="nofollow">libiconv@1.16</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libjpeg-turbo"
    rel="nofollow">libjpeg-turbo@2.1.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libmd" rel="nofollow">libmd@1.0.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libpng"
    rel="nofollow">libpng@1.6.37</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libsigsegv"
    rel="nofollow">libsigsegv@2.13</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libxml2"
    rel="nofollow">libxml2@2.9.12</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libyaml"
    rel="nofollow">libyaml@0.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#m4" rel="nofollow">m4@1.4.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nasm" rel="nofollow">nasm@2.15.05</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ncurses"
    rel="nofollow">ncurses@6.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nemsio"
    rel="nofollow">nemsio@2.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-c"
    rel="nofollow">netcdf-c@4.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-fortran"
    rel="nofollow">netcdf-fortran@4.5.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#numactl"
    rel="nofollow">numactl@2.0.14</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#openssl"
    rel="nofollow">openssl@1.1.1l</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#parallel-netcdf"
    rel="nofollow">parallel-netcdf@1.12.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#perl" rel="nofollow">perl@5.34.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#pkgconf"
    rel="nofollow">pkgconf@1.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#readline"
    rel="nofollow">readline@8.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sfcio" rel="nofollow">sfcio@1.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sigio" rel="nofollow">sigio@2.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sp" rel="nofollow">sp@2.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#udunits"
    rel="nofollow">udunits@2.2.28</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3emc" rel="nofollow">w3emc@2.9.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3nco" rel="nofollow">w3nco@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#wrf-io"
    rel="nofollow">wrf-io@1.2.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xerces-c"
    rel="nofollow">xerces-c@3.2.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xz" rel="nofollow">xz@5.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#zlib" rel="nofollow">zlib@1.2.11</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#lmod" rel="nofollow">lmod@8.5.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nccmp" rel="nofollow">nccmp@1.8.6.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nco" rel="nofollow">nco@4.7.9</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-netcdf"
    rel="nofollow">cray-netcdf@4.6.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-hdf5"
    rel="nofollow">cray-hdf5@1.10.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#uberftp"
    rel="nofollow">uberftp</a></li>

    </ul>

    <h2>

    <a id="user-content-how-to-build" class="anchor" href="#how-to-build" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to build</h2>

    <p><strong>We plan to make this step optional soon.</strong> In order to build
    the Docker images, you will need access to a computer with root-like access, and
    either docker or singularity installed. If you do not have root-like access to
    a suitable machine, you can still run images that were already created (e.g. on
    Docker hub), and we plan on hosting runnable Docker images along with the Dockerfiles
    in this repository soon. If you have root-like access and docker, start by choosing
    one of the currently supported model environments from the list above. Then build
    the Docker container from the Dockerfile using docker build; for example, to build
    the gcc8/mpich/ubuntu18 container:</p>

    <pre><code>docker build --file Dockerfile_gnu_ubuntu20.04 . --tag hpc-me.ubuntu.gnu

    </code></pre>

    <p>The build process takes approximately 2-3 hours, as the packages are downloaded
    and compiled using Spack. After a successful build, you will see that the image
    was built and tagged successfully:</p>

    <pre><code>Successfully built 90a878af77b4

    Successfully tagged hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>Then, you may run the container using docker or singularity on the same host.
    To run the image on a different machine, pushing the image to Docker Hub is recommended.
    Note that you will need a DockerHub account to do this (replace USER with your
    Docker user ID in the examples below). For example:</p>

    <pre><code>docker tag hpc-me.rhel8.gnu USER/hpc-me.rhel8.gnu

    docker login

    docker push USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <h2>

    <a id="user-content-how-to-use" class="anchor" href="#how-to-use" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to use</h2>

    <p>We plan to make improvements on this process. Also, while we plan on making
    Docker images available on the GitHub container registry, currently you must build
    the images yourself. Please start with the <a href="#how-to-build">Build instructions</a>
    to generate a Docker image with your desired OS/compiler HPC-ME environment. Then
    you may run the container using docker or singularity; singularity is more likely
    than docker to be available on HPC environments.</p>

    <p>The usage documentation consists of some general notes on serial/parallel usage,
    files inside and outside the container, downloading the containers, and then specific
    usage scenarios:</p>

    <ul>

    <li><a href="#serial-applications-using-docker">Serial applications using docker</a></li>

    <li><a href="#serial-applications-using-singularity">Serial applications using
    singularity</a></li>

    <li><a href="#parallel-applications-using-singularity">Parallel applications using
    singularity</a></li>

    </ul>

    <h3>

    <a id="user-content-serial-and-parallel-usage" class="anchor" href="#serial-and-parallel-usage"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    and parallel usage</h3>

    <p>HPC-ME containers are intended for both serial and parallel applications. Serial
    applications include compiling model executables, generating input grids, and
    post-processing model output. Earth system, climate, and weather models require
    parallelism to run efficiently, and use one of the Message Passage Interface (MPI)
    implementations OpenMPI, Intel MPI, or mpich. GCC-based HPC-ME containers use
    the mpich-based MPI library, which is widely available on most HPC sites, and
    the Intel-based containers contain both mpich and Intel MPI.</p>

    <h3>

    <a id="user-content-notes-on-filesystems-and-writing-files" class="anchor" href="#notes-on-filesystems-and-writing-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Notes
    on filesystems and writing files</h3>

    <p>We recommend not saving or modifying files within the environment container,
    and instead create and modify files on your regular filesystem. To do this, you
    will need to connect your filesystem to your container using bind mounts.</p>

    <h3>

    <a id="user-content-downloading-containers-and-managing-images-on-the-filesystem"
    class="anchor" href="#downloading-containers-and-managing-images-on-the-filesystem"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Downloading
    containers and managing images on the filesystem</h3>

    <p>Once you have pushed your images to DockerHub, you will need to download them
    before using. In the examples below, replace USER with your Docker Hub ID. If
    using docker,</p>

    <pre><code>docker pull USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity,</p>

    <pre><code>singularity pull docker://USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity, the image file (SIF format) is saved to the current working
    directory</p>

    <pre><code>&gt; ls *.sif

    -rwxr-xr-x 532M Dec 10 16:09 hpc-me.rhel8.gnu_latest.sif*

    </code></pre>

    <p>If using docker, the downloaded image is handled by the central docker service.</p>

    <h3>

    <a id="user-content-serial-applications-using-docker" class="anchor" href="#serial-applications-using-docker"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    applications using docker</h3>

    <p>You may activate an interactive shell within the desired HPC-ME container using
    docker. After running the container, the compilers and tools available within
    the container will be accessible in your PATH; e.g.</p>

    <pre><code>&gt; docker run -it hpc-me.rhel8.gnu:latest


    [root@0d2cf64e1175 /]# which nf-config

    /opt/view/bin/nf-config


    [root@0d2cf64e1175 /]# nf-config --version

    netCDF-Fortran 4.5.3


    [root@0d2cf64e1175 /]# nf-config --cflags

    -I/opt/software/linux-rhel8-x86_64/gcc-8.4.1/netcdf-fortran-4.5.3-g5qfkdlp36unt2s4j4wyrc6heh2sa64n/include

    </code></pre>

    <h3>

    <a id="user-content-serial-applications-using-singularity" class="anchor" href="#serial-applications-using-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    applications using singularity</h3>

    <p>Singularity can run Docker images and is more likely to be available on HPC
    environments. As with docker run, the HPC-ME tools and compilers are available
    in the shell, somewhat similar to loading a set of Environment Modules prepared
    by site administrators.</p>

    <pre><code>&gt;singularity run hpc-me.rhel8.gnu_latest.sif


    Singularity&gt; which nf-config

    /opt/view/bin/nf-config


    Singularity&gt; nf-config --version

    netCDF-Fortran 4.5.3

    </code></pre>

    <h3>

    <a id="user-content-parallel-applications-using-singularity" class="anchor" href="#parallel-applications-using-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Parallel
    applications using singularity</h3>

    <p>HPC-ME containers can provide the runtime environment for MPI applications.
    For instance, one could compile an MPI application using the instructions above
    using one of the HPC-ME development containers; and then run the application using
    the corresponding runtime HPC-ME container.</p>

    <p>Please note that we are continuing to improve the usability of HPC-ME containers
    as well as provide more usage examples.</p>

    <p>Usually, GFDL climate models are run on gaea by submitting a runscript to the
    Slurm scheduler. The runscript loads needed runtime Environment Modules, prepares
    input directories and files, and executes the MPI executable using srun. The HPC-ME
    containers provide the necessary runtime environment, obviating the need for loading
    Environment Modules. Currently, our approach for using the HPC-ME containers is
    as follows:</p>

    <ol>

    <li>Create a new container, starting with the desired HPC-ME runtime container</li>

    <li>Add the MPI-compiled executable to the container filesystem</li>

    <li>Set the MPI-compiled executable to as the container''s command (so that when
    the container is run the MPI executable within the container runs)</li>

    <li>Run the singularity container SIF file using srun within the runscript, replacing
    the traditional MPI executable.</li>

    </ol>

    <ul>

    <li>Replace "srun executable.x" with "srun singularity run container.SIF"</li>

    <li>Add --mpi=pmi2 to the srun call, which connects the system MPI to the container
    MPI to the singularity run call</li>

    <li>Bind the working directory so that the container has access to the input files
    and can write output files (singularity run -B=/path/to/workdir)</li>

    </ul>

    <ol start="5">

    <li>Submit the modified runscript to the scheduler</li>

    </ol>

    <p>We plan to provide more examples and usage scenarios, such as using the HPC-ME
    containers as-is (i.e. not creating a new container as described above)</p>

    <h2>

    <a id="user-content-gfdl-example" class="anchor" href="#gfdl-example" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL example</h2>

    <p>An example of using an HPC-ME container with the GFDL FRE workflow can be found
    <a href="GFDL_EXAMPLE.md">here</a></p>

    <h2>

    <a id="user-content-planned-improvements" class="anchor" href="#planned-improvements"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Planned
    improvements</h2>

    <p>HPC-ME is a work in progress under active development, so please check back
    or follow the repository for more updates.</p>

    <h3>

    <a id="user-content-build-cache" class="anchor" href="#build-cache" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build cache</h3>

    <p>We are working to create a build cache for the libraries listed so that building
    the containers is quick and easy.</p>

    <h3>

    <a id="user-content-github-container-registry" class="anchor" href="#github-container-registry"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Github
    container registry</h3>

    <p>We are working to add CI capability to this repository, so that the containers
    will be automatically built and stored in the github container registry. This
    will make building unnecessary for most cases, though users may build the containers
    themselves if they wish (e.g. for custom modifications).</p>

    <h3>

    <a id="user-content-more-usage-examples-and-documentation-especially-for-mpi-applications"
    class="anchor" href="#more-usage-examples-and-documentation-especially-for-mpi-applications"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>More
    usage examples and documentation, especially for MPI applications</h3>

    <p>We are still learning how to best use the HPC-ME containers with MPI appliations,
    so please check back.</p>

    <h3>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h3>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    <p>This project code is made available through GitHub but is managed by NOAA-GFDL

    at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1639503120.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Configuration files for Spack at Pawsey
  filenames:
  - setonix/environments/env_python/spack.yaml
  - setonix/environments/env_wrf/spack.yaml
  - examples/joey_sprint/env_python_alt_non_consistent/spack.yaml
  - setonix/environments/env_s3_clients/spack.yaml
  - setonix/environments/env_benchmarking/spack.yaml
  - setonix/environments/env_astro/spack.yaml
  - setonix/environments/env_utils/spack.yaml
  - setonix/environments/env_io_libs/spack.yaml
  - setonix/environments/env_vis/spack.yaml
  - examples/joey_sprint/env_python/spack.yaml
  - setonix/environments/env_roms/spack.yaml
  - examples/joey/env5_python/spack.yaml
  - setonix/environments/env_num_libs/spack.yaml
  - setonix/environments/env_bio/spack.yaml
  - examples/joey_sprint/env_cmake/spack.yaml
  - setonix/environments/env_langs/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1>

    <a id="user-content-pawsey-spack-config" class="anchor" href="#pawsey-spack-config"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>pawsey-spack-config</h1>

    <p>Configuration files for Spack at Pawsey.</p>

    <h2>

    <a id="user-content-setonix-setup" class="anchor" href="#setonix-setup" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setonix setup</h2>

    <p>This can be found in the <code>setonix/</code> directory.<br>

    See <code>README.md</code> in there for further information.</p>

    <h2>

    <a id="user-content-other-setups" class="anchor" href="#other-setups" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Other setups</h2>

    <ul>

    <li>

    <code>examples/</code>: deployment examples and tests</li>

    <li>

    <code>examples/joey_sprint/</code>: team sprints on Joey</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1641801068.0
PawseySC/sc-tutorials:
  data_format: 2
  description: SC Tutorials
  filenames:
  - exercises/spack_containerize/spack.yaml
  full_name: PawseySC/sc-tutorials
  latest_release: null
  readme: '<h1>

    <a id="user-content-getting-started-with-containers-on-hpc" class="anchor" href="#getting-started-with-containers-on-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/sc-tutorials/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2>

    <a id="user-content-ecp-supercontainers-tutorial-session" class="anchor" href="#ecp-supercontainers-tutorial-session"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ECP
    Supercontainers Tutorial Session</h2>

    <p><a href="fig/ecp.jpg" target="_blank" rel="noopener noreferrer"><img src="fig/ecp.jpg"
    width="200" style="max-width:100%;"></a><a href="fig/pawsey.png" target="_blank"
    rel="noopener noreferrer"><img src="fig/pawsey.png" width="200" style="max-width:100%;"></a><a
    href="fig/redhat.png" target="_blank" rel="noopener noreferrer"><img src="fig/redhat.png"
    width="200" style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-details" class="anchor" href="#details" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Full-day Tutorial Session</p>

    <p>Venue: Supercomputing Conference (SC 21)</p>

    <p>Date: Monday, 15 November 2021 8am - 5pm Central Standard Time (GMT -6)</p>

    <p>Location: Virtual, St. Louis MO, USA</p>

    <p>Link: <a href="https://sc21.supercomputing.org/presentation/?id=tut114&amp;sess=sess185"
    rel="nofollow">SC 2021 Tutorial Details</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2>

    <a id="user-content-ec2-login" class="anchor" href="#ec2-login" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EC2 Login</h2>

    <p>These will be provided the day of the tutorial.</p>

    <h2>

    <a id="user-content-abstract" class="anchor" href="#abstract" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Within just the past few years, the use of containers has revolutionized the
    way in which industries and enterprises have developed and deployed computational
    software and distributed systems. The containerization model has gained traction
    within the HPC community as well with the promise of improved reliability, reproducibility,
    portability, and levels of customization that were previously not possible on
    supercomputers. This adoption has been enabled by a number of HPC Container runtimes
    that have emerged including Singularity, Shifter, Enroot, Charliecloud and others.</p>

    <p>This hands-on tutorial looks to train users on the usability of containers
    on HPC resources. We will provide a detailed background on Linux containers, along
    with introductory hands-on experience building a container image, sharing the
    container and running it on a HPC cluster. Furthermore, the tutorial will provide
    more advanced information on how to run MPI-based and GPU-enabled HPC applications,
    how to optimize I/O intensive workflows, and how to setup GUI enabled interactive
    sessions. Cutting-edge examples will include machine learning and bioinformatics.
    Users will leave the tutorial with a solid foundational understanding of how to
    utilize containers with HPC resources through Shifter and Singularity, as well
    as an in-depth knowledge to deploy custom containers on their own resources.</p>

    <h2>

    <a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This is a hands-on tutorial.  Participants should bring a laptop and load or
    pre-install a terminal and/or ssh client in advance to make best use of time during
    the tutorial.  We will be providing training user accounts to both pre-configured
    EC2 instances.</p>

    <div><a href="fig/AWS_logo.png" target="_blank" rel="noopener noreferrer"><img
    src="fig/AWS_logo.png" width="250" style="max-width:100%;"></a></div>

    <p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards.  EC2
    images and temporary login credentials will be distributed onsite at the tutorial.</p>

    <p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2
    to run through the tutorial again. We recommend you use your own EC2 key and change
    the password.</p>

    <p>US-West-Oregon: ami-0fe12765123c6a840</p>

    <h3>

    <a id="user-content-optional-prerequisites" class="anchor" href="#optional-prerequisites"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optional
    Prerequisites</h3>

    <p>Users can also install Docker and Singularity prior to attending the tutorial
    session.  Here, it may be beneficial to create Docker and Sylabs (Singularity)
    accounts in advance at <a href="https://cloud.docker.com/" rel="nofollow">https://cloud.docker.com/</a>
    and <a href="https://cloud.sylabs.io/" rel="nofollow">https://cloud.sylabs.io/</a>.  These
    accounts will be needed to create images on Docker Cloud/Dockerhub and Sylabs
    Cloud.</p>

    <p><a href="https://sylabs.io/guides/3.7/user-guide/" rel="nofollow">Install Singularity
    on Linux</a></p>

    <p><a href="https://repo.sylabs.io/desktop/" rel="nofollow">Install Singularity
    on Mac</a> (Alpha)</p>

    <p><a href="https://www.docker.com/products/docker-desktop" rel="nofollow">Install
    Docker for Desktop</a></p>

    <h2>

    <a id="user-content-questions" class="anchor" href="#questions" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2>

    <a id="user-content-schedule" class="anchor" href="#schedule" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Schedule</h2>

    <p>8:00 - 8:20 Introduction and update on Linux containers - SLIDES (Shane)</p>

    <p>8:20 - 8:50 Building and running Docker containers (Shane)</p>

    <p>8:50 - 9:30 Advanced container builds (Eduardo)</p>

    <p>9:30 - 9:55 Container images best practices (Shane)</p>

    <p>9:55 - 10:00 Interactive Q &amp; A session</p>

    <p>10:00 - 10:30 MORNING BREAK</p>

    <p>10:30 - 10:50 HPC and containers - SLIDES (Shane)</p>

    <p>10:50 - 11:10 Installing a container engine - SLIDES (Marco)</p>

    <p>11:10 - 11:50 Running HPC jobs with containers (Marco)</p>

    <p>11:50 - 12:00 Interactive Q &amp; A session</p>

    <p>12:00 - 13:00 LUNCH BREAK</p>

    <p>13:00 - 13:30 Optional Q &amp; A session (including Slurm)</p>

    <p>13:30 - 14:20 Advanced HPC use cases (Marco)</p>

    <p>14:20 - 15:00 Container services and Kubernetes (multiple presenters)</p>

    <p>15:00 - 15:30 AFTERNOON BREAK</p>

    <p>15:30 - 16:20 Containers with E4S (Sameer)</p>

    <p>16:20 - 16:40 Success stories and use cases (Shane)</p>

    <p>16:40 - 17:00 Final Q &amp; A, wrap-up, and feedback survey</p>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1637641196.0
PawseySC/singularity-containers:
  data_format: 2
  description: Webinars&Tutorial on Containers on HPC and Cloud with Singularity
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/singularity-containers
  latest_release: null
  readme: '<h1>

    <a id="user-content-readme" class="anchor" href="#readme" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Readme</h1>

    '
  stargazers_count: 17
  subscribers_count: 12
  topics: []
  updated_at: 1638150886.0
SCOREC/dcs-spack-config:
  data_format: 2
  description: Spack config for CCI DCS (AiMOS) system
  filenames:
  - v0162gccSpectrum/spack.yaml
  full_name: SCOREC/dcs-spack-config
  latest_release: null
  readme: '<h1>

    <a id="user-content-dcs-spack-config" class="anchor" href="#dcs-spack-config"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>dcs-spack-config</h1>

    <p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies

    with the IBM XL compilers and Spectrum-MPI.</p>

    <h2>

    <a id="user-content-contents" class="anchor" href="#contents" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list</p>

    <p>config.yaml - global config</p>

    <p>install.sh - package installation commands</p>

    <p>modules.yaml - hierarchical layout for lua modules</p>

    <p>packages.yaml - system installed packages</p>

    <p>README.md - this file</p>

    <p>setupSpack.sh - env needed for executing spack commands</p>

    <p>spack.yaml - list of packages to install</p>

    <h2>

    <a id="user-content-setup" class="anchor" href="#setup" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>setup</h2>

    <pre><code>git clone git@github.com:spack/spack.git spack

    cd !$

    git checkout v0.13.3

    # add the simmetrix-simmodsuite package from the develop branch

    git cherry-pick 5ddf5e2

    # create the environment

    spack env create v0133

    spack env activate v0133

    # copy the yaml files into the v0133

    cp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.

    # copy the compiler yaml file into the spack etc dir

    cp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.

    </code></pre>

    <h2>

    <a id="user-content-install-cmake" class="anchor" href="#install-cmake" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>install cmake</h2>

    <p>The bootstrap step of the cmake install fails with the XL compilers.  I

    installed it manually outside of the environment with spack and gcc4.8.5</p>

    <pre><code>spack install cmake%gcc@4.8.5_rhel7

    </code></pre>

    <p>Then added the path to <code>packages.yaml</code>.</p>

    <h2>

    <a id="user-content-resuming-work-in-an-environment" class="anchor" href="#resuming-work-in-an-environment"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>resuming
    work in an environment</h2>

    <pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh

    spack env activate v0133

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633029356.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.15.4/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-setup-on-scorec\" class=\"anchor\" href=\"#setup-on-scorec\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1>\n<a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" href=\"#rhel7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2>\n<a id=\"user-content-useful-commands\" class=\"anchor\"\
    \ href=\"#useful-commands\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>useful commands</h2>\n<p>regenerate lmod module\
    \ tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n<h2>\n<a id=\"\
    user-content-installing-new-packages\" class=\"anchor\" href=\"#installing-new-packages\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>installing new packages</h2>\n<p>Our spack repo is tracking the master\
    \ spack branch.  Spack package updates could result in additional installation\
    \ of packages with little or no package source code changes.  These additional\
    \ installs can be avoided when installing new packages by first examining the\
    \ output of the <code>spack spec -I</code> command.  If a utility/infrastructure\
    \ level package, such as cmake or mpich, is marked with a <code>[+]</code> symbol\
    \ in the leftmost column then it means that the existing install will be used.\
    \  If spack does not default to using the existing install you can append the\
    \ hash of the package to the spec command.</p>\n<p>For example, lets see what\
    \ happens when we ask for a pumi install using gcc 7.3.0</p>\n<pre><code>$ spack\
    \ spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1643231013.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/rhel8-runner-x86_64/spack.yaml
  - docker-recipes/archived/rhel7-runner-x86_64/spack.yaml
  - docker-recipes/archived/rhel7-runner-ppc64le/spack.yaml
  - docker-recipes/rhel8-runner-ppc64le/spack.yaml
  - docker-recipes/archived/special/superlu-sc/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a href="figures/SDKdefinition1.png" target="_blank" rel="noopener noreferrer"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width:100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 18
  subscribers_count: 6
  topics: []
  updated_at: 1644561389.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent8/envs/solhawk/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-environments" class="anchor" href="#spack-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPACK
    Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2>

    <a id="user-content-software-deployment-for-centos-8x" class="anchor" href="#software-deployment-for-centos-8x"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3>

    <a id="user-content-compilers" class="anchor" href="#compilers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3>

    <a id="user-content-lu-software" class="anchor" href="#lu-software" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LU Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4>

    <a id="user-content-available-environments" class="anchor" href="#available-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    Environments</h4>

    <h5>

    <a id="user-content-solhawk" class="anchor" href="#solhawk" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-avxavx2avx512" class="anchor" href="#avxavx2avx512" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-python-and-r-packages" class="anchor" href="#python-and-r-packages"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Python
    and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-x86_64" class="anchor" href="#x86_64" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2>

    <a id="user-content-centos-7x-software" class="anchor" href="#centos-7x-software"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CentOS
    7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1629131122.0
aminaramoon/config:
  data_format: 2
  description: null
  filenames:
  - packages/spack.yaml
  full_name: aminaramoon/config
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1637295946.0
antoine-morvan/spack-offline-env:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: antoine-morvan/spack-offline-env
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1644310043.0
ashermancinelli/oci-builder:
  data_format: 2
  description: Repo to use free github actions to build my docker containers in kaniko
  filenames:
  - spack.yaml
  full_name: ashermancinelli/oci-builder
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1630966496.0
boutproject/BOUT-configs:
  data_format: 2
  description: Configuration scripts for BOUT++
  filenames:
  - lassen/spack_env/bout/spack.yaml
  - lassen/spack_env/bout_petsc_with_hypre/spack.yaml
  full_name: boutproject/BOUT-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-configuration-scripts" class="anchor" href="#configuration-scripts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configuration
    scripts</h1>

    <p>The CMake and autotools (configure/make) scripts supplied with BOUT++

    should be able to automatically find and configure BOUT++ in most

    cases. Where a complex configuration is desired, for example including

    many dependencies (esp. complex dependencies like PETSc), or compiling

    for GPUs, configuration can be quite complex.</p>

    <p>The files in this directory are intended to be convenient shortcuts for

    configuration on particular machines. Where there are many scripts, these

    are put into sub-directories (e.g. "cori" and "lassen").</p>

    <h2>

    <a id="user-content-environment" class="anchor" href="#environment" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Environment</h2>

    <p>Scripts which set up the environment, for example loading and unloading

    modules, start with <code>setup</code> or <code>setup-env</code>. These are typically
    modifying

    shell environments and so should be invoked with <code>source</code>.</p>

    <h2>

    <a id="user-content-bout-configuration" class="anchor" href="#bout-configuration"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>BOUT++
    configuration</h2>

    <p>The wrappers around CMake (or configure) start with <code>config</code> or
    <code>config-bout</code>.

    These are shell scripts which can be run without <code>source</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1638261451.0
buildsi/splice-experiment:
  data_format: 2
  description: Preparing for the splice experiment (notes are currently here)
  filenames:
  - ref/e4s/spack.yaml
  full_name: buildsi/splice-experiment
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-splice-experiment\" class=\"anchor\" href=\"\
    #splice-experiment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Splice Experiment</h1>\n<p>This is planning\
    \ for the <a href=\"https://github.com/buildsi/spliced\">spliced</a> experiment\n\
    that we plan to run for the BUILDSI project.</p>\n<h2>\n<a id=\"user-content-pre-requisites\"\
    \ class=\"anchor\" href=\"#pre-requisites\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Pre-requisites</h2>\n<ol>\n<li>We\
    \ need to finish Smeagle, and add as a tester to <a href=\"https://github.com/buildsi/spliced\"\
    >spliced</a>\n</li>\n<li>This experiment will need to be setup to run on slurm\
    \ / a cluster, meaning installing spack and other dependencies (trying to get\
    \ the current container base into a working environment).</li>\n<li>Probably something\
    \ with <a href=\"https://github.com/haampie/libtree\">libtree</a> TBA.</li>\n\
    </ol>\n<h2>\n<a id=\"user-content-plan\" class=\"anchor\" href=\"#plan\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Plan</h2>\n\
    <p>Once the above are done, here is the plan!</p>\n<h3>\n<a id=\"user-content-matrix-automated-tests\"\
    \ class=\"anchor\" href=\"#matrix-automated-tests\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Matrix Automated\
    \ Tests</h3>\n<p>We will first need to choose a set of compilers appropriate for\
    \ a scoped analysis (likely related to what Smeagle can parse). The <a href=\"\
    experiments/e4s.yaml\">experiments/e4s.yaml</a> will be run with a custom Python\
    \ script\nthat reads in each e4s package, and:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>For every package <span class=\"pl-k\">in</span> e4s P with tests:\n  For\
    \ every dependency of package P, D that is also <span class=\"pl-k\">in</span>\
    \ e4s:\n    Perform splice of package P and dependency D</pre></div>\n<p>This\
    \ means that we also need to know the sample of the e4s packages that have tests.\n\
    I wrote a script to do that.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ spack python has_tests.py experiments/e4s.yaml\n44 packages out of 90\
    \ have tests <span class=\"pl-k\">in</span> e4s.yaml</pre></div>\n<p>This will\
    \ also generate a file with the subset of packages that have tests:</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>$ cat experiments/has_tests.yaml\
    \ \nexperiments:\n- swig\n...</pre></div>\n<p>The original spack.yaml for e4s\
    \ is in <a href=\"ref\">ref</a> for reference. Finally, once you  have\nthis list,\
    \ you can do a run on your host to determine which tests might be broken (my first\n\
    run 14/44 failed, or a little less than 1/3, where 1/3 is about half of the libraries\
    \ in the e4s set.</p>\n<div class=\"highlight highlight-source-shell\"><pre>$\
    \ python run_tests.py\nqthreads             <span class=\"pl-c1\">test</span>\
    \ bug or failure\nhypre                <span class=\"pl-c1\">test</span> bug or\
    \ failure\nsuperlu              <span class=\"pl-c1\">test</span> bug or failure\n\
    kokkos               <span class=\"pl-c1\">test</span> bug or failure\nbolt  \
    \               <span class=\"pl-c1\">test</span> bug or failure\nparsec     \
    \          <span class=\"pl-c1\">test</span> bug or failure\nsuperlu-dist    \
    \     <span class=\"pl-c1\">test</span> bug or failure\nheffte               <span\
    \ class=\"pl-c1\">test</span> bug or failure\naml                  install failure\n\
    arborx               <span class=\"pl-c1\">test</span> bug or failure\ntasmanian\
    \            <span class=\"pl-c1\">test</span> bug or failure\nslepc         \
    \       <span class=\"pl-c1\">test</span> bug or failure\nginkgo             \
    \  <span class=\"pl-c1\">test</span> bug or failure\ncaliper              <span\
    \ class=\"pl-c1\">test</span> bug or failure</pre></div>\n<p>For full details\
    \ and error messages you can see <a href=\"experiments/has_tests_results.json\"\
    >experiments/has_tests_results.json</a>.</p>\n<h3>\n<a id=\"user-content-manual-tests\"\
    \ class=\"anchor\" href=\"#manual-tests\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manual Tests</h3>\n<p>Since we\
    \ can't splice in things that aren't dependencies in spack (and we need the tests\
    \ above) we also need a manual approach\nthat picks/chooses some manual cases\
    \ that we know will cause issue (e.g. mpich and openmpi) to run those.\nWe will\
    \ want to do these \"by hand\" and perhaps run a manual experiment (not developed\
    \ yet in spliced but should be fairly\neasy to do) to run the predictions without\
    \ needing to spack install them.</p>\n<h2>\n<a id=\"user-content-running-the-experiment\"\
    \ class=\"anchor\" href=\"#running-the-experiment\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the Experiment</h2>\n\
    <p>Let's clone the experiment repository to get the examples and scripts.\nWe\
    \ have space in <code>/p/vast1/build</code></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> /p/vast1/build\ngit clone https://github.com/buildsi/spliced-experiment</pre></div>\n\
    <p>Let's install anaconda to avoid pain.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>wget https://repo.anaconda.com/archive/Anaconda3-5.3.1-Linux-x86_64.sh\n\
    chmod +x Anaconda3-5.3.1-Linux-x86_64.sh\n./Anaconda3-5.3.1-Linux-x86_64.sh -p\
    \ /p/vast1/build/anaconda3</pre></div>\n<p>And we need spack.</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>git clone -b vsoch/db-17-splice-feb-25\
    \ https://github.com/vsoch/spack\n<span class=\"pl-c1\">.</span> spack/share/spack/setup-env.sh\
    \ \n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> always build with debug\
    \ (this is in template script too)</span>\n<span class=\"pl-k\">export</span>\
    \ SPACK_ADD_DEBUG_FLAGS=true\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ add anaconda (or your favorite python install) to the path to install spliced</span>\n\
    <span class=\"pl-k\">export</span> PATH=/p/vast1/build/anaconda3/bin:<span class=\"\
    pl-smi\">$PATH</span>\nspack compiler find</pre></div>\n<p>Note that libabigail\
    \ with gcc 10.2.0 is going to fail, so we need to use a different\ncompiler and\
    \ install before running anything.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ module load gcc/8.3.1\n$ spack install libabigail%gcc@8.3.1</pre></div>\n\
    <p>Install <a href=\"https://github.com/buildsi/spliced\">spliced</a> and <a href=\"\
    https://github.com/buildsi/symbolator\">symbolator</a></p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pip install spliced symbolator-python</pre></div>\n\
    <p>Note that @vsoch is testing the branch <code>add/spack-tests</code> that will\
    \ run spack tests\nwith a splice for the command. You can see example splices\
    \ in <a href=\"splices\">splices</a> and we are going to be generating them programatically\n\
    based on tests we have.</p>\n<h2>\n<a id=\"user-content-generating-experiments\"\
    \ class=\"anchor\" href=\"#generating-experiments\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Generating experiments</h2>\n\
    <p>To generate new experiment files we can do the following:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$ mkdir -p splices\n$ spack python generate_experiments.py\
    \ splices/</pre></div>\n<p>Note that @vsoch has probably already run this if there\
    \ is a \"splices\" directory in the\nrepository. Then you can have spliced generate\
    \ the commands for you.  Here is an example\nto run on your own to see:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>spliced <span class=\"pl-c1\"\
    >command</span> splices/swig/pcre/pcre/experiment.yaml</pre></div>\n<p>Take a\
    \ look at the commands generated above if you are interested. But let's do this\
    \ in Python. Make a root output directory alongside spack</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$ mkdir -p results</pre></div>\n<p>The script\
    \ <a href=\"submit_jobs.py\">submit_jobs.py</a> will do exactly that.</p>\n<p><strong>important</strong>\
    \ I've hard coded the template for the submission script at the bottom of that\
    \ script, please\nchange this to be where your spack install is, etc. It's hard\
    \ coded for mine because <em>reasons</em>.</p>\n<p>The above will submit a bunch\
    \ of jobs for all versions of the input parameters on the cluster,\nand keep scripts\
    \ in <code>$PWD/scripts</code></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>                        <span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ experiment                           # output directory</span>\n$ python submit_jobs.py\
    \ splices/swig/pcre/pcre/experiment.yaml results</pre></div>\n<p>Note that @vsoch\
    \ needs to add a boolean to spliced to say \"run spack tests for this splice\"\
    \nand then it will be ready to go.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1639367380.0
cayrols/internal_fiber:
  data_format: 2
  description: 'Purpose: PR'
  filenames:
  - .github/CI/spack.yaml
  full_name: cayrols/internal_fiber
  latest_release: null
  readme: "<p><a href=\"https://camo.githubusercontent.com/95208d9a920443b4cae72a2560512aad27c686017c663cb71aa8f434c86f0b08/68747470733a2f2f6269746275636b65742e6f72672f616179616c6133322f6c6f676f732f7261772f646530386466336333626664396435393535383762663834306633316166636234356436303139632f66696265722e706e67\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/95208d9a920443b4cae72a2560512aad27c686017c663cb71aa8f434c86f0b08/68747470733a2f2f6269746275636b65742e6f72672f616179616c6133322f6c6f676f732f7261772f646530386466336333626664396435393535383762663834306633316166636234356436303139632f66696265722e706e67\"\
    \ alt=\"FBI_banner\" data-canonical-src=\"https://bitbucket.org/aayala32/logos/raw/de08df3c3bfd9d595587bf840f31afcb45d6019c/fiber.png\"\
    \ style=\"max-width:100%;\"></a></p>\n<p><strong>FFT Benchmarking Initiative</strong></p>\n\
    <p><strong>Innovative Computing Laboratory</strong></p>\n<p><strong>University\
    \ of Tennessee</strong></p>\n<hr>\n<h1>\n<a id=\"user-content-about\" class=\"\
    anchor\" href=\"#about\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>About</h1>\n<p>The FFT Infrastructure Benchmark\
    \ for Exascale Research (FIBER) provides a framework for Fast Fourier Transform\
    \ (FFT) benchmarks targeting exascale computing systems. It evaluates performance\
    \ and scalability of distributed FFTs on different architectures. Furthermore,\
    \ it analyzes the effect on applications that directly depend on FFTs. It can\
    \ also stress and test the overall network of a supercomputer, give an indication\
    \ on bisection bandwidth, noise, and other network and MPI collectives limitations\
    \ that are of interest to many other ECP applications.</p>\n<p>The current harness\
    \ software puts together FFT libraries supporting distributed 3-D complex-to-complex\
    \ and real-to-complex FFTs.</p>\n<hr>\n<h1>\n<a id=\"user-content-setting-up\"\
    \ class=\"anchor\" href=\"#setting-up\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up</h1>\n<p>Create a\
    \ folder; e.g., <code>Benchmarks_FFT</code>, and install the FFT libraries to\
    \ benchmark; or load them as modules.</p>\n<pre><code>-- Benchmarks_FFT\n    \
    \    |-- heFFTe\n        |-- fftMPI\n        |-- AccFFT\n        |-- P3DFFT\n\
    \        |-- FFTE\n        |-- SWFFT\n        |-- 2DECOMP&amp;FFT\n        |--\
    \ nb3dFFT\n        |-- FFTW\n        |-- FFTW++\n</code></pre>\n<p>Current libraries\
    \ targeted by FIBER:</p>\n<ul>\n<li>\n<p>CPU support: <a href=\"https://lammps.github.io/fftmpi/\"\
    \ rel=\"nofollow\">fftMPI</a>, <a href=\"https://xgitlab.cels.anl.gov/hacc/SWFFT\"\
    \ rel=\"nofollow\">SWFFT</a>,\n<a href=\"https://github.com/sdsc/p3dfft.3\">P3DFFT</a>,\n\
    <a href=\"https://gitlab.jsc.fz-juelich.de/goebbert/nb3dfft\" rel=\"nofollow\"\
    >nb3dFFT</a>,\n<a href=\"http://www.2decomp.org/download.html\" rel=\"nofollow\"\
    >2DECOMP&amp;FFT</a>, <a href=\"http://www.fftw.org/\" rel=\"nofollow\">FFTW</a>,\
    \ <a href=\"fftwpp.sourceforge.net/\">FFTW++</a></p>\n</li>\n<li>\n<p>CPU-GPU\
    \ support: <a href=\"https://bitbucket.org/icl/heffte\" rel=\"nofollow\">heFFTe</a>,\
    \ <a href=\"https://github.com/amirgholami/accfft\">AccFFT</a>,   <a href=\"http://www.ffte.jp/\"\
    \ rel=\"nofollow\">FFTE</a></p>\n</li>\n</ul>\n<h1>\n<a id=\"user-content-compilation\"\
    \ class=\"anchor\" href=\"#compilation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compilation</h1>\n<p>Next clone\
    \ this repository and create  build folder, and execute the <code>cmake</code>\
    \ commands.\nIn the following example, we install FIBER with heFFTe and fftMPI\
    \ backends:</p>\n<pre><code>mkdir build; cd $_\nbuild/\ncmake -DFIBER_FFT_LIB_DIRS=\"\
    /home/Benchmarks_FFT/fftmpi/src;/home/heffte/build/lib\"\n-DFIBER_FFT_INCLUDE_DIRS=\"\
    /home/Benchmarks_FFT/fftmpi/src;/home/heffte/build/include\"\n-DFIBER_ENABLE_HEFFTE=ON\
    \ -DFIBER_ENABLE_FFTMPI=ON\n-DMPI_DIR=/sw/openmpi/4.0.0/ .. \nmake -j\n</code></pre>\n\
    <p>List the <code>lib</code> and <code>include</code> folders of libraries to\
    \ test, respectively, in <code>FIBER_FFT_LIB_DIRS</code> and <code>FIBER_FFT_INCLUDE_DIRS</code>.</p>\n\
    <h1>\n<a id=\"user-content-testing-integration\" class=\"anchor\" href=\"#testing-integration\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Testing integration</h1>\n<p>Run tests as follows:</p>\n<pre><code>cd\
    \ build/benchmarks\nmpirun -n 2 ./test3D_CPU_C2C &lt;library&gt;\nmpirun -n 2\
    \ ./test3D_CPU_R2C &lt;library&gt;\n</code></pre>\n<p>If FIBER was build linked\
    \ to GPU enabled libraries:</p>\n<pre><code>cd build/benchmarks\nmpirun -n 2 ./test3D_GPU_C2C\
    \ &lt;gpu_library&gt;\nmpirun -n 2 ./test3D_GPU_R2C &lt;gpu_library&gt;\n</code></pre>\n\
    <h1>\n<a id=\"user-content-running-benchmarks\" class=\"anchor\" href=\"#running-benchmarks\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running benchmarks</h1>\n<pre><code>cd build/benchmarks\nmpirun -n\
    \ $NUM_RANKS ./test3D_C2C -lib &lt;library&gt; -backend &lt;1D_backend&gt; -size\
    \ &lt;nx&gt; &lt;ny&gt; &lt;nz&gt; -pgrid &lt;p&gt; &lt;q&gt;\n</code></pre>\n\
    <p>where <code>library</code> has to be replaced by one of the nine available\
    \ libraries, provided user has it installed.\nOnce a parallel FFT library has\
    \ been correctly integrated to heFFTe, running these benchmarks should report\
    \ a correct validation output.</p>\n<h1>\n<a id=\"user-content-documentation\"\
    \ class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<ul>\n<li>Installation\
    \ and a Doxygen documentation will be available shortly.</li>\n</ul>\n<hr>\n<h1>\n\
    <a id=\"user-content-getting-help\" class=\"anchor\" href=\"#getting-help\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting\
    \ Help</h1>\n<p>For assistance with the FIBER project, email <em><a href=\"mailto:fiber@icl.utk.edu\"\
    >fiber@icl.utk.edu</a></em> or start a GitHub issue.</p>\n<p>Contributions are\
    \ very welcome, please create a pull request.</p>\n<h1>\n<a id=\"user-content-resources\"\
    \ class=\"anchor\" href=\"#resources\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Resources</h1>\n<ul>\n<li>Visit\
    \ the <a href=\"http://icl.utk.edu/fiber/\" rel=\"nofollow\">FIBER website</a>\
    \ for more information about the HeFFTe project.</li>\n<li>Visit the <a href=\"\
    https://exascaleproject.org\" rel=\"nofollow\">ECP website</a> to find out more\
    \ about the DOE Exascale Computing Initiative.</li>\n</ul>\n<hr>\n<h1>\n<a id=\"\
    user-content-acknowledgments\" class=\"anchor\" href=\"#acknowledgments\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h1>\n\
    <p>This research was supported by the United States Exascale Computing Project.</p>\n\
    <hr>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>License</h1>\n<pre><code>Copyright (c) 2022, University of Tennessee\n\
    All rights reserved.\n\nRedistribution and use in source and binary forms, with\
    \ or without\nmodification, are permitted provided that the following conditions\
    \ are met:\n    * Redistributions of source code must retain the above copyright\n\
    \      notice, this list of conditions and the following disclaimer.\n    * Redistributions\
    \ in binary form must reproduce the above copyright\n      notice, this list of\
    \ conditions and the following disclaimer in the\n      documentation and/or other\
    \ materials provided with the distribution.\n    * Neither the name of the University\
    \ of Tennessee nor the\n      names of its contributors may be used to endorse\
    \ or promote products\n      derived from this software without specific prior\
    \ written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\
    \ CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT\
    \ NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\
    \ PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL UNIVERSITY OF TENNESSEE\
    \ BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\
    \ DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\
    \ SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\
    \ CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\
    \ OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\
    \ OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1645724748.0
cinemascienceworkflows/exawind-naluwind:
  data_format: 2
  description: Exawind Naluwind workflow
  filenames:
  - inputs/spack/spack.yaml
  full_name: cinemascienceworkflows/exawind-naluwind
  latest_release: null
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643754675.0
cinemascienceworkflows/miniapp:
  data_format: 2
  description: Ascent-based miniapp workflows
  filenames:
  - inputs/spack/spack.yaml
  full_name: cinemascienceworkflows/miniapp
  latest_release: null
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1646254492.0
cinemascienceworkflows/nyx:
  data_format: 2
  description: null
  filenames:
  - inputs/spack/spack_begin.yaml
  full_name: cinemascienceworkflows/nyx
  latest_release: null
  stargazers_count: 1
  subscribers_count: 6
  topics: []
  updated_at: 1640144761.0
eth-cscs/spack-batteries-included:
  data_format: 2
  description: Installing spack without system dependencies
  filenames:
  - build/2_compiler/spack.yaml
  - build/5_runtime/spack.yaml
  - build/6_spack/spack.yaml
  - build/3_more_tools/spack.yaml
  - build/1_ccache/spack.yaml
  full_name: eth-cscs/spack-batteries-included
  latest_release: develop
  readme: "<p><a href=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml\"\
    ><img src=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\"\
    \ alt=\"Update spack develop version\" style=\"max-width:100%;\"></a></p>\n<h1>\n\
    <a id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\"\
    \ href=\"#-spack-with-batteries-included-linuxx86_64\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><g-emoji class=\"\
    g-emoji\" alias=\"battery\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png\"\
    >\U0001F50B</g-emoji> Spack with batteries included (linux/x86_64)</h1>\n<p><a\
    \ href=\"https://github.com/spack/spack\">Spack</a> is a package manager, and\
    \ package managers should be trivial to install.</p>\n<p>This repo offers a single,\
    \ static executable for Spack:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">wget -qO spack.x https://github.com/eth-cscs/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n\
    $ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x\
    \ install curl tls=mbedtls</span></pre></div>\n<h2>\n<a id=\"user-content-what-version-of-spack-is-shipped\"\
    \ class=\"anchor\" href=\"#what-version-of-spack-is-shipped\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What version\
    \ of Spack is shipped?</h2>\n<p>The URL above gives you a rolling release of Spack's\
    \ develop branch, which is updated\nhourly. The exact commit SHA is included as\
    \ a file and can be retrieved like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"\
    pl-k\">&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints\
    \ the Spack commit sha]</span></pre></div>\n<h2>\n<a id=\"user-content-supported-platforms\"\
    \ class=\"anchor\" href=\"#supported-platforms\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Supported platforms</h2>\n<ul>\n\
    <li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n<li>Debian 8 and\
    \ above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and above</li>\n\
    <li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for Linux 2 with any\
    \ of the above distro's.</li>\n</ul>\n<p>The system dependencies are <code>glibc\
    \ 2.17</code> and above and optionally the <code>fusermount</code>\nexecutable.\
    \ If your system supports rootless containers it likely has <code>fusermount</code>\n\
    installed already!</p>\n<h2>\n<a id=\"user-content-how-does-it-work\" class=\"\
    anchor\" href=\"#how-does-it-work\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How does it work?</h2>\n<p><code>spack.x</code>\
    \ consists of a modified version of the AppImage runtime concatenated\nwith a\
    \ big squashfs file which includes <code>binutils</code>, <code>bzip2</code>,\
    \ <code>clingo</code>, <code>curl</code>,\n<code>file</code>, <code>git</code>,\
    \ <code>gmake</code>, <code>gpg</code>, <code>gzip</code>, <code>openssl</code>,\
    \ <code>patch</code>, <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>,\
    \ <code>tar</code>, <code>unzip</code>, <code>xz</code>, <code>zstd</code> and\
    \ their dependencies.</p>\n<p>When you run <code>spack.x [args]</code> it will\
    \ use <code>fusermount</code> to\nmount this squashfs file in a temporary directory,\
    \ and then execute the\nentrypoint executable <a href=\"build/6_spack/spack\"\
    >spack</a>.</p>\n<p>The <code>spack</code> executable sets some environment variables\
    \ like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code> to the bin and lib\
    \ folders of the squashfs file, and then it\nexecutes <code>python3 spack_src/bin/spack\
    \ [args]</code>.</p>\n<p>When the command is done running, the runtime unmounts\
    \ the squashfs file again.</p>\n<h2>\n<a id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    \ class=\"anchor\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>My system doesn't allow me to use <code>fusermount</code>, what now?</h2>\n\
    <p><code>fusermount</code> is used to mount a squashfs file included in the binary.\
    \ If you\ndon't want that, you can just extract it:</p>\n<pre><code>$ spack.x\
    \ --squashfs-extract\n$ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}]\
    \ COMMAND ...\n</code></pre>\n<p>but working with the extracted <code>spack</code>\
    \ folder can come with a performance\npenalty on shared filesystems in HPC centers.</p>\n\
    <h2>\n<a id=\"user-content-differences-and-improvements-over-appimage-runtime\"\
    \ class=\"anchor\" href=\"#differences-and-improvements-over-appimage-runtime\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Differences and improvements over AppImage runtime</h2>\n<ul>\n<li>spack.x\
    \ uses <code>zstd</code> for faster decompression;</li>\n<li>spack.x itself is\
    \ an entirely static binary;</li>\n<li>spack.x does not need to dlopen libfuse.so.</li>\n\
    </ul>\n<h2>\n<a id=\"user-content-troubleshooting\" class=\"anchor\" href=\"#troubleshooting\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Troubleshooting</h2>\n<p><strong>immutability</strong> The squashfs\
    \ mountpoint is a readonly folder, meaning that\nspack can't write to spack/{var,opt}\
    \ folders. spack.x is configured to use some\nnon-standard directories, see <code>spack.x\
    \ config blame config</code> for details.</p>\n<p>Note, spack.x applies <a href=\"\
    https://github.com/spack/spack/pull/20158/\">this patch</a>\nto ensure that log\
    \ files are written to the <code>config:misc_cache</code> folder.</p>\n<p><strong>openssl</strong>:\
    \ By default spack.x uses <code>ca-certificates-mozilla</code> for downloading\n\
    package sources over https. If you somehow need to use system certificates,\n\
    set <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAINFO</code> or <code>SSL_CERT_FILE</code>\
    \ and <code>GIT_SSL_CERT</code>.</p>\n<h2>\n<a id=\"user-content-can-i-run-spackx-inside-a-container\"\
    \ class=\"anchor\" href=\"#can-i-run-spackx-inside-a-container\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Can\
    \ I run spack.x inside a container?</h2>\n<p>Yes, but please don't! Since <code>fusermount</code>\
    \ is a setuid binary, you will need to\nrun a privileged container, which is never\
    \ a good idea.</p>\n<p>The recommended way to run spack.x inside a container is\
    \ to just extract it:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract</span>\n$ <span class=\"\
    pl-s1\">./spack/spack --version</span></pre></div>\n<p>If you insist on running\
    \ spack.x in Docker, this is one way to do it:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">sudo docker run --privileged --device /dev/fuse\
    \ -it -v <span class=\"pl-smi\">$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n\
    # <span class=\"pl-s1\">apt update <span class=\"pl-k\">&amp;&amp;</span> apt\
    \ install fuse <span class=\"pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n\
    # <span class=\"pl-s1\">spack.x --version</span></pre></div>\n<h2>\n<a id=\"user-content-running-an-executable-shipped-with-spackx-directly\"\
    \ class=\"anchor\" href=\"#running-an-executable-shipped-with-spackx-directly\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running an executable shipped with spack.x directly</h2>\n<p>If you\
    \ want to run an executable shipped with <code>spack.x</code> directly instead\n\
    of invoking spack (the default entrypoint), try this:</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x\
    \ which python</span>\n<span class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n\
    <hr>\n<h2>\n<a id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\"\
    \ href=\"#how-do-i-build-spackx-myself\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How do I build spack.x myself?</h2>\n\
    <p>Initially you may need docker to get a rootfs filesystem for centos 7.</p>\n\
    <p>Building goes like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">make rootfs-with-spack</span>\n<span class=\"pl-c1\"\
    >make</span></pre></div>\n<p>You'll find the output in</p>\n<pre><code>build/output\n\
    </code></pre>\n"
  stargazers_count: 10
  subscribers_count: 1
  topics:
  - spack
  - squashfs
  - libfuse
  updated_at: 1632830237.0
eugeneswalker/clacc-ci:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/clacc-ci
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1643137385.0
floquet/builds:
  data_format: 2
  description: Notes and scripts for building applications on HPCs
  filenames:
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-SpWx-docker-spack/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  full_name: floquet/builds
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641760136.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-gcc/spack.yaml
  - ubuntu-clang/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1>

    <a id="user-content-synergia2-containers" class="anchor" href="#synergia2-containers"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for x86-haswell ISA and these
    containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1646758059.0
goma/goma:
  data_format: 2
  description: A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport
  filenames:
  - spack.yaml
  full_name: goma/goma
  latest_release: v7.0.3
  readme: '<h1>

    <a id="user-content-goma" class="anchor" href="#goma" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Goma</h1>

    <p>A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport</p>

    <p>For more information see the <a href="https://www.gomafem.com" rel="nofollow">Goma
    website</a></p>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Most of the documentation can be found at <a href="https://www.gomafem.com/documentation.html"
    rel="nofollow">https://www.gomafem.com/documentation.html</a></p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>See <a href="LICENSE">LICENSE</a> file. Some cmake modules under <code>cmake/</code>
    were modified from the Eigen library

    and are noted at the top of the cmake file.</p>

    <h2>

    <a id="user-content-major-changes" class="anchor" href="#major-changes" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Major Changes</h2>

    <p>See <a href="CHANGES.md">CHANGES.md</a></p>

    <h2>

    <a id="user-content-build-instructions" class="anchor" href="#build-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Instructions</h2>

    <p>See <a href="BUILD.md">BUILD.md</a></p>

    <h2>

    <a id="user-content-spack-package" class="anchor" href="#spack-package" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack package</h2>

    <p>The Spack package manager <a href="https://spack.io/" rel="nofollow">https://spack.io</a>
    can be used to install

    Goma and all of Goma''s third party libraries</p>

    <p>Currently available on the <code>develop</code> branch of spack.</p>

    <p>Example for a bash-like shell:</p>

    <pre><code>git clone https://github.com/spack/spack.git

    . spack/share/spack/setup-env.sh

    spack install goma

    </code></pre>

    <p>For more information on build options see:</p>

    <pre><code>spack info goma

    </code></pre>

    <p>For more information on using spack see the <a href="https://spack.readthedocs.io/en/latest/"
    rel="nofollow">spack documentation</a>.</p>

    <h2>

    <a id="user-content-third-party-libraries" class="anchor" href="#third-party-libraries"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Third
    party libraries</h2>

    <ul>

    <li>Metis 5.1.0 (Optional)</li>

    <li>SEACAS 2022-01-27 (Required: Exodus and Aprepro)</li>

    <li>BLAS/LAPACK (Configured through Trilinos)</li>

    <li>Trilinos matrix solvers 13.0.1 and up (Required: AztecOO, Amesos, Epetra,
    TPL LAPACK; Optional: Stratimikos [with Teko, Ifpack, Belos, Tpetra])</li>

    <li>PETSc matrix solvers (KSP, PC)</li>

    <li>MUMPS 5.4.0 (through Trilinos or PETSc only)</li>

    <li>Superlu_dist 7.2.0 (through Trilinos or PETSc only, Trilinos requires parmetis
    build)</li>

    <li>UMFPACK, SuiteSparse 5.10.1 (Optional)</li>

    <li>ARPACK/arpack-ng 3.8.0 (Optional)</li>

    <li>sparse 1.4b (Optional)</li>

    <li>Catch2 (Optional testing)</li>

    </ul>

    <h3>

    <a id="user-content-run-the-tutorial" class="anchor" href="#run-the-tutorial"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Run
    the tutorial</h3>

    <p>To get started with Goma, use the following:</p>

    <ul>

    <li><a href="https://docs.gomafem.com/files/goma-beginners-tutorial.pdf" rel="nofollow">Tutorial
    instructions</a></li>

    <li><a href="https://docs.gomafem.com/files/goma_beginners_tutorial.tar.gz" rel="nofollow">Tutorial
    files tarball</a></li>

    </ul>

    '
  stargazers_count: 79
  subscribers_count: 22
  topics:
  - finite-elements
  - finite-element-analysis
  - simulation
  - parallel
  - multiphysics
  - fem
  - snl-applications
  updated_at: 1647130875.0
gyselax/gyselalibxx:
  data_format: 2
  description: Gyselalib++ is a collection of C++ components for writing gyrokinetic
    semi-lagrangian codes and similar
  filenames:
  - spack.yaml
  full_name: gyselax/gyselalibxx
  latest_release: null
  readme: '<h1>

    <a id="user-content-gyselalib" class="anchor" href="#gyselalib" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Gyselalib++</h1>

    <p>Gyselalib++ is a collection of C++ components for writing gyrokinetic semi-lagrangian
    codes and

    similar as well as a collection of such codes.</p>

    <h2>

    <a id="user-content-compilation" class="anchor" href="#compilation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h2>

    <p>to compile voice++:</p>

    <pre><code>git clone --recurse-submodules git@gitlab.maisondelasimulation.fr:gysela-developpers/voicexx.git

    cd voicexx

    mkdir build

    cd build

    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-Wall -Wno-sign-compare" ..

    make

    </code></pre>

    <h2>

    <a id="user-content-execution" class="anchor" href="#execution" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Execution</h2>

    <p>to run the tests:</p>

    <pre><code>ctest --output-on-failure

    </code></pre>

    <p>Then, just have a look at <code>tests/landau/dampingrate_t0.0to45.0.png</code>:</p>

    <p><a href="https://camo.githubusercontent.com/6e82e45d4f4a79aa4757fc6b06eb7f6cb365d8cafaad8110f00909b4e5be3d2c/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f64616d70696e67726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/6e82e45d4f4a79aa4757fc6b06eb7f6cb365d8cafaad8110f00909b4e5be3d2c/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f64616d70696e67726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/dampingrate_t0.0to45.0.png" title="Landau damping rate"
    data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/dampingrate_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width:100%;"></a></p>

    <p>and <code>tests/landau/frequency_t0.0to45.0.png</code>:</p>

    <p><a href="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/frequency_t0.0to45.0.png" title="Landau damping frequency"
    data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/frequency_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>To install dependencies through spack, first follow the the 3 first steps of

    <a href="https://github.com/pdidev/spack">https://github.com/pdidev/spack</a></p>

    <p>Then execute the following:</p>

    <div class="highlight highlight-source-shell"><pre>spack env create voice spack.yaml

    spack env activate voice

    spack concretize --reuse

    spack install</pre></div>

    <p>For example, you can find a Dockerfile installing these dependencies on ubuntu
    in

    <code>voicexx_env/Dockerfile</code>.</p>

    '
  stargazers_count: 3
  subscribers_count: 1
  topics:
  - hpc
  - numerical-simulation
  - gyrokinetic
  - poisson-solver
  - vlasov-solver
  - plasma-physics
  - ddc
  updated_at: 1646130547.0
hepnos/HEPnOS-Dataloader:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-Dataloader
  latest_release: v0.5.1
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1643644851.0
iarspider/cms-spack-repo:
  data_format: 2
  description: null
  filenames:
  - environments/CMSSW_12_1_X/spack.yaml
  full_name: iarspider/cms-spack-repo
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1638894331.0
icl-utk-edu/fiber:
  data_format: 2
  description: null
  filenames:
  - .github/CI/spack.yaml
  full_name: icl-utk-edu/fiber
  latest_release: null
  readme: "<p><a href=\"https://camo.githubusercontent.com/95208d9a920443b4cae72a2560512aad27c686017c663cb71aa8f434c86f0b08/68747470733a2f2f6269746275636b65742e6f72672f616179616c6133322f6c6f676f732f7261772f646530386466336333626664396435393535383762663834306633316166636234356436303139632f66696265722e706e67\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/95208d9a920443b4cae72a2560512aad27c686017c663cb71aa8f434c86f0b08/68747470733a2f2f6269746275636b65742e6f72672f616179616c6133322f6c6f676f732f7261772f646530386466336333626664396435393535383762663834306633316166636234356436303139632f66696265722e706e67\"\
    \ alt=\"FBI_banner\" data-canonical-src=\"https://bitbucket.org/aayala32/logos/raw/de08df3c3bfd9d595587bf840f31afcb45d6019c/fiber.png\"\
    \ style=\"max-width:100%;\"></a></p>\n<p><strong>FFT Benchmarking Initiative</strong></p>\n\
    <p><strong>Innovative Computing Laboratory</strong></p>\n<p><strong>University\
    \ of Tennessee</strong></p>\n<hr>\n<h1>\n<a id=\"user-content-about\" class=\"\
    anchor\" href=\"#about\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>About</h1>\n<p>The FFT Infrastructure Benchmark\
    \ for Exascale Research (FIBER) provides a framework for Fast Fourier Transform\
    \ (FFT) benchmarks targeting exascale computing systems. It evaluates performance\
    \ and scalability of distributed FFTs on different architectures. Furthermore,\
    \ it analyzes the effect on applications that directly depend on FFTs. It can\
    \ also stress and test the overall network of a supercomputer, give an indication\
    \ on bisection bandwidth, noise, and other network and MPI collectives limitations\
    \ that are of interest to many other ECP applications.</p>\n<p>The current harness\
    \ software puts together FFT libraries supporting distributed 3-D complex-to-complex\
    \ and real-to-complex FFTs.</p>\n<hr>\n<h1>\n<a id=\"user-content-setting-up\"\
    \ class=\"anchor\" href=\"#setting-up\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up</h1>\n<p>Create a\
    \ folder; e.g., <code>Benchmarks_FFT</code>, and install the FFT libraries to\
    \ benchmark; or load them as modules.</p>\n<pre><code>-- Benchmarks_FFT\n    \
    \    |-- heFFTe\n        |-- fftMPI\n        |-- AccFFT\n        |-- P3DFFT\n\
    \        |-- FFTE\n        |-- SWFFT\n        |-- 2DECOMP&amp;FFT\n        |--\
    \ nb3dFFT\n        |-- FFTW\n        |-- FFTW++\n</code></pre>\n<p>Current libraries\
    \ targeted by FIBER:</p>\n<ul>\n<li>\n<p>CPU support: <a href=\"https://lammps.github.io/fftmpi/\"\
    \ rel=\"nofollow\">fftMPI</a>, <a href=\"https://xgitlab.cels.anl.gov/hacc/SWFFT\"\
    \ rel=\"nofollow\">SWFFT</a>,\n<a href=\"https://github.com/sdsc/p3dfft.3\">P3DFFT</a>,\n\
    <a href=\"https://gitlab.jsc.fz-juelich.de/goebbert/nb3dfft\" rel=\"nofollow\"\
    >nb3dFFT</a>,\n<a href=\"http://www.2decomp.org/download.html\" rel=\"nofollow\"\
    >2DECOMP&amp;FFT</a>, <a href=\"http://www.fftw.org/\" rel=\"nofollow\">FFTW</a>,\
    \ <a href=\"fftwpp.sourceforge.net/\">FFTW++</a></p>\n</li>\n<li>\n<p>CPU-GPU\
    \ support: <a href=\"https://bitbucket.org/icl/heffte\" rel=\"nofollow\">heFFTe</a>,\
    \ <a href=\"https://github.com/amirgholami/accfft\">AccFFT</a>,   <a href=\"http://www.ffte.jp/\"\
    \ rel=\"nofollow\">FFTE</a></p>\n</li>\n</ul>\n<h1>\n<a id=\"user-content-compilation\"\
    \ class=\"anchor\" href=\"#compilation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compilation</h1>\n<p>Next clone\
    \ this repository and create  build folder, and execute the <code>cmake</code>\
    \ commands.\nIn the following example, we install FIBER with heFFTe and fftMPI\
    \ backends:</p>\n<pre><code>mkdir build; cd $_\nbuild/\ncmake -DFIBER_FFT_LIB_DIRS=\"\
    /home/Benchmarks_FFT/fftmpi/src;/home/heffte/build/lib\"\n-DFIBER_FFT_INCLUDE_DIRS=\"\
    /home/Benchmarks_FFT/fftmpi/src;/home/heffte/build/include\"\n-DFIBER_ENABLE_HEFFTE=ON\
    \ -DFIBER_ENABLE_FFTMPI=ON\n-DMPI_DIR=/sw/openmpi/4.0.0/ .. \nmake -j\n</code></pre>\n\
    <p>List the <code>lib</code> and <code>include</code> folders of libraries to\
    \ test, respectively, in <code>FIBER_FFT_LIB_DIRS</code> and <code>FIBER_FFT_INCLUDE_DIRS</code>.</p>\n\
    <h1>\n<a id=\"user-content-testing-integration\" class=\"anchor\" href=\"#testing-integration\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Testing integration</h1>\n<p>Run tests as follows:</p>\n<pre><code>cd\
    \ build/benchmarks\nmpirun -n 2 ./test3D_CPU_C2C &lt;library&gt;\nmpirun -n 2\
    \ ./test3D_CPU_R2C &lt;library&gt;\n</code></pre>\n<p>If FIBER was build linked\
    \ to GPU enabled libraries:</p>\n<pre><code>cd build/benchmarks\nmpirun -n 2 ./test3D_GPU_C2C\
    \ &lt;gpu_library&gt;\nmpirun -n 2 ./test3D_GPU_R2C &lt;gpu_library&gt;\n</code></pre>\n\
    <h1>\n<a id=\"user-content-running-benchmarks\" class=\"anchor\" href=\"#running-benchmarks\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running benchmarks</h1>\n<pre><code>cd build/benchmarks\nmpirun -n\
    \ $NUM_RANKS ./test3D_C2C -lib &lt;library&gt; -backend &lt;1D_backend&gt; -size\
    \ &lt;nx&gt; &lt;ny&gt; &lt;nz&gt; -pgrid &lt;p&gt; &lt;q&gt;\n</code></pre>\n\
    <p>where <code>library</code> has to be replaced by one of the nine available\
    \ libraries, provided user has it installed.\nOnce a parallel FFT library has\
    \ been correctly integrated to heFFTe, running these benchmarks should report\
    \ a correct validation output.</p>\n<h1>\n<a id=\"user-content-documentation\"\
    \ class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<ul>\n<li>Installation\
    \ and a Doxygen documentation will be available shortly.</li>\n</ul>\n<hr>\n<h1>\n\
    <a id=\"user-content-getting-help\" class=\"anchor\" href=\"#getting-help\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting\
    \ Help</h1>\n<p>For assistance with the FIBER project, email <em><a href=\"mailto:fiber@icl.utk.edu\"\
    >fiber@icl.utk.edu</a></em> or start a GitHub issue.</p>\n<p>Contributions are\
    \ very welcome, please create a pull request.</p>\n<h1>\n<a id=\"user-content-resources\"\
    \ class=\"anchor\" href=\"#resources\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Resources</h1>\n<ul>\n<li>Visit\
    \ the <a href=\"http://icl.utk.edu/fiber/\" rel=\"nofollow\">FIBER website</a>\
    \ for more information about the HeFFTe project.</li>\n<li>Visit the <a href=\"\
    https://exascaleproject.org\" rel=\"nofollow\">ECP website</a> to find out more\
    \ about the DOE Exascale Computing Initiative.</li>\n</ul>\n<hr>\n<h1>\n<a id=\"\
    user-content-acknowledgments\" class=\"anchor\" href=\"#acknowledgments\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h1>\n\
    <p>This research was supported by the United States Exascale Computing Project.</p>\n\
    <hr>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>License</h1>\n<pre><code>Copyright (c) 2022, University of Tennessee\n\
    All rights reserved.\n\nRedistribution and use in source and binary forms, with\
    \ or without\nmodification, are permitted provided that the following conditions\
    \ are met:\n    * Redistributions of source code must retain the above copyright\n\
    \      notice, this list of conditions and the following disclaimer.\n    * Redistributions\
    \ in binary form must reproduce the above copyright\n      notice, this list of\
    \ conditions and the following disclaimer in the\n      documentation and/or other\
    \ materials provided with the distribution.\n    * Neither the name of the University\
    \ of Tennessee nor the\n      names of its contributors may be used to endorse\
    \ or promote products\n      derived from this software without specific prior\
    \ written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\
    \ CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT\
    \ NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\
    \ PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL UNIVERSITY OF TENNESSEE\
    \ BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\
    \ DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\
    \ SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\
    \ CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\
    \ OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\
    \ OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n</code></pre>\n"
  stargazers_count: 4
  subscribers_count: 3
  topics: []
  updated_at: 1646874711.0
jeffersonscientific/cees_spack_configs:
  data_format: 2
  description: CEES spack configurations (take 3). Focus on environments only (or
    mostly), and modular configs.
  filenames:
  - configs/spack_petsc_mod.yaml
  full_name: jeffersonscientific/cees_spack_configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-cees_spack_configs" class="anchor" href="#cees_spack_configs"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>cees_spack_configs</h1>

    <p>CEES spack configurations (take 3). Focus on environments only (or mostly),
    and modular configs.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641864561.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack overlay repository of HEP software packaging.
  filenames:
  - environments/key4hep-release-user/spack.yaml
  - environments/key4hep-nightlies/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1>

    <a id="user-content-spack-package-repo-for-key4hep-software-packaging" class="anchor"
    href="#spack-package-repo-for-key4hep-software-packaging" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://github.com/spack/spack">Spack</a>
    package repo for Key4HEP software packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3>

    <a id="user-content-repository-contents" class="anchor" href="#repository-contents"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3>

    <a id="user-content-central-installations" class="anchor" href="#central-installations"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 5
  subscribers_count: 9
  topics: []
  updated_at: 1638895751.0
laristra/ristra_spackages:
  data_format: 2
  description: 'A mirror of Ristra''s internal gitlab repository. '
  filenames:
  - env/broadwell/flecsalemm-deps/spack.yaml
  - env/power9le/flecsalemm-deps/spack.yaml
  - .gitlab-ci/env/dry-run/spack.yaml
  - .gitlab-ci/env/root-build/spack.yaml
  - env/x86_64/flecsalemm-deps/spack.yaml
  full_name: laristra/ristra_spackages
  latest_release: null
  readme: '<h1>

    <a id="user-content-ristra-spackages" class="anchor" href="#ristra-spackages"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ristra
    Spackages</h1>

    <p>This repository contains the custom spackage files for the repos in laristra
    family.</p>

    <h2>

    <a id="user-content-basic-usage" class="anchor" href="#basic-usage" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Basic Usage</h2>

    <p>We assume the user wish to work in the home directory and already have a spack
    instance setup.  The minimum required version of spack is 0.15.2.</p>

    <p>To get the content of this repo</p>

    <pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git

    </code></pre>

    <p>To use the custom spackage files with your spack</p>

    <pre><code>$ spack repo add ristra_spackages/spack-repo

    ==&gt; Added repo with namespace ''lanl_ristra''.


    $ spack repo list

    ==&gt; 2 package repositories.

    lanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo

    builtin            /home/&lt;user&gt;/spack/var/spack/repos/builtin

    </code></pre>

    <p>[Optional]

    To ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code>
    into your spack config folder</p>

    <pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/

    </code></pre>

    <p>Please see the <a href="https://spack.readthedocs.io/en/latest/configuration.html"
    rel="nofollow">Spack documentation</a> for more detailed info.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1641486480.0
mayrmt/spack_environments:
  data_format: 2
  description: A set of spack environemts for some of my projects
  filenames:
  - env_trilinos/spack.yaml
  - env_baci/spack.yaml
  - env_4c/spack.yaml
  full_name: mayrmt/spack_environments
  latest_release: null
  readme: '<h1>

    <a id="user-content-a-set-of-spack-environemts" class="anchor" href="#a-set-of-spack-environemts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>A
    set of spack environemts</h1>

    <h2>

    <a id="user-content-purpose-and-intention" class="anchor" href="#purpose-and-intention"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Purpose
    and intention</h2>

    <p>While this collection of <code>spack.yaml</code> files is mainly inteded for
    my personal use

    to setup <code>spack</code> environments for the development of various software
    projects,

    some of them might actually useful for my colleages or even a broader community.</p>

    <h2>

    <a id="user-content-using-this-repository-to-setup-spack-environment" class="anchor"
    href="#using-this-repository-to-setup-spack-environment" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using this repository
    to setup <code>spack</code> environment</h2>

    <p>In order to create a named environment <code>&lt;myEnv&gt;</code> based on
    a give <code>spack.yaml</code> file

    located at <code>&lt;path/to/environment/spack.yaml&gt;</code>, perform the following
    steps:</p>

    <ol>

    <li>Clone the <a href="https://github.com/spack/spack"><code>spack</code> repository</a>:
    <code>git clone git@github.com:spack/spack.git</code>

    </li>

    <li>Clone this repository: <code>git clone git@github.com:mayrmt/spack_environments.git</code>

    </li>

    <li>Activate spack in your terminal</li>

    <li>Create a named environment: <code>spack env create &lt;myEnv&gt; &lt;path/to/environment/spack.yaml&gt;</code>

    </li>

    </ol>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Feedback and contributions are welcome!

    Just open an <a href="https://github.com/mayrmt/spack_environments/issues">issue</a>

    or <a href="https://github.com/mayrmt/spack_environments/pulls">pull request</a>

    in the <a href="https://github.com/mayrmt/spack_environments">GitHub repository</a>.

    Thank you!</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1634191144.0
mochi-hpc/mobject:
  data_format: 2
  description: Mobject is a prototype Mochi object storage system based on RADOS
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mobject
  latest_release: v0.6
  readme: ''
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1640785210.0
mochi-hpc/mochi-bedrock:
  data_format: 2
  description: Mochi bootstrapping service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bedrock
  latest_release: v0.3.3
  readme: '<h1>

    <a id="user-content-bedrock" class="anchor" href="#bedrock" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bedrock</h1>

    <p>Bedrock is Mochi''s service bootstrapping mechanism.

    For documentations and tutorials, please see

    <a href="https://mochi.readthedocs.io/en/latest/bedrock.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640527359.0
mochi-hpc/mochi-colza:
  data_format: 2
  description: Mochi-based staging service for in situ analysis and visualization
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-colza
  latest_release: v0.1.1
  readme: ''
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640788783.0
mochi-hpc/mochi-doc:
  data_format: 2
  description: Documentations and tutorials for Margo, Thallium, Argobots, Mercury,
    and other Mochi libraries.
  filenames:
  - code/spack.yaml
  full_name: mochi-hpc/mochi-doc
  latest_release: null
  readme: '<p><a href="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"
    target="_blank" rel="noopener noreferrer"><img src="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"
    alt="build" style="max-width:100%;"></a></p>

    <h1>

    <a id="user-content-mochi-documentation" class="anchor" href="#mochi-documentation"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    documentation</h1>

    <p>This repository contains a Sphinx-based documentation

    for the Mochi libraries: Margo, Thallium, Argobots, Mercury,

    ABT-IO, and SSG, as well as corresponding code examples.</p>

    <h2>

    <a id="user-content-building-the-documentation" class="anchor" href="#building-the-documentation"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the documentation</h2>

    <p>To build and/orcontribute to this documentation, make sure

    that you have Sphinx installed as well as the ReadTheDoc theme.

    These can be installed as follows using Python''s <code>pip</code>.</p>

    <pre><code>pip install sphinx

    pip install sphinx_rtd_theme

    pip install sphinx_copybutton

    </code></pre>

    <p>Once you have these dependencies installed, clone this

    repository and cd into it. You can change the documentation

    by editing the files in the source subdirectory (these files

    use the .rst format). You can build the documentation

    using the following command.</p>

    <pre><code>cd docs

    make html

    </code></pre>

    <p>And check the result by opening the <code>build/index.html</code> page

    that has been created in the docs directory.</p>

    <h2>

    <a id="user-content-building-the-code-examples" class="anchor" href="#building-the-code-examples"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the code examples</h2>

    <p>To build the code, you will need spack and the

    <a href="https://xgitlab.cels.anl.gov/sds/sds-repo" rel="nofollow">sds-repo</a>
    setup.</p>

    <pre><code>cd code

    spack env create mochi-doc-env spack.yaml

    spack env activate mochi-doc-env

    spack install

    mkdir build

    cd build

    cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc

    make

    </code></pre>

    '
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1646801350.0
mochi-hpc/mochi-remi:
  data_format: 2
  description: Mochi's REsource Migration Interface
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-remi
  latest_release: null
  readme: '<h1>

    <a id="user-content-resource-migration-interface" class="anchor" href="#resource-migration-interface"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>REsource
    Migration Interface</h1>

    <p>REMI is a Mochi microservice designed to handle the migration of sets of files

    from a node to another. It uses RDMA and memory mapping to efficiently transfer

    potentially large groups of files at once.</p>

    <h3>

    <a id="user-content-installing" class="anchor" href="#installing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>Just like all Mochi services, REMI can be installed using Spack. Once you have

    clone the <a href="https://xgitlab.cels.anl.gov/sds/sds-repo" rel="nofollow">sds-repo</a>
    package repository

    and added it to your spack installation, you can install REMI using the following

    command:</p>

    <pre><code>spack install mochi-remi

    </code></pre>

    <p>REMI depends on <a href="https://xgitlab.cels.anl.gov/sds/thallium/" rel="nofollow">Thallium</a>,
    which

    Spack will install (if needed) along with Thallium''s own dependencies. It also

    depends on Bedrock, unless the <code>bedrock</code> variant is disable when installing

    with Spack (i.e. passing <code>~bedrock</code> to the above command).</p>

    <h3>

    <a id="user-content-overview" class="anchor" href="#overview" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h3>

    <p>REMI works with <em>filesets</em>. A fileset consists of a root directory and

    a set of file paths relative to this root directory. A fileset is also characterized

    by the name of its <em>migration class</em>.</p>

    <p>REMI clients create filesets to group files corresponding to a particular resource

    (e.g. a database''s files). They can then request the migration of fileset to

    a target provider.</p>

    <p>Uppon receiving a request for migration, a provider will recreate the tree
    of

    directories required to receive the files of the fileset, create the files,

    mmap them into memory, and issue an RDMA pull operation from the client''s files

    (themselves mmap-ed into the client''s memory).</p>

    <p>Following successful migration, the provider will call a user-supplied callback

    corresponding to the particular fileset''s migration class.</p>

    <p>For an example of code, please see the <a href="examples">examples</a>

    folder in the source tree.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975455.0
mochi-hpc/mochi-yokan:
  data_format: 2
  description: Remote Key/Value storage service for Mochi
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-yokan
  latest_release: v0.2.4
  readme: '<h1>

    <a id="user-content-yokan---mochis-keyvalue-and-more-storage-service" class="anchor"
    href="#yokan---mochis-keyvalue-and-more-storage-service" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Yokan - Mochi''s Key/Value
    (and more) storage service</h1>

    <p><a href="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"
    target="_blank" rel="noopener noreferrer"><img src="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"
    alt="" style="max-width:100%;"></a>

    <a href="https://codecov.io/gh/mochi-hpc/mochi-yokan" rel="nofollow"><img src="https://camo.githubusercontent.com/fc95c801bafa29b49219f4727f651b97e7385800c8dc4a4757a1dccadefe6611/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d796f6b616e2f6272616e63682f6d61696e2f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/mochi-hpc/mochi-yokan/branch/main/graph/badge.svg"
    style="max-width:100%;"></a></p>

    <p>Please see documentation <a href="https://mochi.readthedocs.io/en/latest/yokan.html"
    rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641326484.0
mochi-hpc/py-mochi-bake:
  data_format: 2
  description: Python wrapper for BAKE
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-bake
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633975348.0
mochi-hpc/py-mochi-colza:
  data_format: 2
  description: Python binding for Mochi's Colza microservice
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-colza
  latest_release: null
  readme: '<p>Py-Colza is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-colza">Colza
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1633974570.0
mochi-hpc/py-mochi-margo:
  data_format: 2
  description: Python wrapper for Margo. Can be used to prototype Margo services in
    Python.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-margo
  latest_release: v0.4
  readme: "<h1>\n<a id=\"user-content-py-margo\" class=\"anchor\" href=\"#py-margo\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Py-Margo</h1>\n<p>Py-Margo provides a Python wrapper on top of <a\
    \ href=\"https://xgitlab.cels.anl.gov/sds/margo\" rel=\"nofollow\">Margo</a>.\n\
    It enables one to develop Margo-based service in Python.</p>\n<h2>\n<a id=\"user-content-dependencies\"\
    \ class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>margo\
    \ (and its dependencies)</li>\n<li>python</li>\n<li>pybind11</li>\n<li>py-pkgconfig</li>\n\
    </ul>\n<h2>\n<a id=\"user-content-installing\" class=\"anchor\" href=\"#installing\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installing</h2>\n<p>The easiest way to install Py-Margo is to use\
    \ <a href=\"https://spack.io/\" rel=\"nofollow\">spack</a>.\nFollow the instructions\
    \ <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">here</a>\n\
    to add the <code>sds</code> namespace and its packages (instal spack first, if\
    \ needed).\nThen type:</p>\n<pre><code>spack install py-margo\n</code></pre>\n\
    <p>Once installed, you need the py-margo package (and its dependencies) to\nbe\
    \ loaded to use it.</p>\n<h2>\n<a id=\"user-content-examples\" class=\"anchor\"\
    \ href=\"#examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<h3>\n<a id=\"user-content-basic-example\"\
    \ class=\"anchor\" href=\"#basic-example\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Basic example</h3>\n<p>The following\
    \ is an example of provider programmed in Python.\nLet's put is in a file <code>server.py</code>.\n\
    The provider listens to an address on a given multiple id (here 42).\nWhenever\
    \ it receives an RPC, it prints \"Hello from\" and the name sent\nby the client,\
    \ then sends the \"Hi \"+name+\"!\" string back to the client,\nand finally terminates.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">pymargo</span>.<span class=\"pl-s1\">core</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-v\">Engine</span>, <span class=\"pl-v\">Provider</span>\n\
    \n<span class=\"pl-k\">class</span> <span class=\"pl-v\">HelloProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>(<span class=\"pl-s1\">engine</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\"\
    >register</span>(<span class=\"pl-s\">\"say_hello\"</span>, <span class=\"pl-s\"\
    >\"hello\"</span>)\n\n\t<span class=\"pl-k\">def</span> <span class=\"pl-en\"\
    >hello</span>(<span class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>,\
    \ <span class=\"pl-s1\">name</span>):\n\t\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Hello from \"</span><span class=\"pl-c1\">+</span><span class=\"\
    pl-s1\">name</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"pl-s\"\
    >\"RPC id is \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">handle</span>.<span class=\"pl-en\">get_id</span>()))\n\t\t\
    <span class=\"pl-s1\">handle</span>.<span class=\"pl-en\">respond</span>(<span\
    \ class=\"pl-s\">\"Hi \"</span><span class=\"pl-c1\">+</span><span class=\"pl-s1\"\
    >name</span><span class=\"pl-c1\">+</span><span class=\"pl-s\">\"!\"</span>)\n\
    \t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\">get_engine</span>().<span\
    \ class=\"pl-en\">finalize</span>()\n\n<span class=\"pl-k\">def</span> <span class=\"\
    pl-v\">WhenFinalize</span>():\n\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Finalize was called\"</span>)\n\n<span class=\"pl-s1\">engine</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Engine</span>(<span class=\"\
    pl-s\">'tcp'</span>)\n<span class=\"pl-s1\">provider_id</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Server running at address \"</span> <span class=\"pl-c1\">+</span>\
    \ <span class=\"pl-en\">str</span>(<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">addr</span>()) <span class=\"pl-c1\">+</span> <span class=\"pl-s\">\"\
    \ with provider_id \"</span> <span class=\"pl-c1\">+</span> <span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">provider_id</span>))\n\n<span class=\"pl-s1\"\
    >engine</span>.<span class=\"pl-en\">on_finalize</span>(<span class=\"pl-v\">WhenFinalize</span>)\n\
    <span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">HelloProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>The following code is the corresponding\
    \ client code (<code>client.py</code>).</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">sys</span>\n<span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">pymargo</span>\n<span class=\"\
    pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"pl-s1\"\
    >core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">name</span>):\n\t<span class=\"pl-s1\">addr</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">lookup</span>(<span\
    \ class=\"pl-s1\">addr_str</span>)\n\t<span class=\"pl-s1\">handle</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">create_handle</span>(<span class=\"pl-s1\">addr</span>, <span class=\"\
    pl-s1\">rpc_id</span>)\n\t<span class=\"pl-k\">return</span> <span class=\"pl-s1\"\
    >handle</span>.<span class=\"pl-en\">forward</span>(<span class=\"pl-s1\">provider_id</span>,\
    \ <span class=\"pl-s1\">name</span>)\n\n<span class=\"pl-k\">with</span> <span\
    \ class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span class=\"\
    pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span> <span class=\"\
    pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">register</span>(<span\
    \ class=\"pl-s\">\"say_hello\"</span>)\n\t<span class=\"pl-s1\">ret</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"\
    pl-c1\">3</span>]))\n\t<span class=\"pl-en\">print</span>(<span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n<p>First, run the\
    \ server on a new terminal:</p>\n<pre><code>python server.py\n</code></pre>\n\
    <p>This will output something like</p>\n<pre><code>Server running at address ofi+sockets://10.0.2.15:39151\
    \ with provider_id=42\n</code></pre>\n<p>Then run the client on a new terminal:</p>\n\
    <pre><code>python client.py ofi+sockets://10.0.2.15:39151 42 Matthieu\n</code></pre>\n\
    <h3>\n<a id=\"user-content-sendingreceiving-python-objects\" class=\"anchor\"\
    \ href=\"#sendingreceiving-python-objects\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Sending/receiving Python objects</h3>\n\
    <p>The example above shows the basic principles of Py-Margo.\nPy-Margo's RPC always\
    \ use a string as input and respond with a string.\nYet this is sufficient to\
    \ cover any use-cases you may have: Python\nindeed comes with a serialization\
    \ package, <code>pickle</code>, that can take\ncare of converting almost any Python\
    \ object from/to a string.</p>\n<p>Let us assume we have a file named <code>mymaths.py</code>\
    \ which contains the\nfollowing definition of a point in 3D.</p>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span\
    \ class=\"pl-v\">Point</span>():\n\t<span class=\"pl-k\">def</span> <span class=\"\
    pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>,<span class=\"pl-s1\"\
    >x</span>,<span class=\"pl-s1\">y</span>,<span class=\"pl-s1\">z</span>):\n\t\t\
    <span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">x</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">x</span>\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">y</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\"\
    >y</span>\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">z</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">z</span>\n\t<span class=\"\
    pl-k\">def</span> <span class=\"pl-en\">__str__</span>(<span class=\"pl-s1\">self</span>):\n\
    \t\t<span class=\"pl-k\">return</span> <span class=\"pl-s\">'Point ('</span><span\
    \ class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\"\
    >self</span>.<span class=\"pl-s1\">x</span>)<span class=\"pl-c1\">+</span><span\
    \ class=\"pl-s\">','</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">y</span>)<span\
    \ class=\"pl-c1\">+</span><span class=\"pl-s\">','</span><span class=\"pl-c1\"\
    >+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">z</span>)<span class=\"pl-c1\">+</span><span class=\"pl-s\"\
    >')'</span></pre></div>\n<p>Then here is a server that can compute a cross product\
    \ on two points sent by\na client.</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Engine</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Provider</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\"\
    >mymaths</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n\
    <span class=\"pl-k\">import</span> <span class=\"pl-s1\">pickle</span>\n\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-v\">VectorMathProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>().<span class=\"pl-en\">__init__</span>(<span class=\"pl-s1\"\
    >engine</span>, <span class=\"pl-s1\">provider_id</span>)\n\t\t<span class=\"\
    pl-s1\">self</span>.<span class=\"pl-en\">register</span>(<span class=\"pl-s\"\
    >\"cross_product\"</span>, <span class=\"pl-s\">\"cross_product\"</span>)\n\n\t\
    <span class=\"pl-k\">def</span> <span class=\"pl-en\">cross_product</span>(<span\
    \ class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>, <span class=\"\
    pl-s1\">args</span>):\n\t\t<span class=\"pl-s1\">points</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">loads</span>(<span\
    \ class=\"pl-s1\">args</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Received: \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">points</span>))\n\t\t<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span> <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">0</span>].<span class=\"pl-s1\">z</span><span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span\
    \ class=\"pl-s1\">y</span>\n\t\t<span class=\"pl-s1\">y</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">z</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">x</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span>\n\t\t<span class=\"pl-s1\">z</span> <span class=\"pl-c1\">=</span>\
    \ <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span class=\"\
    pl-s1\">x</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">1</span>].<span class=\"pl-s1\">y</span> <span class=\"pl-c1\"\
    >-</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\n\
    \t\t<span class=\"pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Point</span>(<span class=\"pl-s1\">x</span>,<span class=\"pl-s1\">y</span>,<span\
    \ class=\"pl-s1\">z</span>)\n\t\t<span class=\"pl-s1\">handle</span>.<span class=\"\
    pl-en\">respond</span>(<span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >dumps</span>(<span class=\"pl-s1\">res</span>))\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-en\">get_engine</span>().<span class=\"pl-en\">finalize</span>()\n\
    \n<span class=\"pl-s1\">engine</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>)\n<span class=\"pl-s1\"\
    >provider_id</span> <span class=\"pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n\
    <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Server running at address\
    \ \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">mid</span>.<span class=\"pl-en\">addr</span>())<span class=\"\
    pl-c1\">+</span><span class=\"pl-s\">\"with provider_id=\"</span><span class=\"\
    pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">provider_id</span>))\n\
    \n<span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">VectorMathProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>And here is a client.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">import</span> <span class=\"\
    pl-s1\">pymargo</span>\n<span class=\"pl-k\">import</span> <span class=\"pl-s1\"\
    >pickle</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">mymaths</span>\
    \ <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n<span\
    \ class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"\
    pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">p1</span>, <span class=\"pl-s1\">p2</span>):\n\t<span class=\"pl-s1\"\
    >addr</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span\
    \ class=\"pl-en\">lookup</span>(<span class=\"pl-s1\">addr_str</span>)\n\t<span\
    \ class=\"pl-s1\">handle</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">engine</span>.<span class=\"pl-en\">create_handle</span>(<span class=\"\
    pl-s1\">addr</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t<span class=\"pl-s1\">args</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">dumps</span>([<span\
    \ class=\"pl-s1\">p1</span>,<span class=\"pl-s1\">p2</span>])\n\t<span class=\"\
    pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">handle</span>.<span\
    \ class=\"pl-en\">forward</span>(<span class=\"pl-s1\">args</span>)\n\t<span class=\"\
    pl-k\">return</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >loads</span>(<span class=\"pl-s1\">res</span>)\n\n<span class=\"pl-k\">with</span>\
    \ <span class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span\
    \ class=\"pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\"\
    >pymargo</span>.<span class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span>\
    \ <span class=\"pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">mid</span>.<span class=\"\
    pl-en\">register</span>(<span class=\"pl-s\">\"cross_product\"</span>)\n\t<span\
    \ class=\"pl-s1\">p1</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >Point</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span\
    \ class=\"pl-c1\">3</span>)\n\t<span class=\"pl-s1\">p2</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-v\">Point</span>(<span class=\"pl-c1\">4</span>,<span\
    \ class=\"pl-c1\">5</span>,<span class=\"pl-c1\">6</span>)\n\t<span class=\"pl-s1\"\
    >ret</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">mid</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-s1\">p1</span>,\
    \ <span class=\"pl-s1\">p2</span>)\n\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-en\">str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633974436.0
mochi-hpc/py-mochi-sonata:
  data_format: 2
  description: Python binding to the Mochi Sonata microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-sonata
  latest_release: null
  readme: '<p>Py-Sonata is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-sonata">Sonata
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975502.0
mochi-hpc/py-mochi-ssg:
  data_format: 2
  description: Python wrapper for SSG group membership service
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-ssg
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1640536463.0
mpbelhorn/olcf-spack-environments:
  data_format: 2
  description: Spack environments for OLCF resources.
  filenames:
  - hosts/summit/envs/base-rh7/spack.yaml
  - hosts/lyra/envs/base/spack.yaml
  - hosts/peak/envs/base/spack.yaml
  - hosts/ascent/envs/base/spack.yaml
  - hosts/andes/envs/base/spack.yaml
  - hosts/cirrus/envs/base/spack.yaml
  - hosts/borg/envs/base/spack.yaml
  - hosts/frontier/envs/base/spack.yaml
  - hosts/ascent/envs/base-rh7/spack.yaml
  - hosts/bones/envs/base/spack.yaml
  - hosts/spock/envs/base/spack.yaml
  full_name: mpbelhorn/olcf-spack-environments
  latest_release: null
  readme: '<h1>

    <a id="user-content-olcf-spack-environments" class="anchor" href="#olcf-spack-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>OLCF
    Spack Environments</h1>

    <p>This repo contains the infrastructure and environment definitions to deploy

    site-provided software on OLCF resources via Spack environments.</p>

    <h2>

    <a id="user-content-getting-started" class="anchor" href="#getting-started" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Started</h2>

    <p>Clone this repo and it''s facility-modified spack fork somewhere on an OLCF

    filesystem:</p>

    <pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git

    </code></pre>

    <p>or</p>

    <pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments

    </code></pre>

    <p>Next, initialize spack and the build environment. This is done by calling</p>

    <pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base
    . ./init-facility-spack.sh

    </code></pre>

    <p>This will configure the spack build- and run-time environment build and install

    the facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this
    repo for the

    current machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both
    of these

    variables are optional. If omitted, each variable will take on their default

    values:</p>

    <pre><code>FACSPACK_MY_ENVS="/sw/${_THIS_HOST}/spack-envs"

    FACSPACK_ENV_NAME="base"

    </code></pre>

    <p>such that sourcing this script by itself</p>

    <pre><code>. ./init-facility-spack.sh

    </code></pre>

    <p>will setup the runtime shell environment to manipulate the production spack

    environment on the current system.</p>

    <p>This repo will always track at least one spack environment per machine named

    <code>base</code> which is the complete standard software environment used in
    production

    for that machine. Furthermore, only the user account with owner permissions on

    the production environment may be used to manipulate it in the default

    <code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent
    multiple

    users from concurrently modifying the production environment. Users may set an

    alternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using
    any

    tracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file
    in this repo.</p>

    <p>From these variables, a unique path per each environment name will be

    constructed:</p>

    <pre><code>FACSPACK_ENV="${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}"

    </code></pre>

    <p>The value of <code>${_THIS_HOST}</code> is determined automatically from the
    hostname on

    which the init script is being run. For each system and environment tracked in

    this repo that you wish to work on, ensure that the final expanded value of

    <code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>

    <p>Configuration paths in our <code>spack.yaml</code> environments that are not
    fixed to

    universal values are expressed in terms of relative paths to either the spack

    instance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.

    These paths are referenced in the <code>spack.yaml</code> files via environment
    variables

    set by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code>
    environment files to

    define portable and relocatable spack environments which can be re-deployed in

    arbitrary private locations by any users without needing to modify the

    environment file.</p>

    <p>The following variables are exported in Spack''s runtime environment by

    <code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code>
    the enviornment

    files tracked in this repo.</p>

    <ul>

    <li>

    <code>${FACSPACK_ENV}</code>:

    Path to where spack environment will be installed. Contains subdirs <code>opt</code>

    and <code>modules</code>.</li>

    <li>

    <code>${FACSPACK_ENV_MODULEROOT}</code>:

    Shortcut to <code>${FACSPACK_ENV}/modules</code> under which static and

    spack-generated modules are generated. Contains subdirectories <code>spack</code>,

    <code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static
    modulefiles

    respectively.</li>

    <li>

    <code>${FACSPACK_CONF_COMMON}</code>:

    Path to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>

    <li>

    <code>${FACSPACK_CONF_HOST}</code>:

    Path to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>

    </li>

    </ul>

    <p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>

    files which cannot de-reference environment variables. These affect</p>

    <ul>

    <li>Mirrors</li>

    <li>Extensions</li>

    </ul>

    <p>Spack does not internally expand environment variables in the configuration
    of

    these items so they must be expressed as hard-coded full path strings. The

    default values in this repo should point to permanent world-readable paths on

    the OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>

    <h2>

    <a id="user-content-spack-fork" class="anchor" href="#spack-fork" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Fork</h2>

    <p>The upstream development branch of spack is not used directly. Instead, the
    OLCF

    has implemented some customizations that are tracked in the "olcf-X.Y.Z"

    branches of a <a href="https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0">facility
    fork of spack</a>

    where <code>X.Y.Z</code> refers to the tagged release of upstream spack from which
    the

    OLCF-modified branch is forked.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1645668126.0
ndevelder/cmb:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: ndevelder/cmb
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1647450577.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - linux-rhel8-ppc64le/summit/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_env/index.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2>

    <a id="user-content-purpose" class="anchor" href="#purpose" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 19
  topics: []
  updated_at: 1635266343.0
pdidev/test_env:
  data_format: 2
  description: Testing environment for PDI
  filenames:
  - spack/2-spack/spack.yaml
  full_name: pdidev/test_env
  latest_release: null
  readme: '<h1>

    <a id="user-content-docker-images" class="anchor" href="#docker-images" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker images:</h1>

    <p>A set of related Docker images to build and test PDI.</p>

    <p>We provide images based on:</p>

    <ul>

    <li>Dask recipes,</li>

    <li>Binary packages.</li>

    </ul>

    <h2>

    <a id="user-content-dask-based-images" class="anchor" href="#dask-based-images"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dask-based
    images</h2>

    <p>These images are based on a minimal Ubuntu 18.08, with spack and all dependencies
    installed through

    spack.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/spack/${deps_version}/${compiler}/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>deps_version</code>:

    <ul>

    <li>

    <code>oldest</code>: dependencies use the oldest versions supported by PDI,</li>

    <li>

    <code>latest</code>: dependencies use the latest versions available in spack at
    the time of generation,</li>

    </ul>

    </li>

    <li>

    <code>compiler</code>:

    <ul>

    <li>

    <code>gcc</code>:   using GCC compiler,</li>

    <li>

    <code>clang</code>: using clang for C/C++ and gfortran for Fortran,</li>

    </ul>

    </li>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image.</li>

    </ul>

    </li>

    </ul>

    <h2>

    <a id="user-content-binary-package-based-images" class="anchor" href="#binary-package-based-images"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binary
    package based images</h2>

    <p>These images are based on Ubuntu 18.08, with all dependencies installed through
    packages.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/ubuntu/bionic/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>mpich</code>: using mpich implementation of MPI,</li>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image,</li>

    <li>

    <code>pdi</code>: PDI is included in the image.</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1641653805.0
player1537-playground/metem:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537-playground/metem
  latest_release: null
  readme: '<h1>

    <a id="user-content-metem-scripts" class="anchor" href="#metem-scripts" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Metem Scripts</h1>

    <p>This repository includes all of the scripts written for the Metem paper as
    part

    of the Triple-R subgoal of the Triple-Convergence project.</p>

    <p>The code is split into 4 categories:</p>

    <ul>

    <li>Overall environment setup (<code>/go.sh</code>)</li>

    <li>Metem-specific code (<code>/metem/</code>)</li>

    <li>ImageNet/ResNet50-specific code (<code>/imagenet/</code>)</li>

    <li>NT3-specific code (<code>/nt3/</code>)</li>

    </ul>

    <h2>

    <a id="user-content-setup" class="anchor" href="#setup" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <p>To setup the environment, run the following command:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">./go.sh
    buildall</span></pre></div>

    <p>This command runs a lot of separate commands in order. Those separate commands

    are:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">./go.sh
    singularity build</span>

    $ <span class="pl-s1">./go.sh spack install</span>

    $ <span class="pl-s1">./go.sh virtualenv setup</span>

    $ <span class="pl-s1">./go.sh wrh configure</span>

    $ <span class="pl-s1">./go.sh wrh build</span>

    $ <span class="pl-s1">./go.sh wrh install</span></pre></div>

    <h2>

    <a id="user-content-existing-data" class="anchor" href="#existing-data" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Existing Data</h2>

    <p>There is already some existing data, primarily checkpoints and log files.</p>

    <p>For ResNet50, these are at:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">ls
    /lus/theta-fs0/projects/VeloC/metem/logs/ai-apps/checkpoint-<span class="pl-k">*</span>e.h5</span>

    $ <span class="pl-s1">ls /lus/theta-fs0/projects/VeloC/metem/logs/ai-apps/<span
    class="pl-k">*</span>of8.log</span></pre></div>

    <p>For example,

    <code>/lus/theta-fs0/projects/VeloC/metem/logs/ai-apps/checkpoint-5e.h5</code>
    is the

    checkpoint taken after 5 epochs have completed.</p>

    <p>For NT3, these are at:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">ls
    /lus/theta-fs0/projects/VeloC/metem/logs/BL<span class="pl-cce">\,</span>dataset<span
    class="pl-cce">\=</span>NT3<span class="pl-cce">\,</span>model<span class="pl-cce">\=</span>default<span
    class="pl-cce">\,</span>nworkers<span class="pl-cce">\=</span>8<span class="pl-cce">\,</span>seed<span
    class="pl-cce">\=</span>1337<span class="pl-cce">\,</span>div<span class="pl-cce">\=</span>1<span
    class="pl-cce">\,</span>nepochs<span class="pl-cce">\=</span>200/checkpoint-<span
    class="pl-k">*</span>.h5</span>

    $ <span class="pl-s1">ls /lus/theta-fs0/projects/VeloC/metem/logs/BL<span class="pl-cce">\,</span>dataset<span
    class="pl-cce">\=</span>NT3<span class="pl-cce">\,</span>model<span class="pl-cce">\=</span>default<span
    class="pl-cce">\,</span>nworkers<span class="pl-cce">\=</span>8<span class="pl-cce">\,</span>seed<span
    class="pl-cce">\=</span>1337<span class="pl-cce">\,</span>div<span class="pl-cce">\=</span>1<span
    class="pl-cce">\,</span>nepochs<span class="pl-cce">\=</span>200/<span class="pl-k">*</span>of8.log</span></pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1629779829.0
range3/spack-playground:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  - spack/envs/broken-verbs-chris8x/spack.yaml
  full_name: range3/spack-playground
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-spack-playground\" class=\"anchor\" href=\"\
    #spack-playground\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>spack-playground</h1>\n<h2>\n<a id=\"user-content-development\"\
    \ class=\"anchor\" href=\"#development\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Development</h2>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> /workspaces/spack-playground\n\
    spack env activate -d spack/envs/dev\nspack install --keep-stage</pre></div>\n\
    <h2>\n<a id=\"user-content-activate-intellisense-provided-by-clangd\" class=\"\
    anchor\" href=\"#activate-intellisense-provided-by-clangd\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>activate\
    \ IntelliSense provided by clangd</h2>\n<ul>\n<li>the vsode extensions are already\
    \ installed in the dev container.</li>\n<li>open vscode command palette\n<ul>\n\
    <li><code>&gt; clangd: Download language server</code></li>\n<li><code>&gt; Developper:\
    \ Reload Window</code></li>\n</ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-create-new-spack-env-if-you-want\"\
    \ class=\"anchor\" href=\"#create-new-spack-env-if-you-want\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Create new\
    \ spack env if you want</h2>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> /workspaces/spack-playground\nspack env\
    \ create -d spack/envs/dev2\nspack env activate -d spack/envs/dev2\nspack compiler\
    \ find\nspack external find\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ edit spack/envs/dev2/spack.yaml</span>\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span># suggestion: remove openssl and python from external packages</span>\n\
    spack concretize -f\nspack install --keep-stage</pre></div>\n<h2>\n<a id=\"user-content-3rd-party-library-license\"\
    \ class=\"anchor\" href=\"#3rd-party-library-license\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>3rd Party Library\
    \ License</h2>\n<h3>\n<a id=\"user-content-akka-httpsgithubcomakkaakka\" class=\"\
    anchor\" href=\"#akka-httpsgithubcomakkaakka\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Akka (<a href=\"https://github.com/akka/akka\"\
    >https://github.com/akka/akka</a>)</h3>\n<details><summary>Apache 2 license</summary>\n\
    <pre><code>This software is licensed under the Apache 2 license, quoted below.\n\
    \nCopyright 2009-2018 Lightbend Inc. &lt;https://www.lightbend.com&gt;\n\nLicensed\
    \ under the Apache License, Version 2.0 (the \"License\"); you may not\nuse this\
    \ file except in compliance with the License. You may obtain a copy of\nthe License\
    \ at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable\
    \ law or agreed to in writing, software\ndistributed under the License is distributed\
    \ on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either\
    \ express or implied. See the\nLicense for the specific language governing permissions\
    \ and limitations under\nthe License.\n</code></pre>\n</details>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1639559107.0
salotz/raylib-scopes:
  data_format: 2
  description: Raylib wrapper for the Scopes language
  filenames:
  - spack.yaml
  full_name: salotz/raylib-scopes
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1640236109.0
scs-lab/ChronoLog:
  data_format: 2
  description: 'ChronoLog: A High-Performance Storage Infrastructure for Activity
    and Log Workloads'
  filenames:
  - CI/enviroment/spack.yaml
  full_name: scs-lab/ChronoLog
  latest_release: null
  readme: '<h1>

    <a id="user-content-chronolog" class="anchor" href="#chronolog" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ChronoLog</h1>

    <p>ChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads
    (NSF CSSI 2104013)</p>

    <h2>

    <a id="user-content-chronolog-project-synopsis" class="anchor" href="#chronolog-project-synopsis"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ChronoLog
    Project Synopsis</h2>

    <p>This project will design and implement ChronoLog, a distributed and tiered
    shared log storage ecosystem. ChronoLog uses physical time to distribute log entries
    while providing total log ordering. It also utilizes multiple storage tiers to
    elastically scale the log capacity (i.e., auto-tiering). ChronoLog will serve
    as a foundation for developing scalable new plugins, including a SQL-like query
    engine for log data, a streaming processor leveraging the time-based data distribution,
    a log-based key-value store, and a log-based TensorFlow module.</p>

    <h2>

    <a id="user-content-workloads-and-applications" class="anchor" href="#workloads-and-applications"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Workloads
    and Applications</h2>

    <p>Modern applications spanning from Edge to High Performance Computing (HPC)
    systems, produce and process log data and create a plethora of workload characteristics
    that rely on a common storage model: <strong>the distributed shared log</strong>.</p>

    <p><a href="/doc/images/log_centric_paradigm.svg" target="_blank" rel="noopener
    noreferrer"><img src="/doc/images/log_centric_paradigm.svg" alt="Log centric paradigm"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-features" class="anchor" href="#features" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Features</h2>

    <p><a href="/doc/images/feature-matrix.png" target="_blank" rel="noopener noreferrer"><img
    src="/doc/images/feature-matrix.png" alt="Feature matrix" style="max-width:100%;"></a></p>

    <hr>

    <h1>

    <a id="user-content-coming-soon-" class="anchor" href="#coming-soon-" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Coming soon ...</h1>

    <p>For more details about the ChronoLog project, please visit our website <a href="http://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html"
    rel="nofollow">http://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1646325735.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - OLCF/crusher/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configs" class="anchor" href="#spack-configs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 37
  subscribers_count: 23
  topics: []
  updated_at: 1639405494.0
srini009/ascent_microservice:
  data_format: 2
  description: Ascent visualization microservice built using the Mochi software stack
  filenames:
  - spack.yaml
  full_name: srini009/ascent_microservice
  latest_release: null
  readme: '<h1>

    <a id="user-content-ascent-visualization-microservice" class="anchor" href="#ascent-visualization-microservice"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ascent
    Visualization Microservice</h1>

    <p>This is an experimental repo implementing a distributed Ascent visualization
    microservice.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641530283.0
supercontainers/sc-tutorials:
  data_format: 2
  description: SC Tutorials
  filenames:
  - exercises/spack_containerize/spack.yaml
  full_name: supercontainers/sc-tutorials
  latest_release: null
  readme: '<h1>

    <a id="user-content-getting-started-with-containers-on-hpc" class="anchor" href="#getting-started-with-containers-on-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/sc-tutorials/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2>

    <a id="user-content-ecp-supercontainers-tutorial-session" class="anchor" href="#ecp-supercontainers-tutorial-session"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ECP
    Supercontainers Tutorial Session</h2>

    <p><a href="fig/ecp.jpg" target="_blank" rel="noopener noreferrer"><img src="fig/ecp.jpg"
    width="200" style="max-width:100%;"></a><a href="fig/pawsey.png" target="_blank"
    rel="noopener noreferrer"><img src="fig/pawsey.png" width="200" style="max-width:100%;"></a><a
    href="fig/redhat.png" target="_blank" rel="noopener noreferrer"><img src="fig/redhat.png"
    width="200" style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-details" class="anchor" href="#details" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Full-day Tutorial Session</p>

    <p>Venue: Supercomputing Conference (SC 21)</p>

    <p>Date: Monday, 15 November 2021 8am - 5pm Central Standard Time (GMT -6)</p>

    <p>Location: Virtual, St. Louis MO, USA</p>

    <p>Link: <a href="https://sc21.supercomputing.org/presentation/?id=tut114&amp;sess=sess185"
    rel="nofollow">SC 2021 Tutorial Details</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2>

    <a id="user-content-ec2-login" class="anchor" href="#ec2-login" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EC2 Login</h2>

    <p>These will be provided the day of the tutorial.</p>

    <h2>

    <a id="user-content-abstract" class="anchor" href="#abstract" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Within just the past few years, the use of containers has revolutionized the
    way in which industries and enterprises have developed and deployed computational
    software and distributed systems. The containerization model has gained traction
    within the HPC community as well with the promise of improved reliability, reproducibility,
    portability, and levels of customization that were previously not possible on
    supercomputers. This adoption has been enabled by a number of HPC Container runtimes
    that have emerged including Singularity, Shifter, Enroot, Charliecloud and others.</p>

    <p>This hands-on tutorial looks to train users on the usability of containers
    on HPC resources. We will provide a detailed background on Linux containers, along
    with introductory hands-on experience building a container image, sharing the
    container and running it on a HPC cluster. Furthermore, the tutorial will provide
    more advanced information on how to run MPI-based and GPU-enabled HPC applications,
    how to optimize I/O intensive workflows, and how to setup GUI enabled interactive
    sessions. Cutting-edge examples will include machine learning and bioinformatics.
    Users will leave the tutorial with a solid foundational understanding of how to
    utilize containers with HPC resources through Shifter and Singularity, as well
    as an in-depth knowledge to deploy custom containers on their own resources.</p>

    <h2>

    <a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This is a hands-on tutorial.  Participants should bring a laptop and load or
    pre-install a terminal and/or ssh client in advance to make best use of time during
    the tutorial.  We will be providing training user accounts to both pre-configured
    EC2 instances.</p>

    <div><a href="fig/AWS_logo.png" target="_blank" rel="noopener noreferrer"><img
    src="fig/AWS_logo.png" width="250" style="max-width:100%;"></a></div>

    <p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards.  EC2
    images and temporary login credentials will be distributed onsite at the tutorial.</p>

    <p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2
    to run through the tutorial again. We recommend you use your own EC2 key and change
    the password.</p>

    <p>US-West-Oregon: ami-0fe12765123c6a840</p>

    <h3>

    <a id="user-content-optional-prerequisites" class="anchor" href="#optional-prerequisites"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optional
    Prerequisites</h3>

    <p>Users can also install Docker and Singularity prior to attending the tutorial
    session.  Here, it may be beneficial to create Docker and Sylabs (Singularity)
    accounts in advance at <a href="https://cloud.docker.com/" rel="nofollow">https://cloud.docker.com/</a>
    and <a href="https://cloud.sylabs.io/" rel="nofollow">https://cloud.sylabs.io/</a>.  These
    accounts will be needed to create images on Docker Cloud/Dockerhub and Sylabs
    Cloud.</p>

    <p><a href="https://sylabs.io/guides/3.7/user-guide/" rel="nofollow">Install Singularity
    on Linux</a></p>

    <p><a href="https://repo.sylabs.io/desktop/" rel="nofollow">Install Singularity
    on Mac</a> (Alpha)</p>

    <p><a href="https://www.docker.com/products/docker-desktop" rel="nofollow">Install
    Docker for Desktop</a></p>

    <h2>

    <a id="user-content-questions" class="anchor" href="#questions" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2>

    <a id="user-content-schedule" class="anchor" href="#schedule" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Schedule</h2>

    <p>8:00 - 8:20 Introduction and update on Linux containers - SLIDES (Shane)</p>

    <p>8:20 - 8:50 Building and running Docker containers (Shane)</p>

    <p>8:50 - 9:30 Advanced container builds (Eduardo)</p>

    <p>9:30 - 9:55 Container images best practices (Shane)</p>

    <p>9:55 - 10:00 Interactive Q &amp; A session</p>

    <p>10:00 - 10:30 MORNING BREAK</p>

    <p>10:30 - 10:50 HPC and containers - SLIDES (Shane)</p>

    <p>10:50 - 11:10 Installing a container engine - SLIDES (Marco)</p>

    <p>11:10 - 11:50 Running HPC jobs with containers (Marco)</p>

    <p>11:50 - 12:00 Interactive Q &amp; A session</p>

    <p>12:00 - 13:00 LUNCH BREAK</p>

    <p>13:00 - 13:30 Optional Q &amp; A session (including Slurm)</p>

    <p>13:30 - 14:20 Advanced HPC use cases (Marco)</p>

    <p>14:20 - 15:00 Container services and Kubernetes (multiple presenters)</p>

    <p>15:00 - 15:30 AFTERNOON BREAK</p>

    <p>15:30 - 16:20 Containers with E4S (Sameer)</p>

    <p>16:20 - 16:40 Success stories and use cases (Shane)</p>

    <p>16:40 - 17:00 Final Q &amp; A, wrap-up, and feedback survey</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1636605005.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2022.03.07
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width:100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2022.03.07\"\
    ><img src=\"https://camo.githubusercontent.com/bc1b92e32abbee4e3df17ad35d3af09db54a4ce202bb8f5e96dbb125df69ac43/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032322e30332e30372d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2022.03.07-informational\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.6335350\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/01a452dfc2f4cc56792a851aad7a612562934ef65b99ecf76517810c8b3f21f5/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e363333353335302e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.6335350.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" href=\"#what-is-spectre\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>What is SpECTRE?</h2>\n<p>SpECTRE\
    \ is an open-source code for multi-scale, multi-physics problems\nin astrophysics\
    \ and gravitational physics. In the future, we hope that\nit can be applied to\
    \ problems across discipline boundaries in fluid\ndynamics, geoscience, plasma\
    \ physics, nuclear physics, and\nengineering. It runs at petascale and is designed\
    \ for future exascale\ncomputers.</p>\n<p>SpECTRE is being developed in support\
    \ of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into\
    \ the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae,\
    \ and\ngamma-ray bursts.</p>\n<h2>\n<a id=\"user-content-citing-spectre\" class=\"\
    anchor\" href=\"#citing-spectre\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Citing SpECTRE</h2>\n<p>Please cite\
    \ SpECTRE in any publications that make use of its code or data. Cite\nthe latest\
    \ version that you use in your publication. The DOI for this version\nis:</p>\n\
    <ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.6335350\" rel=\"nofollow\"\
    >10.5281/zenodo.6335350</a>\n</li>\n</ul>\n<p>You can cite this BibTeX entry in\
    \ your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"><pre><span\
    \ class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and H\\'ebert, Fran\\c{c}ois and Moxon,\
    \ Jordan and Armaza, Crist\\'obal and</span>\n<span class=\"pl-s\">Bonilla, Gabriel\
    \ S. and Kim, Yoonsoo and Kumar, Prayush and Lovelace, Geoffrey</span>\n<span\
    \ class=\"pl-s\">and Macedo, Alexandra and Nelli, Kyle C. and O'Shea, Eamonn and\
    \ Pfeiffer, Harald</span>\n<span class=\"pl-s\">P. and Scheel, Mark A. and Teukolsky,\
    \ Saul A. and Wittek, Nikolas A. and</span>\n<span class=\"pl-s\">others<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> =\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2022.03.07}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2022.03.07<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">publisher</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Zenodo<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">doi</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>10.5281/zenodo.6335350<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>https://spectre-code.org<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">howpublished</span> =\n<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.6335350}{10.5281/zenodo.6335350}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2022<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>3<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2>\n<a\
    \ id=\"user-content-viewing-documentation\" class=\"anchor\" href=\"#viewing-documentation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Viewing Documentation</h2>\n<p>The documentation can be viewed at\
    \ <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 103
  subscribers_count: 14
  topics: []
  updated_at: 1646439386.0
tachidok/scicellxx:
  data_format: 2
  description: SciCell++ is an object-oriented framework for the simulation of biological
    and physical phenomena modelled as continuous or discrete processes.
  filenames:
  - tools/development/docker_and_spack/01_build_docker_DEVEL_spack_INSTALLED/spack.yaml
  full_name: tachidok/scicellxx
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-scicell\" class=\"anchor\" href=\"#scicell\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>SciCell++</h1>\n<p><a href=\"https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\"\
    \ target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\"\
    \ alt=\"GitHub-master-push\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/tachidok/scicellxx\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4d304208a40f5037293d6f8b02ab726b9654e85e8557e43b51ae5a91077fa596/68747470733a2f2f636f6465636f762e696f2f67682f7461636869646f6b2f73636963656c6c78782f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d4a41414f465353314951\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/tachidok/scicellxx/branch/master/graph/badge.svg?token=JAAOFSS1IQ\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://scicellxx.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6ada579e5e58ef38465ec81b91143b7b634c899e63a4a834dc39199f9ded19e6/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73636963656c6c78782f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/scicellxx/badge/?version=latest\"\
    \ style=\"max-width:100%;\"></a></p>\n<hr>\n<p>SciCell++ is an object-oriented\
    \ framework for the simulation of biological and physical phenomena modelled as\
    \ continuous or discrete processes.</p>\n<h2>\n<a id=\"user-content-table-of-contents\"\
    \ class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Table of Contents</h2>\n<ol>\n\
    <li><a href=\"#documentation\">Documentation</a></li>\n<li><a href=\"#featured_demos\"\
    >Featured demos</a></li>\n<li><a href=\"#how_to_contribute\">How to contribute</a></li>\n\
    <li><a href=\"#facts_and_curiosities\">Facts and curiosities</a></li>\n<li><a\
    \ href=\"#license\">License</a></li>\n</ol>\n<h2>\n<a id=\"user-content-documentation-\"\
    \ class=\"anchor\" href=\"#documentation-\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation <a name=\"user-content-documentation\"\
    ></a>\n</h2>\n<p>The full documentation is\n<a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\">here</a>. You\nwill find installation instructions, demos,\
    \ tutorials and workflows to\nease your journey with SciCell++.</p>\n<h2>\n<a\
    \ id=\"user-content-featured-demos-\" class=\"anchor\" href=\"#featured-demos-\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Featured demos <a name=\"user-content-featured_demos\"></a>\n</h2>\n\
    <ul>\n<li>Interpolation</li>\n<li>Linear solvers</li>\n<li>Matrices operations</li>\n\
    <li>Newton's method</li>\n<li>Solution of ODE's\n<ul>\n<li>Lotka-Volterra solved\
    \ with different time steppers</li>\n<li>N-body problem (only 3-body and 4-body)</li>\n\
    <li>Explicit time steppers</li>\n<li>Implicit time steppers (full implicit and\
    \ <em>E(PC)^k E</em>\nimplementations)</li>\n<li>Adaptive time steppers</li>\n\
    </ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-how-to-contribute-\" class=\"\
    anchor\" href=\"#how-to-contribute-\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to contribute <a name=\"\
    user-content-how_to_contribute\"></a>\n</h2>\n<p>Please check the\n<a href=\"\
    https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">constributions</a>\n\
    section in the documentation.</p>\n<h5>\n<a id=\"user-content-optional\" class=\"\
    anchor\" href=\"#optional\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Optional</h5>\n<ul>\n<li>MPI support for parallel\
    \ features - <code>not currently supported</code>.</li>\n</ul>\n<h2>\n<a id=\"\
    user-content-facts-and-curiosities-\" class=\"anchor\" href=\"#facts-and-curiosities-\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Facts and curiosities <a name=\"user-content-facts_and_curiosities\"\
    ></a>\n</h2>\n<h3>\n<a id=\"user-content-how-many-developers-are-currently-working-on-this-project\"\
    \ class=\"anchor\" href=\"#how-many-developers-are-currently-working-on-this-project\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>How many developers are currently working on this project?</h3>\n\
    <p>At Thursday, December/23, 2021 there is one and only one developer, me\n<g-emoji\
    \ class=\"g-emoji\" alias=\"no_mouth\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f636.png\"\
    >\U0001F636</g-emoji> <g-emoji class=\"g-emoji\" alias=\"envelope\" fallback-src=\"\
    https://github.githubassets.com/images/icons/emoji/unicode/2709.png\">\u2709\uFE0F\
    </g-emoji></p>\n<p><g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"\
    https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\U0001F6A7\
    </g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\"\
    >\U0001F6A7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"\
    https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\U0001F6A7\
    </g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\"\
    >\U0001F6A7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"\
    https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\U0001F6A7\
    </g-emoji></p>\n<h3>\n<a id=\"user-content-when-did-this-start\" class=\"anchor\"\
    \ href=\"#when-did-this-start\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>When did this start?</h3>\n<p>This\
    \ project was initially uploaded to GitHub on Friday, 11 March 2016\n<g-emoji\
    \ class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f604.png\"\
    >\U0001F604</g-emoji></p>\n<h2>\n<a id=\"user-content-license-\" class=\"anchor\"\
    \ href=\"#license-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>License <a name=\"user-content-license\"></a>\n\
    </h2>\n<p>Licensed under the GNU GPLv3. A copy can be found on the <a href=\"\
    ./LICENSE\">LICENSE</a> file.</p>\n"
  stargazers_count: 4
  subscribers_count: 2
  topics:
  - numerical-methods
  - finite-element-methods
  - parallel-programming
  - linear-algebra
  - equation-solver
  - smoothed-particle-hydrodynamics
  - finite-difference-methods
  - object-oriented-programming
  - mesh-free-methods
  - computational-biology
  - cellular-automata
  updated_at: 1642555179.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/intelmpi/bpmf-mpi_isend/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/intelmpi/bpmf-gpi/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-mpi_isend/spack.yaml
  - var/spack/environments/karolina/bpmf-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-gpi/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-cluster/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1635166163.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - spack-environments/myriad/spack.yaml
  - spack-environments/csd3/spack.yaml
  - spack-environments/github-actions/spack.yaml
  - spack-environments/cosma8/spack.yaml
  - spack-environments/isambard-cascadelake/spack.yaml
  - spack-environments/tesseract/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-excalibur-tests\" class=\"anchor\" href=\"#excalibur-tests\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks and regression tests\
    \ for the ExCALIBUR project.</p>\n<p>These benchmarks are based on a similar project\
    \ by\n<a href=\"https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2>\n\
    <a id=\"user-content-requirements\" class=\"anchor\" href=\"#requirements\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h2>\n\
    <h3>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><em><strong>Note</strong>: in some HPC facilities there may be already a central\
    \ Spack\ninstallation available.  In principle you should be able to use that\
    \ one (you\nonly need to set the <code>SPACK_ROOT</code> environment variable),\
    \ but you may need an\nup-to-date version of Spack in order to install some packages.\
    \  Instructions\nbelow show you how to install Spack locally.</em></p>\n<p><a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager specifically\
    \ designed for HPC\nfacilities.  Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall the latest version of\
    \ Spack.</p>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable.  This\
    \ can be achieved for instance by running\nthe commands to get shell support described\
    \ in Spack documentation, which you\ncan also add to your shell init script to\
    \ do it automatically in every session.\nFor example, if you use a shell of the\
    \ family bash/zsh/sh you can add to your\ninit script:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR project.  If you want to\
    \ use a different Spack environment, set the\nenvironment variable <code>EXCALIBUR_SPACK_ENV</code>\
    \ to the path of the directory where\nthe environment is.  If this is not set,\
    \ ReFrame will try to use the environment\nfor the current system, if known, otherwise\
    \ it will automatically create a very\nbasic environment.</p>\n<h3>\n<a id=\"\
    user-content-reframe\" class=\"anchor\" href=\"#reframe\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ReFrame</h3>\n\
    <p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\" rel=\"nofollow\"\
    >ReFrame</a> is a high-level\nframework for writing regression tests for HPC systems.\
    \  For our tests we\nrequire ReFrame 3.8.0.  Follow the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall this package.  Note\
    \ that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a\
    \ specific module to have this version of Python available.</p>\n<p>We provide\
    \ a ReFrame configuration file with the settings of some systems that\nare part\
    \ of the ExCALIBUR project.  You can point ReFrame to this file by\nsetting the\n\
    <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILE</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILE=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${PWD}</span>/reframe_config.py<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>If you want to use a different ReFrame configuration file, for example because\n\
    you use a different system, you can set this environment variable to the path\
    \ of\nthat file.</p>\n<p><strong>Note</strong>: in order to use the Spack build\
    \ system in ReFrame, the <code>spack</code>\nexecutable must be in the <code>PATH</code>,\
    \ also on the computing nodes of a cluster, if\nyou want to run your benchmarks\
    \ on them.  Note that by default ReFrame uses</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a>, which would not load\nthe user's init script.  If you have added\
    \ Spack to your <code>PATH</code> within your init\nscript, you may want to set\
    \ the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ in order to make ReFrame use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash\
    \ -l</span></pre></div>\n<p>as shebang line, instead.</p>\n<h3>\n<a id=\"user-content-extra-python-modules\"\
    \ class=\"anchor\" href=\"#extra-python-modules\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Extra Python modules</h3>\n<p>The\
    \ benchmarks in this suite will additionally need the following Python modules:</p>\n\
    <ul>\n<li><a href=\"https://matplotlib.org/\" rel=\"nofollow\"><code>matplotlib</code></a></li>\n\
    <li><a href=\"https://pandas.pydata.org/\" rel=\"nofollow\"><code>pandas</code></a></li>\n\
    </ul>\n<p>Check the recommended way to install Python modules in your system,\
    \ it may be\nfor example by using <code>pip</code>, or creating environments with\
    \ <code>pyenv</code> or\nConda/Anaconda. For example, see <a href=\"https://docs.hpc.cam.ac.uk/hpc/software-tools/python.html\"\
    \ rel=\"nofollow\">the guide for CSD3</a>.</p>\n<h2>\n<a id=\"user-content-usage\"\
    \ class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<p>Once you have set up\
    \ Spack and ReFrame, you can execute a benchmark with</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/BENCH_NAME -r --performance-report</pre></div>\n\
    <p>where <code>apps/BENCH_NAME</code> is the directory where the benchmark is.\
    \  The command\nabove supposes you have the program <code>reframe</code> in your\
    \ PATH, if it is not the\ncase you can also call <code>reframe</code> with its\
    \ relative or absolute path.  For\nexample, to run the Sombrero benchmark in the\
    \ <code>apps/sombrero</code> directory you can\nuse</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/sombrero -r --performance-report</pre></div>\n\
    <p>For benchmark using the Spack build system, the tests define a default Spack\
    \ specification\nto be installed in the environment, but users can change it when\
    \ invoking ReFrame on the\ncommand line with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c apps/sombrero -r --performance-report -S\
    \ spack_spec='sombrer@2021-08-16%intel'\n</code></pre>\n<h3>\n<a id=\"user-content-selecting-system-and-queue-access-options\"\
    \ class=\"anchor\" href=\"#selecting-system-and-queue-access-options\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  You can always use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h2>\n<a id=\"user-content-contributing-new-systems-or-benchmarks\"\
    \ class=\"anchor\" href=\"#contributing-new-systems-or-benchmarks\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\n\
    <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1638371749.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-374/spack.yaml
  - spackenvs/python-38/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: 0.8.0
  stargazers_count: 10
  subscribers_count: 5
  topics:
  - jupyter
  - jupyter-notebooks
  - jupyter-kernels
  - ipython
  - ipywidgets
  - ipython-widget
  - spack
  - pipenv
  - dvc
  - data-science
  - pandas
  updated_at: 1641756482.0
wangzhezhe/Gorilla:
  data_format: 2
  description: The Gorilla framework which provides distributed in-memory data management
    service
  filenames:
  - spack.yaml
  - spack_cpu.yaml
  full_name: wangzhezhe/Gorilla
  latest_release: null
  readme: "<h2>\n<a id=\"user-content-motivation\" class=\"anchor\" href=\"#motivation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Motivation</h2>\n<p>Gorilla framework is a in-memory data management\
    \ servie. The name of the framework comes from the brand \"gorilla glue\", since\
    \ we are basically gluing different components together. It mainly supoorts follwing\
    \ capabilities:</p>\n<p>(1) suppot M:N data put/get for data based on grid mesh.</p>\n\
    <p>(2)User can use customized trigger to express the logic flow of the task executions.\
    \ The implementation of in-memory data storage service layer is inspired by the\
    \ <a href=\"https://github.com/philip-davis/dataspaces\">DataSpaces</a> and the\
    \ <a href=\"https://github.com/ornladios/ADIOS2\">ADIOS</a> projects. [adios test\
    \ case is deprecated]</p>\n<p>(3)There is specific event queue binded with the\
    \ trigger to support the data-driven task executions, the properties of the data\
    \ can be captured and client can acquire the metadata of the raw data by poll\
    \ events. The idea of data driven approach mainly comes from the <a href=\"https://www.osti.gov/biblio/1493245\"\
    \ rel=\"nofollow\">OSTI technical report</a>.</p>\n<p><strong>More key design\
    \ strategies can be found at the designDoc/scratch.md</strong></p>\n<h2>\n<a id=\"\
    user-content-compiling-and-running-the-server\" class=\"anchor\" href=\"#compiling-and-running-the-server\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Compiling and running the server</h2>\n<p>this is an eample to compile\
    \ the gorilla server on cori cluster</p>\n<pre><code>source ~/.gorilla\ncmake\
    \ ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=~/cworkspace/src/VTK/build/\
    \ -DUSE_GNI=ON\n</code></pre>\n<p>If the paraveiw is used for particular test</p>\n\
    <pre><code>old one\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc\
    \ -DVTK_DIR=$SCRATCH/build_paraview_matthieu_release/ -DUSE_GNI=ON -DParaView_DIR=$SCRATCH/build_paraview_matthieu/\
    \ -DBUILD_SHARED_LIBS=ON -DAMReX_DIR=/global/cscratch1/sd/zw241/build_amrex/install/lib/cmake/AMReX\n\
    </code></pre>\n<pre><code>new one (the cray based MPI can be detected and used\
    \ in this case when we use the cc and CC)\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC\
    \ -DCMAKE_C_COMPILER=cc -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0\
    \ -DUSE_GNI=ON\n</code></pre>\n<p>this is the content of the <code>~/.gorilla_cpu</code>\
    \ file on cori cluster:</p>\n<pre><code>#!/bin/bash\n\nsource ~/.color\nmodule\
    \ load cmake/3.18.2\nmodule load spack\n#spack load cmake@3.18.2%gcc@8.2.0\n\n\
    module swap PrgEnv-intel PrgEnv-gnu\n# ssg works well for gcc 9.3.0\nmodule swap\
    \ gcc/8.3.0 gcc/9.3.0\n\nspack load -r mochi-thallium%gcc@9.3.0\n#spack load mochi-cfg\n\
    spack load -r mochi-abt-io%gcc@9.3.0\n\nexport CRAYPE_LINK_TYPE=dynamic\n# we\
    \ do not use GPU and vtkm for this version\ncd $SCRATCH/build_Gorilla_cpu\n\n\n\
    export MPICH_GNI_NDREG_ENTRIES=1024 \n# get more mercury info\nexport HG_NA_LOG_LEVEL=debug\n\
    \n# avoid argobot thred pool issue, and set this to 2M\n# this may helps avoid\
    \ segfault when we use the processing and IO in large amount\n# export ABT_THREAD_STACKSIZE=2097152\n\
    # to make sure ther eis enough stack and not oom\nexport ABT_THREAD_STACKSIZE=1048576\n\
    </code></pre>\n<p>refer to the ./scripts dir to check exmaples of running multiple\
    \ servers. The configuration of the server contains item such as protocol used\
    \ by communication layer, the log level, the global domain and if the trigger\
    \ is started and so on. The example of the configuration is in ./server/settings.json</p>\n\
    <h3>\n<a id=\"user-content-build-on-gpu-nodes\" class=\"anchor\" href=\"#build-on-gpu-nodes\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>build on gpu nodes</h3>\n<p>this is the content of the <code>~/.gorilla_gpu</code>\
    \ file on cori cluster:</p>\n<pre><code>#!/bin/bash\nsource ~/.color\n\nsource\
    \ ~/cworkspace/src/spack/share/spack/setup-env.sh\nmodule swap PrgEnv-intel PrgEnv-gnu\n\
    module swap gcc/8.3.0 gcc/9.3.0\n# cuda can not use this cray-mpich\nmodule unload\
    \ cray-mpich/7.7.10\nmodule load cgpu cuda openmpi\nmodule load cmake/3.20.5\n\
    \n# jump to the gpu node\nsalloc -C gpu -t 60 -c 8 -G 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\
    \n# for thallium\nspack load -r mochi-thallium%gcc@9.3.0\nspack load -r mochi-abt-io%gcc@9.3.0\n\
    \nexport CRAYPE_LINK_TYPE=dynamic\n</code></pre>\n<p>build</p>\n<p>(associated\
    \ vtkm accelarator should be enabled when building vtk in this case)\n(we do not\
    \ need extra vtkm build when there is vtk integration?)\n(we use vtkm associated\
    \ with vtk)</p>\n<pre><code>cmake ~/cworkspace/src/Gorilla/ -DCMAKE_CUDA_COMPILER=nvcc\
    \ -DCMAKE_CXX_COMPILER=g++ -DCMAKE_C_COMPILER=gcc -DVTKm_DIR=/global/cscratch1/sd/zw241/build_vtkm/lib/cmake/vtkm-1.6\
    \ -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0 -DUSE_GNI=ON\
    \ -DUSE_GPU=ON -DBUILD_SHARED_LIBS=ON -DVTKm_ENABLE_CUDA=ON -DVTKm_CUDA_Architecture=volta\n\
    </code></pre>\n<p>example to run the test</p>\n<pre><code>srun -C gpu -n 1 --gpus-per-task=1\
    \  nvprof ./test/test_insitu_ana\n</code></pre>\n<h3>\n<a id=\"user-content-using-the-spack-env\"\
    \ class=\"anchor\" href=\"#using-the-spack-env\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using the spack env</h3>\n<p>if\
    \ we use the spack env, it means that we do not set the public packages.yaml file.\
    \ We also need to set the customized spack env for the Gorilla repo.</p>\n<p>set\
    \ up env (we use the spack installed by the colza-experiments)</p>\n<pre><code>source\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nspack\
    \ env create gorilla ~/cworkspace/src/Gorilla/spack.yaml\nspack repo add --scope\
    \ env:gorilla /global/cscratch1/sd/zw241/colza-experiments/cori/vtk/sw/mochi-spack-packages/\n\
    spack env update gorilla \nspack install -y\n</code></pre>\n<p>if the spack env\
    \ is installed successfully</p>\n<pre><code>#!/bin/bash\nsource ~/.color\n\nsource\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nmodule\
    \ swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\n# cuda can not\
    \ use this cray-mpich\nmodule unload cray-mpich/7.7.10\nmodule load cgpu cuda\
    \ openmpi\nmodule load cmake/3.20.5\n\n# activate env for the thallium\nspack\
    \ env activate gorilla\n\n# jump to the gpu node\nsalloc -C gpu -t 60 -c 8 -G\
    \ 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\nexport CRAYPE_LINK_TYPE=dynamic\n\
    </code></pre>\n<h3>\n<a id=\"user-content-run\" class=\"anchor\" href=\"#run\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>run</h3>\n<p>exmaple on cori</p>\n<pre><code>srun -C haswell -n 8\
    \ ./unimos_server ~/cworkspace/src/Gorilla/server/settings_gni.json\n</code></pre>\n\
    <p>remember to set the env if MPICH is used</p>\n<pre><code>MPICH_GNI_NDREG_ENTRIES=1024\n\
    </code></pre>\n<p>simple example to put the data</p>\n<pre><code>srun -C haswell\
    \ -n 16 ./example/gray-scott-stg ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ gni\n</code></pre>\n<p>simple example to get the data for further processing</p>\n\
    <pre><code>srun -n 4 ./example/isosurface ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ 10 0.5 gni\n</code></pre>\n<h3>\n<a id=\"user-content-version-info\" class=\"\
    anchor\" href=\"#version-info\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Version info</h3>\n<p>v0.1</p>\n<p>M:N\
    \ put get for Cartesian grid</p>\n<p>memory and file backend\n(file backend will\
    \ be used when there is not enough mem space)</p>\n<p>in-memory data trigger (experimental)</p>\n\
    <h3>\n<a id=\"user-content-related-issue\" class=\"anchor\" href=\"#related-issue\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>related issue</h3>\n<pre><code>/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so:\
    \ undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023'\n</code></pre>\n\
    <p>try this:</p>\n<p>SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")</p>\n\
    <p>refer to</p>\n<p><a href=\"https://github.com/halide/Halide/issues/1112\">https://github.com/halide/Halide/issues/1112</a></p>\n\
    <p>make -j may hide some potential cmake mistakes, try to use make if there is\
    \ specific link issue</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1641259621.0
wdconinc/spack-environments:
  data_format: 2
  description: Collection of spack environments
  filenames:
  - default-clang/spack.yaml
  - default-sycl/spack.yaml
  - default/spack.yaml
  full_name: wdconinc/spack-environments
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-environments" class="anchor" href="#spack-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-environments</h1>

    <p>Collection of spack environments for personal use and synchronization purposes.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1638573115.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/lassen/spack.yaml
  - platformFiles/spock/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1>

    <a id="user-content-useful-supplementary-materials-for-installing-the-xsdk" class="anchor"
    href="#useful-supplementary-materials-for-installing-the-xsdk" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful supplementary
    materials for installing the xSDK</h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 4
  subscribers_count: 8
  topics: []
  updated_at: 1637108321.0
