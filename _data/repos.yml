AMReX-Codes/pyamrex:
  data_format: 2
  description: '[Experimental] AMReX Python Bindings'
  filenames:
  - spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: null
  readme: '<h1><a id="user-content-pyamrex" class="anchor" aria-hidden="true" href="#pyamrex"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>pyAMReX</h1>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width: 100%;"></a> <a target="_blank" rel="noopener noreferrer nofollow"
    href="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"><img
    src="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"
    alt="Python3 API: Pre-Alpha" title="Status: Pre-Alpha" data-canonical-src="https://img.shields.io/badge/phase-pre--alpha-yellowgreen"
    style="max-width: 100%;"></a>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License AMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a><br>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    alt="linux" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    alt="macos" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    alt="windows" style="max-width: 100%;"></a></p>

    <p>pyAMReX is part of AMReX.</p>

    <p>Due to its <strong>highly experimental</strong> nature, we develop it currently
    in a separate respository.</p>

    <p>We will add further information here once first development versions are ready
    for testing.</p>

    <h2><a id="user-content-users" class="anchor" aria-hidden="true" href="#users"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Users</h2>

    <p><em>to do</em></p>

    <ul>

    <li>pip/pypa</li>

    <li>conda-forge</li>

    <li>spack</li>

    <li>brew</li>

    <li>...</li>

    </ul>

    <h3><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h3>

    <p><em>to do</em></p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <h2><a id="user-content-developers" class="anchor" aria-hidden="true" href="#developers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Developers</h2>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <h3><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B17" rel="nofollow">C++17</a>
    compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.20.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.10.1+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.7+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://www.openmp.org" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (for
    CUDA support, needs 3.7.9+ and 4.2+ is recommended)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <p>Optional CUDA-capable dependencies for tests include:</p>

    <ul>

    <li>

    <a href="https://github.com/cupy/cupy#installation">cupy</a> 11.2+</li>

    <li>

    <a href="https://numba.readthedocs.io/en/stable/user/installing.html" rel="nofollow">numba</a>
    0.56+</li>

    <li>

    <a href="https://pytorch.org/get-started/locally/" rel="nofollow">torch</a> 1.12+</li>

    </ul>

    <h3><a id="user-content-install-dependencies" class="anchor" aria-hidden="true"
    href="#install-dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Install
    Dependencies</h3>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.20.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional:                                    --user</span>

    python3 -m pip install -U pip setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <h3><a id="user-content-configure-your-compiler" class="anchor" aria-hidden="true"
    href="#configure-your-compiler"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configure
    your compiler</h3>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    python3 -m pip install -U -r requirements.txt

    python3 -m pip install -v --force-reinstall --no-deps <span class="pl-c1">.</span></pre></div>

    <p>If you are iterating on builds, it will faster to rely on <code>ccache</code>
    and to let CMake call the <code>pip</code> install logic:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build

    cmake --build build --target pip_install -j 8</pre></div>

    <h3><a id="user-content-test" class="anchor" aria-hidden="true" href="#test"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Test</h3>

    <p>After successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests</span>

    python3 -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python3 -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python3 -m pytest tests/test_intvect.py::test_iv_conversions


    <span class="pl-c"><span class="pl-c">#</span> Run all tests, do not capture "print"
    output and be verbose</span>

    python3 -m pytest -s -vvvv tests/</pre></div>

    <h3><a id="user-content-build-options" class="anchor" aria-hidden="true" href="#build-options"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Options</h3>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>1/2/<strong>3</strong>

    </td>

    <td>Dimension of AMReX</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>PYBIND11_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    <tr>

    <td><code>PYAMREX_LIBDIR</code></td>

    <td><em>None</em></td>

    <td>If set, search for pre-built a pyAMReX library</td>

    </tr>

    <tr>

    <td><code>PYINSTALLOPTIONS</code></td>

    <td><em>None</em></td>

    <td>Additional options for <code>pip install</code>, e.g., <code>-v --user</code>

    </td>

    </tr>

    </tbody>

    </table>

    <p>For example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgements</h2>

    <p>This work was supported by the Laboratory Directed Research and Development
    Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy
    Contract No. DE-AC02-05CH11231.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>pyAMReX Copyright (c) 2021-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for pyamrex can be found at <a href="LICENSE">LICENSE</a>.</p>

    '
  stargazers_count: 18
  subscribers_count: 15
  topics:
  - amrex
  - python
  updated_at: 1675839641.0
AlexanderRichert-NOAA/CItest:
  data_format: 2
  description: Set up a simplified test case based on spack/HDF5 build fail due to
    /usr/local contents
  filenames:
  - spack.yaml
  full_name: AlexanderRichert-NOAA/CItest
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1671482597.0
CUP-ECS/ping-pong-gpu:
  data_format: 2
  description: null
  filenames:
  - configs/unm-hopper/spack-mpich+yaksa.yaml
  - configs/llnl-lassen/spack-mvapich.yaml
  - build-hpctoolkit/spack-spectrum.yaml
  - build-mvapich/spack-mvapich.yaml
  - build-xlc/spack-xlc-mvapich.yaml
  - build-xlc/spack-xlc-spectrum.yaml
  - build-lassen-spectrum/spack.yaml
  - configs/llnl-lassen/spack-spectrum.yaml
  - configs/unm-hopper/spack-mpich+yaksa+ucx.yaml
  - configs/unm-hopper/spack-openmpi+ucx.yaml
  full_name: CUP-ECS/ping-pong-gpu
  latest_release: null
  readme: '<h1><a id="user-content-gpu-ping-pong-benchmark" class="anchor" aria-hidden="true"
    href="#gpu-ping-pong-benchmark"><span aria-hidden="true" class="octicon octicon-link"></span></a>GPU
    Ping Pong Benchmark</h1>

    <p>Basic regular mesh ping pong benchmark for GPUs written in Kokkos. Baseline
    for

    comparison is a Kokkos parallel loop that packs the data prior to sending. Mesh

    data structure extracted from UNM Fiesta CFD application.</p>

    <h2><a id="user-content-running" class="anchor" aria-hidden="true" href="#running"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running</h2>

    <p>Arguments:</p>

    <ul>

    <li>-n: Length of one face of the mesh being communicated (resulting communciation
    is n * n * 5 * 3 doubles</li>

    <li>-i: Number of iterations to perform</li>

    <li>-d: Face of mesh to communicate (0 = y/z, 1 = x/z, 2 = x/y)</li>

    <li>-m: Mode to use for sending and receiving (0 = MPI datatypes, 1 = Hand gpu
    pack, gpu-aware MPI, 2 = Hand gpu pack, host memory send)</li>

    </ul>

    <p>Example command line:

    <code>srun --mpi=pmi2 --ntasks 2 --gpus-per-task=1 --tasks-per-node=1 -p cup-ecs
    ping_pong -n 200 -i 100 -d 1 -m 0</code></p>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Spack configuration files for different MPIs are in the configs/ directory.
    Generally

    we create spack environments for building, use a setup script to load any necessary

    modules (generally the compiler, which the spack environment doesn''t necessarily

    provide), and activate the spack environment for the buiuld</p>

    <h2><a id="user-content-future-features" class="anchor" aria-hidden="true" href="#future-features"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Future features</h2>

    <ol>

    <li>Option to pack into pinned host memory instead of GPU memory</li>

    <li>Restructure to support other ping pong of data structures extracted from

    other applications.</li>

    <li>Option to change number of ghost cell layers sent</li>

    </ol>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1667693779.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/23.02/rocm-x86_64/spack.yaml
  - environments/23.02/cuda-x86_64/spack.yaml
  - environments/22.08/cuda-ppc64le.spack.yaml
  - environments/23.02/cuda-ppc64le/spack.yaml
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/23.02/cuda-aarch64/spack.yaml
  - environments/22.08/cuda-aarch64.spack.yaml
  - environments/22.08/oneapi.spack.yaml
  - environments/22.08/rocm.spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#e4s\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n<ul>\n<li>User\
    \ Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\">https://e4s.readthedocs.io</a>\n\
    </li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub: <a href=\"https://github.com/E4S-Project/\"\
    >https://github.com/E4S-Project/</a>\n</li>\n<li>Slack Channel: <a href=\"https://e4s-project.slack.com\"\
    \ rel=\"nofollow\">https://e4s-project.slack.com</a>\n</li>\n<li>E4S Dashboard:\
    \ <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\
    >E4S-Project/E4S-Project.github.io</a> - E4S Documentation repo that is hosted\
    \ on <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 17
  subscribers_count: 10
  topics: []
  updated_at: 1676907408.0
ECP-WarpX/impactx:
  data_format: 2
  description: 'ImpactX: an s-based beam dynamics code including space charge effects'
  filenames:
  - docs/spack.yaml
  full_name: ECP-WarpX/impactx
  latest_release: '23.02'
  readme: "<h1><a id=\"user-content-impactx\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#impactx\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ImpactX</h1>\n<p><a href=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml\"\
    ><img src=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml/badge.svg\"\
    \ alt=\"CI Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://impactx.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1090ab96071a0b6311590a818911f8b10c5d65e31760367fbaed373f8d727e03/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f696d70616374782f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/impactx/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\"\
    \ alt=\"License ImpactX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://impactx.readthedocs.io/en/latest/install/users.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://doi.org/10.5281/zenodo.6954922\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/baf88cee0be27d736412a9f20b5bbbcf3474dd6522e2c3aed8acb112ef750bd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e363935343932322d626c75652e737667\"\
    \ alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.6954922-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.18429/JACoW-NAPAC2022-TUYE2\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ef742b6bcde081f05456eb05f8ea05f4053f8f7fd021c6891cfaf5c6e935f73c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e31383432392532464a41436f572d2d4e41504143323032322d2d54555945322d626c75652e737667\"\
    \ alt=\"DOI (paper)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(paper)-10.18429%2FJACoW--NAPAC2022--TUYE2-blue.svg\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://en.wikipedia.org/wiki/Software_release_life_cycle\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d8c054b6da1ff81634c84041dfe111aec24b166c8ea31edb0ade140ea2c9015/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646576656c6f706d656e742532307374617475732d626574612d6f72616e67652e737667\"\
    \ alt=\"Development Status\" data-canonical-src=\"https://img.shields.io/badge/development%20status-beta-orange.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://isocpp.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\"\
    \ alt=\"Language: C++17\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://python.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\"\
    \ alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>ImpactX: an s-based beam dynamics code\
    \ including space charge effects.\nThis is the next generation of the <a href=\"\
    https://github.com/impact-lbl/IMPACT-Z\">IMPACT-Z</a> code.</p>\n<h2><a id=\"\
    user-content-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p>In order to learn how to install and run the code, please see the online documentation:\n\
    <a href=\"https://impactx.readthedocs.io\" rel=\"nofollow\">https://impactx.readthedocs.io</a></p>\n\
    <ul>\n<li>ImpactX Doxygen: <a href=\"https://impactx.readthedocs.io/en/latest/_static/doxyhtml\"\
    \ rel=\"nofollow\">https://impactx.readthedocs.io/en/latest/_static/doxyhtml</a>\n\
    </li>\n<li>AMReX Doxygen: <a href=\"https://amrex-codes.github.io/amrex/doxygen\"\
    \ rel=\"nofollow\">https://amrex-codes.github.io/amrex/doxygen</a>\n</li>\n<li>WarpX\
    \ Doxygen: <a href=\"https://warpx.readthedocs.io/en/latest/_static/doxyhtml\"\
    \ rel=\"nofollow\">https://warpx.readthedocs.io/en/latest/_static/doxyhtml</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contributing</h2>\n<p><a href=\"https://amrex-codes.github.io/\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\"\
    \ alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our workflow is described in <a href=\"\
    CONTRIBUTING.rst\">CONTRIBUTING.rst</a>.</p>\n<h2><a id=\"user-content-developer-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#developer-environment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developer Environment</h2>\n\
    <p>Please prepare you local development environment as follows.\nPick <em>one</em>\
    \ of the methods below:</p>\n<h3><a id=\"user-content-perlmutter-nersc\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#perlmutter-nersc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Perlmutter (NERSC)</h3>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>ssh perlmutter-p1.nersc.gov</pre></div>\n\
    <p>Now <code>cd</code> to your ImpactX source directory.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>module load cmake/3.22.0\nmodule load cray-hdf5-parallel/1.12.2.1\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> CCache for faster rebuilds</span>\n\
    <span class=\"pl-k\">export</span> PATH=/global/common/software/spackecp/perlmutter/e4s-22.05/78535/spack/opt/spack/cray-sles15-zen3/gcc-11.2.0/ccache-4.5.1-ybl7xefvggn6hov4dsdxxnztji74tolj/bin:<span\
    \ class=\"pl-smi\">$PATH</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Python</span>\nmodule load cray-python/3.9.13.1\n<span class=\"pl-k\">if</span>\
    \ [ <span class=\"pl-k\">-d</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx<span\
    \ class=\"pl-pds\">\"</span></span> ]\n<span class=\"pl-k\">then</span>\n  <span\
    \ class=\"pl-c1\">source</span> <span class=\"pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx/bin/activate\n\
    <span class=\"pl-k\">else</span>\n  python3 -m pip install --user --upgrade pip\n\
    \  python3 -m pip install --user virtualenv\n  python3 -m venv <span class=\"\
    pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx\n  <span class=\"pl-c1\">source</span>\
    \ <span class=\"pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx/bin/activate\n\
    \n  python3 -m pip install --upgrade pip\n  MPICC=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>cc -target-accel=nvidia80 -shared<span class=\"pl-pds\">\"</span></span>\
    \ python3 -m pip install -U --no-cache-dir -v mpi4py\n  python3 -m pip install\
    \ --upgrade pytest\n  python3 -m pip install -r requirements.txt\n  python3 -m\
    \ pip install -r examples/requirements.txt\n<span class=\"pl-k\">fi</span>\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> GPU-aware MPI</span>\n<span\
    \ class=\"pl-k\">export</span> MPICH_GPU_SUPPORT_ENABLED=1\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> necessary to use CUDA-Aware MPI and run a job</span>\n\
    <span class=\"pl-k\">export</span> CRAY_ACCEL_TARGET=nvidia80\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optimize CUDA compilation for A100</span>\n\
    <span class=\"pl-k\">export</span> AMREX_CUDA_ARCH=8.0\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> compiler environment hints</span>\n<span class=\"\
    pl-k\">export</span> CC=cc\n<span class=\"pl-k\">export</span> CXX=CC\n<span class=\"\
    pl-k\">export</span> FC=ftn\n<span class=\"pl-k\">export</span> CUDACXX=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">$(</span>which nvcc<span class=\"pl-pds\"\
    >)</span></span>\n<span class=\"pl-k\">export</span> CUDAHOSTCXX=CC</pre></div>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> work on an interactive node</span>\nsalloc -N 1 --ntasks-per-node=4\
    \ -t 1:00:00 -C gpu --gpu-bind=single:1 -c 32 -G 4 --qos=interactive -A m3906_g\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> configure</span>\ncmake -S\
    \ <span class=\"pl-c1\">.</span> -B build_perlmutter -DImpactX_COMPUTE=CUDA -DImpactX_PYTHON=ON\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compile</span>\ncmake --build\
    \ build_perlmutter -j 64\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ test</span>\nctest --test-dir build_perlmutter -E AMReX --output-on-failure\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> run</span>\n<span class=\"\
    pl-c1\">cd</span> build_perlmutter/bin\nsrun ./impactx ../../examples/fodo/input_fodo.in</pre></div>\n\
    <h3><a id=\"user-content-cori-knl-nersc\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#cori-knl-nersc\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Cori KNL (NERSC)</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>ssh cori.nersc.gov</pre></div>\n<p>Now <code>cd</code> to your ImpactX source\
    \ directory.</p>\n<div class=\"highlight highlight-source-shell\"><pre>module\
    \ swap craype-haswell craype-mic-knl\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule\
    \ load cmake/3.22.1\nmodule load cray-hdf5-parallel/1.10.5.2\nmodule load cray-fftw/3.3.8.10\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Python</span>\nmodule load\
    \ cray-python/3.9.7.1\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\">-d</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$HOME</span>/sw/knl/venvs/impactx<span class=\"pl-pds\">\"</span></span> ]\n\
    <span class=\"pl-k\">then</span>\n  <span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx/bin/activate\n<span class=\"\
    pl-k\">else</span>\n  python3 -m pip install --user --upgrade pip\n  python3 -m\
    \ pip install --user virtualenv\n  python3 -m venv <span class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx\n\
    \  <span class=\"pl-c1\">source</span> <span class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx/bin/activate\n\
    \n  python3 -m pip install --upgrade pip\n  MPICC=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>cc -shared<span class=\"pl-pds\">\"</span></span> python3 -m\
    \ pip install -U --no-cache-dir -v mpi4py\n  python3 -m pip install --upgrade\
    \ pytest\n  python3 -m pip install -r requirements.txt\n  python3 -m pip install\
    \ -r examples/requirements.txt\n<span class=\"pl-k\">fi</span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> tune exactly for KNL sub-architecture</span>\n\
    <span class=\"pl-k\">export</span> CXXFLAGS=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>-march=knl<span class=\"pl-pds\">\"</span></span>\n<span class=\"\
    pl-k\">export</span> CFLAGS=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-march=knl<span\
    \ class=\"pl-pds\">\"</span></span></pre></div>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> configure</span>\ncmake\
    \ -S <span class=\"pl-c1\">.</span> -B build_knl\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> compile</span>\ncmake --build build_knl -j 8\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> test</span>\nsrun -C knl -N 1 -t\
    \ 30 -q debug ctest --test-dir build_knl --output-on-failure\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> run</span>\n<span class=\"pl-c1\">cd</span>\
    \ build_knl/bin\nsrun -C knl -N 1 -t 30 -q debug ./impactx ../../examples/fodo/input_fodo.in</pre></div>\n\
    <h3><a id=\"user-content-homebrew-macos\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#homebrew-macos\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Homebrew (macOS)</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew update\nbrew install adios2      <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> for openPMD</span>\nbrew install ccache\nbrew install cmake\n\
    brew install fftw\nbrew install git\nbrew install hdf5-mpi    <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> for openPMD</span>\nbrew install libomp      <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for OpenMP</span>\nbrew install\
    \ pkg-config  <span class=\"pl-c\"><span class=\"pl-c\">#</span> for fftw</span>\n\
    brew install open-mpi</pre></div>\n<h3><a id=\"user-content-apt-debianubuntu\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#apt-debianubuntu\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Apt (Debian/Ubuntu)</h3>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>sudo apt update\nsudo apt install\
    \ build-essential ccache cmake g++ git libfftw3-mpi-dev libfftw3-dev libhdf5-openmpi-dev\
    \ libopenmpi-dev pkg-config python3 python3-matplotlib python3-numpy python3-scipy</pre></div>\n\
    <h3><a id=\"user-content-spack-linux\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #spack-linux\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack\
    \ (Linux)</h3>\n<div class=\"highlight highlight-source-shell\"><pre>spack env\
    \ create impactx-dev\nspack env activate impactx-dev\nspack add adios2       \
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> for openPMD</span>\nspack\
    \ add ccache\nspack add cmake\nspack add fftw\nspack add hdf5          <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> for openPMD</span>\nspack add mpi\nspack\
    \ add pkgconfig     <span class=\"pl-c\"><span class=\"pl-c\">#</span> for fftw</span>\n\
    spack add python\nspack add py-pip\nspack add py-setuptools\nspack add py-wheel\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> OpenMP support on macOS</span>\n\
    [[ <span class=\"pl-smi\">$OSTYPE</span> <span class=\"pl-k\">==</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span>darwin<span class=\"pl-pds\">'</span></span><span\
    \ class=\"pl-k\">*</span> ]] <span class=\"pl-k\">&amp;&amp;</span> spack add\
    \ llvm-openmp\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:\
    \ Linux only</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>spack add\
    \ cuda</span>\n\nspack install\npython3 -m pip install matplotlib numpy openpmd-api\
    \ pandas pytest scipy</pre></div>\n<p>In new terminals, re-activate the environment\
    \ with <code>spack env activate impactx-dev</code> again.</p>\n<h3><a id=\"user-content-conda-linuxmacoswindows\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#conda-linuxmacoswindows\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conda (Linux/macOS/Windows)</h3>\n\
    <div class=\"highlight highlight-source-shell\"><pre>conda create -n impactx-dev\
    \ -c conda-forge adios2 ccache cmake compilers git hdf5 fftw matplotlib ninja\
    \ numpy pandas pytest scipy\nconda activate impactx-dev\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> compile with -DImpactX_MPI=OFF</span></pre></div>\n\
    <h2><a id=\"user-content-get-the-source-code\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#get-the-source-code\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Get the Source Code</h2>\n<p>Before you start, you\
    \ will need a copy of the ImpactX source code:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>git clone git@github.com:ECP-WarpX/impactx.git\n<span class=\"pl-c1\">cd</span>\
    \ impactx</pre></div>\n<h2><a id=\"user-content-compile\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#compile\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Compile</h2>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> find dependencies &amp; configure</span>\n\
    cmake -S <span class=\"pl-c1\">.</span> -B build\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> compile</span>\ncmake --build build -j 4</pre></div>\n\
    <p>That's all!\nImpactX binaries are now in <code>build/bin/</code>.\nMost people\
    \ execute these binaries directly or copy them out.</p>\n<p>You can inspect and\
    \ modify build options after running <code>cmake -S . -B</code> build with either</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>ccmake build</pre></div>\n\
    <p>or by adding arguments with <code>-D&lt;OPTION&gt;=&lt;VALUE&gt;</code> to\
    \ the first CMake call, e.g.:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DImpactX_COMPUTE=CUDA\
    \ -DImpactX_MPI=OFF</pre></div>\n<h3><a id=\"user-content-python-compile\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#python-compile\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Python Compile</h3>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> find dependencies &amp; configure</span>\ncmake -S <span class=\"pl-c1\"\
    >.</span> -B build -DImpactX_PYTHON=ON\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> compile &amp; install</span>\ncmake --build build -j 4 --target\
    \ pip_install</pre></div>\n<h2><a id=\"user-content-run\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#run\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Run</h2>\n<p>An executable ImpactX binary with the current compile-time\
    \ options encoded in its file name will be created in <code>build/bin/</code>.</p>\n\
    <p>Additionally, a symbolic link named <code>impactx</code> can be found in that\
    \ directory, which points to the last built ImpactX executable.</p>\n<p>The command-line\
    \ syntax for this executable is:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">Usage: impactx &lt;inputs-file&gt; [some.overwritten.option=value]...</span>\n\
    \n<span class=\"pl-c1\">Mandatory arguments (remove the &lt;&gt;):</span>\n<span\
    \ class=\"pl-c1\">  inputs-file     the path to an input file; can be relative\
    \ to the current</span>\n<span class=\"pl-c1\">                  working directory\
    \ or absolute.</span>\n<span class=\"pl-c1\">                  Example: input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">Optional arguments (remove the []):</span>\n<span class=\"\
    pl-c1\">  options         this can overwrite any line in an inputs-file</span>\n\
    <span class=\"pl-c1\">                  Example: quad1.ds=0.5 sbend1.rc=1.5</span>\n\
    \n<span class=\"pl-c1\">Examples:</span>\n<span class=\"pl-c1\">  In the current\
    \ working directory, there is a file \"input_fodo.in\" and the</span>\n<span class=\"\
    pl-c1\">  \"impactx\" executable.</span>\n<span class=\"pl-c1\">  The line to\
    \ execute would look like this:</span>\n<span class=\"pl-c1\">    ./impactx input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">  In the current working directory, there is a file \"\
    input_fodo.in\" and the</span>\n<span class=\"pl-c1\">  executable \"impactx\"\
    \ is in a directory that is listed in the \"PATH\"</span>\n<span class=\"pl-c1\"\
    >  environment variable.</span>\n<span class=\"pl-c1\">  The line to execute would\
    \ look like this:</span>\n<span class=\"pl-c1\">    impactx input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">  In the current working directory, there is a file \"\
    input_fodo.in\" and the</span>\n<span class=\"pl-c1\">  \"impactx\" executable.\
    \ We want to voerwrite the segment length of the beamline</span>\n<span class=\"\
    pl-c1\">  element \"quad1\" that is already defined in it. We also want to change\
    \ the</span>\n<span class=\"pl-c1\">  radius of curvature of the bending magnet\
    \ \"sbend1\" to a different value than</span>\n<span class=\"pl-c1\">  in the\
    \ file \"input_fodo.in\".</span>\n<span class=\"pl-c1\">  The line to execute\
    \ would look like this:</span>\n<span class=\"pl-c1\">    ./impactx input_fodo.in\
    \ quad1.ds=0.5 sbend1.rc=1.5</span></pre></div>\n<h2><a id=\"user-content-test\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#test\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Test</h2>\n<p>In order to run our\
    \ tests, you need to have a few Python packages installed:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">python3 -m\
    \ pip install -U pip setuptools wheel pytest</span>\n<span class=\"pl-c1\">python3\
    \ -m pip install -r examples/requirements.txt</span></pre></div>\n<p>You can run\
    \ all our tests with:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">ctest --test-dir build --output-on-failure</span></pre></div>\n\
    <p>Further options:</p>\n<ul>\n<li>help: <code>ctest --test-dir build --help</code>\n\
    </li>\n<li>list all tests: <code>ctest --test-dir build -N</code>\n</li>\n<li>only\
    \ run tests that have \"FODO\" in their name: <code>ctest --test-dir build -R\
    \ FODO</code>\n</li>\n</ul>\n<h2><a id=\"user-content-acknowledgements\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#acknowledgements\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h2>\n<p>This\
    \ work was supported by the Laboratory Directed Research and Development Program\
    \ of Lawrence Berkeley National Laboratory under U.S. Department of Energy Contract\
    \ No. DE-AC02-05CH11231.</p>\n<h2><a id=\"user-content-copyright-notice\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#copyright-notice\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Copyright Notice</h2>\n<p>Copyright\
    \ (c) 2022-2023, The Regents of the University of California, through Lawrence\
    \ Berkeley National Laboratory (subject to receipt of any required approvals from\
    \ the U.S. Dept. of Energy).\nAll rights reserved.</p>\n<p>If you have questions\
    \ about your rights to use or distribute this software, please contact Berkeley\
    \ Lab's Intellectual Property Office at <a href=\"mailto:IPO@lbl.gov\">IPO@lbl.gov</a>.</p>\n\
    <p>NOTICE. This Software was developed under funding from the U.S. Department\
    \ of Energy and the U.S. Government consequently retains certain rights.  As such,\
    \ the U.S. Government has been granted for itself and others acting on its behalf\
    \ a paid-up, nonexclusive, irrevocable, worldwide license in the Software to reproduce,\
    \ distribute copies to the public, prepare derivative works, and perform publicly\
    \ and display publicly, and to permit others to do so.</p>\n<p>Please see the\
    \ full license agreement in <a href=\"LICENSE.txt\">LICENSE.txt</a>, which is\
    \ the <code>BSD-3-Clause-LBNL</code> license.</p>\n"
  stargazers_count: 11
  subscribers_count: 7
  topics:
  - simulation
  - beam-dynamics
  - particle-in-cell
  - gpu
  - physics
  - pic
  - particle
  - accelerator
  - research
  updated_at: 1675516359.0
FTHPC/Correlation_Compressibility:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: FTHPC/Correlation_Compressibility
  latest_release: v0.1
  readme: "<h1><a id=\"user-content-compressibility-analysis-correlation_compressibility\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#compressibility-analysis-correlation_compressibility\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compressibility\
    \ Analysis (Correlation_Compressibility)</h1>\n<h2><a id=\"user-content-statement-of-purpose\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#statement-of-purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Statement of Purpose</h2>\n<p>This\
    \ repo contains scripts to perform compressibility analysis on several leading\
    \ lossy compressors.\nThe compressibility analysis relies on deriving statistics\
    \ on scientific data and explore their relationships to their compression ratios\
    \ from various lossy compressors (based on various compression scheme).\nThe extracted\
    \ relationships between compression ratios and statistical predictors are modeled\
    \ via regression models, which provide a statistical framework to predict compression\
    \ ratios for the different studied lossy compressors.</p>\n<p>This repo contains\
    \ an automatic framework of scripts that perform the compression of scientific\
    \ datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding and Bit\
    \ Grooming), the derivation of the statistical predictors of compression ratios\
    \ (SVD, standard deviation, quantized entropy), and scripts to perform the training\
    \ of the regression models (linear and spline regressions) as well as the validation\
    \ of the regression predictions.\nA runtime analysis is also performed and associated\
    \ codes are provided.</p>\n<h3><a id=\"user-content-main-code-structures\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#main-code-structures\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Main code structures</h3>\n<p>Compression\
    \ metrics, including compression ratios, and derivation of statistical predictors\
    \ (SVD, standard deviation, quantized entropy) codes are found in <code>compress_package</code>\
    \ and are run via <code>scripts/run.sh</code> as described in the section \"How\
    \ to compute statistical predictors and compression analysis on datasets\".\n\
    Linear and spline regressions training and validation (functions <code>cr_regression_linreg</code>\
    \ and <code>cr_regression_gam</code> from the script <code>replicate_figures/functions_paper.R</code>).\n\
    Codes for the different runtime analysis are found in the folder <code>runtime_analysis</code>\
    \ and are automated with the script <code>runtime.sh</code>, the study includes\
    \ compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled)\
    \ variogram and local (tiled) variogram, and runtime for training and prediction\
    \ of the regressions.<br>\nFinally, the script <code>replicate_figures/graphs_paper_container.R</code>\
    \ replicates and saves all the figures from the paper ad as well as numbers from\
    \ the tables.</p>\n<p>For each dataset in the <code>dataset</code> folder, slicing\
    \ is performed for each variable field (e.g. density in Miranda), each slice is\
    \ stored in a class. The class is updated as compressions with the 8 compressors\
    \ is performed and updated as the statistical predictors are derived. Results\
    \ of each class are stored in a .csv file (example of csv files can be found at\
    \ <code>replicate_figures/generated_data/</code>).\nAll the datasets stored in\
    \ the <code>dataset</code> folder can be analyzed with the given set of codes,\
    \ one needs to source <code>scripts/config.json</code> with the appropriate dataset\
    \ name as described in the below section \"How to compute statistical predictors\
    \ and compression analysis on datasets\".\nThe regression analysis and its prediction\
    \ is then performed on R dataframes based on the aforementioned .csv files.</p>\n\
    <h2><a id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#system-information\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>System Information</h2>\n<p>The hardware and software\
    \ versions used for the performance evaluations can be found in the table below.\
    \ These nodes come from Clemson University's Palmetto Cluster.</p>\n<p>These nodes\
    \ have:</p>\n<table>\n<thead>\n<tr>\n<th>component</th>\n<th>version</th>\n<th>component</th>\n\
    <th>version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CPU</td>\n<td>Intel Xeon\
    \ 6148G (40 cores)</td>\n<td>sz2</td>\n<td>2.1.12.2</td>\n</tr>\n<tr>\n<td>GPU</td>\n\
    <td>2 Nvidia v100</td>\n<td>sz3</td>\n<td>3.1.3.1</td>\n</tr>\n<tr>\n<td>Memory</td>\n\
    <td>372GB</td>\n<td>zfp</td>\n<td>0.5.5</td>\n</tr>\n<tr>\n<td>Network</td>\n\
    <td>2 Mellanox MT27710 (HDR)</td>\n<td>mgard</td>\n<td>1.0.0</td>\n</tr>\n<tr>\n\
    <td>FileSystem</td>\n<td>BeeGFS 7.2.3 (24 targets)</td>\n<td>bit grooming</td>\n\
    <td>2.1.9</td>\n</tr>\n<tr>\n<td>Compiler</td>\n<td>GCC 8.4.1</td>\n<td>digit\
    \ rounding</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>OS</td>\n<td>CentOS 8.2.2004</td>\n\
    <td>R</td>\n<td>4.1.3</td>\n</tr>\n<tr>\n<td>MPI</td>\n<td>OpenMPI 4.0.5</td>\n\
    <td>Python</td>\n<td>3.9.12</td>\n</tr>\n<tr>\n<td>LibPressio</td>\n<td>0.83.4</td>\n\
    <td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-first-time-setup\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-setup\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>First time setup</h2>\n<h3><a\
    \ id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#container-installation-for-ease-of-setup\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Container Installation\
    \ (for ease of setup)</h3>\n<p>We provide a container for <code>x86_64</code>\
    \ image for ease of installation.</p>\n<p>This container differs from our experimental\
    \ setup slightly. The production build used <code>-march=native -mtune=native</code>\
    \ for architecture optimized builds where as the container does not use these\
    \ flags to maximize compatibility across <code>x86_64</code> hardware.</p>\n<p>NOTE\
    \ this file is &gt;= 11 GB , download with caution.</p>\n<h4><a id=\"user-content-docker\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#docker\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Docker</h4>\n<p>Many other systems\
    \ can use podman or docker.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>docker pull ghcr.io/fthpc/correlation_compressibility:latest\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>most systems</span>\ndocker run -it --rm ghcr.io/fthpc/correlation_compressibility:latest\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> if running on a SeLinux enforcing\
    \ system</span>\ndocker run -it --rm --security-opt label=disable ghcr.io/fthpc/correlation_compressibility:latest</pre></div>\n\
    <h3><a id=\"user-content-building-the-container\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#building-the-container\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Building the Container</h3>\n<p>You can build the\
    \ container yourself as follows:\nNOTE this process takes 3+ hours on a modern\
    \ laptop, and most clusters do not\nprovide sufficient permissions to run container\
    \ builds on the cluster.</p>\n<p>Additionally compiling MGRAD -- one of the compressors\
    \ we use takes &gt;= 4GB RAM per core, be cautious\nwith systems with low RAM.\
    \  You may be able compensate by using fewer cores by changing the spack install\n\
    instruction in the Dockerfile to have a <code>-j N</code> where <code>N</code>\
    \ is the number of cores you wish to use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> install/module load git-lfs,\
    \ needed to download example_data for building the container</span>\nsudo dnf\
    \ install git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span>Fedora/CentOS\
    \ Stream 8</span>\nsudo apt-get install git-lfs <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Ubuntu</span>\nspack install git-lfs<span class=\"pl-k\">;</span>\
    \ spack load git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> using\
    \ spack</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> clone this\
    \ repository</span>\ngit clone --recursive https://github.com/FTHPC/Correlation_Compressibility\n\
    <span class=\"pl-c1\">cd</span> Correlation_Compressibility\ndocker build <span\
    \ class=\"pl-c1\">.</span> -t correlation_compressibility</pre></div>\n<h3><a\
    \ id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#manual-installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Manual Installation</h3>\n<p>By default, it is recommended to follow\
    \ the install locations that are indicated on the top of <code>scripts/run.sh</code>\n\
    and the top of <code>config.json</code>. These two files provide the configuration\
    \ options to get the program running.</p>\n<p>Spack should be installed in the\
    \ following location: <code>$HOME/spack/</code></p>\n<p>This Github repo should\
    \ be cloned in the following location: <code>$HOME/Correlation_Compressibility/</code>\n\
    This location is also referenced as the <code>COMPRESS_HOME</code> environment\
    \ variable.</p>\n<p>A dataset folder called 'datasets' should be in the following\
    \ location: <code>$HOME/Correlation_Compressibility/datasets/</code>.</p>\n<p>Clone\
    \ the repo but make sure to install or load <code>git-lfs</code> first.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> install/module load git-lfs, needed to download example_data\
    \ for building the container</span>\nsudo dnf install git-lfs <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>Fedora/CentOS Stream 8</span>\nsudo apt-get install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ubuntu</span>\nspack\
    \ install git-lfs<span class=\"pl-k\">;</span> spack load git-lfs <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> clone this repository</span>\ngit clone https://github.com/FTHPC/Correlation_Compressibility\
    \ <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility</pre></div>\n\
    <p>If you forgot to install <code>git-lfs</code> before and have an empty file\
    \ in the  <code>datasets</code> folder, you should install <code>git-lfs</code>\n\
    and then run the following:</p>\n<pre><code>git lfs fetch\ngit lfs checkout\n\
    </code></pre>\n<p>Once Spack is installed, there is a <code>spack.yaml</code>\
    \ configuration file containing the Spack environment necessary to run the program.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">$HOME</span>\ngit clone --depth=1 https://github.com/spack/spack\n\
    git clone --depth=1 https://github.com/robertu94/spack_packages \n<span class=\"\
    pl-c1\">source</span> ./spack/share/spack/setup-env.sh \nspack compiler find\n\
    spack external find \nspack repo add --scope=site ./spack_packages \n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ \nspack env activate <span class=\"pl-c1\">.</span>\nspack install\n<span class=\"\
    pl-k\">export</span> COMPRESS_HOME=<span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ </pre></div>\n<p>These commands will install the environment. The environment\
    \ only needs to be installed once.\nIf you are using an older &lt; gcc11, then\
    \ you will need to add the following to the <code>spack.yaml</code> file:</p>\n\
    <pre><code>^libstdcompat+boost\n</code></pre>\n<p>after <code>^mgard@robertu94+cuda</code>\
    \ but before the <code>,</code>.</p>\n<h2><a id=\"user-content-replication-of-results\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-results\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication of\
    \ Results</h2>\n<h3><a id=\"user-content-how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to compute\
    \ statistical predictors and compression metrics on datasets</h3>\n<p>In order\
    \ to run the statistical analysis that computes the statistical predictors (SVD,\
    \ standard deviation, quantized entropy) of compression ratios, a dataset and\
    \ a configuration file must be specified.\nTEST is a dataset that is specified\
    \ within the <code>config.json</code> file.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh scripts/run.sh -c config.json -d TEST -n 2</pre></div>\n<p>The command\
    \ above performs the computation of statistical predictors and writes output to\
    \ the output file specified in the configuration file.\nThis will use local hardware\
    \ without a scheduler. Use <code>-n</code> to specify the MPI processes on your\
    \ local system. Default value is 32.\nIt is recommended that this value matches\
    \ your CPU core count.</p>\n<p>If one has the PBS scheduler and runs outside of\
    \ the container, feel free to use flags <code>-p</code> or <code>-s</code> for\
    \ job execution.\n<code>-p</code> will schedule multiple jobs based on the quantized\
    \ error bounds and error bound types for a specified dataset.\n<code>-s</code>\
    \ will schedule a single job grouping all the analysis for a specified dataset.</p>\n\
    <p>See <code>-h</code> for more options or help with syntax.</p>\n<p>If a dataset\
    \ is wanted to run, the <code>config.json</code> file provides options to add\
    \ datasets.\nThe following options must be added when adding another dataset in\
    \ the configuration file:</p>\n<div class=\"highlight highlight-source-json\"\
    ><pre><span class=\"pl-ent\">\"_comment\"</span> : \n{\n    <span class=\"pl-ent\"\
    >\"folder\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>folder containing h5 or binary files<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"data_dimensions\"</span>   : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>dimensions of the datasets within dataset_folder.\
    \ Either 1x2 or 1x3. EX: '1028, 1028'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"slice_dimensions\"</span>  : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>list of the dimensions wanted: EX: 'None' or\
    \ 'X, Y, Z'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\"\
    >\"output\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>name of the output csv file: EX: 'test.csv'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"dtype\"</span>             : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>data type. can be 'float32' or 'float64'<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\">\"parse_info\"\
    </span>        : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type of\
    \ parsing needed: 'None', 'slice', 'gaussian', 'gaussian_multi', 'spatialweight',\
    \ or 'scalarweight'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"\
    pl-ent\">\"dataset_name\"</span>      : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>necessary accessing 2D HDF5 files: 'standard' if not custom. custom\
    \ EX: 'Z'<span class=\"pl-pds\">\"</span></span>\n} </pre></div>\n<p>From this\
    \ section, .csv files are generated for each dataset and contain all the statistical\
    \ predictors described in the paper as well as compression metrcis including compresison\
    \ ratios for the 8 lossy compressors and 4 error bounds.</p>\n<h3><a id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To run the\
    \ training and prediction timing analysis demonstration</h3>\n<p>In order to run\
    \ the timing analysis, a dataset must be specified.\nThere are two datasets setup\
    \ within this demonstration.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh runtime_analysis/runtime.sh -d [DATASET]</pre></div>\n<p>[DATASET] can\
    \ be either [NYX] or [SCALE]</p>\n<p>After running the above script, an *.RData\
    \ file(s) will be produced giving the approprirate timing information of\nthe\
    \ training and prediction for the regression models.</p>\n<p>Note: A quicker and\
    \ more efficient quantized entropy method is demonstrated in <code>qentropy.cc</code></p>\n\
    <h4><a id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-following-below-runs-qentropycc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The following below runs <code>qentropy.cc</code>\n\
    </h4>\n<div class=\"highlight highlight-source-shell\"><pre>g++ -std=c++2a -O3\
    \ qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy</pre></div>\n\
    <p>Note: Please run the runtime analysis for both datasets before running the\
    \ following section.</p>\n<h3><a id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication\
    \ of figures: how to run statistical prediction of compression ratios and the\
    \ prediction validation</h3>\n<p>The script <code>graphs_paper_container.R</code>\
    \  saves the graphs presented in the paper and provides associated validation\
    \ metrics (correlation and median absolute error percentage).</p>\n<p>The script\
    \ <code>graphs_paper_container.R</code> will source the scripts  <code>load_dataset_paper.R</code>\
    \ and <code>functions_paper.R</code> that respectively load the dataset of interest\
    \ and perform the regression analysis (training and prediction in cross-validation).\n\
    As a consequence the scripts  <code>load_dataset_paper.R</code> and <code>functions_paper.R</code>\
    \ do not need to be run by the user.</p>\n<p>The script <code>graphs_paper_container.R</code>\
    \  is run via the command:\n<code>bash sh replicate.sh</code></p>\n<p>From running\
    \ the script once, it will save all Figures 1, 3, 4 and 5 into .png files from\
    \ the paper as well as corresponding validation metrics.\nFigure 2 is not saved\
    \ as it provides a simple vizualization of slices of the datasets.\nSlices of\
    \ the datasets are generated in the Section \"How to compute statistical predictors\
    \ and compression metrics\" and can be stored, however we do not save them here\
    \ to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in\
    \ the R console.\nAll printed validation metrics are save into a file named <code>figure_replication.log</code>.\n\
    Figures and the log-file are saved in the same folder as the one where R script\
    \ is run and the filename structure is <code>figY_*.png</code> with Y is the figure\
    \ number reference in the paper and <code>*</code> provides additional informnation\
    \ about the data and the compressor.<br>\nNumbers for Table 4 are saved in the\
    \ last section in .txt files <code>statistic_benchmark_runtime_X.txt</code> with\
    \ X the studied dataset (NYX or SCALE).</p>\n<p>In order to limit the container\
    \ size to aid reproducibility, we only added a restricted number of scientific\
    \ datasets in the container and we rely on csv files from our production runs\
    \ (saved as described above in the Section \"How to compute statistical predictors\
    \ on datasets\").\nMore datasets are available on <a href=\"https://sdrbench.github.io\"\
    \ rel=\"nofollow\">SDRBench</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1675473427.0
JeffersonLab/epsci-containers:
  data_format: 2
  description: Container recipes used or maintained by EPSCI group
  filenames:
  - geant4/spack.yaml
  full_name: JeffersonLab/epsci-containers
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 10
  topics: []
  updated_at: 1636203976.0
JuliaParallel/MPI.jl:
  data_format: 2
  description: MPI wrappers for Julia
  filenames:
  - .ci/mvapich/spack.yaml
  full_name: JuliaParallel/MPI.jl
  latest_release: v0.20.8
  readme: '<h1><a id="user-content-mpi-interface-for-the-julia-language" class="anchor"
    aria-hidden="true" href="#mpi-interface-for-the-julia-language"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>MPI interface for the Julia language</h1>

    <p><a href="https://juliaparallel.github.io/MPI.jl/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667"
    alt="Docs latest" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667"
    alt="Docs stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml"><img
    src="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml/badge.svg"
    alt="Unit Tests" style="max-width: 100%;"></a>

    <a href="https://buildkite.com/julialang/mpi-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/87debbd756a8b45df7ac1f25dc034436051f7ccfe155df49f1ec1f6209e51caf/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65643831336263346437396635353761646264623832316231633863386465393839393936383665363937646634613337332e7376673f6272616e63683d6d6173746572"
    alt="GPU tests" data-canonical-src="https://badge.buildkite.com/ed813bc4d79f557adbdb821b1c8c8de98999686e697df4a373.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00ad86424fd334dccd9dde2876e4f3e82b84ad4219e5c1661d6a06b63f46f516/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f4d50492e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572"
    alt="codecov.io" data-canonical-src="https://codecov.io/github/JuliaParallel/MPI.jl/coverage.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://coveralls.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/4d989c928ad758732dcf79e5d1a0b592a1765763c2237af784955ed806e37ef1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f4d50492e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaParallel/MPI.jl/badge.svg?branch=master&amp;service=github"
    style="max-width: 100%;"></a></p>

    <p>This provides <a href="http://julialang.org/" rel="nofollow">Julia</a> interface
    to the Message Passing Interface (<a href="http://www.mpi-forum.org/" rel="nofollow">MPI</a>),
    roughly inspired by <a href="https://github.com/mpi4py/mpi4py/">mpi4py</a>.</p>

    <p>Please see the <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow">documentation</a>
    for instructions on <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/"
    rel="nofollow">configuration</a> and <a href="https://juliaparallel.github.io/MPI.jl/stable/usage/"
    rel="nofollow">usage</a>.</p>

    <p><strong>Breaking changes with v0.20:</strong> The way how MPI.jl is configured
    to use

    different MPI implementations has changed from v0.19 to v0.20 in a

    <em>non-backward-compatible</em> manner.

    Specifically, most <code>JULIA_MPI_XXX</code> variables do not have an effect
    anymore.

    Please refer to the

    <a href="https://juliaparallel.org/MPI.jl/stable/configuration/#Migration-from-MPI.jl-v0.19-or-earlier"
    rel="nofollow">docs</a>

    for information on how to migrate your existing configuration.</p>

    <h1><a id="user-content-help-and-discussion" class="anchor" aria-hidden="true"
    href="#help-and-discussion"><span aria-hidden="true" class="octicon octicon-link"></span></a>Help
    and discussion</h1>

    <p>For help and discussion, we suggest asking on the following venues:</p>

    <ul>

    <li><a href="https://discourse.julialang.org/c/domain/parallel/34" rel="nofollow">"Julia
    at Scale" topic on the Julia Discourse</a></li>

    <li>#distributed channel on the <a href="https://julialang.slack.com/" rel="nofollow">Julia
    Slack</a> (visit <a href="https://julialang.org/slack/" rel="nofollow">https://julialang.org/slack/</a>
    to join).</li>

    </ul>

    <h1><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h1>

    <p>Contributions are encouraged. In particular, MPI provides several hundred functions,
    only a small number of which are currently exposed. If there are additional functions
    you would like to use, please open an <a href="https://github.com/JuliaParallel/MPI.jl/issues">issue</a>
    or <a href="https://github.com/JuliaParallel/MPI.jl/pulls">pull request</a>.</p>

    <p>Additional examples and documentation improvements are also very welcome.</p>

    <h1><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citation</h1>

    <p>If you use MPI.jl in your work, please cite the following paper:</p>

    <blockquote>

    <p>Simon Byrne, Lucas C. Wilcox, and Valentin Churavy (2021) "MPI.jl: Julia bindings
    for the Message Passing Interface". <em>JuliaCon Proceedings</em>, 1(1), 68, doi:
    <a href="https://doi.org/10.21105/jcon.00068" rel="nofollow">10.21105/jcon.00068</a></p>

    </blockquote>

    '
  stargazers_count: 316
  subscribers_count: 20
  topics:
  - mpi
  - julia
  - hpc
  - julia-language
  - mpich
  - openmpi
  - microsoft-mpi
  updated_at: 1677493787.0
L-LYR/playground:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: L-LYR/playground
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676371970.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/spack-nightly/int64-double/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int32-single/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int64-single/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int64-double/spack.yaml
  - docker/sundials-ci/spack-nightly/int32-double/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int32-double/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.5.0
  readme: '<h1><a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" aria-hidden="true" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SUNDIALS: SUite of
    Nonlinear and DIfferential/ALgebraic equation Solvers</h1>

    <h3><a id="user-content-version-650-dec-2022" class="anchor" aria-hidden="true"
    href="#version-650-dec-2022"><span aria-hidden="true" class="octicon octicon-link"></span></a>Version
    6.5.0 (Dec 2022)</h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form</p>

    <p>$$ M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0 $$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form</p>

    <p>$$ y'' = f(t,y), \quad y(t_0) = y_0 $$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form</p>

    <p>$$ y'' = f(t,y,p), \quad y(t_0) = y_0(p) $$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form</p>

    <p>$$ F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0'' $$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form</p>

    <p>$$ F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p) $$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form</p>

    <p>$$ F(u) = 0 \quad \text{or} \quad G(u) = u $$</p>

    </li>

    </ul>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" href="#support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2><a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Slaven Peles, Cosmin Petra, H. Hunter Schwartz, Jean M. Sexton,

    Dan Shumaker, Steve G. Smith, Allan G. Taylor, Hilari C. Tiedeman, Chris White,

    Ting Yan, and Ulrike M. Yang.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 332
  subscribers_count: 34
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1677510009.0
LLNL/uberenv:
  data_format: 2
  description: Automates using spack to build and deploy software
  filenames:
  - .ci/test-project/spack_configs/linux_ubuntu_22/spack.yaml
  - .ci/test-project/spack_configs/toss_3_x86_64_ib/spack.yaml
  - .ci/test-project/spack_configs/darwin/spack.yaml
  full_name: LLNL/uberenv
  latest_release: v1.0.0
  readme: '<h1><a id="user-content-uberenv" class="anchor" aria-hidden="true" href="#uberenv"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>uberenv</h1>

    <p>Automates using a package manager to build and deploy software.</p>

    <p><a href="https://uberenv.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/02247bd3961daeb4d17d6d1d8f821df0c991efeb0c5f0411fed0a94bd9fa3ebe/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f75626572656e762f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/uberenv/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Uberenv is a python script that helps automate building

    third-party dependencies for development and deployment.</p>

    <p>Uberenv uses Spack (<a href="https://www.spack.io/" rel="nofollow">https://www.spack.io/</a>)
    on Unix-based systems (e.g. Linux and macOS)

    and Vcpkg (<a href="https://github.com/microsoft/vcpkg">https://github.com/microsoft/vcpkg</a>)
    on Windows systems.</p>

    <p>Uberenv was released as part of the Conduit project (<a href="https://github.com/LLNL/conduit/">https://github.com/LLNL/conduit/</a>).

    It is included in-source in several projects, this repo is used to hold the latest
    reference version.</p>

    <p>For more details, see Uberenv''s documention:</p>

    <p><a href="https://uberenv.readthedocs.io" rel="nofollow">https://uberenv.readthedocs.io</a></p>

    <p>You can also find details about how it is used in Conduit''s documentation:</p>

    <p><a href="https://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies"
    rel="nofollow">https://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies</a></p>

    <p>Conduit''s source repo also serves as an example for uberenv and spack configuration
    files, etc:</p>

    <p><a href="https://github.com/LLNL/conduit/tree/master/scripts/uberenv">https://github.com/LLNL/conduit/tree/master/scripts/uberenv</a></p>

    '
  stargazers_count: 20
  subscribers_count: 8
  topics:
  - shell
  - build-tools
  updated_at: 1676463765.0
MeteoSwiss/fdb-fortran:
  data_format: 2
  description: Fortran Interface to ECMWF's FDB
  filenames:
  - docker/spack.yaml
  full_name: MeteoSwiss/fdb-fortran
  latest_release: null
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1676364883.0
MichaelBrim/unify-olcf-scripts:
  data_format: 2
  description: null
  filenames:
  - crusher/spack-env/spack.yaml
  - summit/spack-env/spack.yaml
  full_name: MichaelBrim/unify-olcf-scripts
  latest_release: null
  readme: '<h1><a id="user-content-unify-olcf-scripts" class="anchor" aria-hidden="true"
    href="#unify-olcf-scripts"><span aria-hidden="true" class="octicon octicon-link"></span></a>unify-olcf-scripts</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649778838.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Sat Dec 17 18:52:51 MST 2022</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>9f557cbfe06b92815bc29b92e7cf4eff09917601</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>22.12</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td>165cd55980572fc3ccef5f322ad8ad8b3e5dd3db</td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/22.12</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/22.12/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 3
  subscribers_count: 12
  topics: []
  updated_at: 1676353353.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/gcc/spack.yaml
  - spack-configs/cori-e4s-21.02/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/prod/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cce/spack.yaml
  - spack-configs/cori-e4s-21.02/prod/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/nvhpc/spack.yaml
  - spack-configs/perlmutter-user-spack/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/nvhpc/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file. The documentation is available at\
    \ <a href=\"https://nersc-spack-infrastructure.rtfd.io/\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io/</a></p>\n\
    <h2><a id=\"user-content-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-configuration\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Configuration</h2>\n<p>The spack configuration\
    \ can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<h2><a id=\"user-content-running-ci-pipelines\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-ci-pipelines\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>. Please make sure you\
    \ login to the appropriate hostname when starting the gitlab runner.</p>\n<table>\n\
    <thead>\n<tr>\n<th>System</th>\n<th>Runner Name</th>\n<th>Hostname</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n\
    <td><code>login27</code></td>\n</tr>\n<tr>\n<td>cori</td>\n<td><code>cori-e4s</code></td>\n\
    <td><code>cori02</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    <td><code>login02</code></td>\n</tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n\
    <td><code>gert01</code></td>\n</tr>\n</tbody>\n</table>\n<p>The runner configuration\
    \ files are located in <code>~/.gitlab-runner</code> for user <strong>e4s</strong>.</p>\n\
    <p>The production pipelines are triggered via web-interface which requires approval\
    \ from a project maintainer. Production pipelines should be run when we need to\
    \ do full redeployment of stack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#current-challenges\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have external packages set for packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li><strong>Erik Palmer (<a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>)</strong></li>\n\
    <li><strong>Justin Cook (<a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 8
  subscribers_count: 13
  topics: []
  updated_at: 1673545287.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: upp-srw-v2.1.0
  readme: '<h1><a id="user-content-unified-post-processing-upp" class="anchor" aria-hidden="true"
    href="#unified-post-processing-upp"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unified
    Post-Processing (UPP)</h1>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecasting System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Application

    Forecasting System (HAFS), and the Medium Range Weather (MRW) and Short

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model

    derived brightness temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages, or for

    further downstream post-processing, e.g. statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <h2><a id="user-content-user-support" class="anchor" aria-hidden="true" href="#user-support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>User Support</h2>

    <p>Support for the UFS UPP is provided through <a href="https://github.com/NOAA-EMC/UPP/discussions">GitHub
    Discussions</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>User Guide for latest public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <h2><a id="user-content-developer-information" class="anchor" aria-hidden="true"
    href="#developer-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>Developer
    Information</h2>

    <p>Please see review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Kate Fossell</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>The UPP requires certain NCEPLIB packages to be installed via

    the HPC-Stack project.</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-gfsio">NCEPLIBS-gfsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">libz</a></li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for Regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 23
  subscribers_count: 15
  topics: []
  updated_at: 1677617073.0
NOAA-EMC/WW3:
  data_format: 2
  description: WAVEWATCH III
  filenames:
  - model/ci/spack_gnu.yaml
  - model/ci/spack_intel.yaml
  full_name: NOAA-EMC/WW3
  latest_release: 6.07.1
  readme: "<h1><a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2><a id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#general-features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 192
  subscribers_count: 48
  topics: []
  updated_at: 1677215045.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/ufs-weather-model-static/spack.yaml
  - configs/templates/unified-dev/spack.yaml
  - configs/templates/jedi-ufs-all/spack.yaml
  - configs/templates/skylab-no-python-dev/spack.yaml
  - configs/templates/hpc-stack-dev/spack.yaml
  - configs/templates/skylab-dev/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: spack-stack-1.2.0
  readme: '<h1><a id="user-content-spack-stack" class="anchor" aria-hidden="true"
    href="#spack-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>Spack-stack enables the installation of software required

    for HPC system deployments of NOAA''s Unified Forecast System (UFS) and

    other weather and climate models, including components of the Joint

    Effort for Data assimilation Integration (JEDI).</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>.</li>

    </ul>

    <p>Spack-stack is a thin layer around a fork of the

    <a href="https://github.com/spack/spack">spack</a> repository. Spack is a

    community-supported, multi-platform, Python-based package manager

    originally developed by the Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about spack see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for

    spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack

    documentation</a>.</p>

    <p>The stack can be installed on a range of platforms, from Linux and

    macOS laptops to HPC systems, and comes pre-configured for many

    systems. Users can install the necessary packages for a particular

    application and later add the missing packages for another application

    without having to rebuild the entire stack.</p>

    <p>spack-stack is mainly a collection of Spack configuration files, but

    provides a Spack extension to simplify the installation process:</p>

    <ul>

    <li>

    <p><code>spack stack create</code> is provided to copy common, site-specific,
    and

    application-specific configuration files into a coherent Spack

    environment and to create container recipes</p>

    </li>

    <li>

    <p><code>spack stack setup-meta-modules</code> creates compiler, MPI and Python

    meta-modules for a convenient setup of a user environment using

    modules (lua and tcl)</p>

    </li>

    </ul>

    <p>Documentation for installing and using spack-stack can be found here:

    <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a></p>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>

    <p><a href="https://www.github.com/AlexanderRichert-NOAA">Alex Richert</a>, <a
    href="https://www.github.com/Hang-Lei-NOAA">Hang

    Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed

    Hartnett</a> NOAA-EMC</p>

    </li>

    <li>

    <p><a href="https://www.github.com/climbfuji">Dom Heinzeller</a>, JCSDA</p>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 13
  subscribers_count: 6
  topics: []
  updated_at: 1675192557.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.18.1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#rhel7-spack-config\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#useful-commands\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack\
    \ module lmod refresh\n</code></pre>\n<h2><a id=\"user-content-installing-new-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-new-packages\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new\
    \ packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack\
    \ package updates could result in additional installation of packages with little\
    \ or no package source code changes.  These additional installs can be avoided\
    \ when installing new packages by first examining the output of the <code>spack\
    \ spec -I</code> command.  If a utility/infrastructure level package, such as\
    \ cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column\
    \ then it means that the existing install will be used.  If spack does not default\
    \ to using the existing install you can append the hash of the package to the\
    \ spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi\
    \ install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\n\
    Input spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\n\
    Concretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo\
    \ ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]     \
    \ ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64\
    \ \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64\
    \ \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]  \
    \        ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]  \
    \            ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643231013.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/archived/minimal/rhel8-x86_64/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-x86_64/spack.yaml
  - docker-recipes/archived/minimal/rhel8-aarch64/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-x86_64/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-aarch64/spack.yaml
  - docker-recipes/archived/minimal/rhel8-ppc64le/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-aarch64/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-ppc64le/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 20
  subscribers_count: 6
  topics: []
  updated_at: 1673374590.0
actions-marketplace-validations/haampie-spack_setup-spack:
  data_format: 2
  description: null
  filenames:
  - example-environment/spack.yaml
  full_name: actions-marketplace-validations/haampie-spack_setup-spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1669840356.0
antoine-morvan/spack-offline-env:
  data_format: 2
  description: null
  filenames:
  - complete_env/spack.yaml
  - compilers_env/spack.yaml
  - simple_env/spack.yaml
  full_name: antoine-morvan/spack-offline-env
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1644310043.0
bsurc/BSU-software-configs:
  data_format: 2
  description: null
  filenames:
  - borah/environments/libraries/netcdf/_spack.yaml
  - borah/environments/applications/wrf/_spack.yaml
  - borah/environments/libraries/hdf5/_spack.yaml
  - borah/environments/base/_spack.yaml
  full_name: bsurc/BSU-software-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configurations-used-to-stand-up-stacks-at-boise-state-university"
    class="anchor" aria-hidden="true" href="#spack-configurations-used-to-stand-up-stacks-at-boise-state-university"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configurations
    used to stand up stacks at Boise State University</h1>

    <p>(C) 2022 Frank Willmore, et. al. Boise State Univesity Reseach Computing

    <a href="mailto:frankwillmore@boisestate.edu">frankwillmore@boisestate.edu</a></p>

    <p>Note that the environment (spack.yaml) files as checked in are named _spack.yaml,
    since spack rewrites and reorders spack.yaml as it digests the environment. _spack.yaml
    can be regarded as the master, and copied to spack.yaml when processing an environment.
    There is a .gitignore under BOISESTATE set to ignore spack.yaml''s under this
    tree.</p>

    <p>Base configurations provided gcc and oneapi compilers, cuda built with these
    compilers, mpich, openmpi, and intel-oneapi-mpi MPI stacks built with these compilers,
    and modules that will load the correct cuda build and compiler when loading the
    MPI.</p>

    <p>Copies of modules are checked in as well, as these needed to be modified considerably
    from the original generated modules.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676657373.0
buildtesters/buildtest-nersc:
  data_format: 2
  description: null
  filenames:
  - buildspecs/apps/e4s/22.02/spack.yaml
  - buildspecs/apps/e4s/22.05/spack.yaml
  full_name: buildtesters/buildtest-nersc
  latest_release: null
  readme: '<h1><a id="user-content-buildtest-nersc" class="anchor" aria-hidden="true"
    href="#buildtest-nersc"><span aria-hidden="true" class="octicon octicon-link"></span></a>buildtest-nersc</h1>

    <p>This repository contains tests for Cori and Perlmutter using the <a href="https://buildtest.readthedocs.io/en/devel/"
    rel="nofollow">buildtest</a> framework.</p>

    <h2><a id="user-content-useful-links" class="anchor" aria-hidden="true" href="#useful-links"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful Links</h2>

    <ul>

    <li>CDASH: <a href="https://my.cdash.org/index.php?project=buildtest-nersc" rel="nofollow">https://my.cdash.org/index.php?project=buildtest-nersc</a>

    </li>

    <li>Upstream Repo: <a href="https://software.nersc.gov/NERSC/buildtest-nersc"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc</a>

    </li>

    <li>Github Mirror Repo: <a href="https://github.com/buildtesters/buildtest-nersc">https://github.com/buildtesters/buildtest-nersc</a>

    </li>

    </ul>

    <h2><a id="user-content-buildtest-references" class="anchor" aria-hidden="true"
    href="#buildtest-references"><span aria-hidden="true" class="octicon octicon-link"></span></a>Buildtest
    References</h2>

    <ul>

    <li>Documentation: <a href="https://buildtest.readthedocs.io/en/devel/" rel="nofollow">https://buildtest.readthedocs.io/en/devel/</a>

    </li>

    <li>Schema Docs: <a href="https://buildtesters.github.io/buildtest/" rel="nofollow">https://buildtesters.github.io/buildtest/</a>

    </li>

    <li>Slack Channel: <a href="https://hpcbuildtest.slack.com" rel="nofollow">https://hpcbuildtest.slack.com</a>

    </li>

    <li>Getting Started: <a href="https://buildtest.readthedocs.io/en/devel/getting_started.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/getting_started.html</a>

    </li>

    <li>Writing Buildspecs: <a href="https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html</a>

    </li>

    <li>Contributing Guide: <a href="https://buildtest.readthedocs.io/en/devel/contributing.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/contributing.html</a>

    </li>

    </ul>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <p>To get started, please <a href="https://docs.nersc.gov/connect/" rel="nofollow">connect
    to NERSC system</a> and clone this repo and buildtest:</p>

    <pre><code>git clone https://github.com/buildtesters/buildtest

    git clone https://software.nersc.gov/NERSC/buildtest-nersc

    </code></pre>

    <p>Note if you don''t have access to Gitlab server you may clone the mirror on
    Github:</p>

    <pre><code>git clone https://github.com/buildtesters/buildtest-nersc

    </code></pre>

    <p>You will need python 3.7 or higher to <a href="https://buildtest.readthedocs.io/en/devel/installing_buildtest.html"
    rel="nofollow">install buildtest</a>, on Cori/Perlmutter this can be done by loading
    <strong>python</strong>

    module and create a conda environment as shown below.</p>

    <pre><code>module load python

    conda create -n buildtest

    conda activate buildtest

    </code></pre>

    <p>Now let''s install buildtest, assuming you have cloned buildtest in $HOME directory
    source the setup script. For csh users you need to source <strong>setup.csh</strong></p>

    <pre><code>source ~/buildtest/setup.sh


    # csh users

    source ~/buildtest/setup.csh

    </code></pre>

    <p>Next, navigate to <code>buildtest-nersc</code> directory and set environment
    <code>BUILDTEST_CONFIGFILE</code> to point to <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/config.yml"
    rel="nofollow">config.yml</a> which is the configuration file for NERSC system.</p>

    <pre><code>cd buildtest-nersc

    export BUILDTEST_CONFIGFILE=$(pwd)/config.yml

    </code></pre>

    <p>Make sure the configuration is valid, this can be done by running the following.
    buildtest will validate the configuration file with the JSON schema :</p>

    <pre><code>buildtest config validate

    </code></pre>

    <p>Please make sure you are using tip of <a href="https://github.com/buildtesters/buildtest/tree/devel">devel</a>
    branch of buildtest when writing tests. You should sync your local devel branch
    with upstream

    fork, for more details see <a href="https://buildtest.readthedocs.io/en/devel/contributing/code_contribution_guide.html"
    rel="nofollow">contributing guide</a>.</p>

    <p>First time around you should discover all buildspecs this can be done via <code>buildtest
    buildspec find</code>.  The command below will find

    and validate all buildspecs in the <strong>buildtest-nersc</strong> repo and load
    them in buildspec cache. Note that one needs to specify <code>--root</code> to
    specify location where

    all buildspecs are located, we have not configured <a href="https://buildtest.readthedocs.io/en/devel/configuring_buildtest/overview.html#buildspec-roots"
    rel="nofollow">buildspec_root</a> in the configuration file since we don''t have
    a central location where this repo will reside.</p>

    <pre><code>cd buildtest-nersc

    buildtest buildspec find --root buildspecs --rebuild -q

    </code></pre>

    <p>The buildspecs are loaded in buildspec cache file (JSON) that is used by <code>buildtest
    buildspec find</code> for querying cache. Subsequent runs will

    read from cache.  For more details see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/buildspecs_interface.html"
    rel="nofollow">buildspec interface</a>.</p>

    <h2><a id="user-content-building-tests" class="anchor" aria-hidden="true" href="#building-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building Tests</h2>

    <p><strong>Note: All tests are written in YAML using .yml extension</strong></p>

    <p>To build tests use <code>buildtest build</code> command for example we build
    all tests in <code>system</code> directory as follows</p>

    <pre><code>buildtest build -b system/

    </code></pre>

    <p>You can specify multiple buildspecs either files or directory via <code>-b</code>
    option</p>

    <pre><code>buildtest build -b slurm/partition.yml -b slurmutils/

    </code></pre>

    <p>You can exclude a buildspec via <code>-x</code> option this behaves same way
    as <code>-b</code> option so you can specify

    a directory or filepath which could be absolute path, or relative path. This is
    useful when

    you want to run multiple tests grouped in directory but exclude a few.</p>

    <pre><code>buildtest build -b slurm -x slurm/sinfo.yml

    </code></pre>

    <p>buildtest can run tests via tags which can be useful when grouping tests, to
    see a list of available tags you

    can run: <code>buildtest buildspec find --tags</code></p>

    <p>For instance if you want to run all <code>lustre</code> tests you can run the
    following:</p>

    <pre><code>buildtest build --tags lustre

    </code></pre>

    <p>For more details on buildtest test please see the <a href="https://buildtest.readthedocs.io/en/devel/getting_started.html"
    rel="nofollow">buildtest tutorial</a></p>

    <h2><a id="user-content-tags-breakdown" class="anchor" aria-hidden="true" href="#tags-breakdown"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Tags Breakdown</h2>

    <p>When you write buildspecs, please make sure you attach one or more <code>tags</code>
    to the test that way your test will get picked up during one of the CI checks.
    Shown

    below is a summary of tag description</p>

    <ul>

    <li>

    <strong>daily</strong> - this tag is used for running daily system checks using
    gitlab CI. Tests should run relatively quick</li>

    <li>

    <strong>system</strong> - this tag is used for classifying all system tests that
    may include: system configuration, servers, network, cray tests. This tag should
    be used</li>

    <li>

    <strong>slurm</strong> - this tag is used for slurm test that includes slurm utility
    check, slurm controller, etc... This tag <strong>shouldn''t</strong> be used for
    job submission that is managed by <strong>jobs</strong> tag. The <code>slurm</code>
    tag tests should be short running test that use a Local Executor.</li>

    <li>

    <strong>jobs</strong> - this tag is used for testing slurm policies by submitting
    jobs to scheduler.</li>

    <li>

    <strong>compile</strong> - this tag is used for compilation of application (OpenMP,
    MPI, OpenACC, CUDA, upc, bupc, etc...)</li>

    <li>

    <strong>e4s</strong> - this tag is used for running tests for E4S stack via <code>spack
    test</code> or <a href="https://github.com/E4S-Project/testsuite">E4S Testsuite</a>.</li>

    <li>

    <strong>module</strong> - this tag is used for testing module system</li>

    <li>

    <strong>benchmark</strong> - this tag is used for benchmark tests. This can be
    application benchmarks, mini-benchmarks, kernels, etc...</li>

    </ul>

    <p>You can see breakdown of tags and buildspec summary with the following commands</p>

    <pre><code>buildtest buildspec summary

    buildtest buildspec find --group-by-tags

    </code></pre>

    <h2><a id="user-content-querying-tests" class="anchor" aria-hidden="true" href="#querying-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Querying Tests</h2>

    <p>You can use <code>buildtest report</code> and <code>buildtest inspect</code>
    to query tests. The commands differ slightly and data is

    represented differently. The <code>buildtest report</code> command will show output
    in tabular form and only show some of the metadata,

    if you want to access the entire test record use <code>buildtest inspect</code>
    command which displays the content in JSON format.

    For more details on querying tests see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a></p>

    <h2><a id="user-content-ci-setup" class="anchor" aria-hidden="true" href="#ci-setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CI Setup</h2>

    <p>Tests are run on schedule basis with one schedule corresponding to one gitlab
    job in <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/.gitlab-ci.yml"
    rel="nofollow">.gitlab-ci.yml</a>. The scheduled pipelines are configured in

    <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules</a>.
    Each schedule has a variable <code>TESTNAME</code> defined to control which pipeline

    is run since we have multiple gitlab jobs. In the <code>.gitlab-ci.yml</code>
    we make use of conditional rules using <a href="https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic"
    rel="nofollow">only</a>.</p>

    <p>The scheduled jobs are run at different intervals (1x/day, 1x/week, etc...)
    at different times of day to avoid overloading the system. The gitlab jobs

    will run jobs based on tags, alternately some tests may be defined by running
    all tests in a directory (<code>buildtest build -b apps</code>). If you want to
    add a new

    scheduled job, please define a <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules/new"
    rel="nofollow">new schedule</a> with an appropriate time. The

    <code>target branch</code> should be <code>devel</code> and define a unique variable
    used to distinguish scheduled jobs. Next, create a job in <code>.gitlab-ci.yml</code>
    that references the scheduled job and define variable <code>TESTNAME</code> in
    the scheduled pipeline.</p>

    <h2><a id="user-content-integrations" class="anchor" aria-hidden="true" href="#integrations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Integrations</h2>

    <p>This project has integration with Slack to notify CI builds to <a href="https://hpcbuildtest.slack.com"
    rel="nofollow">buildtest Slack</a> at <strong>#buildtest-nersc</strong> workspace.
    The integrations can be

    found at <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations</a>.</p>

    <p>This project has setup a push mirror to <a href="https://github.com/buildtesters/buildtest-nersc">https://github.com/buildtesters/buildtest-nersc</a>
    which can be seen at <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository</a>

    under <strong>Mirroring Repositories</strong>. If the push mirror is not setup,
    please add the mirror.</p>

    <h2><a id="user-content-cdash" class="anchor" aria-hidden="true" href="#cdash"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CDASH</h2>

    <p>buildtest will push test results to <a href="https://www.cdash.org/" rel="nofollow">CDASH</a>
    server

    at <a href="https://my.cdash.org/index.php?project=buildtest-nersc" rel="nofollow">https://my.cdash.org/index.php?project=buildtest-nersc</a>
    using <code>buildtest cdash upload</code> command.</p>

    <h2><a id="user-content-contributing-guide" class="anchor" aria-hidden="true"
    href="#contributing-guide"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing
    Guide</h2>

    <p>To contribute back you will want to make sure your buildspec is validated before
    you contribute back, this could be

    done by running test manually <code>buildtest build</code> or see if buildspec
    is valid via <code>buildtest buildspec find</code>. It

    would be good to run your test and make sure it is working as expected, you can
    view test detail using <code>buildtest inspect name &lt;testname&gt;</code> or
    <code>buildtest inspect query &lt;testname&gt;</code>. For more

    details on querying test please see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a>.</p>

    <p>If you want to contribute your tests, please see <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/CONTRIBUTING.md"
    rel="nofollow">CONTRIBUTING.md</a></p>

    <h2><a id="user-content-submitting-an-issue" class="anchor" aria-hidden="true"
    href="#submitting-an-issue"><span aria-hidden="true" class="octicon octicon-link"></span></a>Submitting
    an Issue</h2>

    <p>Please submit all issues to <a href="https://github.com/buildtesters/buildtest-nersc/issues">https://github.com/buildtesters/buildtest-nersc/issues</a>.
    When creating an issue, please see the <a href="https://github.com/buildtesters/buildtest-nersc/labels">labels</a>

    and try to select one or more labels to categorize issue. Please use the following
    labels depending on the type of issue you are reporting</p>

    <ul>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/bug">Bug</a>:
    When creating an issue related to a test bug</li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/new-test">new-test</a>:
    An issue for adding a new test</li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/E4S-Testsuite">E4S-Testsuite</a>:
    Issues related to <a href="https://github.com/E4S-Project/testsuite">E4S testsuite
    project</a>

    </li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/spack">spack</a>:
    Issues related to <code>spack test</code>

    </li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/documentation">documentation</a>:
    Issues with documentation such as README.md, CONTRIBUTING.md</li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/gitlab-ci">gitlab-ci</a>:
    Issues with Gitlab CI/CD</li>

    </ul>

    '
  stargazers_count: 6
  subscribers_count: 4
  topics:
  - buildtest
  updated_at: 1671402594.0
celeritas-project/celeritas:
  data_format: 2
  description: Celeritas is a new Monte Carlo transport code designed for high-performance
    simulation of high-energy physics detectors.
  filenames:
  - scripts/spack.yaml
  full_name: celeritas-project/celeritas
  latest_release: v0.2.1
  readme: "<h1><a id=\"user-content-celeritas\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Celeritas</h1>\n<p>The Celeritas project implements HEP detector physics\
    \ on GPU accelerator\nhardware with the ultimate goal of supporting the massive\
    \ computational\nrequirements of the <a href=\"https://home.cern/science/accelerators/high-luminosity-lhc\"\
    \ rel=\"nofollow\">HL-LHC upgrade</a>.</p>\n<h1><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>Most of\
    \ the Celeritas documentation is readable through the codebase through a\ncombination\
    \ of <a href=\"doc/index.rst\">static RST documentation</a> and Doxygen-markup\n\
    comments in the source code itself. The full <a href=\"https://celeritas-project.github.io/celeritas/user/index.html\"\
    \ rel=\"nofollow\">Celeritas user\ndocumentation</a> (including selected code\
    \ documentation incorporated\nby Breathe) and the <a href=\"https://celeritas-project.github.io/celeritas/dev/index.html\"\
    \ rel=\"nofollow\">Celeritas code documentation</a> are mirrored on\nour GitHub\
    \ pages site. You can generate these yourself by\nsetting the <code>CELERITAS_BUILD_DOCS=ON</code>\
    \ configuration option and running <code>ninja doc</code> (user) or <code>ninja\
    \ doxygen</code> (developer). A continuously updated version of\nthe <a href=\"\
    https://celeritas.readthedocs.io/en/latest/\" rel=\"nofollow\">static Celeritas\
    \ user documentation</a> (without API documentation) is\nhosted on <code>readthedocs.io</code>.</p>\n\
    <h1><a id=\"user-content-installation-for-applications\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#installation-for-applications\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Installation for applications</h1>\n<p>The easiest\
    \ way to install Celeritas as a library/app is with Spack:</p>\n<ul>\n<li>Follow\
    \ the first two steps above to install <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">Spack</a> and set up its CUDA usage.</li>\n<li>Install Celeritas\
    \ with <code>spack install celeritas</code>\n</li>\n<li>Use <code>spack load celeritas</code>\
    \ to add the installation to your <code>PATH</code>.</li>\n</ul>\n<p>Then see\
    \ the \"Downstream usage as a library\" section of the <a href=\"doc/installation.rst\"\
    >installation\ndocumentation</a> for how to use Celeritas in your application\
    \ or framework.</p>\n<h1><a id=\"user-content-installation-for-developers\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#installation-for-developers\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation for developers</h1>\n\
    <p>Since Celeritas is still under heavy development and is not yet full-featured\n\
    for downstream integration, you are likely installing it for development\npurposes.\
    \ The <a href=\"doc/installation.rst\">installation documentation</a> has a\n\
    complete description of the code's dependencies and installation process for\n\
    development.</p>\n<p>As an example, if you have the <a href=\"https://github.com/spack/spack\"\
    >Spack</a> package manager\ninstalled and want to do development on a CUDA system\
    \ with Volta-class graphics\ncards, execute the following steps:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre># <span class=\"pl-s1\">Set up CUDA\
    \ (optional)</span>\n$ <span class=\"pl-s1\">spack external find cuda</span>\n\
    $ <span class=\"pl-s1\">spack config add packages:all:variants:<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>+cuda cuda_arch=70<span class=\"pl-pds\"\
    >\"</span></span></span>\n# <span class=\"pl-s1\">Install celeritas dependencies</span>\n\
    $ <span class=\"pl-s1\">spack env create celeritas scripts/spack.yaml</span>\n\
    $ <span class=\"pl-s1\">spack env activate celeritas</span>\n$ <span class=\"\
    pl-s1\">spack install</span>\n# <span class=\"pl-s1\">Configure, build, and <span\
    \ class=\"pl-c1\">test</span></span>\n$ <span class=\"pl-s1\">./build.sh base</span></pre></div>\n\
    <p>If you don't use Spack but have all the dependencies you want (Geant4,\ngoogletest,\
    \ VecGeom, etc.) in your <code>CMAKE_PREFIX_PATH</code>, you can configure and\n\
    build Celeritas as you would any other project:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">mkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build</span>\n$ <span class=\"pl-s1\">cmake\
    \ ..</span>\n$ <span class=\"pl-s1\">make <span class=\"pl-k\">&amp;&amp;</span>\
    \ ctest</span></pre></div>\n<p>Celeritas guarantees full compatibility and correctness\
    \ only on the\ncombinations of compilers and dependencies tested under continuous\
    \ integration.\nCurrently supported compilers are GCC 11.2 + NVCC 11.8, and HIP-Clang\
    \ 15.0, but\nsince we compile with extra warning flags and avoid non-portable\
    \ code, most\nother compilers <em>should</em> work.\nCurrently Geant4 11.0 and\
    \ VecGeom 1.2 are the only versions that are guaranteed\nto work, but older versions\
    \ might be OK.\nThe full set of configurations is viewable on <a href=\"https://cloud.cees.ornl.gov/jenkins-ci/blue/organizations/jenkins/Celeritas/activity?branch=master\"\
    \ rel=\"nofollow\">the CI web site</a>.\nCompatibility fixes that do not cause\
    \ newer versions to fail are welcome.</p>\n<h1><a id=\"user-content-development\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Development</h1>\n<p>See the\
    \ <a href=\"CONTRIBUTING.rst\">contribution guide</a> for the contribution process,\n\
    <a href=\"doc/appendices/development.rst\">the development guidelines</a> for\
    \ further\ndetails on coding in Celeritas, and <a href=\"doc/appendices/administration.rst\"\
    >the administration guidelines</a> for community standards and roles.</p>\n<h1><a\
    \ id=\"user-content-citing-celeritas\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #citing-celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing Celeritas</h1>\n<p>If using Celeritas in your work, we ask\
    \ that you cite the code using its\n<a href=\"https://www.osti.gov/doecode/biblio/94866\"\
    \ rel=\"nofollow\">DOECode</a> registration:</p>\n<blockquote>\n<p>Johnson, Seth\
    \ R., Amanda Lund, Soon Yung Jun, Stefano Tognini, Guilherme Lima, Paul Romano,\
    \ Philippe Canal, Ben Morgan, and Tom Evans. \u201CCeleritas,\u201D July 2022.\
    \ <a href=\"https://doi.org/10.11578/dc.20221011.1\" rel=\"nofollow\">https://doi.org/10.11578/dc.20221011.1</a>.</p>\n\
    </blockquote>\n<p>Additional references for code implementation details, benchmark\
    \ problem\nresults, etc., can be found in our continually evolving <a href=\"\
    doc/_static/celeritas.bib\">citation\nfile</a>.</p>\n"
  stargazers_count: 30
  subscribers_count: 9
  topics:
  - hep
  - cuda
  - computational-physics
  - monte-carlo
  updated_at: 1676731995.0
charmoniumQ/wf-reg-test:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: charmoniumQ/wf-reg-test
  latest_release: null
  readme: "<h1><a id=\"user-content-wf-reg-test\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#wf-reg-test\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>wf-reg-test</h1>\n<p>Software tends to break or \"collapse\" over\
    \ time, even if it is unchanged, due to non-obvious changes in the computational\
    \ environment.\nCollapse in computational experiments undermines long-term credibility\
    \ and hinders day-to-day operations.\nWe propose to create the first public dataset\
    \ of automatically executable scientific experiments.\nThis data could be used\
    \ to identify best practices, make continuous testing feasible, and repair broken\
    \ programs.\nThese techniques increase the replicability of computational experiments.</p>\n\
    <p>Conceptually, we intend to collect the following:</p>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">registry</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >registries</span>:\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\"\
    >experiment</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">registry</span>:\n\
    \        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">version</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">experiment</span>:\n \
    \           <span class=\"pl-k\">for</span> <span class=\"pl-s1\">i</span> <span\
    \ class=\"pl-c1\">in</span> <span class=\"pl-en\">range</span>(<span class=\"\
    pl-s1\">num_repetitions</span>):\n                <span class=\"pl-s1\">execution</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-en\">execute</span>(<span class=\"\
    pl-s1\">version</span>)\n                <span class=\"pl-s1\">data</span>.<span\
    \ class=\"pl-en\">append</span>((\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">date</span>,   <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">output</span>,\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">logs</span>,   <span class=\"pl-s1\">execuiton</span>.<span\
    \ class=\"pl-s1\">res_usage</span>,\n                    <span class=\"pl-s1\"\
    >version</span>.<span class=\"pl-s1\">date</span>,     <span class=\"pl-s1\">version</span>.<span\
    \ class=\"pl-s1\">code</span>,\n                    <span class=\"pl-s1\">experiment</span>.<span\
    \ class=\"pl-s1\">name</span>,  <span class=\"pl-s1\">registry</span>.<span class=\"\
    pl-s1\">name</span>,\n                ))</pre></div>\n<h1><a id=\"user-content-reproducing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reproducing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Reproducing</h1>\n<p>See <a href=\"\
    REPRODUCING.md\"><code>REPRODUCING.md</code></a> for instructions on reproducing\
    \ these results.</p>\n<h1><a id=\"user-content-todo\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#todo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>TODO</h1>\n<p>See <a href=\"TODO.md\"><code>TODO.md</code></a> for\
    \ instructions on reproducing these results.</p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n<p>See <a\
    \ href=\"CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on\
    \ setting up a development environment.</p>\n"
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1676689037.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<h1><a id=\"user-content-d-seams\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#d-seams\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>d-SEAMS</h1>\n<p><strong>Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations</strong></p>\n<p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82b492dd4f94cd6fe1783f1065487d3dbc0602c2a65b1717a5613df3b6e8f65f/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <h1><a id=\"user-content-citation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #citation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citation</h1>\n\
    <ul>\n<li>\n<p>This has been published at the <a href=\"https://doi.org/10.1021/acs.jcim.0c00031\"\
    \ rel=\"nofollow\">Journal of Chemical Information and Modeling\n(JCIM)</a></p>\n\
    </li>\n<li>\n<p>You may also read <a href=\"https://arxiv.org/abs/1909.09830\"\
    \ rel=\"nofollow\">the preprint on arXiv</a></p>\n</li>\n</ul>\n<p>If you use\
    \ this software please cite the following:</p>\n<pre><code>Goswami, R., Goswami,\
    \ A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations. Journal of Chemical Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n\
    </code></pre>\n<p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<h1><a id=\"\
    user-content-compilation\" class=\"anchor\" aria-hidden=\"true\" href=\"#compilation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compilation</h1>\n\
    <p>We use a deterministic build system to generate both bug reports and uniform\n\
    usage statistics. This also handles the <code>lua</code> scripting engine.</p>\n\
    <p>\\note The lua functions are documented on the <a href=\"https://docs.dseams.info/md_markdown_luafunctions\"\
    \ rel=\"nofollow\">on the API Docs</a></p>\n<p>We also provide a <code>conda</code>\
    \ environment as a fallback, which is also recommended for MacOS users.</p>\n\
    <h2><a id=\"user-content-build\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build</h2>\n\
    <h3><a id=\"user-content-conda\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #conda\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conda</h3>\n\
    <p>Although we strongly suggest using <code>nix</code>, for MacOS systems, the\
    \ following\ninstructions may be more suitable. We will assume the presence of\
    \ <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\" rel=\"\
    nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>micromamba create -f environment.yml\nmicromamba activate dseams</pre></div>\n\
    <p>Now the installation can proceed.</p>\n<p>\\note we do not install a new version\
    \ of <code>cmake</code> within the <code>conda</code> environment because of conflicts\
    \ with <code>lua</code></p>\n<div class=\"highlight highlight-source-shell\"><pre>mkdir\
    \ build\n<span class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span class=\"\
    pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span class=\"\
    pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake install</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<h3><a\
    \ id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>Manually this can be done in a painful way as follows:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack install eigen@3.3.9 lua@5.2\nspack install\
    \ catch2 fmt yaml-cpp openblas boost cmake ninja meson\nspack load catch2 fmt\
    \ yaml-cpp openblas boost cmake ninja meson eigen@3.3.9 lua@5.2\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span\
    \ class=\"pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> After loading the packages</span>\nluarocks install luafilesystem</pre></div>\n\
    <p>Now we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<h3><a id=\"user-content-nix\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#nix\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Nix</h3>\n<p>Since this project is\
    \ built with <code>nix</code>, we can simply do the following from the\nroot directory\
    \ (longer method):</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Make sure there are no artifacts</span>\n\
    rm -rf build\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> This will take\
    \ a long time the first time as it builds the dependencies</span>\nnix-build <span\
    \ class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Optional</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Install\
    \ into your path</span>\nnix-env -if <span class=\"pl-c1\">.</span> <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>A faster method of building the software is by using the <a href=\"https://dseams.cachix.org/\"\
    \ rel=\"nofollow\">cachix binary cache</a> as shown:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install cachix</span>\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Use the binary cache</span>\n\
    cachix use dseams\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with\
    \ the cache than building from scratch</span>\nnix-build <span class=\"pl-c1\"\
    >.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <h3><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h3>\n\
    <p>Having installed the <code>yodaStruct</code> binary and library, we can now\
    \ use it.</p>\n<div class=\"highlight highlight-source-shell\"><pre>yodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>\\note The paths in the <code>.yml</code>\
    \ should be <strong>relative to the folder from which the binary is called</strong>.</p>\n\
    <p>If you're confused about how to handle the relative paths, run the command\
    \ <code>yodaStruct -c lua_inputs/config.yml</code> in the top-level directory,\
    \ and set the paths relative to the top-level directory. This is the convention\
    \ used in the examples as well.</p>\n<h3><a id=\"user-content-language-server-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#language-server-support\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Language Server\
    \ Support</h3>\n<p>To generate a <code>compile_commands.json</code> file for working\
    \ with a language server\nlike <a href=\"https://github.com/MaskRay/ccls\">ccls</a>\
    \ use the following commands:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\n\
    nix-shell --pure\nmkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span\
    \ class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES\
    \ ../\ncp compile_commands.json ../</pre></div>\n<p>Note that there is no need\
    \ to actually compile the project if you simply need to\nget the compiler database\
    \ for the language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<h2><a id=\"user-content-development\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development</h2>\n<p>We can simply use the <code>nix</code> environment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> From the project root</span>\nnix-shell --pure</pre></div>\n\
    <h1><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n\
    <p>This is built completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install\
    \ systemwide\nnix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply\
    \ install the software, and ensure that <code>input/</code> is a child directory.</p>\n\
    <pre lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<h2><a id=\"user-content-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#tests\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Tests</h2>\n<p>Apart from the <a href=\"\
    https://docs.dseams.info/pages.html\" rel=\"nofollow\">examples</a>, the test-suite\n\
    can be run with the <code>yodaStruct_test</code> binary, which will drop into\
    \ the\n<code>nix</code> environment before building and executing <code>gdb</code>:</p>\n\
    <pre lang=\"{bash}\"><code># Just run this\n./testBuild.sh\n# quit gdb with quit\n\
    # Go run the test binary\ncd shellBuild\n./yodaStruct_test\n</code></pre>\n<p>Do\
    \ note that the regular installation via <code>nix-env</code> runs the tests before\
    \ the installation</p>\n<h1><a id=\"user-content-developer-documentation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#developer-documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Developer Documentation</h1>\n\
    \n<p>While developing, it is sometimes expedient to update the packages used.\
    \ It is\nthen useful to note that we use <a href=\"https://github.com/nmattia/niv/\"\
    >niv</a> to handle our pinned packages (apart from\nthe ones built from Github).\
    \ Thus, one might need, say:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>niv update nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with\
    \ nix:</p>\n<div class=\"highlight highlight-source-shell\"><pre>nix-build <span\
    \ class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Outputs are in ./result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ If you get a CMake error</span>\nrm -rf build\nnix-store --delete /nix/store/<span\
    \ class=\"pl-smi\">$whatever</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> $whatever is the derivation complaining</span>\nnix-collect-garbage\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> then try again [worst case\
    \ scenario]</span></pre></div>\n<h2><a id=\"user-content-leaks-and-performance\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#leaks-and-performance\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Leaks and performance</h2>\n\
    <p>While testing for leaks, use <code>clang</code> (for\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\"\
    >AddressSanitizer</a>\nand\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<h1><a id=\"user-content-overview\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Overview</h1>\n<p>As of Mon Jan\
    \ 20 15:57:18 2020, the lines of code calculated by\n<a href=\"http://cloc.sourceforge.net/\"\
    \ rel=\"nofollow\">cloc</a> are as follows:</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"><img src=\"images/cloc-2020-01-20_15-56.png\"\
    \ alt=\"Cloc Lines\" style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n<p>Please\
    \ ensure that all contributions are formatted according to the\n<a href=\"./clang-format\"\
    >clang-format</a> configuration file.</p>\n<p>Specifically, consider using the\
    \ following:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\"\
    >Sublime Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"\
    https://github.com/lassik/emacs-format-all-the-code\">format-all</a> for Emacs</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\">vim-clang-format</a>\
    \ for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <h2><a id=\"user-content-commit-hook\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #commit-hook\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Commit\
    \ Hook</h2>\n<p>Note that we expect compliance with the <code>clang-format</code>\
    \ as mentioned above, and this may be enforced by using the provided scripts for\
    \ a pre-commit hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<h1><a id=\"user-content-acknowledgements\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#acknowledgements\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h1>\n<p>The\
    \ following tools are used in this project:</p>\n<ul>\n<li>\n<a href=\"https://cmake.org/\"\
    \ rel=\"nofollow\">CMake</a> for compilation (<a href=\"https://github.com/cginternals/cmake-init\"\
    >cmake-init</a> was used as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\"\
    \ rel=\"nofollow\">Clang</a> because it is more descriptive with better tools</li>\n\
    <li>\n<a href=\"https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the\
    \ developer API</li>\n<li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\"\
    \ rel=\"nofollow\">clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"\
    https://github.com/barisione/clang-format-hooks\">clang-format-hooks</a> for <code>git</code>\
    \ hooks to enforce formatting</li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\"\
    \ rel=\"nofollow\">lua</a> for the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\"\
    \ rel=\"nofollow\">yaml</a> for the configuration</li>\n</ul>\n<h2><a id=\"user-content-third-party-libraries\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#third-party-libraries\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Third Party Libraries</h2>\n\
    <p>The libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n</ul>\n"
  stargazers_count: 27
  subscribers_count: 5
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1677838715.0
deephyper/deephyper-platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running DeepHyper experiments on various platforms.
  filenames:
  - ANL/Swing/spack.yaml
  - ANL/Polaris/spack.yaml
  full_name: deephyper/deephyper-platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-deephyper-platform-configurations" class="anchor"
    aria-hidden="true" href="#deephyper-platform-configurations"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>DeepHyper Platform Configurations</h1>

    <p>This repository provides a set of configuration files and example scripts for
    running DeepHyper experiments on various platforms.</p>

    <p>The <code>generic</code> subdirectory contains a minimal DeepHyper environment
    example that can be used as a starting point for systems for which there is no
    existing recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which DeepHyper packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <div class="highlight highlight-source-shell"><pre>git clone -c feature.manyFiles=true
    https://github.com/spack/spack.git

    <span class="pl-c1">.</span> spack/share/spack/setup-env.sh</pre></div>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>deephyper-spack-packages</code>, which contains
    the DeepHyper packages.</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-spack-packages.git

    spack repo add deephyper-spack-packages</pre></div>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-platform-configurations.git

    <span class="pl-c1">cd</span> deephyper-platform-configurations/ANL/Polaris</pre></div>

    <p>Edit the path to <code>deephyper-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <div class="highlight highlight-source-shell"><pre>spack env create myenv spack.yaml</pre></div>

    <p>Change to a directory outside of the <code>deephyper-platform-configurations</code>
    folders

    and activate the environment as follows.</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate myenv</pre></div>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <div class="highlight highlight-source-shell"><pre>spack install</pre></div>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-acknowledgment" class="anchor" aria-hidden="true" href="#acknowledgment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgment</h2>

    <p>This repository was created by following the example of the <a href="https://github.com/mochi-hpc-experiments/platform-configurations">Mochi
    Project</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675421226.0
dyokelson/soma_c:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: dyokelson/soma_c
  latest_release: null
  readme: '<p>Your project "soma" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675627136.0
eic/containers:
  data_format: 2
  description: Container building infrastructure
  filenames:
  - spack.yaml
  full_name: eic/containers
  latest_release: null
  readme: '<h1><a id="user-content-eic-software-environment-container" class="anchor"
    aria-hidden="true" href="#eic-software-environment-container"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>EIC software environment container</h1>

    <p>For installation instructions of <code>eic-shell</code>, see <a href="https://github.com/eic/eic-shell">https://github.com/eic/eic-shell</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1669259240.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - env-bipp-izar/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<h1><a id="user-content-ska-spack-env" class="anchor" aria-hidden="true"
    href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a>ska-spack-env</h1>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
epfl-scitas/spack-sdploy:
  data_format: 2
  description: Toolset to deploy software stacks
  filenames:
  - samples/spack.yaml
  full_name: epfl-scitas/spack-sdploy
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-sdploy\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-sdploy\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>spack-sdploy</h1>\n<p>Spack extension for automatic package configuration\
    \ and deployment.</p>\n<h2><a id=\"user-content-how-to-install\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#how-to-install\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>How to install</h2>\n<p>You can try out this\
    \ Spack extension be executing 4 easy steps:</p>\n<ul>\n<li>Set up and activate\
    \ a local python environment</li>\n<li>Set up and activate <code>spack</code>\n\
    </li>\n<li>Install <code>spack-sdploy</code> dependencies</li>\n<li>Clone and\
    \ configure spack-sdploy</li>\n</ul>\n<p>This 4 steps are now detailed in the\
    \ next section.</p>\n<h3><a id=\"user-content-step-by-step-installation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#step-by-step-installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step-by-step installation</h3>\n\
    <p>Just for a matter of completeness, all the steps needed get up and running\
    \ with\nspack-sdploy extension will be covered, which can be a bit pedantic.</p>\n\
    <h4><a id=\"user-content-set-up-and-activate-a-local-python-environment\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#set-up-and-activate-a-local-python-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Set up and\
    \ activate a local python environment</h4>\n<p>It is recommended that a Python\
    \ environment be used to support sdploy. This same\nPython can also be used to\
    \ run Spack.</p>\n<pre><code>python3 -m venv &lt;path-to-environment-directory&gt;\n\
    . &lt;path-to-environment-directory&gt;/bin/activate\n</code></pre>\n<p>For more\
    \ information on how to create a virtual environment in Python refer to\nthe PEP\
    \ 405 \u2013 Python Virtual Environments documentation.</p>\n<h4><a id=\"user-content-set-up-and-activate-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#set-up-and-activate-spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Set up and activate\
    \ Spack</h4>\n<p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">Spack documentation</a>\non how to install Spack. For sake\
    \ of completeness, we copy paste the commands here:</p>\n<pre><code>git clone\
    \ -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n\
    </code></pre>\n<h4><a id=\"user-content-install-spack-sdploy-dependencies\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#install-spack-sdploy-dependencies\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Install <code>spack-sdploy</code>\
    \ dependencies</h4>\n<p>Up to now the only dependency of spack-sdploy if jinja2.\
    \ Once you have activated\nPython environment, you can simply use pip to install\
    \ the packages.</p>\n<pre><code>pip install jinja2\n</code></pre>\n<h4><a id=\"\
    user-content-clone-and-configure-spack-sdploy\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#clone-and-configure-spack-sdploy\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Clone and configure spack-sdploy</h4>\n<pre><code>git\
    \ clone git@github.com:epfl-scitas/spack-sdploy\n</code></pre>\n<p>To activate\
    \ the spack-sdploy extension you must add it to the config.yaml. If\nyou already\
    \ have another Spack installation and just want to try out\nspack-sdploy may very\
    \ well create a temporary directory to store the\nconfiguration and then use the\
    \ SPACK_USER_CONFIG_PATH variable to point this new\ndirectory.</p>\n<pre><code>mkdir\
    \ temporary_config\nexport SPACK_USER_CONFIG_PATH=/path/to/temporary_config\n\
    </code></pre>\n<p>and then, inside the temporary_config directory, write a config.yaml\
    \ file with\nthe following contents:</p>\n<pre><code>config:\n  extensions:\n\
    \  - /path/to/spack-sdploy\n</code></pre>\n<p>Be sure you do not change the spack-dploy\
    \ directory. Spack forces the extensions\nto follow strict rules. Please see the\n\
    <a href=\"https://spack.readthedocs.io/en/latest/extensions.html\" rel=\"nofollow\"\
    >Spack Extensions</a>\ndocumentation for more details about this subject. At this\
    \ point you should now\nbe able to call <code>spack -h</code> and see the new\
    \ Spack commands deployed by the\nspack-sdploy extension.</p>\n<h2><a id=\"user-content-how-to-use\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-use\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to use</h2>\n<p>At the present\
    \ time, spack-sdploy will add 2 commands to your already existing\nSpack commands.\
    \ These commandes are:</p>\n<pre><code>spack write-spack-yaml\nspack write-packages-yaml\n\
    </code></pre>\n<p>In the future we may change the names of these commands, but\
    \ for now lets just\nimagine these are short and easy to type commands.</p>\n\
    <p>As you may have guessed it (if you haven't that's ok), write-spack-yaml will\n\
    write the spack.yaml file and write-packages-yaml will write the packages.yaml\n\
    file. Of course, Spack does not (yet!) guess what you may want to install and\n\
    for that purpose, both these commands will read all the specs you want in your\n\
    spack.yaml file by reading another file you have previously written and which\n\
    we call by stack.yaml.</p>\n<p>For the time being, spack-sdploy already comes\
    \ with a dummy stack.yaml so we can\nget started using the new commands.</p>\n\
    <h2><a id=\"user-content-write-spack-yaml\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#write-spack-yaml\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>write-spack-yaml</h2>\n<pre><code>spack write-spack-yaml\n</code></pre>\n\
    <h2><a id=\"user-content-write-packages-yaml\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#write-packages-yaml\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>write-packages-yaml</h2>\n<pre><code>spack write-packages-yaml\n\
    </code></pre>\n<h2><a id=\"user-content-write-activate-list\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#write-activate-list\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>write-activate-list</h2>\n<pre><code>spack\
    \ write-activate-list -p &lt;platform&gt; -s &lt;stack&gt;\n</code></pre>\n<p>Write\
    \ to file named <code>packages_to_activate</code> list of packages to activate,\
    \ using <code>spack activate &lt;package&gt;</code>. Packages are writen one per\
    \ line.</p>\n<p>Packages to activate can be marked in the stack file in two possible\
    \ ways: by adding the keyword <code>activate: true</code> in the metadata section\
    \ of a list of packages or by adding the keyword <code>activate: true</code> to\
    \ an individual package. Duplicates are removed.</p>\n"
  stargazers_count: 0
  subscribers_count: 9
  topics: []
  updated_at: 1669125412.0
eugeneswalker/qmcpack-ci-container:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/qmcpack-ci-container
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678039711.0
floquet/builds:
  data_format: 2
  description: Notes and scripts for building applications on HPCs
  filenames:
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  full_name: floquet/builds
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641760136.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-clang/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1><a id="user-content-synergia2-containers" class="anchor" aria-hidden="true"
    href="#synergia2-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1674725167.0
hancheng2000/calcHW:
  data_format: 2
  description: null
  filenames:
  - environments/spack/spack.yaml
  full_name: hancheng2000/calcHW
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676957739.0
hariharan-devarajan/unifyfs-bug:
  data_format: 2
  description: null
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/unifyfs-bug
  latest_release: null
  readme: "<h1><a id=\"user-content-unifyfs-bug\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#unifyfs-bug\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>unifyfs-bug</h1>\n<h2><a id=\"user-content-the-bug-comes-in-multi-node-case-only\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#the-bug-comes-in-multi-node-case-only\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The bug\
    \ comes in multi-node case only.</h2>\n<h2><a id=\"user-content-instructions\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Instructions</h2>\n<ul>\n<li>update\
    \ path of unifyfs on dependency/spack.yaml packages</li>\n<li>activate dependency\
    \ spack folder\n<div class=\"highlight highlight-source-shell\"><pre>spack activate\
    \ -p dependency\nspack install</pre></div>\n</li>\n<li>update path of unifyfs\
    \ install on line 3 of CMakeLists</li>\n<li>build code.\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>cmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_C_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/gcc\
    \ -DCMAKE_CXX_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/g++ -G <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>CodeBlocks - Unix Makefiles<span class=\"\
    pl-pds\">\"</span></span> /g/g92/haridev/temp/unifyfs-bug\ncmake --build /g/g92/haridev/temp/unifyfs-bug/cmake-build-debug\
    \ --target all -- -j 128</pre></div>\n</li>\n<li>Run Unifyfs server\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> unifyfs-bug\n\
    <span class=\"pl-k\">export</span> UNIFYFS_LOG_VERBOSITY=3\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> SET ME</span>\n<span class=\"pl-k\">export</span>\
    \ UNIFYFS_ROOT_DIR=/usr/workspace/iopp/software/tailorfs/dependency/.spack-env/view\
    \  \n<span class=\"pl-k\">export</span> UNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >${HOME}</span>/unifyfs/logs\n<span class=\"pl-k\">export</span> pfs=/p/gpfs1/iopp\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">${PWD}</span>/dependency/.spack-env/view/lib:<span\
    \ class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/lib\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> ACTUAL RUN</span>\nUNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >$UNIFYFS_LOG_DIR</span> UNIFYFS_SERVER_CORES=8 <span class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/bin/unifyfs\
    \ start --share-dir=<span class=\"pl-smi\">${pfs}</span>/unifyfs/share-dir -d</pre></div>\n\
    </li>\n<li>Run code\n<div class=\"highlight highlight-source-shell\"><pre>jsrun\
    \ -r 1 -a 1 -c 1  -d packed <span class=\"pl-smi\">$PWD</span>/cmake-build-debug/unifyfs-bug</pre></div>\n\
    </li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675706965.0
hpc/mpifileutils:
  data_format: 2
  description: File utilities designed for scalability and performance.
  filenames:
  - spack.yaml
  full_name: hpc/mpifileutils
  latest_release: v0.11.1
  readme: '<h1><a id="user-content-mpifileutils" class="anchor" aria-hidden="true"
    href="#mpifileutils"><span aria-hidden="true" class="octicon octicon-link"></span></a>mpiFileUtils</h1>

    <p>mpiFileUtils provides both a library called <a href="src/common/README.md">libmfu</a>
    and a suite of MPI-based tools to manage large datasets, which may vary from large
    directory trees to large files. High-performance computing users often generate
    large datasets with parallel applications that run with many processes (millions
    in some cases). However those users are then stuck with single-process tools like
    cp and rm to manage their datasets. This suite provides MPI-based tools to handle
    typical jobs like copy, remove, and compare for such datasets, providing speedups
    of up to 20-30x.  It also provides a library that simplifies the creation of new
    tools or can be used in applications.</p>

    <p>Documentation is available on <a href="http://mpifileutils.readthedocs.io"
    rel="nofollow">ReadTheDocs</a>.</p>

    <h2><a id="user-content-daos-support" class="anchor" aria-hidden="true" href="#daos-support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>DAOS Support</h2>

    <p>mpiFileUtils supports a DAOS backend for dcp, dsync, and dcmp. Custom serialization
    and deserialization for DAOS containers to and from a POSIX filesystem is provided
    with daos-serialize and daos-deserialize. Details and usage examples are provided
    in <a href="DAOS-Support.md">DAOS Support</a>.</p>

    <h2><a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributors</h2>

    <p>We welcome contributions to the project.  For details on how to help, see our
    <a href="CONTRIBUTING.md">Contributor Guide</a></p>

    <h3><a id="user-content-copyrights" class="anchor" aria-hidden="true" href="#copyrights"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Copyrights</h3>

    <p>Copyright (c) 2013-2015, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory

    CODE-673838</p>

    <p>Copyright (c) 2006-2007,2011-2015, Los Alamos National Security, LLC.

    (LA-CC-06-077, LA-CC-10-066, LA-CC-14-046)</p>

    <p>Copyright (2013-2015) UT-Battelle, LLC under Contract No.

    DE-AC05-00OR22725 with the Department of Energy.</p>

    <p>Copyright (c) 2015, DataDirect Networks, Inc.</p>

    <p>All rights reserved.</p>

    <h2><a id="user-content-build-status" class="anchor" aria-hidden="true" href="#build-status"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Status</h2>

    <p>The current status of the mpiFileUtils master branch is <a href="https://travis-ci.org/hpc/mpifileutils"
    rel="nofollow"><img src="https://camo.githubusercontent.com/76717f664d99534173ac7e9fb8e904b0e4bd14fbd51ac6969a88de2e6e86a94f/68747470733a2f2f7472617669732d63692e6f72672f6870632f6d706966696c657574696c732e706e673f6272616e63683d6d6173746572"
    alt="Build Status" data-canonical-src="https://travis-ci.org/hpc/mpifileutils.png?branch=master"
    style="max-width: 100%;"></a>.</p>

    '
  stargazers_count: 134
  subscribers_count: 25
  topics: []
  updated_at: 1674881096.0
hppritcha/spack_ompix:
  data_format: 2
  description: null
  filenames:
  - intel_release_x86_64/spack.yaml
  - gnu_release_x86_64/spack.yaml
  - gnu_master_x86_64/spack.yaml
  - intel_master_x86_64/spack.yaml
  full_name: hppritcha/spack_ompix
  latest_release: null
  readme: '<p>Project for using Gitlab CI to test spack builds of Open MPI master
    and release tarballs.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1640037910.0
j-woz/SV-CP-2022-11-23:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: j-woz/SV-CP-2022-11-23
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669233200.0
jeffersonscientific/cees_spack_configs:
  data_format: 2
  description: CEES spack configurations (take 3). Focus on environments only (or
    mostly), and modular configs.
  filenames:
  - spack_env_files/cees_kimlab_spack.yaml
  - spack_env_files/dev_paraview_spack.yaml
  - spack_env_files/cees_skylake-beta_spack.yaml
  - spack_env_files/dev_py-bottleneck_spack.yaml
  - spack_env_files/cees_seissol_spack.yaml
  - spack_env_files/cees_x86_64-beta_spack.yaml
  - spack_env_files/cees_zen2-beta_spack.yaml
  - spack_env_files/cees_compilers_spack.yaml
  - configs/spack_petsc_mod.yaml
  - spack_env_files/dev_cees-x86-oneapi_spack.yaml
  - spack_env_files/dev_cees-x86-intel_spack.yaml
  full_name: jeffersonscientific/cees_spack_configs
  latest_release: null
  readme: "<h1><a id=\"user-content-cees_spack_configs\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#cees_spack_configs\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>cees_spack_configs</h1>\n<p>CEES spack configurations\
    \ (take 3). Focus on environments only (or mostly), and modular configs.</p>\n\
    <p>This constitutes a continued effort to find a way to Git-Support and modularize\
    \ Spack setups. While knowledge is much improved, success\nis arguably limited\
    \ -- alas. The idea is to be able to easily maintain a list of SW that is then\
    \ compiled over a suite of compiler, mpi,\narchitecture types.</p>\n<p>A few points:</p>\n\
    <ul>\n<li>Using environments is key.</li>\n<li>Using an <code>include:</code>\
    \ section can help. For example,</li>\n</ul>\n<pre><code>  include:\n  - $spack/../configs/packages_petsc.yaml\n\
    \  - $spack/../configs/compilers_sherlock_O2.yaml\n</code></pre>\n<p>might be\
    \ useful to build <code>petsc</code> environments for multiple architectures or\
    \ compilers. Unfortunatly -- at least at this time, not all sections\ncan be satisfied\
    \ as <code>include</code> files.</p>\n<ul>\n<li>Compilers remain a challenge...</li>\n\
    <li>If <code>providers</code> are specified, optimal (and functional) choices\
    \ will likely vary for different compilers.</li>\n</ul>\n<p>CONVENTIONS:</p>\n\
    <ul>\n<li>Configuration components indicated with <code>_inc</code> in name, eg\
    \ <code>packages_inc.yaml</code>. These files should stand alone for non-environment\
    \ builds\n(not recommended...) or can be included in an <code>include:</code>\
    \ clause of an environment.</li>\n<li>Environment files may be tagged with <code>_mod</code>\
    \ in the name, to indicate a \"modular\" envorinment, that uses an <code>include:</code>\
    \ section.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641864561.0
jeffersonscientific/seissol_compile:
  data_format: 2
  description: Compile (and similar) script for SeisSol
  filenames:
  - ss_spack_env_template.yaml
  full_name: jeffersonscientific/seissol_compile
  latest_release: null
  readme: '<h1><a id="user-content-seissol_compile" class="anchor" aria-hidden="true"
    href="#seissol_compile"><span aria-hidden="true" class="octicon octicon-link"></span></a>seissol_compile</h1>

    <p>Compile (and similar) script for SeisSol</p>

    <h1></h1>

    <p>To date, these scripts can be used to install SeisSol on Stanford Research
    Computing''s Sherlock HPC. The <code>compile_seissol_spack.sh</code> script primarily
    uses a <code>spack</code> built environment, and so can be adapted to another
    HPC relatively easily.</p>

    <p>The <code>compile_seissol_sherlock.sh</code> script might be refrenced as a
    template -- the idea being to use pre-built SW modules to build SeisSol, but it
    ultimately crashes and burns prety spetacularly. One issue is that the various
    components may have differend dependencies. Namely, some packages are built from
    a <code>gcc/10.1.0</code> toolchain and another from <code>gcc/12.1.0</code>.</p>

    <p>Files:</p>

    <ul>

    <li>

    <code>build_spack_env.sh</code>: a generic batchable bash script to build a spack
    environment.</li>

    <li>

    <code>ss_env.yaml</code>: Should be the einvironment file we use to define the
    <code>seissol</code> spack environment. Note that the environment includes some
    external package definitions and Sherlock''s built in <code>gcc</code> compilers,
    including the primary <code>gcc@12.1.0</code>. These will need to be modified
    to deploy on a different HPC. Compilers can be built natively in Spack, then automagically
    discovered and added, but ultimately it will still likely be neessary to modify
    their definition in the environment file.</li>

    <li>

    <code>compile_seissol_spack.sh</code>: Working (on Sherlock HPC) compile script.
    will build all the non-Spack components</li>

    <li>

    <code>compile_seissol_cees_sherlock</code>: An older compile script that attempts
    to use Sherlock''s standard SW to compile. It ultimately crashes and burns, but
    might be referenced as a template.</li>

    <li>

    <code>install_ss_spack.sh</code>: An early template to build the Spack environment
    from scratch, including building, and <code>find</code>ing compilers in Spack.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666893798.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - ornl/summit/summit.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/ellis/utilities/spack.yaml
  - configs/ellis/compilers/spack.yaml
  - configs/ellis/software/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" aria-hidden="true" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666717629.0
lanl/cellar-gtest-mpi:
  data_format: 2
  description: null
  filenames:
  - spack/agaspar/spack.yaml
  full_name: lanl/cellar-gtest-mpi
  latest_release: null
  readme: "<h1><a id=\"user-content-google-test-for-mpi-gtest-mpi\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#google-test-for-mpi-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Google Test for MPI (gtest-mpi)</h1>\n\
    <p>This is a support library that helps users write Google Test unit tests that\n\
    rely on MPI.</p>\n<h2><a id=\"user-content-features\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Features</h2>\n<ul>\n<li>Serialized and rank-tagged Google Test output.</li>\n\
    <li>Rank-tagged failure reports.</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> is the easiest way\
    \ to install gtest-mpi. The gtest-mpi\npackage is available in\n<a href=\"https://gitlab.lanl.gov/agaspar/spack-repo\"\
    \ rel=\"nofollow\">agaspar/spack-repo</a>. Follow the\nREADME there to use that\
    \ spack repo. Once the agaspar-spack-repo repo is\ninstalled, installing gtest-mpi\
    \ is as simple as running:</p>\n<pre><code>spack install gtest-mpi\n</code></pre>\n\
    <p>When you want to use gtest-mpi, run <code>spack load gtest-mpi</code> to load\
    \ it into your\ncurrent environment.</p>\n<h3><a id=\"user-content-cmake\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>CMake</h3>\n<p>If you don't want to use spack,\
    \ you can install gtest-mpi directly using CMake.\ngtest-mpi uses CMake, so all\
    \ of your knowledge of CMake applies. gtest-mpi\nhas a dependency on Google Test,\
    \ and uses\n<a href=\"https://cmake.org/cmake/help/latest/module/FindGTest.html\"\
    \ rel=\"nofollow\">FindGTest.cmake</a> to\nfind it. Therefore, in order to install\
    \ gtest-mpi, you must first have a\nworking installation of <a href=\"https://github.com/google/googletest/\"\
    >Google Test</a>.</p>\n<p>Once you've installed Google Test, building and installing\
    \ gtest-mpi is just\nlike any other modern CMake package.</p>\n<pre><code>git\
    \ clone git@gitlab.lanl.gov:agaspar/gtest-mpi.git\ncd gtest-mpi\nmkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake install\n</code></pre>\n<h2><a id=\"user-content-using-gtest-mpi\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using gtest-mpi</h2>\n<h3><a\
    \ id=\"user-content-with-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #with-cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>With\
    \ CMake</h3>\n<p>If you don't need any custom startup logic, using gtest-mpi in\
    \ your own CMake\nproject is simple:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">find_package</span>(gtest-mpi 0.1 <span class=\"pl-k\"\
    >REQUIRED</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> gtest-mpi-main\
    \ provides a main function for you</span>\n<span class=\"pl-c1\">add_executable</span>(my-test\
    \ mytest.cpp)\n<span class=\"pl-c1\">target_link_libraries</span>(my-test gtest-mpi-main)</pre></div>\n\
    <p>Then you can write a Google Test just like you normally would:</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> mytest.cpp</span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-en\"\
    >TEST</span>(GTestMPI, Basic) {\n    <span class=\"pl-k\">int</span> rank;\n \
    \   <span class=\"pl-c1\">MPI_Comm_rank</span>(MPI_COMM_WORLD, &amp;rank);\n\n\
    \    <span class=\"pl-k\">bool</span> is_root = rank == <span class=\"pl-c1\"\
    >0</span>;\n\n    <span class=\"pl-k\">bool</span> is_anyone_root = <span class=\"\
    pl-c1\">false</span>;\n    <span class=\"pl-c1\">MPI_Allreduce</span>(\n     \
    \   &amp;is_root, &amp;is_anyone_root, <span class=\"pl-c1\">1</span>, MPI_CXX_BOOL,\
    \ MPI_LOR, MPI_COMM_WORLD);\n\n    <span class=\"pl-c1\">ASSERT_TRUE</span>(is_anyone_root);\n\
    }</pre></div>\n<p>If you need to write your own main function, that's also fairly\
    \ straighforward.\nIn your CMake project, you link against <code>gtest-mpi-lib</code>\
    \ instead of\n<code>gtest-mpi-main</code>. Then you must provide your own main\
    \ function:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> main.cpp</span>\n#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest-mpi/init.hpp<span\
    \ class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"\
    pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\
    \n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span> **argv) {\n    <span\
    \ class=\"pl-c1\">testing::InitGoogleTest</span>(&amp;argc, argv);\n    <span\
    \ class=\"pl-c1\">MPI_Init</span>(&amp;argc, &amp;argv);\n    <span class=\"pl-c1\"\
    >gtest_mpi::init</span>(&amp;argc, &amp;argv);\n\n    <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Your custom init logic goes here</span>\n\n    <span\
    \ class=\"pl-k\">int</span> exit_code = <span class=\"pl-c1\">RUN_ALL_TESTS</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Your custom finalize\
    \ logic goes here</span>\n\n    <span class=\"pl-c1\">gtest_mpi::finalize</span>();\n\
    \    <span class=\"pl-c1\">MPI_Finalize</span>();\n\n    <span class=\"pl-k\"\
    >return</span> exit_code;\n}</pre></div>\n<h3><a id=\"user-content-without-cmake\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#without-cmake\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Without CMake</h3>\n<p>CMake\
    \ is not required to use gtest-mpi, but it is recommended. If you wish to\nuse\
    \ a different build system, then adding <code>-lgtest-mpi-lib</code> and (optionally)\n\
    <code>-lgtest-mpi-main</code> to your link line will work.</p>\n<h2><a id=\"user-content-ctest\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#ctest\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>CTest</h2>\n<p>Here's an example of\
    \ adding a CTest using gtest-mpi to your CMake file:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">enable_testing</span>()\n\
    \n<span class=\"pl-c1\">add_test</span>(\n    <span class=\"pl-k\">NAME</span>\
    \ my-test\n    <span class=\"pl-k\">COMMAND</span>\n        <span class=\"pl-smi\"\
    >${MPIEXEC}</span> <span class=\"pl-smi\">${MPIEXEC_NUMPROC_FLAG}</span> 4 <span\
    \ class=\"pl-smi\">${MPIEXEC_PREFLAGS}</span>\n            $&lt;<span class=\"\
    pl-k\">TARGET_FILE</span>:my-test&gt; <span class=\"pl-smi\">${MPIEXEC_POSTFLAGS}</span>)</pre></div>\n\
    <p>These tests can be run using <code>ctest</code>.</p>\n"
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1668046366.0
laristra/ristra_spackages:
  data_format: 2
  description: 'A mirror of Ristra''s internal gitlab repository. '
  filenames:
  - env/broadwell/flecsalemm-deps/spack.yaml
  - env/power9le/flecsalemm-deps/spack.yaml
  - env/x86_64/flecsalemm-deps/spack.yaml
  full_name: laristra/ristra_spackages
  latest_release: null
  readme: '<h1><a id="user-content-ristra-spackages" class="anchor" aria-hidden="true"
    href="#ristra-spackages"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ristra
    Spackages</h1>

    <p>This repository contains the custom spackage files for the repos in laristra
    family.</p>

    <h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Basic Usage</h2>

    <p>We assume the user wish to work in the home directory and already have a spack
    instance setup.  The minimum required version of spack is 0.15.2.</p>

    <p>To get the content of this repo</p>

    <pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git

    </code></pre>

    <p>To use the custom spackage files with your spack</p>

    <pre><code>$ spack repo add ristra_spackages/spack-repo

    ==&gt; Added repo with namespace ''lanl_ristra''.


    $ spack repo list

    ==&gt; 2 package repositories.

    lanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo

    builtin            /home/&lt;user&gt;/spack/var/spack/repos/builtin

    </code></pre>

    <p>[Optional]

    To ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code>
    into your spack config folder</p>

    <pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/

    </code></pre>

    <p>Please see the <a href="https://spack.readthedocs.io/en/latest/configuration.html"
    rel="nofollow">Spack documentation</a> for more detailed info.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1649449003.0
ma595/fenics-csd3-spack:
  data_format: 2
  description: Set up fenics spack on csd3
  filenames:
  - spack-icelake.yaml
  - spack-skylake.yaml
  full_name: ma595/fenics-csd3-spack
  latest_release: null
  readme: '<h1><a id="user-content-fenics-csd3-spack" class="anchor" aria-hidden="true"
    href="#fenics-csd3-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>fenics-csd3-spack</h1>

    <p>Follow instructions in icelake-spack-env.sh</p>

    <p>Or, copy existing <code>spack.yaml</code> files into cloned Spack repo. It
    is necessary to <code>module purge</code> environment first, otherwise the prepend
    path inside <code>spack.yaml</code> will lead to duplications.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667830944.0
marcodelapierre/toy-cowsay-nf:
  data_format: 2
  description: Toy pipeline for simple Nextflow tests
  filenames:
  - spack.yaml
  full_name: marcodelapierre/toy-cowsay-nf
  latest_release: null
  readme: '<h2><a id="user-content-toy-pipeline-for-simple-nextflow-tests" class="anchor"
    aria-hidden="true" href="#toy-pipeline-for-simple-nextflow-tests"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Toy pipeline for simple Nextflow tests</h2>

    <p>The purpose of this repo is to have a pipeline with features including:</p>

    <p>General:</p>

    <ul>

    <li>Simple</li>

    <li>Small (including required software)</li>

    <li>Quick to setup and run</li>

    </ul>

    <p>Pipeline:</p>

    <ul>

    <li>Requires a small package, that can be installed with Conda or Spack

    <ul>

    <li>Conda: <code>cowpy</code> (from <code>conda-forge</code>)</li>

    <li>Spack: <code>cowsay</code>

    </li>

    </ul>

    </li>

    <li>Reads/writes files</li>

    </ul>

    <p>Software options:</p>

    <ul>

    <li>Host</li>

    <li>Containers</li>

    <li>Conda</li>

    <li>Conda with Wave</li>

    <li>Spack</li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1676008940.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ANL/Theta/spack.yaml
  - ANL/Cooley/spack.yaml
  - ANL/JLSE/spack.yaml
  - ORNL/Summit/spack.yaml
  - ORNL/Crusher/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" href="#platform-configurations-for-mochi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Platform configurations for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    href="#contributing-to-this-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1677790084.0
mochi-hpc/margo-microservice-template:
  data_format: 2
  description: Template for a margo-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/margo-microservice-template
  latest_release: null
  readme: '<h1><a id="user-content-margo-microservice-template" class="anchor" aria-hidden="true"
    href="#margo-microservice-template"><span aria-hidden="true" class="octicon octicon-link"></span></a>Margo
    Microservice Template</h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Margo.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/01_margo.html" rel="nofollow">here</a>.</p>

    <p>To use this template:</p>

    <ul>

    <li>Click on the green "Use this template" button at the top.</li>

    <li>Give a name to your project.</li>

    <li>Once your project repository is created, go to Settings &gt; Actions &gt;
    General and give "Read and write permissions" under <em>Workflow permissions</em>.</li>

    <li>Finally, edit the initial-setup.json file and push the changes to your repo.</li>

    </ul>

    <p>Editing the initial-setup.json file with trigger a github action that will

    cleanup your repository and rename files, namespaces, functions, etc. according

    to the name of your service and the resources it manages.</p>

    <p>Enjoy working with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1649078785.0
mochi-hpc/mochi-poesie:
  data_format: 2
  description: POESIE is a Mochi microservice designed to run interpreters of various
    scripting languages (currently Lua and Python) and make them accessible remotely.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-poesie
  latest_release: v0.2
  readme: "<h1><a id=\"user-content-poesie-embedding-scripting-languages-for-mochi-services\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#poesie-embedding-scripting-languages-for-mochi-services\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>POESIE:\
    \ Embedding Scripting Languages for Mochi Services</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>POESIE\
    \ can easily be installed using Spack:</p>\n<p><code>spack install mochi-poesie</code></p>\n\
    <p>This will install POESIE (and any required dependencies) with both\nPython\
    \ and Lua backends. Disabling one or the other can be done by\nappending <code>~lua</code>\
    \ or <code>~python</code>, for example:</p>\n<p><code>spack install poesie~lua</code></p>\n\
    <h2><a id=\"user-content-architecture\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#architecture\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Architecture</h2>\n<p>Like most mochi services, POESIE relies on a\
    \ client/provider architecture.\nA provider, identified by its <em>address</em>\
    \ and <em>provider id</em>, manages one or more\ninterpreters (called <em>virtual\
    \ machines</em>, or <em>VMs</em>), referenced externally\nby either their name\
    \ or their VM id.</p>\n<h2><a id=\"user-content-starting-a-daemon-using-bedrock\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#starting-a-daemon-using-bedrock\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting\
    \ a daemon using Bedrock</h2>\n<p>By installing POESIE with the <code>+bedrock</code>\
    \ variant, one can deploy a daemon\nby providing a JSON configuration like the\
    \ following to Bedrock.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\
    \    <span class=\"pl-ent\">\"libraries\"</span>: [\n        <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>libpoesie-bedrock-module.so<span class=\"pl-pds\"\
    >\"</span></span>\n    ],\n    <span class=\"pl-ent\">\"providers\"</span>: [\n\
    \        {\n            <span class=\"pl-ent\">\"name\"</span>: <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>my_poesie_provider<span class=\"pl-pds\"\
    >\"</span></span>,\n            <span class=\"pl-ent\">\"provider_id\"</span>:\
    \ <span class=\"pl-c1\">0</span>,\n            <span class=\"pl-ent\">\"config\"\
    </span>: {\n                <span class=\"pl-ent\">\"vms\"</span>: {\n       \
    \             <span class=\"pl-ent\">\"my_vm\"</span>: {\n                   \
    \     <span class=\"pl-ent\">\"language\"</span>: <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>python<span class=\"pl-pds\">\"</span></span>\n            \
    \        }\n                }\n            }\n        }\n    ]\n}</pre></div>\n\
    <h2><a id=\"user-content-client-api\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #client-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client\
    \ API</h2>\n<p>The client API is available in <em>poesie-client.h</em>.\nThe codes\
    \ in the <em>test</em> folder illustrate how to use it.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975197.0
mochi-hpc/mochi-remi:
  data_format: 2
  description: Mochi's REsource Migration Interface
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-remi
  latest_release: v0.3.2
  readme: '<h1><a id="user-content-resource-migration-interface" class="anchor" aria-hidden="true"
    href="#resource-migration-interface"><span aria-hidden="true" class="octicon octicon-link"></span></a>REsource
    Migration Interface</h1>

    <p>REMI is a Mochi microservice designed to handle the migration of sets of files

    from a node to another. It uses RDMA and memory mapping to efficiently transfer

    potentially large groups of files at once.</p>

    <h3><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>Just like all Mochi services, REMI can be installed using Spack. Once you have

    clone the <a href="https://xgitlab.cels.anl.gov/sds/sds-repo" rel="nofollow">sds-repo</a>
    package repository

    and added it to your spack installation, you can install REMI using the following

    command:</p>

    <pre><code>spack install mochi-remi

    </code></pre>

    <p>REMI depends on <a href="https://xgitlab.cels.anl.gov/sds/thallium/" rel="nofollow">Thallium</a>,
    which

    Spack will install (if needed) along with Thallium''s own dependencies. It also

    depends on Bedrock, unless the <code>bedrock</code> variant is disable when installing

    with Spack (i.e. passing <code>~bedrock</code> to the above command).</p>

    <h3><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h3>

    <p>REMI works with <em>filesets</em>. A fileset consists of a root directory and

    a set of file paths relative to this root directory. A fileset is also characterized

    by the name of its <em>migration class</em>.</p>

    <p>REMI clients create filesets to group files corresponding to a particular resource

    (e.g. a database''s files). They can then request the migration of fileset to

    a target provider.</p>

    <p>Uppon receiving a request for migration, a provider will recreate the tree
    of

    directories required to receive the files of the fileset, create the files,

    mmap them into memory, and issue an RDMA pull operation from the client''s files

    (themselves mmap-ed into the client''s memory).</p>

    <p>Following successful migration, the provider will call a user-supplied callback

    corresponding to the particular fileset''s migration class.</p>

    <p>For an example of code, please see the <a href="examples">examples</a>

    folder in the source tree.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975455.0
mochi-hpc/mochi-thallium:
  data_format: 2
  description: Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and
    providing an object-oriented way to use these libraries.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-thallium
  latest_release: v0.11.0
  readme: '<h1><a id="user-content-thallium" class="anchor" aria-hidden="true" href="#thallium"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Thallium</h1>

    <p>Thallium is a C++ interface to <a href="https://github.com/mochi-hpc/mochi-margo/">Margo</a>.

    It offers a modern, object-oriented way of developing HPC data services. More

    information can be found on <a href="https://mochi.readthedocs.io/en/latest/"
    rel="nofollow">Mochi''s readthedocs</a>

    website.</p>

    '
  stargazers_count: 9
  subscribers_count: 4
  topics: []
  updated_at: 1675839350.0
mochi-hpc/thallium-microservice-template:
  data_format: 2
  description: Template for a thallium-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/thallium-microservice-template
  latest_release: null
  readme: '<h1><a id="user-content-thallium-microservice-template" class="anchor"
    aria-hidden="true" href="#thallium-microservice-template"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Thallium Microservice Template</h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Thallium.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/02_thallium.html" rel="nofollow">here</a>.</p>

    <p>To use this template:</p>

    <ul>

    <li>Click on the green "Use this template" button at the top.</li>

    <li>Give a name to your project.</li>

    <li>Once your project repository is created, go to Settings &gt; Actions &gt;
    General and give "Read and write permissions" under <em>Workflow permissions</em>.</li>

    <li>Finally, edit the initial-setup.json file and push the changes to your repo.</li>

    </ul>

    <p>Editing the initial-setup.json file with trigger a github action that will

    cleanup your repository and rename files, namespaces, functions, etc. according

    to the name of your service and the resources it manages.</p>

    <p>Enjoy working with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1649080284.0
mpbelhorn/olcf-spack:
  data_format: 2
  description: Spack fork used on OLCF resources
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  full_name: mpbelhorn/olcf-spack
  latest_release: null
  readme: "<h1><a id=\"user-content--spack\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n\
    <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions?query=workflow%3A%22macOS+builds+nightly%22\"\
    ><img src=\"https://github.com/spack/spack/workflows/macOS%20builds%20nightly/badge.svg?branch=develop\"\
    \ alt=\"macOS Builds (nightly)\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/4bbdc2b44561be6dfffe64e15730e1c5a2bed9c4efe6f9942638091a4ce3ede2/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p><a href=\"\
    https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <h2><a id=\"user-content-tutorial\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tutorial</h2>\n\
    <p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<h2><a id=\"user-content-community\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#community\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Community</h2>\n<p>Spack is an open source project.  Questions, discussion,\
    \ and\ncontributions are welcome. Contributions can be anything from new\npackages\
    \ to bugfixes, documentation, or even new core features.</p>\n<p>Resources:</p>\n\
    <ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<strong>Mailing\
    \ list</strong>: <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\"\
    >groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>: <a\
    \ href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Contributing\
    \ to Spack is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2><a id=\"user-content-releases\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Releases</h2>\n\
    <p>For multi-user site deployments or other use cases that need very stable\n\
    software installations, we recommend using Spack's\n<a href=\"https://github.com/spack/spack/releases\"\
    >stable releases</a>.</p>\n<p>Each Spack release series also has a corresponding\
    \ branch, e.g.\n<code>releases/v0.14</code> has <code>0.14.x</code> versions of\
    \ Spack, and <code>releases/v0.13</code> has\n<code>0.13.x</code> versions. We\
    \ backport important bug fixes to these branches but\nwe do not advance the package\
    \ versions or make other changes that would\nchange the way Spack concretizes\
    \ dependencies within a release branch.\nSo, you can base your Spack deployment\
    \ on a release branch and <code>git pull</code>\nto get fixes, without the package\
    \ churn that comes with <code>develop</code>.</p>\n<p>The latest release is always\
    \ available with the <code>releases/latest</code> tag.</p>\n<p>See the <a href=\"\
    https://spack.readthedocs.io/en/latest/developer_guide.html#releases\" rel=\"\
    nofollow\">docs on releases</a>\nfor more details.</p>\n<h2><a id=\"user-content-code-of-conduct\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#code-of-conduct\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Code of Conduct</h2>\n<p>Please\
    \ note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"><strong>Code of\
    \ Conduct</strong></a>. By participating in\nthe Spack community, you agree to\
    \ abide by its rules.</p>\n<h2><a id=\"user-content-authors\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#authors\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Authors</h2>\n<p>Many thanks go to Spack's <a href=\"\
    https://github.com/spack/spack/graphs/contributors\">contributors</a>.</p>\n<p>Spack\
    \ was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\">tgamblin@llnl.gov</a>.</p>\n\
    <h3><a id=\"user-content-citing-spack\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#citing-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing Spack</h3>\n<p>If you are referencing Spack in a publication,\
    \ please cite the following paper:</p>\n<ul>\n<li>Todd Gamblin, Matthew P. LeGendre,\
    \ Michael R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de Supinski, and\
    \ W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed\
    \ under the terms of both the MIT license and the\nApache License (Version 2.0).\
    \ Users may choose either license, at their\noption.</p>\n<p>All new contributions\
    \ must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"\
    https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n<a\
    \ href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1580743748.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - cray-sles15-zen3/crusher/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_env/index.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2><a id="user-content-purpose" class="anchor" aria-hidden="true" href="#purpose"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 4
  subscribers_count: 19
  topics: []
  updated_at: 1670008521.0
pdidev/test_env:
  data_format: 2
  description: Testing environment for PDI
  filenames:
  - spack/1b-spack/spack.yaml
  full_name: pdidev/test_env
  latest_release: null
  readme: '<h1><a id="user-content-docker-images" class="anchor" aria-hidden="true"
    href="#docker-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Docker
    images:</h1>

    <p>A set of related Docker images to build and test PDI.</p>

    <p>We provide images based on:</p>

    <ul>

    <li>Spack recipes,</li>

    <li>Binary packages.</li>

    </ul>

    <h2><a id="user-content-spack-based-images" class="anchor" aria-hidden="true"
    href="#spack-based-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack-based
    images</h2>

    <p>These images are based on a minimal Ubuntu 18.08, with spack and all dependencies
    installed through

    spack.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/spack/${deps_version}/${compiler}/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>deps_version</code>:

    <ul>

    <li>

    <code>oldest</code>: dependencies use the oldest versions supported by PDI,</li>

    <li>

    <code>latest</code>: dependencies use the latest versions available in spack at
    the time of generation,</li>

    </ul>

    </li>

    <li>

    <code>compiler</code>:

    <ul>

    <li>

    <code>gcc</code>:   using GCC compiler,</li>

    <li>

    <code>clang</code>: using clang for C/C++ and gfortran for Fortran,</li>

    </ul>

    </li>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image.</li>

    </ul>

    </li>

    </ul>

    <h2><a id="user-content-binary-package-based-images" class="anchor" aria-hidden="true"
    href="#binary-package-based-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binary
    package based images</h2>

    <p>These images are based on Ubuntu 18.08, with all dependencies installed through
    packages.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/ubuntu/bionic/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>mpich</code>: using mpich implementation of MPI,</li>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image,</li>

    <li>

    <code>pdi</code>: PDI is included in the image.</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1641653805.0
range3/chfs-containers:
  data_format: 2
  description: null
  filenames:
  - spack/envs/chfs/spack.yaml
  full_name: range3/chfs-containers
  latest_release: null
  readme: '<h1><a id="user-content-chfs-containers" class="anchor" aria-hidden="true"
    href="#chfs-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>chfs-containers</h1>

    <h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>example</h2>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    explicitly pull the latest chfs image </span>

    docker pull range3/chfs:master


    git clone https://github.com/range3/chfs-containers

    <span class="pl-c1">cd</span> chfs-containers


    <span class="pl-c"><span class="pl-c">#</span> start servers</span>

    docker-compose up -d


    <span class="pl-c"><span class="pl-c">#</span> start another container for client</span>

    docker run -it --rm --network chfs_net --privileged range3/chfs:master bash

    <span class="pl-c"><span class="pl-c">#</span> set CHFS_SERVER env</span>

    <span class="pl-k">export</span> CHFS_SERVER=<span class="pl-s"><span class="pl-pds">$(</span>chlist
    -c -s ofi+sockets://172.30.0.3:50000<span class="pl-pds">)</span></span>


    <span class="pl-c"><span class="pl-c">#</span> list chfs servers</span>

    chlist


    <span class="pl-c"><span class="pl-c">#</span> mount chfs via FUSE</span>

    mkdir /tmp/m

    chmkdir /tmp/m

    chfuse -o direct_io,modules=subdir,subdir=<span class="pl-s"><span class="pl-pds">"</span>/tmp/m<span
    class="pl-pds">"</span></span> /tmp/m


    <span class="pl-c"><span class="pl-c">#</span> &lt;ctrl-D&gt;</span>

    <span class="pl-c"><span class="pl-c">#</span> the client container is removed</span>


    <span class="pl-c"><span class="pl-c">#</span> stop and remove server containers</span>

    docker-compose down</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652094301.0
range3/kvs-evaluation:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/kvs-evaluation
  latest_release: null
  readme: "<h1><a id=\"user-content-kvs-evaluation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#kvs-evaluation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>kvs-evaluation</h1>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> external/YCSB-C\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> sudo\u3092\u4F7F\u3063\u3066libhiredis.so\u304C\
    /usr/local/lib\u306B\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB\u3055\u308C\u308B</span>\n\
    make\n<span class=\"pl-k\">export</span> LD_LIBRARY_PATH=/usr/local/lib\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> \u52D5\u4F5C\u78BA\u8A8D</span>\n\
    ./ycsbc -db basic -threads 1 -P workloads/workloada.spec</pre></div>\n<h1><a id=\"\
    user-content-ycsb-c\" class=\"anchor\" aria-hidden=\"true\" href=\"#ycsb-c\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>YCSB-C</h1>\n\
    <h2><a id=\"user-content-workload\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #workload\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>workload</h2>\n\
    <table>\n<thead>\n<tr>\n<th align=\"left\">workload</th>\n<th align=\"left\">description</th>\n\
    <th align=\"right\">read</th>\n<th align=\"right\">insert</th>\n<th align=\"right\"\
    >update</th>\n<th align=\"right\">scan</th>\n<th align=\"right\">R-M-W</th>\n\
    <th align=\"center\">distribution</th>\n<th align=\"center\">remarks</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td align=\"left\">A</td>\n<td align=\"left\">Update\
    \ heavy</td>\n<td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >B</td>\n<td align=\"left\">Read mostly</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">zipfian</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">C</td>\n<td align=\"left\">Read\
    \ only</td>\n<td align=\"right\">1</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\"></td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >D</td>\n<td align=\"left\">Read latest</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\">0.05</td>\n<td align=\"right\"></td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">latest</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">E</td>\n<td align=\"left\">Short\
    \ ranges</td>\n<td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"\
    right\"></td>\n<td align=\"right\">0.95</td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\">maxscanlength=100 random(uniform)</td>\n\
    </tr>\n<tr>\n<td align=\"left\">F</td>\n<td align=\"left\">Read-modify-write</td>\n\
    <td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.5</td>\n<td align=\"center\"\
    >zipfian</td>\n<td align=\"center\"></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-class-diagram-subset\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #class-diagram-subset\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>class diagram (subset)</h2>\n<div class=\"highlight highlight-source-mermaid\"\
    ><pre><span class=\"pl-k\">classDiagram</span>\n<span class=\"pl-k\">class</span>\
    \ <span class=\"pl-en\">DBFactory</span>\n<span class=\"pl-k\">class</span> <span\
    \ class=\"pl-en\">DB</span>\n<span class=\"pl-sg\">&lt;&lt;</span><span class=\"\
    pl-ent\">interface</span><span class=\"pl-sg\">&gt;&gt;</span> <span class=\"\
    pl-en\">DB</span>\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">HashtableDB</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">abstruct</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">HashtableDB</span>\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-en\">LockStlDB</span>\n<span class=\"\
    pl-k\">class</span> <span class=\"pl-en\">StringHashtable</span><span class=\"\
    pl-sg\">~</span><span class=\"pl-ent\">V</span><span class=\"pl-sg\">~</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">StringHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">KeyHashtable</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">KeyHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">FieldHashtable</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">FieldHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">StlHashTable</span><span\
    \ class=\"pl-sg\">~</span><span class=\"pl-ent\">V</span><span class=\"pl-sg\"\
    >~</span>\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">StlHashTableKey</span>\
    \ <span class=\"pl-sg\">{</span>\n  <span class=\"pl-k\">std::unorderd_map</span><span\
    \ class=\"pl-sg\">~</span><span class=\"pl-ent\">String,FieldHashtable*</span><span\
    \ class=\"pl-sg\">~</span>\n<span class=\"pl-sg\">}</span>\n<span class=\"pl-k\"\
    >class</span> <span class=\"pl-en\">StlHashTableField</span> <span class=\"pl-sg\"\
    >{</span>\n  <span class=\"pl-k\">std::unorderd_map</span><span class=\"pl-sg\"\
    >~</span><span class=\"pl-ent\">String,const char*</span><span class=\"pl-sg\"\
    >~</span>\n<span class=\"pl-sg\">}</span>\n<span class=\"pl-k\">class</span> <span\
    \ class=\"pl-en\">LockStlHashtable</span><span class=\"pl-sg\">~</span><span class=\"\
    pl-ent\">T</span><span class=\"pl-sg\">~</span>\n<span class=\"pl-k\">class</span>\
    \ <span class=\"pl-en\">LockStlHashtableKey</span> <span class=\"pl-sg\">{</span>\n\
    \  <span class=\"pl-k\">std::mutex</span>\n<span class=\"pl-sg\">}</span>\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-en\">LockStlHashtableField</span>\
    \ <span class=\"pl-sg\">{</span>\n  <span class=\"pl-k\">std::mutex</span>\n<span\
    \ class=\"pl-sg\">}</span>\n\n<span class=\"pl-en\">DBFactory</span> <span class=\"\
    pl-k\">..&gt;</span> <span class=\"pl-en\">LockStlDB</span> <span class=\"pl-k\"\
    >:</span> <span class=\"pl-s\">create</span>\n<span class=\"pl-en\">LockStlDB</span>\
    \ <span class=\"pl-k\">*--</span> <span class=\"pl-en\">LockStlHashtableKey</span>\n\
    <span class=\"pl-en\">LockStlHashtableKey</span> <span class=\"pl-k\">o--</span>\
    \ <span class=\"pl-en\">LockStlHashtableField</span>\n<span class=\"pl-en\">LockStlDB</span>\
    \ <span class=\"pl-k\">..&gt;</span> <span class=\"pl-en\">LockStlHashtableField</span>\
    \ <span class=\"pl-k\">:</span> <span class=\"pl-s\">create</span>\n\n<span class=\"\
    pl-en\">DB</span> <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">HashtableDB</span>\n\
    <span class=\"pl-en\">HashtableDB</span> <span class=\"pl-k\">&lt;|..</span> <span\
    \ class=\"pl-en\">LockStlDB</span>\n<span class=\"pl-en\">StringHashtable</span>\
    \ <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">StlHashTable</span>\n\
    <span class=\"pl-en\">StlHashTable</span> <span class=\"pl-k\">&lt;|--</span><span\
    \ class=\"pl-en\">LockStlHashtable</span>\n\n<span class=\"pl-en\">StringHashtable</span>\
    \ <span class=\"pl-k\">..</span> <span class=\"pl-en\">FieldHashtable</span> <span\
    \ class=\"pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n<span class=\"\
    pl-en\">StringHashtable</span> <span class=\"pl-k\">..</span> <span class=\"pl-en\"\
    >KeyHashtable</span> <span class=\"pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n\
    <span class=\"pl-en\">StlHashTable</span> <span class=\"pl-k\">..</span> <span\
    \ class=\"pl-en\">StlHashTableKey</span> <span class=\"pl-k\">:</span> <span class=\"\
    pl-s\">instantiation</span>\n<span class=\"pl-en\">StlHashTable</span> <span class=\"\
    pl-k\">..</span> <span class=\"pl-en\">StlHashTableField</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n<span class=\"pl-en\"\
    >LockStlHashtable</span> <span class=\"pl-k\">..</span> <span class=\"pl-en\"\
    >LockStlHashtableKey</span> <span class=\"pl-k\">:</span> <span class=\"pl-s\"\
    >instantiation</span>\n<span class=\"pl-en\">LockStlHashtable</span> <span class=\"\
    pl-k\">..</span> <span class=\"pl-en\">LockStlHashtableField</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n\n<span class=\"pl-en\"\
    >StlHashTableKey</span>  <span class=\"pl-k\">&lt;|--</span> <span class=\"pl-en\"\
    >LockStlHashtableKey</span>\n<span class=\"pl-en\">StlHashTableField</span>  <span\
    \ class=\"pl-k\">&lt;|--</span> <span class=\"pl-en\">LockStlHashtableField</span>\n\
    <span class=\"pl-en\">KeyHashtable</span> <span class=\"pl-k\">&lt;|..</span>\
    \ <span class=\"pl-en\">StlHashTableKey</span>\n<span class=\"pl-en\">FieldHashtable</span>\
    \ <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">StlHashTableField</span>\n\
    \n<span class=\"pl-en\">HashtableDB</span> <span class=\"pl-k\">..&gt;</span>\
    \ <span class=\"pl-en\">KeyHashtable</span> <span class=\"pl-k\">:</span> <span\
    \ class=\"pl-s\">use</span>\n<span class=\"pl-en\">HashtableDB</span> <span class=\"\
    pl-k\">..&gt;</span> <span class=\"pl-en\">FieldHashtable</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">use</span></pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667533964.0
range3/ucx_practice:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/ucx_practice
  latest_release: null
  readme: '<h1><a id="user-content-ucx_practice" class="anchor" aria-hidden="true"
    href="#ucx_practice"><span aria-hidden="true" class="octicon octicon-link"></span></a>ucx_practice</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666601300.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<h1><a id=\"user-content-libpressio\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#libpressio\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>LibPressio</h1>\n<p><em>the stable version of this code is found at\
    \ <a href=\"https://github.com/CODARcode/libpressio\">at the CODARCode organization</a>\
    \ it is updated about anually</em></p>\n<p>Pressio is latin for compression. \
    \ LibPressio is a C++ library with C compatible bindings to abstract between different\
    \ lossless and lossy compressors and their configurations.  It solves the problem\
    \ of having to having to write separate application level code for each lossy\
    \ compressor that is developed.  Instead, users write application level code using\
    \ LibPressio, and the library will make the correct underlying calls to the compressors.\
    \  It provides interfaces to represent data, compressors settings, and compressors.</p>\n\
    <p>Documentation for the <code>master</code> branch can be <a href=\"https://robertu94.github.io/libpressio/\"\
    \ rel=\"nofollow\">found here</a></p>\n<h1><a id=\"user-content-using-libpressio\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-libpressio\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using LibPressio</h1>\n<p>Example\
    \ using the CLI from <a href=\"https://github.com/robertu94/pressio-tools\"><code>pressio-tools</code></a>\n\
    We also have C, C++, Rust, Julia, and Python bindings.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pressio -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<h2><a id=\"user-content-getting-started\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#getting-started\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>After skimming\
    \ the example, LibPressio has 6 major headers that you will need to use:</p>\n\
    <table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>pressio.h</code></td>\n<td>Error reporting and aquiring handles\
    \ to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<h2><a id=\"user-content-supported-compressors-and-metrics\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#supported-compressors-and-metrics\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ Compressors and Metrics</h2>\n<p>Libpressio provides a number of builtin compressor\
    \ and metrics modules.\nAll of these are <strong>disabled by default</strong>.\n\
    They can be enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code>\
    \ variable to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information\
    \ on writing a compressor plugin see [Writing a Compressor Plugin](@ref writingacompressor)\n\
    For information on writing a metrics plugin see [Writing a Metrics Plugin](@ref\
    \ writingametric)</p>\n<h3><a id=\"user-content-compressor-plugins\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#compressor-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compressor Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the [compressor settings page](@ref compressors)\
    \ for information on how to configure them.</p>\n<h3><a id=\"user-content-metrics-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#metrics-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Metrics Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the [metrics results page](@ref metrics)\
    \ for information on what they produce</p>\n<h3><a id=\"user-content-io-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#io-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>IO Plugins</h3>\n<p>1st party\
    \ compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the [io settings page](@ref io) for information\
    \ on how to configure them</p>\n<h1><a id=\"user-content-installation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Installation</h1>\n<h2><a id=\"user-content-installing-libpressio-using-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-libpressio-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ LibPressio using Spack</h2>\n<p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\"\
    >spack</a>.  This example will install libpressio with only the SZ3 plugin.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<h2><a id=\"user-content-doing-a-development-build-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#doing-a-development-build-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Doing a\
    \ development build with spack</h2>\n<p>The easiest way to do a development build\
    \ of libpressio is to use Spack envionments.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> one time setup: create\
    \ an envionment</span>\nspack env create -d mydevenviroment\nspack env activate\
    \ mydevenvionment\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one time\
    \ setup: install libpressio-tools and checkout </span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> libpressio for development</span>\nspack add libpressio-tools\n\
    spack develop libpressio@git.master\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> compile and install (repeat as needed)</span>\nspack install </pre></div>\n\
    <h2><a id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#manual-installation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Manual Installation</h2>\n<p>Libpressio unconditionally\
    \ requires:</p>\n<ul>\n<li><code>cmake</code></li>\n<li><code>pkg-config</code></li>\n\
    <li><a href=\"https://github.com/robertu94/std_compat\"><code>std_compat</code></a></li>\n\
    <li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code> or later</li>\n<li>\n<code>clang-7.0.0</code>\
    \ or later using either <code>libc++</code> or <code>libstdc++</code>.  Beware\
    \ that system libraries may need to be recompiled with <code>libc++</code> if\
    \ using <code>libc++</code>\n</li>\n</ul>\n</li>\n</ul>\n<p>Dependency versions\
    \ and optional dependencies are documented <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<h2><a id=\"user-content-configuring-libpressio-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-libpressio-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ LibPressio Manually</h2>\n<p>LibPressio uses a fairly standard CMake buildsystem.\n\
    For more information on <a href=\"https://robertu94.github.io/learning/cmake\"\
    \ rel=\"nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration\
    \ options for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\n\
    For information on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<h1><a id=\"user-content-api-stability\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#api-stability\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>API Stability</h1>\n<p>Please refer to <a href=\"\
    docs/stability.md\">docs/stability.md</a>.</p>\n<h1><a id=\"user-content-how-to-contribute\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-contribute\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to Contribute</h1>\n<p>Please\
    \ refer to <a href=\"CONTRIBUTORS.md\">CONTRIBUTORS.md</a> for a list of contributors,\
    \ sponsors, and contribution guidelines.</p>\n<h1><a id=\"user-content-bug-reports\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#bug-reports\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Bug Reports</h1>\n<p>Please files\
    \ bugs to the Github Issues page on the CODARCode libpressio repository.</p>\n\
    <p>Please read this post on <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\"\
    \ rel=\"nofollow\">how to file a good bug report</a>.\_ After reading this post,\
    \ please provide the following information specific to libpressio:</p>\n<ul>\n\
    <li>Your OS version and distribution information, usually this can be found in\
    \ <code>/etc/os-release</code>\n</li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n\
    </li>\n<li>the version of each of libpressio's dependencies listed in the README\
    \ that you have installed. Where possible, please provide the commit hashes.</li>\n\
    </ul>\n<h1><a id=\"user-content-citing-libpressio\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#citing-libpressio\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Citing LibPressio</h1>\n<p>If you find LibPressio\
    \ useful, please cite this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n\
    \  title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n\
    \  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di,\
    \ Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on\
    \ Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n\
    \  year={2021},\n  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 16
  subscribers_count: 5
  topics: []
  updated_at: 1673367032.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<h1><a id="user-content-roibin-sz-experiments" class="anchor" aria-hidden="true"
    href="#roibin-sz-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>ROIBIN-SZ
    Experiments</h1>

    <h2><a id="user-content-system-information" class="anchor" aria-hidden="true"
    href="#system-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>System
    Information</h2>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <h2><a id="user-content-where-is-the-implementation-of-roibin-sz3" class="anchor"
    aria-hidden="true" href="#where-is-the-implementation-of-roibin-sz3"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Where is the implementation of ROIBIN-SZ3?</h2>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <h3><a id="user-content-obtaining-data" class="anchor" aria-hidden="true" href="#obtaining-data"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining Data</h3>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <h3><a id="user-content-quality-assessment" class="anchor" aria-hidden="true"
    href="#quality-assessment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quality
    Assessment</h3>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <h3><a id="user-content-container-install-for-ease-of-setup" class="anchor" aria-hidden="true"
    href="#container-install-for-ease-of-setup"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Container Install (for ease of setup)</h3>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <h4><a id="user-content-singularity" class="anchor" aria-hidden="true" href="#singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h4>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <h4><a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h4>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <h3><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    href="#building-the-container"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <h3><a id="user-content-manual-install-for-scale" class="anchor" aria-hidden="true"
    href="#manual-install-for-scale"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    Install (for scale)</h3>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <h2><a id="user-content-running-the-experiments" class="anchor" aria-hidden="true"
    href="#running-the-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Experiments</h2>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <h3><a id="user-content-example-output" class="anchor" aria-hidden="true" href="#example-output"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example Output</h3>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <h2><a id="user-content-results-for-figures" class="anchor" aria-hidden="true"
    href="#results-for-figures"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results
    for Figures</h2>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1648861627.0
robertu94/sz-zfp-zchecker:
  data_format: 2
  description: container for the ISC/SC compression tutorial
  filenames:
  - spack.yaml
  full_name: robertu94/sz-zfp-zchecker
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1652997619.0
soma-monitoring-toolbox/soma-collector:
  data_format: 2
  description: soma-collector is the component exposing the core SOMA measurement
    API
  filenames:
  - examples/lulesh-inst/spack.yaml
  - spack.yaml
  full_name: soma-monitoring-toolbox/soma-collector
  latest_release: null
  readme: '<h2><a id="user-content-soma-collector" class="anchor" aria-hidden="true"
    href="#soma-collector"><span aria-hidden="true" class="octicon octicon-link"></span></a>soma-collector</h2>

    <p>soma-collector is the component exposing the core SOMA measurement API</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1677986895.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-21.11/ci/spack.yaml
  - NERSC/perlmutter/e4s-21.11/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 46
  subscribers_count: 24
  topics: []
  updated_at: 1675363464.0
sundials-codes/sundials-manyvector-demo:
  data_format: 2
  description: Demonstration application for Multirate+ManyVector capabilities
  filenames:
  - docker/spack-develop.yaml
  - docker/spack-latest.yaml
  - spack/spack-summit.yaml
  full_name: sundials-codes/sundials-manyvector-demo
  latest_release: null
  readme: "<h1><a id=\"user-content-sundials-manyvectormultirate-demonstration-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#sundials-manyvectormultirate-demonstration-code\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SUNDIALS\
    \ ManyVector+Multirate Demonstration Code</h1>\n<p>[Note: this project is in active\
    \ development.]</p>\n<p>This is a <a href=\"https://github.com/LLNL/sundials\"\
    >SUNDIALS</a>-based demonstration\napplication to assess and demonstrate the large-scale\
    \ parallel performance of\nnew capabilities that have been added to SUNDIALS in\
    \ recent years. Namely:</p>\n<ol>\n<li>\n<p>The new SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html#the-nvector-mpimanyvector-module\"\
    \ rel=\"nofollow\">MPIManyVector</a>\nimplementation, that enables flexibility\
    \ in how a solution data is\npartitioned across computational resources e.g.,\
    \ CPUs and GPUs.</p>\n</li>\n<li>\n<p>The new <a href=\"https://sundials.readthedocs.io/en/latest/arkode/index.html\"\
    \ rel=\"nofollow\">ARKODE</a>\nmultirate integration module, MRIStep, allowing\
    \ high-order accurate\ncalculations that subcycle \"fast\" processes within \"\
    slow\" ones.</p>\n</li>\n<li>\n<p>The new flexible SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/sunlinsol/index.html\"\
    \ rel=\"nofollow\">SUNLinearSolver</a>\ninterfaces, to enable streamlined use\
    \ of problem specific and scalable\nlinear solver libraries e.g., SuiteSparse\
    \ and MAGMA.</p>\n</li>\n</ol>\n<h2><a id=\"user-content-model-equations\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#model-equations\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Model Equations</h2>\n<p>This code\
    \ simulates a 3D nonlinear inviscid compressible Euler equation with\nadvection\
    \ and reaction of chemical species,</p>\n<p>$$w_t = -\\nabla\\cdot F(w) + G(X,t,w),$$</p>\n\
    <p>for independent variables $(X,t) = (x,y,z,t) \\in \\Omega \\times [t_0, t_f]$\n\
    where the spatial domain is a three-dimensional cube,\n$\\Omega = [x_l, x_r] \\\
    times [y_l, y_r] \\times [z_l, z_r]$.</p>\n<p>The differential equation is completed\
    \ using initial condition\n$w(X,t_0) = w_0(X)$ and face-specific boundary conditions\
    \ may be periodic (0),\nhomogeneous Neumann (1), homogeneous Dirichlet (2), or\
    \ reflecting (3) under the\nrestriction that if any boundary is set to \"periodic\"\
    \ then the opposite face\nmust also indicate a periodic condition.</p>\n<p>The\
    \ system state vector $w$ is</p>\n<p>$$w = \\begin{bmatrix} \\rho &amp; \\rho\
    \ v_x &amp; \\rho v_y &amp; \\rho v_z &amp; e_t &amp; \\mathbf{c} \\end{bmatrix}^T\
    \ = \\begin{bmatrix} \\rho &amp; m_x &amp; m_y &amp; m_z &amp; e_t &amp; \\mathbf{c}\
    \ \\end{bmatrix}^T$$</p>\n<p>corresponding to the density, momentum in the x,\
    \ y, and z directions, total\nenergy per unit volume, and any number of chemical\
    \ densities\n$\\mathbf{c}\\in\\mathbb{R}^{nchem}$ that are advected along with\
    \ the fluid. The\nfluxes are given by</p>\n<p>$$F_x(w) = \\begin{bmatrix} \\rho\
    \ v_x &amp; \\rho v_x^2 + p &amp; \\rho v_x v_y &amp; \\rho v_x v_z &amp; v_x\
    \ (e_t+p) &amp; \\mathbf{c} v_x \\end{bmatrix}^T,$$</p>\n<p>$$F_y(w) = \\begin{bmatrix}\
    \ \\rho v_y &amp; \\rho v_x v_y &amp; \\rho v_y^2 + p &amp; \\rho v_y v_z &amp;\
    \ v_y (e_t+p) &amp; \\mathbf{c} v_y \\end{bmatrix}^T,$$</p>\n<p>$$F_z(w) = \\\
    begin{bmatrix} \\rho v_z &amp; \\rho v_x v_z &amp; \\rho v_y v_z &amp; \\rho v_z^2\
    \ + p &amp; v_z (e_t+p) &amp; \\mathbf{c} v_z \\end{bmatrix}^T.$$</p>\n<p>The\
    \ external force $G(X,t,w)$ is test-problem-dependent, and the ideal gas\nequation\
    \ of state gives $p = \\frac{R}{c_v}(e_t - \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2))$\n\
    and $e_t = \\frac{pc_v}{R} + \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$\nor equivalently,\
    \ $p = (\\gamma-1) (e_t - \\frac{\\rho}{2} (v_x^2 + v_y^2 + v_z^2))$\nand $e_t\
    \ = \\frac{p}{\\gamma - 1}\\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$.</p>\n<p>We\
    \ have the physical parameters:</p>\n<ul>\n<li>\n<p>$R$ is the specific ideal\
    \ gas constant (287.14 J/kg/K),</p>\n</li>\n<li>\n<p>$c_v$ is the specific heat\
    \ capacity at constant volume (717.5 J/kg/K),</p>\n</li>\n<li>\n<p>$\\gamma =\
    \ c_p/c_v = 1 + R/c_v$ is the ratio of specific heats (1.4),</p>\n</li>\n</ul>\n\
    <p>corresponding to air (predominantly an ideal diatomic gas). The speed\nof sound\
    \ in the gas is then given by $c = \\sqrt{\\dfrac{\\gamma p}{\\rho}}$.</p>\n<p>The\
    \ fluid variables above are non-dimensionalized; in standard SI units\nthese would\
    \ be:</p>\n<ul>\n<li>\n<p>$[\\rho] = kg / m^3$,</p>\n</li>\n<li>\n<p>$[v_x] =\
    \ [v_y] = [v_z] = m/s$, which implies $[m_x] = [m_y] = [m_z] = kg / m^2 / s$</p>\n\
    </li>\n<li>\n<p>$[e_t] = kg / m / s^2$, and</p>\n</li>\n<li>\n<p>$[\\mathbf{c}_i]\
    \ = kg / m^3$</p>\n</li>\n</ul>\n<p>Note: the fluid portion of the description\
    \ above follows the presentation\n<a href=\"https://www.theoretical-physics.net/dev/fluid-dynamics/euler.html\"\
    \ rel=\"nofollow\">here</a>\nin sections 7.3.1 - 7.3.3.</p>\n<h2><a id=\"user-content-discretization\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#discretization\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Discretization</h2>\n<p>We discretize\
    \ this problem using the method of lines, where we first semi-discretize\nin space\
    \ using a regular finite volume grid with dimensions <code>nx</code> x <code>ny</code>\
    \ x <code>nz</code>, with\nfluxes at cell faces calculated using a 5th-order FD-WENO\
    \ reconstruction.  MPI\nparallelization is achieved using a standard 3D domain\
    \ decomposition, using <code>nprocs</code>\nMPI ranks, with layout <code>npx</code>\
    \ x <code>npy</code> x <code>npz</code> defined automatically via the\n<code>MPI_Dims_create</code>\
    \ utility routine.  The minimum size for any dimension is 3, so\nto run a two-dimensional\
    \ test in the yz-plane, one could specify <code>nx = 3</code> and\n<code>ny =\
    \ nz = 200</code>.  When run in parallel, only \"active\" spatial dimensions (those\n\
    with extent greater than 3) will be parallelized.</p>\n<p>The fluid fields $\\\
    rho$, $m_x$, $m_y$, $m_z$, and $e_t$ are stored in separate serial\n<code>N_Vector</code>\
    \ objects on each MPI rank. The chemical species at all spatial locations over\n\
    each MPI rank are collocated into a single serial or RAJA <code>N_Vector</code>\
    \ object when\nrunning on the CPU or GPU respectively. The five fluid vectors\
    \ and the chemical\nspecies vector are combined together to form the full \"solution\"\
    \ vector $w$ using\nthe <code>MPIManyVector</code> <code>N_Vector</code> module.</p>\n\
    <p>After spatial semi-discretization, we are faced with a large IVP system,</p>\n\
    <p>$$w'(t) = f_1(w) + f_2(w), \\quad w(t_0)=w_0,$$</p>\n<p>where $f_1(w)$ and\
    \ $f_2(w)$ contain the spatially discretized forms of\n$-\\nabla\\cdot F(w)$ and\
    \ $G(X,t,w)$, respectively.</p>\n<p>For non-reactive flows, the resulting initial-value\
    \ problem is evolved in time\nusing an adaptive step explicit Runge-Kutta method\
    \ from the ARKStep module in\nARKODE. For problems involving (typically stiff)\
    \ chemical reactions, the problem\nmay be solved using one of two approaches.</p>\n\
    <ol>\n<li>\n<p>It may be treated as a multirate initial-value problem, that is\
    \ solved using\nthe MRIStep module in ARKODE, wherein the gas dynamics equations\
    \ are evolved\nexplicitly at the slow time scale, while the chemical kinetics\
    \ are evolved\nat a faster time scale using a temporally-adaptive, diagonally-implicit\n\
    Runge-Kutta method from the ARKStep module.</p>\n</li>\n<li>\n<p>It may be treated\
    \ using mixed implicit-explicit (IMEX) methods at a single\ntime scale.  Here,\
    \ the gas dynamics equations are treated explicitly, while\nthe chemical kinetics\
    \ are treated implicitly, using an additive Runge-Kutta\nmethod from the ARKStep\
    \ module.</p>\n</li>\n</ol>\n<p>For (1) we use SUNDIALS' modified Newton solver\
    \ to handle the global nonlinear\nalgebraic systems arising at each implicit stage\
    \ of each time step.  Since only\n$f_2$ is treated implicitly and the reactions\
    \ are purely local in space, the\nNewton linear systems are block-diagonal. As\
    \ such, we provide a custom\n<code>SUNLinearSolver</code> implementation that\
    \ solves each MPI rank-local linear system\nindependently. The portion of the\
    \ Jacobian matrix on each rank is itself\nblock-diagonal. We further leverage\
    \ this structure by solving each rank-local\nlinear system using either the sparse\
    \ KLU (CPU-only) or batched dense MAGMA\n(GPU-enabled) SUNDIALS <code>SUNLinearSolver</code>\
    \ implementations.</p>\n<p>The multirate approach (2) can leverage the structure\
    \ of $f_2$ at a higher\nlevel. Since the MRI method applied to this problem evolves\
    \ \"fast\" sub-problems\nof the form</p>\n<p>$$v'(t) = f_2(t,v) + r_i(t), \\quad\
    \ i=2,\\ldots,s,$$</p>\n<p>and all MPI communication necessary to construct the\
    \ forcing functions, $r_i(t)$,\nhas already been performed, each sub-problem consists\
    \ of <code>nx</code> x <code>ny</code> x <code>nz</code>\nspatially-decoupled\
    \ fast IVPs. We construct a custom fast integrator that groups\nall the independent\
    \ fast IVPs on an MPI rank together as a single system evolved\nusing a rank-local\
    \ ARKStep instance.  The code for this custom integrator itself\nis minimal, primarily\
    \ consisting of steps to access the local subvectors in $w$\non a given MPI rank\
    \ and wrapping them in MPI-unaware ManyVectors provided to the\nlocal ARKStep\
    \ instance. The collection of independent local IVPs also leads to a\nblock diagonal\
    \ Jacobian, and we again utilize the <code>SUNLinearSolver</code> modules listed\n\
    above for linear systems that arise within the modified Newton iteration.</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The following steps describe how to build the\
    \ demonstration code in a Linux or\nOS X environment.</p>\n<h3><a id=\"user-content-gettting-the-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#gettting-the-code\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Gettting the Code</h3>\n<p>To\
    \ obtain the code, clone this repository with Git:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  git clone https://github.com/sundials-codes/sundials-manyvector-demo.git</pre></div>\n\
    <h3><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Requirements</h3>\n<p>To compile the code you will need:</p>\n<ul>\n\
    <li>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\">CMake</a> 3.20 or newer</p>\n\
    </li>\n<li>\n<p>modern C and C++ compilers</p>\n</li>\n<li>\n<p>the NVIDIA <a\
    \ href=\"https://developer.nvidia.com/cuda-toolkit\" rel=\"nofollow\">CUDA Toolkit</a>\
    \ (when\nusing the CUDA backend)</p>\n</li>\n<li>\n<p>an MPI library e.g., <a\
    \ href=\"https://www.open-mpi.org/\" rel=\"nofollow\">OpenMPI</a>,\n<a href=\"\
    https://www.mpich.org/\" rel=\"nofollow\">MPICH</a>, etc.</p>\n</li>\n<li>\n<p>the\
    \ <a href=\"https://www.hdfgroup.org/\" rel=\"nofollow\">HDF5</a> high-performance\
    \ data management and\nstorage suite</p>\n</li>\n<li>\n<p>the <a href=\"https://github.com/LLNL/RAJA\"\
    >RAJA</a> performance portability library</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://computing.llnl.gov/projects/sundials\" rel=\"nofollow\">SUNDIALS</a> library\
    \ of time\nintegrators and nonlinear solvers</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://people.engr.tamu.edu/davis/suitesparse.html\" rel=\"nofollow\">SuiteSparse</a>\
    \ library\nof sparse direct linear solvers (when using a CPU backend)</p>\n</li>\n\
    <li>\n<p>the <a href=\"https://icl.utk.edu/magma/\" rel=\"nofollow\">MAGMA</a>\
    \ dense linear solver library (when\nusing a GPU backend)</p>\n</li>\n</ul>\n\
    <h4><a id=\"user-content-installing-dependencies-with-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#installing-dependencies-with-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing Dependencies with\
    \ Spack</h4>\n<p>Many of the above dependencies can be installed using the\n<a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> package manager. For information\
    \ on using Spack see\nthe getting started <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#getting-started\"\
    \ rel=\"nofollow\">guide</a>.\nThe instructions below were formulated from Spack\
    \ v0.19.0, although newer versions should also work.</p>\n<p>Once Spack is setup,\
    \ we recommend creating a Spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html#\"\
    \ rel=\"nofollow\">environment</a>\nwith the required dependencies e.g., on a\
    \ system with Pascal GPUs and CUDA\n11.4.2 installed:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack env create --with-view <span class=\"pl-k\"\
    >~</span>/views/sundials-demo sundials-demo\nspack env activate sundials-demo\n\
    spack add sundials@6.2.0 +openmp +mpi +logging-mpi +klu +magma +raja +cuda cuda_arch=60\
    \ ^cuda@11.4.2 ^magma@2.6.1 +cuda cuda_arch=60 ^raja@0.13.0 +cuda cuda_arch=60\
    \ ^suite-sparse@5.8.1\nspack add hdf5@1.10.7 +hl +mpi\nspack install</pre></div>\n\
    <p>To assist in building the dependencies on select systems the <a href=\"./spack\"\
    >spack</a>\ndirectory contains environment files leveraging software already available\
    \ on\nthe system. For example, on the OLCF Summit system:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>module load gcc/10.2.0 cuda/11.4.2 cmake/3.21.3\n\
    <span class=\"pl-c1\">cd</span> spack\nspack env create sundials-demo spack-summit.yaml\n\
    spack env activate sundials-demo\nspack install</pre></div>\n<h4><a id=\"user-content-using-docker-containers\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-docker-containers\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Docker\
    \ Containers</h4>\n<p>It also possible to use the Docker containers from the <a\
    \ href=\"https://github.com/orgs/sundials-codes/packages?repo_name=sundials-manyvector-demo\"\
    >GitHub Container Registry</a>\nwith the necessary dependencies preinstalled for\
    \ CPU-only testing. Two images\nare provided:</p>\n<ul>\n<li>\n<p>sundials-demo-spack-latest\
    \ -- based on the latest Spack release (currently\nv0.19.0)</p>\n</li>\n<li>\n\
    <p>sundials-demo-spack-develop -- based on the Spack develop branch and updated\n\
    monthly</p>\n</li>\n</ul>\n<p>Pull the image(s) using <a href=\"https://www.docker.com/\"\
    \ rel=\"nofollow\">Docker</a> (or <a href=\"https://podman.io\" rel=\"nofollow\"\
    >Podman</a>).\nFor example, the <code>run</code> command below will pull the image\
    \ and start the container\nand the <code>exec</code> command will start a bash\
    \ shell inside the container.</p>\n<pre><code>docker run -t -d --name sundialsci-demo-spack-latest\
    \ ghcr.io/sundials-codes/sundials-demo-spack-latest:spack-latest\ndocker exec\
    \ -it sundials-demo-spack-lateset bash\n</code></pre>\n<p>Then clone this repository\
    \ with Git and configure/build the code as described\nbelow. The Spack installed\
    \ dependencies are available from the <code>/opt/view</code>\ndirectory.</p>\n\
    <h3><a id=\"user-content-configuration-options\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#configuration-options\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Configuration Options</h3>\n<p>Once the necessary\
    \ dependencies are installed, the following CMake variables can\nbe used to configure\
    \ the demonstration code build:</p>\n<ul>\n<li>\n<p><code>CMAKE_INSTALL_PREFIX</code>\
    \ - the path where executables and input files should be\ninstalled e.g., <code>my/install/path</code>.\
    \ The executables will be installed in the\n<code>bin</code> directory and input\
    \ files in the <code>tests</code> directory under the given path.</p>\n</li>\n\
    <li>\n<p><code>CMAKE_C_COMPILER</code> - the C compiler to use e.g., <code>mpicc</code>.\
    \ If not set, CMake\nwill attempt to automatically detect the C compiler.</p>\n\
    </li>\n<li>\n<p><code>CMAKE_C_FLAGS</code> - the C compiler flags to use e.g.,\
    \ <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_C_STANDARD</code> - the\
    \ C standard to use, defaults to <code>99</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_COMPILER</code>\
    \ - the C++ compiler to use e.g., <code>mpicxx</code>. If not set,\nCMake will\
    \ attempt to automatically detect the C++ compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_FLAGS</code>\
    \ - the C++ flags to use e.g., <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_STANDARD</code>\
    \ - the C++ standard to use, defaults to <code>11</code>.</p>\n</li>\n<li>\n<p><code>RAJA_ROOT</code>\
    \ - the root directory of the RAJA installation, defaults to the\nvalue of the\
    \ <code>RAJA_ROOT</code> environment variable. If not set, CMake will attempt\n\
    to automatically locate a RAJA install on the system.</p>\n</li>\n<li>\n<p><code>RAJA_BACKEND</code>\
    \ - the RAJA backend to use with the demonstration code, defaults\nto <code>SERIAL</code>.\
    \ Supported options are <code>SERIAL</code>, <code>OPENMP</code> and <code>CUDA</code>.\
    \  Note that this\nonly applies to on-node parallelism that is used when evaluating\
    \ chemistry-based\ncomponents associated with $f_2(w)$.</p>\n</li>\n<li>\n<p><code>SUNDIALS_ROOT</code>\
    \ - the root directory of the SUNDIALS installation, defaults to\nthe value of\
    \ the <code>SUNDIALS_ROOT</code> environment variable. If not set, CMake will\n\
    attempt to automatically locate a SUNDIALS install on the system.</p>\n</li>\n\
    <li>\n<p><code>ENABLE_HDF5</code> - build with HDF5 I/O support, defaults to <code>OFF</code>.</p>\n\
    </li>\n<li>\n<p><code>HDF5_ROOT</code> - the root directory of the HDF5 installation,\
    \ defaults to the\nvalue of the <code>HDF5_ROOT</code> environment variable. If\
    \ not set, CMake will attempt\nto automatically locate a HDF5 install on the system.</p>\n\
    </li>\n</ul>\n<p>When RAJA is installed with CUDA support enabled, the following\
    \ additional\nvariables may also be set:</p>\n<ul>\n<li>\n<p><code>CMAKE_CUDA_COMPILER</code>\
    \ - the CUDA compiler to use e.g., <code>nvcc</code>. If not set,\nCMake will\
    \ attempt to automatically detect the CUDA compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_FLAGS</code>\
    \ - the CUDA compiler flags to use.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_ARCHITECTURES</code>\
    \ - the CUDA architecture to target e.g., <code>70</code>.</p>\n</li>\n</ul>\n\
    <h3><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h3>\n\
    <p>In-source builds are not permitted, as such the code should be configured and\n\
    built from a separate build directory e.g.,</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  <span class=\"pl-c1\">cd</span> sundials-manyvector-demo\n  mkdir build\n\
    \  <span class=\"pl-c1\">cd</span> build\n  cmake ../. \\\n    -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>[install-path]<span class=\"\
    pl-pds\">\"</span></span> \\\n    -DRAJA_BACKEND=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>SERIAL<span class=\"pl-pds\">\"</span></span> \\\n    -DENABLE_HDF5=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DHDF5_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span> \\\n    -DRAJA_ROOT=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>[spack-view-path]<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DSUNDIALS_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span>\n  make\n  make install</pre></div>\n<p>where\
    \ <code>[install-path]</code> is the path to where the binary and test input files\n\
    should be installed and <code>[spack-view-path]</code> is the path to the Spack\
    \ environment\nview, <code>~/views/sundials-demo</code> when following the Spack\
    \ instructions above or\n<code>/opt/view</code> when using the Docker containers.</p>\n\
    <h2><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n\
    <p>Several test cases are included with the code and the necessary input files\
    \ for\neach case are contained in the subdirectories within the <a href=\"./tests\"\
    >tests</a>\ndirectory. Each input file is internally documented to discuss all\
    \ possible\ninput parameters (in case some have been added since this <code>README</code>\
    \ was last\nupdated).</p>\n<p>The input files contain parameters to set up the\
    \ physical problem:</p>\n<ul>\n<li>\n<p>spatial domain, $\\Omega$ -- <code>xl</code>,\
    \ <code>xr</code>, <code>yl</code>, <code>yr</code>, <code>zl</code>, <code>zr</code></p>\n\
    </li>\n<li>\n<p>time interval, $[t_0, t_f]$ -- <code>t0</code>, <code>tf</code></p>\n\
    </li>\n<li>\n<p>the ratio of specific heats, $\\gamma$ -- <code>gamma</code></p>\n\
    </li>\n<li>\n<p>spatial discretization dimensions -- <code>nx</code>, <code>ny</code>,\
    \ <code>nz</code></p>\n</li>\n<li>\n<p>boundary condition types -- <code>xlbc</code>,\
    \ <code>xrbc</code>, <code>ylbc</code>, <code>yrbc</code>, <code>zlbc</code>,\
    \ <code>zrbc</code></p>\n</li>\n</ul>\n<p>Parameters to control the execution\
    \ of the code:</p>\n<ul>\n<li>\n<p>desired CFL fraction -- <code>cfl</code> (if\
    \ set to zero, then the time step is chosen purely using temporal adaptivity).</p>\n\
    </li>\n<li>\n<p>number of desired solution outputs -- <code>nout</code></p>\n\
    </li>\n<li>\n<p>a flag to enable optional output of RMS averages for each field\
    \ at the frequency specified via <code>nout</code> -- <code>showstats</code></p>\n\
    </li>\n</ul>\n<p>Numerous parameters are also provided to control how time integration\
    \ is\nperformed (these are passed directly to ARKODE). For further information\
    \ on the\nARKODE solver parameters and the meaning of individual values, see the\n\
    <a href=\"https://sundials.readthedocs.io/en/latest/index.html\" rel=\"nofollow\"\
    >ARKODE documentation</a>.</p>\n<p>To specify an input file to the executable,\
    \ the input filename should be\nprovided using the <code>-f</code> flag e.g.,</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> -f <span class=\"pl-k\">&lt;</span>input_file<span\
    \ class=\"pl-k\">&gt;</span></pre></div>\n<p>Additionally, any input parameters\
    \ may also be specified on the\ncommand line e.g.,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> --nx=100 --ny=100 --nz=400</pre></div>\n<p>For example,\
    \ continuing with the Summit case from above, the primordial blast\ntest can be\
    \ run on one Summit node using four cores and four GPUs with the\nfollowing commands:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">${MEMBERWORK}</span>/[projid]/sundials-demo/tests/primordial_blast\n\
    \  bsub -q debug -nnodes 1 -W 0:10 -P [projid] -Is <span class=\"pl-smi\">$SHELL</span>\n\
    \  jsrun -n4 -a1 -c1 -g1 ../../bin/primordial_blast_mr.exe -f input_primordial_blast_mr_gpu.txt</pre></div>\n\
    <p>The <code>bsub</code> command above will submit a request for an interactive\
    \ job to the\ndebug queue allocating one node for 10 minutes with the compute\
    \ time charged to\n<code>[projid]</code>. Once the interactive session starts\
    \ the test case is launched using\nthe <code>jsrun</code> command. Solutions are\
    \ output to disk using parallel HDF5, solution\nstatistics are optionally output\
    \ to the screen at specified frequencies, and run\nstatistics are printed at the\
    \ end of the simulation.</p>\n<p>The parallel HDF5 solution snapshots are written\
    \ at the frequency specified by\n<code>nout</code>.  Accompanying these <code>output-#######.hdf5</code>\
    \ files is an automatically\ngenerated input file, <code>restart_parameters.txt</code>\
    \ that stores a complete set of\ninput parameters to restart the simulation from\
    \ the most recently generated\noutput file. This is a \"warm\" restart, in that\
    \ it will pick up the calculation\nwhere the previous one left off, using the\
    \ same initial time step size as\nARKStep would use. This restart may differ slightly\
    \ from an uninterrupted run\nsince other internal ARKStep time adaptivity parameters\
    \ cannot be reused.  We\nnote that the restart must use the same spatial grid\
    \ size and number of chemical\ntracers as the original run, but it may use a different\
    \ number of MPI tasks if\ndesired.</p>\n<h2><a id=\"user-content-adding-new-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-tests\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Adding New Tests</h2>\n<p>Individual\
    \ test problems are uniquely specified through an input file and\nauxiliary source\
    \ code file(s) that should be linked with the main routine at\ncompile time. By\
    \ default, all codes are built with no chemical species; however,\nthis may be\
    \ controlled at compilation time using the <code>NVAR</code> preprocessor\ndirective,\
    \ corresponding to the number of unknowns at any spatial location.\nHence, the\
    \ (default) minimum value for <code>NVAR</code> is 5, so for a calculation with\
    \ 4\nchemical species the code should be compiled with the preprocessor directive\n\
    <code>NVAR=9</code>. See <a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ for examples of how to\nspecify <code>NVAR</code> when adding a new test/executable.</p>\n\
    <p>The auxiliary source code files for creating a new test must contain three\n\
    functions. Each of these must return an integer flag indicating success (0) or\n\
    failure (nonzero). The initial condition function $w_0(X)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">initial_conditions</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector w, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>and the forcing function $G(X,t,w)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">external_forces</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector G, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>Additionally, a function must be supplied to compute/output\
    \ any\ndesired solution diagnostic information with the signature</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span> <span\
    \ class=\"pl-en\">output_diagnostics</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, <span class=\"pl-k\">const</span> N_Vector w, <span class=\"\
    pl-k\">const</span> UserData&amp; udata);</pre></div>\n<p>If no diagnostics information\
    \ is desired, then this routine may just return 0.</p>\n<p>Here, the <code>initial_conditions</code>\
    \ routine will be called once when the simulation\nbegins, <code>external_forces</code>\
    \ will be called on every evaluation of the ODE\nright-hand side function for\
    \ the Euler equations (it is assumed that this does\nnot require the results from\
    \ (<code>UserData::ExchangeStart</code>\n/ <code>UserData::ExchangeEnd</code>),\
    \ and <code>output_diagnostics</code> will be called at the same\nfrequency as\
    \ the solution is output to disk.</p>\n<p>To add a new executable using these\
    \ auxiliary source code file(s), update\n<a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ to include a new call to\n<code>sundemo_add_executable</code> in a similar manner\
    \ as the existing test problems e.g.,\n<code>hurricane_yz.exe</code>.</p>\n<h2><a\
    \ id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" href=\"#authors\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n\
    <p><a href=\"https://people.smu.edu/dreynolds\" rel=\"nofollow\">Daniel R. Reynolds</a>\
    \ and\n<a href=\"https://people.llnl.gov/gardner48\" rel=\"nofollow\">David J.\
    \ Gardner</a></p>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1655924113.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2023.02.09
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2023.02.09\"\
    ><img src=\"https://camo.githubusercontent.com/de8fce411a546507908f8ebb75df1eb23bdea1642c644fb458f82cbc0e4622c1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032332e30322e30392d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2023.02.09-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.7626579\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6c34eed56081f22323bcf62905ffa15d8709d0ed701bdf7bde3bdd44e83c5402/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e373632363537392e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.7626579.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#what-is-spectre\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>What is SpECTRE?</h2>\n<p>SpECTRE\
    \ is an open-source code for multi-scale, multi-physics problems\nin astrophysics\
    \ and gravitational physics. In the future, we hope that\nit can be applied to\
    \ problems across discipline boundaries in fluid\ndynamics, geoscience, plasma\
    \ physics, nuclear physics, and\nengineering. It runs at petascale and is designed\
    \ for future exascale\ncomputers.</p>\n<p>SpECTRE is being developed in support\
    \ of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into\
    \ the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae,\
    \ and\ngamma-ray bursts.</p>\n<h2><a id=\"user-content-citing-spectre\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#citing-spectre\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Citing SpECTRE</h2>\n<p>Please cite\
    \ SpECTRE in any publications that make use of its code or data. Cite\nthe latest\
    \ version that you use in your publication. The DOI for this version\nis:</p>\n\
    <ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.7626579\" rel=\"nofollow\"\
    >10.5281/zenodo.7626579</a>\n</li>\n</ul>\n<p>You can cite this BibTeX entry in\
    \ your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"><pre><span\
    \ class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and H\\'ebert, Fran\\c{c}ois and Moxon,\
    \ Jordan and Armaza, Crist\\'obal and</span>\n<span class=\"pl-s\">Bonilla, Gabriel\
    \ S. and Kim, Yoonsoo and Kumar, Prayush and Lovelace, Geoffrey</span>\n<span\
    \ class=\"pl-s\">and Macedo, Alexandra and Nelli, Kyle C. and O'Shea, Eamonn and\
    \ Pfeiffer, Harald</span>\n<span class=\"pl-s\">P. and Scheel, Mark A. and Teukolsky,\
    \ Saul A. and Wittek, Nikolas A. and</span>\n<span class=\"pl-s\">others<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> =\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2023.02.09}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2023.02.09<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">publisher</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Zenodo<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">doi</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>10.5281/zenodo.7626579<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>https://spectre-code.org<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">howpublished</span> =\n<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.7626579}{10.5281/zenodo.7626579}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2023<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>2<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2><a id=\"\
    user-content-viewing-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #viewing-documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Viewing Documentation</h2>\n<p>The documentation can be viewed at\
    \ <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 121
  subscribers_count: 14
  topics: []
  updated_at: 1677196272.0
tgamblin/cali-container:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: tgamblin/cali-container
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1667175253.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - cooley/spack.yaml
  - chifflot/v100/spack.yaml
  - local/spack.yaml
  - gemini/spack.yaml
  - chifflot/p100/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1><a id="user-content-spack-envs" class="anchor" aria-hidden="true" href="#spack-envs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-envs</h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2><a id="user-content-locally" class="anchor" aria-hidden="true" href="#locally"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Locally</h2>

    <pre><code>spack config --scope defaults edit config

    install_tree: $spack/opt/spack

    build_stage: $user_cache_path/stage


    spack env activate ~/Dev/spack-envs/local

    spack install

    </code></pre>

    <h2><a id="user-content-g5k" class="anchor" aria-hidden="true" href="#g5k"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>G5k</h2>

    <pre><code>spack config --scope defaults edit config

    install_tree: /mnt/spack

    build_stage: /tmp/spack-stage

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1673281960.0
toxa81/se:
  data_format: 2
  description: Software environments
  filenames:
  - catalog-config/libxc-5.2.3/spack.yaml
  - catalog-config/core/spack.yaml
  - catalog-config/compilers/nvhpc-22.9/spack.yaml
  - catalog-config/compilers/gcc-11.3.0/spack.yaml
  full_name: toxa81/se
  latest_release: null
  readme: '<h1><a id="user-content-software-environments" class="anchor" aria-hidden="true"
    href="#software-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    environments</h1>

    <p>Deployment steps</p>

    <ul>

    <li>clone spack <code>git clone https://github.com/spack/spack.git</code>

    </li>

    <li>enable spack <code>source enable-spack</code>

    </li>

    <li>srun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16</li>

    <li>install gcc-11.3.0 view <code>spack -e  ./env-spec/gcc-11.3.0/ install</code>

    </li>

    <li>install nvhpc-22.9 <code>srun -N1 --partition=nvgpu spack -e . install -j64</code>

    </li>

    </ul>

    <p>spack compiler find $(spack find --format {prefix.bin} gcc@11)</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669195550.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/intelmpi/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1635166163.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/hpccf/franklin/omics/spack.yaml
  - environments/hpccf/franklin/general/spack.yaml
  - environments/hpccf/franklin/cluster-core/spack.yaml
  - environments/hpccf/franklin/r-stack/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<h1><a id="user-content-spack--uc-davis" class="anchor" aria-hidden="true"
    href="#spack--uc-davis"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    @ UC Davis</h1>

    <h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters" class="anchor"
    aria-hidden="true" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack repos and configs
    for UC Davis HPCCF Clusters</h2>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1676322811.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/summit/spack.yaml
  - platformFiles/lassen/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1><a id="user-content-useful-supplementary-materials-for-installing-the-xsdk"
    class="anchor" aria-hidden="true" href="#useful-supplementary-materials-for-installing-the-xsdk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful supplementary
    materials for installing the xSDK</h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics: []
  updated_at: 1669065329.0
