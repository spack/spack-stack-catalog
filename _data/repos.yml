Alpine-DAV/spack_configs:
  data_format: 2
  description: spack envs
  filenames:
  - envs/llnl/quartz/spack.yaml
  - envs/alpinedav/ubuntu_18_cuda_10.1_devel/spack.yaml
  - envs/llnl/pascal-cuda/spack.yaml
  - envs/alpinedav/ubuntu_18_devel/spack.yaml
  - envs/olcf/summit/spack.yaml
  full_name: Alpine-DAV/spack_configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack_configs" class="anchor" href="#spack_configs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack_configs</h1>

    <p>shared spack configs repo</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1639176281.0
ArjunaCluster/spack:
  data_format: 2
  description: Spack Repos and Configuration Files
  filenames:
  - environments/slurm/spack.yaml
  - environments/common/spack.yaml
  full_name: ArjunaCluster/spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1637623732.0
CUP-ECS/cajitafluids:
  data_format: 2
  description: A simple poisson finite difference fluid solver in Cajita/Kokkos for
    testing MPI communication abstractions and their performance
  filenames:
  - configs/tutorial-uao-cuda/spack.yaml
  - configs/github/spack.yaml
  - configs/generic/spack-cuda-wrapper.yaml
  - configs/llnl-lassen/spack.yaml
  - configs/generic/spack-cuda-clang.yaml
  full_name: CUP-ECS/cajitafluids
  latest_release: null
  readme: '<h1>

    <a id="user-content-poisson-mpi-benchmark" class="anchor" href="#poisson-mpi-benchmark"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Poisson
    MPI Benchmark</h1>

    <p>This directory contains code for a relatively simple finite difference

    fluid advection solver for exploring communication issues on modern architectures

    (particularly GPUs). The main goal is to look at different neighbor collective

    and GPU communication approaches.</p>

    <p>Computationally, the benchmark advects a material feature (that doesn''t otherwise
    effect

    fluid flow, e.g. by changing pressite) using the incompressible Euler fluid flow
    equations.

    Consider, for example, something like a dye being carried through a tank of water
    or a

    fragrance wafting across a room.</p>

    <p>The main elements of the benchmark are:</p>

    <ul>

    <li>Solution of the pressure gradient at each timestep to maintain

    incompressibility. The benchmark has two initial implementations:

    (1) Calling a matrix-free solver in HYPRE to solve the problem or (2)

    running a local matrix-free preconditioned CG solver, in which different

    MPI approaches for the halo exchange are explored.</li>

    <li>Interpolation (either cubic splines or linear) for semi-Lagrangian

    advection of the material being advected across timesteps.</li>

    <li>3rd-order Runge Kutta for time integration</li>

    </ul>

    <p>Sources:</p>

    <ul>

    <li>Fluid Simulation for Comptuer Graphics by Bridson</li>

    <li>Incremental Fluids in Kokkos (<a href="mailto:git@github.com">git@github.com</a>:pkestene/incremental-fluids-kokkos.git)</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1654983605.0
CivetWang/HPCHarryW:
  data_format: 2
  description: null
  filenames:
  - assignment/spack.yaml
  full_name: CivetWang/HPCHarryW
  latest_release: null
  readme: '<h1>

    <a id="user-content-hpcharryw" class="anchor" href="#hpcharryw" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPCHarryW</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1653448958.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/22.05/rocm.spack.yaml
  - environments/22.05/cuda-x86_64.spack.yaml
  - environments/22.05/oneapi.spack.yaml
  - environments/22.05/cuda-ppc64le.spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    \ target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width:100%;\"></a></p> \n<p><a href=\"\
    https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-e4s\" class=\"\
    anchor\" href=\"#e4s\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2>\n<a id=\"user-content-related-projects\"\
    \ class=\"anchor\" href=\"#related-projects\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Related Projects</h2>\n<ul>\n\
    <li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\">E4S-Project/E4S-Project.github.io</a>\
    \ - E4S Documentation repo that is hosted on <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-license\"\
    \ class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2>\n<a id=\"user-content-contact\" class=\"anchor\" href=\"\
    #contact\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 13
  subscribers_count: 9
  topics: []
  updated_at: 1655324301.0
FTHPC/Correlation_Compressibility:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: FTHPC/Correlation_Compressibility
  latest_release: v0.1
  readme: "<h1>\n<a id=\"user-content-compressibility-analysis-correlation_compressibility\"\
    \ class=\"anchor\" href=\"#compressibility-analysis-correlation_compressibility\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Compressibility Analysis (Correlation_Compressibility)</h1>\n<h2>\n\
    <a id=\"user-content-statement-of-purpose\" class=\"anchor\" href=\"#statement-of-purpose\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Statement of Purpose</h2>\n<p>This repo contains scripts to perform\
    \ compressibility analysis on several leading lossy compressors.\nThe compressibility\
    \ analysis relies on deriving statistics on scientific data and explore their\
    \ relationships to their compression ratios from various lossy compressors (based\
    \ on various compression scheme).\nThe extracted relationships between compression\
    \ ratios and statistical predictors are modeled via regression models, which provide\
    \ a statistical framework to predict compression ratios for the different studied\
    \ lossy compressors.</p>\n<p>This repo contains an automatic framework of scripts\
    \ that perform the compression of scientific datasets from 8 compressors (SZ2,\
    \ ZFP, MGARD, FPZIP, Digit Rounding and Bit Grooming), the derivation of the statistical\
    \ predictors of compression ratios (SVD, standard deviation, quantized entropy),\
    \ and scripts to perform the training of the regression models (linear and spline\
    \ regressions) as well as the validation of the regression predictions.\nA runtime\
    \ analysis is also performed and associated codes are provided.</p>\n<h3>\n<a\
    \ id=\"user-content-main-code-structures\" class=\"anchor\" href=\"#main-code-structures\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Main code structures</h3>\n<p>Compression metrics, including compression\
    \ ratios, and derivation of statistical predictors (SVD, standard deviation, quantized\
    \ entropy) codes are found in <code>compress_package</code> and are run via <code>scripts/run.sh</code>\
    \ as described in the section \"How to compute statistical predictors and compression\
    \ analysis on datasets\".\nLinear and spline regressions training and validation\
    \ (functions <code>cr_regression_linreg</code> and <code>cr_regression_gam</code>\
    \ from the script <code>replicate_figures/functions_paper.R</code>).\nCodes for\
    \ the different runtime analysis are found in the folder <code>runtime_analysis</code>\
    \ and are automated with the script <code>runtime.sh</code>, the study includes\
    \ compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled)\
    \ variogram and local (tiled) variogram, and runtime for training and prediction\
    \ of the regressions.<br>\nFinally, the script <code>replicate_figures/graphs_paper_container.R</code>\
    \ replicates and saves all the figures from the paper ad as well as numbers from\
    \ the tables.</p>\n<p>For each dataset in the <code>dataset</code> folder, slicing\
    \ is performed for each variable field (e.g. density in Miranda), each slice is\
    \ stored in a class. The class is updated as compressions with the 8 compressors\
    \ is performed and updated as the statistical predictors are derived. Results\
    \ of each class are stored in a .csv file (example of csv files can be found at\
    \ <code>replicate_figures/generated_data/</code>).\nAll the datasets stored in\
    \ the <code>dataset</code> folder can be analyzed with the given set of codes,\
    \ one needs to source <code>scripts/config.json</code> with the appropriate dataset\
    \ name as described in the below section \"How to compute statistical predictors\
    \ and compression analysis on datasets\".\nThe regression analysis and its prediction\
    \ is then performed on R dataframes based on the aforementioned .csv files.</p>\n\
    <h2>\n<a id=\"user-content-system-information\" class=\"anchor\" href=\"#system-information\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>System Information</h2>\n<p>The hardware and software versions used\
    \ for the performance evaluations can be found in the table below. These nodes\
    \ come from Clemson University's Palmetto Cluster.</p>\n<p>These nodes have:</p>\n\
    <table>\n<thead>\n<tr>\n<th>component</th>\n<th>version</th>\n<th>component</th>\n\
    <th>version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CPU</td>\n<td>Intel Xeon\
    \ 6148G (40 cores)</td>\n<td>sz2</td>\n<td>2.1.12.2</td>\n</tr>\n<tr>\n<td>GPU</td>\n\
    <td>2 Nvidia v100</td>\n<td>sz3</td>\n<td>3.1.3.1</td>\n</tr>\n<tr>\n<td>Memory</td>\n\
    <td>372GB</td>\n<td>zfp</td>\n<td>0.5.5</td>\n</tr>\n<tr>\n<td>Network</td>\n\
    <td>2 Mellanox MT27710 (HDR)</td>\n<td>mgard</td>\n<td>1.0.0</td>\n</tr>\n<tr>\n\
    <td>FileSystem</td>\n<td>BeeGFS 7.2.3 (24 targets)</td>\n<td>bit grooming</td>\n\
    <td>2.1.9</td>\n</tr>\n<tr>\n<td>Compiler</td>\n<td>GCC 8.4.1</td>\n<td>digit\
    \ rounding</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>OS</td>\n<td>CentOS 8.2.2004</td>\n\
    <td>R</td>\n<td>4.1.3</td>\n</tr>\n<tr>\n<td>MPI</td>\n<td>OpenMPI 4.0.5</td>\n\
    <td>Python</td>\n<td>3.9.12</td>\n</tr>\n<tr>\n<td>LibPressio</td>\n<td>0.83.4</td>\n\
    <td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-first-time-setup\"\
    \ class=\"anchor\" href=\"#first-time-setup\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>First time setup</h2>\n<h3>\n\
    <a id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\"\
    \ href=\"#container-installation-for-ease-of-setup\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Container Installation\
    \ (for ease of setup)</h3>\n<p>We provide a container for <code>x86_64</code>\
    \ image for ease of installation.</p>\n<p>This container differs from our experimental\
    \ setup slightly. The production build used <code>-march=native -mtune=native</code>\
    \ for architecture optimized builds where as the container does not use these\
    \ flags to maximize compatibility across <code>x86_64</code> hardware.</p>\n<p>NOTE\
    \ this file is &gt;= 11 GB , download with caution.</p>\n<h4>\n<a id=\"user-content-docker\"\
    \ class=\"anchor\" href=\"#docker\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Docker</h4>\n<p>Many other systems\
    \ can use podman or docker.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>docker pull ghcr.io/fthpc/correlation_compressibility:latest\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>most systems</span>\ndocker run -it --rm ghcr.io/fthpc/correlation_compressibility:latest\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> if running on a SeLinux enforcing\
    \ system</span>\ndocker run -it --rm --security-opt label=disable ghcr.io/fthpc/correlation_compressibility:latest</pre></div>\n\
    <h3>\n<a id=\"user-content-building-the-container\" class=\"anchor\" href=\"#building-the-container\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Building the Container</h3>\n<p>You can build the container yourself\
    \ as follows:\nNOTE this process takes 3+ hours on a modern laptop, and most clusters\
    \ do not\nprovide sufficient permissions to run container builds on the cluster.</p>\n\
    <p>Additionally compiling MGRAD -- one of the compressors we use takes &gt;= 4GB\
    \ RAM per core, be cautious\nwith systems with low RAM.  You may be able compensate\
    \ by using fewer cores by changing the spack install\ninstruction in the Dockerfile\
    \ to have a <code>-j N</code> where <code>N</code> is the number of cores you\
    \ wish to use</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> install/module load git-lfs, needed\
    \ to download example_data for building the container</span>\nsudo dnf install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span>Fedora/CentOS Stream\
    \ 8</span>\nsudo apt-get install git-lfs <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Ubuntu</span>\nspack install git-lfs<span class=\"pl-k\">;</span> spack\
    \ load git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> clone this repository</span>\n\
    git clone --recursive https://github.com/FTHPC/Correlation_Compressibility\n<span\
    \ class=\"pl-c1\">cd</span> Correlation_Compressibility\ndocker build <span class=\"\
    pl-c1\">.</span> -t correlation_compressibility</pre></div>\n<h3>\n<a id=\"user-content-manual-installation\"\
    \ class=\"anchor\" href=\"#manual-installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manual Installation</h3>\n<p>By\
    \ default, it is recommended to follow the install locations that are indicated\
    \ on the top of <code>scripts/run.sh</code>\nand the top of <code>config.json</code>.\
    \ These two files provide the configuration options to get the program running.</p>\n\
    <p>Spack should be installed in the following location: <code>$HOME/spack/</code></p>\n\
    <p>This Github repo should be cloned in the following location: <code>$HOME/Correlation_Compressibility/</code>\n\
    This location is also referenced as the <code>COMPRESS_HOME</code> environment\
    \ variable.</p>\n<p>A dataset folder called 'datasets' should be in the following\
    \ location: <code>$HOME/Correlation_Compressibility/datasets/</code>.</p>\n<p>Clone\
    \ the repo but make sure to install or load <code>git-lfs</code> first.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> install/module load git-lfs, needed to download example_data\
    \ for building the container</span>\nsudo dnf install git-lfs <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>Fedora/CentOS Stream 8</span>\nsudo apt-get install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ubuntu</span>\nspack\
    \ install git-lfs<span class=\"pl-k\">;</span> spack load git-lfs <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> clone this repository</span>\ngit clone https://github.com/FTHPC/Correlation_Compressibility\
    \ <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility</pre></div>\n\
    <p>If you forgot to install <code>git-lfs</code> before and have an empty file\
    \ in the  <code>datasets</code> folder, you should install <code>git-lfs</code>\n\
    and then run the following:</p>\n<pre><code>git lfs fetch\ngit lfs checkout\n\
    </code></pre>\n<p>Once Spack is installed, there is a <code>spack.yaml</code>\
    \ configuration file containing the Spack environment necessary to run the program.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">$HOME</span>\ngit clone --depth=1 https://github.com/spack/spack\n\
    git clone --depth=1 https://github.com/robertu94/spack_packages \n<span class=\"\
    pl-c1\">source</span> ./spack/share/spack/setup-env.sh \nspack compiler find\n\
    spack external find \nspack repo add --scope=site ./spack_packages \n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ \nspack env activate <span class=\"pl-c1\">.</span>\nspack install\n<span class=\"\
    pl-k\">export</span> COMPRESS_HOME=<span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ </pre></div>\n<p>These commands will install the environment. The environment\
    \ only needs to be installed once.\nIf you are using an older &lt; gcc11, then\
    \ you will need to add the following to the <code>spack.yaml</code> file:</p>\n\
    <pre><code>^libstdcompat+boost\n</code></pre>\n<p>after <code>^mgard@robertu94+cuda</code>\
    \ but before the <code>,</code>.</p>\n<h2>\n<a id=\"user-content-replication-of-results\"\
    \ class=\"anchor\" href=\"#replication-of-results\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication of\
    \ Results</h2>\n<h3>\n<a id=\"user-content-how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    \ class=\"anchor\" href=\"#how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>How to compute statistical predictors and compression metrics on datasets</h3>\n\
    <p>In order to run the statistical analysis that computes the statistical predictors\
    \ (SVD, standard deviation, quantized entropy) of compression ratios, a dataset\
    \ and a configuration file must be specified.\nTEST is a dataset that is specified\
    \ within the <code>config.json</code> file.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh scripts/run.sh -c config.json -d TEST -n 2</pre></div>\n<p>The command\
    \ above performs the computation of statistical predictors and writes output to\
    \ the output file specified in the configuration file.\nThis will use local hardware\
    \ without a scheduler. Use <code>-n</code> to specify the MPI processes on your\
    \ local system. Default value is 32.\nIt is recommended that this value matches\
    \ your CPU core count.</p>\n<p>If one has the PBS scheduler and runs outside of\
    \ the container, feel free to use flags <code>-p</code> or <code>-s</code> for\
    \ job execution.\n<code>-p</code> will schedule multiple jobs based on the quantized\
    \ error bounds and error bound types for a specified dataset.\n<code>-s</code>\
    \ will schedule a single job grouping all the analysis for a specified dataset.</p>\n\
    <p>See <code>-h</code> for more options or help with syntax.</p>\n<p>If a dataset\
    \ is wanted to run, the <code>config.json</code> file provides options to add\
    \ datasets.\nThe following options must be added when adding another dataset in\
    \ the configuration file:</p>\n<div class=\"highlight highlight-source-json\"\
    ><pre><span class=\"pl-ent\">\"_comment\"</span> : \n{\n    <span class=\"pl-ent\"\
    >\"folder\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>folder containing h5 or binary files<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"data_dimensions\"</span>   : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>dimensions of the datasets within dataset_folder.\
    \ Either 1x2 or 1x3. EX: '1028, 1028'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"slice_dimensions\"</span>  : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>list of the dimensions wanted: EX: 'None' or\
    \ 'X, Y, Z'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\"\
    >\"output\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>name of the output csv file: EX: 'test.csv'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"dtype\"</span>             : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>data type. can be 'float32' or 'float64'<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\">\"parse_info\"\
    </span>        : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type of\
    \ parsing needed: 'None', 'slice', 'gaussian', 'gaussian_multi', 'spatialweight',\
    \ or 'scalarweight'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"\
    pl-ent\">\"dataset_name\"</span>      : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>necessary accessing 2D HDF5 files: 'standard' if not custom. custom\
    \ EX: 'Z'<span class=\"pl-pds\">\"</span></span>\n} </pre></div>\n<p>From this\
    \ section, .csv files are generated for each dataset and contain all the statistical\
    \ predictors described in the paper as well as compression metrcis including compresison\
    \ ratios for the 8 lossy compressors and 4 error bounds.</p>\n<h3>\n<a id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ class=\"anchor\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>To run the training and prediction timing analysis demonstration</h3>\n\
    <p>In order to run the timing analysis, a dataset must be specified.\nThere are\
    \ two datasets setup within this demonstration.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh runtime_analysis/runtime.sh -d [DATASET]</pre></div>\n<p>[DATASET] can\
    \ be either [NYX] or [SCALE]</p>\n<p>After running the above script, an *.RData\
    \ file(s) will be produced giving the approprirate timing information of\nthe\
    \ training and prediction for the regression models.</p>\n<p>Note: A quicker and\
    \ more efficient quantized entropy method is demonstrated in <code>qentropy.cc</code></p>\n\
    <h4>\n<a id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\"\
    \ href=\"#the-following-below-runs-qentropycc\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The following below runs <code>qentropy.cc</code>\n\
    </h4>\n<div class=\"highlight highlight-source-shell\"><pre>g++ -std=c++2a -O3\
    \ qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy</pre></div>\n\
    <p>Note: Please run the runtime analysis for both datasets before running the\
    \ following section.</p>\n<h3>\n<a id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ class=\"anchor\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Replication of figures: how to run statistical prediction of compression\
    \ ratios and the prediction validation</h3>\n<p>The script <code>graphs_paper_container.R</code>\
    \  saves the graphs presented in the paper and provides associated validation\
    \ metrics (correlation and median absolute error percentage).</p>\n<p>The script\
    \ <code>graphs_paper_container.R</code> will source the scripts  <code>load_dataset_paper.R</code>\
    \ and <code>functions_paper.R</code> that respectively load the dataset of interest\
    \ and perform the regression analysis (training and prediction in cross-validation).\n\
    As a consequence the scripts  <code>load_dataset_paper.R</code> and <code>functions_paper.R</code>\
    \ do not need to be run by the user.</p>\n<p>The script <code>graphs_paper_container.R</code>\
    \  is run via the command:\n<code>bash sh replicate.sh</code></p>\n<p>From running\
    \ the script once, it will save all Figures 1, 3, 4 and 5 into .png files from\
    \ the paper as well as corresponding validation metrics.\nFigure 2 is not saved\
    \ as it provides a simple vizualization of slices of the datasets.\nSlices of\
    \ the datasets are generated in the Section \"How to compute statistical predictors\
    \ and compression metrics\" and can be stored, however we do not save them here\
    \ to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in\
    \ the R console.\nAll printed validation metrics are save into a file named <code>figure_replication.log</code>.\n\
    Figures and the log-file are saved in the same folder as the one where R script\
    \ is run and the filename structure is <code>figY_*.png</code> with Y is the figure\
    \ number reference in the paper and <code>*</code> provides additional informnation\
    \ about the data and the compressor.<br>\nNumbers for Table 4 are saved in the\
    \ last section in .txt files <code>statistic_benchmark_runtime_X.txt</code> with\
    \ X the studied dataset (NYX or SCALE).</p>\n<p>In order to limit the container\
    \ size to aid reproducibility, we only added a restricted number of scientific\
    \ datasets in the container and we rely on csv files from our production runs\
    \ (saved as described above in the Section \"How to compute statistical predictors\
    \ on datasets\").\nMore datasets are available on <a href=\"https://sdrbench.github.io\"\
    \ rel=\"nofollow\">SDRBench</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1648227729.0
FairRootGroup/FairSoft:
  data_format: 2
  description: Repository for installation routines of the external software required
    by FairRoot
  filenames:
  - test/env/dds/spack.yaml
  - env/nov20/sim/spack.yaml
  - test/env/fairmq/spack.yaml
  - env/nov20/sim_mt_headless/spack.yaml
  - test/env/pandaroot/spack.yaml
  - env/nov20/sim_mt/spack.yaml
  full_name: FairRootGroup/FairSoft
  latest_release: apr22
  readme: "<h1>\n<a id=\"user-content-fairsoft\" class=\"anchor\" href=\"#fairsoft\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>FairSoft</h1>\n<p>The FairSoft distribution provides the software\
    \ packages needed to compile and run the <a href=\"https://github.com/FairRootGroup/FairRoot\"\
    >FairRoot framework</a> and experiment packages based on FairRoot. FairSoft is\
    \ a source distribution with recurring releases for macOS and Linux.</p>\n<h2>\n\
    <a id=\"user-content-installation-from-source\" class=\"anchor\" href=\"#installation-from-source\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation from Source</h2>\n<p>Choose between the classic (called\
    \ \"Legacy\") installation method or the new Spack-based one:</p>\n<table>\n<thead>\n\
    <tr>\n<th><strong>Legacy (Recommended)</strong></th>\n<th><strong>Spack (EXPERIMENTAL)</strong></th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>This is the classic bash/cmake based setup\
    \ system.</td>\n<td>This is an ongoing standardization and modernization effort\
    \ based on Spack (which itself is still under heavy development). Most things\
    \ are already working. For early adopters.</td>\n</tr>\n<tr>\n<td>Releases are\
    \ reflected in the git history via tags and branches, e.g.: <code>apr22</code>,\
    \ <code>apr21p2</code>, <code>nov20_patches</code>\n</td>\n<td>Always use the\
    \ latest <code>dev</code> branch. Multiple releases are described within the metadata\
    \ contained in the repo (read on in the Installation instructions on how to select\
    \ a release).</td>\n</tr>\n<tr>\n<td>\u25BA <a href=\"legacy/README.md\">continue</a>\n\
    </td>\n<td>\u25BA <a href=\"docs/README.md\">continue</a>\n</td>\n</tr>\n</tbody>\n\
    </table>\n<h2>\n<a id=\"user-content-installation-of-pre-compiled-binaries\" class=\"\
    anchor\" href=\"#installation-of-pre-compiled-binaries\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ of pre-compiled Binaries</h2>\n<p><em>Note</em>: FairSoft is primarily a source\
    \ distribution. Availability of latest releases as pre-compiled binaries may be\
    \ delayed.</p>\n<h3>\n<a id=\"user-content-gsi-virgo-cluster\" class=\"anchor\"\
    \ href=\"#gsi-virgo-cluster\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>GSI Virgo Cluster</h3>\n<p>For all\
    \ <a href=\"https://hpc.gsi.de/virgo/platform/software.html#application-environment\"\
    \ rel=\"nofollow\">VAEs</a> at <code>/cvmfs/fairsoft.gsi.de/&lt;vae-os&gt;/fairsoft/&lt;release&gt;</code>.\
    \ Use by exporting the <code>SIMPATH</code> environment variable pointing to one\
    \ of the directories.</p>\n<h3>\n<a id=\"user-content-macos-beta\" class=\"anchor\"\
    \ href=\"#macos-beta\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>macOS (beta)</h3>\n<p>Tested: <code>macOS 11\
    \ (x86_64)</code>, <code>macOS 12 (x86_64)</code>, <code>macOS 12 (arm64)</code>\
    \ with <em>Command Line Tools for Xcode</em> <code>13</code></p>\n<p>FairSoft\
    \ config: <a href=\"FairSoftConfig.cmake\">default</a>, no other configs planned</p>\n\
    <ol>\n<li>Install <em>Command Line Tools for Xcode</em> from <a href=\"https://developer.apple.com/downloads\"\
    \ rel=\"nofollow\">https://developer.apple.com/downloads</a> (requires Apple account)</li>\n\
    <li>Install <a href=\"https://brew.sh/\" rel=\"nofollow\">Homebrew</a>\n</li>\n\
    <li>Run <code>brew update &amp;&amp; brew doctor</code> and fix potential issues\
    \ reported by these commands until <code>Your system is ready to brew.</code>\n\
    </li>\n<li>Run</li>\n</ol>\n<pre><code>brew tap fairrootgroup/fairsoft\nbrew install\
    \ fairsoft@22.4\n</code></pre>\n<ol start=\"5\">\n<li>Use via <code>export SIMPATH=$(brew\
    \ --prefix fairsoft@22.4)</code>\n</li>\n</ol>\n<p><em>Note</em>: macOS is a fast\
    \ moving target and it is possible the packages will stop working from one day\
    \ to another after some system component was updated. We try our best to keep\
    \ up, one great way to help is to provide detailed problem reports <a href=\"\
    https://github.com/FairRootGroup/FairSoft/issues/new\">here on github</a>.</p>\n\
    <h3>\n<a id=\"user-content-other-platforms\" class=\"anchor\" href=\"#other-platforms\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Other platforms</h3>\n<p>Binary packages for non-GSI Linux as well\
    \ as Spack binary caches and/or pre-populated install trees are planned for the\
    \ future.</p>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"\
    #contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Contributing</h2>\n<p>Please ask your questions, request\
    \ features, and report issues by <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\
    >creating a github issue</a>.</p>\n"
  stargazers_count: 12
  subscribers_count: 14
  topics: []
  updated_at: 1655212124.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1655837702.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - test/spack/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.2.0
  readme: '<h1>

    <a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SUNDIALS:
    SUite of Nonlinear and DIfferential/ALgebraic equation Solvers</h1>

    <h3>

    <a id="user-content-version-620-apr-2022" class="anchor" href="#version-620-apr-2022"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Version
    6.2.0 (Apr 2022)</h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form</p>

    <p><code>M(t) y'' = f1(t,y) + f2(t,y), y(t0) = y0</code></p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form</p>

    <p><code>y'' = f(t,y), y(t0) = y0</code></p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form</p>

    <p><code>y'' = f(t,y,p), y(t0) = y0(p)</code></p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form</p>

    <p><code>F(t,y,y'') = 0, y(t0) = y0, y''(t0) = y0''</code></p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form</p>

    <p><code>F(t,y,y'',p) = 0, y(t0) = y0(p), y''(t0) = y0''(p)</code></p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form</p>

    <p><code>F(u) = 0</code> or <code>G(u) = u</code></p>

    </li>

    </ul>

    <h2>

    <a id="user-content-installation" class="anchor" href="#installation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online documentation</a>,

    the <a href="./INSTALL_GUIDE.pdf">INSTALL_GUIDE</a>, or the installation chapter
    in any of

    the package user guides.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2>

    <a id="user-content-support" class="anchor" href="#support" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2>

    <a id="user-content-citing" class="anchor" href="#citing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2>

    <a id="user-content-authors" class="anchor" href="#authors" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Slaven Peles, Cosmin Petra, H. Hunter Schwartz, Jean M. Sexton,

    Dan Shumaker, Steve G. Smith, Allan G. Taylor, Hilari C. Tiedeman, Chris White,

    Ting Yan, and Ulrike M. Yang.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 278
  subscribers_count: 35
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1658566398.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-22.05/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/spack.yaml
  - spack-configs/perlmutter-spack-develop/spack.yaml
  - spack-configs/cori-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-spack-infrastructure\" class=\"anchor\" href=\"\
    #spack-infrastructure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file.</p>\n<h2>\n<a id=\"user-content-spack-configuration\"\
    \ class=\"anchor\" href=\"#spack-configuration\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack Configuration</h2>\n<p>The\
    \ spack configuration can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<table>\n<thead>\n<tr>\n<th>system</th>\n\
    <th>status</th>\n<th>PIPELINE_NAME</th>\n<th>description</th>\n<th>spack.yaml</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>Perlmutter</td>\n<td><strong>IN-PROGRESS</strong></td>\n\
    <td><code>PERLMUTTER_SPACK_DEVELOP</code></td>\n<td>This spack configuration is\
    \ based on <code>spack@develop</code> branch to see what packages can be built.\
    \ We expect this pipeline will fail and we are not expected to fix build failure.\
    \ The main purpose of this project is to build as many packages across all the\
    \ compilers, mpi, blas providers of interest and see what works. Since we don't\
    \ know which package works during deployment, we will leverage data from this\
    \ pipeline to make informed decision what packages should be picked with given\
    \ compilers. This pipeline is our development and we should use this to experiment\
    \ new compilers. Note that we won't hardcode versions for packages since we want\
    \ to build with latest release. However we will hardcode externals depending on\
    \ how system is configured.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>IN-PROGRESS</strong></td>\n<td><code>CORI_SPACK_DEVELOP</code></td>\n\
    <td>This spack configuration will build E4S stack using spack <code>develop</code>\
    \ branch on Cori.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-spack-develop/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-spack-develop/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>IN-PROGRESS</strong></td>\n<td><code>PERLMUTTER_E4S_22.05</code></td>\n\
    <td>This spack configuration will build E4S 22.05 on Perlmutter on scheduled pipeline</td>\n\
    <td><a href=\"https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/spack.yaml/\"\
    \ rel=\"nofollow\">https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/spack.yaml/</a></td>\n\
    </tr>\n<tr>\n<td>Muller</td>\n<td><strong>IN-PROGRESS</strong></td>\n<td><code>MULLER_E4S_22.05</code></td>\n\
    <td>This spack configuration will build E4S 22.05 on Muller on scheduled pipeline</td>\n\
    <td><a href=\"https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/muller/spack.yaml/\"\
    \ rel=\"nofollow\">https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/muller/spack.yaml/</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>CORI_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on Cori using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Gerty</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>GERTY_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on gerty using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11_DEPLOY</code></td>\n\
    <td>This spack configuration is deployment configuration for E4S/21.11. For more\
    \ details on this stack see  <a href=\"https://docs.nersc.gov/applications/e4s/perlmutter/21.11/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/perlmutter/21.11/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11</code></td>\n\
    <td>This spack configuration is used for development for building E4S/21.11 using\
    \ scheduled pipeline.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Muller</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>MULLER_E4S_21.11</code></td>\n\
    <td>This spack configuration was used to build E4S/21.11 on Muller using scheduled\
    \ pipeline. Once e4s/21.11 was built on Muller we followed up with building the\
    \ same spack configuration on Perlmutter.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.05\
    \ spack stack based on <a href=\"https://github.com/spack/spack/tree/e4s-21.05\"\
    >e4s-21.05</a> branch of spack. This stack can be accessed via <code>module load\
    \ e4s/21.05</code>.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration used for deployment purposes, this can be accessed via <code>module\
    \ load e4s/21.02</code> on Cori. For more details see <a href=\"https://docs.nersc.gov/applications/e4s/cori/21.02/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/21.02/</a>\n</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration that push to buildcache.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration that push to build cache using <code>spack ci</code>.  This\
    \ project lives in <a href=\"https://software.nersc.gov/NERSC/e4s-2010\" rel=\"\
    nofollow\">https://software.nersc.gov/NERSC/e4s-2010</a> and configuration was\
    \ copied over here.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration for Cori used for deployment purpose. This stack can be\
    \ accessed via <code>module load e4s/20.10</code>. This is documented at <a href=\"\
    https://docs.nersc.gov/applications/e4s/cori/20.10/\" rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/20.10/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml</a></td>\n\
    </tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-running-ci-pipelines\" class=\"\
    anchor\" href=\"#running-ci-pipelines\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>.</p>\n<table>\n<thead>\n\
    <tr>\n<th>System</th>\n<th>Runner Name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n</tr>\n<tr>\n<td>cori</td>\n\
    <td><code>cori-e4s</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    </tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n</tr>\n</tbody>\n\
    </table>\n<p>The runner configuration files are located in <code>~/.gitlab-runner</code>\
    \ for user <strong>e4s</strong>.</p>\n<p>The production pipelines are triggered\
    \ via web-interface which requires approval from a project maintainer. Production\
    \ pipelines should be run when we need to do full redeployment of stack.</p>\n\
    <h2>\n<a id=\"user-content-troubleshooting-gitlab-runner\" class=\"anchor\" href=\"\
    #troubleshooting-gitlab-runner\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Troubleshooting gitlab runner</h2>\n\
    <p>You will need to login as <code>e4s</code> user via <code>collabsu</code> command.\
    \ This will prompt you for password which is your <strong>NERSC password</strong>\
    \ for your username not <strong>e4s</strong> user.</p>\n<pre><code>collabsu e4s\n\
    </code></pre>\n<p>Once you are logged in, you can login to the desired system\
    \ to restart the runner. You can check the runner status by navigating to <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\" rel=\"\
    nofollow\">Settings &gt; CI/CD &gt; Runners</a>. If gitlab runner is down you\
    \ will need to restart the runner which is located in <code>$HOME/cron</code>\
    \ directory for e4s user.</p>\n<p>For instance, to access muller you will need\
    \ to login to Cori/DTN nodes and run <code>ssh login.muller.nersc.gov</code>.</p>\n\
    <p>The <code>gitlab-runner</code> command should be accessible with e4s user.\
    \ To register a runner you can run <code>gitlab-runner register</code> and follow\
    \ the prompt. The runner configuration will be written to <code>~/.gitlab-runner/config.toml</code>\
    \ however we recommend you create a separate config.toml or copy the file to separate\
    \ file. For instance if you want to register a runner for muller you can set <code>gitlab-runner\
    \ register -c ~/.gitlab-runner/muller.config.toml</code> when registering the\
    \ runner and it will write the runner configuration to <code>~/.gitlab-runner/muller.config.toml</code>.\
    \ For more details regarding runner register please see <a href=\"https://docs.gitlab.com/runner/register/\"\
    \ rel=\"nofollow\">https://docs.gitlab.com/runner/register/</a></p>\n<p>To restart\
    \ a runner you can run the script based on runner type</p>\n<pre><code># restart\
    \ gerty runner\nbash $HOME/cron/restart-gerty.sh\n\n# restart muller runner\n\
    bash $HOME/cron/restart-muller.sh\n\n# restart perlmutter runner\nbash $HOME/cron/restart-perlmutter.sh\n\
    \n# restart cori runner\nbash $HOME/cron/restart-cori.sh\n</code></pre>\n<p>In\
    \ order to access gerty, you will need to login to data transfer node and then\
    \ login to gerty as follows</p>\n<pre><code>ssh dtn01.nersc.gov\ncollabsu e4s\n\
    ssh gerty\n</code></pre>\n<h2>\n<a id=\"user-content-current-challenges\" class=\"\
    anchor\" href=\"#current-challenges\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have externals set to packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2>\n<a id=\"user-content-contact\" class=\"anchor\" href=\"#contact\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 3
  subscribers_count: 14
  topics: []
  updated_at: 1656175573.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 37
  subscribers_count: 17
  topics: []
  updated_at: 1658059896.0
NOAA-EMC/GSI-Monitor:
  data_format: 2
  description: GSI Monitoring Tools
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-Monitor
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-gsi-monitor\" class=\"anchor\" href=\"#gsi-monitor\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>GSI-Monitor</h1>\n<p>GSI Monitoring Tools</p>\n<p>These tools monitor\
    \ the Gridpoint Statsical Interpolation (GSI) package's data assimiliation, detecting\n\
    and reporting missing data sources, low obervational counts, and high penalty\
    \ values.</p>\n<p>Suite includes:</p>\n<pre><code>  ConMon   Conventional Monitor\
    \     \n  MinMon   GSI Minimization Monitor \n  OznMon   Ozone Monitor       \
    \     \n  RadMon   Radiance Monitor         \n</code></pre>\n<p>PoC:  <a href=\"\
    mailto:edward.safford@noaa.gov\">edward.safford@noaa.gov</a></p>\n"
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1654193829.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<h1>

    <a id="user-content-gsi-utils" class="anchor" href="#gsi-utils" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GSI-Utils</h1>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1656597684.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: gefs_v12.3.0
  readme: '<h1>

    <a id="user-content-unified-post-processing-upp" class="anchor" href="#unified-post-processing-upp"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unified
    Post-Processing (UPP)</h1>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecasting System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Application

    Forecasting System (HAFS), and the Medium Range Weather (MRW) and Short

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model

    derived brightness temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages, or for

    further downstream post-processing, e.g. statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <h2>

    <a id="user-content-user-support" class="anchor" href="#user-support" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>User Support</h2>

    <p>Support for the UFS UPP is provided through the <a href="https://forums.ufscommunity.org/"
    rel="nofollow">UFS Forum</a>

    by the Developmental Testbed Center (DTC).</p>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>User Guide for latest public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <h2>

    <a id="user-content-developer-information" class="anchor" href="#developer-information"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Developer
    Information</h2>

    <p>Please see review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <h2>

    <a id="user-content-authors" class="anchor" href="#authors" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Kate Fossell</p>

    <h2>

    <a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>The UPP requires certain NCEPLIB packages to be installed via

    the HPC-Stack project.</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-gfsio">NCEPLIBS-gfsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">libz</a></li>

    </ul>

    <h2>

    <a id="user-content-building" class="anchor" href="#building" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for Regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 19
  subscribers_count: 17
  topics: []
  updated_at: 1658022730.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/empty/spack.yaml
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/skylab-1.0.0/spack.yaml
  - configs/templates/ufs-weather-model/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/gfs-v16.2/spack.yaml
  - configs/templates/jedi-ufs-all/spack.yaml
  - configs/templates/skylab-1.0.0-public/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: spack-stack-1.0.1
  readme: '<h1>

    <a id="user-content-spack-stack" class="anchor" href="#spack-stack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>Spack-stack enables the installation of software required

    for HPC system deployments of NOAA''s Unified Forecast System (UFS) and

    other weather and climate models, including components of the Joint

    Effort for Data assimilation Integration (JEDI).</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>.</li>

    </ul>

    <p>Spack-stack is a thin layer around a fork of the

    <a href="https://github.com/spack/spack">spack</a> repository. Spack is a

    community-supported, multi-platform, Python-based package manager

    originally developed by the Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about spack see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for

    spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack

    documentation</a>.</p>

    <p>The stack can be installed on a range of platforms, from Linux and

    macOS laptops to HPC systems, and comes pre-configured for many

    systems. Users can install the necessary packages for a particular

    application and later add the missing packages for another application

    without having to rebuild the entire stack.</p>

    <p>spack-stack is mainly a collection of Spack configuration files, but

    provides a Spack extension to simplify the installation process:</p>

    <ul>

    <li>

    <p><code>spack stack create</code> is provided to copy common, site-specific,
    and

    application-specific configuration files into a coherent Spack

    environment and to create container recipes</p>

    </li>

    <li>

    <p><code>spack stack setup-meta-modules</code> creates compiler, MPI and Python

    meta-modules for a convenient setup of a user environment using

    modules (lua and tcl)</p>

    </li>

    </ul>

    <p>Documentation for installing and using spack-stack can be found here:

    <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a></p>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>

    <p><a href="https://www.github.com/kgerheiser">Kyle Gerheiser</a>, <a href="https://www.github.com/Hang-Lei-NOAA">Hang

    Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed

    Hartnett</a> NOAA-EMC</p>

    </li>

    <li>

    <p><a href="https://www.github.com/climbfuji">Dom Heinzeller</a>, JCSDA</p>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 4
  subscribers_count: 6
  topics: []
  updated_at: 1658329088.0
NOAA-GFDL/HPC-ME:
  data_format: 2
  description: null
  filenames:
  - spack_gnu.yaml
  full_name: NOAA-GFDL/HPC-ME
  latest_release: null
  readme: '<h1>

    <a id="user-content-hpc-me-hpc-portable-containers-for-model-environments" class="anchor"
    href="#hpc-me-hpc-portable-containers-for-model-environments" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPC-ME: HPC Portable
    Containers for Model Environments</h1>

    <h2>

    <a id="user-content-contents" class="anchor" href="#contents" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contents</h2>

    <ul>

    <li><a href="#what-is-hpc-me">What is HPC-ME</a></li>

    <li><a href="#list-of-current-compilers">List of current compilers/MPI/OS</a></li>

    <li><a href="#list-of-current-libraries">List of current libraries</a></li>

    <li><a href="#how-to-build">How to build</a></li>

    <li><a href="#how-to-use">How to use</a></li>

    <li><a href="#gfdl-example">GFDL example</a></li>

    <li><a href="#planned-improvements">Planned improvements</a></li>

    </ul>

    <h2>

    <a id="user-content-what-is-hpc-me" class="anchor" href="#what-is-hpc-me" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>What is HPC-ME</h2>

    <p>HPC Portable Container - Model Environments is a set of Dockerfiles, Singularity
    Definition files, and containers to provide portable model environments for scientific
    applications that require the same set of libraries.  The ultimate goal is to
    have a community-based list of libraries that are needed for compiling, executing,
    and post-processing earth science models.  We all use many of the same underlying
    libraries, and by working together we can agree upon a community-based approach
    to making container usage as standardized as possible.</p>

    <h2>

    <a id="user-content-list-of-current-compilersmpios" class="anchor" href="#list-of-current-compilersmpios"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>List
    of current compilers/MPI/OS</h2>

    <p>For each container, there is a full version that contains the programming environment
    and a smaller runtime environment that can be used to run compiled executables.
    (The runtime container definition files will be added soon.)

    #- <a href="Dockerfile_gnu_ubuntu20.04">gcc 8/mpich/ubuntu 20.04</a></p>

    <ul>

    <li><a href="Dockerfile_gnu_rhel8">gcc 8/mpich/RHEL8</a></li>

    <li>

    <a href="Dockerfile_intel_ubuntu18.04">intel oneAPI 2022.1/mpich(impi)/ubuntu
    18.04</a>

    #- <a href="Dockerfile_intel_centos8">intel oneAPI 2021.4/mpich(impi)/centos 8</a>

    </li>

    </ul>

    <h2>

    <a id="user-content-list-of-current-libraries" class="anchor" href="#list-of-current-libraries"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>List
    of current libraries</h2>

    <p>This is the current list of most of the libraries used in the HPC-ME containers
    (We are trying to keep this up-to-date).

    The complete lit should be found in the respective YAML file.</p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#automake"
    rel="nofollow">automake@1.16.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bacio" rel="nofollow">bacio@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#berkeley-db"
    rel="nofollow">berkeley-db@18.1.40</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bison" rel="nofollow">bison@3.7.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bzip2" rel="nofollow">bzip2@1.0.8</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cmake" rel="nofollow">cmake@3.21.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#crtm" rel="nofollow">crtm@2.3.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#curl" rel="nofollow">curl@7.78.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#diffutils"
    rel="nofollow">diffutils@3.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#esmf" rel="nofollow">esmf@8.1.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#expat" rel="nofollow">expat@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2" rel="nofollow">g2@3.4.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2tmpl"
    rel="nofollow">g2tmpl@1.10.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gdbm" rel="nofollow">gdbm@1.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gsl" rel="nofollow">gsl@2.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#hdf5" rel="nofollow">hdf5@1.10.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#intel-mpi"
    rel="nofollow">intel-mpi@2019.10.317</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip" rel="nofollow">ip@3.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip2" rel="nofollow">ip2@1.1.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#jasper"
    rel="nofollow">jasper@2.0.32</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libbsd"
    rel="nofollow">libbsd@0.11.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libiconv"
    rel="nofollow">libiconv@1.16</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libjpeg-turbo"
    rel="nofollow">libjpeg-turbo@2.1.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libmd" rel="nofollow">libmd@1.0.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libpng"
    rel="nofollow">libpng@1.6.37</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libsigsegv"
    rel="nofollow">libsigsegv@2.13</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libxml2"
    rel="nofollow">libxml2@2.9.12</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libyaml"
    rel="nofollow">libyaml@0.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#m4" rel="nofollow">m4@1.4.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nasm" rel="nofollow">nasm@2.15.05</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ncurses"
    rel="nofollow">ncurses@6.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nemsio"
    rel="nofollow">nemsio@2.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-c"
    rel="nofollow">netcdf-c@4.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-fortran"
    rel="nofollow">netcdf-fortran@4.5.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#numactl"
    rel="nofollow">numactl@2.0.14</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#openssl"
    rel="nofollow">openssl@1.1.1l</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#parallel-netcdf"
    rel="nofollow">parallel-netcdf@1.12.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#perl" rel="nofollow">perl@5.34.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#pkgconf"
    rel="nofollow">pkgconf@1.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#readline"
    rel="nofollow">readline@8.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sfcio" rel="nofollow">sfcio@1.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sigio" rel="nofollow">sigio@2.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sp" rel="nofollow">sp@2.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#udunits"
    rel="nofollow">udunits@2.2.28</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3emc" rel="nofollow">w3emc@2.9.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3nco" rel="nofollow">w3nco@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#wrf-io"
    rel="nofollow">wrf-io@1.2.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xerces-c"
    rel="nofollow">xerces-c@3.2.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xz" rel="nofollow">xz@5.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#zlib" rel="nofollow">zlib@1.2.11</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#lmod" rel="nofollow">lmod@8.5.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nccmp" rel="nofollow">nccmp@1.8.6.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nco" rel="nofollow">nco@4.7.9</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-netcdf"
    rel="nofollow">cray-netcdf@4.6.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-hdf5"
    rel="nofollow">cray-hdf5@1.10.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#uberftp"
    rel="nofollow">uberftp</a></li>

    </ul>

    <h2>

    <a id="user-content-how-to-build" class="anchor" href="#how-to-build" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to build</h2>

    <p><strong>We plan to make this step optional soon.</strong> In order to build
    the Docker images, you will need access to a computer with root-like access, and
    either docker or singularity installed. If you do not have root-like access to
    a suitable machine, you can still run images that were already created (e.g. on
    Docker hub), and we plan on hosting runnable Docker images along with the Dockerfiles
    in this repository soon. If you have root-like access and docker, start by choosing
    one of the currently supported model environments from the list above. Then build
    the Docker container from the Dockerfile using docker build; for example, to build
    the gcc8/mpich/ubuntu18 container:</p>

    <pre><code>docker build --file Dockerfile_gnu_ubuntu20.04 . --tag hpc-me.ubuntu.gnu

    </code></pre>

    <p>The build process takes approximately 2-3 hours, as the packages are downloaded
    and compiled using Spack. After a successful build, you will see that the image
    was built and tagged successfully:</p>

    <pre><code>Successfully built 90a878af77b4

    Successfully tagged hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>Then, you may run the container using docker or singularity on the same host.
    To run the image on a different machine, pushing the image to Docker Hub is recommended.
    Note that you will need a DockerHub account to do this (replace USER with your
    Docker user ID in the examples below). For example:</p>

    <pre><code>docker tag hpc-me.rhel8.gnu USER/hpc-me.rhel8.gnu

    docker login

    docker push USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <h2>

    <a id="user-content-how-to-use" class="anchor" href="#how-to-use" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to use</h2>

    <p>We plan to make improvements on this process. Also, while we plan on making
    Docker images available on the GitHub container registry, currently you must build
    the images yourself. Please start with the <a href="#how-to-build">Build instructions</a>
    to generate a Docker image with your desired OS/compiler HPC-ME environment. Then
    you may run the container using docker or singularity; singularity is more likely
    than docker to be available on HPC environments.</p>

    <p>The usage documentation consists of some general notes on serial/parallel usage,
    files inside and outside the container, downloading the containers, and then specific
    usage scenarios:</p>

    <ul>

    <li><a href="#serial-applications-using-docker">Serial applications using docker</a></li>

    <li><a href="#serial-applications-using-singularity">Serial applications using
    singularity</a></li>

    <li><a href="#parallel-applications-using-singularity">Parallel applications using
    singularity</a></li>

    </ul>

    <h3>

    <a id="user-content-serial-and-parallel-usage" class="anchor" href="#serial-and-parallel-usage"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    and parallel usage</h3>

    <p>HPC-ME containers are intended for both serial and parallel applications. Serial
    applications include compiling model executables, generating input grids, and
    post-processing model output. Earth system, climate, and weather models require
    parallelism to run efficiently, and use one of the Message Passage Interface (MPI)
    implementations OpenMPI, Intel MPI, or mpich. GCC-based HPC-ME containers use
    the mpich-based MPI library, which is widely available on most HPC sites, and
    the Intel-based containers contain both mpich and Intel MPI.</p>

    <h3>

    <a id="user-content-notes-on-filesystems-and-writing-files" class="anchor" href="#notes-on-filesystems-and-writing-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Notes
    on filesystems and writing files</h3>

    <p>We recommend not saving or modifying files within the environment container,
    and instead create and modify files on your regular filesystem. To do this, you
    will need to connect your filesystem to your container using bind mounts.</p>

    <h3>

    <a id="user-content-downloading-containers-and-managing-images-on-the-filesystem"
    class="anchor" href="#downloading-containers-and-managing-images-on-the-filesystem"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Downloading
    containers and managing images on the filesystem</h3>

    <p>Once you have pushed your images to DockerHub, you will need to download them
    before using. In the examples below, replace USER with your Docker Hub ID. If
    using docker,</p>

    <pre><code>docker pull USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity,</p>

    <pre><code>singularity pull docker://USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity, the image file (SIF format) is saved to the current working
    directory</p>

    <pre><code>&gt; ls *.sif

    -rwxr-xr-x 532M Dec 10 16:09 hpc-me.rhel8.gnu_latest.sif*

    </code></pre>

    <p>If using docker, the downloaded image is handled by the central docker service.</p>

    <h3>

    <a id="user-content-serial-applications-using-docker" class="anchor" href="#serial-applications-using-docker"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    applications using docker</h3>

    <p>You may activate an interactive shell within the desired HPC-ME container using
    docker. After running the container, the compilers and tools available within
    the container will be accessible in your PATH; e.g.</p>

    <pre><code>&gt; docker run -it hpc-me.rhel8.gnu:latest


    [root@0d2cf64e1175 /]# which nf-config

    /opt/view/bin/nf-config


    [root@0d2cf64e1175 /]# nf-config --version

    netCDF-Fortran 4.5.3


    [root@0d2cf64e1175 /]# nf-config --cflags

    -I/opt/software/linux-rhel8-x86_64/gcc-8.4.1/netcdf-fortran-4.5.3-g5qfkdlp36unt2s4j4wyrc6heh2sa64n/include

    </code></pre>

    <h3>

    <a id="user-content-serial-applications-using-singularity" class="anchor" href="#serial-applications-using-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    applications using singularity</h3>

    <p>Singularity can run Docker images and is more likely to be available on HPC
    environments. As with docker run, the HPC-ME tools and compilers are available
    in the shell, somewhat similar to loading a set of Environment Modules prepared
    by site administrators.</p>

    <pre><code>&gt;singularity run hpc-me.rhel8.gnu_latest.sif


    Singularity&gt; which nf-config

    /opt/view/bin/nf-config


    Singularity&gt; nf-config --version

    netCDF-Fortran 4.5.3

    </code></pre>

    <h3>

    <a id="user-content-parallel-applications-using-singularity" class="anchor" href="#parallel-applications-using-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Parallel
    applications using singularity</h3>

    <p>HPC-ME containers can provide the runtime environment for MPI applications.
    For instance, one could compile an MPI application using the instructions above
    using one of the HPC-ME development containers; and then run the application using
    the corresponding runtime HPC-ME container.</p>

    <p>Please note that we are continuing to improve the usability of HPC-ME containers
    as well as provide more usage examples.</p>

    <p>Usually, GFDL climate models are run on gaea by submitting a runscript to the
    Slurm scheduler. The runscript loads needed runtime Environment Modules, prepares
    input directories and files, and executes the MPI executable using srun. The HPC-ME
    containers provide the necessary runtime environment, obviating the need for loading
    Environment Modules. Currently, our approach for using the HPC-ME containers is
    as follows:</p>

    <ol>

    <li>Create a new container, starting with the desired HPC-ME runtime container</li>

    <li>Add the MPI-compiled executable to the container filesystem</li>

    <li>Set the MPI-compiled executable to as the container''s command (so that when
    the container is run the MPI executable within the container runs)</li>

    <li>Run the singularity container SIF file using srun within the runscript, replacing
    the traditional MPI executable.</li>

    </ol>

    <ul>

    <li>Replace "srun executable.x" with "srun singularity run container.SIF"</li>

    <li>Add --mpi=pmi2 to the srun call, which connects the system MPI to the container
    MPI to the singularity run call</li>

    <li>Bind the working directory so that the container has access to the input files
    and can write output files (singularity run -B=/path/to/workdir)</li>

    </ul>

    <ol start="5">

    <li>Submit the modified runscript to the scheduler</li>

    </ol>

    <p>We plan to provide more examples and usage scenarios, such as using the HPC-ME
    containers as-is (i.e. not creating a new container as described above)</p>

    <h2>

    <a id="user-content-gfdl-example" class="anchor" href="#gfdl-example" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL example</h2>

    <p>An example of using an HPC-ME container with the GFDL FRE workflow can be found
    <a href="GFDL_EXAMPLE.md">here</a></p>

    <h2>

    <a id="user-content-planned-improvements" class="anchor" href="#planned-improvements"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Planned
    improvements</h2>

    <p>HPC-ME is a work in progress under active development, so please check back
    or follow the repository for more updates.</p>

    <h3>

    <a id="user-content-build-cache" class="anchor" href="#build-cache" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build cache</h3>

    <p>We are working to create a build cache for the libraries listed so that building
    the containers is quick and easy.</p>

    <h3>

    <a id="user-content-github-container-registry" class="anchor" href="#github-container-registry"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Github
    container registry</h3>

    <p>We are working to add CI capability to this repository, so that the containers
    will be automatically built and stored in the github container registry. This
    will make building unnecessary for most cases, though users may build the containers
    themselves if they wish (e.g. for custom modifications).</p>

    <h3>

    <a id="user-content-more-usage-examples-and-documentation-especially-for-mpi-applications"
    class="anchor" href="#more-usage-examples-and-documentation-especially-for-mpi-applications"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>More
    usage examples and documentation, especially for MPI applications</h3>

    <p>We are still learning how to best use the HPC-ME containers with MPI appliations,
    so please check back.</p>

    <h3>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h3>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    <p>This project code is made available through GitHub but is managed by NOAA-GFDL

    at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1650907447.0
ParaToolsInc/exago-crusher:
  data_format: 2
  description: Spack-based deployment of ROCm enabled ExaGO for OLCF Crusher
  filenames:
  - spack.yaml
  full_name: ParaToolsInc/exago-crusher
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-exago-on-olcf-crusher\" class=\"anchor\" href=\"\
    #exago-on-olcf-crusher\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>ExaGO on OLCF Crusher</h1>\n<p>ROCm-enabled\
    \ ExaGO on OLCF Crusher using Spack</p>\n<h2>\n<a id=\"user-content-install-from-build-cache-example\"\
    \ class=\"anchor\" href=\"#install-from-build-cache-example\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Install\
    \ from Build Cache (Example)</h2>\n<ul>\n<li>View a demo video of these instructions\
    \ run at <a href=\"https://asciinema.org/a/508123\" rel=\"nofollow\">https://asciinema.org/a/508123</a>\n\
    </li>\n</ul>\n<pre><code>$crusher:~&gt; git clone https://github.com/ParaToolsInc/exago-crusher.git\n\
    $crusher:~&gt; cd exago-crusher\n\n$crusher:~/exago-crusher&gt; git clone https://github.com/spack/spack\n\
    $crusher:~/exago-crusher&gt; (cd spack &amp;&amp; git checkout dac31ef3c)\n\n\
    $crusher:~/exago-crusher&gt; export SPACK_DISABLE_LOCAL_CONFIG=1\n$crusher:~/exago-crusher&gt;\
    \ export SPACK_USER_CACHE_PATH=$(pwd)/_cache\n$crusher:~/exago-crusher&gt; . spack/share/spack/setup-env.sh\n\
    \n$crusher:~/exago-crusher&gt; spack mirror add paratools /gpfs/alpine/csc439/world-shared/E4S/ParaTools/exago\n\
    $crusher:~/exago-crusher&gt; spack buildcache keys -it\ngpg: key 4345F04B40005581:\
    \ public key \"University of Oregon - E4S\" imported\ngpg: Total number processed:\
    \ 1\ngpg:               imported: 1\ngpg: inserting ownertrust of 6\n\n$crusher:~/exago-crusher&gt;\
    \ time spack -e . concretize -f | tee concretize.log\n... output truncated for\
    \ brevity; see concretize.log in this repo for full output\nreal\t0m46.340s\n\
    user\t1m25.263s\nsys\t0m2.094s\n\n$crusher:~/exago-crusher&gt; time spack -e .\
    \ install --cache-only\n... output truncated for brevity\nreal\t7m40.626s\nuser\t\
    4m44.081s\nsys\t0m33.864s\n\n$crusher:~/exago-crusher&gt; spack find -lv exago\
    \ hiop ipopt coinhsl\n==&gt; 8 installed packages\n-- cray-sles15-zen3 / gcc@11.2.0\
    \ --------------------------------\nue74alo coinhsl@2015.06.23+blas\nmnelc7u exago@develop~cuda+hiop~ipo~ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nanahf5s exago@develop~cuda+hiop~ipo~ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\n2qog6zw exago@develop~cuda+hiop~ipo+ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\ndr3jlyb exago@develop~cuda+hiop~ipo+ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nwtqj2hu hiop@0.6.2~cuda~cusolver~deepchecking~ginkgo~ipo~jsrun~kron+mpi+raja+rocm~shared+sparse\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nrlw4qhu hiop@0.6.2~cuda~cusolver~deepchecking~ginkgo~ipo~jsrun+kron+mpi+raja+rocm~shared+sparse\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nufjh4v7 ipopt@3.14.5+coinhsl~debug+metis~mumps\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657663349.0
PawseySC/hpc-container-training:
  data_format: 2
  description: 'Training material on using containers in an HPC setting. '
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/hpc-container-training
  latest_release: null
  readme: '<h1>

    <a id="user-content-readme" class="anchor" href="#readme" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Readme</h1>

    '
  stargazers_count: 1
  subscribers_count: 5
  topics:
  - docker
  - singularity
  - hpc
  - pawsey
  - training-materials
  updated_at: 1650946836.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Configuration files for Spack at Pawsey
  filenames:
  - joey/environments/env_langs/spack.yaml
  - joey/environments/env_benchmarking/spack.yaml
  - joey/environments/env_astro/spack.yaml
  - setonix/environments/env_utils/spack.yaml
  - magnus/template_environment/spack.yaml
  - joey/environments/env_s3_clients/spack.yaml
  - setonix/environments/env_vis/spack.yaml
  - zeus/environment3_clingo/spack.yaml
  - joey/environments/env_vis/spack.yaml
  - setonix/environments/env_apps/spack.yaml
  - joey/environments/env_num_libs/spack.yaml
  - magnus/environment_iolib/spack.yaml
  - joey/environments/env_utils/spack.yaml
  - setonix/environments/env_langs/spack.yaml
  - setonix/environments/env_python/spack.yaml
  - magnus/environment_astro/spack.yaml
  - setonix/environments/env_bench/spack.yaml
  - setonix/environments/env_s3_clients/spack.yaml
  - joey/environments/env_apps/spack.yaml
  - setonix/environments/env_bio/spack.yaml
  - setonix/environments/env_devel/spack.yaml
  - setonix/environments/env_wrf/spack.yaml
  - joey/environments/env_python/spack.yaml
  - setonix/environments/env_num_libs/spack.yaml
  - joey/environments/env_bio/spack.yaml
  - joey/environments/env_roms/spack.yaml
  - joey/environments/env_wrf/spack.yaml
  - setonix/environments/env_roms/spack.yaml
  - zeus/environment2_python/spack.yaml
  - joey/environments/env_io_libs/spack.yaml
  - setonix/environments/env_io_libs/spack.yaml
  - magnus/environment_chem/spack.yaml
  - zeus/environment1_compchem/spack.yaml
  - setonix/environments/env_astro/spack.yaml
  - topaz/environment_compchem/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1>

    <a id="user-content-pawsey-spack-config" class="anchor" href="#pawsey-spack-config"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>pawsey-spack-config</h1>

    <p>Configuration files for Spack at Pawsey.</p>

    <h2>

    <a id="user-content-setonix-setup" class="anchor" href="#setonix-setup" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setonix setup</h2>

    <p>This can be found in the <code>setonix/</code> directory.<br>

    See <code>README.md</code> in there for further information.</p>

    <h2>

    <a id="user-content-other-setups" class="anchor" href="#other-setups" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Other setups</h2>

    <ul>

    <li>

    <code>joey/</code>: test deployment for the Setonix test system</li>

    <li>Current Pawsey systems

    <ul>

    <li><code>askapingest/</code></li>

    <li><code>garrawarla/</code></li>

    <li><code>magnus/</code></li>

    <li><code>topaz/</code></li>

    <li><code>zeus/</code></li>

    </ul>

    </li>

    <li>

    <code>examples/</code>: deployment examples and tests</li>

    <li>

    <code>deprecated/</code>: legacy deployments</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 10
  topics: []
  updated_at: 1641801068.0
SC-SGS/CPPuddle:
  data_format: 2
  description: Utility library to handle small, reusable pools of both device memory
    buffers (via allocators) and device executors (with multiple scheduling policies).
  filenames:
  - spack.yaml
  full_name: SC-SGS/CPPuddle
  latest_release: v0.1.0
  readme: "<h3>\n<a id=\"user-content-cppuddle\" class=\"anchor\" href=\"#cppuddle\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>CPPuddle</h3>\n<p><a href=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml\"\
    ><img src=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml/badge.svg\"\
    \ alt=\"ctest\" style=\"max-width:100%;\"></a>\n<a href=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/view/Octo-Tiger%20and%20Dependencies/job/CPPuddle/job/master/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f85055028a87ff41032206704d36fede5e5cc779d3369a6650f02d9d46676a45/68747470733a2f2f73696d7367732e696e666f726d6174696b2e756e692d7374757474676172742e64652f6a656e6b696e732f6275696c645374617475732f69636f6e3f6a6f623d4350507564646c652532466d617374657226636f6e6669673d616c6c6275696c6473\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=CPPuddle%2Fmaster&amp;config=allbuilds\"\
    \ style=\"max-width:100%;\"></a></p>\n<h4>\n<a id=\"user-content-purpose\" class=\"\
    anchor\" href=\"#purpose\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Purpose</h4>\n<p>This repository was initially\
    \ created to explore how to best use HPX and Kokkos together!\nFor fine-grained\
    \ GPU tasks, we needed a way to avoid excessive allocations of one-usage GPU buffers\
    \ (as allocations block the device for all streams) and creation/deletion of GPU\
    \ executors (as those are usually tied to a stream which is expensive to create\
    \ as well).</p>\n<p>We currently test/use CPPuddle in <a href=\"https://github.com/STEllAR-GROUP/octotiger\"\
    >Octo-Tiger</a>, together with <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\
    >HPX-Kokkos</a>.\nIn this use-case, allocating GPU buffers for all sub-grids in\
    \ advance would have wasted a lot of memory. On the other hand, unified memory\
    \ would have caused unnecessary GPU to CPU page migrations (as the old input data\
    \ gets overwritten anyway). Allocating buffers on-the-fly would have blocked the\
    \ device. Hence, we currently test this buffer management solution!</p>\n<h4>\n\
    <a id=\"user-content-tools-provided-by-this-repository\" class=\"anchor\" href=\"\
    #tools-provided-by-this-repository\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Tools provided by this repository</h4>\n\
    <ul>\n<li>Allocators that reuse previousely allocated buffers if available (works\
    \ with normal heap memory, pinned memory, aligned memory, CUDA/HIP device memory,\
    \ and Kokkos Views). Note that separate buffers do not coexist on a single chunk\
    \ of continuous memory, but use different allocations.</li>\n<li>Executor pools\
    \ and various scheduling policies (round robin, priority queue, multi-gpu), which\
    \ rely on reference counting to gauge the current load of a executor instead of\
    \ querying the device itself. Tested with CUDA, HIP and Kokkos executors provided\
    \ by HPX / HPX-Kokkos.</li>\n</ul>\n<h4>\n<a id=\"user-content-requirements\"\
    \ class=\"anchor\" href=\"#requirements\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Requirements</h4>\n<ul>\n<li>C++14</li>\n\
    <li>CMake (&gt;= 3.11)</li>\n<li>Optional (for the header-only utilities / test):\
    \ CUDA, Boost, <a href=\"https://github.com/STEllAR-GROUP/hpx\">HPX</a>, <a href=\"\
    https://github.com/kokkos/kokkos\">Kokkos</a>, <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\
    >HPX-Kokkos</a>\n</li>\n</ul>\n<p>The submodules can be used to obtain the optional\
    \ dependencies which are required for testing the header-only utilities. If these\
    \ tests are not required, the submodule (and the respective buildscripts in /scripts)\
    \ can be ignored safely.</p>\n<h4>\n<a id=\"user-content-build--install\" class=\"\
    anchor\" href=\"#build--install\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Build / Install</h4>\n<pre><code>\
    \  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle\
    \ -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF                     \
    \                                        \n  cmake --build /path/to/build -- -j4\
    \ VERBOSE=1                                                                  \
    \                                                                            \
    \                                                            \n  cmake --build\
    \ /path/to/build --target install  \n</code></pre>\n<p>If installed correctly,\
    \ cppuddle can be used in other cmake-based projects via</p>\n<pre><code>find_package(CPPuddle\
    \ REQUIRED)\n</code></pre>\n"
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1652160432.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.15.4/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-setup-on-scorec\" class=\"anchor\" href=\"#setup-on-scorec\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1>\n<a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" href=\"#rhel7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2>\n<a id=\"user-content-useful-commands\" class=\"anchor\"\
    \ href=\"#useful-commands\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>useful commands</h2>\n<p>regenerate lmod module\
    \ tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n<h2>\n<a id=\"\
    user-content-installing-new-packages\" class=\"anchor\" href=\"#installing-new-packages\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>installing new packages</h2>\n<p>Our spack repo is tracking the master\
    \ spack branch.  Spack package updates could result in additional installation\
    \ of packages with little or no package source code changes.  These additional\
    \ installs can be avoided when installing new packages by first examining the\
    \ output of the <code>spack spec -I</code> command.  If a utility/infrastructure\
    \ level package, such as cmake or mpich, is marked with a <code>[+]</code> symbol\
    \ in the leftmost column then it means that the existing install will be used.\
    \  If spack does not default to using the existing install you can append the\
    \ hash of the package to the spec command.</p>\n<p>For example, lets see what\
    \ happens when we ask for a pumi install using gcc 7.3.0</p>\n<pre><code>$ spack\
    \ spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643231013.0
SYSU-SCC/sysu-scc-spack-repo:
  data_format: 2
  description: Spack package repository maintained by Student Cluster Competition
    Team @ Sun Yat-sen University.
  filenames:
  - spack.yaml
  full_name: SYSU-SCC/sysu-scc-spack-repo
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-sysu-scc-spack-repo\" class=\"anchor\" href=\"\
    #sysu-scc-spack-repo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>sysu-scc-spack-repo</h1>\n<p><a href=\"https://spack.readthedocs.io/en/stable/repositories.html\"\
    \ rel=\"nofollow\">Spack</a> package <a href=\"./packages\">repository</a> maintained\
    \ by Student Cluster Competition Team @ Sun Yat-sen University.</p>\n<p>\u7531\
    \u4E2D\u5C71\u5927\u5B66\u8D85\u7B97\u961F\u7EF4\u62A4\u7684 <a href=\"https://spack.readthedocs.io/en/stable/repositories.html\"\
    \ rel=\"nofollow\">spack</a> package <a href=\"./packages\">repository</a>\uFF1B\
    \u540C\u65F6\uFF0C\u6211\u4EEC\u4E5F\u5411\u4E0A\u6E38\u63D0\u4EA4\u4E86\u5305\
    \u62EC cutlass\uFF08<a href=\"https://github.com/spack/spack/pull/31379\">spack#31379</a>\uFF09\
    \u3001py-altair\uFF08<a href=\"https://github.com/spack/spack/pull/31386\">spack#31386</a>\uFF09\
    \u5728\u5185\u7684 package\uFF0C\u5E76\u5DF2\u5408\u5E76\u5165\u4E3B\u7EBF\u3002\
    </p>\n<p>\u540C\u65F6\u63D0\u4F9B\u4E86\u4E00\u4E2A\u9762\u5411\u8D85\u7B97\u7ADE\
    \u8D5B\u7684<a href=\"./sysu-scc-spack-repo/share/sysu-scc-spack-repo/init-env.sh\"\
    >\u73AF\u5883\u90E8\u7F72\u811A\u672C</a>\uFF0C\u65E8\u5728\u6BD4\u8D5B\u671F\u95F4\
    \u5FEB\u901F\u6784\u5EFA\u4E00\u4E2A\u53EF\u4EE5\u4F7F\u7528\u7684 spack \u73AF\
    \u5883\uFF0C\u5176\u4E2D\u5305\u62EC\uFF1A</p>\n<ol>\n<li>\u4ECE\u6E90\u7801\u91CD\
    \u65B0\u7F16\u8BD1\u7684\u65E7\u7248\u672C <code>gcc</code>\uFF08\u6B64\u5904\u9009\
    \u62E9\u4E86 <code>gcc@7.5.0</code>\uFF0C\u4E5F\u53EF\u4EE5\u5728<a href=\"./share/sysu-scc-spack-repo/setup-env.sh\"\
    >\u8FD9\u4E2A\u6587\u4EF6</a>\u4E2D\u4FEE\u6539\u5BF9\u5E94\u7684\u73AF\u5883\u53D8\
    \u91CF\uFF09\u3002</li>\n<li>\u57FA\u4E8E <a href=\"https://spack.readthedocs.io/en/stable/environments.html\"\
    \ rel=\"nofollow\">spack environments</a> \u5FEB\u901F\u5B89\u88C5\u5FC5\u8981\
    \u7684\u8F6F\u4EF6\u73AF\u5883\uFF0C\u4F8B\u5982 <code>mpi</code> \u7B49\u3002\
    \n<ul>\n<li>\u9700\u8981\u6CE8\u610F\u7684\u662F\uFF0C\u6B64\u5904\u7684 <a href=\"\
    ./spack.yaml\">spack.yaml</a> \u4EC5\u4F5C\u4E3A\u793A\u4F8B\uFF0C\u5E76\u975E\
    \u4E2D\u5927\u8D85\u7B97\u961F\u5728\u6BD4\u8D5B\u4E2D\u4F7F\u7528\u7684\u7248\
    \u672C\u3002\u53EF\u4EE5\u53C2\u7167 <a href=\"https://spack.readthedocs.io/en/stable/environments.html#spack-yaml\"\
    \ rel=\"nofollow\">spack \u6587\u6863</a>\uFF0C\u6253\u5305\u7B26\u5408\u5B9E\u9645\
    \u9700\u8981\u7684\u8F6F\u4EF6\u73AF\u5883\u3002</li>\n</ul>\n</li>\n<li>\u57FA\
    \u4E8E <a href=\"https://github.com/SYSU-SCC/sysu-scc-spack-repo/actions\">GitHub\
    \ Actions</a> \u7684\u6784\u5EFA\u6D4B\u8BD5\uFF0C\u4FDD\u969C\u811A\u672C\u7684\
    \u4EE3\u7801\u8D28\u91CF\u3002</li>\n</ol>\n<p>\u540C\u6837\u6B22\u8FCE\u5176\u4ED6\
    \u5B66\u6821\u4F7F\u7528\uFF0C\u6B22\u8FCE<a href=\"https://github.com/SYSU-SCC/sysu-scc-spack-repo\"\
    ><img src=\"https://camo.githubusercontent.com/8f5080e7e91e30b74cbff3785fb9df00a90a1f037e01b9a1c4381152d96b582d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f535953552d5343432f737973752d7363632d737061636b2d7265706f2e737667\"\
    \ alt=\"Stars\" data-canonical-src=\"https://img.shields.io/github/stars/SYSU-SCC/sysu-scc-spack-repo.svg\"\
    \ style=\"max-width:100%;\"></a><a href=\"https://github.com/SYSU-SCC/sysu-scc-spack-repo/issues\"\
    ><img src=\"https://camo.githubusercontent.com/848ed52ef2de9e7d7c1ba55df59461f0625d496356678db1fd63539ba08caea5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f535953552d5343432f737973752d7363632d737061636b2d7265706f2e737667\"\
    \ alt=\"Issues\" data-canonical-src=\"https://img.shields.io/github/issues/SYSU-SCC/sysu-scc-spack-repo.svg\"\
    \ style=\"max-width:100%;\"></a><a href=\"https://github.com/SYSU-SCC/sysu-scc-spack-repo/pulls\"\
    ><img src=\"https://camo.githubusercontent.com/d983ef658bcd27fc984f73cd7ed8ba713839dca01aeed699929d4ed7e7d8282e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f535953552d5343432f737973752d7363632d737061636b2d7265706f\"\
    \ alt=\"Issues-pr\" data-canonical-src=\"https://img.shields.io/github/issues-pr/SYSU-SCC/sysu-scc-spack-repo\"\
    \ style=\"max-width:100%;\"></a>\uFF01\u53CB\u597D\u7684\u8D85\u7B97\u6BD4\u8D5B\
    \u73AF\u5883\uFF0C\u7531\u4F60\u6211\u5171\u5EFA\uFF5E</p>\n<h2>\n<a id=\"user-content-how-to-use\"\
    \ class=\"anchor\" href=\"#how-to-use\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to use</h2>\n<h3>\n<a id=\"\
    user-content-\u4ECE\u96F6\u5F00\u59CB\" class=\"anchor\" href=\"#%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>\u4ECE\u96F6\u5F00\u59CB</h3>\n<p>\u6700\u5C0F\u5316\u914D\u7F6E\u4E00\
    \u4E2A\u53EF\u4EE5\u4F7F\u7528\u7684 spack\uFF0C\u9700\u8981\u7684\u8F6F\u4EF6\
    \u4F9D\u8D56\u53EF\u4EE5\u53C2\u8003 <a href=\"./Dockerfile\">Dockerfile</a>\u3002\
    </p>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/SYSU-SCC/sysu-scc-spack-repo\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> \u53EA\u4F9D\u8D56\u8FD9\u4E00\
    \u4E2A\u73AF\u5883\u53D8\u91CF\uFF0C\u53EF\u4EE5\u653E\u8FDB ~/.bashrc</span>\n\
    <span class=\"pl-k\">export</span> SCC_SETUP_ENV=<span class=\"pl-s\"><span class=\"\
    pl-pds\">$(</span>realpath sysu-scc-spack-repo/share/sysu-scc-spack-repo/setup-env.sh<span\
    \ class=\"pl-pds\">)</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> \u521D\u59CB\u5316</span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>dirname <span class=\"pl-smi\">${SCC_SETUP_ENV}</span><span class=\"\
    pl-pds\">)</span></span>/init-env.sh\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> \u540E\u7EED\u6BCF\u6B21\u53EA\u9700\u8981\u6267\u884C\u8FD9\u4E00\u53E5\
    \u5373\u53EF\u4F7F\u7528\u914D\u597D\u7684\u73AF\u5883</span>\n<span class=\"\
    pl-c1\">.</span> <span class=\"pl-smi\">${SCC_SETUP_ENV}</span></pre></div>\n\
    <h3>\n<a id=\"user-content-\u96C6\u6210\u8FDB\u5DF2\u6709\u7684-spack-\u73AF\u5883\
    \" class=\"anchor\" href=\"#%E9%9B%86%E6%88%90%E8%BF%9B%E5%B7%B2%E6%9C%89%E7%9A%84-spack-%E7%8E%AF%E5%A2%83\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>\u96C6\u6210\u8FDB\u5DF2\u6709\u7684 spack \u73AF\u5883</h3>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/SYSU-SCC/sysu-scc-spack-repo\n\
    spack repo add --scope=site sysu-scc-spack-repo\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> A Simple Test</span>\nspack env create sysu-scc sysu-scc-spack-repo/spack.yaml\n\
    spack env activate -p sysu-scc\nspack install\nspack env deactivate</pre></div>\n\
    <h3>\n<a id=\"user-content-\u6D4B\u8BD5\u662F\u5426\u80FD\u7528\" class=\"anchor\"\
    \ href=\"#%E6%B5%8B%E8%AF%95%E6%98%AF%E5%90%A6%E8%83%BD%E7%94%A8\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\u6D4B\
    \u8BD5\u662F\u5426\u80FD\u7528</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack install sysu-scc.hpl-ai ^blaspp+openmp ^openblas threads=openmp ^mpich\n\
    spack load hpl-ai\ncp <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>spack\
    \ location -i hpl-ai<span class=\"pl-pds\">)</span></span>/bin/HPL.dat HPL.dat\n\
    OMP_NUM_THREADS=2 <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which mpirun<span\
    \ class=\"pl-pds\">)</span></span> -n 4 xhpl_ai</pre></div>\n<h3>\n<a id=\"user-content-\u5728\
    -docker-\u4E2D\u6D4B\u8BD5\" class=\"anchor\" href=\"#%E5%9C%A8-docker-%E4%B8%AD%E6%B5%8B%E8%AF%95\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>\u5728 docker \u4E2D\u6D4B\u8BD5</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>docker pull wukan0621/sccenv\ndocker run \\\n  --name sccenv \\\n  -it wukan0621/sccenv\
    \ \\\n  bash\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> \u7136\u540E\
    \u5728 docker \u4E2D\u68C0\u67E5</span>\n<span class=\"pl-c1\">.</span> <span\
    \ class=\"pl-smi\">${SCC_SETUP_ENV}</span>\nspack find</pre></div>\n<h2>\n<a id=\"\
    user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>This project is part of Spack. Spack is distributed under the terms of both\
    \ the\nMIT license and the Apache License (Version 2.0). Users may choose either\n\
    license, at their option.</p>\n<p>All new contributions must be made under both\
    \ the MIT and Apache-2.0 licenses.</p>\n<p>See LICENSE-MIT, LICENSE-APACHE, COPYRIGHT,\
    \ and NOTICE for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-811652</p>\n"
  stargazers_count: 3
  subscribers_count: 1
  topics: []
  updated_at: 1651130675.0
SouthernMethodistUniversity/mp_testing:
  data_format: 2
  description: null
  filenames:
  - mp/testing/01_spack/spack_lammps.yaml
  - mp/testing/05_openmm/spack.yaml
  - mp/testing/01_spack/spack_nvhpc.yaml
  - mp/testing/08_pytorch/spack.yaml
  full_name: SouthernMethodistUniversity/mp_testing
  latest_release: null
  readme: '<h1>

    <a id="user-content-notes" class="anchor" href="#notes" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h1>

    <p><strong>All code in this repo is for testing. The code may not work and may
    change. Pull requests and issues welcome.</strong></p>

    <p>See <a href="quick_start_notes.md">Quick Start Notes</a> for a short overview
    of MP usage.</p>

    <h2>

    <a id="user-content-usage-example" class="anchor" href="#usage-example" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage Example</h2>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/SouthernMethodistUniversity/mp_testing.git

    <span class="pl-c1">cd</span> mp_testing/demos/00_nemo

    ./submit_jobs.sh</pre></div>

    <h2>

    <a id="user-content-applications" class="anchor" href="#applications" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Applications</h2>

    <ul>

    <li>LAMMPS (NGC)</li>

    <li>AMBER</li>

    <li>NAMD (NGC)</li>

    <li>OpenMM</li>

    <li>Gaussian</li>

    <li>VASP</li>

    <li>CRYSTAL</li>

    <li>Q-Chem</li>

    <li>Quantum Espresso</li>

    </ul>

    <h2>

    <a id="user-content-analysis-tools" class="anchor" href="#analysis-tools" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Analysis Tools</h2>

    <ul>

    <li>Memory profiling</li>

    <li>Performance profiling</li>

    </ul>

    <h2>

    <a id="user-content-librariesapis" class="anchor" href="#librariesapis" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Libraries/APIs</h2>

    <ul>

    <li>Raja</li>

    <li>Magma</li>

    <li>heFFTe</li>

    <li>Pandas</li>

    <li>NumPy</li>

    <li>TensorFlow</li>

    <li>PyTorch</li>

    <li>DALI</li>

    </ul>

    <h2>

    <a id="user-content-languages" class="anchor" href="#languages" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Languages</h2>

    <ul>

    <li>C</li>

    <li>C++</li>

    <li>Python</li>

    <li>Some custom layer in C++/CUDA</li>

    <li>Fortran</li>

    <li>CUDA Fortran</li>

    <li>Julia</li>

    </ul>

    <h2>

    <a id="user-content-molecular-dynamics" class="anchor" href="#molecular-dynamics"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Molecular
    Dynamics</h2>

    <ul>

    <li>OpenMM</li>

    <li>AMBER</li>

    <li>Desmond</li>

    <li>GROMACS</li>

    <li>Mentioned MIC modes?</li>

    <li>NGC for Keras/TF and Pytorch</li>

    </ul>

    <h2>

    <a id="user-content-issues" class="anchor" href="#issues" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Issues</h2>

    <ul>

    <li>Can''t run enroot images directly via <code>enroot start hello_world.sqsh</code>.
    The OS

    needs squashfuse and fuse-overlayfs installed. I installed these on Easley and

    it works.</li>

    <li>Custom build and final images for containerized Spack environments fails due

    to apparently assuming that Spack already exists. See: <code>01_spack/spack_nvhpc.yaml</code>.</li>

    <li>Spack-blessed NVIDIA container fails to build due to public key error. See:
    <code>01_spack/spack_lammps.yaml</code>.</li>

    <li>

    <code>export ENROOT_MOUNT_HOME=1</code> to bind $HOME.</li>

    <li>Default flags and <code>target=zen2</code> gave LAMMPS run times of 4:44,
    while <code>target=zen2 cppflags=-O3</code>

    </li>

    <li>Running containers or non-hpc-x MPI produces warnings about <code>Unknown
    interface name</code> /

    <code>An invalid value was given for btl_tcp_if_include</code>. It appears not
    to see the Mellanox / IB correctly?</li>

    </ul>

    <h2>

    <a id="user-content-maybe-useful" class="anchor" href="#maybe-useful" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Maybe Useful</h2>

    <ul>

    <li><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/gpu-applications-catalog.pdf"
    rel="nofollow">https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/gpu-applications-catalog.pdf</a></li>

    <li><a href="https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html"
    rel="nofollow">https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html</a></li>

    <li><a href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html"
    rel="nofollow">https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html</a></li>

    <li><a href="https://secure.cci.rpi.edu/wiki/" rel="nofollow">https://secure.cci.rpi.edu/wiki/</a></li>

    </ul>

    <h2>

    <a id="user-content-things-we-need-to-plan-for" class="anchor" href="#things-we-need-to-plan-for"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Things
    we need to plan for</h2>

    <ul>

    <li>How and when do we decide we''re updating Nvidia Drivers / Cuda. I think we
    need to be very clear about this if we''re not going to maintain the latest and
    greatest. (we''re currently on 11.4, but 11.7 and associated drivers are available)</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1656601332.0
SouthernMethodistUniversity/msds_hpc:
  data_format: 2
  description: null
  filenames:
  - classes/03_2/spack.yaml
  - classes/04_2/spack_containers/spack.yaml
  - classes/06_2/spack_20.04_mkl.yaml
  - classes/06_2/spack_20.04_openblas.yaml
  full_name: SouthernMethodistUniversity/msds_hpc
  latest_release: null
  readme: '<h1>

    <a id="user-content-ds-7347-high-performance-computing-hpc-and-data-science" class="anchor"
    href="#ds-7347-high-performance-computing-hpc-and-data-science" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>DS 7347 High-Performance
    Computing (HPC) and Data Science</h1>

    <h2>

    <a id="user-content-assignments" class="anchor" href="#assignments" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Assignments</h2>

    <table>

    <thead>

    <tr>

    <th align="left">Key</th>

    <th align="left">Value</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="left">A</td>

    <td align="left">Assignment</td>

    </tr>

    <tr>

    <td align="left">L</td>

    <td align="left">Lab</td>

    </tr>

    <tr>

    <td align="left">P</td>

    <td align="left">Project</td>

    </tr>

    </tbody>

    </table>

    <table>

    <thead>

    <tr>

    <th align="left">Assignment</th>

    <th align="left">Issued</th>

    <th align="left">Due</th>

    <th align="left">Deliverable</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="left">A1</td>

    <td align="left">04-26</td>

    <td align="left">NA</td>

    <td align="left">Fork class repo.</td>

    </tr>

    <tr>

    <td align="left">A2</td>

    <td align="left">04-28</td>

    <td align="left">05-03</td>

    <td align="left"><code>assignments/assignment_02.md</code></td>

    </tr>

    <tr>

    <td align="left">A3</td>

    <td align="left">05-05</td>

    <td align="left">NA</td>

    <td align="left">Detail the CPU, GPU, memory, and hard drive for your own computer.</td>

    </tr>

    <tr>

    <td align="left">A4.1</td>

    <td align="left">05-10</td>

    <td align="left">05-17</td>

    <td align="left"><code>assignments/assignment_04.sh</code></td>

    </tr>

    <tr>

    <td align="left">L1</td>

    <td align="left">05-12</td>

    <td align="left">05-19</td>

    <td align="left"><code>assignments/lab_01.{yaml,md}</code></td>

    </tr>

    <tr>

    <td align="left">A4.2</td>

    <td align="left">05-17</td>

    <td align="left">05-24</td>

    <td align="left"><code>assignments/assignment_04.dockerfile</code></td>

    </tr>

    <tr>

    <td align="left">L2</td>

    <td align="left">05-19</td>

    <td align="left">05-26</td>

    <td align="left"><code>assignments/lab_02.{dockerfile,png,jpg}</code></td>

    </tr>

    <tr>

    <td align="left">A5.1</td>

    <td align="left">05-24</td>

    <td align="left">05-31</td>

    <td align="left"><code>assignments/assignment_05.out</code></td>

    </tr>

    <tr>

    <td align="left">P1</td>

    <td align="left">05-26</td>

    <td align="left">06-02</td>

    <td align="left"><code>project/proposal.md</code></td>

    </tr>

    <tr>

    <td align="left">L3</td>

    <td align="left">06-07</td>

    <td align="left">06-21</td>

    <td align="left"><code>assignments/lab_03.{yaml,sh,make or cmake}</code></td>

    </tr>

    <tr>

    <td align="left">P2</td>

    <td align="left">06-09</td>

    <td align="left">06-16</td>

    <td align="left">Create new GitHub repo from project template.</td>

    </tr>

    <tr>

    <td align="left">P3</td>

    <td align="left">06-16</td>

    <td align="left">06-21</td>

    <td align="left">Prototype of multi-job Slurm submit script.</td>

    </tr>

    <tr>

    <td align="left">A5.2</td>

    <td align="left">06-21</td>

    <td align="left">06-23</td>

    <td align="left"><code>assignments/assignment_05.txt</code></td>

    </tr>

    <tr>

    <td align="left">P4</td>

    <td align="left">06-23</td>

    <td align="left">06-28</td>

    <td align="left">Implement one subtask of your workflow using "easiest" installation
    path.</td>

    </tr>

    <tr>

    <td align="left">P5</td>

    <td align="left">06-30</td>

    <td align="left">NA</td>

    <td align="left">Explore various file formats for your data and compare performance.</td>

    </tr>

    <tr>

    <td align="left">P6</td>

    <td align="left">07-05</td>

    <td align="left">07-12</td>

    <td align="left">Complete non-optimized and basic workflow, reduce data or analysis
    complexity if needed.</td>

    </tr>

    <tr>

    <td align="left">P7</td>

    <td align="left">07-14</td>

    <td align="left">07-19</td>

    <td align="left">Report three targets for optimization and baseline performance</td>

    </tr>

    <tr>

    <td align="left">P8</td>

    <td align="left">07-19</td>

    <td align="left">07-28</td>

    <td align="left">Implement initial improvements for your three optimization targets</td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657068578.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/runner/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64-oneapi/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64/spack.yaml
  - docker-recipes/runner/rhel8-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu18.04-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu22.04-x86_64/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a href="figures/SDKdefinition1.png" target="_blank" rel="noopener noreferrer"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width:100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 18
  subscribers_count: 6
  topics: []
  updated_at: 1644561389.0
adamqc/devcontainer:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: adamqc/devcontainer
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1646725990.0
akhilred36/gameOfLifeKokkos:
  data_format: 2
  description: Game of Life implementation in Kokkos.
  filenames:
  - spack.yaml
  full_name: akhilred36/gameOfLifeKokkos
  latest_release: null
  readme: '<h1>

    <a id="user-content-gameoflifekokkos" class="anchor" href="#gameoflifekokkos"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>gameOfLifeKokkos</h1>

    <p>Game of Life implementation in Kokkos with MPI.</p>

    <h2>

    <a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <ul>

    <li>GCC&gt;=7.5.0</li>

    <li>CUDA&gt;=11.2.0</li>

    <li>Kokkos&gt;=3.5.00 with cuda and nvcc_wrapper</li>

    <li>OpenMPI&gt;=4.1.2 with cuda</li>

    <li>CMake&gt;=3.10</li>

    </ul>

    <h2>

    <a id="user-content-install-prerequisites-into-a-spack-environment" class="anchor"
    href="#install-prerequisites-into-a-spack-environment" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Install prerequisites
    into a spack environment:</h2>

    <div class="highlight highlight-source-shell"><pre>spack env create <span class="pl-k">&lt;</span>name<span
    class="pl-k">&gt;</span> spack.yaml</pre></div>

    <div class="highlight highlight-source-shell"><pre>spack env activate <span class="pl-k">&lt;</span>name<span
    class="pl-k">&gt;</span></pre></div>

    <div class="highlight highlight-source-shell"><pre>spack install</pre></div>

    <h2>

    <a id="user-content-building" class="anchor" href="#building" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <h3>

    <a id="user-content-initial-setup" class="anchor" href="#initial-setup" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Initial setup:</h3>

    <div class="highlight highlight-source-shell"><pre>mkdir build <span class="pl-k">&amp;&amp;</span>
    mkdir data</pre></div>

    <h3>

    <a id="user-content-compile" class="anchor" href="#compile" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compile:</h3>

    <div class="highlight highlight-source-shell"><pre>make clean <span class="pl-k">&amp;&amp;</span>
    make</pre></div>

    <h3>

    <a id="user-content-clean-generated-log-files" class="anchor" href="#clean-generated-log-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Clean
    generated log files:</h3>

    <div class="highlight highlight-source-shell"><pre>make cleandata</pre></div>

    <h2>

    <a id="user-content-running" class="anchor" href="#running" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running</h2>

    <p>Run the following in the build directory:</p>

    <h3>

    <a id="user-content-format" class="anchor" href="#format" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Format:</h3>

    <div class="highlight highlight-source-shell"><pre>mpirun -n <span class="pl-k">&lt;</span>numTasks<span
    class="pl-k">&gt;</span> ./gol <span class="pl-k">&lt;</span>meshSize<span class="pl-k">&gt;</span>
    <span class="pl-k">&lt;</span>numIterations<span class="pl-k">&gt;</span> <span
    class="pl-k">&lt;</span>coord1X coord1Y<span class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>coord2X
    coord2Y<span class="pl-k">&gt;</span> .... <span class="pl-k">&lt;</span>coordNX
    coordNY<span class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>print<span
    class="pl-k">&gt;</span></pre></div>

    <h3>

    <a id="user-content-example-runs" class="anchor" href="#example-runs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example runs:</h3>

    <p>4 tasks, mesh size 32, 100 iterations, (10, 10) (10, 11) (10, 13) as active
    cells, and log enabled:</p>

    <div class="highlight highlight-source-shell"><pre>mpirun -n 4 ./gol 32 100 10
    10 10 11 10 13 1</pre></div>

    <p>4 tasks, mesh size 32, 100 iterations, (10, 10) (10, 11) (10, 13) as active
    cells, and log disabled:</p>

    <div class="highlight highlight-source-shell"><pre>mpirun -n 4 ./gol 32 100 10
    10 10 11 10 13 0</pre></div>

    <h2>

    <a id="user-content-interpreting-logs" class="anchor" href="#interpreting-logs"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Interpreting
    logs:</h2>

    <p>The logs are written into the directory data/. The naming convention used is
    <code>&lt;rank&gt;_&lt;iter&gt;</code>. For example, to view the state of a mesh
    of rank 0 and iteration 12, run:</p>

    <div class="highlight highlight-source-shell"><pre>cat 0_12</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649796861.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent8/envs/solhawk/spack.yaml
  - cent8/envs/avx2/lusoft/spack.yaml
  - cent8/envs/x86_64/spack.yaml
  - cent8/envs/avx/lusoft/spack.yaml
  - cent7/python_376/spack.yaml
  - cent8/envs/avx/rproject/spack.yaml
  - cent7/library/spack.yaml
  - cent8/envs/avx512/lusoft/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-environments" class="anchor" href="#spack-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPACK
    Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2>

    <a id="user-content-software-deployment-for-centos-8x" class="anchor" href="#software-deployment-for-centos-8x"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3>

    <a id="user-content-compilers" class="anchor" href="#compilers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3>

    <a id="user-content-lu-software" class="anchor" href="#lu-software" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LU Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4>

    <a id="user-content-available-environments" class="anchor" href="#available-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    Environments</h4>

    <h5>

    <a id="user-content-solhawk" class="anchor" href="#solhawk" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-avxavx2avx512" class="anchor" href="#avxavx2avx512" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-python-and-r-packages" class="anchor" href="#python-and-r-packages"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Python
    and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-x86_64" class="anchor" href="#x86_64" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2>

    <a id="user-content-centos-7x-software" class="anchor" href="#centos-7x-software"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CentOS
    7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657632897.0
arcaneframework/containers:
  data_format: 2
  description: Containers with Arcane and Alien
  filenames:
  - spack/envs/all/spack.yaml
  - spack/envs/alien/spack.yaml
  full_name: arcaneframework/containers
  latest_release: null
  readme: '<h1>

    <a id="user-content-containers" class="anchor" href="#containers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>containers</h1>

    <p>Containers with Arcane and Alien</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1637878998.0
ashermancinelli/oci-builder:
  data_format: 2
  description: Repo to use free github actions to build my docker containers in kaniko
  filenames:
  - spack.yaml
  full_name: ashermancinelli/oci-builder
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1630966496.0
buildtesters/buildtest-nersc:
  data_format: 2
  description: null
  filenames:
  - buildspecs/apps/e4s/22.02/spack.yaml
  full_name: buildtesters/buildtest-nersc
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-buildtest-nersc\" class=\"anchor\" href=\"#buildtest-nersc\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>buildtest-nersc</h1>\n<p>This repository contains tests for Cori and\
    \ Perlmutter using <a href=\"https://buildtest.readthedocs.io/en/devel/\" rel=\"\
    nofollow\">buildtest</a> framework. A mirror of this repository is located on\
    \ GitHub at <a href=\"https://github.com/buildtesters/buildtest-nersc\">https://github.com/buildtesters/buildtest-nersc</a>\
    \ that is public facing.</p>\n<h2>\n<a id=\"user-content-setup\" class=\"anchor\"\
    \ href=\"#setup\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Setup</h2>\n<p>To get started, please <a href=\"https://docs.nersc.gov/connect/\"\
    \ rel=\"nofollow\">connect to NERSC system</a> and clone this repo and buildtest:</p>\n\
    <pre><code>git clone https://github.com/buildtesters/buildtest.git\ngit clone\
    \ https://software.nersc.gov/NERSC/buildtest-nersc.git\n</code></pre>\n<p>Note\
    \ if you don't have access to Gitlab server you may clone the mirror on Github:</p>\n\
    <pre><code>git clone https://github.com/buildtesters/buildtest-nersc.git\n</code></pre>\n\
    <p>You will need python 3.7 or higher to <a href=\"https://buildtest.readthedocs.io/en/devel/installing_buildtest.html\"\
    \ rel=\"nofollow\">install buildtest</a>, on Cori/Perlmutter this can be done\
    \ by loading <strong>python</strong>\nmodule and create a conda environment as\
    \ shown below.</p>\n<pre><code>module load python\nconda create -n buildtest\n\
    conda activate buildtest\n</code></pre>\n<p>Now let's install buildtest, assuming\
    \ you have cloned buildtest in $HOME directory source the setup script. For csh\
    \ users you need to source <strong>setup.csh</strong></p>\n<pre><code>source ~/buildtest/setup.sh\n\
    \n# csh users\nsource ~/buildtest/setup.csh\n</code></pre>\n<p>Next, navigate\
    \ to <code>buildtest-nersc</code> directory and set environment <code>BUILDTEST_CONFIGFILE</code>\
    \ to point to <a href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/config.yml\"\
    \ rel=\"nofollow\">config.yml</a> which is the configuration file for NERSC system.</p>\n\
    <pre><code>cd buildtest-nersc\nexport BUILDTEST_CONFIGFILE=$(pwd)/config.yml\n\
    </code></pre>\n<p>Make sure the configuration is valid, this can be done by running\
    \ the following. buildtest will validate the configuration file with the JSON\
    \ schema :</p>\n<pre><code>buildtest config validate\n</code></pre>\n<p>Please\
    \ make sure you are using tip of <a href=\"https://github.com/buildtesters/buildtest/tree/devel\"\
    >devel</a> branch of buildtest when writing tests. You should sync your local\
    \ devel branch with upstream\nfork, for more details see <a href=\"https://buildtest.readthedocs.io/en/devel/contributing/code_contribution_guide.html\"\
    \ rel=\"nofollow\">contributing guide</a>.</p>\n<p>First time around you should\
    \ discover all buildspecs this can be done via <code>buildtest buildspec find</code>.\
    \  The command below will find\nand validate all buildspecs in the <strong>buildtest-nersc</strong>\
    \ repo and load them in buildspec cache. Note that one needs to specify <code>--root</code>\
    \ to specify location where\nall buildspecs are located, we have not configured\
    \ <a href=\"https://buildtest.readthedocs.io/en/devel/configuring_buildtest/overview.html#buildspec-roots\"\
    \ rel=\"nofollow\">buildspec_root</a> in the configuration file since we don't\
    \ have a central location where this repo will reside.</p>\n<pre><code>cd buildtest-nersc\n\
    buildtest buildspec find --root buildspecs --rebuild -q\n</code></pre>\n<p>The\
    \ buildspecs are loaded in buildspec cache file (JSON) that is used by <code>buildtest\
    \ buildspec find</code> for querying cache. Subsequent runs will\nread from cache.\
    \  For more details see <a href=\"https://buildtest.readthedocs.io/en/devel/gettingstarted/buildspecs_interface.html\"\
    \ rel=\"nofollow\">buildspec interface</a>.</p>\n<h2>\n<a id=\"user-content-building-tests\"\
    \ class=\"anchor\" href=\"#building-tests\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building Tests</h2>\n<p><strong>Note:\
    \ All tests are written in YAML using .yml extension</strong></p>\n<p>To build\
    \ tests use <code>buildtest build</code> command for example we build all tests\
    \ in <code>system</code> directory as follows</p>\n<pre><code>buildtest build\
    \ -b system/\n</code></pre>\n<p>You can specify multiple buildspecs either files\
    \ or directory via <code>-b</code> option</p>\n<pre><code>buildtest build -b slurm/partition.yml\
    \ -b slurmutils/\n</code></pre>\n<p>You can exclude a buildspec via <code>-x</code>\
    \ option this behaves same way as <code>-b</code> option so you can specify\n\
    a directory or filepath which could be absolute path, or relative path. This is\
    \ useful when\nyou want to run multiple tests grouped in directory but exclude\
    \ a few.</p>\n<pre><code>buildtest build -b slurm -x slurm/sinfo.yml\n</code></pre>\n\
    <p>buildtest can run tests via tags which can be useful when grouping tests, to\
    \ see a list of available tags you\ncan run: <code>buildtest buildspec find --tags</code></p>\n\
    <p>For instance if you want to run all <code>lustre</code> tests you can run the\
    \ following:</p>\n<pre><code>buildtest build --tags lustre\n</code></pre>\n<p>For\
    \ more details on buildtest test please see the <a href=\"https://buildtest.readthedocs.io/en/devel/getting_started.html\"\
    \ rel=\"nofollow\">buildtest tutorial</a></p>\n<h2>\n<a id=\"user-content-tags-breakdown\"\
    \ class=\"anchor\" href=\"#tags-breakdown\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Tags Breakdown</h2>\n<p>When\
    \ you write buildspecs, please make sure you attach one or more <code>tags</code>\
    \ to the test that way your test will get picked up during one of the CI checks.\
    \ Shown\nbelow is a summary of tag description</p>\n<ul>\n<li>\n<strong>daily</strong>\
    \ - this tag is used for running daily system checks using gitlab CI. Tests should\
    \ run relatively quick</li>\n<li>\n<strong>system</strong> - this tag is used\
    \ for classifying all system tests that may include: system configuration, servers,\
    \ network, cray tests. This tag should be used</li>\n<li>\n<strong>slurm</strong>\
    \ - this tag is used for slurm test that includes slurm utility check, slurm controller,\
    \ etc... This tag <strong>shouldn't</strong> be used for job submission that is\
    \ managed by <strong>jobs</strong> tag. The <code>slurm</code> tag tests should\
    \ be short running test that use a Local Executor.</li>\n<li>\n<strong>jobs</strong>\
    \ - this tag is used for testing slurm policies by submitting jobs to scheduler.</li>\n\
    <li>\n<strong>compile</strong> - this tag is used for compilation of application\
    \ (OpenMP, MPI, OpenACC, CUDA, upc, bupc, etc...)</li>\n<li>\n<strong>e4s</strong>\
    \ - this tag is used for running tests for E4S stack via <code>spack test</code>\
    \ or <a href=\"https://github.com/E4S-Project/testsuite\">E4S Testsuite</a>.</li>\n\
    <li>\n<strong>module</strong> - this tag is used for testing module system</li>\n\
    <li>\n<strong>benchmark</strong> - this tag is used for benchmark tests. This\
    \ can be application benchmarks, mini-benchmarks, kernels, etc...</li>\n</ul>\n\
    <p>You can see breakdown of tags and buildspec summary with the following commands</p>\n\
    <pre><code>buildtest buildspec summary\nbuildtest buildspec find --group-by-tags\n\
    </code></pre>\n<h2>\n<a id=\"user-content-querying-tests\" class=\"anchor\" href=\"\
    #querying-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Querying Tests</h2>\n<p>You can use <code>buildtest\
    \ report</code> and <code>buildtest inspect</code> to query tests. The commands\
    \ differ slightly and data is\nrepresented differently. The <code>buildtest report</code>\
    \ command will show output in tabular form and only show some of the metadata,\n\
    if you want to access the entire test record use <code>buildtest inspect</code>\
    \ command which displays the content in JSON format.\nFor more details on querying\
    \ tests see <a href=\"https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html\"\
    \ rel=\"nofollow\">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a></p>\n\
    <h2>\n<a id=\"user-content-ci-setup\" class=\"anchor\" href=\"#ci-setup\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CI\
    \ Setup</h2>\n<p>Tests are run on schedule basis with one schedule corresponding\
    \ to one gitlab job in <a href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a>. The scheduled pipelines are configured\
    \ in\n<a href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules</a>.\
    \ Each schedule has a variable <code>TESTNAME</code> defined to control which\
    \ pipeline\nis run since we have multiple gitlab jobs. In the <code>.gitlab-ci.yml</code>\
    \ we make use of conditional rules using <a href=\"https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic\"\
    \ rel=\"nofollow\">only</a>.</p>\n<p>The scheduled jobs are run at different intervals\
    \ (1x/day, 1x/week, etc...) at different times of day to avoid overloading the\
    \ system. The gitlab jobs\nwill run jobs based on tags, alternately some tests\
    \ may be defined by running all tests in a directory (<code>buildtest build -b\
    \ apps</code>). If you want to add a new\nscheduled job, please define a <a href=\"\
    https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules/new\" rel=\"\
    nofollow\">new schedule</a> with an appropriate time. The\n<code>target branch</code>\
    \ should be <code>devel</code> and define a unique variable used to distinguish\
    \ scheduled jobs. Next, create a job in <code>.gitlab-ci.yml</code> that references\
    \ the scheduled job and define variable <code>TESTNAME</code> in the scheduled\
    \ pipeline.</p>\n<h3>\n<a id=\"user-content-runner-settings\" class=\"anchor\"\
    \ href=\"#runner-settings\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Runner settings</h3>\n<p>This project is using\
    \ a custom runner hosted via user <a href=\"https://iris.nersc.gov/user/93315/info\"\
    \ rel=\"nofollow\">e4s</a> in order for all jobs to be run by user <em>e4s</em>.\
    \ The <strong>e4s</strong> user is a <a href=\"https://docs.nersc.gov/accounts/collaboration_accounts/\"\
    \ rel=\"nofollow\">collaboration account</a>, if you don't have access to collaboration\
    \ account, please contact the PI for project <a href=\"https://iris.nersc.gov/project/67107/info\"\
    \ rel=\"nofollow\">m3503</a> to see if you can be added to group.  If you are\
    \ logged in to Cori/Perlmutter you can run the following command to switch to\
    \ e4s user.</p>\n<pre><code>collabsu e4s\n</code></pre>\n<p>You will be prompted\
    \ to type your NERSC password for your user account.</p>\n<p>The <code>e4s</code>\
    \ user has two shell runners configured with this project. Please note that you\
    \ must be on the login node to the appropriate system to restart the runner</p>\n\
    <table>\n<thead>\n<tr>\n<th>System</th>\n<th>Runner Tag Name</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td>Cori</td>\n<td><code>tags: [cori-e4s]</code></td>\n</tr>\n\
    <tr>\n<td>Perlmutter</td>\n<td><code>tags: [perlmutter-e4s]</code></td>\n</tr>\n\
    </tbody>\n</table>\n<p>The runner can be started manually by running the following.</p>\n\
    <pre><code># Cori\nbash $HOME/cron/restart-cori.sh\n\n# Perlmutter\nbash $HOME/cron/restart-perlmutter.sh\n\
    </code></pre>\n<p>The gitlab-runner is the ECP fork runner which can be found\
    \ at <code>$HOME/nersc-ecp-staff-runner/</code>, and <code>gitlab-runner</code>\
    \ should be in <code>$PATH</code> when you login via <em>e4s</em> which is set\
    \ in <code>~/.bashrc</code> file.</p>\n<p>The runner is tied to a particular hostname\
    \ and is not run as a service, it is advisable to check/be notified when the runner\
    \ goes down. There is a cronjob setup on <code>cori01</code> to automatically\
    \ restart the gitlab runner if it goes down. Shown below is the crontab</p>\n\
    <pre><code># Crontab on Cori - cori01\ne4s@cori01:~/cron&gt; crontab -l\n0 * *\
    \ * * $HOME/cron/restart-cori.sh &gt;/dev/null  2&gt;&amp;1 \n</code></pre>\n\
    <p>All scheduled pipelines are run via <code>e4s</code> user your gitlab job must\
    \ specify the appropriate tag name. You can check registered runner at <a href=\"\
    https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/ci_cd\" rel=\"nofollow\"\
    >https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/ci_cd</a> under <code>Runners</code>\
    \ section. Please make sure <code>e4s</code> user has access to all the queues\
    \ required to run tests, this can be configured in <a href=\"https://iris.nersc.gov/\"\
    \ rel=\"nofollow\">iris</a>.</p>\n<h2>\n<a id=\"user-content-integrations\" class=\"\
    anchor\" href=\"#integrations\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Integrations</h2>\n<p>This project\
    \ has integration with Slack to notify CI builds to <a href=\"https://hpcbuildtest.slack.com\"\
    \ rel=\"nofollow\">buildtest Slack</a> at <strong>#buildtest-nersc</strong> workspace.\
    \ The integrations can be\nfound at <a href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations</a>.</p>\n\
    <p>This project has setup a push mirror to <a href=\"https://github.com/buildtesters/buildtest-nersc\"\
    >https://github.com/buildtesters/buildtest-nersc</a> which can be seen at <a href=\"\
    https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository\" rel=\"\
    nofollow\">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository</a>\n\
    under <strong>Mirroring Repositories</strong>. If the push mirror is not setup,\
    \ please add the mirror.</p>\n<h2>\n<a id=\"user-content-cdash\" class=\"anchor\"\
    \ href=\"#cdash\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>CDASH</h2>\n<p>buildtest will push test results to\
    \ <a href=\"https://www.kitware.com/cdash/project/about.html\" rel=\"nofollow\"\
    >CDASH</a> server\nat <a href=\"https://my.cdash.org/index.php?project=buildtest-nersc\"\
    \ rel=\"nofollow\">https://my.cdash.org/index.php?project=buildtest-nersc</a>\
    \ using <code>buildtest cdash upload</code> command.</p>\n<h2>\n<a id=\"user-content-contributing-guide\"\
    \ class=\"anchor\" href=\"#contributing-guide\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing Guide</h2>\n<p>To\
    \ contribute back you will want to make sure your buildspec is validated before\
    \ you contribute back, this could be\ndone by running test manually <code>buildtest\
    \ build</code> or see if buildspec is valid via <code>buildtest buildspec find</code>.\
    \ It\nwould be good to run your test and make sure it is working as expected,\
    \ you can view test detail using <code>buildtest inspect name &lt;testname&gt;</code>\
    \ or <code>buildtest inspect query &lt;testname&gt;</code>. For more\ndetails\
    \ on querying test please see <a href=\"https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html\"\
    \ rel=\"nofollow\">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a>.</p>\n\
    <p>If you want to contribute your tests, please see <a href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/CONTRIBUTING.md\"\
    \ rel=\"nofollow\">CONTRIBUTING.md</a></p>\n<h2>\n<a id=\"user-content-references\"\
    \ class=\"anchor\" href=\"#references\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>References</h2>\n<ul>\n<li>buildtest\
    \ documentation: <a href=\"https://buildtest.readthedocs.io/en/devel/\" rel=\"\
    nofollow\">https://buildtest.readthedocs.io/en/devel/</a>\n</li>\n<li>buildtest\
    \ schema docs: <a href=\"https://buildtesters.github.io/buildtest/\" rel=\"nofollow\"\
    >https://buildtesters.github.io/buildtest/</a>\n</li>\n<li>Getting Started: <a\
    \ href=\"https://buildtest.readthedocs.io/en/devel/getting_started.html\" rel=\"\
    nofollow\">https://buildtest.readthedocs.io/en/devel/getting_started.html</a>\n\
    </li>\n<li>Writing Buildspecs: <a href=\"https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html\"\
    \ rel=\"nofollow\">https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html</a>\n\
    </li>\n<li>Contributing Guide: <a href=\"https://buildtest.readthedocs.io/en/devel/contributing.html\"\
    \ rel=\"nofollow\">https://buildtest.readthedocs.io/en/devel/contributing.html</a>\n\
    </li>\n</ul>\n"
  stargazers_count: 4
  subscribers_count: 3
  topics:
  - buildtest
  updated_at: 1657142158.0
celeritas-project/celeritas:
  data_format: 2
  description: Celeritas is a new Monte Carlo transport code designed for high-performance
    simulation of high-energy physics detectors.
  filenames:
  - scripts/spack.yaml
  full_name: celeritas-project/celeritas
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-celeritas\" class=\"anchor\" href=\"#celeritas\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Celeritas</h1>\n<p>The Celeritas project implements HEP detector physics\
    \ on GPU accelerator\nhardware with the ultimate goal of supporting the massive\
    \ computational\nrequirements of LHC-HL upgrade.</p>\n<h1>\n<a id=\"user-content-installation-and-development\"\
    \ class=\"anchor\" href=\"#installation-and-development\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ and development</h1>\n<p>This project requires external dependencies to build\
    \ with full functionality.\nHowever, any combination of these requirements can\
    \ be omitted to enable\nlimited development on personal machines with fewer available\
    \ components.</p>\n<ul>\n<li>\n<a href=\"https://developer.nvidia.com/cuda-toolkit\"\
    \ rel=\"nofollow\">CUDA</a>: on-device computation</li>\n<li>an MPI implementation\
    \ (such as <a href=\"https://www.open-mpi.org\" rel=\"nofollow\">Open MPI</a>):\
    \ shared-memory parallelism</li>\n<li>\n<a href=\"https://root.cern\" rel=\"nofollow\"\
    >ROOT</a>: I/O</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">nljson</a>:\
    \ simple text-based I/O for\ndiagnostics and program setup</li>\n<li>\n<a href=\"\
    https://gitlab.cern.ch/VecGeom/VecGeom\" rel=\"nofollow\">VecGeom</a>: on-device\
    \ navigation of GDML-defined detector geometry</li>\n<li>\n<a href=\"https://geant4.web.cern.ch/support/download\"\
    \ rel=\"nofollow\">Geant4</a>: preprocessing physics data for a problem input</li>\n\
    <li>\n<a href=\"https://geant4.web.cern.ch/support/download\" rel=\"nofollow\"\
    >G4EMLOW</a>: EM physics model data</li>\n<li>\n<a href=\"http://hepmc.web.cern.ch/hepmc/\"\
    \ rel=\"nofollow\">HepMC3</a>: Event input</li>\n<li>\n<a href=\"http://swig.org\"\
    \ rel=\"nofollow\">SWIG</a>: limited set of Python wrappers for analyzing input\n\
    data</li>\n</ul>\n<p>Build/test dependencies are:</p>\n<ul>\n<li>\n<a href=\"\
    https://cmake.org\" rel=\"nofollow\">CMake</a>: build system</li>\n<li>\n<a href=\"\
    https://clang.llvm.org/docs/ClangFormat.html\" rel=\"nofollow\">clang-format</a>:\
    \ formatting enforcement</li>\n<li>\n<a href=\"https://github.com/google/googletest\"\
    >GoogleTest</a>: test harness</li>\n</ul>\n<h2>\n<a id=\"user-content-installing-with-spack\"\
    \ class=\"anchor\" href=\"#installing-with-spack\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing with\
    \ Spack</h2>\n<p><a href=\"https://github.com/spack/spack\">Spack</a> is an HPC-oriented\
    \ package manager that\nincludes numerous scientific packages, including those\
    \ used in HEP. An included\nSpack \"environment\" (at <code>scripts/dev/env/celeritas-{platform}.yaml</code>)\
    \ defines\nthe required prerequisites for this project.</p>\n<p>The script at\
    \ <code>scripts/dev/install-spack.sh</code> provides a \"one-button solution\"\
    \nto installing and activating the Spack prerequisites for building Celeritas.\n\
    Alternatively, you can manually perform the following steps:</p>\n<ul>\n<li>Clone\
    \ Spack following its <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">getting started instructions</a>\n</li>\n<li>Add CUDA to your\
    \ <code>$SPACK_ROOT/etc/spack/packages.yaml</code> file</li>\n<li>Run <code>spack\
    \ env create celeritas scripts/dev/env/celeritas-linux.yaml</code> (or\nreplace\
    \ <code>linux</code> with <code>darwin</code> if running on a mac); then <code>spack\
    \ -e celeritas concretize</code> and <code>spack -e celeritas install</code>\n\
    </li>\n<li>Run and add to your startup environment profile <code>spack env activate\
    \ celeritas</code>\n</li>\n<li>Configure Celeritas by creating a build directory\
    \ and running CMake (or\n<code>ccmake</code> for an interactive prompt for configuring\
    \ options).</li>\n</ul>\n<p>An example file for a <code>packages.yaml</code> that\
    \ defines an externally installed CUDA\non a system with an NVIDIA GPU that has\
    \ architecture capability 3.5 is thus:</p>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre><span class=\"pl-ent\">packages</span>:\n  <span class=\"pl-ent\">cuda</span>:\n\
    \    <span class=\"pl-ent\">paths</span>:\n      <span class=\"pl-ent\">cuda@10.2</span>:\
    \ <span class=\"pl-s\">/usr/local/cuda-10.2</span>\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">False</span>\n  <span class=\"pl-ent\"\
    >all</span>:\n    <span class=\"pl-ent\">variants</span>: <span class=\"pl-s\"\
    >cuda_arch=35</span></pre></div>\n<h2>\n<a id=\"user-content-configuring-and-building-celeritas\"\
    \ class=\"anchor\" href=\"#configuring-and-building-celeritas\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ and building Celeritas</h2>\n<p>To configure Celeritas, assuming the dependencies\
    \ you want are located in the\n<code>CMAKE_PREFIX_PATH</code> search path, and\
    \ other environment variables such as <code>CXX</code>\nare set, you should be\
    \ able to just run CMake and build:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">mkdir build</span>\n$ <span class=\"pl-s1\"><span\
    \ class=\"pl-c1\">cd</span> build <span class=\"pl-k\">&amp;&amp;</span> cmake\
    \ ..</span>\n$ <span class=\"pl-s1\">make</span></pre></div>\n<p>Ideally you will\
    \ build Celeritas with all dependencies to gain the full\nfunctionality of the\
    \ code, but there are circumstances in which you may not\nhave all the dependencies\
    \ or features available. By default, the CMake code in\nCeleritas queries available\
    \ packages and sets several <code>CELERITAS_USE_{package}</code>\noptions based\
    \ on what it finds, so you have a good chance of successfully\nconfiguring Celeritas\
    \ on the first go. Two optional components,\n<code>CELERITAS_BUILD_&lt;DEMOS|TESTS&gt;</code>,\
    \ will error in the configure if their required\ncomponents are missing, but they\
    \ will update the CMake cache variable so that\nthe next configure will succeed\
    \ (but with that component disabled).</p>\n<p>For a slightly more advanced but\
    \ potentially simpler setup, you can use the\nCMake presets provided by Celeritas\
    \ via the <code>CMakePresets.json</code> file for CMake\n3.21 and higher:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >cmake --preset=default</span></pre></div>\n<p>The three main options are \"minimal\"\
    , \"default\", and \"full\", which all set\ndifferent expectations for available\
    \ dependencies.</p>\n<p>If you want to add your own set of custom options and\
    \ flags, create a\n<code>CMakeUserPresets.json</code> file or, if you are a developer,\
    \ create a preset at\n<code>scripts/cmake-presets/${HOSTNAME%%.*}.json</code>\
    \ and call <code>scripts/build.sh {preset}</code> to create the symlink, configure\
    \ the preset, build, and test. See\n<a href=\"scripts/README.md\">the scripts\
    \ readme</a> for more details.</p>\n<p>If your CMake version is too old, you may\
    \ get an unhelpful message:</p>\n<pre><code>CMake Error: Could not read presets\
    \ from celeritas: Unrecognized \"version\" field\n</code></pre>\n<p>which is just\
    \ a poor way of saying the version in the <code>CMakePresets.json</code> file\n\
    is newer than that version knows how to handle.</p>\n<h2>\n<a id=\"user-content-commit-hooks\"\
    \ class=\"anchor\" href=\"#commit-hooks\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Commit hooks</h2>\n<p>Run <code>scripts/dev/install-commit-hooks.sh</code>\
    \ to install a git post-commit hook\nthat will amend each commit with clang-format\
    \ updates if necessary.</p>\n<h2>\n<a id=\"user-content-contributing\" class=\"\
    anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>See the <a href=\"\
    https://github.com/celeritas-project/celeritas/wiki/Development\">development\
    \ wiki\npage</a> for\nguidelines and best practices for code in the project.</p>\n\
    <p>The <a href=\"https://github.com/celeritas-project/celeritas/wiki/Code-design\"\
    >code design\npage</a> outlines\nthe basic physics design philosophy and classes,\
    \ and <a href=\"https://github.com/celeritas-project/celeritas-docs/tree/master/graphs\"\
    >the layout of some\nalgorithms and\nclasses</a>\nare available on the <code>celeritas-docs</code>\
    \ repo.</p>\n<p>All submissions to the Celeritas project are automatically licensed\
    \ under the\nterms of <a href=\"COPYRIGHT\">the project copyright</a> as formalized\
    \ by the <a href=\"https://docs.github.com/en/github/site-policy/github-terms-of-service#6-contributions-under-repository-license\"\
    >GitHub terms\nof service</a>.</p>\n"
  stargazers_count: 20
  subscribers_count: 9
  topics:
  - hep
  - cuda
  - computational-physics
  - monte-carlo
  updated_at: 1658598037.0
charmoniumQ/astrophysics-project:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: charmoniumQ/astrophysics-project
  latest_release: null
  readme: '<h1>

    <a id="user-content-neural-network-superresolving-for-cosmological-simulations"
    class="anchor" href="#neural-network-superresolving-for-cosmological-simulations"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Neural
    Network Superresolving for Cosmological Simulations</h1>

    <p>In this repository, I attempt to reproduce the analysis of <a href="https://arxiv.org/pdf/2111.06393.pdf"
    rel="nofollow">Schaurecker et

    al. 2021</a> on Enzo data (they use Illustris).</p>

    <h1>

    <a id="user-content-to-reproduce" class="anchor" href="#to-reproduce" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>To reproduce</h1>

    <p>The code <code>main.py</code> is intended to be run locally. It sends commands
    to the

    remote. You will need to modify this with your site-specific parameters. It

    should be the only file you need to modify.</p>

    <p>To set up the remote machine (should be capable of Slurm):</p>

    <div class="highlight highlight-source-shell"><pre>remote$ <span class="pl-c"><span
    class="pl-c">#</span> Install Spack on the remote</span>

    remote$ git clone -c feature.manyFiles=true https://github.com/spack/spack.git


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy spack.lock to the
    remote</span>

    remote$ spack/bin/spack environment create main4 spack.lock

    remote$ spack/bin/spack environment activate main4

    remote$ spack/bin/spack concretize

    remote$ spack/bin/spack install


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy envirment.yaml ot
    the remote</span>

    remote$ spack/bin/spack activate main4

    remote$ conda install --name main3 --file environment,yaml


    remote$ <span class="pl-c"><span class="pl-c">#</span> Ensure that Slurm works</span>

    remote$ sbatch --help</pre></div>

    <p>To set up the local machine:</p>

    <div class="highlight highlight-source-shell"><pre>locla$ <span class="pl-c"><span
    class="pl-c">#</span> Install conda</span>

    locla$ <span class="pl-c"><span class="pl-c">#</span> Install conda environment</span>

    local$ conda install --name main3 --file environment,yaml</pre></div>

    <p>You will need to configure SSH keys to the remote.</p>

    <p>Then you should be to run <code>main.py</code>. <code>main.py</code> runs the
    entire workflow. It is

    smart about not running a certain step if the data already exists. It also

    hashes the input parameters in the filename of the data, so it is unlikely to

    return stale data.</p>

    <p>The end result will end up in <code>output</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1650312591.0
eflows4hpc/workflow-registry:
  data_format: 2
  description: Registry to store workflow descriptions
  filenames:
  - rom_pillar_I/reduce_order_model/spack.yaml
  - minimal_workflow/wordcount/spack.yaml
  full_name: eflows4hpc/workflow-registry
  latest_release: null
  readme: "<p>#Workflow Registry</p>\n<p>This is a repository to store the Workflow\
    \ descriptions using the eFlows4HPC methodology. This description consist of at\
    \ least the TOSCA description of the worklfow, the code of the their different\
    \ steps and their required software per step.</p>\n<h2>\n<a id=\"user-content-repository-structure\"\
    \ class=\"anchor\" href=\"#repository-structure\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Repository structure</h2>\n<p>Workflow\
    \ descriptions have to be included inside this repository according to the following\
    \ structure.</p>\n<pre><code>workflow-registry\n  |- workflow_1\n  |    |- tosca\n\
    \  |    |    |- types.yml               TOSCA description of the different components\
    \ involved in the workflow\n  |    |       ... \n  |    |- step_1\n  |    |  \
    \  |- spack.yml               Sofware requirements for this workflow step as a\
    \ Spack environment specification \n  |    |    |- src                     PyCOMPSs\
    \ code of the workflow step\n  |    |       ...\n  |    |- step_2\n  |       \
    \  ....\n  |- workflow_2                                \n  |\t...\n\n</code></pre>\n\
    <h2>\n<a id=\"user-content-including-new-workflows\" class=\"anchor\" href=\"\
    #including-new-workflows\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Including new Workflows</h2>\n<p>To include\
    \ new workflows in the repository, first create a new fork of the repository and\
    \  include a new folder for the workflow with a subfolder for the TOSCA description\
    \ and the different workflow steps. Finally, create a pull request with the new\
    \ workflow description. This pull request will be reviewed and included in the\
    \ repository.</p>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1647595412.0
eth-cscs/spack-stack:
  data_format: 2
  description: fast spack builds on slow filesystem
  filenames:
  - packages/clang/spack.yaml
  - packages/gcc/spack.yaml
  - compilers/1-gcc/spack.yaml
  - packages/nvhpc/spack.yaml
  - packages/tools/spack.yaml
  - compilers/3-llvm/spack.yaml
  - compilers/2-gcc/spack.yaml
  full_name: eth-cscs/spack-stack
  latest_release: null
  readme: "<p>Bootstrap GCC, LLVM and NVHPC, and build an HPC software stack based\
    \ on\nOpenMPI, with a few unique features:</p>\n<ol>\n<li>parallel package builds\
    \ with single jobserver for all builds;</li>\n<li>avoiding relocation issues by\
    \ fixing the install path to a new directory <code>/some-dir</code> of choice\
    \ (no root access required);</li>\n<li>fast, in-memory builds.</li>\n</ol>\n<p><strong>Requirements</strong>:</p>\n\
    <ul>\n<li><code>spack</code></li>\n<li>\n<code>bwrap</code> (when not already\
    \ building inside a sandbox)</li>\n</ul>\n<p><strong>Usage</strong>:</p>\n<ol>\n\
    <li>Copy <code>Make.user.example</code> to <code>Make.user</code> and change some\
    \ variables<sup><a href=\"#fn-1\" id=\"user-content-fnref-1\">1</a></sup>.</li>\n\
    <li>Run <code>make -j$(nproc)</code> to bootstrap compilers and packages<sup><a\
    \ href=\"#fn-2\" id=\"user-content-fnref-2\">2</a></sup>.</li>\n<li>Run <code>make\
    \ store.squashfs</code> to bundle those in a squashfs file.</li>\n</ol>\n<p><strong>Unprivileged\
    \ mounts</strong></p>\n<p>The squashfs file can then be mounted using <a href=\"\
    https://github.com/eth-cscs/squashfs-mount\">squashfs-mount</a> or <code>squashfuse</code></p>\n\
    <p><strong>Generating modules</strong></p>\n<p>There's no <code>modules.yaml</code>\
    \ file right now, but generating modules goes along those lines:</p>\n<div class=\"\
    highlight highlight-source-yaml\"><pre><span class=\"pl-ent\">modules</span>:\n\
    \  <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-ent\"\
    >default:</span><span class=\"pl-pds\">'</span></span>:\n    <span class=\"pl-ent\"\
    >arch_folder</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >roots</span>:\n      <span class=\"pl-ent\">tcl</span>: <span class=\"pl-s\"\
    >/path/to/tcl/modules</span>\n    <span class=\"pl-ent\">enable</span>:\n    -\
    \ <span class=\"pl-s\">tcl</span>\n    <span class=\"pl-ent\">tcl</span>:\n  \
    \    <span class=\"pl-ent\">projections</span>:\n        <span class=\"pl-ent\"\
    >all</span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>{name}/{version}-{compiler.name}-{compiler.version}<span\
    \ class=\"pl-pds\">'</span></span>\n      <span class=\"pl-ent\">all</span>:\n\
    \        <span class=\"pl-ent\">autoload</span>: <span class=\"pl-s\">none</span>\n\
    \        <span class=\"pl-ent\">filter</span>:\n          <span class=\"pl-ent\"\
    >environment_blacklist</span>: <span class=\"pl-s\">['LD_LIBRARY_PATH', 'LIBRARY_PATH',\
    \ 'CPATH']</span></pre></div>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">spack module tcl refresh</span>\n<span class=\"pl-c1\"\
    >spack module tcl setdefault gcc@11</span></pre></div>\n<section>\n<ol>\n<li id=\"\
    user-content-fn-1\">\n<p>For reproducibility, build with a clean environment:\
    \ <code>env -i PATH=/usr/bin:/bin make ...</code>. <a href=\"#fnref-1\"><g-emoji\
    \ class=\"g-emoji\" alias=\"leftwards_arrow_with_hook\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/21a9.png\"\
    >\u21A9</g-emoji></a></p>\n</li>\n<li id=\"user-content-fn-2\">\n<p>A few variables\
    \ should be set in <code>Make.user</code>:</p>\n<ul>\n<li>\n<code>STORE</code>:\
    \ where to install packages;</li>\n<li>\n<code>SPACK</code>: what <code>spack</code>\
    \ to use;</li>\n<li>\n<code>SPACK_USER_CONFIG_PATH</code>: path to spack config\
    \ dir (e.g. <a href=\"config/hohgant\">config/hohgant</a>).</li>\n<li>\n<code>BWRAP</code>:\
    \ use bubblewrap for sandboxing and speed: see <code>Make.user.example</code>\
    \ for details.</li>\n<li>\n<code>SPACK_INSTALL_FLAGS</code>: specify more install\
    \ flags, like <code>--verbose</code>.</li>\n</ul>\n<a href=\"#fnref-2\"><g-emoji\
    \ class=\"g-emoji\" alias=\"leftwards_arrow_with_hook\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/21a9.png\"\
    >\u21A9</g-emoji></a>\n</li>\n</ol>\n</section>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1658141772.0
eugeneswalker/facility-spack:
  data_format: 2
  description: null
  filenames:
  - arcticus/develop/spack.yaml
  - crusher/22.05/PrgEnv-amd/spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/separately.wo-failures.spack.yaml
  - perlmutter/22.05/mvapich2/spack.yaml
  - uo-containers/22.05/production/base/aarch64-cuda.spack.yaml
  - uo-containers/22.05/components/e4s-cpu-builder.spack.yaml
  - crusher/develop/PrgEnv-cray/base/spack.yaml
  - crusher/22.05/PrgEnv-gnu/spack.yaml
  - uo-containers/22.05/archives/spack-rocm.spack.yaml
  - uo-containers/22.05/components/e4s-cuda-builder-ppc64le-noextern.spack.yaml
  - uo-containers/22.05/production/e4s-22.05-oneapi.spack.yaml
  - perlmutter/develop/spack.yaml
  - crusher/22.02/PrgEnv-amd/spack.yaml
  - uo-containers/22.05/components/e4s-oneapi-builder.spack.yaml
  - uo-containers/22.05/archives/spack-full-clang.spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/together.w-failures.spack.yaml
  - arcticus/experimental/spack.yaml
  - crusher/22.05/PrgEnv-cray/failures/spack.yaml
  - uo-containers/22.05/production/e4s-22.05-cuda-ppc64le-noextern.spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/together.wo-failures.spack.yaml
  - frontera/22.05/spack.yaml
  - aws/paratools/parallelcluster-3.1.4/spack.yaml
  - uo-containers/22.05/production/base/amd64-rocm.spack.yaml
  - uo-containers/22.05/components/save/e4s-oneapi-builder.spack.yaml
  - crusher/22.02/PrgEnv-cray/spack.yaml
  - arcticus/22.05/failures/spack.yaml
  - uo-containers/22.05/production/e4s-22.05-cuda-noextern.spack.yaml
  - uo-containers/22.05/production/e4s-22.05-cuda.spack.yaml
  - uo-containers/22.05/production/e4s-22.05-rocm-noextern.spack.yaml
  - uo-containers/22.05/production/base/amd64-cuda.spack.yaml
  - uo-containers/22.05/archives/spack-cuda-ppc64le.spack.yaml
  - uo-containers/22.05/components/e4s-cuda-builder-noextern.spack.yaml
  - uo-containers/22.05/components/e4s-cuda-builder.spack.yaml
  - uo-containers/22.05/components/e4s-rocm-builder.spack.yaml
  - uo-containers/22.05/archives/spack-cuda-external.spack.yaml
  - crusher/22.02/PrgEnv-gnu/spack.yaml
  - crusher/22.05/PrgEnv-cray/spack.yaml
  - applications/exago/container/spack.yaml
  - aws/paratools/parallelcluster-3.1.4/exawind-demo/spack.yaml
  - uo-containers/22.05/production/e4s-22.05-cuda-ppc64le.spack.yaml
  - uo-containers/22.05/components/e4s-cpu-builder-ppc64le.spack.yaml
  - crusher/develop/PrgEnv-cray/failures/spack.yaml
  - uo-containers/22.05/archives/spack-cuda.spack.yaml
  - applications/exago/crusher/spack.yaml
  - uo-containers/22.05/failed-oneapi/spack.yaml
  - arcticus/experimental/failures/spack.yaml
  - uo-containers/22.05/production/base/ppc64le-cuda.spack.yaml
  - uo-containers/22.05/archives/spack-rocm-external.spack.yaml
  - uo-containers/22.05/production/base/amd64-oneapi.spack.yaml
  - arcticus/22.02/spack.yaml
  - uo-containers/22.05/archives/spack-cuda-external-ppc64le.spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/separately.w-failures.spack.yaml
  - arcticus/22.05/spack.yaml
  - perlmutter/22.05/PrgEnv-gnu/spack.yaml
  - uo-containers/22.05/archives/spack-cpu.spack.yaml
  - cori/21.05/PrgEnv-intel/spack.yaml
  - perlmutter/22.05/PrgEnv-gnu/failures/spack.yaml
  - uo-containers/22.05/production/e4s-22.05-rocm.spack.yaml
  - uo-containers/22.05/components/e4s-rocm-builder-noextern.spack.yaml
  - crusher/develop/PrgEnv-cray/spack.yaml
  - crusher/22.05/PrgEnv-amd/failures/spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/spack.yaml
  - perlmutter/develop/failures/spack.yaml
  - uo-containers/22.05/archives/spack-cpu-ppc64le.spack.yaml
  - crusher/develop/PrgEnv-cray/full-wrappers/failures/spack.yaml
  - uo-containers/22.05/production/save/e4s-22.05-oneapi.spack.yaml
  - crusher/develop/PrgEnv-cray/full-wrappers/spack.yaml
  - crusher/develop/PrgEnv-gnu/spack.yaml
  - uo-containers/22.05/components/e4s-cuda-builder-ppc64le.spack.yaml
  - crusher/22.05/PrgEnv-gnu/failures/spack.yaml
  full_name: eugeneswalker/facility-spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1655395315.0
floquet/builds:
  data_format: 2
  description: Notes and scripts for building applications on HPCs
  filenames:
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-20_11,45/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/dantopa/2022-04-20_09,09/yamls/spacktivity/mageia-8-dantopa-docker-spack/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/amzn-2.0.20220316.0/amzn-2.0.20220316.0-dantopa-docker-spack/2022-04-07_21,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/dantopa/2022-03-20_11,43/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/dantopa/2022-03-20_11,43/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/shell-scripts/2022-03-24_12,17/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/shell-scripts/2022-03-24_12,17/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-20_11,45/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-20_11,45/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/amzn-2.0.20220316.0/amzn-2.0.20220316.0-dantopa-docker-spack/2022-04-07_21,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/shell-scripts/2022-03-24_12,17/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/shell-scripts/2022-03-24_12,17/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_07,27/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_09,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/dantopa/2022-03-20_11,43/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/amzn-2.0.20220316.0/amzn-2.0.20220316.0-dantopa-docker-spack/2022-04-07_21,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/amzn-2.0.20220316.0/amzn-2.0.20220316.0-dantopa-docker-spack/2022-04-07_21,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/dantopa/2022-03-20_11,43/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-20_11,45/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-20_11,45/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-20_11,45/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/amzn-2.0.20220316.0/amzn-2.0.20220316.0-dantopa-docker-spack/2022-04-07_21,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/dantopa/2022-03-20_11,43/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/amzn-2.0.20220316.0/amzn-2.0.20220316.0-dantopa-docker-spack/2022-04-07_21,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/build-logs/2022-03-20_18,24/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/build-logs/2022-03-20_18,24/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/build-logs/2022-03-20_18,24/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/dantopa/2022-03-20_11,43/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/shell-scripts/2022-03-24_12,17/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/build-logs/2022-03-20_18,24/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/build-logs/2022-03-20_18,24/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/build-logs/2022-03-20_18,24/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/shell-scripts/2022-03-24_12,17/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  full_name: floquet/builds
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641760136.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-gcc/spack.yaml
  - ubuntu-clang/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1>

    <a id="user-content-synergia2-containers" class="anchor" href="#synergia2-containers"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1646758059.0
giltirn/mochi-margo:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: giltirn/mochi-margo
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-margo\" class=\"anchor\" href=\"#margo\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n\
    <p><a href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ alt=\"\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings\
    \ to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\"\
    \ rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\n\
    library optimized for use in HPC environments.  Its native API presents a\ncallback-oriented\
    \ interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\"\
    \ rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n\
    <p>Margo combines Mercury and Argobots to simplify development of distributed\n\
    services.  Mercury operations are presented as conventional blocking\noperations,\
    \ and RPC handlers are presented as sequential threads.  This\nconfiguration enables\
    \ high degree of concurrency while hiding the\ncomplexity associated with asynchronous\
    \ communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends\
    \ callers after issuing a Mercury operation, and\nautomatically resumes them when\
    \ the operation completes.  This allows\nother concurrent user-level threads to\
    \ make progress while Mercury\noperations are in flight without consuming operating\
    \ system threads.\nThe goal of this design is to combine the performance advantages\
    \ of\nMercury's native event-driven execution model with the progamming\nsimplicity\
    \ of a multi-threaded execution model.</p>\n<p>A companion library called abt-io\
    \ provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\"\
    >https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should\
    \ be compatible with any Mercury network\ntransport (NA plugin).  The documentation\
    \ assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury\
    \ for\nsimplicity.  This plugin is only valid for communication between\nprocesses\
    \ on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\"\
    >Using Margo with other Mercury NA\nplugins</a> for information\non other configuration\
    \ options.</p>\n<h2>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing\
    \ the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"\
    nofollow\">https://spack.io/</a>).</p>\n<h2>\n<a id=\"user-content-dependencies\"\
    \ class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury\
    \  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\"\
    >https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone\
    \ <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n\
    </ul>\n<h3>\n<a id=\"user-content-recommended-mercury-build-options\" class=\"\
    anchor\" href=\"#recommended-mercury-build-options\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury\
    \ build options</h3>\n<ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON\
    \ to enable the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should\
    \ be compiled with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast\
    \ execution path for cases in which a Mercury service is linked into the same\n\
    executable as the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir\
    \ build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON\
    \ -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install\
    \ \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n\
    <h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n\
    <p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install\
    \ \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"\
    -g -Wall\"\n</code></pre>\n<h2>\n<a id=\"user-content-running-examples\" class=\"\
    anchor\" href=\"#running-examples\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The\
    \ examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example\
    \ client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]:\
    \ an example RPC definition</li>\n</ul>\n<p>The following example shows how to\
    \ execute them.  Note that when the server starts it will display the address\
    \ that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server\
    \ na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with\
    \ input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val:\
    \ 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client\
    \ na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3]\
    \ running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\n\
    Got response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n\
    <p>The client will issue 4 concurrent RPCs to the server and wait for them to\n\
    complete.</p>\n<h2>\n<a id=\"user-content-running-tests\" class=\"anchor\" href=\"\
    #running-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Running tests</h2>\n<p><code>make check</code></p>\n\
    <h2>\n<a id=\"user-content-using-margo-with-the-other-na-plugins\" class=\"anchor\"\
    \ href=\"#using-margo-with-the-other-na-plugins\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using Margo with the other NA\
    \ plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\"\
    \ rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible\
    \ with any Mercury transport and uses the same address\nformat.</p>\n<h2>\n<a\
    \ id=\"user-content-instrumentation\" class=\"anchor\" href=\"#instrumentation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Instrumentation</h2>\n<p>See the <a href=\"doc/instrumentation.md\"\
    >Instrumentation documentation</a> for\ninformation on how to extract diagnostic\
    \ instrumentation from Margo.</p>\n<h2>\n<a id=\"user-content-debugging\" class=\"\
    anchor\" href=\"#debugging\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Debugging</h2>\n<p>See the <a href=\"doc/debugging.md\"\
    >Debugging documentation</a> for Margo debugging\nfeatures and strategies.</p>\n\
    <h2>\n<a id=\"user-content-design-details\" class=\"anchor\" href=\"#design-details\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Design details</h2>\n<p><a href=\"doc/fig/margo-diagram.png\" target=\"\
    _blank\" rel=\"noopener noreferrer\"><img src=\"doc/fig/margo-diagram.png\" alt=\"\
    Margo architecture\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware\
    \ wrappers to common Mercury library functions\nlike HG_Forward(), HG_Addr_lookup(),\
    \ and HG_Bulk_transfer().  The wrappers\nhave the same arguments as their native\
    \ Mercury counterparts except that no\ncallback function is specified.  Each function\
    \ blocks until the operation\nis complete.  The above diagram illustrates a typical\
    \ control flow.</p>\n<p>Margo launches a long-running user-level thread internally\
    \ to drive\nprogress on Mercury and execute Mercury callback functions (labeled\n\
    <code>__margo_progress()</code> above).  This thread can be assigned to a\ndedicated\
    \ Argobots execution stream (i.e., an operating system thread)\nto drive network\
    \ progress with a dedicated core.  Otherwise it will be\nautomatically scheduled\
    \ when the caller's execution stream is blocked\nwaiting for network events as\
    \ shown in the above diagram.</p>\n<p>Argobots eventual constructs are used to\
    \ suspend and resume user-level\nthreads while Mercury operations are in flight.</p>\n\
    <p>Margo allows several different threading/multicore configurations:</p>\n<ul>\n\
    <li>The progress loop can run on a dedicated operating system thread or not</li>\n\
    <li>Multiple Margo instances (and thus progress loops) can be\nexecuted on different\
    \ operating system threads</li>\n<li>(for servers) a single Margo instance can\
    \ launch RPC handlers\non different operating system threads</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1654705049.0
gyselax/gyselalibxx:
  data_format: 2
  description: Gyselalib++ is a collection of C++ components for writing gyrokinetic
    semi-lagrangian codes and similar
  filenames:
  - spack.yaml
  full_name: gyselax/gyselalibxx
  latest_release: null
  readme: '<h1>

    <a id="user-content-gyselalib" class="anchor" href="#gyselalib" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Gyselalib++</h1>

    <p>Gyselalib++ is a collection of C++ components for writing gyrokinetic semi-lagrangian
    codes and

    similar as well as a collection of such codes.</p>

    <h2>

    <a id="user-content-compilation" class="anchor" href="#compilation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h2>

    <p>to compile voice++:</p>

    <pre><code>git clone --recurse-submodules git@gitlab.maisondelasimulation.fr:gysela-developpers/voicexx.git

    cd voicexx

    mkdir build

    cd build

    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-Wall -Wno-sign-compare" ..

    make

    </code></pre>

    <h2>

    <a id="user-content-execution" class="anchor" href="#execution" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Execution</h2>

    <p>to run the tests:</p>

    <pre><code>ctest --output-on-failure

    </code></pre>

    <p>Then, just have a look at <code>tests/landau/growthrate_t0.0to45.0.png</code>:</p>

    <p><a href="https://camo.githubusercontent.com/b767f6df1712f338f85a7b0b813f7452888524845e8a67bf6223a02a8ca6dc83/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f67726f777468726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/b767f6df1712f338f85a7b0b813f7452888524845e8a67bf6223a02a8ca6dc83/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f67726f777468726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/growthrate_t0.0to45.0.png" title="Landau damping rate" data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/growthrate_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width:100%;"></a></p>

    <p>and <code>tests/landau/frequency_t0.0to45.0.png</code>:</p>

    <p><a href="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/frequency_t0.0to45.0.png" title="Landau damping frequency"
    data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/frequency_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>To install dependencies through spack, first follow the the 3 first steps of

    <a href="https://github.com/pdidev/spack">https://github.com/pdidev/spack</a></p>

    <p>Then execute the following:</p>

    <div class="highlight highlight-source-shell"><pre>spack env create voice spack.yaml

    spack env activate voice

    spack concretize --reuse

    spack install</pre></div>

    <p>For example, you can find a Dockerfile installing these dependencies on ubuntu
    in

    <code>voicexx_env/Dockerfile</code>.</p>

    '
  stargazers_count: 4
  subscribers_count: 1
  topics:
  - hpc
  - numerical-simulation
  - gyrokinetic
  - poisson-solver
  - vlasov-solver
  - plasma-physics
  - ddc
  updated_at: 1656331134.0
haampie/spack-pgo-lto-environment:
  data_format: 2
  description: Enable PGO and LTO in Spack software stacks
  filenames:
  - spack.yaml
  full_name: haampie/spack-pgo-lto-environment
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1653473825.0
hariharan-devarajan/tailorfs:
  data_format: 2
  description: null
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/tailorfs
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1656016375.0
hepnos/HEPnOS:
  data_format: 2
  description: HEPnOS is a distributed object store for high energy physics applications,
    developed at Argonne National Laboratory.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS
  latest_release: v0.6.5
  readme: '<h1>

    <a id="user-content-hepnos" class="anchor" href="#hepnos" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS</h1>

    <p>HEPnOS is the <em>High-Energy Physics''s new Object Store</em>, a distributed
    storage

    system specially designed for HEP experiments and workflows for the FermiLab.

    HEPnOS relies on libraries developed at Argonne National Laboratory within the

    context of the Mochi project (ANL, CMU, LANL, HDF Group).</p>

    <p>For information on copyright and licensing, see the COPYRIGHT file.

    For information on how to use, see the <a href="https://xgitlab.cels.anl.gov/sds/HEPnOS/wikis/home"
    rel="nofollow">wiki</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641296454.0
hppritcha/spack_ompix:
  data_format: 2
  description: null
  filenames:
  - gnu_release_x86_64/spack.yaml
  - intel_master_x86_64/spack.yaml
  - intel_release_x86_64/spack.yaml
  - gnu_master_x86_64/spack.yaml
  full_name: hppritcha/spack_ompix
  latest_release: null
  readme: '<p>Project for using Gitlab CI to test spack builds of Open MPI master
    and release tarballs.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1640037910.0
iarspider/cms-spack-repo:
  data_format: 2
  description: null
  filenames:
  - environments/CMSSW_12_4_X/spack.yaml
  full_name: iarspider/cms-spack-repo
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1638894331.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/eagle/compilers/spack.yaml
  - configs/eagle/utilities/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    configuration files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1651762796.0
justbennet/biospack:
  data_format: 2
  description: Setting up Spack to provide Bioinformatics packages
  filenames:
  - environments/arc/spack.yaml
  full_name: justbennet/biospack
  latest_release: null
  readme: '<h1>

    <a id="user-content-biospack" class="anchor" href="#biospack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Biospack</h1>

    <p>These are files that provide local customization for the Spack installation

    that is used to provide Bioinformatics packages on the Great Lakes and

    Armis clusters.  This was all intended for use on Red Hat 8 systems, and

    the Spack installation will cohabit software installed in the traditional

    manner.  We are consciously restricting ourselves to non-MPI software,

    and only for Bioinformatics.</p>

    <p>The presumption is that these will be used to set up the test Spack for a

    new contributor, so all the settings in the configuration files presume a

    root directory of <code>/var/software/$USER</code>, and that all Spack created
    files

    (including temporary files) will be in directories beneath it.</p>

    <p>The files in the repository can be modified to create a Spack installation

    to provide the production installation intended for real users.  The targets

    should be</p>

    <p>Software:  <code>/sw/pkgs/bio</code>

    Modules:  <code>/sw/modules/bio/spack</code></p>

    <p>To set up a new installation, first run the <code>start_new_biospack</code>
    script.

    That will create the <code>/var/software/$USER/bio</code> directory, clone Spack

    itself into it, prompt you for the version of Spack to set, create the

    directories used for Spack temporary and cache files.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1650732078.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/contrib-compilers/spack.yaml
  - environments/key4hep-release/spack.yaml
  - environments/key4hep-desy-release/spack.yaml
  - environments/key4hep-nightlies-debug/spack.yaml
  - environments/key4hep-nightlies/spack.yaml
  - environments/key4hep-release-user/spack.yaml
  - environments/geant4-data-share/spack.yaml
  - environments/key4hep-debug/spack.yaml
  - environments/key4hep-nightlies-clang/spack.yaml
  - environments/key4hep-release-clang/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1>

    <a id="user-content-spack-package-repo-for-key4hep-software-packaging" class="anchor"
    href="#spack-package-repo-for-key4hep-software-packaging" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://github.com/spack/spack">Spack</a>
    package repo for Key4HEP software packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3>

    <a id="user-content-repository-contents" class="anchor" href="#repository-contents"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3>

    <a id="user-content-central-installations" class="anchor" href="#central-installations"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 9
  subscribers_count: 9
  topics: []
  updated_at: 1657179516.0
lcompilers/lpython:
  data_format: 2
  description: Python compiler
  filenames:
  - spack.yaml
  full_name: lcompilers/lpython
  latest_release: null
  readme: '<h1>

    <a id="user-content-lpython" class="anchor" href="#lpython" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LPython</h1>

    <p>LPython is a Python compiler. It is in heavy development, currently in

    pre-alpha stage. Some of the goals of LPython:</p>

    <ul>

    <li>The best possible performance for numerical array oriented code</li>

    <li>Run on all platforms</li>

    <li>Compile a subset of Python and be Python compatible</li>

    <li>Explore how to design it so that it can be eventually used with any Python

    code</li>

    <li>Fast compilation</li>

    <li>Excellent user friendly diagnostic messages: error, warnings, hints, notes,

    etc.</li>

    <li>Ahead of time compilation to binaries and interactive usage (Jupyter

    notebook)</li>

    <li>Able to transform the Python code to C++, Fortran and other languages</li>

    </ul>

    <p>And more.</p>

    <h1>

    <a id="user-content-installation" class="anchor" href="#installation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h1>

    <p>LPython works on Windows, macOS and Linux.</p>

    <h2>

    <a id="user-content-install-conda" class="anchor" href="#install-conda" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Install Conda</h2>

    <p>If you do not have Conda already installed, please follow the instructions

    here to install Conda on your platform:</p>

    <p><a href="https://github.com/conda-forge/miniforge/#download">https://github.com/conda-forge/miniforge/#download</a></p>

    <h2>

    <a id="user-content-compile-lpython" class="anchor" href="#compile-lpython" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compile LPython</h2>

    <p>Install required packages (Linux - 64 bit):</p>

    <div class="highlight highlight-source-shell"><pre>sudo apt install binutils-dev</pre></div>

    <p>Clone LPython</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/lcompilers/lpython.git

    <span class="pl-c1">cd</span> lpython</pre></div>

    <p>Create a Conda environment using the preexisting environment.yml file:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment.yml

    conda activate lp</pre></div>

    <p>Create autogenerated files (choose the command for your platform):</p>

    <div class="highlight highlight-source-shell"><pre>./build0.sh      <span class="pl-c"><span
    class="pl-c">#</span> macOS/Linux</span>

    call build0.bat  <span class="pl-c"><span class="pl-c">#</span> Windows</span></pre></div>

    <p>Compile LPython:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -DCMAKE_BUILD_TYPE=Debug
    -DWITH_LLVM=yes -DWITH_STACKTRACE=yes -DWITH_LFORTRAN_BINARY_MODFILES=no <span
    class="pl-c1">.</span>

    cmake --build <span class="pl-c1">.</span> -j16</pre></div>

    <h2>

    <a id="user-content-tests" class="anchor" href="#tests" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Tests:</h2>

    <p>Run tests:</p>

    <div class="highlight highlight-source-shell"><pre>ctest

    ./run_tests.py</pre></div>

    <p>Run integration tests:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    integration_tests

    ./run_tests.sh</pre></div>

    <h3>

    <a id="user-content-speed-up-integration-test-on-macs" class="anchor" href="#speed-up-integration-test-on-macs"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Speed
    up Integration Test on Macs</h3>

    <p>Integration tests run slowly because Apple checks the hash of each

    executable online before running. You can turn off that feature

    in the Privacy tab of the Security and Privacy item of System

    Preferences, Developer Tools, Terminal.app, "allow the apps below

    to run software locally that does not meet the system''s security

    policy."</p>

    <h2>

    <a id="user-content-examples" class="anchor" href="#examples" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Examples</h2>

    <p>You can run the following examples by hand in a terminal:</p>

    <div class="highlight highlight-source-shell"><pre>./src/bin/lpython examples/expr2.py

    ./a.out

    ./src/bin/lpython --show-ast examples/expr2.py

    ./src/bin/lpython --show-asr examples/expr2.py

    ./src/bin/lpython --show-cpp examples/expr2.py

    ./src/bin/lpython --show-llvm examples/expr2.py

    ./src/bin/lpython --show-c examples/expr2.py</pre></div>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>We welcome contributions from anyone, even if you are new to open source. It

    might sound daunting to contribute to a compiler at first, but please do, it is

    not complicated. We will help you with any technical issues and help improve

    your contribution so that it can be merged.</p>

    <p>To contribute, submit a Pull Request (PR) against our repository at:</p>

    <p><a href="https://github.com/lcompilers/lpython">https://github.com/lcompilers/lpython</a></p>

    <p>Please report any bugs you may find at our issue tracker: <a href="https://github.com/lcompilers/lpython/issues">https://github.com/lcompilers/lpython/issues</a>.

    Or, even better, fork the repository on GitHub and create a PR. We welcome all
    changes, big or small, and we will help you make a PR if you are new to git.</p>

    <p>If you have any questions or need help, please ask us at Zulip (<a href="https://lfortran.zulipchat.com/"
    rel="nofollow"><img src="https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667"
    alt="project chat" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg"
    style="max-width:100%;"></a>) or our

    <a href="https://groups.io/g/lfortran" rel="nofollow">mailinglist</a>.</p>

    <p>See the <a href="CONTRIBUTING.md">CONTRIBUTING</a> document for more information.</p>

    '
  stargazers_count: 49
  subscribers_count: 6
  topics: []
  updated_at: 1658239866.0
lfortran/lfortran:
  data_format: 2
  description: Official main repository for LFortran
  filenames:
  - spack.yaml
  full_name: lfortran/lfortran
  latest_release: null
  readme: '<h1>

    <a id="user-content-lfortran" class="anchor" href="#lfortran" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LFortran</h1>

    <p><a href="https://mybinder.org/v2/gl/lfortran%2Fweb%2Flfortran-binder/master?filepath=Demo.ipynb"
    rel="nofollow"><img src="https://camo.githubusercontent.com/581c077bdbc6ca6899c86d0acc6145ae85e9d80e6f805a1071793dbe48917982/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667"
    alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"></a>

    <a href="https://lfortran.zulipchat.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667"
    alt="project chat" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg"
    style="max-width:100%;"></a>

    <a href="https://gitlab.com/lfortran/lfortran/-/commits/master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/779e847f325091dfbcc9a392bdcb5a7718f2cffd076460ff9fc9e03d15666fca/68747470733a2f2f6769746c61622e636f6d2f6c666f727472616e2f6c666f727472616e2f6261646765732f6d61737465722f706970656c696e652e737667"
    alt="pipeline status" data-canonical-src="https://gitlab.com/lfortran/lfortran/badges/master/pipeline.svg"
    style="max-width:100%;"></a></p>

    <p>LFortran is a modern open-source (BSD licensed) interactive Fortran compiler

    built on top of LLVM. It can execute user''s code interactively to allow

    exploratory work (much like Python, MATLAB or Julia) as well as compile to

    binaries with the goal to run user''s code on modern architectures such as

    multi-core CPUs and GPUs.</p>

    <p>Website: <a href="https://lfortran.org/" rel="nofollow">https://lfortran.org/</a></p>

    <h1>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>All documentation, installation instructions, motivation, design, ... is

    available at:</p>

    <p><a href="https://docs.lfortran.org/" rel="nofollow">https://docs.lfortran.org/</a></p>

    <p>Which is generated using the files in the <code>doc</code> directory.</p>

    <h1>

    <a id="user-content-development" class="anchor" href="#development" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Development</h1>

    <p>We welcome all contributions.

    The main development repository is at GitHub:</p>

    <p><a href="https://github.com/lfortran/lfortran">https://github.com/lfortran/lfortran</a></p>

    <p>Please send Pull Requests (PRs) there.</p>

    <p>We moved to the above GitHub repository from GitLab on July 18, 2022. For now

    we are still using our old GitLab repository as an issue tracker:

    <a href="https://gitlab.com/lfortran/lfortran" rel="nofollow">https://gitlab.com/lfortran/lfortran</a>,

    please use it to open issues.

    See the <a href="CONTRIBUTING.md">CONTRIBUTING</a> document for more information.</p>

    <p>Main mailinglist:</p>

    <p><a href="https://groups.io/g/lfortran" rel="nofollow">https://groups.io/g/lfortran</a></p>

    <p>You can also chat with us on Zulip (<a href="https://lfortran.zulipchat.com/"
    rel="nofollow"><img src="https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667"
    alt="project chat" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg"
    style="max-width:100%;"></a>).</p>

    '
  stargazers_count: 345
  subscribers_count: 16
  topics:
  - fortran
  - interactive
  - compiler
  - library
  - repl
  - jupyter
  - jupyter-notebook
  - jupyter-kernels
  updated_at: 1658586935.0
mdorier/mobject:
  data_format: 2
  description: Mobject is a Mochi object store presenting an API similar to that of
    RADOS
  filenames:
  - spack.yaml
  full_name: mdorier/mobject
  latest_release: null
  readme: '<p>Your project "mobject" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652975191.0
mochi-hpc-experiments/colza-experiments:
  data_format: 2
  description: Experiments using Colza for In Situ Analysis
  filenames:
  - ubuntu/collectives/spack.yaml
  - cori/collectives/spack.yaml
  - cori/vtk/spack.yaml
  - ubuntu/overhead/spack.yaml
  - ubuntu/resizing/spack.yaml
  - ubuntu/vtk/spack.yaml
  - theta/amr-wind/spack.yaml
  full_name: mochi-hpc-experiments/colza-experiments
  latest_release: ipdps2022
  readme: '<h1>

    <a id="user-content-colza-experiments" class="anchor" href="#colza-experiments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Colza
    Experiments</h1>

    <p>This repository contains scripts to reproduce experiments

    related to the Colza elastic in situ analysis framework.

    These experiments were run on the Cori supercomputer.</p>

    <p>Each subfolder contains a README file explaining what the

    experiment in the subfolder does, how to install its

    dependencies, and how to run it.</p>

    <p>The ubuntu folder contains scripts that allow reproducing

    the most experiments on a single Linux workstation or a

    cluster of Linux machines.</p>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1655200495.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - NERSC/Perlmutter/spack.yaml
  - ANL/Bebop/spack.yaml
  - ORNL/Crusher/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1>

    <a id="user-content-platform-configurations-for-mochi" class="anchor" href="#platform-configurations-for-mochi"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Platform
    configurations for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <h2>

    <a id="user-content-using-spackyaml-files" class="anchor" href="#using-spackyaml-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2>

    <a id="user-content-contributing-to-this-repository" class="anchor" href="#contributing-to-this-repository"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing
    to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1641290694.0
mochi-hpc/mochi-colza:
  data_format: 2
  description: Mochi-based staging service for in situ analysis and visualization
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-colza
  latest_release: v0.2.1
  readme: ''
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640788783.0
mochi-hpc/mochi-yokan:
  data_format: 2
  description: Remote Key/Value storage service for Mochi
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-yokan
  latest_release: v0.2.7
  readme: '<h1>

    <a id="user-content-yokan---mochis-keyvalue-and-more-storage-service" class="anchor"
    href="#yokan---mochis-keyvalue-and-more-storage-service" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Yokan - Mochi''s Key/Value
    (and more) storage service</h1>

    <p><a href="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"
    target="_blank" rel="noopener noreferrer"><img src="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"
    alt="" style="max-width:100%;"></a>

    <a href="https://codecov.io/gh/mochi-hpc/mochi-yokan" rel="nofollow"><img src="https://camo.githubusercontent.com/fc95c801bafa29b49219f4727f651b97e7385800c8dc4a4757a1dccadefe6611/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d796f6b616e2f6272616e63682f6d61696e2f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/mochi-hpc/mochi-yokan/branch/main/graph/badge.svg"
    style="max-width:100%;"></a></p>

    <p>Please see documentation <a href="https://mochi.readthedocs.io/en/latest/yokan.html"
    rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641326484.0
mochi-hpc/py-mochi-colza:
  data_format: 2
  description: Python binding for Mochi's Colza microservice
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-colza
  latest_release: null
  readme: '<p>Py-Colza is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-colza">Colza
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1633974570.0
mochi-hpc/py-mochi-margo:
  data_format: 2
  description: Python wrapper for Margo. Can be used to prototype Margo services in
    Python.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-margo
  latest_release: v0.4
  readme: "<h1>\n<a id=\"user-content-py-margo\" class=\"anchor\" href=\"#py-margo\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Py-Margo</h1>\n<p>Py-Margo provides a Python wrapper on top of <a\
    \ href=\"https://xgitlab.cels.anl.gov/sds/margo\" rel=\"nofollow\">Margo</a>.\n\
    It enables one to develop Margo-based service in Python.</p>\n<h2>\n<a id=\"user-content-dependencies\"\
    \ class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>margo\
    \ (and its dependencies)</li>\n<li>python</li>\n<li>pybind11</li>\n<li>py-pkgconfig</li>\n\
    </ul>\n<h2>\n<a id=\"user-content-installing\" class=\"anchor\" href=\"#installing\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installing</h2>\n<p>The easiest way to install Py-Margo is to use\
    \ <a href=\"https://spack.io/\" rel=\"nofollow\">spack</a>.\nFollow the instructions\
    \ <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">here</a>\n\
    to add the <code>sds</code> namespace and its packages (instal spack first, if\
    \ needed).\nThen type:</p>\n<pre><code>spack install py-margo\n</code></pre>\n\
    <p>Once installed, you need the py-margo package (and its dependencies) to\nbe\
    \ loaded to use it.</p>\n<h2>\n<a id=\"user-content-examples\" class=\"anchor\"\
    \ href=\"#examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<h3>\n<a id=\"user-content-basic-example\"\
    \ class=\"anchor\" href=\"#basic-example\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Basic example</h3>\n<p>The following\
    \ is an example of provider programmed in Python.\nLet's put is in a file <code>server.py</code>.\n\
    The provider listens to an address on a given multiple id (here 42).\nWhenever\
    \ it receives an RPC, it prints \"Hello from\" and the name sent\nby the client,\
    \ then sends the \"Hi \"+name+\"!\" string back to the client,\nand finally terminates.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">pymargo</span>.<span class=\"pl-s1\">core</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-v\">Engine</span>, <span class=\"pl-v\">Provider</span>\n\
    \n<span class=\"pl-k\">class</span> <span class=\"pl-v\">HelloProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>(<span class=\"pl-s1\">engine</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\"\
    >register</span>(<span class=\"pl-s\">\"say_hello\"</span>, <span class=\"pl-s\"\
    >\"hello\"</span>)\n\n\t<span class=\"pl-k\">def</span> <span class=\"pl-en\"\
    >hello</span>(<span class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>,\
    \ <span class=\"pl-s1\">name</span>):\n\t\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Hello from \"</span><span class=\"pl-c1\">+</span><span class=\"\
    pl-s1\">name</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"pl-s\"\
    >\"RPC id is \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">handle</span>.<span class=\"pl-en\">get_id</span>()))\n\t\t\
    <span class=\"pl-s1\">handle</span>.<span class=\"pl-en\">respond</span>(<span\
    \ class=\"pl-s\">\"Hi \"</span><span class=\"pl-c1\">+</span><span class=\"pl-s1\"\
    >name</span><span class=\"pl-c1\">+</span><span class=\"pl-s\">\"!\"</span>)\n\
    \t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\">get_engine</span>().<span\
    \ class=\"pl-en\">finalize</span>()\n\n<span class=\"pl-k\">def</span> <span class=\"\
    pl-v\">WhenFinalize</span>():\n\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Finalize was called\"</span>)\n\n<span class=\"pl-s1\">engine</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Engine</span>(<span class=\"\
    pl-s\">'tcp'</span>)\n<span class=\"pl-s1\">provider_id</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Server running at address \"</span> <span class=\"pl-c1\">+</span>\
    \ <span class=\"pl-en\">str</span>(<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">addr</span>()) <span class=\"pl-c1\">+</span> <span class=\"pl-s\">\"\
    \ with provider_id \"</span> <span class=\"pl-c1\">+</span> <span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">provider_id</span>))\n\n<span class=\"pl-s1\"\
    >engine</span>.<span class=\"pl-en\">on_finalize</span>(<span class=\"pl-v\">WhenFinalize</span>)\n\
    <span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">HelloProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>The following code is the corresponding\
    \ client code (<code>client.py</code>).</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">sys</span>\n<span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">pymargo</span>\n<span class=\"\
    pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"pl-s1\"\
    >core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">name</span>):\n\t<span class=\"pl-s1\">addr</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">lookup</span>(<span\
    \ class=\"pl-s1\">addr_str</span>)\n\t<span class=\"pl-s1\">handle</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">create_handle</span>(<span class=\"pl-s1\">addr</span>, <span class=\"\
    pl-s1\">rpc_id</span>)\n\t<span class=\"pl-k\">return</span> <span class=\"pl-s1\"\
    >handle</span>.<span class=\"pl-en\">forward</span>(<span class=\"pl-s1\">provider_id</span>,\
    \ <span class=\"pl-s1\">name</span>)\n\n<span class=\"pl-k\">with</span> <span\
    \ class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span class=\"\
    pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span> <span class=\"\
    pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">register</span>(<span\
    \ class=\"pl-s\">\"say_hello\"</span>)\n\t<span class=\"pl-s1\">ret</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"\
    pl-c1\">3</span>]))\n\t<span class=\"pl-en\">print</span>(<span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n<p>First, run the\
    \ server on a new terminal:</p>\n<pre><code>python server.py\n</code></pre>\n\
    <p>This will output something like</p>\n<pre><code>Server running at address ofi+sockets://10.0.2.15:39151\
    \ with provider_id=42\n</code></pre>\n<p>Then run the client on a new terminal:</p>\n\
    <pre><code>python client.py ofi+sockets://10.0.2.15:39151 42 Matthieu\n</code></pre>\n\
    <h3>\n<a id=\"user-content-sendingreceiving-python-objects\" class=\"anchor\"\
    \ href=\"#sendingreceiving-python-objects\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Sending/receiving Python objects</h3>\n\
    <p>The example above shows the basic principles of Py-Margo.\nPy-Margo's RPC always\
    \ use a string as input and respond with a string.\nYet this is sufficient to\
    \ cover any use-cases you may have: Python\nindeed comes with a serialization\
    \ package, <code>pickle</code>, that can take\ncare of converting almost any Python\
    \ object from/to a string.</p>\n<p>Let us assume we have a file named <code>mymaths.py</code>\
    \ which contains the\nfollowing definition of a point in 3D.</p>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span\
    \ class=\"pl-v\">Point</span>():\n\t<span class=\"pl-k\">def</span> <span class=\"\
    pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>,<span class=\"pl-s1\"\
    >x</span>,<span class=\"pl-s1\">y</span>,<span class=\"pl-s1\">z</span>):\n\t\t\
    <span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">x</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">x</span>\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">y</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\"\
    >y</span>\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">z</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">z</span>\n\t<span class=\"\
    pl-k\">def</span> <span class=\"pl-en\">__str__</span>(<span class=\"pl-s1\">self</span>):\n\
    \t\t<span class=\"pl-k\">return</span> <span class=\"pl-s\">'Point ('</span><span\
    \ class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\"\
    >self</span>.<span class=\"pl-s1\">x</span>)<span class=\"pl-c1\">+</span><span\
    \ class=\"pl-s\">','</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">y</span>)<span\
    \ class=\"pl-c1\">+</span><span class=\"pl-s\">','</span><span class=\"pl-c1\"\
    >+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">z</span>)<span class=\"pl-c1\">+</span><span class=\"pl-s\"\
    >')'</span></pre></div>\n<p>Then here is a server that can compute a cross product\
    \ on two points sent by\na client.</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Engine</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Provider</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\"\
    >mymaths</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n\
    <span class=\"pl-k\">import</span> <span class=\"pl-s1\">pickle</span>\n\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-v\">VectorMathProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>().<span class=\"pl-en\">__init__</span>(<span class=\"pl-s1\"\
    >engine</span>, <span class=\"pl-s1\">provider_id</span>)\n\t\t<span class=\"\
    pl-s1\">self</span>.<span class=\"pl-en\">register</span>(<span class=\"pl-s\"\
    >\"cross_product\"</span>, <span class=\"pl-s\">\"cross_product\"</span>)\n\n\t\
    <span class=\"pl-k\">def</span> <span class=\"pl-en\">cross_product</span>(<span\
    \ class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>, <span class=\"\
    pl-s1\">args</span>):\n\t\t<span class=\"pl-s1\">points</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">loads</span>(<span\
    \ class=\"pl-s1\">args</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Received: \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">points</span>))\n\t\t<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span> <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">0</span>].<span class=\"pl-s1\">z</span><span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span\
    \ class=\"pl-s1\">y</span>\n\t\t<span class=\"pl-s1\">y</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">z</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">x</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span>\n\t\t<span class=\"pl-s1\">z</span> <span class=\"pl-c1\">=</span>\
    \ <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span class=\"\
    pl-s1\">x</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">1</span>].<span class=\"pl-s1\">y</span> <span class=\"pl-c1\"\
    >-</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\n\
    \t\t<span class=\"pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Point</span>(<span class=\"pl-s1\">x</span>,<span class=\"pl-s1\">y</span>,<span\
    \ class=\"pl-s1\">z</span>)\n\t\t<span class=\"pl-s1\">handle</span>.<span class=\"\
    pl-en\">respond</span>(<span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >dumps</span>(<span class=\"pl-s1\">res</span>))\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-en\">get_engine</span>().<span class=\"pl-en\">finalize</span>()\n\
    \n<span class=\"pl-s1\">engine</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>)\n<span class=\"pl-s1\"\
    >provider_id</span> <span class=\"pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n\
    <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Server running at address\
    \ \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">mid</span>.<span class=\"pl-en\">addr</span>())<span class=\"\
    pl-c1\">+</span><span class=\"pl-s\">\"with provider_id=\"</span><span class=\"\
    pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">provider_id</span>))\n\
    \n<span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">VectorMathProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>And here is a client.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">import</span> <span class=\"\
    pl-s1\">pymargo</span>\n<span class=\"pl-k\">import</span> <span class=\"pl-s1\"\
    >pickle</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">mymaths</span>\
    \ <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n<span\
    \ class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"\
    pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">p1</span>, <span class=\"pl-s1\">p2</span>):\n\t<span class=\"pl-s1\"\
    >addr</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span\
    \ class=\"pl-en\">lookup</span>(<span class=\"pl-s1\">addr_str</span>)\n\t<span\
    \ class=\"pl-s1\">handle</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">engine</span>.<span class=\"pl-en\">create_handle</span>(<span class=\"\
    pl-s1\">addr</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t<span class=\"pl-s1\">args</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">dumps</span>([<span\
    \ class=\"pl-s1\">p1</span>,<span class=\"pl-s1\">p2</span>])\n\t<span class=\"\
    pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">handle</span>.<span\
    \ class=\"pl-en\">forward</span>(<span class=\"pl-s1\">args</span>)\n\t<span class=\"\
    pl-k\">return</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >loads</span>(<span class=\"pl-s1\">res</span>)\n\n<span class=\"pl-k\">with</span>\
    \ <span class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span\
    \ class=\"pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\"\
    >pymargo</span>.<span class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span>\
    \ <span class=\"pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">mid</span>.<span class=\"\
    pl-en\">register</span>(<span class=\"pl-s\">\"cross_product\"</span>)\n\t<span\
    \ class=\"pl-s1\">p1</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >Point</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span\
    \ class=\"pl-c1\">3</span>)\n\t<span class=\"pl-s1\">p2</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-v\">Point</span>(<span class=\"pl-c1\">4</span>,<span\
    \ class=\"pl-c1\">5</span>,<span class=\"pl-c1\">6</span>)\n\t<span class=\"pl-s1\"\
    >ret</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">mid</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-s1\">p1</span>,\
    \ <span class=\"pl-s1\">p2</span>)\n\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-en\">str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633974436.0
mochi-hpc/py-mochi-ssg:
  data_format: 2
  description: Python wrapper for SSG group membership service
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-ssg
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1640536463.0
mpbelhorn/olcf-spack-environments:
  data_format: 2
  description: Spack environments for OLCF resources.
  filenames:
  - hosts/summit/envs/base/spack.yaml
  - hosts/afw/envs/base/spack.yaml
  - hosts/cirrus/envs/base/spack.yaml
  - hosts/borg/envs/base/spack.yaml
  - hosts/peak/envs/base/spack.yaml
  - hosts/ascent/envs/base/spack.yaml
  - hosts/crusher/envs/base/spack.yaml
  full_name: mpbelhorn/olcf-spack-environments
  latest_release: null
  readme: '<h1>

    <a id="user-content-olcf-spack-environments" class="anchor" href="#olcf-spack-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>OLCF
    Spack Environments</h1>

    <p>This repo contains the infrastructure and environment definitions to deploy

    site-provided software on OLCF resources via Spack environments.</p>

    <h2>

    <a id="user-content-getting-started" class="anchor" href="#getting-started" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Started</h2>

    <p>Clone this repo and it''s facility-modified spack fork somewhere on an OLCF

    filesystem:</p>

    <pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git

    </code></pre>

    <p>or</p>

    <pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments

    </code></pre>

    <p>Next, initialize spack and the build environment. This is done by calling</p>

    <pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base
    . ./init-facility-spack.sh

    </code></pre>

    <p>This will configure the spack build- and run-time environment build and install

    the facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this
    repo for the

    current machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both
    of these

    variables are optional. If omitted, each variable will take on their default

    values:</p>

    <pre><code>FACSPACK_MY_ENVS="/sw/${_THIS_HOST}/spack-envs"

    FACSPACK_ENV_NAME="base"

    </code></pre>

    <p>such that sourcing this script by itself</p>

    <pre><code>. ./init-facility-spack.sh

    </code></pre>

    <p>will setup the runtime shell environment to manipulate the production spack

    environment on the current system.</p>

    <p>This repo will always track at least one spack environment per machine named

    <code>base</code> which is the complete standard software environment used in
    production

    for that machine. Furthermore, only the user account with owner permissions on

    the production environment may be used to manipulate it in the default

    <code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent
    multiple

    users from concurrently modifying the production environment. Users may set an

    alternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using
    any

    tracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file
    in this repo.</p>

    <p>From these variables, a unique path per each environment name will be

    constructed:</p>

    <pre><code>FACSPACK_ENV="${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}"

    </code></pre>

    <p>The value of <code>${_THIS_HOST}</code> is determined automatically from the
    hostname on

    which the init script is being run. For each system and environment tracked in

    this repo that you wish to work on, ensure that the final expanded value of

    <code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>

    <p>Configuration paths in our <code>spack.yaml</code> environments that are not
    fixed to

    universal values are expressed in terms of relative paths to either the spack

    instance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.

    These paths are referenced in the <code>spack.yaml</code> files via environment
    variables

    set by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code>
    environment files to

    define portable and relocatable spack environments which can be re-deployed in

    arbitrary private locations by any users without needing to modify the

    environment file.</p>

    <p>The following variables are exported in Spack''s runtime environment by

    <code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code>
    the enviornment

    files tracked in this repo.</p>

    <ul>

    <li>

    <code>${FACSPACK_ENV}</code>:

    Path to where spack environment will be installed. Contains subdirs <code>opt</code>

    and <code>modules</code>.</li>

    <li>

    <code>${FACSPACK_ENV_MODULEROOT}</code>:

    Shortcut to <code>${FACSPACK_ENV}/modules</code> under which static and

    spack-generated modules are generated. Contains subdirectories <code>spack</code>,

    <code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static
    modulefiles

    respectively.</li>

    <li>

    <code>${FACSPACK_CONF_COMMON}</code>:

    Path to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>

    <li>

    <code>${FACSPACK_CONF_HOST}</code>:

    Path to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>

    </li>

    </ul>

    <p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>

    files which cannot de-reference environment variables. These affect</p>

    <ul>

    <li>Mirrors</li>

    <li>Extensions</li>

    </ul>

    <p>Spack does not internally expand environment variables in the configuration
    of

    these items so they must be expressed as hard-coded full path strings. The

    default values in this repo should point to permanent world-readable paths on

    the OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>

    <h2>

    <a id="user-content-spack-fork" class="anchor" href="#spack-fork" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Fork</h2>

    <p>The upstream development branch of spack is not used directly. Instead, the
    OLCF

    has implemented some customizations that are tracked in the "olcf-X.Y.Z"

    branches of a <a href="https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0">facility
    fork of spack</a>

    where <code>X.Y.Z</code> refers to the tagged release of upstream spack from which
    the

    OLCF-modified branch is forked.</p>

    '
  stargazers_count: 3
  subscribers_count: 1
  topics: []
  updated_at: 1654273247.0
openPMD/openPMD-api:
  data_format: 2
  description: ':floppy_disk: C++ & Python API for Scientific I/O'
  filenames:
  - .github/ci/spack-envs/clang8_py38_mpich_h5_ad1_ad2/spack.yaml
  full_name: openPMD/openPMD-api
  latest_release: 0.14.5
  readme: "<h1>\n<a id=\"user-content-c--python-api-for-scientific-io-with-openpmd\"\
    \ class=\"anchor\" href=\"#c--python-api-for-scientific-io-with-openpmd\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++\
    \ &amp; Python API for Scientific I/O with openPMD</h1>\n<p><a href=\"https://github.com/openPMD/openPMD-standard/releases\"\
    ><img src=\"https://camo.githubusercontent.com/5957dc11cb68f6705ef9ef6683152c6c4fcc057a24dff340e1e8bada1bee0d01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\"\
    \ alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d54fa5adcf7ca50d2cdb45823be5064379b613d526fa06f6e193ba2ce616318/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/f551141eea2176c34aa163092549d6fdde9a220d605d6efe9128b024c6e5932b/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\"\
    \ alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"\
    https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"\
    max-width:100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4fc8091716dbd967fa2a82eef3d29227110e5081f3128aaa38663e547c24f812/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/104f6901ae04bff8385acc8273bb276ab84656a927a418108b940d09fd6e5d7c/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\"\
    \ style=\"max-width:100%;\"></a><br>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0d568047fbbd300af56b766d9a4235a20534485f5827194e859d4f5c20e58334/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\"\
    \ alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/context:cpp\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/63a7f9e783999e3afc03ef38ee82e2048017e4e6d279ff4120ad8b8718480ccd/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f6370702f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\"\
    \ alt=\"LGTM: C/C++\" data-canonical-src=\"https://img.shields.io/lgtm/grade/cpp/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/context:python\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5046bf66a4612476a030d38de817c23fa03990183d2d74fa92c5f1379feb5d09/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\"\
    \ alt=\"LGTM: Python\" data-canonical-src=\"https://img.shields.io/lgtm/grade/python/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/alerts/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/85e32deb8face392eea9bfa2be4da4c11ca7c0f834fa069223fbc63758b68c4f/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\"\
    \ alt=\"LGTM: Total alerts\" data-canonical-src=\"https://img.shields.io/lgtm/alerts/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f0487a8fc14d269210ae8ce80b556d4afcd93684f02e61386d2d02daa4423cbd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\"\
    \ style=\"max-width:100%;\"></a><br>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f438ca4eaa308f982d0a28c48f05bf63ca1a86e52c3d2817f6d7559d1dee68e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8278d89e3634e25a818a2d673fe997c2aa5a09fd5995f716aeffa743388030ee/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\"\
    \ alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/30679331f3c6a5ae54970eda85f36a30347dee8a9111448d7aa48587fd524a1d/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\"\
    \ alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\
    ><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\"\
    \ alt=\"PyPI Wheel Release\" style=\"max-width:100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fc9c860bb1fc8e7e145ea9dd6723b9ac6ac2743c195e5e899f6cfa3d38a5a69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\"\
    \ alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0b068d7b5718aafccb46e2ee35f8249938ef189a36ba353c15222ed5e6f65e49/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\"\
    \ alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>openPMD is an open meta-data schema that\
    \ provides meaning and self-description for data sets in science and engineering.\n\
    See <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a>\
    \ for details of this schema.</p>\n<p>This library provides a reference API for\
    \ openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable,\
    \ hierarchical file formats, this library implements various backends such as\
    \ HDF5, ADIOS1, ADIOS2 and JSON.\nWriting &amp; reading through those backends\
    \ and their associated files are supported for serial and <a href=\"https://www.mpi-forum.org/docs/\"\
    \ rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<h2>\n<a id=\"user-content-usage\"\
    \ class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<h3>\n<a id=\"user-content-c\"\
    \ class=\"anchor\" href=\"#c\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>C++</h3>\n<p><a href=\"https://isocpp.org/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d47ea5fd5ff323ff5c76593ea37f2340533c73de5e6e37a2b27d7dc28070cd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\"\
    \ alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\"\
    \ style=\"max-width:100%;\"></a> <a href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span>\
    \ s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span\
    \ class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"\
    pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>\
    \ &amp; [step, it] : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span>\
    \ &lt;&lt; step &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span\
    \ class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\"\
    >const</span> &amp; [name, mesh] : it.<span class=\"pl-smi\">meshes</span> ) {\n\
    \        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\
    \  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; name &lt;&lt; <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\"\
    >\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\"\
    >for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp;\
    \ val : mesh.<span class=\"pl-c1\">attributes</span>() )\n            std::cout\
    \ &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"\
    pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\
    \    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span>\
    \ <span class=\"pl-k\">const</span> &amp; [name, species] : it.<span class=\"\
    pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"\
    </span></span> &lt;&lt; name &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\"\
    >auto</span> <span class=\"pl-k\">const</span>&amp; val : species.<span class=\"\
    pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt;\
    \ val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n\
    <h3>\n<a id=\"user-content-python\" class=\"anchor\" href=\"#python\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Python</h3>\n\
    <p><a href=\"https://www.python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\"\
    \ alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\"\
    \ style=\"max-width:100%;\"></a> <a href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span>\
    \ <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"\
    pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span\
    \ class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\"\
    >io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\
    \n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"\
    pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span\
    \ class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n  \
    \  <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\
    \n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span\
    \ class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n\
    \        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}'\
    \ attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\"\
    >k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"\
    pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span\
    \ class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span\
    \ class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"\
    pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"\
    pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n  \
    \          <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n\
    <h3>\n<a id=\"user-content-more\" class=\"anchor\" href=\"#more\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>More!</h3>\n\
    <p>Curious?\nOur manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\"\
    \ rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n\
    <h2>\n<a id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Dependencies</h2>\n<p>Required:</p>\n<ul>\n<li>CMake 3.15.0+</li>\n\
    <li>C++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx</li>\n\
    </ul>\n<p>Shipped internally in <code>share/openPMD/thirdParty/</code>:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> 2.13.9+\
    \ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\">BSL-1.0</a>)</li>\n\
    <li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> 2.9.1+ (<a href=\"\
    https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)</li>\n<li>\n\
    <a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a> 3.9.1+ (<a href=\"\
    https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\">MIT</a>)</li>\n<li>\n\
    <a href=\"https://github.com/ToruNiina/toml11\">toml11</a> 3.7.1+ (<a href=\"\
    https://github.com/ToruNiina/toml11/blob/master/LICENSE\">MIT</a>)</li>\n</ul>\n\
    <p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\"\
    \ rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\"\
    \ rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://www.olcf.ornl.gov/center-projects/adios\"\
    \ rel=\"nofollow\">ADIOS1</a> 1.13.1+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either\
    \ with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n\
    </ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python\
    \ 3.6 - 3.10</li>\n<li>pybind11 2.9.1+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py\
    \ 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n\
    <li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n<li>CUDA C++\
    \ (optional, currently used only in tests)</li>\n</ul>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"\
    https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/580cdb6331254f66680bd967326d9630f5124291efd5ace18549fbb93cbae6db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3c3728308a9e416589fa8b3b8168967287c515037bfbd4b40f1b14f266de56fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/92b7b7bb69b2b17d1981ae5fdcdb32f971ee57f54a98ea4804e93fd0a2eb58ef/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4eeb2c48c0e554ea8dbe8e90f73a6f2d217e775e0bd5e5cb90ddf4619ef3a6a0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/2babf79954ea524c24f2f9b1cfa05728fdaccbe0a80c2da6a7a7595cc131894c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\"\
    \ alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>Our community loves to help each other.\n\
    Please <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\"\
    >report installation problems</a> in case you should get stuck.</p>\n<p>Choose\
    \ <em>one</em> of the install methods below to get started:</p>\n<h3>\n<a id=\"\
    user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://spack.io\"\
    \ rel=\"nofollow\">Spack</a>\n</h3>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/becffbecb6a50502286f02ec86c4e62f239f3671148d11341152e0dc695a2fc9/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\"\
    \ alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b29fc54abf92a2a6d1d2c70159eb276df53b67a1294ae3f82b1b0bf22a3c586b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\"\
    \ alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\"\
    \ style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \    +python +adios1 -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack\
    \ load openpmd-api</pre></div>\n<h3>\n<a id=\"user-content-conda\" class=\"anchor\"\
    \ href=\"#conda\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a>\n\
    </h3>\n<p><a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/3ad2b345bb3589aa2d733ca20df72938ed54a48342b69f7cbe9eacab43d84549/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a51d3cd2bfa3c6b01bd0f2e36abc206fb9db5700105fac2acd2c2105fced2ec4/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\"\
    \ style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \           OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\n\
    conda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n\
    <h3>\n<a id=\"user-content-brew\" class=\"anchor\" href=\"#brew\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://brew.sh\" rel=\"nofollow\">Brew</a>\n</h3>\n<p><a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/d873c8c473fece8abf1c34a8299a50b7ee0da9772eb50cce8649e7ca32468a6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\"\
    \ alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/7b767b67facc26db7d850ae5c3155fa949048991dde7a0f5471c1e6862f0a586/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\"\
    \ alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\"\
    \ style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<h3>\n<a\
    \ id=\"user-content-pypi\" class=\"anchor\" href=\"#pypi\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"\
    https://pypi.org\" rel=\"nofollow\">PyPI</a>\n</h3>\n<p><a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fc28bd368523d0b8adab5f4b414aebb304743130eef42bca203f4e9eed428ae7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\"\
    \ alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7cef25e887c028f65d5d7e20f3e7abe394ab328ecb499e34e47460afd2c78558/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\"\
    \ alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82acdd95515851a5ba4a3006871151f76cfe4d6583f6c24e80bd0fd29d391845/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\"\
    \ alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9)\
    \ or on exotic processor architectures, this install method <em>compiles from\
    \ source</em> against the found installations of HDF5, ADIOS1, ADIOS2, and/or\
    \ MPI (in system paths, from other package managers, or loaded via a module system,\
    \ ...).</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                   --user</span>\n\
    python3 -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n\
    <p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional:                                    --user</span>\npython3\
    \ -m pip install -U pip setuptools wheel\npython3 -m pip install -U cmake\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                 \
    \                                                  --user</span>\nopenPMD_USE_MPI=ON\
    \ python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n<p>For\
    \ some exotic architectures and compilers, you might need to disable a compiler\
    \ feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\"\
    \ rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter\
    \ linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                               \
    \                 --user</span>\npython3 -m pip install openpmd-api --no-binary\
    \ openpmd-api</pre></div>\n<p>Additional CMake options can be passed via individual\
    \ environment variables, which need to be prefixed with <code>openPMD_CMAKE_</code>.</p>\n\
    <h3>\n<a id=\"user-content-from-source\" class=\"anchor\" href=\"#from-source\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>From Source</h3>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/0a40953107090abff3b564ec3436668756b873cd4d9e021738a046781a5a0e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\"\
    \ alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>openPMD-api can also be built and installed\
    \ from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\
    \nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests,\
    \ with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which\
    \ python3)</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\"\
    >.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\n\
    ctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required\
    \ for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target\
    \ install</pre></div>\n<p>The following options can be added to the <code>cmake</code>\
    \ call to control features.\nCMake controls options with prefixed <code>-D</code>,\
    \ e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n\
    <td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_ADIOS1</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS1 backend (<code>.bp</code> files up to version BP3)</td>\n</tr>\n<tr>\n\
    <td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n\
    <td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code\
    \ <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro\
    \ independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_INSTALL_RPATH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Add RPATHs to installed binaries</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n\
    <td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n\
    </table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n\
    <sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without\
    \ specific cause is highly discouraged</em></p>\n<p>Additionally, the following\
    \ libraries are shipped internally.\nThe following options allow to switch to\
    \ external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n\
    <th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.9+</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>pybind11</td>\n<td>2.9.1+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_TOML11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>toml11</td>\n<td>3.7.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this\
    \ will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and\
    \ installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code>\
    \ to the <code>cmake</code> command.\nYou can only build a static or a shared\
    \ library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\n\
    In order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code>\
    \ to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and\
    \ command line tools are built.\nIn order to skip building those, pass <code>OFF</code>\
    \ to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_CUDA_EXAMPLES</code></td>\n<td>ON/<strong>OFF</strong>\n\
    </td>\n<td>Use CUDA in examples</td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"\
    user-content-linking-to-your-project\" class=\"anchor\" href=\"#linking-to-your-project\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Linking to your project</h2>\n<p>The install will contain header files\
    \ and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n\
    <h3>\n<a id=\"user-content-cmake\" class=\"anchor\" href=\"#cmake\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CMake</h3>\n\
    <p>If your project is using CMake for its build, one can conveniently use our\
    \ provided <code>openPMDConfig.cmake</code> package which is installed alongside\
    \ the library.</p>\n<p>First set the following environment hint if openPMD-api\
    \ was <em>not</em> installed in a system path:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed\
    \ if installed outside of system paths</span>\n<span class=\"pl-k\">export</span>\
    \ CMAKE_PREFIX_PATH=<span class=\"pl-smi\">$HOME</span>/somepath:<span class=\"\
    pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n<p>Use the following lines in\
    \ your project's <code>CMakeLists.txt</code>:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> supports:           \
    \            COMPONENTS MPI NOMPI HDF5 ADIOS1 ADIOS2</span>\n<span class=\"pl-c1\"\
    >find_package</span>(openPMD 0.9.0 <span class=\"pl-k\">CONFIG</span>)\n\n<span\
    \ class=\"pl-k\">if</span>(openPMD_FOUND)\n    <span class=\"pl-c1\">target_link_libraries</span>(YourTarget\
    \ <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)\n<span class=\"pl-k\"\
    >endif</span>()</pre></div>\n<p><em>Alternatively</em>, add the openPMD-api repository\
    \ source directly to your project and use it via:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">add_subdirectory</span>(<span\
    \ class=\"pl-s\">\"path/to/source/of/openPMD-api\"</span>)\n\n<span class=\"pl-c1\"\
    >target_link_libraries</span>(YourTarget <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n\
    <p>For development workflows, you can even automatically download and build openPMD-api\
    \ from within a depending CMake project.\nJust replace the <code>add_subdirectory</code>\
    \ call with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"\
    pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077\
    \ <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> set(openPMD_BUILD_SHARED_LIBS OFF)  # precedence over BUILD_SHARED_LIBS\
    \ if needed; or:</span>\n<span class=\"pl-c1\">set</span>(openPMD_INSTALL <span\
    \ class=\"pl-smi\">${BUILD_SHARED_LIBS}</span>)  <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> only install if used as shared a library</span>\n<span class=\"\
    pl-c1\">set</span>(openPMD_USE_PYTHON <span class=\"pl-k\">OFF</span>)\nFetchContent_Declare(openPMD\n\
    \  GIT_REPOSITORY <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"\
    </span>\n  GIT_TAG        <span class=\"pl-s\">\"dev\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n\
    <h3>\n<a id=\"user-content-manually\" class=\"anchor\" href=\"#manually\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manually</h3>\n\
    <p>If your (Linux/OSX) project is build by calling the compiler directly or uses\
    \ a manually written <code>Makefile</code>, consider using our <code>openPMD.pc</code>\
    \ helper file for <code>pkg-config</code> which are installed alongside the library.</p>\n\
    <p>First set the following environment hint if openPMD-api was <em>not</em> installed\
    \ in a system path:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed if installed\
    \ outside of system paths</span>\n<span class=\"pl-k\">export</span> PKG_CONFIG_PATH=<span\
    \ class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span class=\"pl-smi\"\
    >$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and compiler flags\
    \ for your project are available via:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> switch to check if openPMD-api\
    \ was build as static library</span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> (via BUILD_SHARED_LIBS=OFF) or as shared library (default)</span>\n\
    <span class=\"pl-k\">if</span> [ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config --variable=static\
    \ openPMD<span class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\
    \ <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>true<span class=\"pl-pds\">\"</span></span> ]\n<span class=\"pl-k\">then</span>\n\
    \    pkg-config --libs --static openPMD\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so\
    \ /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config\
    \ --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib\
    \ -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n\
    <h2>\n<a id=\"user-content-author-contributions\" class=\"anchor\" href=\"#author-contributions\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Author Contributions</h2>\n<p>openPMD-api is developed by many people.\n\
    It was initially started by the <a href=\"https://hzdr.de/crp\" rel=\"nofollow\"\
    >Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\
    >libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\"\
    \ rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"\
    https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe\
    \ following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\
    >contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\"\
    >Axel Huebl (HZDR, now LBNL)</a>:\nproject lead, releases, documentation, automated\
    \ CI/CD, Python bindings, Dask, installation &amp; packaging, prior reference\
    \ implementations</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\">Franz\
    \ Poeschel (CASUS)</a>:\nJSON &amp; ADIOS2 backend, data staging/streaming, reworked\
    \ class design</li>\n<li>\n<a href=\"https://github.com/C0nsultant\">Fabian Koller\
    \ (HZDR)</a>:\ninitial library design and implementation with HDF5 &amp; ADIOS1\
    \ backend</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu (LBNL)</a>:\n\
    non-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n</ul>\n\
    <p>Further thanks go to improvements and contributions from:</p>\n<ul>\n<li>\n\
    <a href=\"https://github.com/CFGrote\">Carsten Fortmann-Grote (EU XFEL GmbH, now\
    \ MPI-EvolBio)</a>:\ndraft of our Python unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\"\
    >Dominik Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n\
    <li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\n\
    support on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\"\
    >James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"\
    https://github.com/psychocoderHPC\">Ren\xE9 Widera (HZDR)</a>:\ndesign improvements\
    \ for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\"\
    >Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n\
    <a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation\
    \ improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\xE9\
    mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n\
    <a href=\"https://github.com/LDAmorim\">L\xEDgia Diana Amorim (LBNL)</a>:\npackage\
    \ integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\"\
    >Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"\
    https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing,\
    \ documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\"\
    >Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"\
    https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask prototyping\
    \ &amp; ADIOS2 benchmarking</li>\n<li>\n<a href=\"https://github.com/jakirkham\"\
    >John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n<li>\n<a href=\"\
    https://github.com/eschnett\">Erik Schnetter (PITP)</a>:\nC++ API bug fixes</li>\n\
    <li>\n<a href=\"https://github.com/jeanbez\">Jean Luca Bez (LBNL)</a>:\nHDF5 performance\
    \ tuning</li>\n</ul>\n<h3>\n<a id=\"user-content-grants\" class=\"anchor\" href=\"\
    #grants\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Grants</h3>\n<p>The openPMD-api authors acknowledge support via the\
    \ following programs.\nThis project has received funding from the European Unions\
    \ Horizon 2020 research and innovation programme under grant agreement No 654220.\n\
    Supported by the Consortium for Advanced Modeling of Particles Accelerators (CAMPA),\
    \ funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\n\
    Supported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort\
    \ of two U.S. Department of Energy organizations (Office of Science and the National\
    \ Nuclear Security Administration).\nThis work was partially funded by the Center\
    \ of Advanced Systems Understanding (CASUS), which is financed by Germany's Federal\
    \ Ministry of Education and Research (BMBF) and by the Saxon Ministry for Science,\
    \ Culture and Tourism (SMWK) with tax funds on the basis of the budget approved\
    \ by the Saxon State Parliament.</p>\n<h3>\n<a id=\"user-content-transitive-contributions\"\
    \ class=\"anchor\" href=\"#transitive-contributions\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Transitive Contributions</h3>\n\
    <p>openPMD-api stands on the shoulders of giants and we are grateful for the following\
    \ projects included as direct dependencies:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS\"\
    >ADIOS1</a> and <a href=\"https://github.com/ornladios/ADIOS2\">ADIOS2</a> by\
    \ <a href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky (ORNL), team,\
    \ collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"\
    https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\xFD</a> and <a href=\"\
    https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n\
    <li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a>\
    \ and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a>\
    \ by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"\
    https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> by <a href=\"\
    https://github.com/ToruNiina\">Toru Niina</a> and <a href=\"https://github.com/ToruNiina/toml11#Contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\"\
    >pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a>\
    \ and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n\
    </li>\n<li>all contributors to the evolution of modern C++ and early library preview\
    \ developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n\
    </li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a>\
    \ and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n\
    </li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"\
    nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\
    \ and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among\
    \ others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\"\
    >openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR,\
    \ now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\
    >contributors</a>\n</li>\n</ul>\n"
  stargazers_count: 85
  subscribers_count: 9
  topics:
  - openpmd
  - openscience
  - hdf5
  - adios
  - mpi
  - hpc
  - research
  - file-handling
  - python3
  - opendata
  - cpp14
  - metadata
  updated_at: 1653490928.0
panosc-eu/spack-repo:
  data_format: 2
  description: EuXFEL Spack Package Repository
  filenames:
  - .docker/opt/spack/etc/spack/spack.yaml
  full_name: panosc-eu/spack-repo
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1648151763.0
player1537-playground/metem:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537-playground/metem
  latest_release: null
  readme: '<h1>

    <a id="user-content-metem-scripts" class="anchor" href="#metem-scripts" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Metem Scripts</h1>

    <p>This repository includes all of the scripts written for the Metem paper as
    part

    of the Triple-R subgoal of the Triple-Convergence project.</p>

    <p>The code is split into 4 categories:</p>

    <ul>

    <li>Overall environment setup (<code>/go.sh</code>)</li>

    <li>Metem-specific code (<code>/metem/</code>)</li>

    <li>ImageNet/ResNet50-specific code (<code>/imagenet/</code>)</li>

    <li>NT3-specific code (<code>/nt3/</code>)</li>

    </ul>

    <h2>

    <a id="user-content-setup" class="anchor" href="#setup" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <p>To setup the environment, run the following command:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">./go.sh
    buildall</span></pre></div>

    <p>This command runs a lot of separate commands in order. Those separate commands

    are:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">./go.sh
    singularity build</span>

    $ <span class="pl-s1">./go.sh spack install</span>

    $ <span class="pl-s1">./go.sh virtualenv setup</span>

    $ <span class="pl-s1">./go.sh wrh configure</span>

    $ <span class="pl-s1">./go.sh wrh build</span>

    $ <span class="pl-s1">./go.sh wrh install</span></pre></div>

    <h2>

    <a id="user-content-existing-data" class="anchor" href="#existing-data" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Existing Data</h2>

    <p>There is already some existing data, primarily checkpoints and log files.</p>

    <p>For ResNet50, these are at:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">ls
    /lus/theta-fs0/projects/VeloC/metem/logs/ai-apps/checkpoint-<span class="pl-k">*</span>e.h5</span>

    $ <span class="pl-s1">ls /lus/theta-fs0/projects/VeloC/metem/logs/ai-apps/<span
    class="pl-k">*</span>of8.log</span></pre></div>

    <p>For example,

    <code>/lus/theta-fs0/projects/VeloC/metem/logs/ai-apps/checkpoint-5e.h5</code>
    is the

    checkpoint taken after 5 epochs have completed.</p>

    <p>For NT3, these are at:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">ls
    /lus/theta-fs0/projects/VeloC/metem/logs/BL<span class="pl-cce">\,</span>dataset<span
    class="pl-cce">\=</span>NT3<span class="pl-cce">\,</span>model<span class="pl-cce">\=</span>default<span
    class="pl-cce">\,</span>nworkers<span class="pl-cce">\=</span>8<span class="pl-cce">\,</span>seed<span
    class="pl-cce">\=</span>1337<span class="pl-cce">\,</span>div<span class="pl-cce">\=</span>1<span
    class="pl-cce">\,</span>nepochs<span class="pl-cce">\=</span>200/checkpoint-<span
    class="pl-k">*</span>.h5</span>

    $ <span class="pl-s1">ls /lus/theta-fs0/projects/VeloC/metem/logs/BL<span class="pl-cce">\,</span>dataset<span
    class="pl-cce">\=</span>NT3<span class="pl-cce">\,</span>model<span class="pl-cce">\=</span>default<span
    class="pl-cce">\,</span>nworkers<span class="pl-cce">\=</span>8<span class="pl-cce">\,</span>seed<span
    class="pl-cce">\=</span>1337<span class="pl-cce">\,</span>div<span class="pl-cce">\=</span>1<span
    class="pl-cce">\,</span>nepochs<span class="pl-cce">\=</span>200/<span class="pl-k">*</span>of8.log</span></pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1629779829.0
range3/chfs-containers:
  data_format: 2
  description: null
  filenames:
  - spack/envs/chfs/spack.yaml
  - spack/envs/chfs-master/spack.yaml
  full_name: range3/chfs-containers
  latest_release: null
  readme: '<h1>

    <a id="user-content-chfs-containers" class="anchor" href="#chfs-containers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>chfs-containers</h1>

    <h2>

    <a id="user-content-example" class="anchor" href="#example" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>example</h2>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    explicitly pull the latest chfs image </span>

    docker pull range3/chfs:master


    git clone https://github.com/range3/chfs-containers

    <span class="pl-c1">cd</span> chfs-containers


    <span class="pl-c"><span class="pl-c">#</span> start servers</span>

    docker-compose up -d


    <span class="pl-c"><span class="pl-c">#</span> start another container for client</span>

    docker run -it --rm --network chfs_net --privileged range3/chfs:master bash

    <span class="pl-c"><span class="pl-c">#</span> set CHFS_SERVER env</span>

    <span class="pl-k">export</span> CHFS_SERVER=<span class="pl-s"><span class="pl-pds">$(</span>chlist
    -c -s ofi+sockets://172.30.0.3:50000<span class="pl-pds">)</span></span>


    <span class="pl-c"><span class="pl-c">#</span> list chfs servers</span>

    chlist


    <span class="pl-c"><span class="pl-c">#</span> mount chfs via FUSE</span>

    mkdir /tmp/m

    chmkdir /tmp/m

    chfuse -o direct_io,modules=subdir,subdir=<span class="pl-s"><span class="pl-pds">"</span>/tmp/m<span
    class="pl-pds">"</span></span> /tmp/m


    <span class="pl-c"><span class="pl-c">#</span> &lt;ctrl-D&gt;</span>

    <span class="pl-c"><span class="pl-c">#</span> the client container is removed</span>


    <span class="pl-c"><span class="pl-c">#</span> stop and remove server containers</span>

    docker-compose down</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652094301.0
robertu94/libpressio-sperr:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/libpressio-sperr
  latest_release: null
  readme: '<h1>

    <a id="user-content-libpressio-sperr" class="anchor" href="#libpressio-sperr"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>LibPressio-SPERR</h1>

    <p>A LibPressio compressor plugin for SPERR. Packaged seperately because of GPL
    Licensing</p>

    <h2>

    <a id="user-content-installation" class="anchor" href="#installation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Via Spack</p>

    <pre><code>git clone https://github.com/robertu94/spack_packages robertu94_packages

    spack repo add ./robertu94_packages


    spack install libpressio-sperr

    </code></pre>

    <p>Manually Via CMake</p>

    <pre><code># install cmake, sperr, libpressio and dependencies first


    cmake -S . -B build -DCMAKE_INSTALL_PREFIX

    cmake --build build

    cmake --install

    </code></pre>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1658183703.0
robertu94/libpressio_adios2:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/libpressio_adios2
  latest_release: null
  readme: '<h1>

    <a id="user-content-libpressio-adios2-io-plugin" class="anchor" href="#libpressio-adios2-io-plugin"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>LibPressio
    ADIOS2 IO Plugin</h1>

    <p>An experimental plugin to read ADIOS2 files in LibPressio use at your own risk</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652738176.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<h1>

    <a id="user-content-roibin-sz-experiments" class="anchor" href="#roibin-sz-experiments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ROIBIN-SZ
    Experiments</h1>

    <h2>

    <a id="user-content-system-information" class="anchor" href="#system-information"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>System
    Information</h2>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <h2>

    <a id="user-content-where-is-the-implementation-of-roibin-sz3" class="anchor"
    href="#where-is-the-implementation-of-roibin-sz3" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Where is the implementation of ROIBIN-SZ3?</h2>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <h2>

    <a id="user-content-getting-started" class="anchor" href="#getting-started" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <h3>

    <a id="user-content-obtaining-data" class="anchor" href="#obtaining-data" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining Data</h3>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <h3>

    <a id="user-content-quality-assessment" class="anchor" href="#quality-assessment"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quality
    Assessment</h3>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <h3>

    <a id="user-content-container-install-for-ease-of-setup" class="anchor" href="#container-install-for-ease-of-setup"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Container
    Install (for ease of setup)</h3>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <h4>

    <a id="user-content-singularity" class="anchor" href="#singularity" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h4>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <h4>

    <a id="user-content-docker" class="anchor" href="#docker" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h4>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <h3>

    <a id="user-content-building-the-container" class="anchor" href="#building-the-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <h3>

    <a id="user-content-manual-install-for-scale" class="anchor" href="#manual-install-for-scale"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    Install (for scale)</h3>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <h2>

    <a id="user-content-running-the-experiments" class="anchor" href="#running-the-experiments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Experiments</h2>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <h3>

    <a id="user-content-example-output" class="anchor" href="#example-output" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example Output</h3>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <h2>

    <a id="user-content-results-for-figures" class="anchor" href="#results-for-figures"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results
    for Figures</h2>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1648861627.0
robertu94/sz-zfp-zchecker:
  data_format: 2
  description: container for the ISC/SC compression tutorial
  filenames:
  - spack.yaml
  full_name: robertu94/sz-zfp-zchecker
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652997619.0
roblatham00/cachercise:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: roblatham00/cachercise
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-cachercise\" class=\"anchor\" href=\"#cachercise\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Cachercise:</h1>\n<p>exploring scalable ways to manage concurrency\
    \ in mochi.  The provider maintains\na simple in-memory data structure.  The client\
    \ api sets and retrieves values\nfrom this structure.</p>\n<h2>\n<a id=\"user-content-requirements\"\
    \ class=\"anchor\" href=\"#requirements\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Requirements</h2>\n<ul>\n<li>bedrock</li>\n\
    </ul>\n<h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Building</h2>\n<p>Pick your <code>INSTALL_PREFIX</code> (e.g. ${HOME}/soft/cachercise)\
    \ and <code>BUILD_TYPE</code> (e.g\nDebug, Release, etc)</p>\n<pre><code>    mkdir\
    \ build\n    cd build\n    cmake .. -DENABLE_TESTS=ON -DENABLE_EXAMPLES=ON -DENABLE_BEDROCK=ON\
    \ \\\n        -DCMAKE_INSTALL_PREFIX=... -DCMAKE_BUILD_TYPE=...\n</code></pre>\n\
    <h2>\n<a id=\"user-content-running-provider\" class=\"anchor\" href=\"#running-provider\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running Provider</h2>\n<p>This is a bedrock-based service.  There\
    \ are some json files in <code>examples</code> to get you started.  One way to\
    \ start the provider side of this benchmark:</p>\n<pre><code>    bedrock -c examples/cachercise-4x-server.json\
    \ na+sm &amp;\n</code></pre>\n<p>Once the provider is running the client can read\
    \ the SSG group file to find the\nprovider.  Client tunables are in a separate\
    \ JSON file.  The\n<code>cachercise-client.json</code> file in <code>examples</code>\
    \ is a good starting point.</p>\n<h3>\n<a id=\"user-content-running-with-jx9\"\
    \ class=\"anchor\" href=\"#running-with-jx9\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running with jx9</h3>\n<p>bedrock\
    \ will let you start the serivce with a json-like configuration language,\ninstead\
    \ of straight json.  See examples/cachercise-server.jx9, which allows us\nto vary\
    \ the number of pools and execution streams like so, instead of creating\na JSON\
    \ file for each configuration:</p>\n<pre><code>   bedrock na+sm -v trace --jx9\
    \ -c examples/cachercise-server.jx9 --jx9-context 'num_extra_pools=4,num_extra_xstreams=16'\
    \ &amp;\n\n</code></pre>\n<h2>\n<a id=\"user-content-clients\" class=\"anchor\"\
    \ href=\"#clients\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Clients</h2>\n<p>The client is an MPI program.  You\
    \ can find some job scripts in the <code>examples</code> directory.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652391781.0
roblatham00/cashersize:
  data_format: 2
  description: Exercise caching in the mochi context
  filenames:
  - spack.yaml
  full_name: roblatham00/cashersize
  latest_release: null
  readme: '<p>Your project "cachersize" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652377734.0
salotz/raylib-scopes:
  data_format: 2
  description: Raylib wrapper for the Scopes language
  filenames:
  - spack.yaml
  full_name: salotz/raylib-scopes
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-scopes-raylib\" class=\"anchor\" href=\"#scopes-raylib\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>scopes-raylib</h1>\n<p>Bindings of <a href=\"https://github.com/raysan5/raylib\"\
    >Raylib</a> for the\n<a href=\"https://scopes.rocks\" rel=\"nofollow\">Scopes</a>\
    \ programming language.</p>\n<p>This is an incredibly thin wrapper as such and\
    \ you can basically use\nthe Raylib C-API with Scopes notation. Some of the naming\
    \ prefixes\nhave been scrubbed to make calling things less verbose.</p>\n<p>There\
    \ are a few macros added for \"begin-end\" type constructs that you\ncan see in\
    \ use in the examples, but you don't need to use them.</p>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The module\
    \ is under <code>src/raylib</code>. You can copy this subtree into your\nproject\
    \ and then add it to the <code>package.path</code> in your Scopes\n<code>_project.sc</code>\
    \ file.</p>\n<h3>\n<a id=\"user-content-with-spack\" class=\"anchor\" href=\"\
    #with-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>With Spack</h3>\n<p>This module is available as the\
    \ <code>scopes-raylib</code> package in the\n<a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> repository. This will pull in the necessary dependencies\nincluding\
    \ Scopes.</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spack install\
    \ scopes-raylib</pre></div>\n<p>See the <a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> documentation for more best practices of installing.</p>\n<h2>\n\
    <a id=\"user-content-development-environment\" class=\"anchor\" href=\"#development-environment\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development Environment</h2>\n<p>We use <a href=\"https://spack.io/\"\
    \ rel=\"nofollow\">Spack</a> to install dependencies. First install Spack.</p>\n\
    <p>Then you'll need our custom repo of build recipes:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  mkdir -p <span class=\"pl-s\"><span class=\"\
    pl-pds\">`</span>/.spack/repos</span>\n<span class=\"pl-s\">  git clone git@github.com:salotz/snailpacks.git\
    \ <span class=\"pl-pds\">`</span></span>/.spack/repos/snailpacks\n  spack repo\
    \ add <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  spack env create -d <span class=\"pl-c1\">.</span></pre></div>\n<p>Activate\
    \ the environment (i.e. set the environment variables\nappropriately) and install\
    \ the packages:</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spacktivate\
    \ <span class=\"pl-c1\">.</span>\n  spack install</pre></div>\n<p>To exit the\
    \ environment (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics:
  - raylib
  - scopes-lang
  updated_at: 1648089749.0
salotz/scopes-chipmunk2d:
  data_format: 2
  description: Scopes language wrapper of Chipmunk2D
  filenames:
  - spack.yaml
  full_name: salotz/scopes-chipmunk2d
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-scopes-chipmunk2d\" class=\"anchor\" href=\"\
    #scopes-chipmunk2d\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>scopes-chipmunk2d</h1>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The module\
    \ is under <code>src/chipmunk2d</code>. You can copy this subtree into your\n\
    project and then add it to the <code>package.path</code> in your Scopes\n<code>_project.sc</code>\
    \ file.</p>\n<h3>\n<a id=\"user-content-with-spack\" class=\"anchor\" href=\"\
    #with-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>With Spack</h3>\n<p>This module is available as the\
    \ <code>scopes-chipmunk2d</code> package in the\n<a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> repository. This will pull in the necessary dependencies\nincluding\
    \ Scopes.</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spack install\
    \ scopes-chipmunk2d</pre></div>\n<p>See the <a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> documentation for more best practices of installing.</p>\n<h2>\n\
    <a id=\"user-content-development-environment\" class=\"anchor\" href=\"#development-environment\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development Environment</h2>\n<p>We use <a href=\"https://spack.io/\"\
    \ rel=\"nofollow\">Spack</a> to install dependencies. First install Spack.</p>\n\
    <p>Then you'll need our custom repo of build recipes:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  mkdir -p <span class=\"pl-s\"><span class=\"\
    pl-pds\">`</span>/.spack/repos</span>\n<span class=\"pl-s\">  git clone git@github.com:salotz/snailpacks.git\
    \ <span class=\"pl-pds\">`</span></span>/.spack/repos/snailpacks\n  spack repo\
    \ add <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  spack env create -d <span class=\"pl-c1\">.</span></pre></div>\n<p>Activate\
    \ the environment (i.e. set the environment variables\nappropriately) and install\
    \ the packages:</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spacktivate\
    \ <span class=\"pl-c1\">.</span>\n  spack install</pre></div>\n<p>To exit the\
    \ environment (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - scopes-lang
  - chipmunk2d
  updated_at: 1648788744.0
salotz/scopes-demos:
  data_format: 2
  description: null
  filenames:
  - 001_chipmunk2d-hello-world/spack.yaml
  - 002_pong/spack.yaml
  - template/{{name}}/spack.yaml
  full_name: salotz/scopes-demos
  latest_release: null
  readme: "<h2>\n<a id=\"user-content-running-the-demos\" class=\"anchor\" href=\"\
    #running-the-demos\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Running the Demos</h2>\n<p>You will need Spack\
    \ installed as well as the <a href=\"\">snailpacks</a> repo. The\nquick bootstrap\
    \ script should be enough to get going if you don't have\nthis installed already:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>curl --proto <span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>=https<span class=\"pl-pds\">'</span></span>\
    \ --tlsv1.2 -sSf https://raw.githubusercontent.com/salotz/snailpacks/master/bootstrap.sh\
    \ <span class=\"pl-k\">|</span> sh</pre></div>\n<p>Then for each demo you can\
    \ build the environment, activate it, and run\nthem.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  <span class=\"pl-c1\">cd</span> XXX_demo-name\n\
    \  make env\n  spacktivate <span class=\"pl-c1\">.</span>\n  make run</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657842137.0
salotz/scopes-lib_copier-template:
  data_format: 2
  description: Copier template for a Scopes library
  filenames:
  - template/spack.yaml
  full_name: salotz/scopes-lib_copier-template
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-project-template-for-a-scopes-lang-library\"\
    \ class=\"anchor\" href=\"#project-template-for-a-scopes-lang-library\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Project\
    \ Template for a Scopes Lang Library</h1>\n<p>This is a project template generator\
    \ and updater using the\n<a href=\"https://github.com/copier-org/copier/\">copier</a>\
    \ tool for creating libraries for the <a href=\"http://scopes.rocks\" rel=\"nofollow\"\
    >Scopes</a> programming language.</p>\n<p>Please install from the latest copier\
    \ for this to work, not the latest\nstable release. Currently I am using\n<a href=\"\
    https://github.com/pypa/pipx\">pipx</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pipx install git+https://github.com/copier-org/copier.git@e98314063246993532048ba2ecf80a049154d2f6</pre></div>\n\
    <h2>\n<a id=\"user-content-generating-a-project\" class=\"anchor\" href=\"#generating-a-project\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Generating a Project</h2>\n<p>Then you can generate your project:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>copier <span class=\"pl-s\"\
    ><span class=\"pl-pds\">'</span>gh:salotz/scopes-lib_copier-template<span class=\"\
    pl-pds\">'</span></span> ./</pre></div>\n<p>This should generate the following\
    \ (<code>repo_name = my-lib</code>):</p>\n<pre><code>my-lib\n\u251C\u2500\u2500\
    \ __env.sc\n\u251C\u2500\u2500 Makefile\n\u251C\u2500\u2500 README.md\n\u251C\u2500\
    \u2500 spack.yaml\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 my-lib\n   \
    \     \u251C\u2500\u2500 init.sc\n        \u2514\u2500\u2500 sanity.sc\n</code></pre>\n\
    <h2>\n<a id=\"user-content-development-environment\" class=\"anchor\" href=\"\
    #development-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Development Environment</h2>\n<p>Create a <a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> environment and install\n\
    dependencies</p>\n<pre><code>cd my-lib\nspack env create -d .\nspacktivate .\n\
    spack install\n</code></pre>\n<p>If you need more you can add them to <code>spack.yaml</code>.</p>\n\
    <p>Then you should be able to run the sanity check:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>scopes -e -m my-lib.sanity</pre></div>\n<p>Start\
    \ coding!</p>\n<h2>\n<a id=\"user-content-libraries-using-this-template\" class=\"\
    anchor\" href=\"#libraries-using-this-template\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Libraries Using this Template</h2>\n\
    <ul>\n<li><a href=\"https://github.com/salotz/raylib-scopes\">scopes-raylib</a></li>\n\
    <li><a href=\"https://github.com/salotz/scopes-chipmunk2d\">scopes-chipmunk2d</a></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - copier-template
  - scopes-lang
  updated_at: 1648781021.0
salotz/snailpacks:
  data_format: 2
  description: Spack repo for multimedia development
  filenames:
  - examples/scopes/spack.yaml
  full_name: salotz/snailpacks
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics:
  - spack
  - spack-repo
  - scopes-lang
  - multimedia
  - game-development
  - package-manager
  - development-environment
  updated_at: 1648089720.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - OLCF/crusher/spack.yaml
  - BOISESTATE/borah/environments/b4s/_spack.yaml
  - OLCF/summit/spack.yaml
  - BOISESTATE/borah/environments/base/_spack.yaml
  - OLCF/spock/spack.yaml
  - BOISESTATE/borah/applications/gromacs/_spack.yaml
  - OLCF/andes/spack.yaml
  - OLCF/peak/spack.yaml
  - OLCF/frontier/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configs" class="anchor" href="#spack-configs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 43
  subscribers_count: 22
  topics: []
  updated_at: 1658168564.0
srini009/soma:
  data_format: 2
  description: 'SPINCER: A Shared Performance Analysis and Monitoring Microservice'
  filenames:
  - spack.yaml
  full_name: srini009/soma
  latest_release: null
  readme: '<h1>

    <a id="user-content-soma-a-service-based-observability-monitoring-and-analytics-framework-for-hpc"
    class="anchor" href="#soma-a-service-based-observability-monitoring-and-analytics-framework-for-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SOMA:
    A Service-based Observability, Monitoring, and Analytics Framework for HPC</h1>

    <p>This is an experimental repo containing a performance monitoring and analysis
    microservice

    for the TAU performance system. SOMA is designed using the Mochi software stack.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1653524006.0
supercontainers/isc-tutorial:
  data_format: 2
  description: ISC 2022 -- Getting Started with Containers on HPC
  filenames:
  - files/spack_contenerize/spack.yaml
  - exercises/spack_contenerize/spack.yaml
  full_name: supercontainers/isc-tutorial
  latest_release: null
  readme: '<h1>

    <a id="user-content-getting-started-with-containers-on-hpc" class="anchor" href="#getting-started-with-containers-on-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/isc-tutorial/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2>

    <a id="user-content-ecp-supercontainers-tutorial-session" class="anchor" href="#ecp-supercontainers-tutorial-session"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ECP
    Supercontainers Tutorial Session</h2>

    <p><a href="fig/ecp.jpg" target="_blank" rel="noopener noreferrer"><img src="fig/ecp.jpg"
    width="250" style="max-width:100%;"></a><a href="fig/pawsey.jpeg" target="_blank"
    rel="noopener noreferrer"><img src="fig/pawsey.jpeg" width="250" style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-details" class="anchor" href="#details" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Half-day Tutorial Session</p>

    <p>Venue: International Supercomputing Conference (ISC 2022)</p>

    <p>Date: 29 May 2022 2:00pm - 6:00pm, Central European Summer Time CEST (GMT+2)</p>

    <p>Location: Hamburg, Germany</p>

    <p>Link: <a href="https://app.swapcard.com/widget/event/isc-high-performance-2022/planning/UGxhbm5pbmdfODYxMTU3"
    rel="nofollow">ISC 2022 Schedule</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2>

    <a id="user-content-ec2-login" class="anchor" href="#ec2-login" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EC2 Login</h2>

    <p>These will be provided the day of the tutorial.</p>

    <h2>

    <a id="user-content-abstract" class="anchor" href="#abstract" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Container computing has revolutionized the way applications are developed and
    delivered.  It offers opportunities that never existed before for significantly
    improving efficiency of scientific workflows and easily moving these workflows
    from the laptop to the supercomputer.  Tools like Docker, Shifter, Singularity,
    Charliecloud and Podman enable a new paradigm for scientific and technical computing.  However,
    to fully unlock its potential, users and administrators need to understand how
    to utilize these new approaches.  This tutorial will introduce attendees to the
    basics of creating container images, explain best practices, and cover more advanced
    topics such as creating images to be run on HPC platforms using various container
    runtimes.  The tutorial will also explain how research scientists can utilize
    container-based computing to accelerate their research and how these tools can
    boost the impact of their research by enabling better reproducibility and sharing
    of their scientific process without compromising security.</p>

    <p>This is an updated version of the highly successful tutorial presented at SC16-21
    and ISC19-21.</p>

    <h2>

    <a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This is a hands-on tutorial.  Participants should bring a laptop and load or
    pre-install a terminal and/or ssh client in advance to make best use of time during
    the tutorial.  We will be providing training user accounts to both pre-configured
    EC2 instances.</p>

    <div><a href="fig/AWS_logo.png" target="_blank" rel="noopener noreferrer"><img
    src="fig/AWS_logo.png" width="250" style="max-width:100%;"></a></div>

    <p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards.  EC2
    images and temporary login credentials will be distributed onsite at the tutorial.</p>

    <p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2
    to run through the tutorial again. We recommend you use your own EC2 key and change
    the password.</p>

    <p>US-West-Oregon: ami-0fe12765123c6a840</p>

    <h3>

    <a id="user-content-optional-prerequisites" class="anchor" href="#optional-prerequisites"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optional
    Prerequisites</h3>

    <p>Users can also install Docker and Singularity prior to attending the tutorial
    session.  Here, it may be beneficial to create Docker and Sylabs (Singularity)
    accounts in advance at <a href="https://cloud.docker.com/" rel="nofollow">https://cloud.docker.com/</a>
    and <a href="https://cloud.sylabs.io/" rel="nofollow">https://cloud.sylabs.io/</a>.  These
    accounts will be needed to create images on Docker Cloud/Dockerhub and Sylabs
    Cloud.</p>

    <p><a href="https://sylabs.io/guides/3.7/user-guide/" rel="nofollow">Install Singularity
    on Linux</a></p>

    <p><a href="https://repo.sylabs.io/desktop/" rel="nofollow">Install Singularity
    on Mac</a> (Alpha)</p>

    <p><a href="https://www.docker.com/products/docker-desktop" rel="nofollow">Install
    Docker for Desktop</a></p>

    <h2>

    <a id="user-content-questions" class="anchor" href="#questions" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2>

    <a id="user-content-schedule-see-the-git-pages-site-for-the-autogenerated-version"
    class="anchor" href="#schedule-see-the-git-pages-site-for-the-autogenerated-version"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Schedule
    (See the git pages site for the autogenerated version)</h2>

    <p>14:00 - 14:15 Introduction to containers in HPC (Shane)<br>

    Including defining jargon (containers, images, registries/repos,..)</p>

    <p>14:15 - 14:55 Build and run your first container (Eduardo)<br>

    Basic of containers and understanding the OCI Image Spec</p>

    <p>14:55 - 15:30 Deploy containers on a supercomputer (Alexis)</p>

    <p>15:30 - 16:00 High-performance containers (Alexis)</p>

    <p>16:00 - 16:30 BREAK</p>

    <p>16:30 - 17:05 Best practices (Shane)</p>

    <p>17:05 - 17:35 E4S containers initiative (Sameer)</p>

    <p>17:35 - 17:55 Advanced container builds (Eduardo)</p>

    <p>17:55 - 18:00 Wrap-up and final Q&amp;A</p>

    '
  stargazers_count: 6
  subscribers_count: 8
  topics:
  - hpc
  - containers
  - singularity-container
  - singularity
  - shifter
  - docker
  - tutorial
  - supercomputer
  updated_at: 1653332288.0
supercontainers/sc-tutorials:
  data_format: 2
  description: SC Tutorials
  filenames:
  - exercises/spack_containerize/spack.yaml
  full_name: supercontainers/sc-tutorials
  latest_release: null
  readme: '<h1>

    <a id="user-content-getting-started-with-containers-on-hpc" class="anchor" href="#getting-started-with-containers-on-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/sc-tutorials/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2>

    <a id="user-content-hpc-containers-tutorial-session" class="anchor" href="#hpc-containers-tutorial-session"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>HPC
    Containers Tutorial Session</h2>

    <p><a href="fig/ecp.jpg" target="_blank" rel="noopener noreferrer"><img src="fig/ecp.jpg"
    width="200" style="max-width:100%;"></a><a href="fig/pawsey.png" target="_blank"
    rel="noopener noreferrer"><img src="fig/pawsey.png" width="200" style="max-width:100%;"></a><a
    href="fig/redhat.png" target="_blank" rel="noopener noreferrer"><img src="fig/redhat.png"
    width="200" style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-details" class="anchor" href="#details" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Full-day Tutorial Session</p>

    <p>Venue: Supercomputing Conference (SC 21)</p>

    <p>Date: TBD November 2022 8am - 5pm Central Standard Time (GMT -6)</p>

    <p>Location: Virtual, St. Louis MO, USA</p>

    <p>Link: <a href="https://sc22.supercomputing.org/presentation/?id=tut114&amp;sess=sess185"
    rel="nofollow">SC 2022 Tutorial Details</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2>

    <a id="user-content-abstract" class="anchor" href="#abstract" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Within just the past few years, the use of containers has revolutionized the
    way in which industries and enterprises have developed and deployed computational
    software and distributed systems. The containerization model has gained traction
    within the HPC community as well with the promise of improved reliability, reproducibility,
    portability, and levels of customization that were previously not possible on
    supercomputers. This adoption has been enabled by a number of HPC Container runtimes
    that have emerged including Singularity, Shifter, Enroot, Charliecloud and others.</p>

    <p>This hands-on tutorial looks to train users on the usability of containers
    on HPC resources. We will provide a detailed background on Linux containers, along
    with introductory hands-on experience building a container image, sharing the
    container and running it on a HPC cluster. Furthermore, the tutorial will provide
    more advanced information on how to run MPI-based and GPU-enabled HPC applications,
    how to optimize I/O intensive workflows, and how to setup GUI enabled interactive
    sessions. Cutting-edge examples will include machine learning and bioinformatics.
    Users will leave the tutorial with a solid foundational understanding of how to
    utilize containers with HPC resources through Shifter and Singularity, as well
    as an in-depth knowledge to deploy custom containers on their own resources.</p>

    <h2>

    <a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>Please consult the website for prerequisites and recommended setup steps.</p>

    <h2>

    <a id="user-content-questions" class="anchor" href="#questions" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2>

    <a id="user-content-schedule---autogenerated-from-the-metadata" class="anchor"
    href="#schedule---autogenerated-from-the-metadata" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Schedule - Autogenerated from the metadata</h2>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics: []
  updated_at: 1649669614.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2022.07.18
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width:100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2022.07.18\"\
    ><img src=\"https://camo.githubusercontent.com/83704e512da41dcecf644b0028c89215c17678ed4fdd8fdf32dc38ef13d42294/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032322e30372e31382d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2022.07.18-informational\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.6856873\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/21a466c7d80106825a14fe2cef160f3cd17ac941d55bb815020554d44d0a5213/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e363835363837332e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.6856873.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" href=\"#what-is-spectre\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>What is SpECTRE?</h2>\n<p>SpECTRE\
    \ is an open-source code for multi-scale, multi-physics problems\nin astrophysics\
    \ and gravitational physics. In the future, we hope that\nit can be applied to\
    \ problems across discipline boundaries in fluid\ndynamics, geoscience, plasma\
    \ physics, nuclear physics, and\nengineering. It runs at petascale and is designed\
    \ for future exascale\ncomputers.</p>\n<p>SpECTRE is being developed in support\
    \ of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into\
    \ the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae,\
    \ and\ngamma-ray bursts.</p>\n<h2>\n<a id=\"user-content-citing-spectre\" class=\"\
    anchor\" href=\"#citing-spectre\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Citing SpECTRE</h2>\n<p>Please cite\
    \ SpECTRE in any publications that make use of its code or data. Cite\nthe latest\
    \ version that you use in your publication. The DOI for this version\nis:</p>\n\
    <ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.6856873\" rel=\"nofollow\"\
    >10.5281/zenodo.6856873</a>\n</li>\n</ul>\n<p>You can cite this BibTeX entry in\
    \ your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"><pre><span\
    \ class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and H\\'ebert, Fran\\c{c}ois and Moxon,\
    \ Jordan and Armaza, Crist\\'obal and</span>\n<span class=\"pl-s\">Bonilla, Gabriel\
    \ S. and Kim, Yoonsoo and Kumar, Prayush and Lovelace, Geoffrey</span>\n<span\
    \ class=\"pl-s\">and Macedo, Alexandra and Nelli, Kyle C. and O'Shea, Eamonn and\
    \ Pfeiffer, Harald</span>\n<span class=\"pl-s\">P. and Scheel, Mark A. and Teukolsky,\
    \ Saul A. and Wittek, Nikolas A. and</span>\n<span class=\"pl-s\">others<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> =\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2022.07.18}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2022.07.18<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">publisher</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Zenodo<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">doi</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>10.5281/zenodo.6856873<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>https://spectre-code.org<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">howpublished</span> =\n<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.6856873}{10.5281/zenodo.6856873}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2022<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>7<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2>\n<a\
    \ id=\"user-content-viewing-documentation\" class=\"anchor\" href=\"#viewing-documentation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Viewing Documentation</h2>\n<p>The documentation can be viewed at\
    \ <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 109
  subscribers_count: 14
  topics: []
  updated_at: 1658243994.0
trilinos/ForTrilinos:
  data_format: 2
  description: ForTrilinos provides portable object-oriented Fortran interfaces to
    Trilinos C++ packages.
  filenames:
  - scripts/spack.yaml
  full_name: trilinos/ForTrilinos
  latest_release: v2.0.0
  readme: '<h1>

    <a id="user-content-fortrilinos" class="anchor" href="#fortrilinos" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ForTrilinos</h1>

    <p><a href="https://cloud.cees.ornl.gov/jenkins-ci/job/ForTrilinos-master-continuous"
    rel="nofollow"><img src="https://camo.githubusercontent.com/857fffb6b672ed62abe998b01a81c3932111fcba10541918cb2f938f414440e6/68747470733a2f2f636c6f75642e636565732e6f726e6c2e676f762f6a656e6b696e732d63692f6275696c645374617475732f69636f6e3f6a6f623d466f725472696c696e6f732d6d61737465722d636f6e74696e756f7573"
    alt="Build Status" data-canonical-src="https://cloud.cees.ornl.gov/jenkins-ci/buildStatus/icon?job=ForTrilinos-master-continuous"
    style="max-width:100%;"></a>

    <a href="http://fortrilinos.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/e261f09cffcfcbf7e647f541614bf7912e3018ccd3a085f035a1219a854f5867/687474703a2f2f72656164746865646f63732e6f72672f70726f6a656374732f666f727472696c696e6f732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="http://readthedocs.org/projects/fortrilinos/badge/?version=latest"
    style="max-width:100%;"></a>

    <a href="https://codecov.io/gh/trilinos/ForTrilinos/branch/develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/fbeea009914f87218441791dba76a1a512b7c287749f94ff47d7b76f49902d23/68747470733a2f2f636f6465636f762e696f2f67682f7472696c696e6f732f466f725472696c696e6f732f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/trilinos/ForTrilinos/branch/develop/graph/badge.svg"
    style="max-width:100%;"></a></p>

    <p><a href="http://trilinos.org/packages/fortrilinos" rel="nofollow">ForTrilinos</a>
    is a part of the <a href="http://trilinos.org" rel="nofollow">Trilinos</a> project
    and provides object-oriented Fortran interfaces to Trilinos C++ packages.</p>

    <p>This is the new effort to provide Fortran interfaces to Trilinos through

    automatic code generation using SWIG. The previous effort (ca. 2008-2012) can

    be obtained by downloading Trilinos releases prior to 12.12. See <a href="https://fortrilinos.readthedocs.io/en/latest/install.html#version-compatibility"
    rel="nofollow">the

    documentation</a> for details on version compatibility.</p>

    <h2>

    <a id="user-content-provided-functionality" class="anchor" href="#provided-functionality"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Provided
    functionality</h2>

    <p>ForTrilinos provides Fortran interfaces for the following capabilities:</p>

    <ul>

    <li>Parameter lists and XML parsers (through Teuchos);</li>

    <li>Distributed linear algebra object including sparse graphs, sparse matrices,
    and dense vectors (through Tpetra);</li>

    <li>Linear solvers and preconditioners (through Stratimikos, Ifpack2, Belos, MueLu);</li>

    <li>Eigen solvers (through Anasazi).</li>

    </ul>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <ul>

    <li>

    <p><a href="https://fortrilinos.readthedocs.org" rel="nofollow">Documentation</a></p>

    </li>

    <li>

    <p><a href="https://trilinos.github.io/ForTrilinos/" rel="nofollow">Summary</a></p>

    </li>

    </ul>

    <h2>

    <a id="user-content-installing-fortrilinos" class="anchor" href="#installing-fortrilinos"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing
    ForTrilinos</h2>

    <p>Please consult the documentation available <a href="https://fortrilinos.readthedocs.io/en/latest/install.html"
    rel="nofollow">here</a>.</p>

    <h2>

    <a id="user-content-questions-bug-reporting-and-issue-tracking" class="anchor"
    href="#questions-bug-reporting-and-issue-tracking" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Questions, Bug Reporting, and Issue Tracking</h2>

    <p>Questions, bug reporting and issue tracking are provided by GitHub. Please

    report all bugs by creating a new issue with the bug tag. You can ask

    questions by creating a new issue with the question tag.</p>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>We encourage you to contribute to ForTrilinos! Please check out the

    <a href="CONTRIBUTING.md">guidelines</a> about how to proceed.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>ForTrilinos is licensed under a BSD license.</p>

    '
  stargazers_count: 24
  subscribers_count: 10
  topics:
  - trilinos
  - fortran
  - swig
  - scientific-computing
  updated_at: 1654781824.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - spack-environments/dial3/compute-node/spack.yaml
  - spack-environments/cosma8/compute-node/spack.yaml
  - spack-environments/csd3/skylake/spack.yaml
  - spack-environments/myriad/compute-node/spack.yaml
  - spack-environments/tesseract/compute-node/spack.yaml
  - spack-environments/github-actions/default/spack.yaml
  - spack-environments/csd3/icelake/spack.yaml
  - spack-environments/tursa/cpu/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-excalibur-tests\" class=\"anchor\" href=\"#excalibur-tests\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks and regression tests\
    \ for the ExCALIBUR project.</p>\n<p>These benchmarks are based on a similar project\
    \ by\n<a href=\"https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2>\n\
    <a id=\"user-content-requirements\" class=\"anchor\" href=\"#requirements\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h2>\n\
    <h3>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><em><strong>Note</strong>: in some HPC facilities there may be already a central\
    \ Spack\ninstallation available.  In principle you should be able to use that\
    \ one (you\nonly need to have <code>spack</code> in the <code>PATH</code>), but\
    \ you may need an up-to-date version\nof Spack in order to install some packages.\
    \  Instructions below show you how to\ninstall Spack locally.</em></p>\n<p><a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager specifically\
    \ designed for HPC\nfacilities.  Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall the latest version of\
    \ Spack.</p>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable.  This\
    \ can be achieved for instance by running\nthe commands to get shell support described\
    \ in Spack documentation, which you\ncan also add to your shell init script to\
    \ do it automatically in every session.\nFor example, if you use a shell of the\
    \ family bash/zsh/sh you can add to your\ninit script:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRac projects.  If\
    \ you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system, if known, otherwise it will automatically\ncreate a very basic environment.</p>\n\
    <h3>\n<a id=\"user-content-reframe\" class=\"anchor\" href=\"#reframe\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ReFrame</h3>\n\
    <p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\" rel=\"nofollow\"\
    >ReFrame</a> is a high-level\nframework for writing regression tests for HPC systems.\
    \  For our tests we\nrequire ReFrame 3.10.1.  Follow the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall this package.  Note\
    \ that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a\
    \ specific module to have this version of Python available.</p>\n<p>We provide\
    \ a ReFrame configuration file with the settings of some systems that\nare part\
    \ of the ExCALIBUR project.  You can point ReFrame to this file by\nsetting the\n\
    <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILE</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILE=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${PWD}</span>/reframe_config.py<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>If you want to use a different ReFrame configuration file, for example because\n\
    you use a different system, you can set this environment variable to the path\
    \ of\nthat file.</p>\n<p><strong>Note</strong>: in order to use the Spack build\
    \ system in ReFrame, the <code>spack</code>\nexecutable must be in the <code>PATH</code>,\
    \ also on the computing nodes of a cluster, if\nyou want to run your benchmarks\
    \ on them.  Note that by default ReFrame uses</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a>, which would not load\nthe user's init script.  If you have added\
    \ Spack to your <code>PATH</code> within your init\nscript, you may want to set\
    \ the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ in order to make ReFrame use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash\
    \ -l</span></pre></div>\n<p>as shebang line, instead.</p>\n<h2>\n<a id=\"user-content-usage\"\
    \ class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<p>Once you have set up\
    \ Spack and ReFrame, you can execute a benchmark with</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/BENCH_NAME -r --performance-report</pre></div>\n\
    <p>where <code>apps/BENCH_NAME</code> is the directory where the benchmark is.\
    \  The command\nabove supposes you have the program <code>reframe</code> in your\
    \ PATH, if it is not the\ncase you can also call <code>reframe</code> with its\
    \ relative or absolute path.  For\nexample, to run the Sombrero benchmark in the\
    \ <code>apps/sombrero</code> directory you can\nuse</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/sombrero -r --performance-report</pre></div>\n\
    <p>For benchmark using the Spack build system, the tests define a default Spack\
    \ specification\nto be installed in the environment, but users can change it when\
    \ invoking ReFrame on the\ncommand line with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c apps/sombrero -r --performance-report -S\
    \ spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3>\n<a id=\"user-content-selecting-system-and-queue-access-options\"\
    \ class=\"anchor\" href=\"#selecting-system-and-queue-access-options\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  You can always use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3>\n<a id=\"user-content-unsupported-systems\"\
    \ class=\"anchor\" href=\"#unsupported-systems\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Unsupported systems</h3>\n<p>The\
    \ configuration provided in <a href=\"./reframe_config.py\"><code>reframe_config.py</code></a>\
    \ lets you run the\nbenchmarks on systems for which the configuration has been\
    \ already contributed.  However you\ncan still use this framework on any system\
    \ by choosing the \"generic\" system with <code>--system generic</code>, or using\
    \ your own ReFrame configuration.  Note, however, that if you use the\n\"generic\"\
    \ system, ReFrame will not know anything about the queue manager of your system,\
    \ if\nany, or the MPI launcher.  For the benchmarks using the Spack build system,\
    \ if you choose\nthe \"generic\" system, a new empty Spack environment will be\
    \ automatically created in\n<code>spack-environments/generic</code>.  In any case,\
    \ you can always make the benchmarks use a\ndifferent Spack environment by setting\
    \ the environment variable <code>EXCALIBUR_SPACK_ENV</code>\ndescribed above.</p>\n\
    <h2>\n<a id=\"user-content-contributing-new-systems-or-benchmarks\" class=\"anchor\"\
    \ href=\"#contributing-new-systems-or-benchmarks\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\n\
    <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 2
  subscribers_count: 6
  topics: []
  updated_at: 1657545914.0
uturuncoglu/testing:
  data_format: 2
  description: It is used for component testing and GitHub Action implementation
  filenames:
  - spack.yaml
  full_name: uturuncoglu/testing
  latest_release: null
  readme: '<h1>

    <a id="user-content-testing" class="anchor" href="#testing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>testing</h1>

    <p>It is used for component testing and GitHub Action implementation</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657212117.0
vanderwb/spack-crayenv:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: vanderwb/spack-crayenv
  latest_release: null
  readme: '<h1>

    <a id="user-content-ncar-spack-deployment" class="anchor" href="#ncar-spack-deployment"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>crayenv</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Fri Jun 17 18:21:49 MDT 2022</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>24319d896f9bd0d58f5327fd89f251d80b844198</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>22.02</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td>v0.18.0</td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/scratch/vanderwb/spack-tests/crayenv/22.02</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/scratch/vanderwb/spack-tests/crayenv/22.02/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1655513096.0
