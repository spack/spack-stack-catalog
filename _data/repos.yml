AlexanderRichert-NOAA/CItest:
  data_format: 2
  description: Set up a simplified test case based on spack/HDF5 build fail due to
    /usr/local contents
  filenames:
  - spack.yaml
  full_name: AlexanderRichert-NOAA/CItest
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1671482597.0
ArjunaCluster/spack:
  data_format: 2
  description: Spack Repos and Configuration Files
  filenames:
  - environments/slurm/spack.yaml
  full_name: ArjunaCluster/spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1637623732.0
CivetWang/HPCHarryW:
  data_format: 2
  description: null
  filenames:
  - assignment/spack.yaml
  full_name: CivetWang/HPCHarryW
  latest_release: null
  readme: '<h1><a id="user-content-hpcharryw" class="anchor" aria-hidden="true" href="#hpcharryw"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPCHarryW</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1653448958.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/22.11/oneapi-x86_64/spack.yaml
  - environments/23.02/oneapi-x86_64/spack.yaml
  - environments/22.11/rocm-x86_64/spack.yaml
  - environments/22.11/cuda-x86_64/spack.yaml
  - environments/22.11/cuda-ppc64le/spack.yaml
  - environments/22.11/cuda-aarch64/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#e4s\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n<ul>\n<li>User\
    \ Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\">https://e4s.readthedocs.io</a>\n\
    </li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub: <a href=\"https://github.com/E4S-Project/\"\
    >https://github.com/E4S-Project/</a>\n</li>\n<li>E4S Slack Channel: <a href=\"\
    https://e4s-project.slack.com\" rel=\"nofollow\">https://e4s-project.slack.com</a>\n\
    </li>\n<li>Slack Channel Invitation: <a href=\"https://communityinviter.com/apps/e4s-project/e4s\"\
    \ rel=\"nofollow\">https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n\
    <li>E4S Dashboard: <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\
    >E4S-Project/E4S-Project.github.io</a> - E4S Documentation repo that is hosted\
    \ on <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 17
  subscribers_count: 10
  topics: []
  updated_at: 1678287231.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, time-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/desktop/spack-ubuntu-openmp.yaml
  - Tools/machines/desktop/spack-macos-openmp.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '23.03'
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" href="#warpx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667"
    alt="Gitter" data-canonical-src="https://badges.gitter.im/ECP-WarpX/community.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1109/SC41404.2022.00008" rel="nofollow"><img src="https://camo.githubusercontent.com/2be0ab9ceaff22581aac9ee5d5eac9cc73cae7e4bad2c69bcf0ffd6713337293/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our Gitter room at <a href="https://gitter.im/ECP-WarpX/community" rel="nofollow">https://gitter.im/ECP-WarpX/community</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 176
  subscribers_count: 15
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1680027971.0
ECP-WarpX/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/artemis
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" href="#artemis"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a development
    fork of WarpX for modeling micromagnetics and electrodynamic waves in next-generation
    microelectornics.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 7
  subscribers_count: 5
  topics: []
  updated_at: 1674918589.0
FTHPC/Correlation_Compressibility:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: FTHPC/Correlation_Compressibility
  latest_release: v0.1
  readme: "<h1><a id=\"user-content-compressibility-analysis-correlation_compressibility\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#compressibility-analysis-correlation_compressibility\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compressibility\
    \ Analysis (Correlation_Compressibility)</h1>\n<h2><a id=\"user-content-statement-of-purpose\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#statement-of-purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Statement of Purpose</h2>\n<p>This\
    \ repo contains scripts to perform compressibility analysis on several leading\
    \ lossy compressors.\nThe compressibility analysis relies on deriving statistics\
    \ on scientific data and explore their relationships to their compression ratios\
    \ from various lossy compressors (based on various compression scheme).\nThe extracted\
    \ relationships between compression ratios and statistical predictors are modeled\
    \ via regression models, which provide a statistical framework to predict compression\
    \ ratios for the different studied lossy compressors.</p>\n<p>This repo contains\
    \ an automatic framework of scripts that perform the compression of scientific\
    \ datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding and Bit\
    \ Grooming), the derivation of the statistical predictors of compression ratios\
    \ (SVD, standard deviation, quantized entropy), and scripts to perform the training\
    \ of the regression models (linear and spline regressions) as well as the validation\
    \ of the regression predictions.\nA runtime analysis is also performed and associated\
    \ codes are provided.</p>\n<h3><a id=\"user-content-main-code-structures\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#main-code-structures\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Main code structures</h3>\n<p>Compression\
    \ metrics, including compression ratios, and derivation of statistical predictors\
    \ (SVD, standard deviation, quantized entropy) codes are found in <code>compress_package</code>\
    \ and are run via <code>scripts/run.sh</code> as described in the section \"How\
    \ to compute statistical predictors and compression analysis on datasets\".\n\
    Linear and spline regressions training and validation (functions <code>cr_regression_linreg</code>\
    \ and <code>cr_regression_gam</code> from the script <code>replicate_figures/functions_paper.R</code>).\n\
    Codes for the different runtime analysis are found in the folder <code>runtime_analysis</code>\
    \ and are automated with the script <code>runtime.sh</code>, the study includes\
    \ compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled)\
    \ variogram and local (tiled) variogram, and runtime for training and prediction\
    \ of the regressions.<br>\nFinally, the script <code>replicate_figures/graphs_paper_container.R</code>\
    \ replicates and saves all the figures from the paper ad as well as numbers from\
    \ the tables.</p>\n<p>For each dataset in the <code>dataset</code> folder, slicing\
    \ is performed for each variable field (e.g. density in Miranda), each slice is\
    \ stored in a class. The class is updated as compressions with the 8 compressors\
    \ is performed and updated as the statistical predictors are derived. Results\
    \ of each class are stored in a .csv file (example of csv files can be found at\
    \ <code>replicate_figures/generated_data/</code>).\nAll the datasets stored in\
    \ the <code>dataset</code> folder can be analyzed with the given set of codes,\
    \ one needs to source <code>scripts/config.json</code> with the appropriate dataset\
    \ name as described in the below section \"How to compute statistical predictors\
    \ and compression analysis on datasets\".\nThe regression analysis and its prediction\
    \ is then performed on R dataframes based on the aforementioned .csv files.</p>\n\
    <h2><a id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#system-information\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>System Information</h2>\n<p>The hardware and software\
    \ versions used for the performance evaluations can be found in the table below.\
    \ These nodes come from Clemson University's Palmetto Cluster.</p>\n<p>These nodes\
    \ have:</p>\n<table>\n<thead>\n<tr>\n<th>component</th>\n<th>version</th>\n<th>component</th>\n\
    <th>version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CPU</td>\n<td>Intel Xeon\
    \ 6148G (40 cores)</td>\n<td>sz2</td>\n<td>2.1.12.2</td>\n</tr>\n<tr>\n<td>GPU</td>\n\
    <td>2 Nvidia v100</td>\n<td>sz3</td>\n<td>3.1.3.1</td>\n</tr>\n<tr>\n<td>Memory</td>\n\
    <td>372GB</td>\n<td>zfp</td>\n<td>0.5.5</td>\n</tr>\n<tr>\n<td>Network</td>\n\
    <td>2 Mellanox MT27710 (HDR)</td>\n<td>mgard</td>\n<td>1.0.0</td>\n</tr>\n<tr>\n\
    <td>FileSystem</td>\n<td>BeeGFS 7.2.3 (24 targets)</td>\n<td>bit grooming</td>\n\
    <td>2.1.9</td>\n</tr>\n<tr>\n<td>Compiler</td>\n<td>GCC 8.4.1</td>\n<td>digit\
    \ rounding</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>OS</td>\n<td>CentOS 8.2.2004</td>\n\
    <td>R</td>\n<td>4.1.3</td>\n</tr>\n<tr>\n<td>MPI</td>\n<td>OpenMPI 4.0.5</td>\n\
    <td>Python</td>\n<td>3.9.12</td>\n</tr>\n<tr>\n<td>LibPressio</td>\n<td>0.83.4</td>\n\
    <td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-first-time-setup\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-setup\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>First time setup</h2>\n<h3><a\
    \ id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#container-installation-for-ease-of-setup\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Container Installation\
    \ (for ease of setup)</h3>\n<p>We provide a container for <code>x86_64</code>\
    \ image for ease of installation.</p>\n<p>This container differs from our experimental\
    \ setup slightly. The production build used <code>-march=native -mtune=native</code>\
    \ for architecture optimized builds where as the container does not use these\
    \ flags to maximize compatibility across <code>x86_64</code> hardware.</p>\n<p>NOTE\
    \ this file is &gt;= 11 GB , download with caution.</p>\n<h3><a id=\"user-content-manual-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#manual-installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manual Installation</h3>\n<p>By\
    \ default, it is recommended to follow the install locations that are indicated\
    \ on the top of <code>scripts/run.sh</code>\nand the top of <code>config.json</code>.\
    \ These two files provide the configuration options to get the program running.</p>\n\
    <p>Spack should be installed in the following location: <code>$HOME/spack/</code></p>\n\
    <p>This Github repo should be cloned in the following location: <code>$HOME/Correlation_Compressibility/</code>\n\
    This location is also referenced as the <code>COMPRESS_HOME</code> environment\
    \ variable.</p>\n<p>A dataset folder called 'datasets' should be in the following\
    \ location: <code>$HOME/Correlation_Compressibility/datasets/</code>.</p>\n<p>Clone\
    \ the repo but make sure to install or load <code>git-lfs</code> first.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> install/module load git-lfs, needed to download example_data\
    \ for building the container</span>\nsudo dnf install git-lfs <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>Fedora/CentOS Stream 8</span>\nsudo apt-get install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ubuntu</span>\nspack\
    \ install git-lfs<span class=\"pl-k\">;</span> spack load git-lfs <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> clone this repository</span>\ngit clone https://github.com/FTHPC/Correlation_Compressibility\
    \ <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility</pre></div>\n\
    <p>If you forgot to install <code>git-lfs</code> before and have an empty file\
    \ in the  <code>datasets</code> folder, you should install <code>git-lfs</code>\n\
    and then run the following:</p>\n<pre><code>git lfs fetch\ngit lfs checkout\n\
    </code></pre>\n<p>Once Spack is installed, there is a <code>spack.yaml</code>\
    \ configuration file containing the Spack environment necessary to run the program.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">$HOME</span>\ngit clone --depth=1 https://github.com/spack/spack\n\
    git clone --depth=1 https://github.com/robertu94/spack_packages \n<span class=\"\
    pl-c1\">source</span> ./spack/share/spack/setup-env.sh \nspack compiler find\n\
    spack external find \nspack repo add --scope=site ./spack_packages \n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ \nspack env activate <span class=\"pl-c1\">.</span>\nspack install\n<span class=\"\
    pl-k\">export</span> COMPRESS_HOME=<span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ </pre></div>\n<p>These commands will install the environment. The environment\
    \ only needs to be installed once.\nIf you are using an older &lt; gcc11, then\
    \ you will need to add the following to the <code>spack.yaml</code> file:</p>\n\
    <pre><code>^libstdcompat+boost\n</code></pre>\n<p>after <code>^mgard@robertu94+cuda</code>\
    \ but before the <code>,</code>.</p>\n<h3><a id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To run the\
    \ training and prediction timing analysis demonstration</h3>\n<p>In order to run\
    \ the timing analysis, a dataset must be specified.\nThere are two datasets setup\
    \ within this demonstration.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh runtime_analysis/runtime.sh -d [DATASET]</pre></div>\n<p>[DATASET] can\
    \ be either [NYX] or [SCALE]</p>\n<p>After running the above script, an *.RData\
    \ file(s) will be produced giving the approprirate timing information of\nthe\
    \ training and prediction for the regression models.</p>\n<p>Note: A quicker and\
    \ more efficient quantized entropy method is demonstrated in <code>qentropy.cc</code></p>\n\
    <h4><a id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-following-below-runs-qentropycc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The following below runs <code>qentropy.cc</code>\n\
    </h4>\n<div class=\"highlight highlight-source-shell\"><pre>g++ -std=c++2a -O3\
    \ qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy</pre></div>\n\
    <p>Note: Please run the runtime analysis for both datasets before running the\
    \ following section.</p>\n<h3><a id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication\
    \ of figures: how to run statistical prediction of compression ratios and the\
    \ prediction validation</h3>\n<p>The script <code>graphs_paper_container.R</code>\
    \  saves the graphs presented in the paper and provides associated validation\
    \ metrics (correlation and median absolute error percentage).</p>\n<p>The script\
    \ <code>graphs_paper_container.R</code> will source the scripts  <code>load_dataset_paper.R</code>\
    \ and <code>functions_paper.R</code> that respectively load the dataset of interest\
    \ and perform the regression analysis (training and prediction in cross-validation).\n\
    As a consequence the scripts  <code>load_dataset_paper.R</code> and <code>functions_paper.R</code>\
    \ do not need to be run by the user.</p>\n<p>The script <code>graphs_paper_container.R</code>\
    \  is run via the command:\n<code>bash sh replicate.sh</code></p>\n<p>From running\
    \ the script once, it will save all Figures 1, 3, 4 and 5 into .png files from\
    \ the paper as well as corresponding validation metrics.\nFigure 2 is not saved\
    \ as it provides a simple vizualization of slices of the datasets.\nSlices of\
    \ the datasets are generated in the Section \"How to compute statistical predictors\
    \ and compression metrics\" and can be stored, however we do not save them here\
    \ to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in\
    \ the R console.\nAll printed validation metrics are save into a file named <code>figure_replication.log</code>.\n\
    Figures and the log-file are saved in the same folder as the one where R script\
    \ is run and the filename structure is <code>figY_*.png</code> with Y is the figure\
    \ number reference in the paper and <code>*</code> provides additional informnation\
    \ about the data and the compressor.<br>\nNumbers for Table 4 are saved in the\
    \ last section in .txt files <code>statistic_benchmark_runtime_X.txt</code> with\
    \ X the studied dataset (NYX or SCALE).</p>\n<p>In order to limit the container\
    \ size to aid reproducibility, we only added a restricted number of scientific\
    \ datasets in the container and we rely on csv files from our production runs\
    \ (saved as described above in the Section \"How to compute statistical predictors\
    \ on datasets\").\nMore datasets are available on <a href=\"https://sdrbench.github.io\"\
    \ rel=\"nofollow\">SDRBench</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1675473427.0
GoogleCloudPlatform/scientific-computing-examples:
  data_format: 2
  description: Open Source examples using Google Cloud to solve various Scientific
    and Technical Computing problems.
  filenames:
  - fluxfw-gcp/tf/examples/containers/spack.yaml
  full_name: GoogleCloudPlatform/scientific-computing-examples
  latest_release: null
  readme: '<h1><a id="user-content-scientific-computing-with-google-cloud" class="anchor"
    aria-hidden="true" href="#scientific-computing-with-google-cloud"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Scientific Computing with Google Cloud</h1>

    <p>A repository of examples.</p>

    <p>These examples are currently organized by the various schedulers used to

    orchestrate the scientific workloads on the Google Cloud Platform (GCP).</p>

    <hr>

    <h2><a id="user-content-flux" class="anchor" aria-hidden="true" href="#flux"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Flux</h2>

    <ul>

    <li><a href="/fluxfw-gcp/README.md">Flux Framework on Google Cloud</a></li>

    </ul>

    <h2><a id="user-content-kubernetes" class="anchor" aria-hidden="true" href="#kubernetes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Kubernetes</h2>

    <ul>

    <li><a href="higgs/README.md">Rediscovering the Higgs boson using the Google Cloud
    Platform</a></li>

    <li><a href="slurm-cookbook/docker/README.md">Running Docker on Slurm (Cookbook)</a></li>

    </ul>

    <h2><a id="user-content-slurm" class="anchor" aria-hidden="true" href="#slurm"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Slurm</h2>

    <ul>

    <li><a href="slurm-cookbook/docker/README.md">HPC Toolkit Support for Slurm and
    Docker on Google Cloud</a></li>

    </ul>

    <h2><a id="user-content-notebooks" class="anchor" aria-hidden="true" href="#notebooks"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Notebooks</h2>

    <p>Various notebooks to demonstrate running Google Cloud from a notebook.</p>

    <ul>

    <li><a href="notebooks/batch_hello_world.ipynb">Hello World for Google Batch</a></li>

    </ul>

    '
  stargazers_count: 5
  subscribers_count: 6
  topics: []
  updated_at: 1680042420.0
JeffersonLab/epsci-containers:
  data_format: 2
  description: Container recipes used or maintained by EPSCI group
  filenames:
  - geant4/spack.yaml
  full_name: JeffersonLab/epsci-containers
  latest_release: null
  readme: ''
  stargazers_count: 1
  subscribers_count: 10
  topics: []
  updated_at: 1679432879.0
JuliaParallel/MPI.jl:
  data_format: 2
  description: MPI wrappers for Julia
  filenames:
  - .ci/mvapich/spack.yaml
  full_name: JuliaParallel/MPI.jl
  latest_release: v0.20.8
  readme: '<h1><a id="user-content-mpi-interface-for-the-julia-language" class="anchor"
    aria-hidden="true" href="#mpi-interface-for-the-julia-language"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>MPI interface for the Julia language</h1>

    <p><a href="https://juliaparallel.github.io/MPI.jl/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667"
    alt="Docs latest" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667"
    alt="Docs stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml"><img
    src="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml/badge.svg"
    alt="Unit Tests" style="max-width: 100%;"></a>

    <a href="https://buildkite.com/julialang/mpi-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/87debbd756a8b45df7ac1f25dc034436051f7ccfe155df49f1ec1f6209e51caf/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65643831336263346437396635353761646264623832316231633863386465393839393936383665363937646634613337332e7376673f6272616e63683d6d6173746572"
    alt="GPU tests" data-canonical-src="https://badge.buildkite.com/ed813bc4d79f557adbdb821b1c8c8de98999686e697df4a373.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00ad86424fd334dccd9dde2876e4f3e82b84ad4219e5c1661d6a06b63f46f516/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f4d50492e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572"
    alt="codecov.io" data-canonical-src="https://codecov.io/github/JuliaParallel/MPI.jl/coverage.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://coveralls.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/4d989c928ad758732dcf79e5d1a0b592a1765763c2237af784955ed806e37ef1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f4d50492e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaParallel/MPI.jl/badge.svg?branch=master&amp;service=github"
    style="max-width: 100%;"></a></p>

    <p>This provides <a href="http://julialang.org/" rel="nofollow">Julia</a> interface
    to the Message Passing Interface (<a href="http://www.mpi-forum.org/" rel="nofollow">MPI</a>),
    roughly inspired by <a href="https://github.com/mpi4py/mpi4py/">mpi4py</a>.</p>

    <p>Please see the <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow">documentation</a>
    for instructions on <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/"
    rel="nofollow">configuration</a> and <a href="https://juliaparallel.github.io/MPI.jl/stable/usage/"
    rel="nofollow">usage</a>.</p>

    <p><strong>Breaking changes with v0.20:</strong> The way how MPI.jl is configured
    to use

    different MPI implementations has changed from v0.19 to v0.20 in a

    <em>non-backward-compatible</em> manner.

    Specifically, most <code>JULIA_MPI_XXX</code> variables do not have an effect
    anymore.

    Please refer to the

    <a href="https://juliaparallel.org/MPI.jl/stable/configuration/#Migration-from-MPI.jl-v0.19-or-earlier"
    rel="nofollow">docs</a>

    for information on how to migrate your existing configuration.</p>

    <h1><a id="user-content-help-and-discussion" class="anchor" aria-hidden="true"
    href="#help-and-discussion"><span aria-hidden="true" class="octicon octicon-link"></span></a>Help
    and discussion</h1>

    <p>For help and discussion, we suggest asking on the following venues:</p>

    <ul>

    <li><a href="https://discourse.julialang.org/c/domain/parallel/34" rel="nofollow">"Julia
    at Scale" topic on the Julia Discourse</a></li>

    <li>#distributed channel on the <a href="https://julialang.slack.com/" rel="nofollow">Julia
    Slack</a> (visit <a href="https://julialang.org/slack/" rel="nofollow">https://julialang.org/slack/</a>
    to join).</li>

    </ul>

    <h1><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h1>

    <p>Contributions are encouraged. In particular, MPI provides several hundred functions,
    only a small number of which are currently exposed. If there are additional functions
    you would like to use, please open an <a href="https://github.com/JuliaParallel/MPI.jl/issues">issue</a>
    or <a href="https://github.com/JuliaParallel/MPI.jl/pulls">pull request</a>.</p>

    <p>Additional examples and documentation improvements are also very welcome.</p>

    <h1><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citation</h1>

    <p>If you use MPI.jl in your work, please cite the following paper:</p>

    <blockquote>

    <p>Simon Byrne, Lucas C. Wilcox, and Valentin Churavy (2021) "MPI.jl: Julia bindings
    for the Message Passing Interface". <em>JuliaCon Proceedings</em>, 1(1), 68, doi:
    <a href="https://doi.org/10.21105/jcon.00068" rel="nofollow">10.21105/jcon.00068</a></p>

    </blockquote>

    '
  stargazers_count: 319
  subscribers_count: 21
  topics:
  - mpi
  - julia
  - hpc
  - julia-language
  - mpich
  - openmpi
  - microsoft-mpi
  updated_at: 1680005017.0
L-LYR/playground:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: L-LYR/playground
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676371970.0
MeteoSwiss/fdb-fortran:
  data_format: 2
  description: Fortran Interface to ECMWF's FDB
  filenames:
  - docker/spack.yaml
  full_name: MeteoSwiss/fdb-fortran
  latest_release: null
  stargazers_count: 0
  subscribers_count: 4
  topics:
  - numericalweatherpredictions
  updated_at: 1678447894.0
MuonColliderSoft/mucoll-spack:
  data_format: 2
  description: Muon Collider software repository for Spack
  filenames:
  - environments/mucoll-release/spack.yaml
  - environments/mucoll-common/spack.yaml
  full_name: MuonColliderSoft/mucoll-spack
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-package-repository-for-muon-collider-software-stack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#spack-package-repository-for-muon-collider-software-stack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n<a href=\"\
    https://github.com/spack/spack\">Spack</a> package repository for Muon Collider\
    \ software stack</h1>\n<p>This repository holds a set of Spack recipes for Muon\
    \ Collider software (under namespace <code>mucoll</code>) based on <a href=\"\
    https://key4hep.github.io/key4hep-doc/\" rel=\"nofollow\">Key4hep</a> stack. It\
    \ extends the corresponding <a href=\"https://github.com/key4hep/key4hep-spack\"\
    >key4hep-stack</a> repository, which is required for installation, overriding\
    \ several packages by the ones customised for Muon Collider simulation studies.</p>\n\
    <p>After installing <a href=\"https://github.com/key4hep/spack\">Spack</a> and\
    \ downloading the <a href=\"https://github.com/key4hep/key4hep-spack\">key4hep-spack</a>\
    \ and <a href=\"https://github.com/MuonColliderSoft/mucoll-spack\">mucoll-spack</a>\
    \ repositories, the whole software stack can be installed using the following\
    \ commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Add repositories</span>\nspack repo add ./key4hep-spack\n\
    spack repo add ./mucoll-spack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a Spack environment</span>\nspack env create sim\nspack env activate\
    \ sim\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy package configurations</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Install the software stack</span>\nspack add mucoll-stack\nspack\
    \ concretize\nspack install --fail-fast\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Load packages into environment</span>\nspack load</pre></div>\n\
    <h2><a id=\"user-content-package-versioning\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#package-versioning\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Package versioning</h2>\n<p>Preferred convention for\
    \ version names in Spack is numbers separated by dots, without leading zeros,\
    \ e.g. <code>1.2.13</code>.\nConversion to tag names in <code>mucoll</code> packages\
    \ is provided by <code>MCIlcsoftpackage</code> class defined in <code>packages/mucoll-stack/mucoll_utils.py</code>,\
    \ e.g. for <a href=\"https://github.com/MuonColliderSoft/lcgeo/releases/tag/v00-17-MC\"\
    ><code>lcgeo</code></a> package version <code>0.17</code> corresponds to tag name\
    \ <code>v00-17-MC</code>.</p>\n<h2><a id=\"user-content-adding-new-versions-for-individual-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-versions-for-individual-packages\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new\
    \ versions for individual packages</h2>\n<p>After a new tag for repository is\
    \ created, e.g. <code>v00-17-MC</code> in <code>lcgeo</code> repository, it can\
    \ be added to this Spack repository in two steps:</p>\n<ol>\n<li>Get the archive\
    \ checksum for the new tag</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack checksum lcgeo 0.17\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Validates archive URL and returns the checksum</span>\n    version(<span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>0.17<span class=\"pl-pds\">'</span></span>,\
    \ sha256=<span class=\"pl-s\"><span class=\"pl-pds\">'</span>5ab33aaf5bc37deba82c2dde78cdce6c0041257222ed7ea052ecdd388a41cf9b<span\
    \ class=\"pl-pds\">'</span></span>)</pre></div>\n<ol start=\"2\">\n<li>Add the\
    \ returned version definition to the corresponding package file: <a href=\"packages/lcgeo/package.py\"\
    ><code>packages/lcgeo/package.py</code></a>\n</li>\n</ol>\n<blockquote>\n<p>NOTE:\
    \ This repository only contains packages maintained by the Muon Collider collaboration.\n\
    If the version of interest is missing from Spack for an external package, the\
    \ line with new version definition should be added to the package file in the\
    \ corresponding repository.<br>\nTo see locations of other repositories: <code>spack\
    \ repo list</code></p>\n</blockquote>\n<h2><a id=\"user-content-creating-a-new-stack-release\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#creating-a-new-stack-release\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ a new stack release</h2>\n<p>To introduce a new release version for the whole\
    \ software stack, update the version number in <a href=\"packages/mucoll-stack/package.py\"\
    ><code>packages/mucoll-stack/package.py</code></a> and then update versions of\
    \ all the relevant packages in [environments/mucoll-release/packages.yaml].<br>\n\
    Test this new configuration in a fresh environment:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a development environment</span>\nspack env create dev\nspack env activate\
    \ dev\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy the package configuration</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Add stack with updated version to the environment</span>\nspack\
    \ add mucoll-stack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Check\
    \ which packages would be installed</span>\nspack spec --reuse -NIt</pre></div>\n\
    <p>If the previous release is already installed in a separate environment, packages\
    \ that have not changed since last release will be marked as installed, providing\
    \ a convenient overview of changes in the new release.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1679435634.0
NCAR/spack-casper:
  data_format: 2
  description: Spack production user software stack on the Casper system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-casper
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>casper</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Wed Mar 22 21:50:19 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fc3df9ab78502b74368eb656923301f672d491f6</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.03</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/casper/23.03</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/casper/23.03/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 0
  subscribers_count: 8
  topics: []
  updated_at: 1679548145.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-22.05/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/prod/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cce/spack.yaml
  - spack-configs/perlmutter-user-spack/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file. The documentation is available at\
    \ <a href=\"https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <h2><a id=\"user-content-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-configuration\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Configuration</h2>\n<p>The spack configuration\
    \ can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<h2><a id=\"user-content-running-ci-pipelines\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-ci-pipelines\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>. Please make sure you\
    \ login to the appropriate hostname when starting the gitlab runner.</p>\n<table>\n\
    <thead>\n<tr>\n<th>System</th>\n<th>Runner Name</th>\n<th>Hostname</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n\
    <td><code>login27</code></td>\n</tr>\n<tr>\n<td>cori</td>\n<td><code>cori-e4s</code></td>\n\
    <td><code>cori02</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    <td><code>login02</code></td>\n</tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n\
    <td><code>gert01</code></td>\n</tr>\n</tbody>\n</table>\n<p>The runner configuration\
    \ files are located in <code>~/.gitlab-runner</code> for user <strong>e4s</strong>.</p>\n\
    <p>The production pipelines are triggered via web-interface which requires approval\
    \ from a project maintainer. Production pipelines should be run when we need to\
    \ do full redeployment of stack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#current-challenges\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have external packages set for packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li><strong>Erik Palmer (<a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>)</strong></li>\n\
    <li><strong>Justin Cook (<a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 8
  subscribers_count: 14
  topics: []
  updated_at: 1673545287.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 44
  subscribers_count: 21
  topics: []
  updated_at: 1680023614.0
NOAA-EMC/NCEPLIBS-grib_util:
  data_format: 2
  description: This is a collection of NCEP GRIB related utilities.
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/NCEPLIBS-grib_util
  latest_release: v1.2.4
  readme: '<h1><a id="user-content-nceplibs-grib_util" class="anchor" aria-hidden="true"
    href="#nceplibs-grib_util"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCEPLIBS-grib_util</h1>

    <p>This is a collection of NCEP GRIB related utilities. This is related

    to the <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> project.</p>

    <p>For complete documentation see

    <a href="https://noaa-emc.github.io/NCEPLIBS-grib_util/" rel="nofollow">https://noaa-emc.github.io/NCEPLIBS-grib_util/</a>.
    For the NCEP WMO GRIB2

    Documentation see

    <a href="https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/" rel="nofollow">https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/</a>.</p>

    <h2><a id="user-content-related-nceplibs-projects" class="anchor" aria-hidden="true"
    href="#related-nceplibs-projects"><span aria-hidden="true" class="octicon octicon-link"></span></a>Related
    NCEPLIBS Projects</h2>

    <table>

    <thead>

    <tr>

    <th>Repository</th>

    <th>Notes</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2c">NCEPLIBS-g2c</a></td>

    <td>C implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></td>

    <td>Fortran implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></td>

    <td>Utilities for GRIB2 templates</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <table>

    <thead>

    <tr>

    <th>Utility</th>

    <th>Author(s)</th>

    <th>User(s)</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>cnvgrib</td>

    <td>Stephen Gilbert, Gordon, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>copygb</td>

    <td>Mark Iredell, Stephen Gilbert, Trojan, Boi Vuong</td>

    <td>UFS_UTILS</td>

    </tr>

    <tr>

    <td>copygb2</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>degrib2</td>

    <td>Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grb2index</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grbindex</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong, W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    <tr>

    <td>tocgrib</td>

    <td>Stephen Gilbert, Boi Vuong, Farley, R. E. Jones</td>

    <td>RAP for FAA</td>

    </tr>

    <tr>

    <td>tocgrib2</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>tocgrib2super</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>wgrib</td>

    <td>W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    </tbody>

    </table>

    <p>Code Manager : Hang Lei, Edward Hartnett</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This package requires the following third party libraries:</p>

    <ul>

    <li><a href="http://www.ece.uvic.ca/~mdadams/jasper/" rel="nofollow">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="http://www.gzip.org/zlib/" rel="nofollow">libz</a></li>

    </ul>

    <p>This package requires the folling NCEPLIBS libraries:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a> (before
    version 1.3.0)</li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a> (starting
    version 1.3.0)</li>

    </ul>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <pre><code>mkdir build

    cd build

    cmake -DCMAKE_INSTALL_PREFIX=/path/to/install -DCMAKE_PREFIX_PATH=/path/to/dependencies
    ..

    make -j4

    make install

    </code></pre>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 6
  subscribers_count: 3
  topics: []
  updated_at: 1656698184.0
NOAA-EMC/WW3:
  data_format: 2
  description: WAVEWATCH III
  filenames:
  - model/ci/spack_gnu.yaml
  - model/ci/spack_intel.yaml
  full_name: NOAA-EMC/WW3
  latest_release: 6.07.1
  readme: "<h1><a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2><a id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#general-features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 193
  subscribers_count: 47
  topics: []
  updated_at: 1679444380.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/gfs-v16.2/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/ufs-weather-model-static/spack.yaml
  - configs/templates/unified-dev/spack.yaml
  - configs/templates/skylab-no-python-dev/spack.yaml
  - configs/templates/skylab-dev/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: spack-stack-1.2.0
  readme: '<h1><a id="user-content-spack-stack" class="anchor" aria-hidden="true"
    href="#spack-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>Spack-stack enables the installation of software required

    for HPC system deployments of NOAA''s Unified Forecast System (UFS) and

    other weather and climate models, including components of the Joint

    Effort for Data assimilation Integration (JEDI).</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>.</li>

    </ul>

    <p>Spack-stack is a thin layer around a fork of the

    <a href="https://github.com/spack/spack">spack</a> repository. Spack is a

    community-supported, multi-platform, Python-based package manager

    originally developed by the Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about spack see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for

    spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack

    documentation</a>.</p>

    <p>The stack can be installed on a range of platforms, from Linux and

    macOS laptops to HPC systems, and comes pre-configured for many

    systems. Users can install the necessary packages for a particular

    application and later add the missing packages for another application

    without having to rebuild the entire stack.</p>

    <p>spack-stack is mainly a collection of Spack configuration files, but

    provides a Spack extension to simplify the installation process:</p>

    <ul>

    <li>

    <p><code>spack stack create</code> is provided to copy common, site-specific,
    and

    application-specific configuration files into a coherent Spack

    environment and to create container recipes</p>

    </li>

    <li>

    <p><code>spack stack setup-meta-modules</code> creates compiler, MPI and Python

    meta-modules for a convenient setup of a user environment using

    modules (lua and tcl)</p>

    </li>

    </ul>

    <p>Documentation for installing and using spack-stack can be found here:

    <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a></p>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>

    <p><a href="https://www.github.com/AlexanderRichert-NOAA">Alex Richert</a>, <a
    href="https://www.github.com/Hang-Lei-NOAA">Hang

    Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed

    Hartnett</a> NOAA-EMC</p>

    </li>

    <li>

    <p><a href="https://www.github.com/climbfuji">Dom Heinzeller</a>, JCSDA</p>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 15
  subscribers_count: 7
  topics: []
  updated_at: 1678872587.0
PDC-support/PDC-SoftwareStack:
  data_format: 2
  description: null
  filenames:
  - spack-settings/22.06/0.18.1/prod/spack.yaml
  full_name: PDC-support/PDC-SoftwareStack
  latest_release: null
  readme: '<h1><a id="user-content-pdc-software-stack" class="anchor" aria-hidden="true"
    href="#pdc-software-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>PDC
    Software Stack</h1>

    <p>Repository to store documentation, installation procedure, installation procedures
    and data for validation of installed software</p>

    <h2><a id="user-content-modules" class="anchor" aria-hidden="true" href="#modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Modules</h2>

    <p>Modules for easybuild and CrayPE are within the module folder.</p>

    <h2><a id="user-content-easybuild" class="anchor" aria-hidden="true" href="#easybuild"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EasyBuild</h2>

    <p>EasyBuild easyconfigs should be stored in <em>easybuild/easyconfigs</em> folder</p>

    <h2><a id="user-content-spack" class="anchor" aria-hidden="true" href="#spack"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack</h2>

    <p>Spack installation procedures for software should be store in the <em>spack</em>
    folder</p>

    <h2><a id="user-content-manual-installations" class="anchor" aria-hidden="true"
    href="#manual-installations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    installations</h2>

    <p>Procedures should be store in the <em>other</em> folder</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1666354279.0
RMeli/my-spack:
  data_format: 2
  description: Spack environments
  filenames:
  - envs/alps/dlaf-mkl-cuda/spack.yaml
  - envs/alps/cp2k-dlaf-cpu/spack.yaml
  full_name: RMeli/my-spack
  latest_release: null
  readme: '<h1><a id="user-content-my-spack" class="anchor" aria-hidden="true" href="#my-spack"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>My Spack</h1>

    <p>Spack-related stuff for @RMeli.</p>

    <h2><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    href="#package-repository"><span aria-hidden="true" class="octicon octicon-link"></span></a>Package
    Repository</h2>

    <p><a href="https://spack.readthedocs.io/en/latest/repositories.html" rel="nofollow">Spack
    Package Repositories</a></p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679671251.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.18.1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#rhel7-spack-config\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#useful-commands\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack\
    \ module lmod refresh\n</code></pre>\n<h2><a id=\"user-content-installing-new-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-new-packages\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new\
    \ packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack\
    \ package updates could result in additional installation of packages with little\
    \ or no package source code changes.  These additional installs can be avoided\
    \ when installing new packages by first examining the output of the <code>spack\
    \ spec -I</code> command.  If a utility/infrastructure level package, such as\
    \ cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column\
    \ then it means that the existing install will be used.  If spack does not default\
    \ to using the existing install you can append the hash of the package to the\
    \ spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi\
    \ install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\n\
    Input spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\n\
    Concretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo\
    \ ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]     \
    \ ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64\
    \ \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64\
    \ \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]  \
    \        ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]  \
    \            ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643231013.0
SeisSol/yateto:
  data_format: 2
  description: null
  filenames:
  - tests/spack.yaml
  full_name: SeisSol/yateto
  latest_release: null
  readme: "<h1><a id=\"user-content-yateto\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#yateto\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>YATeTo</h1>\n\
    <p>It is <strong>Y</strong>et <strong>A</strong>nother <strong>Te</strong>nsor\
    \ <strong>To</strong>olbox for discontinuous Galerkin methods and other\napplications.\
    \ You can find much more information about the package\n<a href=\"https://arxiv.org/abs/1903.11521\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h2><a id=\"user-content-installation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Installation</h2>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pip install -e <span class=\"pl-c1\">.</span></pre></div>\n\
    <h2><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">yateto</span> <span class=\"pl-k\">import</span> <span\
    \ class=\"pl-c1\">*</span>\n\n...\n<span class=\"pl-k\">def</span> <span class=\"\
    pl-en\">add</span>(<span class=\"pl-s1\">g</span>):\n  <span class=\"pl-v\">N</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-c1\">8</span>\n  <span class=\"\
    pl-v\">A</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Tensor</span>(<span\
    \ class=\"pl-s\">'A'</span>, (<span class=\"pl-v\">N</span>, <span class=\"pl-v\"\
    >N</span>))\n  <span class=\"pl-v\">B</span> <span class=\"pl-c1\">=</span> <span\
    \ class=\"pl-v\">Tensor</span>(<span class=\"pl-s\">'B'</span>, (<span class=\"\
    pl-v\">N</span>, <span class=\"pl-v\">N</span>, <span class=\"pl-v\">N</span>))\n\
    \  <span class=\"pl-s1\">w</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Tensor</span>(<span class=\"pl-s\">'w'</span>, (<span class=\"pl-v\">N</span>,))\n\
    \  <span class=\"pl-v\">C</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Tensor</span>(<span class=\"pl-s\">'C'</span>, (<span class=\"pl-v\">N</span>,\
    \ <span class=\"pl-v\">N</span>))\n  \n  <span class=\"pl-s1\">kernel</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">C</span>[<span class=\"pl-s\"\
    >'ij'</span>] <span class=\"pl-c1\">&lt;=</span> <span class=\"pl-c1\">2.0</span>\
    \ <span class=\"pl-c1\">*</span> <span class=\"pl-v\">C</span>[<span class=\"\
    pl-s\">'ij'</span>] <span class=\"pl-c1\">+</span> <span class=\"pl-v\">A</span>[<span\
    \ class=\"pl-s\">'lj'</span>] <span class=\"pl-c1\">*</span> <span class=\"pl-v\"\
    >B</span>[<span class=\"pl-s\">'ikl'</span>] <span class=\"pl-c1\">*</span> <span\
    \ class=\"pl-s1\">w</span>[<span class=\"pl-s\">'k'</span>]\n  <span class=\"\
    pl-s1\">g</span>.<span class=\"pl-en\">add</span>(<span class=\"pl-s1\">name</span><span\
    \ class=\"pl-c1\">=</span><span class=\"pl-s\">'kernel'</span>, <span class=\"\
    pl-s1\">ast</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\">kernel</span>)\n\
    \n<span class=\"pl-c\"># 'd' - double precision; 'hsw' - haswell-like architecture</span>\n\
    <span class=\"pl-s1\">arch</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-en\">useArchitectureIdentifiedBy</span>(<span class=\"pl-s\">\"dhsw\"</span>)\n\
    <span class=\"pl-s1\">generator</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Generator</span>(<span class=\"pl-s1\">arch</span>)\n<span class=\"pl-en\"\
    >add</span>(<span class=\"pl-s1\">generator</span>)\n<span class=\"pl-s1\">generator</span>.<span\
    \ class=\"pl-en\">generate</span>(<span class=\"pl-s1\">output_dir</span>, <span\
    \ class=\"pl-v\">GeneratorCollection</span>([<span class=\"pl-v\">LIBXSMM</span>(<span\
    \ class=\"pl-s1\">arch</span>), <span class=\"pl-v\">Eigen</span>(<span class=\"\
    pl-s1\">arch</span>)]))\n...</pre></div>\n"
  stargazers_count: 5
  subscribers_count: 12
  topics: []
  updated_at: 1676025850.0
SouthernMethodistUniversity/msds_hpc:
  data_format: 2
  description: null
  filenames:
  - classes/04_2/spack_containers/spack.yaml
  full_name: SouthernMethodistUniversity/msds_hpc
  latest_release: null
  readme: '<h1><a id="user-content-ds-7347-high-performance-computing-hpc-and-data-science"
    class="anchor" aria-hidden="true" href="#ds-7347-high-performance-computing-hpc-and-data-science"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>DS 7347 High-Performance
    Computing (HPC) and Data Science</h1>

    <h2><a id="user-content-assignments" class="anchor" aria-hidden="true" href="#assignments"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Assignments</h2>

    <table>

    <thead>

    <tr>

    <th align="left">Key</th>

    <th align="left">Value</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="left">A</td>

    <td align="left">Assignment</td>

    </tr>

    <tr>

    <td align="left">L</td>

    <td align="left">Lab</td>

    </tr>

    <tr>

    <td align="left">P</td>

    <td align="left">Project</td>

    </tr>

    </tbody>

    </table>

    <table>

    <thead>

    <tr>

    <th align="left">Assignment</th>

    <th align="left">Issued</th>

    <th align="left">Due</th>

    <th align="left">Deliverable</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="left">A1</td>

    <td align="left">04-26</td>

    <td align="left">NA</td>

    <td align="left">Fork class repo.</td>

    </tr>

    <tr>

    <td align="left">A2</td>

    <td align="left">04-28</td>

    <td align="left">05-03</td>

    <td align="left"><code>assignments/assignment_02.md</code></td>

    </tr>

    <tr>

    <td align="left">A3</td>

    <td align="left">05-05</td>

    <td align="left">NA</td>

    <td align="left">Detail the CPU, GPU, memory, and hard drive for your own computer.</td>

    </tr>

    <tr>

    <td align="left">A4.1</td>

    <td align="left">05-10</td>

    <td align="left">05-17</td>

    <td align="left"><code>assignments/assignment_04.sh</code></td>

    </tr>

    <tr>

    <td align="left">L1</td>

    <td align="left">05-12</td>

    <td align="left">05-19</td>

    <td align="left"><code>assignments/lab_01.{yaml,md}</code></td>

    </tr>

    <tr>

    <td align="left">A4.2</td>

    <td align="left">05-17</td>

    <td align="left">05-24</td>

    <td align="left"><code>assignments/assignment_04.dockerfile</code></td>

    </tr>

    <tr>

    <td align="left">L2</td>

    <td align="left">05-19</td>

    <td align="left">05-26</td>

    <td align="left"><code>assignments/lab_02.{dockerfile,png,jpg}</code></td>

    </tr>

    <tr>

    <td align="left">A5.1</td>

    <td align="left">05-24</td>

    <td align="left">05-31</td>

    <td align="left"><code>assignments/assignment_05.out</code></td>

    </tr>

    <tr>

    <td align="left">P1</td>

    <td align="left">05-26</td>

    <td align="left">06-02</td>

    <td align="left"><code>project/proposal.md</code></td>

    </tr>

    <tr>

    <td align="left">L3</td>

    <td align="left">06-07</td>

    <td align="left">06-21</td>

    <td align="left"><code>assignments/lab_03.{yaml,sh,make or cmake}</code></td>

    </tr>

    <tr>

    <td align="left">P2</td>

    <td align="left">06-09</td>

    <td align="left">06-16</td>

    <td align="left">Create new GitHub repo from project template.</td>

    </tr>

    <tr>

    <td align="left">P3</td>

    <td align="left">06-16</td>

    <td align="left">06-21</td>

    <td align="left">Prototype of multi-job Slurm submit script.</td>

    </tr>

    <tr>

    <td align="left">A5.2</td>

    <td align="left">06-21</td>

    <td align="left">06-23</td>

    <td align="left"><code>assignments/assignment_05.txt</code></td>

    </tr>

    <tr>

    <td align="left">P4</td>

    <td align="left">06-23</td>

    <td align="left">06-28</td>

    <td align="left">Implement one subtask of your workflow using "easiest" installation
    path.</td>

    </tr>

    <tr>

    <td align="left">P5</td>

    <td align="left">06-30</td>

    <td align="left">NA</td>

    <td align="left">Explore various file formats for your data and compare performance.</td>

    </tr>

    <tr>

    <td align="left">P6</td>

    <td align="left">07-05</td>

    <td align="left">07-12</td>

    <td align="left">Complete non-optimized and basic workflow, reduce data or analysis
    complexity if needed.</td>

    </tr>

    <tr>

    <td align="left">P7</td>

    <td align="left">07-14</td>

    <td align="left">07-19</td>

    <td align="left">Report three targets for optimization and baseline performance</td>

    </tr>

    <tr>

    <td align="left">P8</td>

    <td align="left">07-19</td>

    <td align="left">07-28</td>

    <td align="left">Implement initial improvements for your three optimization targets</td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657068578.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/runner/_archived/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/runner/_archived/ubuntu18.04-x86_64/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 20
  subscribers_count: 6
  topics: []
  updated_at: 1673374590.0
ai2cm/fv3net:
  data_format: 2
  description: explore the FV3 data for parameterization
  filenames:
  - docker/ufs_utils/spack.yaml
  full_name: ai2cm/fv3net
  latest_release: n2f-3km-initial-submission
  readme: '<h1><a id="user-content-fv3net" class="anchor" aria-hidden="true" href="#fv3net"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>fv3net</h1>

    <p><a href="https://circleci.com/gh/ai2cm/fv3net/tree/master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a552f20b68ca052bd00beeb5ce611dd080f121e453b44f371d63405aeec20c78/68747470733a2f2f636972636c6563692e636f6d2f67682f616932636d2f6676336e65742f747265652f6d61737465722e7376673f7374796c653d737667"
    alt="CircleCI" data-canonical-src="https://circleci.com/gh/ai2cm/fv3net/tree/master.svg?style=svg"
    style="max-width: 100%;"></a></p>

    <p>Improving the GFDL FV3 model physics with machine learning. See the <a href="https://vulcanclimatemodeling.com/docs/fv3net/"
    rel="nofollow">documentation</a> for more information on using this suite of tools.</p>

    <p>Disclaimer: This is a work in progress.</p>

    '
  stargazers_count: 14
  subscribers_count: 8
  topics: []
  updated_at: 1675296401.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent7/libs_old/spack.yaml
  - cent8/envs/avx512/rproject/spack.yaml
  - cent7/bio_old/spack.yaml
  - cent7/bioinformatics_default/spack.yaml
  - cent7/library/spack.yaml
  - cent8/envs/avx2/python/spack.yaml
  - cent8/envs/avx/python/spack.yaml
  - cent7/python_376/spack.yaml
  - cent8/envs/avx/rproject/spack.yaml
  - cent7/py_376/spack.yaml
  - compilers/envs/compilers/spack.yaml
  - cent7/apps/spack.yaml
  - cent7/mpis/spack.yaml
  - cent7/ece_hpc/spack.yaml
  - cent7/bioinformatics/spack.yaml
  - cent7/library/bak/spack.yaml
  - cent8/envs/avx2/rproject/spack.yaml
  - cent8/envs/avx512/python/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1><a id="user-content-spack-environments" class="anchor" aria-hidden="true"
    href="#spack-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPACK
    Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2><a id="user-content-software-deployment-for-centos-8x" class="anchor" aria-hidden="true"
    href="#software-deployment-for-centos-8x"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Software deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3><a id="user-content-compilers" class="anchor" aria-hidden="true" href="#compilers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3><a id="user-content-lu-software" class="anchor" aria-hidden="true" href="#lu-software"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LU Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4><a id="user-content-available-environments" class="anchor" aria-hidden="true"
    href="#available-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    Environments</h4>

    <h5><a id="user-content-solhawk" class="anchor" aria-hidden="true" href="#solhawk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-avxavx2avx512" class="anchor" aria-hidden="true" href="#avxavx2avx512"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-python-and-r-packages" class="anchor" aria-hidden="true"
    href="#python-and-r-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>Python
    and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-x86_64" class="anchor" aria-hidden="true" href="#x86_64"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2><a id="user-content-centos-7x-software" class="anchor" aria-hidden="true"
    href="#centos-7x-software"><span aria-hidden="true" class="octicon octicon-link"></span></a>CentOS
    7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657632897.0
antoine-morvan/spack-offline-env:
  data_format: 2
  description: null
  filenames:
  - compilers_env/spack.yaml
  - simple_env/spack.yaml
  - complete_env/spack.yaml
  full_name: antoine-morvan/spack-offline-env
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1644310043.0
apt-sim/AdePT:
  data_format: 2
  description: Accelerated demonstrator of electromagnetic Particle Transport
  filenames:
  - scripts/spack.yaml
  full_name: apt-sim/AdePT
  latest_release: null
  readme: '

    <h1><a id="user-content-adept" class="anchor" aria-hidden="true" href="#adept"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>AdePT</h1>

    <p>Accelerated demonstrator of electromagnetic Particle Transport</p>

    <h2><a id="user-content-build-requirements" class="anchor" aria-hidden="true"
    href="#build-requirements"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Requirements</h2>

    <p>The following packages are a required to build and run:</p>

    <ul>

    <li>CMake &gt;= 3.18</li>

    <li>C/C++ Compiler with C++14 support</li>

    <li>CUDA Toolkit (tested 10.1, min version TBD)</li>

    <li>VecCore <a href="https://github.com/root-project/veccore">library</a> 0.7.0
    (recommended, but older versions &gt;= 0.5.0 also work)</li>

    <li>VecGeom <a href="https://gitlab.cern.ch/VecGeom/VecGeom" rel="nofollow">library</a>
    &gt;= 1.1.20</li>

    </ul>

    <p>A suitable environment may be set up either from CVMFS (requires the sft.cern.ch
    and projects.cern.ch repos

    to be available on the local system):</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c1">source</span> /cvmfs/sft.cern.ch/lcg/views/devAdePT/latest/x86_64-centos7-gcc11-opt/setup.sh</span></pre></div>

    <p>or from the supplied <a href="https://spack.io" rel="nofollow">spack</a> environment
    file:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">spack
    env create adept-spack ./scripts/spack.yaml</span>

    $ <span class="pl-s1">spack -e adept-spack concretize -f</span>

    $ <span class="pl-s1">spack -e adept-spack install</span>

    <span class="pl-c1">...</span>

    $ <span class="pl-s1">spack env activate -p adept-spack</span></pre></div>

    <p>Note that the above assumes your spack configuration defaults to use a suitable
    C++ compiler and has

    <code>cuda_arch</code> set appropriately for the hardware you will be running
    on.</p>

    <p>You can also build the packages manually as follows. To configure and build
    VecCore, simply run:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    -S. -B./veccore-build -DCMAKE_INSTALL_PREFIX=<span class="pl-s"><span class="pl-pds">"</span>&lt;path_to_veccore_installation&gt;<span
    class="pl-pds">"</span></span></span>

    $ <span class="pl-s1">cmake --build ./veccore-build --target install</span></pre></div>

    <p>Add your CUDA installation to the PATH and LD_LIBRARY_PATH environment variables,
    as in:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-k">export</span> PATH=<span class="pl-smi">${PATH}</span>:/usr/local/cuda/bin</span>

    $ <span class="pl-s1"><span class="pl-k">export</span> LD_LIBRARY_PATH=<span class="pl-smi">${LD_LIBRARY_PATH}</span>:/usr/local/cuda/lib64</span></pre></div>

    <p>Find the CUDA architecture for the target GPU. If you installed the CUDA demo
    suite, the fastest way is to use the deviceQuery executable from <code>extras/demo_suite</code>.
    This lists the CUDA capability for all installed GPUs, remember the value for
    your target:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">/usr/local/cuda/extras/demo_suite/deviceQuery</span>

    <span class="pl-c1">Device 0: "GeForce RTX 2080 SUPER"</span>

    <span class="pl-c1">  CUDA Capability Major/Minor version number:    7.5 (cuda_architecture=75)</span>

    <span class="pl-c1">...</span>

    <span class="pl-c1">Device 1: "Quadro K4200"</span>

    <span class="pl-c1">  CUDA Capability Major/Minor version number:    3.0 (cuda_architecture=30)</span></pre></div>

    <p>To configure and build VecGeom, use the configuration options below, using
    as &lt;cuda_architecture&gt; the value from the step above:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    -S. -B./vecgeom-build \</span>

    <span class="pl-c1">  -DCMAKE_INSTALL_PREFIX="&lt;path_to_vecgeom_installation&gt;"
    \</span>

    <span class="pl-c1">  -DCMAKE_PREFIX_PATH="&lt;path_to_veccore_installation&gt;"
    \</span>

    <span class="pl-c1">  -DVECGEOM_ENABLE_CUDA=ON \</span>

    <span class="pl-c1">  -DVECGEOM_GDML=ON \</span>

    <span class="pl-c1">  -DBACKEND=Scalar \</span>

    <span class="pl-c1">  -DCMAKE_CUDA_ARCHITECTURES=&lt;cuda_architecture&gt; \</span>

    <span class="pl-c1">  -DVECGEOM_USE_NAVINDEX=ON \</span>

    <span class="pl-c1">  -DCMAKE_BUILD_TYPE=Release</span>

    $ <span class="pl-s1">cmake --build ./vecgeom-build --target install -- -j6 <span
    class="pl-c"><span class="pl-c">#</span>## build using 6 threads and install</span></span></pre></div>

    <p>To configure AdePT, simply run:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    -S. -B./adept-build <span class="pl-k">&lt;</span>otherargs<span class="pl-k">&gt;</span></span></pre></div>

    <p>As  one needs to provide the paths to the dependence libraries VecCore and
    VecGeom, and optionally the path to the Alpaka installation (in case you want
    to build FisherPrice_Alpaka)</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">   -DCMAKE_PREFIX_PATH="&lt;path_to_veccore_installation&gt;;&lt;path_to_vecgeom_installation&gt;;[&lt;alpakaInstallDir&gt;]"
    \</span>

    <span class="pl-c1">   -DCMAKE_CUDA_ARCHITECTURES=&lt;cuda_architecture&gt; \</span>

    <span class="pl-c1">   -DCMAKE_BUILD_TYPE=Release</span></pre></div>

    <p>To build, run:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    --build ./adept-build -- -j6 <span class="pl-c"><span class="pl-c">#</span>##
    build using 6 threads</span></span></pre></div>

    <p>The provided examples and tests can be run from the build directory:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c1">cd</span> adept-build</span>

    $ <span class="pl-s1">CUDA_VISIBLE_DEVICES=0 BuildProducts/bin/<span class="pl-k">&lt;</span>executable<span
    class="pl-k">&gt;</span>   <span class="pl-c"><span class="pl-c">#</span>## use
    the device number matching the selected &lt;cuda_architecture&gt;</span></span></pre></div>

    <h2><a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Copyright</h2>

    <p>AdePT code is Copyright (C) CERN, 2020, for the benefit of the AdePT project.

    Any other code in the project has (C) and license terms clearly indicated.</p>

    <p>Contributions of all authors to AdePT and their institutes are acknowledged
    in

    the <code>AUTHORS.md</code> file.</p>

    '
  stargazers_count: 14
  subscribers_count: 9
  topics: []
  updated_at: 1678241719.0
ashermancinelli/vimconfig:
  data_format: 2
  description: null
  filenames:
  - spack/envs/triage/spack.yaml
  full_name: ashermancinelli/vimconfig
  latest_release: null
  readme: "<h1><a id=\"user-content-vimconfig\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#vimconfig\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>vimconfig</h1>\n<p>Lots and lots of different configurations for various\
    \ programs all wrapped up into one repo. Under heavy development so tread with\
    \ some caution :)</p>\n<h2><a id=\"user-content-how-to-use\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#how-to-use\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>How to use</h2>\n<p>The top directory has a\
    \ script to deal with installation - you should pretty much only interact with\
    \ the repo through that script.\nThe help message is quite descriptive:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ ./configure --h\n\n  Usage:\n\
    \n  -p <span class=\"pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>  \
    \         Sets install prefix. Default: /people/manc568/.local\n  -r <span class=\"\
    pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>           Path to RC file\
    \ <span class=\"pl-k\">for</span> given shell. Default: /qfs/people/manc568/.bashrc\n\
    \  -d                  Default installation. Installs ctags, vim, and bash\n \
    \ -s <span class=\"pl-k\">&lt;</span>pkg<span class=\"pl-k\">&gt;</span>     \
    \       Show installation script <span class=\"pl-k\">for</span> pacakge\n  -i\
    \                  One or more of the following list, separated by commas with\
    \ no spaces:\n\n       zsh\n       bash\n       ctags\n       vim\n       tmux\n\
    \       emacs\n       profiles\n       modules\n       rice\n       rice.sh\n\
    \       fresh</pre></div>\n<h2><a id=\"user-content-examples\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#examples\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<p>For example, to just install\
    \ my vim configuration, you'd do:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ ./configure -i vim</pre></div>\n<p>Or to install configs for multiple\
    \ programs:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ ./configure\
    \ -i vim,ctags,tmux,emacs,bash</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1670527897.0
bfovet/config:
  data_format: 2
  description: My personal configuration files
  filenames:
  - spack-env/linux-ubuntu22.04-skylake/spack.yaml
  full_name: bfovet/config
  latest_release: null
  readme: '<h1><a id="user-content-config" class="anchor" aria-hidden="true" href="#config"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>config</h1>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1658465316.0
bsurc/BSU-software-configs:
  data_format: 2
  description: null
  filenames:
  - borah/environments/libraries/hdf5/_spack.yaml
  - borah/environments/libraries/netcdf/_spack.yaml
  - borah/environments/applications/wrf/_spack.yaml
  full_name: bsurc/BSU-software-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configurations-used-to-stand-up-stacks-at-boise-state-university"
    class="anchor" aria-hidden="true" href="#spack-configurations-used-to-stand-up-stacks-at-boise-state-university"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configurations
    used to stand up stacks at Boise State University</h1>

    <p>(C) 2022 Frank Willmore, et. al. Boise State Univesity Reseach Computing

    <a href="mailto:frankwillmore@boisestate.edu">frankwillmore@boisestate.edu</a></p>

    <p>Note that the environment (spack.yaml) files as checked in are named _spack.yaml,
    since spack rewrites and reorders spack.yaml as it digests the environment. _spack.yaml
    can be regarded as the master, and copied to spack.yaml when processing an environment.
    There is a .gitignore under BOISESTATE set to ignore spack.yaml''s under this
    tree.</p>

    <p>Base configurations provided gcc and oneapi compilers, cuda built with these
    compilers, mpich, openmpi, and intel-oneapi-mpi MPI stacks built with these compilers,
    and modules that will load the correct cuda build and compiler when loading the
    MPI.</p>

    <p>Copies of modules are checked in as well, as these needed to be modified considerably
    from the original generated modules.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676657373.0
charmoniumQ/astrophysics-project:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: charmoniumQ/astrophysics-project
  latest_release: null
  readme: '<h1><a id="user-content-neural-network-superresolving-for-cosmological-simulations"
    class="anchor" aria-hidden="true" href="#neural-network-superresolving-for-cosmological-simulations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Neural Network Superresolving
    for Cosmological Simulations</h1>

    <p>In this repository, I attempt to reproduce the analysis of <a href="https://arxiv.org/pdf/2111.06393.pdf"
    rel="nofollow">Schaurecker et

    al. 2021</a> on Enzo data (they use Illustris).</p>

    <h1><a id="user-content-to-reproduce" class="anchor" aria-hidden="true" href="#to-reproduce"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>To reproduce</h1>

    <p>The code <code>main.py</code> is intended to be run locally. It sends commands
    to the

    remote. You will need to modify this with your site-specific parameters. It

    should be the only file you need to modify.</p>

    <p>To set up the remote machine (should be capable of Slurm):</p>

    <div class="highlight highlight-source-shell"><pre>remote$ <span class="pl-c"><span
    class="pl-c">#</span> Install Spack on the remote</span>

    remote$ <span class="pl-c"><span class="pl-c">#</span> See my notes in reports/spack_on_cc.md
    for details on the UIUC Campus Cluster.</span>

    remote$ git clone -c feature.manyFiles=true https://github.com/spack/spack.git


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy spack.lock to the
    remote</span>

    remote$ spack/bin/spack environment create main4 spack.lock

    remote$ spack/bin/spack environment activate main4

    remote$ spack/bin/spack concretize

    remote$ spack/bin/spack install


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy envirment.yaml ot
    the remote</span>

    remote$ spack/bin/spack activate main4

    remote$ conda install --name main3 --file environment,yaml


    remote$ <span class="pl-c"><span class="pl-c">#</span> Ensure that Slurm works</span>

    remote$ sbatch --help</pre></div>

    <p>To set up the local machine:</p>

    <div class="highlight highlight-source-shell"><pre>locla$ <span class="pl-c"><span
    class="pl-c">#</span> Install conda</span>

    locla$ <span class="pl-c"><span class="pl-c">#</span> Install conda environment</span>

    local$ conda install --name main3 --file environment,yaml</pre></div>

    <p>You will need to configure SSH keys to the remote.</p>

    <p>Then you should be to run <code>main.py</code>. <code>main.py</code> runs the
    entire workflow. It is

    smart about not running a certain step if the data already exists. It also

    hashes the input parameters in the filename of the data, so it is unlikely to

    return stale data.</p>

    <p>The end result will end up in <code>output</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1650312591.0
charmoniumQ/wf-reg-test:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: charmoniumQ/wf-reg-test
  latest_release: null
  readme: "<h1><a id=\"user-content-wf-reg-test\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#wf-reg-test\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>wf-reg-test</h1>\n<p>Software tends to break or \"collapse\" over\
    \ time, even if it is unchanged, due to non-obvious changes in the computational\
    \ environment.\nCollapse in computational experiments undermines long-term credibility\
    \ and hinders day-to-day operations.\nWe propose to create the first public dataset\
    \ of automatically executable scientific experiments.\nThis data could be used\
    \ to identify best practices, make continuous testing feasible, and repair broken\
    \ programs.\nThese techniques increase the replicability of computational experiments.</p>\n\
    <p>Conceptually, we intend to collect the following:</p>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">registry</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >registries</span>:\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\"\
    >experiment</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">registry</span>:\n\
    \        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">version</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">experiment</span>:\n \
    \           <span class=\"pl-k\">for</span> <span class=\"pl-s1\">i</span> <span\
    \ class=\"pl-c1\">in</span> <span class=\"pl-en\">range</span>(<span class=\"\
    pl-s1\">num_repetitions</span>):\n                <span class=\"pl-s1\">execution</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-en\">execute</span>(<span class=\"\
    pl-s1\">version</span>)\n                <span class=\"pl-s1\">data</span>.<span\
    \ class=\"pl-en\">append</span>((\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">date</span>,   <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">output</span>,\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">logs</span>,   <span class=\"pl-s1\">execuiton</span>.<span\
    \ class=\"pl-s1\">res_usage</span>,\n                    <span class=\"pl-s1\"\
    >version</span>.<span class=\"pl-s1\">date</span>,     <span class=\"pl-s1\">version</span>.<span\
    \ class=\"pl-s1\">code</span>,\n                    <span class=\"pl-s1\">experiment</span>.<span\
    \ class=\"pl-s1\">name</span>,  <span class=\"pl-s1\">registry</span>.<span class=\"\
    pl-s1\">name</span>,\n                ))</pre></div>\n<h1><a id=\"user-content-reproducing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reproducing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Reproducing</h1>\n<p>See <a href=\"\
    REPRODUCING.md\"><code>REPRODUCING.md</code></a> for instructions on reproducing\
    \ these results.</p>\n<h1><a id=\"user-content-todo\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#todo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>TODO</h1>\n<p>See <a href=\"TODO.md\"><code>TODO.md</code></a> for\
    \ instructions on reproducing these results.</p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n<p>See <a\
    \ href=\"CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on\
    \ setting up a development environment.</p>\n"
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1676689037.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - openfoam-amd/spack.yaml
  - hpl-amd/spack.yaml
  - namd-amd/spack.yaml
  - lammps-amd/spack.yaml
  - gromacs-amd/spack.yaml
  - hpcg-amd/spack.yaml
  - wrf-amd/spack.yaml
  - quantum-espresso-amd/spack.yaml
  - nwchem-amd/spack.yaml
  - hmmer-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<h1><a id="user-content-benchmark-containers" class="anchor" aria-hidden="true"
    href="#benchmark-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Benchmark
    Containers</h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
deephyper/deephyper-platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running DeepHyper experiments on various platforms.
  filenames:
  - ANL/Polaris/spack.yaml
  full_name: deephyper/deephyper-platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-deephyper-platform-configurations" class="anchor"
    aria-hidden="true" href="#deephyper-platform-configurations"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>DeepHyper Platform Configurations</h1>

    <p>This repository provides a set of configuration files and example scripts for
    running DeepHyper experiments on various platforms.</p>

    <p>The <code>generic</code> subdirectory contains a minimal DeepHyper environment
    example that can be used as a starting point for systems for which there is no
    existing recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which DeepHyper packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <div class="highlight highlight-source-shell"><pre>git clone -c feature.manyFiles=true
    https://github.com/spack/spack.git

    <span class="pl-c1">.</span> spack/share/spack/setup-env.sh</pre></div>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>deephyper-spack-packages</code>, which contains
    the DeepHyper packages.</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-spack-packages.git

    spack repo add deephyper-spack-packages</pre></div>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-platform-configurations.git

    <span class="pl-c1">cd</span> deephyper-platform-configurations/ANL/Polaris</pre></div>

    <p>Edit the path to <code>deephyper-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <div class="highlight highlight-source-shell"><pre>spack env create myenv spack.yaml</pre></div>

    <p>Change to a directory outside of the <code>deephyper-platform-configurations</code>
    folders

    and activate the environment as follows.</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate myenv</pre></div>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <div class="highlight highlight-source-shell"><pre>spack install</pre></div>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-acknowledgment" class="anchor" aria-hidden="true" href="#acknowledgment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgment</h2>

    <p>This repository was created by following the example of the <a href="https://github.com/mochi-hpc-experiments/platform-configurations">Mochi
    Project</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675421226.0
dyokelson/soma_c:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: dyokelson/soma_c
  latest_release: null
  readme: '<p>Your project "soma" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675627136.0
dyokelson/soma_cpp:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: dyokelson/soma_cpp
  latest_release: null
  readme: '<p>Your project "soma" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675794086.0
eflows4hpc/workflow-registry:
  data_format: 2
  description: Registry to store workflow descriptions
  filenames:
  - rom_pillar_I/reduce_order_model/spack.yaml
  - Pillar_II/esm/spack.yaml
  - Pillar_III/ftrt/spack.yaml
  full_name: eflows4hpc/workflow-registry
  latest_release: 2nd_stack_release
  readme: "<h1><a id=\"user-content-workflow-registry\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#workflow-registry\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Workflow Registry</h1>\n<p>This is a repository to\
    \ store the Workflow descriptions using the eFlows4HPC methodology. This description\
    \ consist of at least the TOSCA description of the worklfow, the code of the their\
    \ different steps and their required software per step.</p>\n<h2><a id=\"user-content-repository-structure\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#repository-structure\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Repository structure</h2>\n<p>Workflow\
    \ descriptions have to be included inside this repository according to the following\
    \ structure.</p>\n<pre><code>workflow-registry\n  |- workflow_1\n  |    |- tosca\n\
    \  |    |    |- types.yml               TOSCA description of the different components\
    \ involved in the workflow\n  |    |       ... \n  |    |- step_1\n  |    |  \
    \  |- spack.yml               Sofware requirements for this workflow step as a\
    \ Spack environment specification \n  |    |    |- src                     PyCOMPSs\
    \ code of the workflow step\n  |    |       ...\n  |    |- step_2\n  |       \
    \  ....\n  |- workflow_2                                \n  |\t...\n\n</code></pre>\n\
    <h2><a id=\"user-content-including-new-workflows\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#including-new-workflows\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Including new Workflows</h2>\n<p>To include new workflows\
    \ in the repository, first create a new fork of the repository and  include a\
    \ new folder for the workflow with a subfolder for the TOSCA description and the\
    \ different workflow steps. Finally, create a pull request with the new workflow\
    \ description. This pull request will be reviewed and included in the repository.</p>\n"
  stargazers_count: 2
  subscribers_count: 8
  topics: []
  updated_at: 1675113861.0
eic/containers:
  data_format: 2
  description: Container building infrastructure (mirror of https://eicweb.phy.anl.gov/containers/eic_container)
  filenames:
  - spack.yaml
  full_name: eic/containers
  latest_release: null
  readme: '<h1><a id="user-content-eic-software-environment-container" class="anchor"
    aria-hidden="true" href="#eic-software-environment-container"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>EIC software environment container</h1>

    <p>For installation instructions of <code>eic-shell</code>, see <a href="https://github.com/eic/eic-shell">https://github.com/eic/eic-shell</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1679421635.0
eic/eic-spack-environments:
  data_format: 2
  description: Spack environments for the Electron Ion Collider
  filenames:
  - athena/spack.yaml
  full_name: eic/eic-spack-environments
  latest_release: null
  readme: '<h1><a id="user-content-eic-spack-environments" class="anchor" aria-hidden="true"
    href="#eic-spack-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>EIC
    Spack Environments</h1>

    <p>This repository contains <a href="https://spack.readthedocs.io/en/latest/index.html"
    rel="nofollow">Spack</a> environments for the EIC.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1661880440.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - env-bipp-izar/spack.yaml
  - bipp-izar-gcc/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<h1><a id="user-content-ska-spack-env" class="anchor" aria-hidden="true"
    href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a>ska-spack-env</h1>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
esm-tools/esm_tools:
  data_format: 2
  description: Simple Infrastructure for Earth System Simulations
  filenames:
  - configs/spack_envs/albedo-spack.yaml
  full_name: esm-tools/esm_tools
  latest_release: v6.0.0
  stargazers_count: 20
  subscribers_count: 9
  topics: []
  updated_at: 1671059683.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - oneapi/failures/spack.yaml
  - clang/failures/spack.yaml
  - gnu/spack.yaml
  - nvhpc/spack.yaml
  - clang/spack.yaml
  - oneapi/spack.yaml
  - gnu/failures/spack.yaml
  - nvhpc/failures/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675202595.0
floquet/builds:
  data_format: 2
  description: Notes and scripts for building applications on HPCs
  filenames:
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-26_00,09/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-25_10,39/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  full_name: floquet/builds
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641760136.0
flux-framework/flux-research-artifacts:
  data_format: 2
  description: Collection of Research Artifacts from Papers Involving Flux
  filenames:
  - 2021-IJHPCA/spack-env/spack.yaml
  full_name: flux-framework/flux-research-artifacts
  latest_release: v0.2
  readme: '<h1><a id="user-content-flux-research-artifacts" class="anchor" aria-hidden="true"
    href="#flux-research-artifacts"><span aria-hidden="true" class="octicon octicon-link"></span></a>flux-research-artifacts</h1>

    <p>Collection of Research Artifacts from Papers Involving Flux</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1628308190.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-clang/spack.yaml
  - ubuntu-gcc/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1><a id="user-content-synergia2-containers" class="anchor" aria-hidden="true"
    href="#synergia2-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1678463172.0
haampie/spack-docker-bootstrap:
  data_format: 2
  description: Build optimized docker images for Spack
  filenames:
  - spack.yaml
  full_name: haampie/spack-docker-bootstrap
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-in-docker-with-buildcache\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#spack-in-docker-with-buildcache\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack in Docker with buildcache</h1>\n\
    <p>This bootstraps Spack's own, optimized dependencies, as well as the\ncompiler\
    \ toolchain of the distro, so that in the end we just depend\non system libc.</p>\n\
    <p>See <a href=\"spack.yaml\">spack.yaml</a> for things that are built by Spack,\
    \ and\n<a href=\"Makefile\">Makefile</a> and <a href=\"Dockerfile\">Dockerfile</a>\
    \ for how it's built.</p>\n<p>Docker buildkit is required.</p>\n<p>Build with:</p>\n\
    <pre><code>DOCKER_BUILDKIT=1 docker build -f linux-ubuntu22.04-x86_64_v2/Dockerfile\
    \ -t spack-optimized --progress=plain .\n</code></pre>\n<p>Since this uses Python\
    \ 3.11 and clingo with some optimizations, it should\ngenerally be faster:</p>\n\
    <pre><code>Benchmark 1: docker run --rm spack-optimized spack spec hdf5\n  Time\
    \ (mean \xB1 \u03C3):      8.494 s \xB1  0.401 s    [User: 0.015 s, System: 0.008\
    \ s]\n  Range (min \u2026 max):    8.034 s \u2026  8.763 s    3 runs\n\nBenchmark\
    \ 2: docker run --rm spack/ubuntu-focal spec hdf5\n  Time (mean \xB1 \u03C3):\
    \     10.795 s \xB1  0.382 s    [User: 0.013 s, System: 0.009 s]\n  Range (min\
    \ \u2026 max):   10.355 s \u2026 11.030 s    3 runs\n\nSummary\n  'docker run\
    \ --rm spack-optimized spack spec hdf5' ran\n    1.27 \xB1 0.07 times faster than\
    \ 'docker run --rm spack/ubuntu-focal spec hdf5'\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674134786.0
haampie/spack-pgo-lto-environment:
  data_format: 2
  description: Enable PGO and LTO in Spack software stacks
  filenames:
  - spack.yaml
  full_name: haampie/spack-pgo-lto-environment
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1653473825.0
haampie/spack-prune-specs:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: haampie/spack-prune-specs
  latest_release: null
  readme: '<p>Utilities:</p>

    <ul>

    <li>

    <code>make buildcache-minus-pipelines.filelist</code>: specs in buildcache no
    longer referenced by develop pipelines in the last x days.</li>

    <li>

    <code>make buildcache-intersect-pipelines.filelist</code>: specs both in buildcache
    referenced by develop pipelines in the last x days.</li>

    </ul>

    <p>Set <code>SINCE=yyy-mm-dd</code> to control the window (note that artifacts
    are removed after 30 days, so it can be max one month back).</p>

    <p><code>make</code> installs <code>aws</code>, <code>jq</code> and other utilities
    for you.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678906710.0
hariharan-devarajan/unifyfs-bug:
  data_format: 2
  description: null
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/unifyfs-bug
  latest_release: null
  readme: "<h1><a id=\"user-content-unifyfs-bug\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#unifyfs-bug\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>unifyfs-bug</h1>\n<h2><a id=\"user-content-the-bug-comes-in-multi-node-case-only\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#the-bug-comes-in-multi-node-case-only\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The bug\
    \ comes in multi-node case only.</h2>\n<h2><a id=\"user-content-instructions\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Instructions</h2>\n<ul>\n<li>update\
    \ path of unifyfs on dependency/spack.yaml packages</li>\n<li>activate dependency\
    \ spack folder\n<div class=\"highlight highlight-source-shell\"><pre>spack activate\
    \ -p dependency\nspack install</pre></div>\n</li>\n<li>update path of unifyfs\
    \ install on line 3 of CMakeLists</li>\n<li>build code.\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>cmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_C_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/gcc\
    \ -DCMAKE_CXX_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/g++ -G <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>CodeBlocks - Unix Makefiles<span class=\"\
    pl-pds\">\"</span></span> /g/g92/haridev/temp/unifyfs-bug\ncmake --build /g/g92/haridev/temp/unifyfs-bug/cmake-build-debug\
    \ --target all -- -j 128</pre></div>\n</li>\n<li>Run Unifyfs server\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> unifyfs-bug\n\
    <span class=\"pl-k\">export</span> UNIFYFS_LOG_VERBOSITY=3\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> SET ME</span>\n<span class=\"pl-k\">export</span>\
    \ UNIFYFS_ROOT_DIR=/usr/workspace/iopp/software/tailorfs/dependency/.spack-env/view\
    \  \n<span class=\"pl-k\">export</span> UNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >${HOME}</span>/unifyfs/logs\n<span class=\"pl-k\">export</span> pfs=/p/gpfs1/iopp\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">${PWD}</span>/dependency/.spack-env/view/lib:<span\
    \ class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/lib\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> ACTUAL RUN</span>\nUNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >$UNIFYFS_LOG_DIR</span> UNIFYFS_SERVER_CORES=8 <span class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/bin/unifyfs\
    \ start --share-dir=<span class=\"pl-smi\">${pfs}</span>/unifyfs/share-dir -d</pre></div>\n\
    </li>\n<li>Run code\n<h2><a id=\"user-content-bug-1\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#bug-1\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Bug 1</h2>\n<div class=\"highlight highlight-source-shell\"><pre>jsrun\
    \ -r 1 -a 1 -c 1  -d packed <span class=\"pl-smi\">$PWD</span>/cmake-build-debug/unifyfs-bug\
    \ 1</pre></div>\nOutput\n<div class=\"highlight highlight-source-shell\"><pre>Running\
    \ transfer</pre></div>\n</li>\n</ul>\n<p>2023-03-27T09:36:22 tid=30501 @ forward_to_server()\
    \ [margo_client.c:233] margo_forward_timed() failed - HG_TIMEOUT\n2023-03-27T09:36:22\
    \ tid=30501 @ invoke_client_transfer_rpc() [margo_client.c:614] forward of transfer\
    \ rpc to server failed\nunifyfs-bug: /g/g92/haridev/project/unifyfs-bug/bug.cpp:137:\
    \ int main(int, char**): Assertion `rc == UNIFYFS_SUCCESS' failed.\n[lassen1:30501]\
    \ *** Process received signal ***\n[lassen1:30501] Signal: Aborted (6)\n[lassen1:30501]\
    \ Signal code:  (-6)</p>\n<pre><code>  ## Bug 2\n\n  ```bash\n  jsrun -r 1 -a\
    \ 1 -c 1  -d packed $PWD/cmake-build-debug/unifyfs-bug 2\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675706965.0
hppritcha/spack_ompix:
  data_format: 2
  description: null
  filenames:
  - gnu_release_x86_64/spack.yaml
  - intel_master_x86_64/spack.yaml
  - gnu_master_x86_64/spack.yaml
  full_name: hppritcha/spack_ompix
  latest_release: null
  readme: '<p>Project for using Gitlab CI to test spack builds of Open MPI master
    and release tarballs.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1640037910.0
j-woz/SV-CP-2022-11-23:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: j-woz/SV-CP-2022-11-23
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669233200.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  - Docs/compile-notes/frontera-github/GPU/spack.yaml
  - Docs/compile-notes/frontera-bitbucket/CPU/spack.yaml
  - Docs/compile-notes/frontera-bitbucket/GPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/8257fa34c1c5b6c660b31bf16a6196859c354c9c503b7742e1cdee871fbb96c8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/b768fc44ae95216e4b53ff734978771466ba222596e760da27e9e60a0d47d6f7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <h2><a id="user-content-available-modules" class="anchor" aria-hidden="true" href="#available-modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Available modules</h2>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>TOVSolver</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    '
  stargazers_count: 8
  subscribers_count: 8
  topics: []
  updated_at: 1679282900.0
jaykalinani/AsterX-Docs:
  data_format: 2
  description: 'AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes'
  filenames:
  - compile-notes/frontera-github/GPU/spack.yaml
  - compile-notes/frontera-bitbucket/CPU/spack.yaml
  - compile-notes/frontera-github/CPU/spack.yaml
  - compile-notes/frontera-bitbucket/GPU/spack.yaml
  full_name: jaykalinani/AsterX-Docs
  latest_release: null
  readme: '<h1><a id="user-content-asterx" class="anchor" aria-hidden="true" href="#asterx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>AsterX</h1>

    <p>AsterX: a new open-source GPU-accelerated GRMHD code for dynamical spacetimes</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1677876939.0
jerrygreenberg2/sdsc:
  data_format: 2
  description: null
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  full_name: jerrygreenberg2/sdsc
  latest_release: null
  readme: '<h1><a id="user-content-sdsc-hpc-software-deployment-guide" class="anchor"
    aria-hidden="true" href="#sdsc-hpc-software-deployment-guide"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>SDSC HPC Software Deployment Guide</h1>

    <p>This document outlines the Spack-based software deployment process in

    use by the San Diego Supercomputer Center''s (SDSC) High-Performance

    Computing (HPC) User Services Group. All definitions, procedures,

    conventions, and policies defined within this guide are used by the

    group to build and maintain the custom Spack instances they deploy on

    SDSC''s HPC systems for end users.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>This is a new and evolving software deployment process in development

    and use by the SDSC HPC User Services Group to centrally manage HPC

    software on HPC systems with Spack. Please consider the status of the

    project as a pre-alpha release at this time. Use at your own risk.</p>

    <h2><a id="user-content-definitions-and-terminology" class="anchor" aria-hidden="true"
    href="#definitions-and-terminology"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definitions
    and Terminology</h2>

    <ul>

    <li>A Spack <em><strong>instance</strong></em> is a unique, stand-alone installation
    of a

    specific version of <code>spack</code> that includes custom Spack configuration

    files, Spack packages, and a collection of Spack-installed software

    applications, libraries, and utilities.</li>

    <li>A Spack <em><strong>package</strong></em> is a set of instructions that defines
    how a

    specific piece of software is compiled and/or installed by Spack. For

    example, a Spack package specifies where to find and how to retrieve

    the software''s source code, its required (and/or optional) software

    dependencies, its compile-time options, any patches to apply, etc. A

    Spack package is primarily defined by it <em>package.py</em> file.</li>

    <li>A Spack <em><strong>spec</strong></em> is a string descriptor that specifies
    a particular

    build configuration of a Spack package. The full syntax of a spec

    may include the package name, its version, the compiler it should be

    built with, the compiler version, the system architecture it should be

    compiled for, any compile-time options for the package, and any

    requirements that should be enforced on its dependencies at build time.</li>

    <li>The <em><strong>core</strong></em> packages of a Spack instance are those
    software

    applications, libraries, and/or utilities compiled with Spack using

    the default system compiler. These packages form the foundation of the

    software environment upon which additional Spack packages are built.

    In general, the core packages of a Spack instance are a set of (core)

    compilers and other general software utilities. e.g., version control

    systems, data transfer tools, etc.</li>

    <li>A Spack package <em><strong>dependency chain</strong></em> is an explicitly-defined<br>

    ordered set of Spack specs that share a common (core) compiler and/or

    MPI library, may depend on one another (or share other software

    dependencies), and should be installed one after another, one at a

    time, as prescribed by their dependencies.</li>

    <li>A Spack <em><strong>deployment branch</strong></em> is a <em>trunk</em>-like
    branch for a specific

    version of <code>spack</code> that tracks all of the Spack configuration files,

    Spack packages, and Spack specs used to deploy a Spack instance (or a

    set of instances).</li>

    </ul>

    <h2><a id="user-content-github-repository" class="anchor" aria-hidden="true" href="#github-repository"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GitHub Repository</h2>

    <p>The <a href="https://github.com/sdsc/spack">sdsc/spack</a> project is a custom
    fork

    of the Spack project''s main GitHub repository, which is referred to in

    this guide as the <a href="https://github.com/spack/spack">spack/spack</a> repo.

    The primary aim of the sdsc/spack repo is to manage and track all

    changes made to the custom Spack instances deployed by SDSC on its HPC

    systems.</p>

    <h3><a id="user-content-deployment-branches" class="anchor" aria-hidden="true"
    href="#deployment-branches"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deployment
    Branches</h3>

    <p>The sdsc/spack repo and its use in practice are fundamentally structured

    around the concept of <em>deployment branches</em>. A deployment branch is a

    <em>trunk</em>-like branch created from an unmodifed, official release version

    of <code>spack</code> and is named accordingly, unless special circumstances

    require that an intermediate commit be used. For example, the

    <code>sdsc-0.17.3</code> deployment branch was created by checking out the

    <a href="https://github.com/spack/spack/releases/tag/v0.17.3">v0.17.3</a> release</p>

    <p>Once a version of Spack is selected and checked out, only a few minor

    changes and/or additions are made to the Spack release in order to

    initialize a deployment branch within the sdsc/spack repo. These

    modifications are as follows:</p>

    <ul>

    <li>The official version of the Spack <code>README.md</code> file is removed and

    replaced with the latest version of this document --- the <em>SDSC HPC

    Software Deployment Guide</em>.</li>

    <li>The latest version of the sdsc/spack <code>CONTRIBUTING.md</code> file is
    also

    included to provide information on how one may contribute to the

    sdsc/spack project and its deployment branches.</li>

    <li>A Spack package repository --- <code>var/spack/repos/sdsc</code> --- created
    to

    store all custom Spack packages created and/or maintained by SDSC,

    including all of SDSC''s custom modifications to Spack''s existing

    <code>builtin</code> packages.</li>

    <li>A Spack instance repository --- <code>etc/spack/sdsc</code> --- is created

    to  ...</li>

    </ul>

    <p>All other types of branches (see

    <a href="CONTRIBUTING.md">CONTRIBUTING.md</a>) should start from a deployment

    branch.</p>

    <h3><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    href="#package-repository"><span aria-hidden="true" class="octicon octicon-link"></span></a>Package
    Repository</h3>

    <h3><a id="user-content-instance-repositories" class="anchor" aria-hidden="true"
    href="#instance-repositories"><span aria-hidden="true" class="octicon octicon-link"></span></a>Instance
    Repositories</h3>

    <h3><a id="user-content-access-control-and-permissions" class="anchor" aria-hidden="true"
    href="#access-control-and-permissions"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Access Control and Permissions</h3>

    <p>etc/spack/repos.yaml

    var/spack/repos/sdsc/repo.yaml

    var/spack/repos/sdsc/packages</p>

    <p>etc/spack/sdsc/expanse/0.17.3/cpu/specs

    etc/spack/sdsc/expanse/0.17.3/cpu/yamls</p>

    <h2><a id="user-content-deploying-hpc-software-via-spack" class="anchor" aria-hidden="true"
    href="#deploying-hpc-software-via-spack"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Deploying HPC Software via Spack</h2>

    <h3><a id="user-content-deploying-a-spack-instance" class="anchor" aria-hidden="true"
    href="#deploying-a-spack-instance"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deploying
    a Spack Instance</h3>

    <ul>

    <li>start from existing deployment branch</li>

    </ul>

    <h3><a id="user-content-managing-changes-to-a-spack-instance" class="anchor" aria-hidden="true"
    href="#managing-changes-to-a-spack-instance"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Managing Changes to a Spack Instance</h3>

    <ul>

    <li>deploy change to configuration file</li>

    <li>add new package to sdsc package repository</li>

    <li>spack install a new spec</li>

    </ul>

    <h3><a id="user-content-setting-up-a-shared-instance-configuration" class="anchor"
    aria-hidden="true" href="#setting-up-a-shared-instance-configuration"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Setting up a Shared Instance Configuration</h3>

    <h3><a id="user-content-using-a-spack-mirror-and-build-caches-for-instance-backups"
    class="anchor" aria-hidden="true" href="#using-a-spack-mirror-and-build-caches-for-instance-backups"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using a Spack Mirror
    and Build Caches for Instance Backup(s)</h3>

    <h2><a id="user-content-additional-notes" class="anchor" aria-hidden="true" href="#additional-notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Additional Notes</h2>

    <h3><a id="user-content-protecting-the-sdscspack-develop-branch" class="anchor"
    aria-hidden="true" href="#protecting-the-sdscspack-develop-branch"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Protecting the sdsc/spack <code>develop</code>
    branch</h3>

    <h3><a id="user-content-fetching-changes-and-re-syncing-the-develop-branch" class="anchor"
    aria-hidden="true" href="#fetching-changes-and-re-syncing-the-develop-branch"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Fetching changes and
    re-syncing the <code>develop</code> branch</h3>

    <h3><a id="user-content-creating-a-new-deployment-branch" class="anchor" aria-hidden="true"
    href="#creating-a-new-deployment-branch"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Creating a new deployment branch</h3>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678670738.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - anl/polaris/polaris.spack.yaml
  - ornl/summit/summit.spack.yaml
  - ornl/crusher/crusher.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/eagle/utilities/spack.yaml
  - configs/eagle/compilers/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" aria-hidden="true" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666717629.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-release-user/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    href="#repository-contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    href="#central-installations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 9
  subscribers_count: 10
  topics: []
  updated_at: 1673125688.0
lanl/CELLAR:
  data_format: 2
  description: The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based
    adaptive mesh refinement data structures and execution for parallel computing
    architectures.
  filenames:
  - spack/ci/spack.yaml
  - spack/default/spack.yaml
  - spack/snow/spack.yaml
  - spack/darwin-power9/spack.yaml
  - spack/agaspar/spack.yaml
  full_name: lanl/CELLAR
  latest_release: null
  readme: '<h1><a id="user-content-cellar-----eap-core" class="anchor" aria-hidden="true"
    href="#cellar-----eap-core"><span aria-hidden="true" class="octicon octicon-link"></span></a>CELLAR  -  EAP
    Core</h1>

    <p>CELLAR is a C++ project that forms the foundation of cell based AMR for applications</p>

    <p>It provides the following:</p>

    <ul>

    <li>AMR Mesh Datastructure</li>

    <li>AMR Mesh Reconstruction</li>

    <li>Communication Patterns</li>

    <li>C++ Error Handling and Tracing</li>

    <li>Performance Monitoring</li>

    <li>C++/Fortran Interop</li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>The easiest way to install dependencies is using <a href="https://spack.io"
    rel="nofollow">Spack</a>.

    After

    <a href="https://spack.readthedocs.io/en/latest/getting_started.html" rel="nofollow">installing
    Spack</a>,

    you can start build dependencies.</p>

    <p>The following instructions assume that you have Spack 0.13 or newer. You can
    check your

    Spack version like so:</p>

    <pre><code>$ spack --version

    0.13.0

    </code></pre>

    <p>First, add <a href="https://github.com/lanl/cellar-spack">lanl/cellar-spack</a>

    to your list of spack repos.</p>

    <p>Once you have the <code>lanl/cellar-spack</code> installed, then you can install
    all

    dependencies using

    <a href="https://spack.readthedocs.io/en/latest/tutorial_environments.html#" rel="nofollow">Spack
    environments</a>.

    You''ll need to use a modern-ish C++ compiler that supports C++14:</p>

    <pre><code>$ module load gcc/9.3.0

    $ spack compiler find

    $ cd path/to/eap-core

    </code></pre>

    <p>Then issue the following commands. This will build all of eap-core''s dependencies.:</p>

    <pre><code>$ spack env create -d spack/default

    $ spack env activate -d $PWD/spack/default

    $ spack install

    </code></pre>

    <p>Any time you open a new shell, you''ll need to re-activate the Spack environment:</p>

    <pre><code>$ spack env activate -d $PWD/spack/default

    </code></pre>

    <p>Now you''re ready to build eap-core. First configure the project using CMake:</p>

    <pre><code>mkdir build &amp;&amp; cd build

    cmake ..

    </code></pre>

    <p>And then build:</p>

    <pre><code>make -j

    </code></pre>

    <p>For snow, substitute in spack/snow in the above instructions in place of spack/default.
    If you need

    to change the environment use "spack env deactivate".</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Code contributors should read the <a href="DEVELOPERS.md">Developers Guide</a>
    prior to

    sending a pull request.</p>

    '
  stargazers_count: 2
  subscribers_count: 5
  topics: []
  updated_at: 1677256390.0
lanl/cellar-gtest-mpi:
  data_format: 2
  description: null
  filenames:
  - spack/agaspar/spack.yaml
  full_name: lanl/cellar-gtest-mpi
  latest_release: null
  readme: "<h1><a id=\"user-content-google-test-for-mpi-gtest-mpi\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#google-test-for-mpi-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Google Test for MPI (gtest-mpi)</h1>\n\
    <p>This is a support library that helps users write Google Test unit tests that\n\
    rely on MPI.</p>\n<h2><a id=\"user-content-features\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Features</h2>\n<ul>\n<li>Serialized and rank-tagged Google Test output.</li>\n\
    <li>Rank-tagged failure reports.</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> is the easiest way\
    \ to install gtest-mpi. The gtest-mpi\npackage is available in\n<a href=\"https://gitlab.lanl.gov/agaspar/spack-repo\"\
    \ rel=\"nofollow\">agaspar/spack-repo</a>. Follow the\nREADME there to use that\
    \ spack repo. Once the agaspar-spack-repo repo is\ninstalled, installing gtest-mpi\
    \ is as simple as running:</p>\n<pre><code>spack install gtest-mpi\n</code></pre>\n\
    <p>When you want to use gtest-mpi, run <code>spack load gtest-mpi</code> to load\
    \ it into your\ncurrent environment.</p>\n<h3><a id=\"user-content-cmake\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>CMake</h3>\n<p>If you don't want to use spack,\
    \ you can install gtest-mpi directly using CMake.\ngtest-mpi uses CMake, so all\
    \ of your knowledge of CMake applies. gtest-mpi\nhas a dependency on Google Test,\
    \ and uses\n<a href=\"https://cmake.org/cmake/help/latest/module/FindGTest.html\"\
    \ rel=\"nofollow\">FindGTest.cmake</a> to\nfind it. Therefore, in order to install\
    \ gtest-mpi, you must first have a\nworking installation of <a href=\"https://github.com/google/googletest/\"\
    >Google Test</a>.</p>\n<p>Once you've installed Google Test, building and installing\
    \ gtest-mpi is just\nlike any other modern CMake package.</p>\n<pre><code>git\
    \ clone git@gitlab.lanl.gov:agaspar/gtest-mpi.git\ncd gtest-mpi\nmkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake install\n</code></pre>\n<h2><a id=\"user-content-using-gtest-mpi\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using gtest-mpi</h2>\n<h3><a\
    \ id=\"user-content-with-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #with-cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>With\
    \ CMake</h3>\n<p>If you don't need any custom startup logic, using gtest-mpi in\
    \ your own CMake\nproject is simple:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">find_package</span>(gtest-mpi 0.1 <span class=\"pl-k\"\
    >REQUIRED</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> gtest-mpi-main\
    \ provides a main function for you</span>\n<span class=\"pl-c1\">add_executable</span>(my-test\
    \ mytest.cpp)\n<span class=\"pl-c1\">target_link_libraries</span>(my-test gtest-mpi-main)</pre></div>\n\
    <p>Then you can write a Google Test just like you normally would:</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> mytest.cpp</span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-en\"\
    >TEST</span>(GTestMPI, Basic) {\n    <span class=\"pl-k\">int</span> rank;\n \
    \   <span class=\"pl-c1\">MPI_Comm_rank</span>(MPI_COMM_WORLD, &amp;rank);\n\n\
    \    <span class=\"pl-k\">bool</span> is_root = rank == <span class=\"pl-c1\"\
    >0</span>;\n\n    <span class=\"pl-k\">bool</span> is_anyone_root = <span class=\"\
    pl-c1\">false</span>;\n    <span class=\"pl-c1\">MPI_Allreduce</span>(\n     \
    \   &amp;is_root, &amp;is_anyone_root, <span class=\"pl-c1\">1</span>, MPI_CXX_BOOL,\
    \ MPI_LOR, MPI_COMM_WORLD);\n\n    <span class=\"pl-c1\">ASSERT_TRUE</span>(is_anyone_root);\n\
    }</pre></div>\n<p>If you need to write your own main function, that's also fairly\
    \ straighforward.\nIn your CMake project, you link against <code>gtest-mpi-lib</code>\
    \ instead of\n<code>gtest-mpi-main</code>. Then you must provide your own main\
    \ function:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> main.cpp</span>\n#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest-mpi/init.hpp<span\
    \ class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"\
    pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\
    \n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span> **argv) {\n    <span\
    \ class=\"pl-c1\">testing::InitGoogleTest</span>(&amp;argc, argv);\n    <span\
    \ class=\"pl-c1\">MPI_Init</span>(&amp;argc, &amp;argv);\n    <span class=\"pl-c1\"\
    >gtest_mpi::init</span>(&amp;argc, &amp;argv);\n\n    <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Your custom init logic goes here</span>\n\n    <span\
    \ class=\"pl-k\">int</span> exit_code = <span class=\"pl-c1\">RUN_ALL_TESTS</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Your custom finalize\
    \ logic goes here</span>\n\n    <span class=\"pl-c1\">gtest_mpi::finalize</span>();\n\
    \    <span class=\"pl-c1\">MPI_Finalize</span>();\n\n    <span class=\"pl-k\"\
    >return</span> exit_code;\n}</pre></div>\n<h3><a id=\"user-content-without-cmake\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#without-cmake\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Without CMake</h3>\n<p>CMake\
    \ is not required to use gtest-mpi, but it is recommended. If you wish to\nuse\
    \ a different build system, then adding <code>-lgtest-mpi-lib</code> and (optionally)\n\
    <code>-lgtest-mpi-main</code> to your link line will work.</p>\n<h2><a id=\"user-content-ctest\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#ctest\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>CTest</h2>\n<p>Here's an example of\
    \ adding a CTest using gtest-mpi to your CMake file:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">enable_testing</span>()\n\
    \n<span class=\"pl-c1\">add_test</span>(\n    <span class=\"pl-k\">NAME</span>\
    \ my-test\n    <span class=\"pl-k\">COMMAND</span>\n        <span class=\"pl-smi\"\
    >${MPIEXEC}</span> <span class=\"pl-smi\">${MPIEXEC_NUMPROC_FLAG}</span> 4 <span\
    \ class=\"pl-smi\">${MPIEXEC_PREFLAGS}</span>\n            $&lt;<span class=\"\
    pl-k\">TARGET_FILE</span>:my-test&gt; <span class=\"pl-smi\">${MPIEXEC_POSTFLAGS}</span>)</pre></div>\n\
    <p>These tests can be run using <code>ctest</code>.</p>\n"
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1668046366.0
lcompilers/lpython:
  data_format: 2
  description: Python compiler
  filenames:
  - spack.yaml
  full_name: lcompilers/lpython
  latest_release: null
  readme: '<h1><a id="user-content-lpython" class="anchor" aria-hidden="true" href="#lpython"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LPython</h1>

    <p>LPython is a Python compiler. It is in heavy development, currently in

    pre-alpha stage. Some of the goals of LPython:</p>

    <ul>

    <li>The best possible performance for numerical, array-oriented code</li>

    <li>Run on all platforms</li>

    <li>Compile a subset of Python yet be fully compatible with Python</li>

    <li>Explore designs so that LPython eventually can compile all Python code</li>

    <li>Fast compilation</li>

    <li>Excellent user-friendly diagnostic messages: error, warnings, hints, notes,

    etc.</li>

    <li>Ahead-of-Time compilation to binaries, plus interactive usage (Jupyter

    notebook)</li>

    <li>Transforming Python code to C++, Fortran and other languages</li>

    </ul>

    <p>And more.</p>

    <h1><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h1>

    <p>LPython works on Windows, macOS and Linux.</p>

    <h2><a id="user-content-install-conda" class="anchor" aria-hidden="true" href="#install-conda"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Install Conda</h2>

    <p>Please follow the instructions here to install Conda on your platform:</p>

    <p><a href="https://github.com/conda-forge/miniforge/#download">https://github.com/conda-forge/miniforge/#download</a></p>

    <h3><a id="user-content-linux" class="anchor" aria-hidden="true" href="#linux"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Linux</h3>

    <div class="highlight highlight-source-shell"><pre>sudo apt install binutils-dev</pre></div>

    <h3><a id="user-content-windows" class="anchor" aria-hidden="true" href="#windows"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Windows</h3>

    <p>Install Visual Studio (MSVC), for example the version 2022, you can download
    the

    Community version for free from: <a href="https://visualstudio.microsoft.com/downloads/"
    rel="nofollow">https://visualstudio.microsoft.com/downloads/</a>.</p>

    <p>Launch the Miniforge prompt from the Desktop.</p>

    <p>In the shell, initialize the MSVC compiler using:</p>

    <div class="highlight highlight-source-shell"><pre>call <span class="pl-s"><span
    class="pl-pds">"</span>C:\Program Files\Microsoft Visual Studio\2022\Community\Common7\Tools\VsDevCmd<span
    class="pl-pds">"</span></span> -arch=x64</pre></div>

    <p>You can optionally test MSVC via:</p>

    <div class="highlight highlight-source-shell"><pre>cl /<span class="pl-k">?</span>

    link /<span class="pl-k">?</span></pre></div>

    <p>Both commands must print several pages of help text.</p>

    <h2><a id="user-content-build-lpython" class="anchor" aria-hidden="true" href="#build-lpython"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build LPython</h2>

    <p>Clone LPython</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/lcompilers/lpython.git

    <span class="pl-c1">cd</span> lpython</pre></div>

    <h3><a id="user-content-linux-and-macos" class="anchor" aria-hidden="true" href="#linux-and-macos"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Linux and MacOS</h3>

    <ul>

    <li>Create a Conda environment using the pre-existing file:</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_unix.yml

    conda activate lp</pre></div>

    <ul>

    <li>Generate prerequisite files; build in Debug Mode:</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>./build0.sh

    ./build1.sh</pre></div>

    <h3><a id="user-content-windows-1" class="anchor" aria-hidden="true" href="#windows-1"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Windows</h3>

    <ul>

    <li>Create a Conda environment using the pre-existing file:</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_win.yml

    conda activate lp</pre></div>

    <ul>

    <li>Generate prerequisite files; build in Release Mode:</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>call build0.bat

    call build1.bat</pre></div>

    <ul>

    <li>Tests and examples</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>ctest

    inst<span class="pl-cce">\b</span>in<span class="pl-cce">\l</span>python examples<span
    class="pl-cce">\e</span>xpr2.py

    inst<span class="pl-cce">\b</span>in<span class="pl-cce">\l</span>python examples<span
    class="pl-cce">\e</span>xpr2.py -o a.out

    a.out</pre></div>

    <ul>

    <li>After you update a test case file, you also need to update all the reference
    results associated with that test case:</li>

    </ul>

    <pre><code>python run_tests.py -u --skip-run-with-dbg

    </code></pre>

    <ul>

    <li>To see all the options associated with LPython test suite, use:</li>

    </ul>

    <pre><code>python run_tests.py --help

    </code></pre>

    <h2><a id="user-content-tests-linux-or-macos" class="anchor" aria-hidden="true"
    href="#tests-linux-or-macos"><span aria-hidden="true" class="octicon octicon-link"></span></a>Tests
    (Linux or MacOs):</h2>

    <p>Run tests:</p>

    <div class="highlight highlight-source-shell"><pre>ctest

    ./run_tests.py</pre></div>

    <p>Run integration tests:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    integration_tests

    ./run_tests.py</pre></div>

    <h3><a id="user-content-speed-up-integration-test-on-macs" class="anchor" aria-hidden="true"
    href="#speed-up-integration-test-on-macs"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Speed up Integration Test on Macs</h3>

    <p>Integration tests run slowly because Apple checks the hash of each

    executable online before running. You can turn off that feature

    in the Privacy tab of the Security and Privacy item of System

    Preferences, Developer Tools, Terminal.app, "allow the apps below

    to run software locally that does not meet the system''s security

    policy."</p>

    <h2><a id="user-content-examples-linux-or-macos" class="anchor" aria-hidden="true"
    href="#examples-linux-or-macos"><span aria-hidden="true" class="octicon octicon-link"></span></a>Examples
    (Linux or MacOs)</h2>

    <p>You can run the following examples by hand in a terminal:</p>

    <div class="highlight highlight-source-shell"><pre>./src/bin/lpython examples/expr2.py

    ./src/bin/lpython examples/expr2.py -o expr

    ./expr

    ./src/bin/lpython --show-ast examples/expr2.py

    ./src/bin/lpython --show-asr examples/expr2.py

    ./src/bin/lpython --show-cpp examples/expr2.py

    ./src/bin/lpython --show-llvm examples/expr2.py

    ./src/bin/lpython --show-c examples/expr2.py</pre></div>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>We welcome contributions from anyone, even if you are new to compilers or to

    open source. It might sound daunting to contribute to a compiler at first, but

    please do, it is not complicated. We will help you with technical issues and

    help improve your contribution so that it can be merged.</p>

    <p>To contribute, submit a Pull Request (PR) against our repository at:</p>

    <p><a href="https://github.com/lcompilers/lpython">https://github.com/lcompilers/lpython</a></p>

    <p>and don''t forget to clean your history, see <a href="./doc/src/rebasing.md">example</a>.</p>

    <p>Please report any bugs you may find at our issue tracker:

    <a href="https://github.com/lcompilers/lpython/issues">https://github.com/lcompilers/lpython/issues</a>.
    Or, even better, fork the

    repository on GitHub and create a PR. We welcome all changes, big or small, and

    we will help you make a PR if you are new to git.</p>

    <p>If you have any questions or need help, please ask us at Zulip (<a href="https://lfortran.zulipchat.com/"
    rel="nofollow"><img src="https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667"
    alt="project chat" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg"
    style="max-width: 100%;"></a>)

    or our <a href="https://groups.io/g/lfortran" rel="nofollow">mailinglist</a>.</p>

    <p>See the <a href="CONTRIBUTING.md">CONTRIBUTING</a> document for more information.</p>

    '
  stargazers_count: 118
  subscribers_count: 8
  topics: []
  updated_at: 1679954703.0
ma595/fenics-csd3-spack:
  data_format: 2
  description: Set up fenics spack on csd3
  filenames:
  - spack-icelake.yaml
  - spack-skylake.yaml
  full_name: ma595/fenics-csd3-spack
  latest_release: null
  readme: '<h1><a id="user-content-fenics-csd3-spack" class="anchor" aria-hidden="true"
    href="#fenics-csd3-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>fenics-csd3-spack</h1>

    <p>Follow instructions in icelake-spack-env.sh</p>

    <p>Or, copy existing <code>spack.yaml</code> files into cloned Spack repo. It
    is necessary to <code>module purge</code> environment first, otherwise the prepend
    path inside <code>spack.yaml</code> will lead to duplications.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667830944.0
marcodelapierre/toy-cowsay-nf:
  data_format: 2
  description: Toy pipeline for simple Nextflow tests
  filenames:
  - spack.yaml
  - scripts/spack/spack.yaml
  - scripts/containerize-spack/spack.yaml
  full_name: marcodelapierre/toy-cowsay-nf
  latest_release: null
  readme: '<h2><a id="user-content-toy-pipeline-for-simple-nextflow-tests" class="anchor"
    aria-hidden="true" href="#toy-pipeline-for-simple-nextflow-tests"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Toy pipeline for simple Nextflow tests</h2>

    <p>The purpose of this repo is to have a pipeline with features including:</p>

    <p>General:</p>

    <ul>

    <li>Simple</li>

    <li>Small (including required software)</li>

    <li>Quick to setup and run</li>

    </ul>

    <p>Pipeline:</p>

    <ul>

    <li>Requires a small package, that can be installed with Conda or Spack

    <ul>

    <li>Conda: <code>cowpy</code> (from <code>conda-forge</code>)</li>

    <li>Spack: <code>cowsay</code>

    </li>

    </ul>

    </li>

    <li>Reads/writes files</li>

    </ul>

    <p>Software options:</p>

    <ul>

    <li>Host</li>

    <li>Containers</li>

    <li>Conda</li>

    <li>Conda with Wave</li>

    <li>Spack</li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1676008940.0
mochi-hpc/mobject:
  data_format: 2
  description: Mobject is a prototype Mochi object storage system based on RADOS
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mobject
  latest_release: v0.6.1
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"mobject_logo.png\"\
    ><img src=\"mobject_logo.png\" alt=\"logo\" style=\"max-width: 100%;\"></a></p>\n\
    <h1><a id=\"user-content-mobject\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #mobject\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mobject</h1>\n\
    <p><a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml/badge.svg\"\
    \ alt=\"check spelling\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml/badge.svg\"\
    \ alt=\"spack mobject\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml/badge.svg\"\
    \ alt=\"spack mobject+bedrock\" style=\"max-width: 100%;\"></a></p>\n<p>Mobject\
    \ is a distributed object storage system\nbuilt using a composition of <a href=\"\
    https://mochi.readthedocs.io\" rel=\"nofollow\">Mochi</a> components:</p>\n<ul>\n\
    <li>\n<a href=\"https://github.com/mochi-hpc/mochi-bake\">mochi-bake</a> (for\
    \ bulk storage)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-bedrock\"\
    >mochi-bedrock</a>\n(for configuration and bootstrapping)</li>\n<li>\n<a href=\"\
    https://github.com/mochi-hpc/mochi-sdskv\">mochi-sdskv</a>\n(for metadata and\
    \ log indexing)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-ssg\"\
    >mochi-ssg</a> (for group membership)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"\
    https://mochi.readthedocs.io/en/latest/installing.html#installing-spack-and-the-mochi-repository\"\
    \ rel=\"nofollow\">Install Spack and Mochi Spack Repository</a>.</p>\n<p>Then,\
    \ run the following command to install mobject.</p>\n<pre><code>   spack install\
    \ mobject\n</code></pre>\n<h2><a id=\"user-content-hdf5-and-mobject\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#hdf5-and-mobject\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>HDF5 and Mobject</h2>\n<p><a\
    \ href=\"/include/librados-mobject-store.h\">Mobject API</a> is a subset of the\n\
    <a href=\"https://github.com/ceph/ceph/blob/main/src/include/rados/librados.h\"\
    >RADOS API</a>\nfrom Ceph\u2019s object storage layer.\nTherefore, <a href=\"\
    https://github.com/HDFGroup/vol-rados\">HDF5 RADOS VOL plugin-in</a>\ncan use\
    \ Mobject.</p>\n<h2><a id=\"user-content-faq\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#faq\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>FAQ</h2>\n<p>See <a href=\"doc/FAQ.md\">doc/FAQ.md</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1640785210.0
mochi-hpc/mochi-bedrock:
  data_format: 2
  description: Mochi bootstrapping service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bedrock
  latest_release: v0.5.2
  readme: '<h1><a id="user-content-bedrock" class="anchor" aria-hidden="true" href="#bedrock"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bedrock</h1>

    <p>Bedrock is Mochi''s service bootstrapping mechanism.

    For documentations and tutorials, please see

    <a href="https://mochi.readthedocs.io/en/latest/bedrock.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640527359.0
mochi-hpc/mochi-mona:
  data_format: 2
  description: Mochi messaging over NA
  filenames:
  - benchmark/cori/spack.yaml
  full_name: mochi-hpc/mochi-mona
  latest_release: v0.2.3
  readme: '<h1><a id="user-content-mona---messaging-over-na" class="anchor" aria-hidden="true"
    href="#mona---messaging-over-na"><span aria-hidden="true" class="octicon octicon-link"></span></a>MoNA
    - Messaging over NA</h1>

    <p>MoNA is a Mochi library combining the NA layer of Mercury with

    the Argobots threading library, in a way similar to how Margo

    combines Mercury with Argobots. It provides a low-level messaging

    interface and hides the NA progress loop into Argobots ULTs.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633974549.0
mochi-hpc/mochi-yokan:
  data_format: 2
  description: Remote Key/Value storage service for Mochi
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-yokan
  latest_release: v0.2.10
  readme: '<h1><a id="user-content-yokan---mochis-keyvalue-and-more-storage-service"
    class="anchor" aria-hidden="true" href="#yokan---mochis-keyvalue-and-more-storage-service"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Yokan - Mochi''s Key/Value
    (and more) storage service</h1>

    <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"><img
    src="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"
    alt="" style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/mochi-hpc/mochi-yokan" rel="nofollow"><img src="https://camo.githubusercontent.com/fc95c801bafa29b49219f4727f651b97e7385800c8dc4a4757a1dccadefe6611/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d796f6b616e2f6272616e63682f6d61696e2f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/mochi-hpc/mochi-yokan/branch/main/graph/badge.svg"
    style="max-width: 100%;"></a></p>

    <p>Please see documentation <a href="https://mochi.readthedocs.io/en/latest/yokan.html"
    rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641326484.0
nantes-m2-rps-exp/qqbar2mumu-2022:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: nantes-m2-rps-exp/qqbar2mumu-2022
  latest_release: null
  readme: "<h1><a id=\"user-content-projet-exp\xE9rimental---production-de-quarkonia\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#projet-exp\xE9rimental---production-de-quarkonia\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Projet exp\xE9\
    rimental - Production de quarkonia</h1>\n<blockquote>\n<p>Ce d\xE9pot git h\xE9\
    berge les fichiers n\xE9cessaires pour d\xE9marrer le projet \"Production de quarkonia\"\
    \ du Master 2 RPS de l'Universit\xE9 de Nantes. Il est principalement \xE0 destination\
    \ des \xE9tudiants qui r\xE9alisent ce projet. Le \"vous\" ci-dessous s'adresse\
    \ donc \xE0 ces \xE9tudiants.</p>\n</blockquote>\n<p>Pour ce projet le language\
    \ de programmation choisi est Python. Nous recommandons de l'utiliser par le biais\
    \ de <a href=\"https://jupyter.org\" rel=\"nofollow\">\"Notebooks Jupyter\"</a>\
    \ qui permettent de m\xE9langer le code, la documentation et les r\xE9sultats\
    \ de l'ex\xE9cution du code.</p>\n<p>Jupyter est un outil commun dans le domaine\
    \ de la science des donn\xE9es. Il y a bien des fa\xE7ons d'utiliser Jupyter et\
    \ de nombreux tutoriels sont disponibles en ligne pour aller plus loin, mais vous\
    \ trouverez ci-dessous trois m\xE9thodes pour d\xE9marrer :</p>\n<ol>\n<li>une\
    \ <a href=\"conda/README.md\">m\xE9thode locale bas\xE9e sur conda</a>\n</li>\n\
    <li>une <a href=\"cloud/README.md\">m\xE9thode cloud</a>\n</li>\n<li>une <a href=\"\
    multipass/README.md\">m\xE9thode locale bas\xE9e sur multipass</a>\n</li>\n</ol>\n\
    <p>A noter que seule la troisi\xE8me m\xE9thode permet, a priori, de r\xE9aliser\
    \ toutes les t\xE2ches n\xE9cessaires \xE0 ce projet, car elle offre des interfaces\
    \ Python de paquets C++ d\xE9velopp\xE9s sp\xE9cifiquement pour ce projet, alors\
    \ que les deux premi\xE8res ne permettent d'acc\xE9der qu'\xE0 des paquets Python\
    \ \"g\xE9n\xE9riques\". Les deux premi\xE8res m\xE9thodes permettent n\xE9anmoins\
    \ de d\xE9marrer assez rapidement.</p>\n<p>Pour ce projet, vous utiliserez \xE9\
    galement <a href=\"https://git.com\" rel=\"nofollow\">Git</a> et <a href=\"https://github.com\"\
    >GitHub</a>. Si ce n'est pas d\xE9j\xE0 le cas, il vous faudra <a href=\"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\"\
    \ rel=\"nofollow\">installer git sur votre machine</a> et vous <a href=\"https://fr.wikihow.com/cr%C3%A9er-un-compte-sur-GitHub\"\
    \ rel=\"nofollow\">cr\xE9\xE9r un compte GitHub</a>.</p>\n<p>Comme pour Jupyter,\
    \ un nombre important de ressources documentaires et tutoriels sont disponibles\
    \ sur le net pour commencer avec git si c'est votre premi\xE8re approche ou encore\
    \ pour approfondir votre ma\xEEtrise de cet outil si vous le connaissez d\xE9\
    j\xE0 un peu.</p>\n<p>Vous trouverez dans le <a href=\"git/README.md\">document\
    \ <code>git/README.md</code></a> les commandes de base pour d\xE9marrer avec ce\
    \ d\xE9p\xF4t git en particulier.</p>\n<p>Une fois la premi\xE8re installation\
    \ r\xE9alis\xE9e, commencez par vous familiariser avec Jupyter en utilisant le\
    \ <a href=\"notebooks/muon-eta-distribution.ipynb\">notebook d'exemple</a></p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1667463557.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - cray-sles15-zen3/crusher/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_env/index.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2><a id="user-content-purpose" class="anchor" aria-hidden="true" href="#purpose"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 4
  subscribers_count: 19
  topics: []
  updated_at: 1670008521.0
pdidev/test_env:
  data_format: 2
  description: Testing environment for PDI
  filenames:
  - spack/1b-spack/spack.yaml
  full_name: pdidev/test_env
  latest_release: null
  readme: '<h1><a id="user-content-docker-images" class="anchor" aria-hidden="true"
    href="#docker-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Docker
    images:</h1>

    <p>A set of related Docker images to build and test PDI.</p>

    <p>We provide images based on:</p>

    <ul>

    <li>Spack recipes,</li>

    <li>Binary packages.</li>

    </ul>

    <h2><a id="user-content-spack-based-images" class="anchor" aria-hidden="true"
    href="#spack-based-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack-based
    images</h2>

    <p>These images are based on a minimal Ubuntu 18.08, with spack and all dependencies
    installed through

    spack.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/spack/${deps_version}/${compiler}/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>deps_version</code>:

    <ul>

    <li>

    <code>oldest</code>: dependencies use the oldest versions supported by PDI,</li>

    <li>

    <code>latest</code>: dependencies use the latest versions available in spack at
    the time of generation,</li>

    </ul>

    </li>

    <li>

    <code>compiler</code>:

    <ul>

    <li>

    <code>gcc</code>:   using GCC compiler,</li>

    <li>

    <code>clang</code>: using clang for C/C++ and gfortran for Fortran,</li>

    </ul>

    </li>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image.</li>

    </ul>

    </li>

    </ul>

    <h2><a id="user-content-binary-package-based-images" class="anchor" aria-hidden="true"
    href="#binary-package-based-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binary
    package based images</h2>

    <p>These images are based on Ubuntu 18.08, with all dependencies installed through
    packages.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/ubuntu/bionic/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>mpich</code>: using mpich implementation of MPI,</li>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image,</li>

    <li>

    <code>pdi</code>: PDI is included in the image.</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1641653805.0
range3/kvs-evaluation:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/kvs-evaluation
  latest_release: null
  readme: "<h1><a id=\"user-content-kvs-evaluation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#kvs-evaluation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>kvs-evaluation</h1>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> external/YCSB-C\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> sudo\u3092\u4F7F\u3063\u3066libhiredis.so\u304C\
    /usr/local/lib\u306B\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB\u3055\u308C\u308B</span>\n\
    make\n<span class=\"pl-k\">export</span> LD_LIBRARY_PATH=/usr/local/lib\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> \u52D5\u4F5C\u78BA\u8A8D</span>\n\
    ./ycsbc -db basic -threads 1 -P workloads/workloada.spec</pre></div>\n<h1><a id=\"\
    user-content-ycsb-c\" class=\"anchor\" aria-hidden=\"true\" href=\"#ycsb-c\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>YCSB-C</h1>\n\
    <h2><a id=\"user-content-workload\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #workload\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>workload</h2>\n\
    <table>\n<thead>\n<tr>\n<th align=\"left\">workload</th>\n<th align=\"left\">description</th>\n\
    <th align=\"right\">read</th>\n<th align=\"right\">insert</th>\n<th align=\"right\"\
    >update</th>\n<th align=\"right\">scan</th>\n<th align=\"right\">R-M-W</th>\n\
    <th align=\"center\">distribution</th>\n<th align=\"center\">remarks</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td align=\"left\">A</td>\n<td align=\"left\">Update\
    \ heavy</td>\n<td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >B</td>\n<td align=\"left\">Read mostly</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">zipfian</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">C</td>\n<td align=\"left\">Read\
    \ only</td>\n<td align=\"right\">1</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\"></td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >D</td>\n<td align=\"left\">Read latest</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\">0.05</td>\n<td align=\"right\"></td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">latest</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">E</td>\n<td align=\"left\">Short\
    \ ranges</td>\n<td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"\
    right\"></td>\n<td align=\"right\">0.95</td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\">maxscanlength=100 random(uniform)</td>\n\
    </tr>\n<tr>\n<td align=\"left\">F</td>\n<td align=\"left\">Read-modify-write</td>\n\
    <td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.5</td>\n<td align=\"center\"\
    >zipfian</td>\n<td align=\"center\"></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-class-diagram-subset\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #class-diagram-subset\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>class diagram (subset)</h2>\n<div class=\"highlight highlight-source-mermaid\"\
    ><pre><span class=\"pl-k\">classDiagram</span>\n<span class=\"pl-k\">class</span>\
    \ <span class=\"pl-en\">DBFactory</span>\n<span class=\"pl-k\">class</span> <span\
    \ class=\"pl-en\">DB</span>\n<span class=\"pl-sg\">&lt;&lt;</span><span class=\"\
    pl-ent\">interface</span><span class=\"pl-sg\">&gt;&gt;</span> <span class=\"\
    pl-en\">DB</span>\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">HashtableDB</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">abstruct</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">HashtableDB</span>\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-en\">LockStlDB</span>\n<span class=\"\
    pl-k\">class</span> <span class=\"pl-en\">StringHashtable</span><span class=\"\
    pl-sg\">~</span><span class=\"pl-ent\">V</span><span class=\"pl-sg\">~</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">StringHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">KeyHashtable</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">KeyHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">FieldHashtable</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">FieldHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">StlHashTable</span><span\
    \ class=\"pl-sg\">~</span><span class=\"pl-ent\">V</span><span class=\"pl-sg\"\
    >~</span>\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">StlHashTableKey</span>\
    \ <span class=\"pl-sg\">{</span>\n  <span class=\"pl-k\">std::unorderd_map</span><span\
    \ class=\"pl-sg\">~</span><span class=\"pl-ent\">String,FieldHashtable*</span><span\
    \ class=\"pl-sg\">~</span>\n<span class=\"pl-sg\">}</span>\n<span class=\"pl-k\"\
    >class</span> <span class=\"pl-en\">StlHashTableField</span> <span class=\"pl-sg\"\
    >{</span>\n  <span class=\"pl-k\">std::unorderd_map</span><span class=\"pl-sg\"\
    >~</span><span class=\"pl-ent\">String,const char*</span><span class=\"pl-sg\"\
    >~</span>\n<span class=\"pl-sg\">}</span>\n<span class=\"pl-k\">class</span> <span\
    \ class=\"pl-en\">LockStlHashtable</span><span class=\"pl-sg\">~</span><span class=\"\
    pl-ent\">T</span><span class=\"pl-sg\">~</span>\n<span class=\"pl-k\">class</span>\
    \ <span class=\"pl-en\">LockStlHashtableKey</span> <span class=\"pl-sg\">{</span>\n\
    \  <span class=\"pl-k\">std::mutex</span>\n<span class=\"pl-sg\">}</span>\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-en\">LockStlHashtableField</span>\
    \ <span class=\"pl-sg\">{</span>\n  <span class=\"pl-k\">std::mutex</span>\n<span\
    \ class=\"pl-sg\">}</span>\n\n<span class=\"pl-en\">DBFactory</span> <span class=\"\
    pl-k\">..&gt;</span> <span class=\"pl-en\">LockStlDB</span> <span class=\"pl-k\"\
    >:</span> <span class=\"pl-s\">create</span>\n<span class=\"pl-en\">LockStlDB</span>\
    \ <span class=\"pl-k\">*--</span> <span class=\"pl-en\">LockStlHashtableKey</span>\n\
    <span class=\"pl-en\">LockStlHashtableKey</span> <span class=\"pl-k\">o--</span>\
    \ <span class=\"pl-en\">LockStlHashtableField</span>\n<span class=\"pl-en\">LockStlDB</span>\
    \ <span class=\"pl-k\">..&gt;</span> <span class=\"pl-en\">LockStlHashtableField</span>\
    \ <span class=\"pl-k\">:</span> <span class=\"pl-s\">create</span>\n\n<span class=\"\
    pl-en\">DB</span> <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">HashtableDB</span>\n\
    <span class=\"pl-en\">HashtableDB</span> <span class=\"pl-k\">&lt;|..</span> <span\
    \ class=\"pl-en\">LockStlDB</span>\n<span class=\"pl-en\">StringHashtable</span>\
    \ <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">StlHashTable</span>\n\
    <span class=\"pl-en\">StlHashTable</span> <span class=\"pl-k\">&lt;|--</span><span\
    \ class=\"pl-en\">LockStlHashtable</span>\n\n<span class=\"pl-en\">StringHashtable</span>\
    \ <span class=\"pl-k\">..</span> <span class=\"pl-en\">FieldHashtable</span> <span\
    \ class=\"pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n<span class=\"\
    pl-en\">StringHashtable</span> <span class=\"pl-k\">..</span> <span class=\"pl-en\"\
    >KeyHashtable</span> <span class=\"pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n\
    <span class=\"pl-en\">StlHashTable</span> <span class=\"pl-k\">..</span> <span\
    \ class=\"pl-en\">StlHashTableKey</span> <span class=\"pl-k\">:</span> <span class=\"\
    pl-s\">instantiation</span>\n<span class=\"pl-en\">StlHashTable</span> <span class=\"\
    pl-k\">..</span> <span class=\"pl-en\">StlHashTableField</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n<span class=\"pl-en\"\
    >LockStlHashtable</span> <span class=\"pl-k\">..</span> <span class=\"pl-en\"\
    >LockStlHashtableKey</span> <span class=\"pl-k\">:</span> <span class=\"pl-s\"\
    >instantiation</span>\n<span class=\"pl-en\">LockStlHashtable</span> <span class=\"\
    pl-k\">..</span> <span class=\"pl-en\">LockStlHashtableField</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n\n<span class=\"pl-en\"\
    >StlHashTableKey</span>  <span class=\"pl-k\">&lt;|--</span> <span class=\"pl-en\"\
    >LockStlHashtableKey</span>\n<span class=\"pl-en\">StlHashTableField</span>  <span\
    \ class=\"pl-k\">&lt;|--</span> <span class=\"pl-en\">LockStlHashtableField</span>\n\
    <span class=\"pl-en\">KeyHashtable</span> <span class=\"pl-k\">&lt;|..</span>\
    \ <span class=\"pl-en\">StlHashTableKey</span>\n<span class=\"pl-en\">FieldHashtable</span>\
    \ <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">StlHashTableField</span>\n\
    \n<span class=\"pl-en\">HashtableDB</span> <span class=\"pl-k\">..&gt;</span>\
    \ <span class=\"pl-en\">KeyHashtable</span> <span class=\"pl-k\">:</span> <span\
    \ class=\"pl-s\">use</span>\n<span class=\"pl-en\">HashtableDB</span> <span class=\"\
    pl-k\">..&gt;</span> <span class=\"pl-en\">FieldHashtable</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">use</span></pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667533964.0
range3/pegasus-lm:
  data_format: 2
  description: null
  filenames:
  - spack/envs/pegasus/spack.yaml
  full_name: range3/pegasus-lm
  latest_release: null
  readme: "<h1><a id=\"user-content-range3pegasus-lm\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#range3pegasus-lm\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>range3/pegasus-lm</h1>\n<h2><a id=\"user-content-setup\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#setup\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>setup</h2>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>module load cuda/11.8.0\nmodule load cudnn/8.6.0/cuda11\nmodule load openmpi/4.1.4/gcc9.4.0-cuda11.8.0\n\
    python3 -m venv .venv\n<span class=\"pl-c1\">source</span> .venv/bin/activate\n\
    pip install -U pip\npip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu118\n\
    pip install neologdn \\\n  prefetch-generator \\\n  datasets \\\n  sentencepiece\
    \ \\\n  transformers \\\n  scikit-learn \\\n  evaluate \\\n  tensorboard \\\n\
    \  accelerate \\\n  git+https://github.com/huggingface/transformers</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678687089.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<h1><a id=\"user-content-libpressio\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#libpressio\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>LibPressio</h1>\n<p><em>the stable version of this code is found at\
    \ <a href=\"https://github.com/CODARcode/libpressio\">at the CODARCode organization</a>\
    \ it is updated about anually</em></p>\n<p>Pressio is latin for compression. \
    \ LibPressio is a C++ library with C compatible bindings to abstract between different\
    \ lossless and lossy compressors and their configurations.  It solves the problem\
    \ of having to having to write separate application level code for each lossy\
    \ compressor that is developed.  Instead, users write application level code using\
    \ LibPressio, and the library will make the correct underlying calls to the compressors.\
    \  It provides interfaces to represent data, compressors settings, and compressors.</p>\n\
    <p>Documentation for the <code>master</code> branch can be <a href=\"https://robertu94.github.io/libpressio/\"\
    \ rel=\"nofollow\">found here</a></p>\n<h1><a id=\"user-content-using-libpressio\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-libpressio\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using LibPressio</h1>\n<p>Example\
    \ using the CLI from <a href=\"https://github.com/robertu94/pressio-tools\"><code>pressio-tools</code></a>\n\
    We also have C, C++, Rust, Julia, and Python bindings.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pressio -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<h2><a id=\"user-content-getting-started\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#getting-started\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>After skimming\
    \ the example, LibPressio has 6 major headers that you will need to use:</p>\n\
    <table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>pressio.h</code></td>\n<td>Error reporting and aquiring handles\
    \ to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<h2><a id=\"user-content-supported-compressors-and-metrics\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#supported-compressors-and-metrics\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ Compressors and Metrics</h2>\n<p>Libpressio provides a number of builtin compressor\
    \ and metrics modules.\nAll of these are <strong>disabled by default</strong>.\n\
    They can be enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code>\
    \ variable to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information\
    \ on writing a compressor plugin see [Writing a Compressor Plugin](@ref writingacompressor)\n\
    For information on writing a metrics plugin see [Writing a Metrics Plugin](@ref\
    \ writingametric)</p>\n<h3><a id=\"user-content-compressor-plugins\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#compressor-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compressor Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the [compressor settings page](@ref compressors)\
    \ for information on how to configure them.</p>\n<h3><a id=\"user-content-metrics-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#metrics-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Metrics Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the [metrics results page](@ref metrics)\
    \ for information on what they produce</p>\n<h3><a id=\"user-content-io-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#io-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>IO Plugins</h3>\n<p>1st party\
    \ compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the [io settings page](@ref io) for information\
    \ on how to configure them</p>\n<h1><a id=\"user-content-installation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Installation</h1>\n<h2><a id=\"user-content-installing-libpressio-using-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-libpressio-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ LibPressio using Spack</h2>\n<p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\"\
    >spack</a>.  This example will install libpressio with only the SZ3 plugin.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<h2><a id=\"user-content-doing-a-development-build-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#doing-a-development-build-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Doing a\
    \ development build with spack</h2>\n<p>The easiest way to do a development build\
    \ of libpressio is to use Spack envionments.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> one time setup: create\
    \ an envionment</span>\nspack env create -d mydevenviroment\nspack env activate\
    \ mydevenvionment\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one time\
    \ setup: install libpressio-tools and checkout </span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> libpressio for development</span>\nspack add libpressio-tools\n\
    spack develop libpressio@git.master\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> compile and install (repeat as needed)</span>\nspack install </pre></div>\n\
    <h2><a id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#manual-installation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Manual Installation</h2>\n<p>Libpressio unconditionally\
    \ requires:</p>\n<ul>\n<li><code>cmake</code></li>\n<li><code>pkg-config</code></li>\n\
    <li><a href=\"https://github.com/robertu94/std_compat\"><code>std_compat</code></a></li>\n\
    <li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code> or later</li>\n<li>\n<code>clang-7.0.0</code>\
    \ or later using either <code>libc++</code> or <code>libstdc++</code>.  Beware\
    \ that system libraries may need to be recompiled with <code>libc++</code> if\
    \ using <code>libc++</code>\n</li>\n</ul>\n</li>\n</ul>\n<p>Dependency versions\
    \ and optional dependencies are documented <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<h2><a id=\"user-content-configuring-libpressio-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-libpressio-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ LibPressio Manually</h2>\n<p>LibPressio uses a fairly standard CMake buildsystem.\n\
    For more information on <a href=\"https://robertu94.github.io/learning/cmake\"\
    \ rel=\"nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration\
    \ options for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\n\
    For information on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<h1><a id=\"user-content-api-stability\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#api-stability\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>API Stability</h1>\n<p>Please refer to <a href=\"\
    docs/stability.md\">docs/stability.md</a>.</p>\n<h1><a id=\"user-content-how-to-contribute\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-contribute\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to Contribute</h1>\n<p>Please\
    \ refer to <a href=\"CONTRIBUTORS.md\">CONTRIBUTORS.md</a> for a list of contributors,\
    \ sponsors, and contribution guidelines.</p>\n<h1><a id=\"user-content-bug-reports\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#bug-reports\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Bug Reports</h1>\n<p>Please files\
    \ bugs to the Github Issues page on the CODARCode libpressio repository.</p>\n\
    <p>Please read this post on <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\"\
    \ rel=\"nofollow\">how to file a good bug report</a>.\_ After reading this post,\
    \ please provide the following information specific to libpressio:</p>\n<ul>\n\
    <li>Your OS version and distribution information, usually this can be found in\
    \ <code>/etc/os-release</code>\n</li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n\
    </li>\n<li>the version of each of libpressio's dependencies listed in the README\
    \ that you have installed. Where possible, please provide the commit hashes.</li>\n\
    </ul>\n<h1><a id=\"user-content-citing-libpressio\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#citing-libpressio\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Citing LibPressio</h1>\n<p>If you find LibPressio\
    \ useful, please cite this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n\
    \  title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n\
    \  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di,\
    \ Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on\
    \ Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n\
    \  year={2021},\n  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 16
  subscribers_count: 5
  topics: []
  updated_at: 1673367032.0
robertu94/poorjit:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/poorjit
  latest_release: null
  readme: '<h1><a id="user-content-poorjit" class="anchor" aria-hidden="true" href="#poorjit"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>poorjit</h1>

    <p>A poor man''s jit for C++ for when you want to instantiate and call templates
    at

    runtime. Is there a more efficient way to do this? sure, but this is ~100 lines

    of code I wrote in less than an afternoon. Almost certainly only works on Linux

    and with either clang or g++.</p>

    <p>See <code>test</code> for a usage example.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1668715291.0
salotz/scopes-chipmunk2d:
  data_format: 2
  description: Scopes language wrapper of Chipmunk2D
  filenames:
  - spack.yaml
  full_name: salotz/scopes-chipmunk2d
  latest_release: null
  readme: "<h1><a id=\"user-content-scopes-chipmunk2d\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#scopes-chipmunk2d\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>scopes-chipmunk2d</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The module\
    \ is under <code>src/chipmunk2d</code>. You can copy this subtree into your\n\
    project and then add it to the <code>package.path</code> in your Scopes\n<code>_project.sc</code>\
    \ file.</p>\n<h3><a id=\"user-content-with-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#with-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>With Spack</h3>\n<p>This module is available as the <code>scopes-chipmunk2d</code>\
    \ package in the\n<a href=\"https://github.com/salotz/snailpacks\">snailpacks</a>\
    \ repository. This will pull in the necessary dependencies\nincluding Scopes.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  spack install scopes-chipmunk2d</pre></div>\n\
    <p>See the <a href=\"https://github.com/salotz/snailpacks\">snailpacks</a> documentation\
    \ for more best practices of installing.</p>\n<h2><a id=\"user-content-development-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development-environment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development Environment</h2>\n\
    <p>We use <a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> to install\
    \ dependencies. First install Spack.</p>\n<p>Then you'll need our custom repo\
    \ of build recipes:</p>\n<div class=\"highlight highlight-source-shell\"><pre>\
    \  mkdir -p <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/.spack/repos</span>\n\
    <span class=\"pl-s\">  git clone git@github.com:salotz/snailpacks.git <span class=\"\
    pl-pds\">`</span></span>/.spack/repos/snailpacks\n  spack repo add <span class=\"\
    pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  spack env create -d <span class=\"pl-c1\">.</span></pre></div>\n<p>Activate\
    \ the environment (i.e. set the environment variables\nappropriately) and install\
    \ the packages:</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spacktivate\
    \ <span class=\"pl-c1\">.</span>\n  spack install</pre></div>\n<p>To exit the\
    \ environment (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - scopes-lang
  - chipmunk2d
  updated_at: 1648788744.0
scifihpc/scibuilder:
  data_format: 2
  description: New build system for building scientific software.
  filenames:
  - test/appl_test/spack.yaml
  - test/spack_env/spack.yaml
  - examples/build-image/spack_example_hy-alma8/spack.yaml
  - examples/without-image/spack_example_ubuntu22.04/spack.yaml
  full_name: scifihpc/scibuilder
  latest_release: null
  readme: "<h1><a id=\"user-content-scibuilder\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#scibuilder\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Scibuilder</h1>\n<p>Scibuilder is a tool for helping with automated\
    \ builds</p>\n<h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>Scibuilder is a Python module and it needs an\
    \ environment with various packages.</p>\n<p>We recommend using <code>mamba</code>\
    \ for faster installation.\n<a href=\"https://github.com/conda-forge/miniforge#install\"\
    >Mambaforge</a> is an excellent way\nof getting <code>mamba</code>.</p>\n<p>Creating\
    \ environment:</p>\n<div class=\"highlight highlight-source-shell\"><pre>mamba\
    \ env create --file environment.yml\n<span class=\"pl-c1\">source</span> activate\
    \ scibuilder</pre></div>\n<h2><a id=\"user-content-running-scibuilder-example\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-scibuilder-example\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running scibuilder\
    \ example</h2>\n<h3><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h3>\n<p>This example build works on Ubuntu 22.04. It installs\
    \ cmake as an example.</p>\n<div class=\"highlight highlight-source-shell\"><pre>git\
    \ clone https://github.com/spack/spack.git\n<span class=\"pl-c1\">.</span> spack/share/spack/setup-env.sh\n\
    python -m scibuilder spack build examples/without-image/spackbuilder_example.yml</pre></div>\n\
    <h3><a id=\"user-content-mamba\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #mamba\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mamba</h3>\n\
    <p>This example build will work on any linux system. It creates two conda environments:\n\
    one with gpu-enabled packgages and one without.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python -m scibuilder mamba build examples/without-image/mambabuilder_example.yml</pre></div>\n\
    <h2><a id=\"user-content-scibuilder-build-image\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#scibuilder-build-image\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>scibuilder-build-image</h2>\n<p>Scibuilder can be\
    \ run in a docker/podman images.</p>\n<p>See image <a href=\"dockerfiles/scibuilder-build-image/README.md\"\
    >README.md</a> for more information.</p>\n<h2><a id=\"user-content-configuring-builds\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-builds\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Configuring builds</h2>\n<h3><a\
    \ id=\"user-content-spack-1\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-1\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>Spack builds are configured by creating a YAML-file that describes what environments\
    \ we\nwant to build and the compilers we want to use for building them.</p>\n\
    <p>Let's look at <a href=\"examples/without-image/spackbuilder_example.yml\">examples/without-image/spackbuilder_example.yml</a>:</p>\n\
    <div class=\"highlight highlight-source-yaml\"><pre><span class=\"pl-ent\">environments</span>:\n\
    \  - <span class=\"pl-ent\">name</span>: <span class=\"pl-s\">spack_example</span>\n\
    \    <span class=\"pl-ent\">tags</span>:\n      - <span class=\"pl-s\">spack</span>\n\
    \      - <span class=\"pl-s\">main</span>\n    <span class=\"pl-ent\">environment_file</span>:\
    \ <span class=\"pl-s\">examples/without-image/spack_example_ubuntu22.04/spack.yaml</span>\n\
    \    <span class=\"pl-ent\">system_compiler</span>: <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>gcc@11.3.0<span class=\"pl-pds\">\"</span></span>\n\
    \    <span class=\"pl-ent\">compilers</span>:\n      - <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>gcc@11.3.0<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>The list <code>environments</code> consist of multiple independent build with\
    \ the following\nattributes:</p>\n<ul>\n<li>\n<code>name</code> - Name of the\
    \ environment</li>\n<li>\n<code>tags</code> - List of arbitrary tags that can\
    \ be used to limit the builder to only these\nbuilds via the <code>--tags=TAGS</code>-parameter.</li>\n\
    <li>\n<code>environmnet_file</code> - A spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">environement file</a>\nthat contains information on what packages\
    \ we want to install and where we want to install them.</li>\n<li>\n<code>system_compiler</code>\
    \ - A compiler present in the system that the builder will try to locate for\n\
    spack to use as an initial compiler.</li>\n<li>\n<code>compilers</code>: List\
    \ of compilers that spack will try to locate and build with the system compiler\n\
    before building the environment in full.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1678697646.0
simonpintarelli/acclapack-tests:
  data_format: 2
  description: null
  filenames:
  - spack-envs/rocm/spack.yaml
  - spack-envs/cuda/spack.yaml
  full_name: simonpintarelli/acclapack-tests
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667393188.0
spack/gitlab-runners:
  data_format: 2
  description: Images used to run Gitlab pipelines in the cloud
  filenames:
  - spack.yaml
  full_name: spack/gitlab-runners
  latest_release: v2023-03-09
  readme: '<p>This repository contains images that are used to run Gitlab pipelines
    to validate PRs in Spack.</p>

    <p>The recipes have been modified from ones in: <a href="https://github.com/UO-OACISS/e4s">https://github.com/UO-OACISS/e4s</a></p>

    '
  stargazers_count: 1
  subscribers_count: 10
  topics: []
  updated_at: 1675192423.0
sundials-codes/sundials-manyvector-demo:
  data_format: 2
  description: Demonstration application for Multirate+ManyVector capabilities
  filenames:
  - spack/spack-summit.yaml
  - docker/spack-develop.yaml
  - docker/spack-latest.yaml
  full_name: sundials-codes/sundials-manyvector-demo
  latest_release: null
  readme: "<h1><a id=\"user-content-sundials-manyvectormultirate-demonstration-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#sundials-manyvectormultirate-demonstration-code\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SUNDIALS\
    \ ManyVector+Multirate Demonstration Code</h1>\n<p>[Note: this project is in active\
    \ development.]</p>\n<p>This is a <a href=\"https://github.com/LLNL/sundials\"\
    >SUNDIALS</a>-based demonstration\napplication to assess and demonstrate the large-scale\
    \ parallel performance of\nnew capabilities that have been added to SUNDIALS in\
    \ recent years. Namely:</p>\n<ol>\n<li>\n<p>The new SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html#the-nvector-mpimanyvector-module\"\
    \ rel=\"nofollow\">MPIManyVector</a>\nimplementation, that enables flexibility\
    \ in how a solution data is\npartitioned across computational resources e.g.,\
    \ CPUs and GPUs.</p>\n</li>\n<li>\n<p>The new <a href=\"https://sundials.readthedocs.io/en/latest/arkode/index.html\"\
    \ rel=\"nofollow\">ARKODE</a>\nmultirate integration module, MRIStep, allowing\
    \ high-order accurate\ncalculations that subcycle \"fast\" processes within \"\
    slow\" ones.</p>\n</li>\n<li>\n<p>The new flexible SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/sunlinsol/index.html\"\
    \ rel=\"nofollow\">SUNLinearSolver</a>\ninterfaces, to enable streamlined use\
    \ of problem specific and scalable\nlinear solver libraries e.g., SuiteSparse\
    \ and MAGMA.</p>\n</li>\n</ol>\n<h2><a id=\"user-content-model-equations\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#model-equations\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Model Equations</h2>\n<p>This code\
    \ simulates a 3D nonlinear inviscid compressible Euler equation with\nadvection\
    \ and reaction of chemical species,</p>\n<p>$$w_t = -\\nabla\\cdot F(w) + G(X,t,w),$$</p>\n\
    <p>for independent variables $(X,t) = (x,y,z,t) \\in \\Omega \\times [t_0, t_f]$\n\
    where the spatial domain is a three-dimensional cube,\n$\\Omega = [x_l, x_r] \\\
    times [y_l, y_r] \\times [z_l, z_r]$.</p>\n<p>The differential equation is completed\
    \ using initial condition\n$w(X,t_0) = w_0(X)$ and face-specific boundary conditions\
    \ may be periodic (0),\nhomogeneous Neumann (1), homogeneous Dirichlet (2), or\
    \ reflecting (3) under the\nrestriction that if any boundary is set to \"periodic\"\
    \ then the opposite face\nmust also indicate a periodic condition.</p>\n<p>The\
    \ system state vector $w$ is</p>\n<p>$$w = \\begin{bmatrix} \\rho &amp; \\rho\
    \ v_x &amp; \\rho v_y &amp; \\rho v_z &amp; e_t &amp; \\mathbf{c} \\end{bmatrix}^T\
    \ = \\begin{bmatrix} \\rho &amp; m_x &amp; m_y &amp; m_z &amp; e_t &amp; \\mathbf{c}\
    \ \\end{bmatrix}^T$$</p>\n<p>corresponding to the density, momentum in the x,\
    \ y, and z directions, total\nenergy per unit volume, and any number of chemical\
    \ densities\n$\\mathbf{c}\\in\\mathbb{R}^{nchem}$ that are advected along with\
    \ the fluid. The\nfluxes are given by</p>\n<p>$$F_x(w) = \\begin{bmatrix} \\rho\
    \ v_x &amp; \\rho v_x^2 + p &amp; \\rho v_x v_y &amp; \\rho v_x v_z &amp; v_x\
    \ (e_t+p) &amp; \\mathbf{c} v_x \\end{bmatrix}^T,$$</p>\n<p>$$F_y(w) = \\begin{bmatrix}\
    \ \\rho v_y &amp; \\rho v_x v_y &amp; \\rho v_y^2 + p &amp; \\rho v_y v_z &amp;\
    \ v_y (e_t+p) &amp; \\mathbf{c} v_y \\end{bmatrix}^T,$$</p>\n<p>$$F_z(w) = \\\
    begin{bmatrix} \\rho v_z &amp; \\rho v_x v_z &amp; \\rho v_y v_z &amp; \\rho v_z^2\
    \ + p &amp; v_z (e_t+p) &amp; \\mathbf{c} v_z \\end{bmatrix}^T.$$</p>\n<p>The\
    \ external force $G(X,t,w)$ is test-problem-dependent, and the ideal gas\nequation\
    \ of state gives $p = \\frac{R}{c_v}(e_t - \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2))$\n\
    and $e_t = \\frac{pc_v}{R} + \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$\nor equivalently,\
    \ $p = (\\gamma-1) (e_t - \\frac{\\rho}{2} (v_x^2 + v_y^2 + v_z^2))$\nand $e_t\
    \ = \\frac{p}{\\gamma - 1}\\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$.</p>\n<p>We\
    \ have the physical parameters:</p>\n<ul>\n<li>\n<p>$R$ is the specific ideal\
    \ gas constant (287.14 J/kg/K),</p>\n</li>\n<li>\n<p>$c_v$ is the specific heat\
    \ capacity at constant volume (717.5 J/kg/K),</p>\n</li>\n<li>\n<p>$\\gamma =\
    \ c_p/c_v = 1 + R/c_v$ is the ratio of specific heats (1.4),</p>\n</li>\n</ul>\n\
    <p>corresponding to air (predominantly an ideal diatomic gas). The speed\nof sound\
    \ in the gas is then given by $c = \\sqrt{\\dfrac{\\gamma p}{\\rho}}$.</p>\n<p>The\
    \ fluid variables above are non-dimensionalized; in standard SI units\nthese would\
    \ be:</p>\n<ul>\n<li>\n<p>$[\\rho] = kg / m^3$,</p>\n</li>\n<li>\n<p>$[v_x] =\
    \ [v_y] = [v_z] = m/s$, which implies $[m_x] = [m_y] = [m_z] = kg / m^2 / s$</p>\n\
    </li>\n<li>\n<p>$[e_t] = kg / m / s^2$, and</p>\n</li>\n<li>\n<p>$[\\mathbf{c}_i]\
    \ = kg / m^3$</p>\n</li>\n</ul>\n<p>Note: the fluid portion of the description\
    \ above follows the presentation\n<a href=\"https://www.theoretical-physics.net/dev/fluid-dynamics/euler.html\"\
    \ rel=\"nofollow\">here</a>\nin sections 7.3.1 - 7.3.3.</p>\n<h2><a id=\"user-content-discretization\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#discretization\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Discretization</h2>\n<p>We discretize\
    \ this problem using the method of lines, where we first semi-discretize\nin space\
    \ using a regular finite volume grid with dimensions <code>nx</code> x <code>ny</code>\
    \ x <code>nz</code>, with\nfluxes at cell faces calculated using a 5th-order FD-WENO\
    \ reconstruction.  MPI\nparallelization is achieved using a standard 3D domain\
    \ decomposition, using <code>nprocs</code>\nMPI ranks, with layout <code>npx</code>\
    \ x <code>npy</code> x <code>npz</code> defined automatically via the\n<code>MPI_Dims_create</code>\
    \ utility routine.  The minimum size for any dimension is 3, so\nto run a two-dimensional\
    \ test in the yz-plane, one could specify <code>nx = 3</code> and\n<code>ny =\
    \ nz = 200</code>.  When run in parallel, only \"active\" spatial dimensions (those\n\
    with extent greater than 3) will be parallelized.</p>\n<p>The fluid fields $\\\
    rho$, $m_x$, $m_y$, $m_z$, and $e_t$ are stored in separate serial\n<code>N_Vector</code>\
    \ objects on each MPI rank. The chemical species at all spatial locations over\n\
    each MPI rank are collocated into a single serial or RAJA <code>N_Vector</code>\
    \ object when\nrunning on the CPU or GPU respectively. The five fluid vectors\
    \ and the chemical\nspecies vector are combined together to form the full \"solution\"\
    \ vector $w$ using\nthe <code>MPIManyVector</code> <code>N_Vector</code> module.</p>\n\
    <p>After spatial semi-discretization, we are faced with a large IVP system,</p>\n\
    <p>$$w'(t) = f_1(w) + f_2(w), \\quad w(t_0)=w_0,$$</p>\n<p>where $f_1(w)$ and\
    \ $f_2(w)$ contain the spatially discretized forms of\n$-\\nabla\\cdot F(w)$ and\
    \ $G(X,t,w)$, respectively.</p>\n<p>For non-reactive flows, the resulting initial-value\
    \ problem is evolved in time\nusing an adaptive step explicit Runge-Kutta method\
    \ from the ARKStep module in\nARKODE. For problems involving (typically stiff)\
    \ chemical reactions, the problem\nmay be solved using one of two approaches.</p>\n\
    <ol>\n<li>\n<p>It may be treated as a multirate initial-value problem, that is\
    \ solved using\nthe MRIStep module in ARKODE, wherein the gas dynamics equations\
    \ are evolved\nexplicitly at the slow time scale, while the chemical kinetics\
    \ are evolved\nat a faster time scale using a temporally-adaptive, diagonally-implicit\n\
    Runge-Kutta method from the ARKStep module.</p>\n</li>\n<li>\n<p>It may be treated\
    \ using mixed implicit-explicit (IMEX) methods at a single\ntime scale.  Here,\
    \ the gas dynamics equations are treated explicitly, while\nthe chemical kinetics\
    \ are treated implicitly, using an additive Runge-Kutta\nmethod from the ARKStep\
    \ module.</p>\n</li>\n</ol>\n<p>For (1) we use SUNDIALS' modified Newton solver\
    \ to handle the global nonlinear\nalgebraic systems arising at each implicit stage\
    \ of each time step.  Since only\n$f_2$ is treated implicitly and the reactions\
    \ are purely local in space, the\nNewton linear systems are block-diagonal. As\
    \ such, we provide a custom\n<code>SUNLinearSolver</code> implementation that\
    \ solves each MPI rank-local linear system\nindependently. The portion of the\
    \ Jacobian matrix on each rank is itself\nblock-diagonal. We further leverage\
    \ this structure by solving each rank-local\nlinear system using either the sparse\
    \ KLU (CPU-only) or batched dense MAGMA\n(GPU-enabled) SUNDIALS <code>SUNLinearSolver</code>\
    \ implementations.</p>\n<p>The multirate approach (2) can leverage the structure\
    \ of $f_2$ at a higher\nlevel. Since the MRI method applied to this problem evolves\
    \ \"fast\" sub-problems\nof the form</p>\n<p>$$v'(t) = f_2(t,v) + r_i(t), \\quad\
    \ i=2,\\ldots,s,$$</p>\n<p>and all MPI communication necessary to construct the\
    \ forcing functions, $r_i(t)$,\nhas already been performed, each sub-problem consists\
    \ of <code>nx</code> x <code>ny</code> x <code>nz</code>\nspatially-decoupled\
    \ fast IVPs. We construct a custom fast integrator that groups\nall the independent\
    \ fast IVPs on an MPI rank together as a single system evolved\nusing a rank-local\
    \ ARKStep instance.  The code for this custom integrator itself\nis minimal, primarily\
    \ consisting of steps to access the local subvectors in $w$\non a given MPI rank\
    \ and wrapping them in MPI-unaware ManyVectors provided to the\nlocal ARKStep\
    \ instance. The collection of independent local IVPs also leads to a\nblock diagonal\
    \ Jacobian, and we again utilize the <code>SUNLinearSolver</code> modules listed\n\
    above for linear systems that arise within the modified Newton iteration.</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The following steps describe how to build the\
    \ demonstration code in a Linux or\nOS X environment.</p>\n<h3><a id=\"user-content-gettting-the-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#gettting-the-code\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Gettting the Code</h3>\n<p>To\
    \ obtain the code, clone this repository with Git:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  git clone https://github.com/sundials-codes/sundials-manyvector-demo.git</pre></div>\n\
    <h3><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Requirements</h3>\n<p>To compile the code you will need:</p>\n<ul>\n\
    <li>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\">CMake</a> 3.20 or newer</p>\n\
    </li>\n<li>\n<p>modern C and C++ compilers</p>\n</li>\n<li>\n<p>the NVIDIA <a\
    \ href=\"https://developer.nvidia.com/cuda-toolkit\" rel=\"nofollow\">CUDA Toolkit</a>\
    \ (when\nusing the CUDA backend)</p>\n</li>\n<li>\n<p>an MPI library e.g., <a\
    \ href=\"https://www.open-mpi.org/\" rel=\"nofollow\">OpenMPI</a>,\n<a href=\"\
    https://www.mpich.org/\" rel=\"nofollow\">MPICH</a>, etc.</p>\n</li>\n<li>\n<p>the\
    \ <a href=\"https://www.hdfgroup.org/\" rel=\"nofollow\">HDF5</a> high-performance\
    \ data management and\nstorage suite</p>\n</li>\n<li>\n<p>the <a href=\"https://github.com/LLNL/RAJA\"\
    >RAJA</a> performance portability library</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://computing.llnl.gov/projects/sundials\" rel=\"nofollow\">SUNDIALS</a> library\
    \ of time\nintegrators and nonlinear solvers</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://people.engr.tamu.edu/davis/suitesparse.html\" rel=\"nofollow\">SuiteSparse</a>\
    \ library\nof sparse direct linear solvers (when using a CPU backend)</p>\n</li>\n\
    <li>\n<p>the <a href=\"https://icl.utk.edu/magma/\" rel=\"nofollow\">MAGMA</a>\
    \ dense linear solver library (when\nusing a GPU backend)</p>\n</li>\n</ul>\n\
    <h4><a id=\"user-content-installing-dependencies-with-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#installing-dependencies-with-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing Dependencies with\
    \ Spack</h4>\n<p>Many of the above dependencies can be installed using the\n<a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> package manager. For information\
    \ on using Spack see\nthe getting started <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#getting-started\"\
    \ rel=\"nofollow\">guide</a>.\nThe instructions below were formulated from Spack\
    \ v0.19.0, although newer versions should also work.</p>\n<p>Once Spack is setup,\
    \ we recommend creating a Spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html#\"\
    \ rel=\"nofollow\">environment</a>\nwith the required dependencies e.g., on a\
    \ system with Pascal GPUs and CUDA\n11.4.2 installed:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack env create --with-view <span class=\"pl-k\"\
    >~</span>/views/sundials-demo sundials-demo\nspack env activate sundials-demo\n\
    spack add sundials@6.2.0 +openmp +mpi +logging-mpi +klu +magma +raja +cuda cuda_arch=60\
    \ ^cuda@11.4.2 ^magma@2.6.1 +cuda cuda_arch=60 ^raja@0.13.0 +cuda cuda_arch=60\
    \ ^suite-sparse@5.8.1\nspack add hdf5@1.10.7 +hl +mpi\nspack install</pre></div>\n\
    <p>To assist in building the dependencies on select systems the <a href=\"./spack\"\
    >spack</a>\ndirectory contains environment files leveraging software already available\
    \ on\nthe system. For example, on the OLCF Summit system:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>module load gcc/10.2.0 cuda/11.4.2 cmake/3.21.3\n\
    <span class=\"pl-c1\">cd</span> spack\nspack env create sundials-demo spack-summit.yaml\n\
    spack env activate sundials-demo\nspack install</pre></div>\n<h4><a id=\"user-content-using-docker-containers\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-docker-containers\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Docker\
    \ Containers</h4>\n<p>It also possible to use the Docker containers from the <a\
    \ href=\"https://github.com/orgs/sundials-codes/packages?repo_name=sundials-manyvector-demo\"\
    >GitHub Container Registry</a>\nwith the necessary dependencies preinstalled for\
    \ CPU-only testing. Two images\nare provided:</p>\n<ul>\n<li>\n<p>sundials-demo-spack-latest\
    \ -- based on the latest Spack release (currently\nv0.19.0)</p>\n</li>\n<li>\n\
    <p>sundials-demo-spack-develop -- based on the Spack develop branch and updated\n\
    monthly</p>\n</li>\n</ul>\n<p>Pull the image(s) using <a href=\"https://www.docker.com/\"\
    \ rel=\"nofollow\">Docker</a> (or <a href=\"https://podman.io\" rel=\"nofollow\"\
    >Podman</a>).\nFor example, the <code>run</code> command below will pull the image\
    \ and start the container\nand the <code>exec</code> command will start a bash\
    \ shell inside the container.</p>\n<pre><code>docker run -t -d --name sundialsci-demo-spack-latest\
    \ ghcr.io/sundials-codes/sundials-demo-spack-latest:spack-latest\ndocker exec\
    \ -it sundials-demo-spack-lateset bash\n</code></pre>\n<p>Then clone this repository\
    \ with Git and configure/build the code as described\nbelow. The Spack installed\
    \ dependencies are available from the <code>/opt/view</code>\ndirectory.</p>\n\
    <h3><a id=\"user-content-configuration-options\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#configuration-options\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Configuration Options</h3>\n<p>Once the necessary\
    \ dependencies are installed, the following CMake variables can\nbe used to configure\
    \ the demonstration code build:</p>\n<ul>\n<li>\n<p><code>CMAKE_INSTALL_PREFIX</code>\
    \ - the path where executables and input files should be\ninstalled e.g., <code>my/install/path</code>.\
    \ The executables will be installed in the\n<code>bin</code> directory and input\
    \ files in the <code>tests</code> directory under the given path.</p>\n</li>\n\
    <li>\n<p><code>CMAKE_C_COMPILER</code> - the C compiler to use e.g., <code>mpicc</code>.\
    \ If not set, CMake\nwill attempt to automatically detect the C compiler.</p>\n\
    </li>\n<li>\n<p><code>CMAKE_C_FLAGS</code> - the C compiler flags to use e.g.,\
    \ <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_C_STANDARD</code> - the\
    \ C standard to use, defaults to <code>99</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_COMPILER</code>\
    \ - the C++ compiler to use e.g., <code>mpicxx</code>. If not set,\nCMake will\
    \ attempt to automatically detect the C++ compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_FLAGS</code>\
    \ - the C++ flags to use e.g., <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_STANDARD</code>\
    \ - the C++ standard to use, defaults to <code>11</code>.</p>\n</li>\n<li>\n<p><code>RAJA_ROOT</code>\
    \ - the root directory of the RAJA installation, defaults to the\nvalue of the\
    \ <code>RAJA_ROOT</code> environment variable. If not set, CMake will attempt\n\
    to automatically locate a RAJA install on the system.</p>\n</li>\n<li>\n<p><code>RAJA_BACKEND</code>\
    \ - the RAJA backend to use with the demonstration code, defaults\nto <code>SERIAL</code>.\
    \ Supported options are <code>SERIAL</code>, <code>OPENMP</code> and <code>CUDA</code>.\
    \  Note that this\nonly applies to on-node parallelism that is used when evaluating\
    \ chemistry-based\ncomponents associated with $f_2(w)$.</p>\n</li>\n<li>\n<p><code>SUNDIALS_ROOT</code>\
    \ - the root directory of the SUNDIALS installation, defaults to\nthe value of\
    \ the <code>SUNDIALS_ROOT</code> environment variable. If not set, CMake will\n\
    attempt to automatically locate a SUNDIALS install on the system.</p>\n</li>\n\
    <li>\n<p><code>ENABLE_HDF5</code> - build with HDF5 I/O support, defaults to <code>OFF</code>.</p>\n\
    </li>\n<li>\n<p><code>HDF5_ROOT</code> - the root directory of the HDF5 installation,\
    \ defaults to the\nvalue of the <code>HDF5_ROOT</code> environment variable. If\
    \ not set, CMake will attempt\nto automatically locate a HDF5 install on the system.</p>\n\
    </li>\n</ul>\n<p>When RAJA is installed with CUDA support enabled, the following\
    \ additional\nvariables may also be set:</p>\n<ul>\n<li>\n<p><code>CMAKE_CUDA_COMPILER</code>\
    \ - the CUDA compiler to use e.g., <code>nvcc</code>. If not set,\nCMake will\
    \ attempt to automatically detect the CUDA compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_FLAGS</code>\
    \ - the CUDA compiler flags to use.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_ARCHITECTURES</code>\
    \ - the CUDA architecture to target e.g., <code>70</code>.</p>\n</li>\n</ul>\n\
    <h3><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h3>\n\
    <p>In-source builds are not permitted, as such the code should be configured and\n\
    built from a separate build directory e.g.,</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  <span class=\"pl-c1\">cd</span> sundials-manyvector-demo\n  mkdir build\n\
    \  <span class=\"pl-c1\">cd</span> build\n  cmake ../. \\\n    -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>[install-path]<span class=\"\
    pl-pds\">\"</span></span> \\\n    -DRAJA_BACKEND=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>SERIAL<span class=\"pl-pds\">\"</span></span> \\\n    -DENABLE_HDF5=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DHDF5_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span> \\\n    -DRAJA_ROOT=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>[spack-view-path]<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DSUNDIALS_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span>\n  make\n  make install</pre></div>\n<p>where\
    \ <code>[install-path]</code> is the path to where the binary and test input files\n\
    should be installed and <code>[spack-view-path]</code> is the path to the Spack\
    \ environment\nview, <code>~/views/sundials-demo</code> when following the Spack\
    \ instructions above or\n<code>/opt/view</code> when using the Docker containers.</p>\n\
    <h2><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n\
    <p>Several test cases are included with the code and the necessary input files\
    \ for\neach case are contained in the subdirectories within the <a href=\"./tests\"\
    >tests</a>\ndirectory. Each input file is internally documented to discuss all\
    \ possible\ninput parameters (in case some have been added since this <code>README</code>\
    \ was last\nupdated).</p>\n<p>The input files contain parameters to set up the\
    \ physical problem:</p>\n<ul>\n<li>\n<p>spatial domain, $\\Omega$ -- <code>xl</code>,\
    \ <code>xr</code>, <code>yl</code>, <code>yr</code>, <code>zl</code>, <code>zr</code></p>\n\
    </li>\n<li>\n<p>time interval, $[t_0, t_f]$ -- <code>t0</code>, <code>tf</code></p>\n\
    </li>\n<li>\n<p>the ratio of specific heats, $\\gamma$ -- <code>gamma</code></p>\n\
    </li>\n<li>\n<p>spatial discretization dimensions -- <code>nx</code>, <code>ny</code>,\
    \ <code>nz</code></p>\n</li>\n<li>\n<p>boundary condition types -- <code>xlbc</code>,\
    \ <code>xrbc</code>, <code>ylbc</code>, <code>yrbc</code>, <code>zlbc</code>,\
    \ <code>zrbc</code></p>\n</li>\n</ul>\n<p>Parameters to control the execution\
    \ of the code:</p>\n<ul>\n<li>\n<p>desired CFL fraction -- <code>cfl</code> (if\
    \ set to zero, then the time step is chosen purely using temporal adaptivity).</p>\n\
    </li>\n<li>\n<p>number of desired solution outputs -- <code>nout</code></p>\n\
    </li>\n<li>\n<p>a flag to enable optional output of RMS averages for each field\
    \ at the frequency specified via <code>nout</code> -- <code>showstats</code></p>\n\
    </li>\n</ul>\n<p>Numerous parameters are also provided to control how time integration\
    \ is\nperformed (these are passed directly to ARKODE). For further information\
    \ on the\nARKODE solver parameters and the meaning of individual values, see the\n\
    <a href=\"https://sundials.readthedocs.io/en/latest/index.html\" rel=\"nofollow\"\
    >ARKODE documentation</a>.</p>\n<p>To specify an input file to the executable,\
    \ the input filename should be\nprovided using the <code>-f</code> flag e.g.,</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> -f <span class=\"pl-k\">&lt;</span>input_file<span\
    \ class=\"pl-k\">&gt;</span></pre></div>\n<p>Additionally, any input parameters\
    \ may also be specified on the\ncommand line e.g.,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> --nx=100 --ny=100 --nz=400</pre></div>\n<p>For example,\
    \ continuing with the Summit case from above, the primordial blast\ntest can be\
    \ run on one Summit node using four cores and four GPUs with the\nfollowing commands:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">${MEMBERWORK}</span>/[projid]/sundials-demo/tests/primordial_blast\n\
    \  bsub -q debug -nnodes 1 -W 0:10 -P [projid] -Is <span class=\"pl-smi\">$SHELL</span>\n\
    \  jsrun -n4 -a1 -c1 -g1 ../../bin/primordial_blast_mr.exe -f input_primordial_blast_mr_gpu.txt</pre></div>\n\
    <p>The <code>bsub</code> command above will submit a request for an interactive\
    \ job to the\ndebug queue allocating one node for 10 minutes with the compute\
    \ time charged to\n<code>[projid]</code>. Once the interactive session starts\
    \ the test case is launched using\nthe <code>jsrun</code> command. Solutions are\
    \ output to disk using parallel HDF5, solution\nstatistics are optionally output\
    \ to the screen at specified frequencies, and run\nstatistics are printed at the\
    \ end of the simulation.</p>\n<p>The parallel HDF5 solution snapshots are written\
    \ at the frequency specified by\n<code>nout</code>.  Accompanying these <code>output-#######.hdf5</code>\
    \ files is an automatically\ngenerated input file, <code>restart_parameters.txt</code>\
    \ that stores a complete set of\ninput parameters to restart the simulation from\
    \ the most recently generated\noutput file. This is a \"warm\" restart, in that\
    \ it will pick up the calculation\nwhere the previous one left off, using the\
    \ same initial time step size as\nARKStep would use. This restart may differ slightly\
    \ from an uninterrupted run\nsince other internal ARKStep time adaptivity parameters\
    \ cannot be reused.  We\nnote that the restart must use the same spatial grid\
    \ size and number of chemical\ntracers as the original run, but it may use a different\
    \ number of MPI tasks if\ndesired.</p>\n<h2><a id=\"user-content-adding-new-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-tests\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Adding New Tests</h2>\n<p>Individual\
    \ test problems are uniquely specified through an input file and\nauxiliary source\
    \ code file(s) that should be linked with the main routine at\ncompile time. By\
    \ default, all codes are built with no chemical species; however,\nthis may be\
    \ controlled at compilation time using the <code>NVAR</code> preprocessor\ndirective,\
    \ corresponding to the number of unknowns at any spatial location.\nHence, the\
    \ (default) minimum value for <code>NVAR</code> is 5, so for a calculation with\
    \ 4\nchemical species the code should be compiled with the preprocessor directive\n\
    <code>NVAR=9</code>. See <a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ for examples of how to\nspecify <code>NVAR</code> when adding a new test/executable.</p>\n\
    <p>The auxiliary source code files for creating a new test must contain three\n\
    functions. Each of these must return an integer flag indicating success (0) or\n\
    failure (nonzero). The initial condition function $w_0(X)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">initial_conditions</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector w, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>and the forcing function $G(X,t,w)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">external_forces</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector G, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>Additionally, a function must be supplied to compute/output\
    \ any\ndesired solution diagnostic information with the signature</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span> <span\
    \ class=\"pl-en\">output_diagnostics</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, <span class=\"pl-k\">const</span> N_Vector w, <span class=\"\
    pl-k\">const</span> UserData&amp; udata);</pre></div>\n<p>If no diagnostics information\
    \ is desired, then this routine may just return 0.</p>\n<p>Here, the <code>initial_conditions</code>\
    \ routine will be called once when the simulation\nbegins, <code>external_forces</code>\
    \ will be called on every evaluation of the ODE\nright-hand side function for\
    \ the Euler equations (it is assumed that this does\nnot require the results from\
    \ (<code>UserData::ExchangeStart</code>\n/ <code>UserData::ExchangeEnd</code>),\
    \ and <code>output_diagnostics</code> will be called at the same\nfrequency as\
    \ the solution is output to disk.</p>\n<p>To add a new executable using these\
    \ auxiliary source code file(s), update\n<a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ to include a new call to\n<code>sundemo_add_executable</code> in a similar manner\
    \ as the existing test problems e.g.,\n<code>hurricane_yz.exe</code>.</p>\n<h2><a\
    \ id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" href=\"#authors\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n\
    <p><a href=\"https://people.smu.edu/dreynolds\" rel=\"nofollow\">Daniel R. Reynolds</a>\
    \ and\n<a href=\"https://people.llnl.gov/gardner48\" rel=\"nofollow\">David J.\
    \ Gardner</a></p>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1655924113.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - chifflot/p100/spack.yaml
  - local/spack.yaml
  - cooley/spack.yaml
  - chifflot/v100/spack.yaml
  - thetagpu/spack.yaml
  - gemini/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1><a id="user-content-spack-envs" class="anchor" aria-hidden="true" href="#spack-envs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-envs</h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2><a id="user-content-locally" class="anchor" aria-hidden="true" href="#locally"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Locally</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: $spack/opt/spack</span>

    <span class="pl-c1">build_stage: $user_cache_path/stage</span>


    <span class="pl-c1">spack env activate ~/Dev/spack-envs/local</span>

    <span class="pl-c1">spack install</span></pre></div>

    <h2><a id="user-content-g5k" class="anchor" aria-hidden="true" href="#g5k"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>G5k</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: /mnt/spack</span>

    <span class="pl-c1">build_stage: /tmp/spack-stage</span></pre></div>

    <h2><a id="user-content-anl" class="anchor" aria-hidden="true" href="#anl"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ANL</h2>

    <h3><a id="user-content-cooley" class="anchor" aria-hidden="true" href="#cooley"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Cooley</h3>

    <p>Before using Spack to compile stuff on Cooley, we recommend to run <code>use_build_cooley</code>
    to get access to newer gcc, cmake, and mvapich versions.</p>

    <h3><a id="user-content-thetagpu" class="anchor" aria-hidden="true" href="#thetagpu"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ThetaGPU</h3>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678891926.0
toxa81/se:
  data_format: 2
  description: Software environments
  filenames:
  - catalog-config/compilers/gcc-11.3.0/spack.yaml
  - catalog-config/core/spack.yaml
  - catalog-config/compilers/nvhpc-22.9/spack.yaml
  - catalog-config/libxc-5.2.3/spack.yaml
  full_name: toxa81/se
  latest_release: null
  readme: '<h1><a id="user-content-software-environments" class="anchor" aria-hidden="true"
    href="#software-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    environments</h1>

    <p>Deployment steps</p>

    <ul>

    <li>clone spack <code>git clone https://github.com/spack/spack.git</code>

    </li>

    <li>enable spack <code>source enable-spack</code>

    </li>

    <li>srun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16</li>

    <li>install gcc-11.3.0 view <code>spack -e  ./env-spec/gcc-11.3.0/ install</code>

    </li>

    <li>install nvhpc-22.9 <code>srun -N1 --partition=nvgpu spack -e . install -j64</code>

    </li>

    </ul>

    <p>spack compiler find $(spack find --format {prefix.bin} gcc@11)</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669195550.0
tpeterka/mpas-o-workflow:
  data_format: 2
  description: null
  filenames:
  - mpas_spack.yaml
  full_name: tpeterka/mpas-o-workflow
  latest_release: null
  readme: '<h1><a id="user-content-instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow"
    class="anchor" aria-hidden="true" href="#instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Instructions for Building
    MPAS-Ocean to Run in a Wilkins Workflow</h1>

    <p>Installation is done through Spack. If you don''t have Spack installed or if
    Spack is new to you, go <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">here</a>
    first.</p>

    <p>Clone this repository and cd into it. These instructions assume there is a
    top-level directory called climate.</p>

    <pre><code>mkdir ~/climate

    cd ~/climate

    git clone https://github.com/tpeterka/mpas-o-workflow

    cd mpas-o-workflow

    </code></pre>

    <hr>

    <h2><a id="user-content-setting-up-spack-environment" class="anchor" aria-hidden="true"
    href="#setting-up-spack-environment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Setting
    up Spack environment</h2>

    <h3><a id="user-content-first-time-create-and-load-the-spack-environment-for-mpas-ocean"
    class="anchor" aria-hidden="true" href="#first-time-create-and-load-the-spack-environment-for-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    and load the Spack environment for MPAS-Ocean</h3>

    <pre><code>cd ~/climate/mpas-o-workflow

    source ./create-mpas.sh     # requires being in the same directory to work properly

    </code></pre>

    <h3><a id="user-content-subsequent-times-load-the-spack-environment-for-mpas-ocean"
    class="anchor" aria-hidden="true" href="#subsequent-times-load-the-spack-environment-for-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Subsequent times: load
    the Spack environment for MPAS-Ocean</h3>

    <pre><code>source ~/climate/mpas-o-workflow/load-mpas.sh

    </code></pre>

    <hr>

    <h2><a id="user-content-building-mpas-ocean" class="anchor" aria-hidden="true"
    href="#building-mpas-ocean"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    MPAS-Ocean</h2>

    <h3><a id="user-content-first-time-clone-mpas-ocean" class="anchor" aria-hidden="true"
    href="#first-time-clone-mpas-ocean"><span aria-hidden="true" class="octicon octicon-link"></span></a>First
    time: clone MPAS-Ocean</h3>

    <pre><code>cd ~/climate

    git clone https://github.com/E3SM-Project/E3SM

    cd E3SM

    git submodule update --init --recursive

    </code></pre>

    <h2><a id="user-content-first-time-modify-mpas-ocean-makefiles-to-link-to-henson"
    class="anchor" aria-hidden="true" href="#first-time-modify-mpas-ocean-makefiles-to-link-to-henson"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: modify
    MPAS-Ocean makefiles to link to Henson</h2>

    <p>Edit ~climate/E3SM/components/mpas-ocean/Makefile:</p>

    <p>Insert at line 596:

    <code>LIBS += -L $(HENSON)/lib -lhenson</code></p>

    <p>Insert at line 732:

    <code>LDFLAGS += -shared</code></p>

    <p>Edit line 1002 to add .so to executable name: <code>$(EXE_NAME).so</code></p>

    <h3><a id="user-content-build-mpas-ocean" class="anchor" aria-hidden="true" href="#build-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build MPAS-Ocean</h3>

    <pre><code>cd ~/climate/E3SM/components/mpas-ocean

    make clean              # if dirty

    make -j gfortran

    </code></pre>

    <p>This will take ~ 5 minutes to compile.</p>

    <h3><a id="user-content-create-a-run-script-for-mpas-ocean" class="anchor" aria-hidden="true"
    href="#create-a-run-script-for-mpas-ocean"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Create a run script for MPAS-Ocean</h3>

    <p>edit (create) <code>~/climate/E3SM/components/mpas-ocean/ocean_model</code>:

    <code>python3 ~/climate/mpas-o-workflow/mpas-henson.py</code></p>

    <p>Set permissions of <code>ocean_model</code> to executable:

    <code>chmod 755 ~/climate/E3SM/components/mpas-ocean/ocean_model</code></p>

    <hr>

    <h2><a id="user-content-setting-up-a-test-case-to-execute" class="anchor" aria-hidden="true"
    href="#setting-up-a-test-case-to-execute"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Setting up a test case to execute</h2>

    <p>Compass is an E3SM system for generating and running test cases for MPAS-Ocean,
    and relies on conda environments. The instructions below assume you have cond
    or miniconda already installed. If not, go <a href="https://docs.conda.io/en/latest/miniconda.html"
    rel="nofollow">here</a> first.</p>

    <h3><a id="user-content-first-time-install-compass-and-create-compass-environment"
    class="anchor" aria-hidden="true" href="#first-time-install-compass-and-create-compass-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: install
    Compass and create Compass environment</h3>

    <pre><code>cd ~

    git clone https://github.com/MPAS-Dev/compass.git compass-env-only

    cd ~/compass-env-only

    git submodule update --init --recursive

    ./conda/configure_compass_env.py --conda ~/miniconda3 --env_only

    source load_dev_compass_1.2.0-alpha.4.sh        # load_dev_compass-1.2.0-alpha.4.sh
    is the script created by the previous command

    </code></pre>

    <h3><a id="user-content-first-time-create-a-compass-configuration-file-for-a-new-machine"
    class="anchor" aria-hidden="true" href="#first-time-create-a-compass-configuration-file-for-a-new-machine"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    a compass configuration file for a new machine</h3>

    <p>Assumes the config file is named ~/compass-env-only/compass.cfg and has these
    contents, or similar (yours may vary)</p>

    <pre><code># This file contains some common config options you might want to set


    # The paths section describes paths to databases and shared compass environments

    [paths]


    # A root directory where MPAS standalone data can be found

    database_root = /home/tpeterka/compass/mpas_standalonedata


    # The parallel section describes options related to running tests in parallel

    [parallel]


    # parallel system of execution: slurm or single_node

    system = single_node


    # whether to use mpirun or srun to run the model

    parallel_executable = mpiexec


    # cores per node on the machine, detected automatically by default

    # cores_per_node = 4

    </code></pre>

    <h3><a id="user-content-first-time-create-test-case-for-the-executable" class="anchor"
    aria-hidden="true" href="#first-time-create-test-case-for-the-executable"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    test case for the executable</h3>

    <p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code> is the name of
    the conda environment load script created initially</p>

    <pre><code>source ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh

    compass setup -t ocean/baroclinic_channel/10km/default -w ~/spack-baroclinic-test
    -p ~/climate/E3SM/components/mpas-ocean -f ~/compass-env-only/compass.cfg

    </code></pre>

    <h3><a id="user-content-run-the-test-case" class="anchor" aria-hidden="true" href="#run-the-test-case"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run the test case</h3>

    <p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code> is the name of
    the conda environment load script created initially</p>

    <pre><code>source ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh

    source ~/climate/mpas-o-workflow/load-mpas.sh

    cd ~/spack-baroclinic-test/ocean/baroclinic_channel/10km/default

    compass run

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679076329.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/intelmpi/bpmf-mpi_isend/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/intelmpi/bpmf-argo/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1635166163.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-374/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: 0.8.0
  stargazers_count: 19
  subscribers_count: 5
  topics:
  - jupyter
  - jupyter-notebooks
  - jupyter-kernels
  - ipython
  - ipywidgets
  - ipython-widget
  - spack
  - pipenv
  - dvc
  - data-science
  - pandas
  updated_at: 1678958728.0
wangzhezhe/Gorilla:
  data_format: 2
  description: The Gorilla framework which provides distributed in-memory data management
    service
  filenames:
  - spack_cpu.yaml
  - spack.yaml
  full_name: wangzhezhe/Gorilla
  latest_release: null
  readme: "<h2><a id=\"user-content-motivation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#motivation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Motivation</h2>\n<p>Gorilla framework is a in-memory data management\
    \ servie. The name of the framework comes from the brand \"gorilla glue\", since\
    \ we are basically gluing different components together. It mainly supoorts follwing\
    \ capabilities:</p>\n<p>(1) suppot M:N data put/get for data based on grid mesh.</p>\n\
    <p>(2)User can use customized trigger to express the logic flow of the task executions.\
    \ The implementation of in-memory data storage service layer is inspired by the\
    \ <a href=\"https://github.com/philip-davis/dataspaces\">DataSpaces</a> and the\
    \ <a href=\"https://github.com/ornladios/ADIOS2\">ADIOS</a> projects. [adios test\
    \ case is deprecated]</p>\n<p>(3)There is specific event queue binded with the\
    \ trigger to support the data-driven task executions, the properties of the data\
    \ can be captured and client can acquire the metadata of the raw data by poll\
    \ events. The idea of data driven approach mainly comes from the <a href=\"https://www.osti.gov/biblio/1493245\"\
    \ rel=\"nofollow\">OSTI technical report</a>.</p>\n<p><strong>More key design\
    \ strategies can be found at the designDoc/scratch.md</strong></p>\n<h2><a id=\"\
    user-content-compiling-and-running-the-server\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#compiling-and-running-the-server\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Compiling and running the server</h2>\n<p>this\
    \ is an eample to compile the gorilla server on cori cluster</p>\n<pre><code>source\
    \ ~/.gorilla\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc\
    \ -DVTK_DIR=~/cworkspace/src/VTK/build/ -DUSE_GNI=ON\n</code></pre>\n<p>If the\
    \ paraveiw is used for particular test</p>\n<pre><code>old one\ncmake ~/cworkspace/src/Gorilla/\
    \ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=$SCRATCH/build_paraview_matthieu_release/\
    \ -DUSE_GNI=ON -DParaView_DIR=$SCRATCH/build_paraview_matthieu/ -DBUILD_SHARED_LIBS=ON\
    \ -DAMReX_DIR=/global/cscratch1/sd/zw241/build_amrex/install/lib/cmake/AMReX\n\
    </code></pre>\n<pre><code>new one (the cray based MPI can be detected and used\
    \ in this case when we use the cc and CC)\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC\
    \ -DCMAKE_C_COMPILER=cc -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0\
    \ -DUSE_GNI=ON\n</code></pre>\n<p>this is the content of the <code>~/.gorilla_cpu</code>\
    \ file on cori cluster:</p>\n<pre><code>#!/bin/bash\n\nsource ~/.color\nmodule\
    \ load cmake/3.18.2\nmodule load spack\n#spack load cmake@3.18.2%gcc@8.2.0\n\n\
    module swap PrgEnv-intel PrgEnv-gnu\n# ssg works well for gcc 9.3.0\nmodule swap\
    \ gcc/8.3.0 gcc/9.3.0\n\nspack load -r mochi-thallium%gcc@9.3.0\n#spack load mochi-cfg\n\
    spack load -r mochi-abt-io%gcc@9.3.0\n\nexport CRAYPE_LINK_TYPE=dynamic\n# we\
    \ do not use GPU and vtkm for this version\ncd $SCRATCH/build_Gorilla_cpu\n\n\n\
    export MPICH_GNI_NDREG_ENTRIES=1024 \n# get more mercury info\nexport HG_NA_LOG_LEVEL=debug\n\
    \n# avoid argobot thred pool issue, and set this to 2M\n# this may helps avoid\
    \ segfault when we use the processing and IO in large amount\n# export ABT_THREAD_STACKSIZE=2097152\n\
    # to make sure ther eis enough stack and not oom\nexport ABT_THREAD_STACKSIZE=1048576\n\
    </code></pre>\n<p>refer to the ./scripts dir to check exmaples of running multiple\
    \ servers. The configuration of the server contains item such as protocol used\
    \ by communication layer, the log level, the global domain and if the trigger\
    \ is started and so on. The example of the configuration is in ./server/settings.json</p>\n\
    <h3><a id=\"user-content-build-on-gpu-nodes\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#build-on-gpu-nodes\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>build on gpu nodes</h3>\n<p>this is the content of\
    \ the <code>~/.gorilla_gpu</code> file on cori cluster:</p>\n<pre><code>#!/bin/bash\n\
    source ~/.color\n\nsource ~/cworkspace/src/spack/share/spack/setup-env.sh\nmodule\
    \ swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\n# cuda can not\
    \ use this cray-mpich\nmodule unload cray-mpich/7.7.10\nmodule load cgpu cuda\
    \ openmpi\nmodule load cmake/3.20.5\n\n# jump to the gpu node\nsalloc -C gpu -t\
    \ 60 -c 8 -G 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\n# for thallium\n\
    spack load -r mochi-thallium%gcc@9.3.0\nspack load -r mochi-abt-io%gcc@9.3.0\n\
    \nexport CRAYPE_LINK_TYPE=dynamic\n</code></pre>\n<p>build</p>\n<p>(associated\
    \ vtkm accelarator should be enabled when building vtk in this case)\n(we do not\
    \ need extra vtkm build when there is vtk integration?)\n(we use vtkm associated\
    \ with vtk)</p>\n<pre><code>cmake ~/cworkspace/src/Gorilla/ -DCMAKE_CUDA_COMPILER=nvcc\
    \ -DCMAKE_CXX_COMPILER=g++ -DCMAKE_C_COMPILER=gcc -DVTKm_DIR=/global/cscratch1/sd/zw241/build_vtkm/lib/cmake/vtkm-1.6\
    \ -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0 -DUSE_GNI=ON\
    \ -DUSE_GPU=ON -DBUILD_SHARED_LIBS=ON -DVTKm_ENABLE_CUDA=ON -DVTKm_CUDA_Architecture=volta\n\
    </code></pre>\n<p>example to run the test</p>\n<pre><code>srun -C gpu -n 1 --gpus-per-task=1\
    \  nvprof ./test/test_insitu_ana\n</code></pre>\n<h3><a id=\"user-content-using-the-spack-env\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-the-spack-env\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using the spack env</h3>\n<p>if\
    \ we use the spack env, it means that we do not set the public packages.yaml file.\
    \ We also need to set the customized spack env for the Gorilla repo.</p>\n<p>set\
    \ up env (we use the spack installed by the colza-experiments)</p>\n<pre><code>source\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nspack\
    \ env create gorilla ~/cworkspace/src/Gorilla/spack.yaml\nspack repo add --scope\
    \ env:gorilla /global/cscratch1/sd/zw241/colza-experiments/cori/vtk/sw/mochi-spack-packages/\n\
    spack env update gorilla \nspack install -y\n</code></pre>\n<p>if the spack env\
    \ is installed successfully</p>\n<pre><code>#!/bin/bash\nsource ~/.color\n\nsource\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nmodule\
    \ swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\n# cuda can not\
    \ use this cray-mpich\nmodule unload cray-mpich/7.7.10\nmodule load cgpu cuda\
    \ openmpi\nmodule load cmake/3.20.5\n\n# activate env for the thallium\nspack\
    \ env activate gorilla\n\n# jump to the gpu node\nsalloc -C gpu -t 60 -c 8 -G\
    \ 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\nexport CRAYPE_LINK_TYPE=dynamic\n\
    </code></pre>\n<h3><a id=\"user-content-run\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#run\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>run</h3>\n<p>exmaple on cori</p>\n<pre><code>srun -C haswell -n 8\
    \ ./unimos_server ~/cworkspace/src/Gorilla/server/settings_gni.json\n</code></pre>\n\
    <p>remember to set the env if MPICH is used</p>\n<pre><code>MPICH_GNI_NDREG_ENTRIES=1024\n\
    </code></pre>\n<p>simple example to put the data</p>\n<pre><code>srun -C haswell\
    \ -n 16 ./example/gray-scott-stg ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ gni\n</code></pre>\n<p>simple example to get the data for further processing</p>\n\
    <pre><code>srun -n 4 ./example/isosurface ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ 10 0.5 gni\n</code></pre>\n<h3><a id=\"user-content-version-info\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#version-info\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Version info</h3>\n<p>v0.1</p>\n<p>M:N\
    \ put get for Cartesian grid</p>\n<p>memory and file backend\n(file backend will\
    \ be used when there is not enough mem space)</p>\n<p>in-memory data trigger (experimental)</p>\n\
    <h3><a id=\"user-content-related-issue\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#related-issue\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>related issue</h3>\n<pre><code>/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so:\
    \ undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023'\n</code></pre>\n\
    <p>try this:</p>\n<p>SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")</p>\n\
    <p>refer to</p>\n<p><a href=\"https://github.com/halide/Halide/issues/1112\">https://github.com/halide/Halide/issues/1112</a></p>\n\
    <p>make -j may hide some potential cmake mistakes, try to use make if there is\
    \ specific link issue</p>\n"
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1641259621.0
waynemitchell/mfem:
  data_format: 2
  description: 'Mirror of MFEM - a lightweight, general, scalable C++ library for
    finite element methods. Please use the official repository, https://github.com/mfem/mfem,
    to create issues and pull requests. See also the MFEM website: '
  filenames:
  - config/docker/spack.yaml
  full_name: waynemitchell/mfem
  latest_release: null
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed under the terms\
    \ of the BSD-3 license. All new contributions\nmust be made under this license.\
    \ See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> for\n\
    details.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release Number:\
    \ LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679324110.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/crusher/PrgEnv-gnu/spack.yaml
  - platformFiles/lassen/spack.yaml
  - platformFiles/summit/spack.yaml
  - platformFiles/crusher/PrgEnv-cray/spack.yaml
  - platformFiles/polaris/gcc-11.2.0/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1><a id="user-content-useful-supplementary-materials-for-installing-the-xsdk"
    class="anchor" aria-hidden="true" href="#useful-supplementary-materials-for-installing-the-xsdk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful supplementary
    materials for installing the xSDK</h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics: []
  updated_at: 1669065329.0
youwuyou/slimfly_collectives:
  data_format: 2
  description: null
  filenames:
  - ompi1-dev/spack.yaml
  full_name: youwuyou/slimfly_collectives
  latest_release: null
  readme: '<h1><a id="user-content-slim-fly-mpi-collective-optimization" class="anchor"
    aria-hidden="true" href="#slim-fly-mpi-collective-optimization"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Slim Fly MPI collective optimization</h1>

    <blockquote>

    <p>TODO: this repo is reset and needs to be put under source control with the
    new structure! Remember to add the <code>.github/workflows/ci.yml</code> as in
    the current git repo</p>

    </blockquote>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1671447123.0
