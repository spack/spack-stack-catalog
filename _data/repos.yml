AlexanderRichert-NOAA/CItest:
  data_format: 2
  description: Set up a simplified test case based on spack/HDF5 build fail due to
    /usr/local contents
  filenames:
  - spack.yaml
  full_name: AlexanderRichert-NOAA/CItest
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1671482597.0
C2SM/spack-c2sm:
  data_format: 2
  description: Repository for c2sm spack config and repo files
  filenames:
  - upstreams/daint/spack.yaml
  full_name: C2SM/spack-c2sm
  latest_release: v0.18.1.3
  readme: '<h1><a id="user-content-the-spack-extension-of-c2sm-and-mch" class="anchor"
    aria-hidden="true" href="#the-spack-extension-of-c2sm-and-mch"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>The spack extension of C2SM and MCH</h1>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/67d98f3f50b1ad629290b2fc5a38331fc19df5a656363fb14bdd892b371dcf0e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616e7369636f6c6f72746167732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/ansicolortags/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is the package manager used by C2SM and MeteoSwiss to install and deploy
    software on supercomputers, local machines and the cloud.</p>

    <h2><a id="user-content-documentations" class="anchor" aria-hidden="true" href="#documentations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentations</h2>

    <p><strong>Infos about c2sm-supported software and machines</strong></p>

    <ul>

    <li><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow">spack-c2sm
    latest</a></li>

    <li><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.3" rel="nofollow">spack-c2sm
    v0.18.1.3</a></li>

    <li><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.2" rel="nofollow">spack-c2sm
    v0.18.1.2</a></li>

    <li><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.1" rel="nofollow">spack-c2sm
    v0.18.1.1</a></li>

    </ul>

    <p><strong>General infos about spack</strong></p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/v0.18.1/" rel="nofollow">Official
    spack v0.18.1</a></li>

    </ul>

    <h2><a id="user-content-workflow" class="anchor" aria-hidden="true" href="#workflow"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Workflow</h2>

    <p>With spack v0.18 we suggest local/individual spack instances and the use of
    spack environments.</p>

    <p>A user clones the spack repo</p>

    <div class="highlight highlight-source-shell"><pre>git clone --depth 1 --recurse-submodules
    --shallow-submodules -b v0.18.1.3 https://github.com/C2SM/spack-c2sm.git</pre></div>

    <p>gets spack in the command line</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">.</span>
    spack-c2sm/setup-env.sh</pre></div>

    <p>activates an environment</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -p <span
    class="pl-k">&lt;</span>path_to_env<span class="pl-k">&gt;</span></pre></div>

    <p>and starts exploring</p>

    <div class="highlight highlight-source-shell"><pre>spack info <span class="pl-k">&lt;</span>package<span
    class="pl-k">&gt;</span>

    spack spec <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>and building</p>

    <div class="highlight highlight-source-shell"><pre>spack install <span class="pl-k">&lt;</span>spec<span
    class="pl-k">&gt;</span>

    spack dev-build <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>a package.</p>

    <p>Updating spack-c2sm is in the hands of the user.</p>

    <div class="highlight highlight-source-shell"><pre>git pull

    git submodule update --recursive</pre></div>

    <p>After an update we advice to clean</p>

    <div class="highlight highlight-source-shell"><pre>spack uninstall -a

    spack clean -a

    rm -rf <span class="pl-k">~</span>/.spack</pre></div>

    <p>and rebuild.</p>

    <h2><a id="user-content-command-cheat-sheet" class="anchor" aria-hidden="true"
    href="#command-cheat-sheet"><span aria-hidden="true" class="octicon octicon-link"></span></a>Command
    cheat sheet</h2>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Clone</td>

    <td><code>git clone --depth 1 --recurse-submodules --shallow-submodules -b &lt;branch/tag&gt;
    https://github.com/C2SM/spack-c2sm.git</code></td>

    </tr>

    <tr>

    <td>Load</td>

    <td>

    <code>. spack-c2sm/setup-env.sh</code> autodetects machine <br>or<br><code>. spack-c2sm/setup-env.sh
    &lt;machine&gt;</code> forces machine<br>or<br><code>. spack-c2sm/setup-env.sh
    unknown</code> uses blank config<br><code>spack compiler find</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-compiler-find"
    rel="nofollow">autodetects compilers</a><br><code>spack external find --all</code>
    <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-external-find"
    rel="nofollow">autodetects externally installed packages</a>

    </td>

    </tr>

    <tr>

    <td>Update</td>

    <td>

    <code>git pull</code><br><code>git submodule update --recursive</code>

    </td>

    </tr>

    <tr>

    <td>Clean</td>

    <td>

    <code>spack uninstall -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-uninstall"
    rel="nofollow">uninstalls all packages</a><br><code>spack clean -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-clean"
    rel="nofollow">cleans all misc caches</a><br><code>rm -rf ~/.spack</code> removes
    user scope data</td>

    </tr>

    </tbody>

    </table>

    <p><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><strong>Spec syntax</strong></a>: <code>&lt;package&gt;</code><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#version-specifier"
    rel="nofollow"><code>@&lt;version&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-specifier"
    rel="nofollow"><code>%&lt;compiler&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#variants"
    rel="nofollow"><code>+&lt;variant&gt; ~&lt;variant&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><code>^&lt;sub-package&gt; +&lt;sub-package-variant&gt;</code></a><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-flags"
    rel="nofollow"><code>&lt;compiler flags&gt;</code></a></p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Find</td>

    <td>

    <code>spack find</code> lists all installed packages. <br><code>spack find &lt;spec&gt;</code>
    lists all installed packages that match the spec.</td>

    </tr>

    <tr>

    <td>Info</td>

    <td><code>spack info &lt;package&gt;</code></td>

    </tr>

    <tr>

    <td>Spec</td>

    <td>

    <code>spack spec &lt;spec&gt;</code> concretizes abstract spec (unspecfied variant
    = <strong>any</strong>)<br><em>Spack is not required to use the default of an
    unspecified variant. The default value is only a tiebreaker for the concretizer.</em>

    </td>

    </tr>

    <tr>

    <td>Install</td>

    <td><code>spack install &lt;spec&gt;</code></td>

    </tr>

    <tr>

    <td>Locate</td>

    <td>

    <code>spack location --install-dir &lt;spec&gt;</code> prints location of <strong>all</strong>
    installs that satisfy the spec</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-load"
    rel="nofollow">Load env</a></td>

    <td>

    <code>spack load &lt;spec&gt;</code> loads run environment</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Activate
    env</a></td>

    <td><code>spack env activate -p &lt;env_name&gt;</code></td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Deactivate
    env</a></td>

    <td><code>spack deactivate</code></td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 3
  subscribers_count: 19
  topics: []
  updated_at: 1676997668.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/23.02/oneapi-x86_64/spack.yaml
  - environments/23.02/rocm-x86_64/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#e4s\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n<ul>\n<li>User\
    \ Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\">https://e4s.readthedocs.io</a>\n\
    </li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub: <a href=\"https://github.com/E4S-Project/\"\
    >https://github.com/E4S-Project/</a>\n</li>\n<li>E4S Slack Channel: <a href=\"\
    https://e4s-project.slack.com\" rel=\"nofollow\">https://e4s-project.slack.com</a>\n\
    </li>\n<li>Slack Channel Invitation: <a href=\"https://communityinviter.com/apps/e4s-project/e4s\"\
    \ rel=\"nofollow\">https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n\
    <li>E4S Dashboard: <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\
    >E4S-Project/E4S-Project.github.io</a> - E4S Documentation repo that is hosted\
    \ on <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 16
  subscribers_count: 10
  topics: []
  updated_at: 1680351263.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, time-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/desktop/spack-ubuntu-openmp.yaml
  - Tools/machines/desktop/spack-macos-openmp.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '23.04'
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" href="#warpx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667"
    alt="Gitter" data-canonical-src="https://badges.gitter.im/ECP-WarpX/community.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1109/SC41404.2022.00008" rel="nofollow"><img src="https://camo.githubusercontent.com/2be0ab9ceaff22581aac9ee5d5eac9cc73cae7e4bad2c69bcf0ffd6713337293/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our Gitter room at <a href="https://gitter.im/ECP-WarpX/community" rel="nofollow">https://gitter.im/ECP-WarpX/community</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 181
  subscribers_count: 15
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1680891339.0
FTHPC/Correlation_Compressibility:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: FTHPC/Correlation_Compressibility
  latest_release: v0.1
  readme: "<h1><a id=\"user-content-compressibility-analysis-correlation_compressibility\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#compressibility-analysis-correlation_compressibility\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compressibility\
    \ Analysis (Correlation_Compressibility)</h1>\n<h2><a id=\"user-content-statement-of-purpose\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#statement-of-purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Statement of Purpose</h2>\n<p>This\
    \ repo contains scripts to perform compressibility analysis on several leading\
    \ lossy compressors.\nThe compressibility analysis relies on deriving statistics\
    \ on scientific data and explore their relationships to their compression ratios\
    \ from various lossy compressors (based on various compression scheme).\nThe extracted\
    \ relationships between compression ratios and statistical predictors are modeled\
    \ via regression models, which provide a statistical framework to predict compression\
    \ ratios for the different studied lossy compressors.</p>\n<p>This repo contains\
    \ an automatic framework of scripts that perform the compression of scientific\
    \ datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding and Bit\
    \ Grooming), the derivation of the statistical predictors of compression ratios\
    \ (SVD, standard deviation, quantized entropy), and scripts to perform the training\
    \ of the regression models (linear and spline regressions) as well as the validation\
    \ of the regression predictions.\nA runtime analysis is also performed and associated\
    \ codes are provided.</p>\n<h3><a id=\"user-content-main-code-structures\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#main-code-structures\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Main code structures</h3>\n<p>Compression\
    \ metrics, including compression ratios, and derivation of statistical predictors\
    \ (SVD, standard deviation, quantized entropy) codes are found in <code>compress_package</code>\
    \ and are run via <code>scripts/run.sh</code> as described in the section \"How\
    \ to compute statistical predictors and compression analysis on datasets\".\n\
    Linear and spline regressions training and validation (functions <code>cr_regression_linreg</code>\
    \ and <code>cr_regression_gam</code> from the script <code>replicate_figures/functions_paper.R</code>).\n\
    Codes for the different runtime analysis are found in the folder <code>runtime_analysis</code>\
    \ and are automated with the script <code>runtime.sh</code>, the study includes\
    \ compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled)\
    \ variogram and local (tiled) variogram, and runtime for training and prediction\
    \ of the regressions.<br>\nFinally, the script <code>replicate_figures/graphs_paper_container.R</code>\
    \ replicates and saves all the figures from the paper ad as well as numbers from\
    \ the tables.</p>\n<p>For each dataset in the <code>dataset</code> folder, slicing\
    \ is performed for each variable field (e.g. density in Miranda), each slice is\
    \ stored in a class. The class is updated as compressions with the 8 compressors\
    \ is performed and updated as the statistical predictors are derived. Results\
    \ of each class are stored in a .csv file (example of csv files can be found at\
    \ <code>replicate_figures/generated_data/</code>).\nAll the datasets stored in\
    \ the <code>dataset</code> folder can be analyzed with the given set of codes,\
    \ one needs to source <code>scripts/config.json</code> with the appropriate dataset\
    \ name as described in the below section \"How to compute statistical predictors\
    \ and compression analysis on datasets\".\nThe regression analysis and its prediction\
    \ is then performed on R dataframes based on the aforementioned .csv files.</p>\n\
    <h2><a id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#system-information\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>System Information</h2>\n<p>The hardware and software\
    \ versions used for the performance evaluations can be found in the table below.\
    \ These nodes come from Clemson University's Palmetto Cluster.</p>\n<p>These nodes\
    \ have:</p>\n<table>\n<thead>\n<tr>\n<th>component</th>\n<th>version</th>\n<th>component</th>\n\
    <th>version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CPU</td>\n<td>Intel Xeon\
    \ 6148G (40 cores)</td>\n<td>sz2</td>\n<td>2.1.12.2</td>\n</tr>\n<tr>\n<td>GPU</td>\n\
    <td>2 Nvidia v100</td>\n<td>sz3</td>\n<td>3.1.3.1</td>\n</tr>\n<tr>\n<td>Memory</td>\n\
    <td>372GB</td>\n<td>zfp</td>\n<td>0.5.5</td>\n</tr>\n<tr>\n<td>Network</td>\n\
    <td>2 Mellanox MT27710 (HDR)</td>\n<td>mgard</td>\n<td>1.0.0</td>\n</tr>\n<tr>\n\
    <td>FileSystem</td>\n<td>BeeGFS 7.2.3 (24 targets)</td>\n<td>bit grooming</td>\n\
    <td>2.1.9</td>\n</tr>\n<tr>\n<td>Compiler</td>\n<td>GCC 8.4.1</td>\n<td>digit\
    \ rounding</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>OS</td>\n<td>CentOS 8.2.2004</td>\n\
    <td>R</td>\n<td>4.1.3</td>\n</tr>\n<tr>\n<td>MPI</td>\n<td>OpenMPI 4.0.5</td>\n\
    <td>Python</td>\n<td>3.9.12</td>\n</tr>\n<tr>\n<td>LibPressio</td>\n<td>0.83.4</td>\n\
    <td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-first-time-setup\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-setup\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>First time setup</h2>\n<h3><a\
    \ id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#container-installation-for-ease-of-setup\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Container Installation\
    \ (for ease of setup)</h3>\n<p>We provide a container for <code>x86_64</code>\
    \ image for ease of installation.</p>\n<p>This container differs from our experimental\
    \ setup slightly. The production build used <code>-march=native -mtune=native</code>\
    \ for architecture optimized builds where as the container does not use these\
    \ flags to maximize compatibility across <code>x86_64</code> hardware.</p>\n<p>NOTE\
    \ this file is &gt;= 11 GB , download with caution.</p>\n<h3><a id=\"user-content-manual-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#manual-installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manual Installation</h3>\n<p>By\
    \ default, it is recommended to follow the install locations that are indicated\
    \ on the top of <code>scripts/run.sh</code>\nand the top of <code>config.json</code>.\
    \ These two files provide the configuration options to get the program running.</p>\n\
    <p>Spack should be installed in the following location: <code>$HOME/spack/</code></p>\n\
    <p>This Github repo should be cloned in the following location: <code>$HOME/Correlation_Compressibility/</code>\n\
    This location is also referenced as the <code>COMPRESS_HOME</code> environment\
    \ variable.</p>\n<p>A dataset folder called 'datasets' should be in the following\
    \ location: <code>$HOME/Correlation_Compressibility/datasets/</code>.</p>\n<p>Clone\
    \ the repo but make sure to install or load <code>git-lfs</code> first.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> install/module load git-lfs, needed to download example_data\
    \ for building the container</span>\nsudo dnf install git-lfs <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>Fedora/CentOS Stream 8</span>\nsudo apt-get install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ubuntu</span>\nspack\
    \ install git-lfs<span class=\"pl-k\">;</span> spack load git-lfs <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> clone this repository</span>\ngit clone https://github.com/FTHPC/Correlation_Compressibility\
    \ <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility</pre></div>\n\
    <p>If you forgot to install <code>git-lfs</code> before and have an empty file\
    \ in the  <code>datasets</code> folder, you should install <code>git-lfs</code>\n\
    and then run the following:</p>\n<pre><code>git lfs fetch\ngit lfs checkout\n\
    </code></pre>\n<p>Once Spack is installed, there is a <code>spack.yaml</code>\
    \ configuration file containing the Spack environment necessary to run the program.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">$HOME</span>\ngit clone --depth=1 https://github.com/spack/spack\n\
    git clone --depth=1 https://github.com/robertu94/spack_packages \n<span class=\"\
    pl-c1\">source</span> ./spack/share/spack/setup-env.sh \nspack compiler find\n\
    spack external find \nspack repo add --scope=site ./spack_packages \n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ \nspack env activate <span class=\"pl-c1\">.</span>\nspack install\n<span class=\"\
    pl-k\">export</span> COMPRESS_HOME=<span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ </pre></div>\n<p>These commands will install the environment. The environment\
    \ only needs to be installed once.\nIf you are using an older &lt; gcc11, then\
    \ you will need to add the following to the <code>spack.yaml</code> file:</p>\n\
    <pre><code>^libstdcompat+boost\n</code></pre>\n<p>after <code>^mgard@robertu94+cuda</code>\
    \ but before the <code>,</code>.</p>\n<h3><a id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To run the\
    \ training and prediction timing analysis demonstration</h3>\n<p>In order to run\
    \ the timing analysis, a dataset must be specified.\nThere are two datasets setup\
    \ within this demonstration.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh runtime_analysis/runtime.sh -d [DATASET]</pre></div>\n<p>[DATASET] can\
    \ be either [NYX] or [SCALE]</p>\n<p>After running the above script, an *.RData\
    \ file(s) will be produced giving the approprirate timing information of\nthe\
    \ training and prediction for the regression models.</p>\n<p>Note: A quicker and\
    \ more efficient quantized entropy method is demonstrated in <code>qentropy.cc</code></p>\n\
    <h4><a id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-following-below-runs-qentropycc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The following below runs <code>qentropy.cc</code>\n\
    </h4>\n<div class=\"highlight highlight-source-shell\"><pre>g++ -std=c++2a -O3\
    \ qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy</pre></div>\n\
    <p>Note: Please run the runtime analysis for both datasets before running the\
    \ following section.</p>\n<h3><a id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication\
    \ of figures: how to run statistical prediction of compression ratios and the\
    \ prediction validation</h3>\n<p>The script <code>graphs_paper_container.R</code>\
    \  saves the graphs presented in the paper and provides associated validation\
    \ metrics (correlation and median absolute error percentage).</p>\n<p>The script\
    \ <code>graphs_paper_container.R</code> will source the scripts  <code>load_dataset_paper.R</code>\
    \ and <code>functions_paper.R</code> that respectively load the dataset of interest\
    \ and perform the regression analysis (training and prediction in cross-validation).\n\
    As a consequence the scripts  <code>load_dataset_paper.R</code> and <code>functions_paper.R</code>\
    \ do not need to be run by the user.</p>\n<p>The script <code>graphs_paper_container.R</code>\
    \  is run via the command:\n<code>bash sh replicate.sh</code></p>\n<p>From running\
    \ the script once, it will save all Figures 1, 3, 4 and 5 into .png files from\
    \ the paper as well as corresponding validation metrics.\nFigure 2 is not saved\
    \ as it provides a simple vizualization of slices of the datasets.\nSlices of\
    \ the datasets are generated in the Section \"How to compute statistical predictors\
    \ and compression metrics\" and can be stored, however we do not save them here\
    \ to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in\
    \ the R console.\nAll printed validation metrics are save into a file named <code>figure_replication.log</code>.\n\
    Figures and the log-file are saved in the same folder as the one where R script\
    \ is run and the filename structure is <code>figY_*.png</code> with Y is the figure\
    \ number reference in the paper and <code>*</code> provides additional informnation\
    \ about the data and the compressor.<br>\nNumbers for Table 4 are saved in the\
    \ last section in .txt files <code>statistic_benchmark_runtime_X.txt</code> with\
    \ X the studied dataset (NYX or SCALE).</p>\n<p>In order to limit the container\
    \ size to aid reproducibility, we only added a restricted number of scientific\
    \ datasets in the container and we rely on csv files from our production runs\
    \ (saved as described above in the Section \"How to compute statistical predictors\
    \ on datasets\").\nMore datasets are available on <a href=\"https://sdrbench.github.io\"\
    \ rel=\"nofollow\">SDRBench</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1675473427.0
JeffersonLab/epsci-containers:
  data_format: 2
  description: Container recipes used or maintained by EPSCI group
  filenames:
  - geant4/spack.yaml
  full_name: JeffersonLab/epsci-containers
  latest_release: null
  readme: ''
  stargazers_count: 1
  subscribers_count: 10
  topics: []
  updated_at: 1679432879.0
JuliaParallel/MPI.jl:
  data_format: 2
  description: MPI wrappers for Julia
  filenames:
  - .ci/mvapich/spack.yaml
  full_name: JuliaParallel/MPI.jl
  latest_release: v0.20.8
  readme: '<h1><a id="user-content-mpi-interface-for-the-julia-language" class="anchor"
    aria-hidden="true" href="#mpi-interface-for-the-julia-language"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>MPI interface for the Julia language</h1>

    <p><a href="https://juliaparallel.github.io/MPI.jl/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667"
    alt="Docs latest" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667"
    alt="Docs stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml"><img
    src="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml/badge.svg"
    alt="Unit Tests" style="max-width: 100%;"></a>

    <a href="https://buildkite.com/julialang/mpi-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/87debbd756a8b45df7ac1f25dc034436051f7ccfe155df49f1ec1f6209e51caf/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65643831336263346437396635353761646264623832316231633863386465393839393936383665363937646634613337332e7376673f6272616e63683d6d6173746572"
    alt="GPU tests" data-canonical-src="https://badge.buildkite.com/ed813bc4d79f557adbdb821b1c8c8de98999686e697df4a373.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00ad86424fd334dccd9dde2876e4f3e82b84ad4219e5c1661d6a06b63f46f516/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f4d50492e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572"
    alt="codecov.io" data-canonical-src="https://codecov.io/github/JuliaParallel/MPI.jl/coverage.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://coveralls.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/4d989c928ad758732dcf79e5d1a0b592a1765763c2237af784955ed806e37ef1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f4d50492e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaParallel/MPI.jl/badge.svg?branch=master&amp;service=github"
    style="max-width: 100%;"></a></p>

    <p>This provides <a href="http://julialang.org/" rel="nofollow">Julia</a> interface
    to the Message Passing Interface (<a href="http://www.mpi-forum.org/" rel="nofollow">MPI</a>),
    roughly inspired by <a href="https://github.com/mpi4py/mpi4py/">mpi4py</a>.</p>

    <p>Please see the <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow">documentation</a>
    for instructions on <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/"
    rel="nofollow">configuration</a> and <a href="https://juliaparallel.github.io/MPI.jl/stable/usage/"
    rel="nofollow">usage</a>.</p>

    <p><strong>Breaking changes with v0.20:</strong> The way how MPI.jl is configured
    to use

    different MPI implementations has changed from v0.19 to v0.20 in a

    <em>non-backward-compatible</em> manner.

    Specifically, most <code>JULIA_MPI_XXX</code> variables do not have an effect
    anymore.

    Please refer to the

    <a href="https://juliaparallel.org/MPI.jl/stable/configuration/#Migration-from-MPI.jl-v0.19-or-earlier"
    rel="nofollow">docs</a>

    for information on how to migrate your existing configuration.</p>

    <h1><a id="user-content-help-and-discussion" class="anchor" aria-hidden="true"
    href="#help-and-discussion"><span aria-hidden="true" class="octicon octicon-link"></span></a>Help
    and discussion</h1>

    <p>For help and discussion, we suggest asking on the following venues:</p>

    <ul>

    <li><a href="https://discourse.julialang.org/c/domain/parallel/34" rel="nofollow">"Julia
    at Scale" topic on the Julia Discourse</a></li>

    <li>#distributed channel on the <a href="https://julialang.slack.com/" rel="nofollow">Julia
    Slack</a> (visit <a href="https://julialang.org/slack/" rel="nofollow">https://julialang.org/slack/</a>
    to join).</li>

    </ul>

    <h1><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h1>

    <p>Contributions are encouraged. In particular, MPI provides several hundred functions,
    only a small number of which are currently exposed. If there are additional functions
    you would like to use, please open an <a href="https://github.com/JuliaParallel/MPI.jl/issues">issue</a>
    or <a href="https://github.com/JuliaParallel/MPI.jl/pulls">pull request</a>.</p>

    <p>Additional examples and documentation improvements are also very welcome.</p>

    <h1><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citation</h1>

    <p>If you use MPI.jl in your work, please cite the following paper:</p>

    <blockquote>

    <p>Simon Byrne, Lucas C. Wilcox, and Valentin Churavy (2021) "MPI.jl: Julia bindings
    for the Message Passing Interface". <em>JuliaCon Proceedings</em>, 1(1), 68, doi:
    <a href="https://doi.org/10.21105/jcon.00068" rel="nofollow">10.21105/jcon.00068</a></p>

    </blockquote>

    '
  stargazers_count: 319
  subscribers_count: 21
  topics:
  - mpi
  - julia
  - hpc
  - julia-language
  - mpich
  - openmpi
  - microsoft-mpi
  updated_at: 1680005017.0
L-LYR/playground:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: L-LYR/playground
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676371970.0
LLNL/Umpire:
  data_format: 2
  description: An application-focused API for memory management on NUMA & GPU architectures
  filenames:
  - .spack_env/llnl/spack.yaml
  - .spack_env/darwin/spack.yaml
  full_name: LLNL/Umpire
  latest_release: v2022.10.0
  readme: '<h1><a id="user-content---umpire-v2022100" class="anchor" aria-hidden="true"
    href="#--umpire-v2022100"><span aria-hidden="true" class="octicon octicon-link"></span></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/81bd6212d0dd884f5a1d99f54f5b792596f42ad2d6643791a885b7ff42aad41e/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"><img
    src="https://camo.githubusercontent.com/81bd6212d0dd884f5a1d99f54f5b792596f42ad2d6643791a885b7ff42aad41e/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"
    width="128" valign="middle" alt="Umpire" data-canonical-src="https://cdn.rawgit.com/LLNL/Umpire/develop/share/umpire/logo/umpire-logo.png"
    style="max-width: 100%;"></a>  Umpire v2022.10.0</h1>

    <p><a href="https://travis-ci.com/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/36f0f474aacbade149e980682a28b1b97aa3ea7737006edce896fa4ebbc9ffa7/68747470733a2f2f7472617669732d63692e636f6d2f4c4c4e4c2f556d706972652e7376673f6272616e63683d646576656c6f70"
    alt="Travis Build Status" data-canonical-src="https://travis-ci.com/LLNL/Umpire.svg?branch=develop"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/davidbeckingsale/Umpire/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/615ebc663bd8e7bce0a236693071d360c1f3d4b04bfabb454ba50068b0bac3c0/68747470733a2f2f6465762e617a7572652e636f6d2f64617669646265636b696e6773616c652f556d706972652f5f617069732f6275696c642f7374617475732f4c4c4e4c2e556d706972653f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/davidbeckingsale/Umpire/_apis/build/status/LLNL.Umpire?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://umpire.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/7fd7eef5a102528cae391ff45e9ae1026690d979c1413498b1604b23febeffaf/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756d706972652f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/umpire/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/d567cb288d0416a63a2faa83e8b2d5265860c1a3e9af604f4b6730340fa830c7/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f556d706972652f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/Umpire/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a> <a href="https://gitter.im/LLNL/Umpire?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/d812b594e8c008b20bc4b4e508035cb3ffd814a168debe18107da92e6c7e5f88/68747470733a2f2f6261646765732e6769747465722e696d2f4c4c4e4c2f556d706972652e737667"
    alt="Join the chat at https://gitter.im/LLNL/Umpire" data-canonical-src="https://badges.gitter.im/LLNL/Umpire.svg"
    style="max-width: 100%;"></a></p>

    <p>Umpire is a resource management library that allows the discovery, provision,

    and management of memory on machines with multiple memory devices like NUMA and
    GPUs.</p>

    <p>Umpire uses CMake and BLT to handle builds. Since BLT is included as a

    submodule, first make sure you run:</p>

    <pre><code>$ git submodule init &amp;&amp; git submodule update

    </code></pre>

    <p>Then, make sure that you have a modern compiler loaded, and the configuration
    is as

    simple as:</p>

    <pre><code>$ mkdir build &amp;&amp; cd build

    $ cmake ..

    </code></pre>

    <p>CMake will provide output about which compiler is being used. Once CMake has

    completed, Umpire can be built with Make:</p>

    <pre><code>$ make

    </code></pre>

    <p>For more advanced configuration you can use standard CMake variables.</p>

    <h1><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>Both user and code documentation is available <a href="http://umpire.readthedocs.io/"
    rel="nofollow">here</a>.</p>

    <p>The Umpire <a href="https://umpire.readthedocs.io/en/develop/sphinx/tutorial.html"
    rel="nofollow">tutorial</a> provides a step by step introduction to Umpire features.</p>

    <p>If you have build problems, we have comprehensive <a href="https://umpire.readthedocs.io/en/develop/sphinx/advanced_configuration.html"
    rel="nofollow">build system documentation</a> too!</p>

    <h1><a id="user-content-getting-involved" class="anchor" aria-hidden="true" href="#getting-involved"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Involved</h1>

    <p>Umpire is an open-source project, and we welcome contributions from the community.</p>

    <h2><a id="user-content-mailing-list" class="anchor" aria-hidden="true" href="#mailing-list"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Mailing List</h2>

    <p>The Umpire mailing list is hosted on Google Groups, and is a great place to
    ask questions:</p>

    <ul>

    <li><a href="https://groups.google.com/forum/#!forum/umpire-users" rel="nofollow">Umpire
    Users Google Group</a></li>

    </ul>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" href="#contributions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits; it''s all great!</p>

    <p>To contribute, make a <a href="https://github.com/LLNL/Umpire/compare">pull
    request</a>, with <code>develop</code> as the destination branch.

    We use Travis to run CI tests, and your branch must pass these tests before being
    merged.</p>

    <p>For more information, see the <a href="https://github.com/LLNL/Umpire/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h1><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h1>

    <p>Thanks to all of Umpire''s

    <a href="https://github.com/LLNL/Umpire/graphs/contributors">contributors</a>.</p>

    <p>Umpire was created by David Beckingsale (<a href="mailto:david@llnl.gov">david@llnl.gov</a>).</p>

    <h2><a id="user-content-citing-umpire" class="anchor" aria-hidden="true" href="#citing-umpire"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citing Umpire</h2>

    <p>If you are referencing Umpire in a publication, please use the following citation:</p>

    <ul>

    <li>D. Beckingsale, M. Mcfadden, J. Dahm, R. Pankajakshan and R. Hornung, <a href="https://ieeexplore.ieee.org/document/8907404"
    rel="nofollow">"Umpire: Application-Focused Management and Coordination of Complex
    Hierarchical Memory,"</a> in IBM Journal of Research and Development. 2019. doi:
    10.1147/JRD.2019.2954403</li>

    </ul>

    <h1><a id="user-content-release" class="anchor" aria-hidden="true" href="#release"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Release</h1>

    <p>Umpire is released under an MIT license. For more details, please see the

    <a href="./LICENSE">LICENSE</a> and <a href="./RELEASE">RELEASE</a> files.</p>

    <p><code>LLNL-CODE-747640</code>

    <code>OCEC-18-031</code></p>

    '
  stargazers_count: 249
  subscribers_count: 16
  topics:
  - hpc
  - memory-management
  - gpu
  - blt
  - portability
  - radiuss
  - cpp
  updated_at: 1679927463.0
LLNL/uberenv:
  data_format: 2
  description: Automates using spack to build and deploy software
  filenames:
  - .ci/test-project/spack_configs/linux_ubuntu_22/spack.yaml
  - .ci/test-project/spack_configs/darwin/spack.yaml
  - .ci/test-project/spack_configs/toss_3_x86_64_ib/spack.yaml
  full_name: LLNL/uberenv
  latest_release: v1.0.0
  readme: '<h1><a id="user-content-uberenv" class="anchor" aria-hidden="true" href="#uberenv"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>uberenv</h1>

    <p>Automates using a package manager to build and deploy software.</p>

    <p><a href="https://uberenv.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/02247bd3961daeb4d17d6d1d8f821df0c991efeb0c5f0411fed0a94bd9fa3ebe/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f75626572656e762f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/uberenv/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Uberenv is a python script that helps automate building

    third-party dependencies for development and deployment.</p>

    <p>Uberenv uses Spack (<a href="https://www.spack.io/" rel="nofollow">https://www.spack.io/</a>)
    on Unix-based systems (e.g. Linux and macOS)

    and Vcpkg (<a href="https://github.com/microsoft/vcpkg">https://github.com/microsoft/vcpkg</a>)
    on Windows systems.</p>

    <p>Uberenv was released as part of the Conduit project (<a href="https://github.com/LLNL/conduit/">https://github.com/LLNL/conduit/</a>).

    It is included in-source in several projects, this repo is used to hold the latest
    reference version.</p>

    <p>For more details, see Uberenv''s documention:</p>

    <p><a href="https://uberenv.readthedocs.io" rel="nofollow">https://uberenv.readthedocs.io</a></p>

    <p>You can also find details about how it is used in Conduit''s documentation:</p>

    <p><a href="https://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies"
    rel="nofollow">https://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies</a></p>

    <p>Conduit''s source repo also serves as an example for uberenv and spack configuration
    files, etc:</p>

    <p><a href="https://github.com/LLNL/conduit/tree/master/scripts/uberenv">https://github.com/LLNL/conduit/tree/master/scripts/uberenv</a></p>

    '
  stargazers_count: 20
  subscribers_count: 9
  topics:
  - shell
  - build-tools
  updated_at: 1676463765.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 22.08/0.19.0/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-for-lumi" class="anchor"
    aria-hidden="true" href="#spack-configuration-files-for-lumi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Spack configuration files for LUMI</h1>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 12
  topics: []
  updated_at: 1675956191.0
MeteoSwiss/fdb-fortran:
  data_format: 2
  description: Fortran Interface to ECMWF's FDB
  filenames:
  - docker/spack.yaml
  full_name: MeteoSwiss/fdb-fortran
  latest_release: null
  stargazers_count: 0
  subscribers_count: 4
  topics:
  - numericalweatherpredictions
  updated_at: 1678447894.0
MuonColliderSoft/mucoll-spack:
  data_format: 2
  description: Muon Collider software repository for Spack
  filenames:
  - environments/mucoll-common/spack.yaml
  - environments/mucoll-release/spack.yaml
  full_name: MuonColliderSoft/mucoll-spack
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-package-repository-for-muon-collider-software-stack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#spack-package-repository-for-muon-collider-software-stack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n<a href=\"\
    https://github.com/spack/spack\">Spack</a> package repository for Muon Collider\
    \ software stack</h1>\n<p>This repository holds a set of Spack recipes for Muon\
    \ Collider software (under namespace <code>mucoll</code>) based on <a href=\"\
    https://key4hep.github.io/key4hep-doc/\" rel=\"nofollow\">Key4hep</a> stack. It\
    \ extends the corresponding <a href=\"https://github.com/key4hep/key4hep-spack\"\
    >key4hep-stack</a> repository, which is required for installation, overriding\
    \ several packages by the ones customised for Muon Collider simulation studies.</p>\n\
    <p>After installing <a href=\"https://github.com/key4hep/spack\">Spack</a> and\
    \ downloading the <a href=\"https://github.com/key4hep/key4hep-spack\">key4hep-spack</a>\
    \ and <a href=\"https://github.com/MuonColliderSoft/mucoll-spack\">mucoll-spack</a>\
    \ repositories, the whole software stack can be installed using the following\
    \ commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Add repositories</span>\nspack repo add ./key4hep-spack\n\
    spack repo add ./mucoll-spack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a Spack environment</span>\nspack env create sim\nspack env activate\
    \ sim\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy package configurations</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Install the software stack</span>\nspack add mucoll-stack\nspack\
    \ concretize --reuse\nspack install --fail-fast\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Load the Muon Collider environment</span>\n<span class=\"\
    pl-c1\">source</span> <span class=\"pl-smi\">$MUCOLL_STACK</span></pre></div>\n\
    <h2><a id=\"user-content-setting-up-the-environment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setting-up-the-environment\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Setting up the environment</h2>\n<p>When signing\
    \ in to a machine with the installed sofware stack (VM or Docker container), it\
    \ has to be loaded into the environment:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate sim\n<span class=\"pl-c1\">source</span> <span class=\"\
    pl-smi\">$MUCOLL_STACK</span></pre></div>\n<h2><a id=\"user-content-package-versioning\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#package-versioning\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Package versioning</h2>\n<p>Preferred\
    \ convention for version names in Spack is numbers separated by dots, without\
    \ leading zeros, e.g. <code>1.2.13</code>.\nConversion to tag names in <code>mucoll</code>\
    \ packages is provided by <code>MCIlcsoftpackage</code> class defined in <code>packages/mucoll-stack/mucoll_utils.py</code>,\
    \ e.g. for <a href=\"https://github.com/MuonColliderSoft/lcgeo/releases/tag/v00-17-MC\"\
    ><code>lcgeo</code></a> package version <code>0.17</code> corresponds to tag name\
    \ <code>v00-17-MC</code>.</p>\n<h2><a id=\"user-content-adding-new-versions-for-individual-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-versions-for-individual-packages\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new\
    \ versions for individual packages</h2>\n<p>After a new tag for the package is\
    \ created, e.g. <code>v00-17-MC</code> in <code>lcgeo</code> repository, it can\
    \ be added to this Spack repository in two steps:</p>\n<ol>\n<li>Get the archive\
    \ checksum for the new tag</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack checksum lcgeo 0.17\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Validates archive URL and returns the checksum</span>\n    version(<span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>0.17<span class=\"pl-pds\">'</span></span>,\
    \ sha256=<span class=\"pl-s\"><span class=\"pl-pds\">'</span>5ab33aaf5bc37deba82c2dde78cdce6c0041257222ed7ea052ecdd388a41cf9b<span\
    \ class=\"pl-pds\">'</span></span>)</pre></div>\n<ol start=\"2\">\n<li>Add the\
    \ returned version definition to the corresponding package file: <a href=\"packages/lcgeo/package.py\"\
    ><code>packages/lcgeo/package.py</code></a>\n</li>\n</ol>\n<blockquote>\n<p>NOTE:\
    \ This repository only contains packages maintained by the Muon Collider collaboration.\n\
    If the version of interest is missing from Spack for some other package, the line\
    \ with a new version definition should be added to the package file in the corresponding\
    \ repository.<br>\nTo see locations of other repositories: <code>spack repo list</code></p>\n\
    </blockquote>\n<h2><a id=\"user-content-creating-a-new-stack-release\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#creating-a-new-stack-release\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Creating a new stack release</h2>\n\
    <p>To introduce a new release version for the whole software stack, update the\
    \ version number in <a href=\"packages/mucoll-stack/package.py\"><code>packages/mucoll-stack/package.py</code></a>\
    \ and then update versions of all the relevant packages in [environments/mucoll-release/packages.yaml].<br>\n\
    Test this new configuration in a fresh environment:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a development environment</span>\nspack env create dev\nspack env activate\
    \ dev\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy the package configuration</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Add stack with updated version to the environment</span>\nspack\
    \ add mucoll-stack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Check\
    \ which packages would be installed</span>\nspack spec --reuse -NIt</pre></div>\n\
    <p>Packages that are already installed in the <code>sim</code> environment are\
    \ known to Spack and will be reused, providing a clear indication of which part\
    \ of the dependency tree will be modified by the new release.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1679435634.0
NCAR/spack-casper:
  data_format: 2
  description: Spack production user software stack on the Casper system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-casper
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>casper</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Wed Mar 22 21:50:19 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fc3df9ab78502b74368eb656923301f672d491f6</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.03</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/casper/23.03</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/casper/23.03/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 0
  subscribers_count: 8
  topics: []
  updated_at: 1679548145.0
NCAR/spack-derecho:
  data_format: 2
  description: Spack production user software stack on the Derecho system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-derecho
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>derecho</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Mon Mar 27 17:05:43 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>faceed4d8058f0f9d5ef385ab0eebb77a9a77c67</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.03</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/derecho/23.03</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/derecho/scratch/csgteam/spack-deployments/derecho/23.03/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679963542.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Wed Mar 22 08:26:39 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fc3df9ab78502b74368eb656923301f672d491f6</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.03</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/23.03</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/23.03/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 3
  subscribers_count: 13
  topics: []
  updated_at: 1680620000.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-22.11/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/cce/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cce/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/cce/spack.yaml
  - spack-configs/perlmutter-user-spack/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/gcc/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file. The documentation is available at\
    \ <a href=\"https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <h2><a id=\"user-content-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-configuration\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Configuration</h2>\n<p>The spack configuration\
    \ can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<h2><a id=\"user-content-running-ci-pipelines\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-ci-pipelines\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>. Please make sure you\
    \ login to the appropriate hostname when starting the gitlab runner.</p>\n<table>\n\
    <thead>\n<tr>\n<th>System</th>\n<th>Runner Name</th>\n<th>Hostname</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n\
    <td><code>login27</code></td>\n</tr>\n<tr>\n<td>cori</td>\n<td><code>cori-e4s</code></td>\n\
    <td><code>cori02</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    <td><code>login02</code></td>\n</tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n\
    <td><code>gert01</code></td>\n</tr>\n</tbody>\n</table>\n<p>The runner configuration\
    \ files are located in <code>~/.gitlab-runner</code> for user <strong>e4s</strong>.</p>\n\
    <p>The production pipelines are triggered via web-interface which requires approval\
    \ from a project maintainer. Production pipelines should be run when we need to\
    \ do full redeployment of stack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#current-challenges\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have external packages set for packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li><strong>Erik Palmer (<a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>)</strong></li>\n\
    <li><strong>Justin Cook (<a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 8
  subscribers_count: 14
  topics: []
  updated_at: 1673545287.0
NOAA-EMC/NCEPLIBS-grib_util:
  data_format: 2
  description: This is a collection of NCEP GRIB related utilities.
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/NCEPLIBS-grib_util
  latest_release: v1.2.4
  readme: '<h1><a id="user-content-nceplibs-grib_util" class="anchor" aria-hidden="true"
    href="#nceplibs-grib_util"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCEPLIBS-grib_util</h1>

    <p>This is a collection of NCEP GRIB related utilities. This is related

    to the <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> project.</p>

    <p>For complete documentation see

    <a href="https://noaa-emc.github.io/NCEPLIBS-grib_util/" rel="nofollow">https://noaa-emc.github.io/NCEPLIBS-grib_util/</a>.
    For the NCEP WMO GRIB2

    Documentation see

    <a href="https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/" rel="nofollow">https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/</a>.</p>

    <h2><a id="user-content-related-nceplibs-projects" class="anchor" aria-hidden="true"
    href="#related-nceplibs-projects"><span aria-hidden="true" class="octicon octicon-link"></span></a>Related
    NCEPLIBS Projects</h2>

    <table>

    <thead>

    <tr>

    <th>Repository</th>

    <th>Notes</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2c">NCEPLIBS-g2c</a></td>

    <td>C implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></td>

    <td>Fortran implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></td>

    <td>Utilities for GRIB2 templates</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <table>

    <thead>

    <tr>

    <th>Utility</th>

    <th>Author(s)</th>

    <th>User(s)</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>cnvgrib</td>

    <td>Stephen Gilbert, Gordon, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>copygb</td>

    <td>Mark Iredell, Stephen Gilbert, Trojan, Boi Vuong</td>

    <td>UFS_UTILS</td>

    </tr>

    <tr>

    <td>copygb2</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>degrib2</td>

    <td>Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grb2index</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grbindex</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong, W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    <tr>

    <td>tocgrib</td>

    <td>Stephen Gilbert, Boi Vuong, Farley, R. E. Jones</td>

    <td>RAP for FAA</td>

    </tr>

    <tr>

    <td>tocgrib2</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>tocgrib2super</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>wgrib</td>

    <td>W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    </tbody>

    </table>

    <p>Code Manager : Hang Lei, Edward Hartnett</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This package requires the following third party libraries:</p>

    <ul>

    <li><a href="http://www.ece.uvic.ca/~mdadams/jasper/" rel="nofollow">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="http://www.gzip.org/zlib/" rel="nofollow">libz</a></li>

    </ul>

    <p>This package requires the folling NCEPLIBS libraries:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a> (before
    version 1.3.0)</li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a> (starting
    version 1.3.0)</li>

    </ul>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <pre><code>mkdir build

    cd build

    cmake -DCMAKE_INSTALL_PREFIX=/path/to/install -DCMAKE_PREFIX_PATH=/path/to/dependencies
    ..

    make -j4

    make install

    </code></pre>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 7
  subscribers_count: 3
  topics: []
  updated_at: 1680626680.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: upp-srw-v2.1.0
  readme: '<h1><a id="user-content-unified-post-processing-upp" class="anchor" aria-hidden="true"
    href="#unified-post-processing-upp"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unified
    Post-Processing (UPP)</h1>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecasting System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Application

    Forecasting System (HAFS), and the Medium Range Weather (MRW) and Short

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model

    derived brightness temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages, or for

    further downstream post-processing, e.g. statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <h2><a id="user-content-user-support" class="anchor" aria-hidden="true" href="#user-support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>User Support</h2>

    <p>Support for the UFS UPP is provided through <a href="https://github.com/NOAA-EMC/UPP/discussions">GitHub
    Discussions</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>User Guide for latest public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <h2><a id="user-content-developer-information" class="anchor" aria-hidden="true"
    href="#developer-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>Developer
    Information</h2>

    <p>Please see review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Kate Fossell</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>The UPP requires certain NCEPLIB packages to be installed via

    the HPC-Stack project.</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-gfsio">NCEPLIBS-gfsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">libz</a></li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for Regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 25
  subscribers_count: 16
  topics: []
  updated_at: 1680455964.0
NOAA-EMC/WW3:
  data_format: 2
  description: WAVEWATCH III
  filenames:
  - model/ci/spack_intel.yaml
  - model/ci/spack_gnu.yaml
  full_name: NOAA-EMC/WW3
  latest_release: 6.07.1
  readme: "<h1><a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2><a id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#general-features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 195
  subscribers_count: 46
  topics: []
  updated_at: 1681150114.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/ufs-weather-model/spack.yaml
  - configs/templates/skylab-dev/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/empty/spack.yaml
  - configs/templates/skylab-no-python-dev/spack.yaml
  - configs/templates/ufs-weather-model-static/spack.yaml
  - configs/templates/unified-dev/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: 1.3.0
  readme: '<h1><a id="user-content-spack-stack" class="anchor" aria-hidden="true"
    href="#spack-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>Spack-stack enables the installation of software required

    for HPC system deployments of NOAA''s Unified Forecast System (UFS) and

    other weather and climate models, including components of the Joint

    Effort for Data assimilation Integration (JEDI).</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>.</li>

    </ul>

    <p>Spack-stack is a thin layer around a fork of the

    <a href="https://github.com/spack/spack">spack</a> repository. Spack is a

    community-supported, multi-platform, Python-based package manager

    originally developed by the Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about spack see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for

    spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack

    documentation</a>.</p>

    <p>The stack can be installed on a range of platforms, from Linux and

    macOS laptops to HPC systems, and comes pre-configured for many

    systems. Users can install the necessary packages for a particular

    application and later add the missing packages for another application

    without having to rebuild the entire stack.</p>

    <p>spack-stack is mainly a collection of Spack configuration files, but

    provides a Spack extension to simplify the installation process:</p>

    <ul>

    <li>

    <p><code>spack stack create</code> is provided to copy common, site-specific,
    and

    application-specific configuration files into a coherent Spack

    environment and to create container recipes</p>

    </li>

    <li>

    <p><code>spack stack setup-meta-modules</code> creates compiler, MPI and Python

    meta-modules for a convenient setup of a user environment using

    modules (lua and tcl)</p>

    </li>

    </ul>

    <p>Documentation for installing and using spack-stack can be found here:

    <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a></p>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>

    <p><a href="https://www.github.com/AlexanderRichert-NOAA">Alex Richert</a>, <a
    href="https://www.github.com/Hang-Lei-NOAA">Hang

    Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed

    Hartnett</a> NOAA-EMC</p>

    </li>

    <li>

    <p><a href="https://www.github.com/climbfuji">Dom Heinzeller</a>, JCSDA</p>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 16
  subscribers_count: 7
  topics: []
  updated_at: 1680703509.0
NOAA-GFDL/HPC-ME:
  data_format: 2
  description: null
  filenames:
  - spack_gnu.yaml
  full_name: NOAA-GFDL/HPC-ME
  latest_release: null
  readme: '<h1><a id="user-content-hpc-me-hpc-portable-containers-for-model-environments"
    class="anchor" aria-hidden="true" href="#hpc-me-hpc-portable-containers-for-model-environments"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPC-ME: HPC Portable
    Containers for Model Environments</h1>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contents</h2>

    <ul>

    <li><a href="#what-is-hpc-me">What is HPC-ME</a></li>

    <li><a href="#list-of-current-compilers">List of current compilers/MPI/OS</a></li>

    <li><a href="#list-of-current-libraries">List of current libraries</a></li>

    <li><a href="#how-to-build">How to build</a></li>

    <li><a href="#how-to-use">How to use</a></li>

    <li><a href="#gfdl-example">GFDL example</a></li>

    <li><a href="#planned-improvements">Planned improvements</a></li>

    </ul>

    <h2><a id="user-content-what-is-hpc-me" class="anchor" aria-hidden="true" href="#what-is-hpc-me"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>What is HPC-ME</h2>

    <p>HPC Portable Container - Model Environments is a set of Dockerfiles, Singularity
    Definition files, and containers to provide portable model environments for scientific
    applications that require the same set of libraries.  The ultimate goal is to
    have a community-based list of libraries that are needed for compiling, executing,
    and post-processing earth science models.  We all use many of the same underlying
    libraries, and by working together we can agree upon a community-based approach
    to making container usage as standardized as possible.</p>

    <h2><a id="user-content-list-of-current-compilersmpios" class="anchor" aria-hidden="true"
    href="#list-of-current-compilersmpios"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>List of current compilers/MPI/OS</h2>

    <p>For each container, there is a full version that contains the programming environment
    and a smaller runtime environment that can be used to run compiled executables.
    (The runtime container definition files will be added soon.)

    #- <a href="Dockerfile_gnu_ubuntu20.04">gcc 8/mpich/ubuntu 20.04</a></p>

    <ul>

    <li><a href="Dockerfile_gnu_rhel8">gcc 8/mpich/RHEL8</a></li>

    <li>

    <a href="Dockerfile_intel_ubuntu18.04">intel oneAPI 2022.1/mpich(impi)/ubuntu
    18.04</a>

    #- <a href="Dockerfile_intel_centos8">intel oneAPI 2021.4/mpich(impi)/centos 8</a>

    </li>

    </ul>

    <h2><a id="user-content-list-of-current-libraries" class="anchor" aria-hidden="true"
    href="#list-of-current-libraries"><span aria-hidden="true" class="octicon octicon-link"></span></a>List
    of current libraries</h2>

    <p>This is the current list of most of the libraries used in the HPC-ME containers
    (We are trying to keep this up-to-date).

    The complete lit should be found in the respective YAML file.</p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#automake"
    rel="nofollow">automake@1.16.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bacio" rel="nofollow">bacio@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#berkeley-db"
    rel="nofollow">berkeley-db@18.1.40</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bison" rel="nofollow">bison@3.7.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bzip2" rel="nofollow">bzip2@1.0.8</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cmake" rel="nofollow">cmake@3.21.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#crtm" rel="nofollow">crtm@2.3.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#curl" rel="nofollow">curl@7.78.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#diffutils"
    rel="nofollow">diffutils@3.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#esmf" rel="nofollow">esmf@8.1.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#expat" rel="nofollow">expat@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2" rel="nofollow">g2@3.4.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2tmpl"
    rel="nofollow">g2tmpl@1.10.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gdbm" rel="nofollow">gdbm@1.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gsl" rel="nofollow">gsl@2.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#hdf5" rel="nofollow">hdf5@1.10.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#intel-mpi"
    rel="nofollow">intel-mpi@2019.10.317</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip" rel="nofollow">ip@3.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip2" rel="nofollow">ip2@1.1.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#jasper"
    rel="nofollow">jasper@2.0.32</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libbsd"
    rel="nofollow">libbsd@0.11.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libiconv"
    rel="nofollow">libiconv@1.16</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libjpeg-turbo"
    rel="nofollow">libjpeg-turbo@2.1.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libmd" rel="nofollow">libmd@1.0.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libpng"
    rel="nofollow">libpng@1.6.37</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libsigsegv"
    rel="nofollow">libsigsegv@2.13</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libxml2"
    rel="nofollow">libxml2@2.9.12</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libyaml"
    rel="nofollow">libyaml@0.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#m4" rel="nofollow">m4@1.4.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nasm" rel="nofollow">nasm@2.15.05</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ncurses"
    rel="nofollow">ncurses@6.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nemsio"
    rel="nofollow">nemsio@2.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-c"
    rel="nofollow">netcdf-c@4.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-fortran"
    rel="nofollow">netcdf-fortran@4.5.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#numactl"
    rel="nofollow">numactl@2.0.14</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#openssl"
    rel="nofollow">openssl@1.1.1l</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#parallel-netcdf"
    rel="nofollow">parallel-netcdf@1.12.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#perl" rel="nofollow">perl@5.34.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#pkgconf"
    rel="nofollow">pkgconf@1.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#readline"
    rel="nofollow">readline@8.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sfcio" rel="nofollow">sfcio@1.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sigio" rel="nofollow">sigio@2.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sp" rel="nofollow">sp@2.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#udunits"
    rel="nofollow">udunits@2.2.28</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3emc" rel="nofollow">w3emc@2.9.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3nco" rel="nofollow">w3nco@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#wrf-io"
    rel="nofollow">wrf-io@1.2.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xerces-c"
    rel="nofollow">xerces-c@3.2.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xz" rel="nofollow">xz@5.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#zlib" rel="nofollow">zlib@1.2.11</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#lmod" rel="nofollow">lmod@8.5.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nccmp" rel="nofollow">nccmp@1.8.6.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nco" rel="nofollow">nco@4.7.9</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-netcdf"
    rel="nofollow">cray-netcdf@4.6.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-hdf5"
    rel="nofollow">cray-hdf5@1.10.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#uberftp"
    rel="nofollow">uberftp</a></li>

    </ul>

    <h2><a id="user-content-how-to-build" class="anchor" aria-hidden="true" href="#how-to-build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to build</h2>

    <p><strong>We plan to make this step optional soon.</strong> In order to build
    the Docker images, you will need access to a computer with root-like access, and
    either docker or singularity installed. If you do not have root-like access to
    a suitable machine, you can still run images that were already created (e.g. on
    Docker hub), and we plan on hosting runnable Docker images along with the Dockerfiles
    in this repository soon. If you have root-like access and docker, start by choosing
    one of the currently supported model environments from the list above. Then build
    the Docker container from the Dockerfile using docker build; for example, to build
    the gcc8/mpich/ubuntu18 container:</p>

    <pre><code>docker build --file Dockerfile_gnu_ubuntu20.04 . --tag hpc-me.ubuntu.gnu

    </code></pre>

    <p>The build process takes approximately 2-3 hours, as the packages are downloaded
    and compiled using Spack. After a successful build, you will see that the image
    was built and tagged successfully:</p>

    <pre><code>Successfully built 90a878af77b4

    Successfully tagged hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>Then, you may run the container using docker or singularity on the same host.
    To run the image on a different machine, pushing the image to Docker Hub is recommended.
    Note that you will need a DockerHub account to do this (replace USER with your
    Docker user ID in the examples below). For example:</p>

    <pre><code>docker tag hpc-me.rhel8.gnu USER/hpc-me.rhel8.gnu

    docker login

    docker push USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <h2><a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to use</h2>

    <p>We plan to make improvements on this process. Also, while we plan on making
    Docker images available on the GitHub container registry, currently you must build
    the images yourself. Please start with the <a href="#how-to-build">Build instructions</a>
    to generate a Docker image with your desired OS/compiler HPC-ME environment. Then
    you may run the container using docker or singularity; singularity is more likely
    than docker to be available on HPC environments.</p>

    <p>The usage documentation consists of some general notes on serial/parallel usage,
    files inside and outside the container, downloading the containers, and then specific
    usage scenarios:</p>

    <ul>

    <li><a href="#serial-applications-using-docker">Serial applications using docker</a></li>

    <li><a href="#serial-applications-using-singularity">Serial applications using
    singularity</a></li>

    <li><a href="#parallel-applications-using-singularity">Parallel applications using
    singularity</a></li>

    </ul>

    <h3><a id="user-content-serial-and-parallel-usage" class="anchor" aria-hidden="true"
    href="#serial-and-parallel-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    and parallel usage</h3>

    <p>HPC-ME containers are intended for both serial and parallel applications. Serial
    applications include compiling model executables, generating input grids, and
    post-processing model output. Earth system, climate, and weather models require
    parallelism to run efficiently, and use one of the Message Passage Interface (MPI)
    implementations OpenMPI, Intel MPI, or mpich. GCC-based HPC-ME containers use
    the mpich-based MPI library, which is widely available on most HPC sites, and
    the Intel-based containers contain both mpich and Intel MPI.</p>

    <h3><a id="user-content-notes-on-filesystems-and-writing-files" class="anchor"
    aria-hidden="true" href="#notes-on-filesystems-and-writing-files"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Notes on filesystems and writing files</h3>

    <p>We recommend not saving or modifying files within the environment container,
    and instead create and modify files on your regular filesystem. To do this, you
    will need to connect your filesystem to your container using bind mounts.</p>

    <h3><a id="user-content-downloading-containers-and-managing-images-on-the-filesystem"
    class="anchor" aria-hidden="true" href="#downloading-containers-and-managing-images-on-the-filesystem"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Downloading containers
    and managing images on the filesystem</h3>

    <p>Once you have pushed your images to DockerHub, you will need to download them
    before using. In the examples below, replace USER with your Docker Hub ID. If
    using docker,</p>

    <pre><code>docker pull USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity,</p>

    <pre><code>singularity pull docker://USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity, the image file (SIF format) is saved to the current working
    directory</p>

    <pre><code>&gt; ls *.sif

    -rwxr-xr-x 532M Dec 10 16:09 hpc-me.rhel8.gnu_latest.sif*

    </code></pre>

    <p>If using docker, the downloaded image is handled by the central docker service.</p>

    <h3><a id="user-content-serial-applications-using-docker" class="anchor" aria-hidden="true"
    href="#serial-applications-using-docker"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Serial applications using docker</h3>

    <p>You may activate an interactive shell within the desired HPC-ME container using
    docker. After running the container, the compilers and tools available within
    the container will be accessible in your PATH; e.g.</p>

    <pre><code>&gt; docker run -it hpc-me.rhel8.gnu:latest


    [root@0d2cf64e1175 /]# which nf-config

    /opt/view/bin/nf-config


    [root@0d2cf64e1175 /]# nf-config --version

    netCDF-Fortran 4.5.3


    [root@0d2cf64e1175 /]# nf-config --cflags

    -I/opt/software/linux-rhel8-x86_64/gcc-8.4.1/netcdf-fortran-4.5.3-g5qfkdlp36unt2s4j4wyrc6heh2sa64n/include

    </code></pre>

    <h3><a id="user-content-serial-applications-using-singularity" class="anchor"
    aria-hidden="true" href="#serial-applications-using-singularity"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Serial applications using singularity</h3>

    <p>Singularity can run Docker images and is more likely to be available on HPC
    environments. As with docker run, the HPC-ME tools and compilers are available
    in the shell, somewhat similar to loading a set of Environment Modules prepared
    by site administrators.</p>

    <pre><code>&gt;singularity run hpc-me.rhel8.gnu_latest.sif


    Singularity&gt; which nf-config

    /opt/view/bin/nf-config


    Singularity&gt; nf-config --version

    netCDF-Fortran 4.5.3

    </code></pre>

    <h3><a id="user-content-parallel-applications-using-singularity" class="anchor"
    aria-hidden="true" href="#parallel-applications-using-singularity"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Parallel applications using singularity</h3>

    <p>HPC-ME containers can provide the runtime environment for MPI applications.
    For instance, one could compile an MPI application using the instructions above
    using one of the HPC-ME development containers; and then run the application using
    the corresponding runtime HPC-ME container.</p>

    <p>Please note that we are continuing to improve the usability of HPC-ME containers
    as well as provide more usage examples.</p>

    <p>Usually, GFDL climate models are run on gaea by submitting a runscript to the
    Slurm scheduler. The runscript loads needed runtime Environment Modules, prepares
    input directories and files, and executes the MPI executable using srun. The HPC-ME
    containers provide the necessary runtime environment, obviating the need for loading
    Environment Modules. Currently, our approach for using the HPC-ME containers is
    as follows:</p>

    <ol>

    <li>Create a new container, starting with the desired HPC-ME runtime container</li>

    <li>Add the MPI-compiled executable to the container filesystem</li>

    <li>Set the MPI-compiled executable to as the container''s command (so that when
    the container is run the MPI executable within the container runs)</li>

    <li>Run the singularity container SIF file using srun within the runscript, replacing
    the traditional MPI executable.</li>

    </ol>

    <ul>

    <li>Replace "srun executable.x" with "srun singularity run container.SIF"</li>

    <li>Add --mpi=pmi2 to the srun call, which connects the system MPI to the container
    MPI to the singularity run call</li>

    <li>Bind the working directory so that the container has access to the input files
    and can write output files (singularity run -B=/path/to/workdir)</li>

    </ul>

    <ol start="5">

    <li>Submit the modified runscript to the scheduler</li>

    </ol>

    <p>We plan to provide more examples and usage scenarios, such as using the HPC-ME
    containers as-is (i.e. not creating a new container as described above)</p>

    <h2><a id="user-content-gfdl-example" class="anchor" aria-hidden="true" href="#gfdl-example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL example</h2>

    <p>An example of using an HPC-ME container with the GFDL FRE workflow can be found
    <a href="GFDL_EXAMPLE.md">here</a></p>

    <h2><a id="user-content-planned-improvements" class="anchor" aria-hidden="true"
    href="#planned-improvements"><span aria-hidden="true" class="octicon octicon-link"></span></a>Planned
    improvements</h2>

    <p>HPC-ME is a work in progress under active development, so please check back
    or follow the repository for more updates.</p>

    <h3><a id="user-content-build-cache" class="anchor" aria-hidden="true" href="#build-cache"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build cache</h3>

    <p>We are working to create a build cache for the libraries listed so that building
    the containers is quick and easy.</p>

    <h3><a id="user-content-github-container-registry" class="anchor" aria-hidden="true"
    href="#github-container-registry"><span aria-hidden="true" class="octicon octicon-link"></span></a>Github
    container registry</h3>

    <p>We are working to add CI capability to this repository, so that the containers
    will be automatically built and stored in the github container registry. This
    will make building unnecessary for most cases, though users may build the containers
    themselves if they wish (e.g. for custom modifications).</p>

    <h3><a id="user-content-more-usage-examples-and-documentation-especially-for-mpi-applications"
    class="anchor" aria-hidden="true" href="#more-usage-examples-and-documentation-especially-for-mpi-applications"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>More usage examples
    and documentation, especially for MPI applications</h3>

    <p>We are still learning how to best use the HPC-ME containers with MPI appliations,
    so please check back.</p>

    <h3><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h3>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    <p>This project code is made available through GitHub but is managed by NOAA-GFDL

    at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1650907447.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Configuration files for Spack at Pawsey
  filenames:
  - systems/topaz/environment_compchem/spack.yaml
  - systems/setonix/environments/env_num_libs/spack.yaml
  - systems/setonix/environments/env_wrf/spack.yaml
  - systems/setonix/environments/env_astro/spack.yaml
  - systems/setonix/environments/env_s3_clients/spack.yaml
  - systems/setonix/environments/env_devel/spack.yaml
  - systems/setonix/environments/env_python/spack.yaml
  - systems/setonix/environments/env_io_libs/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-pawsey-spack-configuration" class="anchor" aria-hidden="true"
    href="#pawsey-spack-configuration"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pawsey
    Spack Configuration</h1>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_DAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <h3><a id="user-content-singularity" class="anchor" aria-hidden="true" href="#singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h3>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <h3><a id="user-content-software-stack-modulefile" class="anchor" aria-hidden="true"
    href="#software-stack-modulefile"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    stack modulefile</h3>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <h2><a id="user-content-repository-structure" class="anchor" aria-hidden="true"
    href="#repository-structure"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    structure</h2>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <h2><a id="user-content-the-scripts-directory" class="anchor" aria-hidden="true"
    href="#the-scripts-directory"><span aria-hidden="true" class="octicon octicon-link"></span></a>The
    <code>scripts</code> directory</h2>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <h2><a id="user-content-the-systemssystem-directory" class="anchor" aria-hidden="true"
    href="#the-systemssystem-directory"><span aria-hidden="true" class="octicon octicon-link"></span></a>The
    <code>systems/&lt;system&gt;</code> directory</h2>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <h2><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h2>

    <h3><a id="user-content-module-categories-in-use" class="anchor" aria-hidden="true"
    href="#module-categories-in-use"><span aria-hidden="true" class="octicon octicon-link"></span></a>Module
    categories in use</h3>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <h3><a id="user-content-testing-modules" class="anchor" aria-hidden="true" href="#testing-modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Testing Modules</h3>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1641801068.0
RMeli/HPCpp:
  data_format: 2
  description: 'Experiments with C++ for HPC and collection of C++ benchmarks. '
  filenames:
  - cpp/libint-hf/spack.yaml
  full_name: RMeli/HPCpp
  latest_release: null
  readme: '<h1><a id="user-content-hpc-experiments-and-notes-for-high-performance-c"
    class="anchor" aria-hidden="true" href="#hpc-experiments-and-notes-for-high-performance-c"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPC++: Experiments
    and Notes for High-Performance C++</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664828168.0
RMeli/my-spack:
  data_format: 2
  description: Spack environments
  filenames:
  - envs/local/cp2k-dlaf-mkl-mpich/spack.yaml
  - envs/alps/dlaf-mkl-cuda/spack.yaml
  - envs/local/dlaf-mkl-mpich/spack.yaml
  - envs/alps/cp2k-dlaf-cpu/spack.yaml
  - envs/local/cp2k/spack.yaml
  full_name: RMeli/my-spack
  latest_release: null
  readme: '<h1><a id="user-content-my-spack" class="anchor" aria-hidden="true" href="#my-spack"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>My Spack</h1>

    <p>Spack-related stuff for @RMeli.</p>

    <h2><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    href="#package-repository"><span aria-hidden="true" class="octicon octicon-link"></span></a>Package
    Repository</h2>

    <p><a href="https://spack.readthedocs.io/en/latest/repositories.html" rel="nofollow">Spack
    Package Repositories</a></p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679671251.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.18.1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#rhel7-spack-config\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#useful-commands\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack\
    \ module lmod refresh\n</code></pre>\n<h2><a id=\"user-content-installing-new-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-new-packages\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new\
    \ packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack\
    \ package updates could result in additional installation of packages with little\
    \ or no package source code changes.  These additional installs can be avoided\
    \ when installing new packages by first examining the output of the <code>spack\
    \ spec -I</code> command.  If a utility/infrastructure level package, such as\
    \ cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column\
    \ then it means that the existing install will be used.  If spack does not default\
    \ to using the existing install you can append the hash of the package to the\
    \ spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi\
    \ install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\n\
    Input spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\n\
    Concretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo\
    \ ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]     \
    \ ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64\
    \ \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64\
    \ \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]  \
    \        ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]  \
    \            ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643231013.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/runner/rhel8-x86_64/spack.yaml
  - docker-recipes/runner/rhel8-aarch64/spack.yaml
  - docker-recipes/runner/ubuntu22.04-aarch64/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64/spack.yaml
  - docker-recipes/runner/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/_archived/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64-oneapi/spack.yaml
  - docker-recipes/runner/ubuntu20.04-aarch64/spack.yaml
  - docker-recipes/runner/_archived/ubuntu18.04-x86_64/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 20
  subscribers_count: 6
  topics: []
  updated_at: 1673374590.0
actions-marketplace-validations/haampie-spack_setup-spack:
  data_format: 2
  description: null
  filenames:
  - example-environment/spack.yaml
  full_name: actions-marketplace-validations/haampie-spack_setup-spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1669840356.0
acwen11/cactusamrex_copy:
  data_format: 2
  description: null
  filenames:
  - utils/Docker/cpu/make-image/spack.yaml
  - utils/Docker/gpu/make-image-gpu/spack.yaml
  full_name: acwen11/cactusamrex_copy
  latest_release: null
  readme: '<h1><a id="user-content-cactusamrex" class="anchor" aria-hidden="true"
    href="#cactusamrex"><span aria-hidden="true" class="octicon octicon-link"></span></a><a
    href="https://bitbucket.org/eschnett/cactusamrex" rel="nofollow">CactusAMReX</a></h1>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/carpetx.png"><img
    src="figures/carpetx.png" alt="CarpetX logo" style="max-width: 100%;"></a></p>

    <p><strong>CarpetX</strong> is a <a href="https://cactuscode.org/" rel="nofollow">Cactus</a>
    driver based on <a href="https://amrex-codes.github.io" rel="nofollow">AMReX</a>,
    a software framework for block-structured AMR (adaptive mesh refinement). CarpetX
    is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>.</p>

    <ul>

    <li>

    <a href="https://bitbucket.org/eschnett/cactusamrex" rel="nofollow">Bitbucket</a>:
    Source code repository</li>

    <li>

    <a href="https://dev.azure.com/schnetter/CactusAMReX/_build" rel="nofollow">Azure   Pipelines</a>:
    Build Status <a href="https://dev.azure.com/schnetter/CactusAMReX/_build/latest?definitionId=6&amp;branchName=master"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c376f6da8aa212a12313b10b09f29b30a096a8f4bc59b67c7baf9a5aaa2ad8a1/68747470733a2f2f6465762e617a7572652e636f6d2f7363686e65747465722f436163747573414d5265582f5f617069732f6275696c642f7374617475732f436163747573414d5265582d43493f6272616e63684e616d653d6d6173746572"
    alt="Build Status" data-canonical-src="https://dev.azure.com/schnetter/CactusAMReX/_apis/build/status/CactusAMReX-CI?branchName=master"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>CarpetX is almost ready for production. (The only missing feature is

    checkpointing/recovery.) You are welcome to give it a try, to look at

    what changes your code might need to benefit from CarpetX''s new

    features, and to give us feedback.</p>

    <p>The recorded talk <a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html"
    rel="nofollow">"Using CarpetX: A Guide for Early

    Adopters"</a>.

    This presentation provides an overview of the current capabilities of

    CarpetX and showcases how to write Cactus code using it.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>Here are instructions for downloading the Einstein Toolkit including

    CarpetX, building, and running an example.</p>

    <h3><a id="user-content-download-and-setup" class="anchor" aria-hidden="true"
    href="#download-and-setup"><span aria-hidden="true" class="octicon octicon-link"></span></a>Download
    and Setup</h3>

    <p>Download the Einstein Toolkit, including CarpetX. This will create a

    new directory <code>Cactus</code> that will contain the code:</p>

    <div class="highlight highlight-source-shell"><pre>curl -kLO https://raw.githubusercontent.com/gridaphobe/CRL/master/GetComponents

    perl GetComponents --parallel https://bitbucket.org/eschnett/cactusamrex/raw/master/manifest/einsteintoolkit-carpetx.th

    <span class="pl-c1">cd</span> Cactus</pre></div>

    <p>We''re using a Docker image to provide dependencies (including AMReX)

    to simplify installation. However, the Einstein Toolkit source code

    does not reside in that image; it resides in the <code>Cactus</code> directory

    which you just created. This leads to the following workflow:</p>

    <ul>

    <li>To download, look at, edit, git add/commit/pull/push etc. the code,

    you use the regular tools you already have installed on your system.

    Docker is not involved in this in any way.</li>

    <li>To build and run, you create an emphemeral (stateless) Docker

    container running Bash, with our Docker image mounted. For

    convenience, there is a shell script for this:</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>./repos/cactusamrex/utils/Docker/cpu/run-container</pre></div>

    <p>The first time you run this script, Docker will download the Docker

    image with the dependencies, which might take a few minutes.</p>

    <p>Inside this container, the hostname is <code>carpetx-docker-cpu</code>, so
    that

    you know you''re inside the container. (You exit the container by

    exiting the shell, e.g. with the <code>exit</code> command.)</p>

    <p>Note: While the container (running the Bash shell) is thrown away

    after each use, the changes to the file system you make persist, since

    your home directory is mounted and thus available in the container.</p>

    <p>As usual, the first time you use the Einstein Toolkit, you have to

    configure Simfactory for your local machine:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim setup</pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>Let''s build the toolkit with CarpetX.</p>

    <p>The default option list doesn''t point to AMReX nor some other

    dependencies. We thus specify our own. (I assume this could be fixed

    in the thorns handling these external dependencies.)</p>

    <p>The default thorn list would build the regular Einstein Toolkit

    without CarpetX; we need to specify a particular thorn list which

    includes all CarpetX thorns. This thorn list also disables those

    thorns that do not yet work with CarpetX.</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim build
    --optionlist=repos/cactusamrex/utils/Docker/cpu/carpetx.cfg --thornlist=repos/cactusamrex/utils/Docker/cpu/carpetx.th</pre></div>

    <p>Of course, once you created your configuration with the command above,

    to re-build after changing some code, the command is simply</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim build</pre></div>

    <p>as usual.</p>

    <h3><a id="user-content-run" class="anchor" aria-hidden="true" href="#run"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run</h3>

    <p>Let''s run some examples!</p>

    <p>Starting slowly, here is a scalar wave:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim submit
    planewave --parfile=arrangements/CarpetX/WaveToyCPU/par/planewave.par --procs=8
    --num-threads=8</pre></div>

    <p>You want to adapt the number of cores (<code>--procs</code>) and threads

    (<code>--num-threads</code>) to your system.</p>

    <p>It seems that the default Simfactory setup that was created above

    buffers the output, so that there might be long periords of time where

    the simulation appears to hang. Use <code>top</code> to see whether it is still

    running, and check the output directory to see whether it is still

    producing output.</p>

    <p>We can also run a binary black hole merger:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim submit
    planewave --parfile=arrangements/CarpetX/Z4c/par/qc0.rpar --procs=40 --num-threads=10</pre></div>

    <p>This setup requires more memory and time. I''m running it with about

    200 GByte of memory on 40 cores for 24 hours.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1680546511.0
ai2cm/fv3net:
  data_format: 2
  description: explore the FV3 data for parameterization
  filenames:
  - docker/ufs_utils/spack.yaml
  full_name: ai2cm/fv3net
  latest_release: n2f-3km-initial-submission
  readme: '<h1><a id="user-content-fv3net" class="anchor" aria-hidden="true" href="#fv3net"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>fv3net</h1>

    <p><a href="https://circleci.com/gh/ai2cm/fv3net/tree/master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a552f20b68ca052bd00beeb5ce611dd080f121e453b44f371d63405aeec20c78/68747470733a2f2f636972636c6563692e636f6d2f67682f616932636d2f6676336e65742f747265652f6d61737465722e7376673f7374796c653d737667"
    alt="CircleCI" data-canonical-src="https://circleci.com/gh/ai2cm/fv3net/tree/master.svg?style=svg"
    style="max-width: 100%;"></a></p>

    <p>Improving the GFDL FV3 model physics with machine learning. See the <a href="https://vulcanclimatemodeling.com/docs/fv3net/"
    rel="nofollow">documentation</a> for more information on using this suite of tools.</p>

    <p>Disclaimer: This is a work in progress.</p>

    '
  stargazers_count: 14
  subscribers_count: 8
  topics: []
  updated_at: 1675296401.0
ashermancinelli/vimconfig:
  data_format: 2
  description: null
  filenames:
  - spack/envs/triage/spack.yaml
  full_name: ashermancinelli/vimconfig
  latest_release: null
  readme: "<h1><a id=\"user-content-vimconfig\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#vimconfig\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>vimconfig</h1>\n<p>Lots and lots of different configurations for various\
    \ programs all wrapped up into one repo. Under heavy development so tread with\
    \ some caution :)</p>\n<h2><a id=\"user-content-how-to-use\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#how-to-use\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>How to use</h2>\n<p>The top directory has a\
    \ script to deal with installation - you should pretty much only interact with\
    \ the repo through that script.\nThe help message is quite descriptive:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ ./configure --h\n\n  Usage:\n\
    \n  -p <span class=\"pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>  \
    \         Sets install prefix. Default: /people/manc568/.local\n  -r <span class=\"\
    pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>           Path to RC file\
    \ <span class=\"pl-k\">for</span> given shell. Default: /qfs/people/manc568/.bashrc\n\
    \  -d                  Default installation. Installs ctags, vim, and bash\n \
    \ -s <span class=\"pl-k\">&lt;</span>pkg<span class=\"pl-k\">&gt;</span>     \
    \       Show installation script <span class=\"pl-k\">for</span> pacakge\n  -i\
    \                  One or more of the following list, separated by commas with\
    \ no spaces:\n\n       zsh\n       bash\n       ctags\n       vim\n       tmux\n\
    \       emacs\n       profiles\n       modules\n       rice\n       rice.sh\n\
    \       fresh</pre></div>\n<h2><a id=\"user-content-examples\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#examples\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<p>For example, to just install\
    \ my vim configuration, you'd do:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ ./configure -i vim</pre></div>\n<p>Or to install configs for multiple\
    \ programs:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ ./configure\
    \ -i vim,ctags,tmux,emacs,bash</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1681145022.0
camierjs/mfem-asan:
  data_format: 2
  description: null
  filenames:
  - config/docker/spack.yaml
  full_name: camierjs/mfem-asan
  latest_release: null
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed under the terms\
    \ of the BSD-3 license. All new contributions\nmust be made under this license.\
    \ See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> for\n\
    details.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release Number:\
    \ LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1680543921.0
celeritas-project/celeritas:
  data_format: 2
  description: Celeritas is a new Monte Carlo transport code designed for high-performance
    simulation of high-energy physics detectors.
  filenames:
  - scripts/spack.yaml
  full_name: celeritas-project/celeritas
  latest_release: v0.2.1
  readme: "<h1><a id=\"user-content-celeritas\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Celeritas</h1>\n<p>The Celeritas project implements HEP detector physics\
    \ on GPU accelerator\nhardware with the ultimate goal of supporting the massive\
    \ computational\nrequirements of the <a href=\"https://home.cern/science/accelerators/high-luminosity-lhc\"\
    \ rel=\"nofollow\">HL-LHC upgrade</a>.</p>\n<h1><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>Most of\
    \ the Celeritas documentation is readable through the codebase through a\ncombination\
    \ of <a href=\"doc/index.rst\">static RST documentation</a> and Doxygen-markup\n\
    comments in the source code itself. The full <a href=\"https://celeritas-project.github.io/celeritas/user/index.html\"\
    \ rel=\"nofollow\">Celeritas user\ndocumentation</a> (including selected code\
    \ documentation incorporated\nby Breathe) and the <a href=\"https://celeritas-project.github.io/celeritas/dev/index.html\"\
    \ rel=\"nofollow\">Celeritas code documentation</a> are mirrored on\nour GitHub\
    \ pages site. You can generate these yourself (if the necessary\nprerequisites\
    \ are installed) by\nsetting the <code>CELERITAS_BUILD_DOCS=ON</code> configuration\
    \ option and running <code>ninja doc</code> (user) or <code>ninja doxygen</code>\
    \ (developer). A continuously updated version of\nthe <a href=\"https://celeritas.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">static Celeritas user documentation</a> (without API documentation)\
    \ is\nhosted on <code>readthedocs.io</code>.</p>\n<h1><a id=\"user-content-installation-for-applications\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation-for-applications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ for applications</h1>\n<p>The easiest way to install Celeritas as a library/app\
    \ is with Spack:</p>\n<ul>\n<li>Follow the first two steps above to install <a\
    \ href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"\
    nofollow\">Spack</a> and set up its CUDA usage.</li>\n<li>Install Celeritas with\
    \ <code>spack install celeritas</code>\n</li>\n<li>Use <code>spack load celeritas</code>\
    \ to add the installation to your <code>PATH</code>.</li>\n</ul>\n<p>Then see\
    \ the \"Downstream usage as a library\" section of the <a href=\"doc/installation.rst\"\
    >installation\ndocumentation</a> for how to use Celeritas in your application\
    \ or framework.</p>\n<h1><a id=\"user-content-installation-for-developers\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#installation-for-developers\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation for developers</h1>\n\
    <p>Since Celeritas is still under heavy development and is not yet full-featured\n\
    for downstream integration, you are likely installing it for development\npurposes.\
    \ The <a href=\"doc/installation.rst\">installation documentation</a> has a\n\
    complete description of the code's dependencies and installation process for\n\
    development.</p>\n<p>As an example, if you have the <a href=\"https://github.com/spack/spack\"\
    >Spack</a> package manager\ninstalled and want to do development on a CUDA system\
    \ with Volta-class graphics\ncards, execute the following steps from within the\
    \ cloned Celeritas source\ndirectory:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre># <span class=\"pl-s1\">Set up CUDA (optional)</span>\n$ <span class=\"\
    pl-s1\">spack external find cuda</span>\n$ <span class=\"pl-s1\">spack config\
    \ add packages:all:variants:<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>+cuda\
    \ cuda_arch=70<span class=\"pl-pds\">\"</span></span></span>\n# <span class=\"\
    pl-s1\">Install celeritas dependencies</span>\n$ <span class=\"pl-s1\">spack env\
    \ create celeritas scripts/spack.yaml</span>\n$ <span class=\"pl-s1\">spack env\
    \ activate celeritas</span>\n$ <span class=\"pl-s1\">spack install</span>\n# <span\
    \ class=\"pl-s1\">Configure, build, and <span class=\"pl-c1\">test</span></span>\n\
    $ <span class=\"pl-s1\">./build.sh base</span></pre></div>\n<p>If you don't use\
    \ Spack but have all the dependencies you want (Geant4,\ngoogletest, VecGeom,\
    \ etc.) in your <code>CMAKE_PREFIX_PATH</code>, you can configure and\nbuild Celeritas\
    \ as you would any other project:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">mkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build</span>\n$ <span class=\"pl-s1\">cmake\
    \ ..</span>\n$ <span class=\"pl-s1\">make <span class=\"pl-k\">&amp;&amp;</span>\
    \ ctest</span></pre></div>\n<p>Celeritas guarantees full compatibility and correctness\
    \ only on the\ncombinations of compilers and dependencies tested under continuous\
    \ integration.\nCurrently supported compilers are GCC 11.2 + NVCC 11.8, and HIP-Clang\
    \ 15.0, but\nsince we compile with extra warning flags and avoid non-portable\
    \ code, most\nother compilers <em>should</em> work.\nCurrently Geant4 11.0 and\
    \ VecGeom 1.2 are the only versions that are guaranteed\nto work, but older versions\
    \ might be OK.\nThe full set of configurations is viewable on <a href=\"https://cloud.cees.ornl.gov/jenkins-ci/blue/organizations/jenkins/Celeritas/activity?branch=master\"\
    \ rel=\"nofollow\">the CI web site</a>.\nCompatibility fixes that do not cause\
    \ newer versions to fail are welcome.</p>\n<h1><a id=\"user-content-development\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Development</h1>\n<p>See the\
    \ <a href=\"CONTRIBUTING.rst\">contribution guide</a> for the contribution process,\n\
    <a href=\"doc/appendices/development.rst\">the development guidelines</a> for\
    \ further\ndetails on coding in Celeritas, and <a href=\"doc/appendices/administration.rst\"\
    >the administration guidelines</a> for community standards and roles.</p>\n<h1><a\
    \ id=\"user-content-citing-celeritas\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #citing-celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing Celeritas</h1>\n<p>If using Celeritas in your work, we ask\
    \ that you cite the code using its\n<a href=\"https://www.osti.gov/doecode/biblio/94866\"\
    \ rel=\"nofollow\">DOECode</a> registration:</p>\n<blockquote>\n<p>Johnson, Seth\
    \ R., Amanda Lund, Soon Yung Jun, Stefano Tognini, Guilherme Lima, Paul Romano,\
    \ Philippe Canal, Ben Morgan, and Tom Evans. \u201CCeleritas,\u201D July 2022.\
    \ <a href=\"https://doi.org/10.11578/dc.20221011.1\" rel=\"nofollow\">https://doi.org/10.11578/dc.20221011.1</a>.</p>\n\
    </blockquote>\n<p>Additional references for code implementation details, benchmark\
    \ problem\nresults, etc., can be found in our continually evolving <a href=\"\
    doc/_static/celeritas.bib\">citation\nfile</a>. An <a href=\"https://github.com/celeritas-project/celeritas-docs/blob/main/presentations/presentations.bib\"\
    >exhaustive list of Celeritas presentations\n</a>\nauthored by (or with content\
    \ authored by) core team members is available in our\ndocuments repo.</p>\n"
  stargazers_count: 31
  subscribers_count: 10
  topics:
  - hep
  - cuda
  - computational-physics
  - monte-carlo
  updated_at: 1680231702.0
charmoniumQ/wf-reg-test:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: charmoniumQ/wf-reg-test
  latest_release: null
  readme: "<h1><a id=\"user-content-wf-reg-test\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#wf-reg-test\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>wf-reg-test</h1>\n<p>Software tends to break or \"collapse\" over\
    \ time, even if it is unchanged, due to non-obvious changes in the computational\
    \ environment.\nCollapse in computational experiments undermines long-term credibility\
    \ and hinders day-to-day operations.\nWe propose to create the first public dataset\
    \ of automatically executable scientific experiments.\nThis data could be used\
    \ to identify best practices, make continuous testing feasible, and repair broken\
    \ programs.\nThese techniques increase the replicability of computational experiments.</p>\n\
    <p>Conceptually, we intend to collect the following:</p>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">registry</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >registries</span>:\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\"\
    >experiment</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">registry</span>:\n\
    \        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">version</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">experiment</span>:\n \
    \           <span class=\"pl-k\">for</span> <span class=\"pl-s1\">i</span> <span\
    \ class=\"pl-c1\">in</span> <span class=\"pl-en\">range</span>(<span class=\"\
    pl-s1\">num_repetitions</span>):\n                <span class=\"pl-s1\">execution</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-en\">execute</span>(<span class=\"\
    pl-s1\">version</span>)\n                <span class=\"pl-s1\">data</span>.<span\
    \ class=\"pl-en\">append</span>((\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">date</span>,   <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">output</span>,\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">logs</span>,   <span class=\"pl-s1\">execuiton</span>.<span\
    \ class=\"pl-s1\">res_usage</span>,\n                    <span class=\"pl-s1\"\
    >version</span>.<span class=\"pl-s1\">date</span>,     <span class=\"pl-s1\">version</span>.<span\
    \ class=\"pl-s1\">code</span>,\n                    <span class=\"pl-s1\">experiment</span>.<span\
    \ class=\"pl-s1\">name</span>,  <span class=\"pl-s1\">registry</span>.<span class=\"\
    pl-s1\">name</span>,\n                ))</pre></div>\n<h1><a id=\"user-content-reproducing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reproducing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Reproducing</h1>\n<p>See <a href=\"\
    REPRODUCING.md\"><code>REPRODUCING.md</code></a> for instructions on reproducing\
    \ these results.</p>\n<h1><a id=\"user-content-todo\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#todo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>TODO</h1>\n<p>See <a href=\"TODO.md\"><code>TODO.md</code></a> for\
    \ instructions on reproducing these results.</p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n<p>See <a\
    \ href=\"CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on\
    \ setting up a development environment.</p>\n"
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1676689037.0
cinemascienceworkflows/2021-06_E4S-Tutorial:
  data_format: 2
  description: null
  filenames:
  - inputs/spack/spack.yaml
  full_name: cinemascienceworkflows/2021-06_E4S-Tutorial
  latest_release: null
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1623424083.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - hmmer-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<h1><a id="user-content-benchmark-containers" class="anchor" aria-hidden="true"
    href="#benchmark-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Benchmark
    Containers</h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
deephyper/deephyper-platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running DeepHyper experiments on various platforms.
  filenames:
  - ANL/Swing/spack.yaml
  - ANL/Polaris/spack.yaml
  full_name: deephyper/deephyper-platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-deephyper-platform-configurations" class="anchor"
    aria-hidden="true" href="#deephyper-platform-configurations"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>DeepHyper Platform Configurations</h1>

    <p>This repository provides a set of configuration files and example scripts for
    running DeepHyper experiments on various platforms.</p>

    <p>The <code>generic</code> subdirectory contains a minimal DeepHyper environment
    example that can be used as a starting point for systems for which there is no
    existing recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which DeepHyper packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <div class="highlight highlight-source-shell"><pre>git clone -c feature.manyFiles=true
    https://github.com/spack/spack.git

    <span class="pl-c1">.</span> spack/share/spack/setup-env.sh</pre></div>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>deephyper-spack-packages</code>, which contains
    the DeepHyper packages.</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-spack-packages.git

    spack repo add deephyper-spack-packages</pre></div>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-platform-configurations.git

    <span class="pl-c1">cd</span> deephyper-platform-configurations/ANL/Polaris</pre></div>

    <p>Edit the path to <code>deephyper-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <div class="highlight highlight-source-shell"><pre>spack env create myenv spack.yaml</pre></div>

    <p>Change to a directory outside of the <code>deephyper-platform-configurations</code>
    folders

    and activate the environment as follows.</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate myenv</pre></div>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <div class="highlight highlight-source-shell"><pre>spack install</pre></div>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-acknowledgment" class="anchor" aria-hidden="true" href="#acknowledgment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgment</h2>

    <p>This repository was created by following the example of the <a href="https://github.com/mochi-hpc-experiments/platform-configurations">Mochi
    Project</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675421226.0
dyokelson/soma_c:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: dyokelson/soma_c
  latest_release: null
  readme: '<p>Your project "soma" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675627136.0
dyokelson/soma_cpp:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: dyokelson/soma_cpp
  latest_release: null
  readme: '<p>Your project "soma" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675794086.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - bipp-izar-gcc/spack.yaml
  - env-bipp-izar/spack.yaml
  - bipp-jed-gcc/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<h1><a id="user-content-ska-spack-env" class="anchor" aria-hidden="true"
    href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a>ska-spack-env</h1>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - nvhpc/failures/spack.yaml
  - clang/spack.yaml
  - oneapi/spack.yaml
  - gnu/spack.yaml
  - clang/failures/spack.yaml
  - oneapi/failures/spack.yaml
  - nvhpc/spack.yaml
  - gnu/failures/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675202595.0
eugeneswalker/qmcpack-ci-container:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  - docker-images/spack.yaml
  full_name: eugeneswalker/qmcpack-ci-container
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678143972.0
floquet/builds:
  data_format: 2
  description: Notes and scripts for building applications on HPCs
  filenames:
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  full_name: floquet/builds
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641760136.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-clang/spack.yaml
  - ubuntu-gcc/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1><a id="user-content-synergia2-containers" class="anchor" aria-hidden="true"
    href="#synergia2-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1678463172.0
giltirn/mochi-margo:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: giltirn/mochi-margo
  latest_release: null
  readme: "<h1><a id=\"user-content-margo\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#margo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    ><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings\
    \ to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\"\
    \ rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\n\
    library optimized for use in HPC environments.  Its native API presents a\ncallback-oriented\
    \ interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\"\
    \ rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n\
    <p>Margo combines Mercury and Argobots to simplify development of distributed\n\
    services.  Mercury operations are presented as conventional blocking\noperations,\
    \ and RPC handlers are presented as sequential threads.  This\nconfiguration enables\
    \ high degree of concurrency while hiding the\ncomplexity associated with asynchronous\
    \ communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends\
    \ callers after issuing a Mercury operation, and\nautomatically resumes them when\
    \ the operation completes.  This allows\nother concurrent user-level threads to\
    \ make progress while Mercury\noperations are in flight without consuming operating\
    \ system threads.\nThe goal of this design is to combine the performance advantages\
    \ of\nMercury's native event-driven execution model with the progamming\nsimplicity\
    \ of a multi-threaded execution model.</p>\n<p>A companion library called abt-io\
    \ provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\"\
    >https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should\
    \ be compatible with any Mercury network\ntransport (NA plugin).  The documentation\
    \ assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury\
    \ for\nsimplicity.  This plugin is only valid for communication between\nprocesses\
    \ on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\"\
    >Using Margo with other Mercury NA\nplugins</a> for information\non other configuration\
    \ options.</p>\n<h2><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing\
    \ the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"\
    nofollow\">https://spack.io/</a>).</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury\
    \  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\"\
    >https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone\
    \ <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n\
    </ul>\n<h3><a id=\"user-content-recommended-mercury-build-options\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#recommended-mercury-build-options\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury build options</h3>\n\
    <ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable\
    \ the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should be compiled\
    \ with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path\
    \ for cases in which a Mercury service is linked into the same\nexecutable as\
    \ the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir\
    \ build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON\
    \ -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install\
    \ \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n\
    <h2><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n\
    <p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install\
    \ \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"\
    -g -Wall\"\n</code></pre>\n<h2><a id=\"user-content-running-examples\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#running-examples\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The\
    \ examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example\
    \ client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]:\
    \ an example RPC definition</li>\n</ul>\n<p>The following example shows how to\
    \ execute them.  Note that when the server starts it will display the address\
    \ that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server\
    \ na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with\
    \ input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val:\
    \ 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client\
    \ na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3]\
    \ running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\n\
    Got response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n\
    <p>The client will issue 4 concurrent RPCs to the server and wait for them to\n\
    complete.</p>\n<h2><a id=\"user-content-running-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#running-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running tests</h2>\n<p><code>make check</code></p>\n<h2><a id=\"user-content-using-margo-with-the-other-na-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-margo-with-the-other-na-plugins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Margo\
    \ with the other NA plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\"\
    \ rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible\
    \ with any Mercury transport and uses the same address\nformat.</p>\n<h2><a id=\"\
    user-content-instrumentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#instrumentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Instrumentation</h2>\n\
    <p>See the <a href=\"doc/instrumentation.md\">Instrumentation documentation</a>\
    \ for\ninformation on how to extract diagnostic instrumentation from Margo.</p>\n\
    <h2><a id=\"user-content-debugging\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #debugging\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Debugging</h2>\n\
    <p>See the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo\
    \ debugging\nfeatures and strategies.</p>\n<h2><a id=\"user-content-design-details\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#design-details\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Design details</h2>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"doc/fig/margo-diagram.png\"><img src=\"\
    doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>Margo provides Argobots-aware wrappers to common Mercury library\
    \ functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The\
    \ wrappers\nhave the same arguments as their native Mercury counterparts except\
    \ that no\ncallback function is specified.  Each function blocks until the operation\n\
    is complete.  The above diagram illustrates a typical control flow.</p>\n<p>Margo\
    \ launches a long-running user-level thread internally to drive\nprogress on Mercury\
    \ and execute Mercury callback functions (labeled\n<code>__margo_progress()</code>\
    \ above).  This thread can be assigned to a\ndedicated Argobots execution stream\
    \ (i.e., an operating system thread)\nto drive network progress with a dedicated\
    \ core.  Otherwise it will be\nautomatically scheduled when the caller's execution\
    \ stream is blocked\nwaiting for network events as shown in the above diagram.</p>\n\
    <p>Argobots eventual constructs are used to suspend and resume user-level\nthreads\
    \ while Mercury operations are in flight.</p>\n<p>Margo allows several different\
    \ threading/multicore configurations:</p>\n<ul>\n<li>The progress loop can run\
    \ on a dedicated operating system thread or not</li>\n<li>Multiple Margo instances\
    \ (and thus progress loops) can be\nexecuted on different operating system threads</li>\n\
    <li>(for servers) a single Margo instance can launch RPC handlers\non different\
    \ operating system threads</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1654705049.0
haampie/spack-docker-bootstrap:
  data_format: 2
  description: Build optimized docker images for Spack
  filenames:
  - spack.yaml
  full_name: haampie/spack-docker-bootstrap
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-in-docker-with-buildcache\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#spack-in-docker-with-buildcache\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack in Docker with buildcache</h1>\n\
    <p>This bootstraps Spack's own, optimized dependencies, as well as the\ncompiler\
    \ toolchain of the distro, so that in the end we just depend\non system libc.</p>\n\
    <p>See <a href=\"spack.yaml\">spack.yaml</a> for things that are built by Spack,\
    \ and\n<a href=\"Makefile\">Makefile</a> and <a href=\"Dockerfile\">Dockerfile</a>\
    \ for how it's built.</p>\n<p>Docker buildkit is required.</p>\n<p>Build with:</p>\n\
    <pre><code>DOCKER_BUILDKIT=1 docker build -f linux-ubuntu22.04-x86_64_v2/Dockerfile\
    \ -t spack-optimized --progress=plain .\n</code></pre>\n<p>Since this uses Python\
    \ 3.11 and clingo with some optimizations, it should\ngenerally be faster:</p>\n\
    <pre><code>Benchmark 1: docker run --rm spack-optimized spack spec hdf5\n  Time\
    \ (mean \xB1 \u03C3):      8.494 s \xB1  0.401 s    [User: 0.015 s, System: 0.008\
    \ s]\n  Range (min \u2026 max):    8.034 s \u2026  8.763 s    3 runs\n\nBenchmark\
    \ 2: docker run --rm spack/ubuntu-focal spec hdf5\n  Time (mean \xB1 \u03C3):\
    \     10.795 s \xB1  0.382 s    [User: 0.013 s, System: 0.009 s]\n  Range (min\
    \ \u2026 max):   10.355 s \u2026 11.030 s    3 runs\n\nSummary\n  'docker run\
    \ --rm spack-optimized spack spec hdf5' ran\n    1.27 \xB1 0.07 times faster than\
    \ 'docker run --rm spack/ubuntu-focal spec hdf5'\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674134786.0
haampie/spack-prune-specs:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: haampie/spack-prune-specs
  latest_release: null
  readme: '<p>Utilities:</p>

    <ul>

    <li>

    <code>make buildcache-minus-pipelines.filelist</code>: specs in buildcache no
    longer referenced by develop pipelines in the last x days.</li>

    <li>

    <code>make buildcache-intersect-pipelines.filelist</code>: specs both in buildcache
    referenced by develop pipelines in the last x days.</li>

    </ul>

    <p>Set <code>SINCE=yyy-mm-dd</code> to control the window (note that artifacts
    are removed after 30 days, so it can be max one month back).</p>

    <p><code>make</code> installs <code>aws</code>, <code>jq</code> and other utilities
    for you.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678906710.0
hancheng2000/calcHW:
  data_format: 2
  description: null
  filenames:
  - environments/spack/spack.yaml
  full_name: hancheng2000/calcHW
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676957739.0
hariharan-devarajan/dlio-profiler:
  data_format: 2
  description: A low-level profiler for capture I/O calls from deep learning applications.
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/dlio-profiler
  latest_release: null
  readme: "<h1><a id=\"user-content-dlio-profiler\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#dlio-profiler\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>dlio-profiler</h1>\n<p>A low-level profiler for capture I/O calls\
    \ from deep learning applications.</p>\n<p>Requirements</p>\n<ol>\n<li>Python\
    \ &gt; 3.8</li>\n<li>spack</li>\n</ol>\n<p>Install dependencies</p>\n<pre><code>git\
    \ clone git@github.com:hariharan-devarajan/dlio-profiler.git\ncd dlio-profiler\n\
    spack env activater -p ./dependency\nspack install\n</code></pre>\n<p>create a\
    \ virtual env for your python package where u will use dlio_profiler.</p>\n<pre><code>python3\
    \ -m venv ./venv\nsource venv/bin/activate\npip install --upgrade pip\n</code></pre>\n\
    <p>Build dlio profiler through cmake</p>\n<pre><code>cd dlio-profiler\nmkdir build\n\
    cd build\ncmake -DCMAKE_INSTALL_PREFIX=../venv ../\nmake install -j\n</code></pre>\n\
    <p>Usage</p>\n<pre><code>import dlio_profiler_py as logger\nfrom time import sleep\n\
    import os\ncwd = os.getcwd()\ndef custom_events():\n    logger.start(\"test\"\
    , \"cat2\")\n    sleep(2)\n    logger.stop()\n\ndef posix_calls1():\n    f = open(f\"\
    {cwd}/data/demofile2.txt\", \"w+\")\n    f.write(\"Now the file has more content!\"\
    )\n    f.close()\n\ndef posix_calls2():\n    f = open(f\"{cwd}/data/demofile2.txt\"\
    , \"r\")\n    data = f.read()\n    f.close()\n\nposix_calls1()\ncustom_events()\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1680080472.0
hariharan-devarajan/unifyfs-bug:
  data_format: 2
  description: null
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/unifyfs-bug
  latest_release: null
  readme: "<h1><a id=\"user-content-unifyfs-bug\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#unifyfs-bug\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>unifyfs-bug</h1>\n<h2><a id=\"user-content-the-bug-comes-in-multi-node-case-only\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#the-bug-comes-in-multi-node-case-only\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The bug\
    \ comes in multi-node case only.</h2>\n<h2><a id=\"user-content-instructions\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Instructions</h2>\n<ul>\n<li>update\
    \ path of unifyfs on dependency/spack.yaml packages</li>\n<li>activate dependency\
    \ spack folder\n<div class=\"highlight highlight-source-shell\"><pre>spack activate\
    \ -p dependency\nspack install</pre></div>\n</li>\n<li>update path of unifyfs\
    \ install on line 3 of CMakeLists</li>\n<li>build code.\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>cmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_C_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/gcc\
    \ -DCMAKE_CXX_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/g++ -G <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>CodeBlocks - Unix Makefiles<span class=\"\
    pl-pds\">\"</span></span> /g/g92/haridev/temp/unifyfs-bug\ncmake --build /g/g92/haridev/temp/unifyfs-bug/cmake-build-debug\
    \ --target all -- -j 128</pre></div>\n</li>\n<li>Run Unifyfs server\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> unifyfs-bug\n\
    <span class=\"pl-k\">export</span> UNIFYFS_LOG_VERBOSITY=3\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> SET ME</span>\n<span class=\"pl-k\">export</span>\
    \ UNIFYFS_ROOT_DIR=/usr/workspace/iopp/software/tailorfs/dependency/.spack-env/view\
    \  \n<span class=\"pl-k\">export</span> UNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >${HOME}</span>/unifyfs/logs\n<span class=\"pl-k\">export</span> pfs=/p/gpfs1/iopp\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">${PWD}</span>/dependency/.spack-env/view/lib:<span\
    \ class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/lib\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> ACTUAL RUN</span>\nUNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >$UNIFYFS_LOG_DIR</span> UNIFYFS_SERVER_CORES=8 <span class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/bin/unifyfs\
    \ start --share-dir=<span class=\"pl-smi\">${pfs}</span>/unifyfs/share-dir -d</pre></div>\n\
    </li>\n<li>Run code\n<h2><a id=\"user-content-bug-1\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#bug-1\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Bug 1</h2>\n<div class=\"highlight highlight-source-shell\"><pre>jsrun\
    \ -r 1 -a 1 -c 1  -d packed <span class=\"pl-smi\">$PWD</span>/cmake-build-debug/unifyfs-bug\
    \ 1</pre></div>\nOutput\n<div class=\"highlight highlight-source-shell\"><pre>Running\
    \ transfer\n2023-03-27T09:36:22 tid=30501 @ <span class=\"pl-en\">forward_to_server</span>()\
    \ [margo_client.c:233] <span class=\"pl-en\">margo_forward_timed</span>() failed\
    \ - HG_TIMEOUT\n2023-03-27T09:36:22 tid=30501 @ <span class=\"pl-en\">invoke_client_transfer_rpc</span>()\
    \ [margo_client.c:614] forward of transfer rpc to server failed\nunifyfs-bug:\
    \ /g/g92/haridev/project/unifyfs-bug/bug.cpp:137: int main(int, char<span class=\"\
    pl-k\">**</span>): Assertion <span class=\"pl-s\"><span class=\"pl-pds\">`</span>rc\
    \ == UNIFYFS_SUCCESS<span class=\"pl-s\"><span class=\"pl-pds\">'</span> failed.</span></span>\n\
    <span class=\"pl-s\"><span class=\"pl-s\">[lassen1:30501] *** Process received\
    \ signal ***</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\">[lassen1:30501]\
    \ Signal: Aborted (6)</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\"\
    >[lassen1:30501] Signal code:  (-6)</span></span></pre></div>\n</li>\n</ul>\n\
    <pre><code>  ## Bug 2\n\n  ```bash\n  jsrun -r 1 -a 1 -c 1  -d packed $PWD/cmake-build-debug/unifyfs-bug\
    \ 2\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675706965.0
hepnos/HEPnOS:
  data_format: 2
  description: HEPnOS is a distributed object store for high energy physics applications,
    developed at Argonne National Laboratory.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS
  latest_release: v0.7.2
  readme: '<h1><a id="user-content-hepnos" class="anchor" aria-hidden="true" href="#hepnos"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS</h1>

    <p>HEPnOS is the <em>High-Energy Physics''s new Object Store</em>, a distributed
    storage

    system specially designed for HEP experiments and workflows for the FermiLab.

    HEPnOS relies on libraries developed at Argonne National Laboratory within the

    context of the Mochi project (ANL, CMU, LANL, HDF Group).</p>

    <p>For information on copyright and licensing, see the COPYRIGHT file.

    For information on how to use, see the <a href="https://xgitlab.cels.anl.gov/sds/HEPnOS/wikis/home"
    rel="nofollow">wiki</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641296454.0
hppritcha/spack_ompix:
  data_format: 2
  description: null
  filenames:
  - intel_release_x86_64/spack.yaml
  - intel_master_x86_64/spack.yaml
  full_name: hppritcha/spack_ompix
  latest_release: null
  readme: '<p>Project for using Gitlab CI to test spack builds of Open MPI master
    and release tarballs.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1640037910.0
iarspider/cms-spack-repo:
  data_format: 2
  description: null
  filenames:
  - environments/CMSSW_12_6_X/spack.yaml
  full_name: iarspider/cms-spack-repo
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1638894331.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-bitbucket/CPU/spack.yaml
  - Docs/compile-notes/frontera-bitbucket/GPU/spack.yaml
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  - Docs/compile-notes/frontera-github/GPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/8257fa34c1c5b6c660b31bf16a6196859c354c9c503b7742e1cdee871fbb96c8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/b768fc44ae95216e4b53ff734978771466ba222596e760da27e9e60a0d47d6f7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <h2><a id="user-content-available-modules" class="anchor" aria-hidden="true" href="#available-modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Available modules</h2>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>TOVSolver</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    '
  stargazers_count: 8
  subscribers_count: 8
  topics: []
  updated_at: 1679282900.0
jaykalinani/AsterX-Docs:
  data_format: 2
  description: 'AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes'
  filenames:
  - compile-notes/frontera-bitbucket/GPU/spack.yaml
  - compile-notes/frontera-github/CPU/spack.yaml
  - compile-notes/frontera-github/GPU/spack.yaml
  - compile-notes/frontera-bitbucket/CPU/spack.yaml
  full_name: jaykalinani/AsterX-Docs
  latest_release: null
  readme: '<h1><a id="user-content-asterx" class="anchor" aria-hidden="true" href="#asterx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>AsterX</h1>

    <p>AsterX: a new open-source GPU-accelerated GRMHD code for dynamical spacetimes</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1677876939.0
jeffersonscientific/cees_spack_configs:
  data_format: 2
  description: CEES spack configurations (take 3). Focus on environments only (or
    mostly), and modular configs.
  filenames:
  - dev_configs/pflotran_spack.yaml
  - spack_env_files/tinker9_spack.yaml
  - dev_configs/cees-x86-oneapi_spack.yaml
  - dev_configs/cees-x86-intel_spack.yaml
  - dev_configs/paraview_spack.yaml
  - dev_configs/py-bottleneck_spack.yaml
  full_name: jeffersonscientific/cees_spack_configs
  latest_release: null
  readme: "<h1><a id=\"user-content-cees_spack_configs\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#cees_spack_configs\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>cees_spack_configs</h1>\n<p>CEES spack configurations\
    \ (take 3). Focus on environments only (or mostly), and modular configs.</p>\n\
    <p>This constitutes a continued effort to find a way to Git-Support and modularize\
    \ Spack setups. While knowledge is much improved, success\nis arguably limited\
    \ -- alas. The idea is to be able to easily maintain a list of SW that is then\
    \ compiled over a suite of compiler, mpi,\narchitecture types.</p>\n<p>A few points:</p>\n\
    <ul>\n<li>Using environments is key.</li>\n<li>Using an <code>include:</code>\
    \ section can help. For example,</li>\n</ul>\n<pre><code>  include:\n  - $spack/../configs/packages_petsc.yaml\n\
    \  - $spack/../configs/compilers_sherlock_O2.yaml\n</code></pre>\n<p>might be\
    \ useful to build <code>petsc</code> environments for multiple architectures or\
    \ compilers. Unfortunatly -- at least at this time, not all sections\ncan be satisfied\
    \ as <code>include</code> files.</p>\n<ul>\n<li>Compilers remain a challenge...</li>\n\
    <li>If <code>providers</code> are specified, optimal (and functional) choices\
    \ will likely vary for different compilers.</li>\n</ul>\n<p>CONVENTIONS:</p>\n\
    <ul>\n<li>Configuration components indicated with <code>_inc</code> in name, eg\
    \ <code>packages_inc.yaml</code>. These files should stand alone for non-environment\
    \ builds\n(not recommended...) or can be included in an <code>include:</code>\
    \ clause of an environment.</li>\n<li>Environment files may be tagged with <code>_mod</code>\
    \ in the name, to indicate a \"modular\" envorinment, that uses an <code>include:</code>\
    \ section.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641864561.0
jerrygreenberg2/sdsc:
  data_format: 2
  description: null
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  full_name: jerrygreenberg2/sdsc
  latest_release: null
  readme: '<h1><a id="user-content-sdsc-hpc-software-deployment-guide" class="anchor"
    aria-hidden="true" href="#sdsc-hpc-software-deployment-guide"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>SDSC HPC Software Deployment Guide</h1>

    <p>This document outlines the Spack-based software deployment process in

    use by the San Diego Supercomputer Center''s (SDSC) High-Performance

    Computing (HPC) User Services Group. All definitions, procedures,

    conventions, and policies defined within this guide are used by the

    group to build and maintain the custom Spack instances they deploy on

    SDSC''s HPC systems for end users.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>This is a new and evolving software deployment process in development

    and use by the SDSC HPC User Services Group to centrally manage HPC

    software on HPC systems with Spack. Please consider the status of the

    project as a pre-alpha release at this time. Use at your own risk.</p>

    <h2><a id="user-content-definitions-and-terminology" class="anchor" aria-hidden="true"
    href="#definitions-and-terminology"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definitions
    and Terminology</h2>

    <ul>

    <li>A Spack <em><strong>instance</strong></em> is a unique, stand-alone installation
    of a

    specific version of <code>spack</code> that includes custom Spack configuration

    files, Spack packages, and a collection of Spack-installed software

    applications, libraries, and utilities.</li>

    <li>A Spack <em><strong>package</strong></em> is a set of instructions that defines
    how a

    specific piece of software is compiled and/or installed by Spack. For

    example, a Spack package specifies where to find and how to retrieve

    the software''s source code, its required (and/or optional) software

    dependencies, its compile-time options, any patches to apply, etc. A

    Spack package is primarily defined by it <em>package.py</em> file.</li>

    <li>A Spack <em><strong>spec</strong></em> is a string descriptor that specifies
    a particular

    build configuration of a Spack package. The full syntax of a spec

    may include the package name, its version, the compiler it should be

    built with, the compiler version, the system architecture it should be

    compiled for, any compile-time options for the package, and any

    requirements that should be enforced on its dependencies at build time.</li>

    <li>The <em><strong>core</strong></em> packages of a Spack instance are those
    software

    applications, libraries, and/or utilities compiled with Spack using

    the default system compiler. These packages form the foundation of the

    software environment upon which additional Spack packages are built.

    In general, the core packages of a Spack instance are a set of (core)

    compilers and other general software utilities. e.g., version control

    systems, data transfer tools, etc.</li>

    <li>A Spack package <em><strong>dependency chain</strong></em> is an explicitly-defined<br>

    ordered set of Spack specs that share a common (core) compiler and/or

    MPI library, may depend on one another (or share other software

    dependencies), and should be installed one after another, one at a

    time, as prescribed by their dependencies.</li>

    <li>A Spack <em><strong>deployment branch</strong></em> is a <em>trunk</em>-like
    branch for a specific

    version of <code>spack</code> that tracks all of the Spack configuration files,

    Spack packages, and Spack specs used to deploy a Spack instance (or a

    set of instances).</li>

    </ul>

    <h2><a id="user-content-github-repository" class="anchor" aria-hidden="true" href="#github-repository"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GitHub Repository</h2>

    <p>The <a href="https://github.com/sdsc/spack">sdsc/spack</a> project is a custom
    fork

    of the Spack project''s main GitHub repository, which is referred to in

    this guide as the <a href="https://github.com/spack/spack">spack/spack</a> repo.

    The primary aim of the sdsc/spack repo is to manage and track all

    changes made to the custom Spack instances deployed by SDSC on its HPC

    systems.</p>

    <h3><a id="user-content-deployment-branches" class="anchor" aria-hidden="true"
    href="#deployment-branches"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deployment
    Branches</h3>

    <p>The sdsc/spack repo and its use in practice are fundamentally structured

    around the concept of <em>deployment branches</em>. A deployment branch is a

    <em>trunk</em>-like branch created from an unmodifed, official release version

    of <code>spack</code> and is named accordingly, unless special circumstances

    require that an intermediate commit be used. For example, the

    <code>sdsc-0.17.3</code> deployment branch was created by checking out the

    <a href="https://github.com/spack/spack/releases/tag/v0.17.3">v0.17.3</a> release</p>

    <p>Once a version of Spack is selected and checked out, only a few minor

    changes and/or additions are made to the Spack release in order to

    initialize a deployment branch within the sdsc/spack repo. These

    modifications are as follows:</p>

    <ul>

    <li>The official version of the Spack <code>README.md</code> file is removed and

    replaced with the latest version of this document --- the <em>SDSC HPC

    Software Deployment Guide</em>.</li>

    <li>The latest version of the sdsc/spack <code>CONTRIBUTING.md</code> file is
    also

    included to provide information on how one may contribute to the

    sdsc/spack project and its deployment branches.</li>

    <li>A Spack package repository --- <code>var/spack/repos/sdsc</code> --- created
    to

    store all custom Spack packages created and/or maintained by SDSC,

    including all of SDSC''s custom modifications to Spack''s existing

    <code>builtin</code> packages.</li>

    <li>A Spack instance repository --- <code>etc/spack/sdsc</code> --- is created

    to  ...</li>

    </ul>

    <p>All other types of branches (see

    <a href="CONTRIBUTING.md">CONTRIBUTING.md</a>) should start from a deployment

    branch.</p>

    <h3><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    href="#package-repository"><span aria-hidden="true" class="octicon octicon-link"></span></a>Package
    Repository</h3>

    <h3><a id="user-content-instance-repositories" class="anchor" aria-hidden="true"
    href="#instance-repositories"><span aria-hidden="true" class="octicon octicon-link"></span></a>Instance
    Repositories</h3>

    <h3><a id="user-content-access-control-and-permissions" class="anchor" aria-hidden="true"
    href="#access-control-and-permissions"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Access Control and Permissions</h3>

    <p>etc/spack/repos.yaml

    var/spack/repos/sdsc/repo.yaml

    var/spack/repos/sdsc/packages</p>

    <p>etc/spack/sdsc/expanse/0.17.3/cpu/specs

    etc/spack/sdsc/expanse/0.17.3/cpu/yamls</p>

    <h2><a id="user-content-deploying-hpc-software-via-spack" class="anchor" aria-hidden="true"
    href="#deploying-hpc-software-via-spack"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Deploying HPC Software via Spack</h2>

    <h3><a id="user-content-deploying-a-spack-instance" class="anchor" aria-hidden="true"
    href="#deploying-a-spack-instance"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deploying
    a Spack Instance</h3>

    <ul>

    <li>start from existing deployment branch</li>

    </ul>

    <h3><a id="user-content-managing-changes-to-a-spack-instance" class="anchor" aria-hidden="true"
    href="#managing-changes-to-a-spack-instance"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Managing Changes to a Spack Instance</h3>

    <ul>

    <li>deploy change to configuration file</li>

    <li>add new package to sdsc package repository</li>

    <li>spack install a new spec</li>

    </ul>

    <h3><a id="user-content-setting-up-a-shared-instance-configuration" class="anchor"
    aria-hidden="true" href="#setting-up-a-shared-instance-configuration"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Setting up a Shared Instance Configuration</h3>

    <h3><a id="user-content-using-a-spack-mirror-and-build-caches-for-instance-backups"
    class="anchor" aria-hidden="true" href="#using-a-spack-mirror-and-build-caches-for-instance-backups"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using a Spack Mirror
    and Build Caches for Instance Backup(s)</h3>

    <h2><a id="user-content-additional-notes" class="anchor" aria-hidden="true" href="#additional-notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Additional Notes</h2>

    <h3><a id="user-content-protecting-the-sdscspack-develop-branch" class="anchor"
    aria-hidden="true" href="#protecting-the-sdscspack-develop-branch"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Protecting the sdsc/spack <code>develop</code>
    branch</h3>

    <h3><a id="user-content-fetching-changes-and-re-syncing-the-develop-branch" class="anchor"
    aria-hidden="true" href="#fetching-changes-and-re-syncing-the-develop-branch"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Fetching changes and
    re-syncing the <code>develop</code> branch</h3>

    <h3><a id="user-content-creating-a-new-deployment-branch" class="anchor" aria-hidden="true"
    href="#creating-a-new-deployment-branch"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Creating a new deployment branch</h3>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678670738.0
jerrypgreenberg/sdsc-tscc:
  data_format: 2
  description: null
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  full_name: jerrypgreenberg/sdsc-tscc
  latest_release: null
  readme: '<h1><a id="user-content-sdsc-hpc-software-deployment-guide" class="anchor"
    aria-hidden="true" href="#sdsc-hpc-software-deployment-guide"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>SDSC HPC Software Deployment Guide</h1>

    <p>This document outlines the Spack-based software deployment process in

    use by the San Diego Supercomputer Center''s (SDSC) High-Performance

    Computing (HPC) User Services Group. All definitions, procedures,

    conventions, and policies defined within this guide are used by the

    group to build and maintain the custom Spack instances they deploy on

    SDSC''s HPC systems for end users.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>This is a new and evolving software deployment process in development

    and use by the SDSC HPC User Services Group to centrally manage HPC

    software on HPC systems with Spack. Please consider the status of the

    project as a pre-alpha release at this time. Use at your own risk.</p>

    <h2><a id="user-content-definitions-and-terminology" class="anchor" aria-hidden="true"
    href="#definitions-and-terminology"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definitions
    and Terminology</h2>

    <ul>

    <li>A Spack <em><strong>instance</strong></em> is a unique, stand-alone installation
    of a

    specific version of <code>spack</code> that includes custom Spack configuration

    files, Spack packages, and a collection of Spack-installed software

    applications, libraries, and utilities.</li>

    <li>A Spack <em><strong>package</strong></em> is a set of instructions that defines
    how a

    specific piece of software is compiled and/or installed by Spack. For

    example, a Spack package specifies where to find and how to retrieve

    the software''s source code, its required (and/or optional) software

    dependencies, its compile-time options, any patches to apply, etc. A

    Spack package is primarily defined by it <em>package.py</em> file.</li>

    <li>A Spack <em><strong>spec</strong></em> is a string descriptor that specifies
    a particular

    build configuration of a Spack package. The full syntax of a spec

    may include the package name, its version, the compiler it should be

    built with, the compiler version, the system architecture it should be

    compiled for, any compile-time options for the package, and any

    requirements that should be enforced on its dependencies at build time.</li>

    <li>The <em><strong>core</strong></em> packages of a Spack instance are those
    software

    applications, libraries, and/or utilities compiled with Spack using

    the default system compiler. These packages form the foundation of the

    software environment upon which additional Spack packages are built.

    In general, the core packages of a Spack instance are a set of (core)

    compilers and other general software utilities. e.g., version control

    systems, data transfer tools, etc.</li>

    <li>A Spack package <em><strong>dependency chain</strong></em> is an explicitly-defined<br>

    ordered set of Spack specs that share a common (core) compiler and/or

    MPI library, may depend on one another (or share other software

    dependencies), and should be installed one after another, one at a

    time, as prescribed by their dependencies.</li>

    <li>A Spack <em><strong>deployment branch</strong></em> is a <em>trunk</em>-like
    branch for a specific

    version of <code>spack</code> that tracks all of the Spack configuration files,

    Spack packages, and Spack specs used to deploy a Spack instance (or a

    set of instances).</li>

    </ul>

    <h2><a id="user-content-github-repository" class="anchor" aria-hidden="true" href="#github-repository"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GitHub Repository</h2>

    <p>The <a href="https://github.com/sdsc/spack">sdsc/spack</a> project is a custom
    fork

    of the Spack project''s main GitHub repository, which is referred to in

    this guide as the <a href="https://github.com/spack/spack">spack/spack</a> repo.

    The primary aim of the sdsc/spack repo is to manage and track all

    changes made to the custom Spack instances deployed by SDSC on its HPC

    systems.</p>

    <h3><a id="user-content-deployment-branches" class="anchor" aria-hidden="true"
    href="#deployment-branches"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deployment
    Branches</h3>

    <p>The sdsc/spack repo and its use in practice are fundamentally structured

    around the concept of <em>deployment branches</em>. A deployment branch is a

    <em>trunk</em>-like branch created from an unmodifed, official release version

    of <code>spack</code> and is named accordingly, unless special circumstances

    require that an intermediate commit be used. For example, the

    <code>sdsc-0.17.3</code> deployment branch was created by checking out the

    <a href="https://github.com/spack/spack/releases/tag/v0.17.3">v0.17.3</a> release</p>

    <p>Once a version of Spack is selected and checked out, only a few minor

    changes and/or additions are made to the Spack release in order to

    initialize a deployment branch within the sdsc/spack repo. These

    modifications are as follows:</p>

    <ul>

    <li>The official version of the Spack <code>README.md</code> file is removed and

    replaced with the latest version of this document --- the <em>SDSC HPC

    Software Deployment Guide</em>.</li>

    <li>The latest version of the sdsc/spack <code>CONTRIBUTING.md</code> file is
    also

    included to provide information on how one may contribute to the

    sdsc/spack project and its deployment branches.</li>

    <li>A Spack package repository --- <code>var/spack/repos/sdsc</code> --- created
    to

    store all custom Spack packages created and/or maintained by SDSC,

    including all of SDSC''s custom modifications to Spack''s existing

    <code>builtin</code> packages.</li>

    <li>A Spack instance repository --- <code>etc/spack/sdsc</code> --- is created

    to  ...</li>

    </ul>

    <p>All other types of branches (see

    <a href="CONTRIBUTING.md">CONTRIBUTING.md</a>) should start from a deployment

    branch.</p>

    <h3><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    href="#package-repository"><span aria-hidden="true" class="octicon octicon-link"></span></a>Package
    Repository</h3>

    <h3><a id="user-content-instance-repositories" class="anchor" aria-hidden="true"
    href="#instance-repositories"><span aria-hidden="true" class="octicon octicon-link"></span></a>Instance
    Repositories</h3>

    <h3><a id="user-content-access-control-and-permissions" class="anchor" aria-hidden="true"
    href="#access-control-and-permissions"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Access Control and Permissions</h3>

    <p>etc/spack/repos.yaml

    var/spack/repos/sdsc/repo.yaml

    var/spack/repos/sdsc/packages</p>

    <p>etc/spack/sdsc/expanse/0.17.3/cpu/specs

    etc/spack/sdsc/expanse/0.17.3/cpu/yamls</p>

    <h2><a id="user-content-deploying-hpc-software-via-spack" class="anchor" aria-hidden="true"
    href="#deploying-hpc-software-via-spack"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Deploying HPC Software via Spack</h2>

    <h3><a id="user-content-deploying-a-spack-instance" class="anchor" aria-hidden="true"
    href="#deploying-a-spack-instance"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deploying
    a Spack Instance</h3>

    <ul>

    <li>start from existing deployment branch</li>

    </ul>

    <h3><a id="user-content-managing-changes-to-a-spack-instance" class="anchor" aria-hidden="true"
    href="#managing-changes-to-a-spack-instance"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Managing Changes to a Spack Instance</h3>

    <ul>

    <li>deploy change to configuration file</li>

    <li>add new package to sdsc package repository</li>

    <li>spack install a new spec</li>

    </ul>

    <h3><a id="user-content-setting-up-a-shared-instance-configuration" class="anchor"
    aria-hidden="true" href="#setting-up-a-shared-instance-configuration"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Setting up a Shared Instance Configuration</h3>

    <h3><a id="user-content-using-a-spack-mirror-and-build-caches-for-instance-backups"
    class="anchor" aria-hidden="true" href="#using-a-spack-mirror-and-build-caches-for-instance-backups"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using a Spack Mirror
    and Build Caches for Instance Backup(s)</h3>

    <h2><a id="user-content-additional-notes" class="anchor" aria-hidden="true" href="#additional-notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Additional Notes</h2>

    <h3><a id="user-content-protecting-the-sdscspack-develop-branch" class="anchor"
    aria-hidden="true" href="#protecting-the-sdscspack-develop-branch"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Protecting the sdsc/spack <code>develop</code>
    branch</h3>

    <h3><a id="user-content-fetching-changes-and-re-syncing-the-develop-branch" class="anchor"
    aria-hidden="true" href="#fetching-changes-and-re-syncing-the-develop-branch"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Fetching changes and
    re-syncing the <code>develop</code> branch</h3>

    <h3><a id="user-content-creating-a-new-deployment-branch" class="anchor" aria-hidden="true"
    href="#creating-a-new-deployment-branch"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Creating a new deployment branch</h3>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679762434.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - anl/polaris/polaris.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-release-user/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    href="#repository-contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    href="#central-installations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 8
  subscribers_count: 10
  topics: []
  updated_at: 1680637567.0
ma595/fenics-csd3-spack:
  data_format: 2
  description: Set up fenics spack on csd3
  filenames:
  - spack-skylake.yaml
  - spack-icelake.yaml
  full_name: ma595/fenics-csd3-spack
  latest_release: null
  readme: '<h1><a id="user-content-fenics-csd3-spack" class="anchor" aria-hidden="true"
    href="#fenics-csd3-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>fenics-csd3-spack</h1>

    <p>Follow instructions in icelake-spack-env.sh</p>

    <p>Or, copy existing <code>spack.yaml</code> files into cloned Spack repo. It
    is necessary to <code>module purge</code> environment first, otherwise the prepend
    path inside <code>spack.yaml</code> will lead to duplications.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667830944.0
marcodelapierre/toy-cowsay-nf:
  data_format: 2
  description: Toy pipeline for simple Nextflow tests
  filenames:
  - scripts/spack/spack.yaml
  - scripts/containerize-spack/spack.yaml
  - spack.yaml
  full_name: marcodelapierre/toy-cowsay-nf
  latest_release: null
  readme: '<h2><a id="user-content-toy-pipeline-for-simple-nextflow-tests" class="anchor"
    aria-hidden="true" href="#toy-pipeline-for-simple-nextflow-tests"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Toy pipeline for simple Nextflow tests</h2>

    <p>The purpose of this repo is to have a pipeline with features including:</p>

    <p>General:</p>

    <ul>

    <li>Simple</li>

    <li>Small (including required software)</li>

    <li>Quick to setup and run</li>

    </ul>

    <p>Pipeline:</p>

    <ul>

    <li>Requires a small package, that can be installed with Conda or Spack

    <ul>

    <li>Conda: <code>cowpy</code> (from <code>conda-forge</code>)</li>

    <li>Spack: <code>cowsay</code>

    </li>

    </ul>

    </li>

    <li>Reads/writes files</li>

    </ul>

    <p>Software options:</p>

    <ul>

    <li>Host</li>

    <li>Containers</li>

    <li>Conda</li>

    <li>Conda with Wave</li>

    <li>Spack</li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1676008940.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ANL/ThetaGPU/spack.yaml
  - ANL/Polaris/spack-ucx.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" href="#platform-configurations-for-mochi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Platform configurations for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    href="#contributing-to-this-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1677790084.0
mochi-hpc/margo-microservice-template:
  data_format: 2
  description: Template for a margo-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/margo-microservice-template
  latest_release: null
  readme: '<h1><a id="user-content-margo-microservice-template" class="anchor" aria-hidden="true"
    href="#margo-microservice-template"><span aria-hidden="true" class="octicon octicon-link"></span></a>Margo
    Microservice Template</h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Margo.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/01_margo.html" rel="nofollow">here</a>.</p>

    <p>To use this template:</p>

    <ul>

    <li>Click on the green "Use this template" button at the top.</li>

    <li>Give a name to your project.</li>

    <li>Once your project repository is created, go to Settings &gt; Actions &gt;
    General and give "Read and write permissions" under <em>Workflow permissions</em>.</li>

    <li>Finally, edit the initial-setup.json file and push the changes to your repo.</li>

    </ul>

    <p>Editing the initial-setup.json file with trigger a github action that will

    cleanup your repository and rename files, namespaces, functions, etc. according

    to the name of your service and the resources it manages.</p>

    <p>Enjoy working with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1649078785.0
mochi-hpc/mobject:
  data_format: 2
  description: Mobject is a prototype Mochi object storage system based on RADOS
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mobject
  latest_release: v0.6.1
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"mobject_logo.png\"\
    ><img src=\"mobject_logo.png\" alt=\"logo\" style=\"max-width: 100%;\"></a></p>\n\
    <h1><a id=\"user-content-mobject\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #mobject\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mobject</h1>\n\
    <p><a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml/badge.svg\"\
    \ alt=\"check spelling\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml/badge.svg\"\
    \ alt=\"spack mobject\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml/badge.svg\"\
    \ alt=\"spack mobject+bedrock\" style=\"max-width: 100%;\"></a></p>\n<p>Mobject\
    \ is a distributed object storage system\nbuilt using a composition of <a href=\"\
    https://mochi.readthedocs.io\" rel=\"nofollow\">Mochi</a> components:</p>\n<ul>\n\
    <li>\n<a href=\"https://github.com/mochi-hpc/mochi-bake\">mochi-bake</a> (for\
    \ bulk storage)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-bedrock\"\
    >mochi-bedrock</a>\n(for configuration and bootstrapping)</li>\n<li>\n<a href=\"\
    https://github.com/mochi-hpc/mochi-yokan\">mochi-yokan</a>\n(for metadata and\
    \ log indexing)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-ssg\"\
    >mochi-ssg</a> (for group membership)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"\
    https://mochi.readthedocs.io/en/latest/installing.html#installing-spack-and-the-mochi-repository\"\
    \ rel=\"nofollow\">Install Spack and Mochi Spack Repository</a>.</p>\n<p>Then,\
    \ run the following command to install mobject.</p>\n<pre><code>   spack install\
    \ mobject\n</code></pre>\n<h2><a id=\"user-content-hdf5-and-mobject\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#hdf5-and-mobject\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>HDF5 and Mobject</h2>\n<p><a\
    \ href=\"/include/librados-mobject-store.h\">Mobject API</a> is a subset of the\n\
    <a href=\"https://github.com/ceph/ceph/blob/main/src/include/rados/librados.h\"\
    >RADOS API</a>\nfrom Ceph\u2019s object storage layer.\nTherefore, <a href=\"\
    https://github.com/HDFGroup/vol-rados\">HDF5 RADOS VOL plugin-in</a>\ncan use\
    \ Mobject.</p>\n<h2><a id=\"user-content-faq\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#faq\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>FAQ</h2>\n<p>See <a href=\"doc/FAQ.md\">doc/FAQ.md</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1640785210.0
mochi-hpc/mochi-bake:
  data_format: 2
  description: A microservice (i.e., Mochi provider) for high performance bulk storage
    of raw data regions
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bake
  latest_release: v0.6.4
  readme: "<h1><a id=\"user-content-bake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #bake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bake</h1>\n\
    <p>Bake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage\
    \ of raw data regions.  Bake uses modular backends to store data\non persistent\
    \ memory, conventional file systems, or other storage media.</p>\n<p>See <a href=\"\
    https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a>\
    \ and\n<a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a>\
    \ for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively\
    \ to data storage.  Capabilities such as\nindexing, name spaces, and sharding\
    \ must be provided by other microservice\ncomponents.</p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The easiest\
    \ way to install Bake is through spack:</p>\n<p><code>spack install bake</code></p>\n\
    <p>This will install BAKE and its dependencies.  Please refer to the end of the\n\
    document for manual compilation instructions.</p>\n<h2><a id=\"user-content-architecture\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#architecture\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>Like most\
    \ Mochi services, BAKE relies on a client/provider architecture.\nA provider,\
    \ identified by its <em>address</em> and <em>multiplex id</em>, manages one or\
    \ more\n<em>BAKE targets</em>, referenced externally by their <em>target id</em>.</p>\n\
    <p>A target can be thought of as a storage device.  This may be (for example)\
    \ a\nPMDK volume or a local file system.</p>\n<h2><a id=\"user-content-setting-up-a-bake-target\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-a-bake-target\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up a\
    \ BAKE target</h2>\n<p>BAKE requires the backend storage file to be created beforehand\
    \ using\n<code>bake-mkpool</code>. For instance:</p>\n<p><code>bake-mkpool -s\
    \ 500M /dev/shm/foo.dat</code></p>\n<p>creates a 500 MB file at <em>/dev/shm/foo.dat</em>\
    \ to be used by BAKE as a target.\nBake will use the <code>pmem</code> (persistent\
    \ memory) backend by default, which means\nthat the underlying file will memory\
    \ mapped for access usign the PMDK\nlibrary.  You can also providie an explicit\
    \ prefix (such as <code>file:</code> for the\nconventional file backend or <code>pmem:</code>\
    \ for the persistent memory backend) to\ndictate a specific target type.</p>\n\
    <h2><a id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#starting-a-daemon\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Starting a daemon</h2>\n<p>BAKE ships with a default daemon program\
    \ that can setup providers and attach\nto storage targets. This daemon can be\
    \ started as follows:</p>\n<p><code>bake-server-daemon [options] &lt;listen_address&gt;\
    \ &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n<p>The program takes\
    \ a set of options followed by an address at which to listen for\nincoming RPCs,\
    \ and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n\
    <p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234\
    \ /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n\
    <ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the\
    \ address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em>\
    \ or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates\
    \ that, if multiple BAKE targets are used (as above),\nthese targets should be\
    \ managed by multiple providers, accessible through\ndifferent multiplex ids 1,\
    \ 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage.\
    \ The <em>targets</em> mode indicates that a single provider should be used to\n\
    manage all the storage targets.</p>\n<h2><a id=\"user-content-integrating-bake-into-a-larger-service\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#integrating-bake-into-a-larger-service\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Integrating\
    \ Bake into a larger service</h2>\n<p>Bake is not intended to be a standalone\
    \ user-facing service.  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\"\
    \ rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for\
    \ guidance on how to\nintegrate it with other providers using Mochi's Bedrock\
    \ capability.</p>\n<h2><a id=\"user-content-client-api-example\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#client-api-example\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Client API example</h2>\n<p>Data is\
    \ stored in <code>regions</code> within a <code>target</code> using explicit create,\n\
    write, and persist operations.  The caller cannot dictate the region id\nthat\
    \ will be used to reference a region; this identifier is generated\nby Bake at\
    \ creation time.  The region size must be specified at creation\ntime as well;\
    \ there is no mechanism for extending the size of an existing\nregion.</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>bake-client.h<span class=\"\
    pl-pds\">&gt;</span></span>\n\n<span class=\"pl-k\">int</span> <span class=\"\
    pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\"\
    >char</span> **argv)\n{\n    <span class=\"pl-k\">char</span> *svr_addr_str; <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> string address of the BAKE server</span>\n\
    \    <span class=\"pl-c1\">hg_addr_t</span> svr_addr; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Mercury address of the BAKE server</span>\n    margo_instance_id\
    \ mid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> Margo instance id</span>\n\
    \    <span class=\"pl-c1\">bake_client_t</span> bcl; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> BAKE client</span>\n    <span class=\"pl-c1\">bake_provider_handle_t</span>\
    \ bph; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE handle to provider</span>\n\
    \    <span class=\"pl-c1\">uint8_t</span> mplex_id; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> multiplex id of the provider</span>\n    <span class=\"\
    pl-c1\">uint32_t</span> target_number; <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> target to use</span>\n    <span class=\"pl-c1\">bake_region_id_t</span>\
    \ rid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE region id handle</span>\n\
    \t<span class=\"pl-c1\">bake_target_id_t</span>* bti; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> array of target ids</span>\n\n\t<span class=\"pl-c\"\
    ><span class=\"pl-c\">/*</span> ... setup variables ... <span class=\"pl-c\">*/</span></span>\n\
    \n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Initialize Margo <span\
    \ class=\"pl-c\">*/</span></span>\n\tmid = <span class=\"pl-c1\">margo_init</span>(...,\
    \ MARGO_CLIENT_MODE, <span class=\"pl-c1\">0</span>, -<span class=\"pl-c1\">1</span>);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Lookup the server <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_lookup</span>(mid,\
    \ svr_addr_str, &amp;svr_addr);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span>\
    \ Creates the BAKE client <span class=\"pl-c\">*/</span></span>\n\t<span class=\"\
    pl-c1\">bake_client_init</span>(mid, &amp;bcl);\n\t<span class=\"pl-c\"><span\
    \ class=\"pl-c\">/*</span> Creates the provider handle <span class=\"pl-c\">*/</span></span>\n\
    \t<span class=\"pl-c1\">bake_provider_handle_create</span>(bcl, svr_addr, mplex_id,\
    \ &amp;bph);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Asks the provider\
    \ for up to target_number target ids <span class=\"pl-c\">*/</span></span>\n\t\
    <span class=\"pl-c1\">uint32_t</span> num_targets = <span class=\"pl-c1\">0</span>;\n\
    \tbti = <span class=\"pl-c1\">calloc</span>(num_targets, <span class=\"pl-k\"\
    >sizeof</span>(*bti));\n\t<span class=\"pl-c1\">bake_probe</span>(bph, target_number,\
    \ bti, &amp;num_targets);\n\t<span class=\"pl-k\">if</span>(num_targets &lt; target_number)\
    \ {\n\t\t<span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>Error: provider has only <span class=\"pl-c1\">%d</span>\
    \ storage targets<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>,\
    \ num_targets);\n\t}\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Create\
    \ a region <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">size_t</span>\
    \ size = ...; <span class=\"pl-c\"><span class=\"pl-c\">//</span> size of the\
    \ region to create</span>\n\t<span class=\"pl-c1\">bake_create</span>(bph, bti[target_number-<span\
    \ class=\"pl-c1\">1</span>], size, &amp;rid);\n\t<span class=\"pl-c\"><span class=\"\
    pl-c\">/*</span> Write data into the region at offset 0 <span class=\"pl-c\">*/</span></span>\n\
    \t<span class=\"pl-k\">char</span>* buf = ...;\n\t<span class=\"pl-c1\">bake_write</span>(bph,\
    \ rid, <span class=\"pl-c1\">0</span>, buf, size);\n\t<span class=\"pl-c\"><span\
    \ class=\"pl-c\">/*</span> Make all modifications persistent <span class=\"pl-c\"\
    >*/</span></span>\n\t<span class=\"pl-c1\">bake_persist</span>(bph, rid);\n\t\
    <span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release provider handle <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_provider_handle_release</span>(bph);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release BAKE client <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_client_finalize</span>(bcl);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Cleanup Margo resources\
    \ <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_free</span>(mid,\
    \ svr_addr);\n\t<span class=\"pl-c1\">margo_finalize</span>(mid);\n\t<span class=\"\
    pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n<p>Note that\
    \ a <code>bake_region_id_t</code> object is persistent.  It can be written\n(into\
    \ a file or a socket) and stored or sent to another program. These\nregion ids\
    \ are what uniquely reference a region within a given target.</p>\n<p>The rest\
    \ of the client-side API can be found in <code>bake-client.h</code>.</p>\n<h2><a\
    \ id=\"user-content-provider-api\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #provider-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider\
    \ API</h2>\n<p>The bake-server-daemon source is a good example of how to create\
    \ providers and\nattach storage targets to them. The provider-side API is located\
    \ in\n<em>bake-server.h</em>, and consists of mainly two functions:</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">bake_provider_register</span>(margo_instance_id      \
    \               mid,\n                           <span class=\"pl-c1\">uint16_t</span>\
    \                              provider_id,\n                           <span\
    \ class=\"pl-k\">const</span> <span class=\"pl-k\">struct</span> bake_provider_init_info*\
    \ args,\n                           <span class=\"pl-c1\">bake_provider_t</span>*\
    \                      provider);</pre></div>\n<p>This creates a provider at the\
    \ given provider id using the specified margo\ninstance.  The <code>args</code>\
    \ parameter can be used to modify default settings,\nincluding passing in a fully\
    \ specified json configuration block.  See\n<code>bake-server.h</code> for details.</p>\n\
    <div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">bake_provider_attach_target</span>(<span class=\"pl-c1\"\
    >bake_provider_t</span>   provider,\n                                <span class=\"\
    pl-k\">const</span> <span class=\"pl-k\">char</span>*       target_name,\n   \
    \                             <span class=\"pl-c1\">bake_target_id_t</span>* target_id);</pre></div>\n\
    <p>This makes the provider manage the given storage target.</p>\n<p>Other functions\
    \ are available to create and detach targets from a provider.</p>\n<h2><a id=\"\
    user-content-generic-bake-benchmark\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #generic-bake-benchmark\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Generic Bake benchmark</h2>\n<p>By using <code>--enable-benchmark</code>\
    \ when compiling Bake (or <code>+benchmark</code> when using Spack),\nyou will\
    \ build a <code>bake-benchmark</code> program that can be used as a configurable\
    \ benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure\
    \ Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n<p>The benchmark\
    \ is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a\
    \ server, while non-zero ranks act as clients. The server will not create\na Bake\
    \ target. The Bake target needs to be created (with <code>bake-makepool</code>)\
    \ beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing\
    \ the sequence\nof benchmarks to execute. An example of such a file is located\
    \ in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code>\
    \ array corresponds to a benchmark. The <code>type</code> field indicates\nthe\
    \ type of benchmark to execute. The <code>repetitions</code> field indicates how\
    \ many times the\nbenchmark should be repeated.</p>\n<p>The following table describes\
    \ each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n\
    <th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n\
    </tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to\
    \ the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n\
    <td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for\
    \ each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n\
    <td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's\
    \ buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n\
    <td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n\
    <td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions,\
    \ or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether\
    \ to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n\
    </tbody>\n</table>\n<h2><a id=\"user-content-manual-installation\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#manual-installation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Manual installation</h2>\n<p>BAKE\
    \ depends on the following libraries:</p>\n<ul>\n<li>uuid (install uuid-dev package\
    \ on ubuntu)</li>\n<li>PMDK (see instructions below)</li>\n<li>json-c</li>\n<li>mochi-abt-io</li>\n\
    <li>mochi-margo</li>\n</ul>\n<p>Bake will automatically identify these dependencies\
    \ at configure time using\npkg-config. To compile BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n\
    <li><code>mkdir build</code></li>\n<li><code>cd build</code></li>\n<li><code>../configure\
    \ --prefix=/home/carns/working/install</code></li>\n<li><code>make</code></li>\n\
    </ul>\n<p>If any dependencies are installed in a nonstandard location, then\n\
    modify the configure step listed above to include the following argument:</p>\n\
    <ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1633975151.0
mochi-hpc/mochi-bedrock:
  data_format: 2
  description: Mochi bootstrapping service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bedrock
  latest_release: v0.5.2
  readme: '<h1><a id="user-content-bedrock" class="anchor" aria-hidden="true" href="#bedrock"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bedrock</h1>

    <p>Bedrock is Mochi''s service bootstrapping mechanism.

    For documentations and tutorials, please see

    <a href="https://mochi.readthedocs.io/en/latest/bedrock.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640527359.0
mochi-hpc/mochi-doc:
  data_format: 2
  description: Documentations and tutorials for Margo, Thallium, Argobots, Mercury,
    and other Mochi libraries.
  filenames:
  - code/spack.yaml
  full_name: mochi-hpc/mochi-doc
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"><img
    src="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"
    alt="build" style="max-width: 100%;"></a></p>

    <h1><a id="user-content-mochi-documentation" class="anchor" aria-hidden="true"
    href="#mochi-documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    documentation</h1>

    <p>This repository contains a Sphinx-based documentation

    for the Mochi libraries: Margo, Thallium, Argobots, Mercury,

    ABT-IO, and SSG, as well as corresponding code examples.</p>

    <h2><a id="user-content-building-the-documentation" class="anchor" aria-hidden="true"
    href="#building-the-documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the documentation</h2>

    <p>To build and/or contribute to this documentation, you must have a Sphinx and

    a few related extensions installed.  These can be installed as follows using

    Python''s <code>pip</code>.</p>

    <pre><code>pip install sphinx

    pip install sphinx_rtd_theme

    pip install sphinx_copybutton

    pip install recommonmark

    pip install breathe

    </code></pre>

    <p>You must also install the <code>doxygen</code> documentation system.  This
    is likely

    available in your platform''s primary package manager.  For example on Ubuntu:</p>

    <pre><code>sudo apt install doxygen

    </code></pre>

    <p>Once you have these dependencies installed, clone this

    repository and cd into it. You can change the documentation

    by editing the files in the source subdirectory (these files

    use the .rst format). You can build the documentation

    using the following command.</p>

    <pre><code>cd docs

    make html

    </code></pre>

    <p>And check the result by opening the <code>build/html/index.html</code> page

    that has been created in the docs directory.</p>

    <h2><a id="user-content-building-the-code-examples" class="anchor" aria-hidden="true"
    href="#building-the-code-examples"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the code examples</h2>

    <p>To build the code, you will need spack and the

    <a href="https://github.com/mochi-hpc/mochi-spack-packages">mochi repo</a> setup.</p>

    <pre><code>cd code

    spack env create mochi-doc-env spack.yaml

    spack env activate mochi-doc-env

    spack install

    mkdir build

    cd build

    cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc

    make

    </code></pre>

    '
  stargazers_count: 4
  subscribers_count: 4
  topics: []
  updated_at: 1668505847.0
mochi-hpc/mochi-remi:
  data_format: 2
  description: Mochi's REsource Migration Interface
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-remi
  latest_release: v0.3.2
  readme: '<h1><a id="user-content-resource-migration-interface" class="anchor" aria-hidden="true"
    href="#resource-migration-interface"><span aria-hidden="true" class="octicon octicon-link"></span></a>REsource
    Migration Interface</h1>

    <p>REMI is a Mochi microservice designed to handle the migration of sets of files

    from a node to another. It uses RDMA and memory mapping to efficiently transfer

    potentially large groups of files at once.</p>

    <h3><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>Just like all Mochi services, REMI can be installed using Spack. Once you have

    clone the <a href="https://xgitlab.cels.anl.gov/sds/sds-repo" rel="nofollow">sds-repo</a>
    package repository

    and added it to your spack installation, you can install REMI using the following

    command:</p>

    <pre><code>spack install mochi-remi

    </code></pre>

    <p>REMI depends on <a href="https://xgitlab.cels.anl.gov/sds/thallium/" rel="nofollow">Thallium</a>,
    which

    Spack will install (if needed) along with Thallium''s own dependencies. It also

    depends on Bedrock, unless the <code>bedrock</code> variant is disable when installing

    with Spack (i.e. passing <code>~bedrock</code> to the above command).</p>

    <h3><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h3>

    <p>REMI works with <em>filesets</em>. A fileset consists of a root directory and

    a set of file paths relative to this root directory. A fileset is also characterized

    by the name of its <em>migration class</em>.</p>

    <p>REMI clients create filesets to group files corresponding to a particular resource

    (e.g. a database''s files). They can then request the migration of fileset to

    a target provider.</p>

    <p>Uppon receiving a request for migration, a provider will recreate the tree
    of

    directories required to receive the files of the fileset, create the files,

    mmap them into memory, and issue an RDMA pull operation from the client''s files

    (themselves mmap-ed into the client''s memory).</p>

    <p>Following successful migration, the provider will call a user-supplied callback

    corresponding to the particular fileset''s migration class.</p>

    <p>For an example of code, please see the <a href="examples">examples</a>

    folder in the source tree.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975455.0
mochi-hpc/thallium-microservice-template:
  data_format: 2
  description: Template for a thallium-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/thallium-microservice-template
  latest_release: null
  readme: '<h1><a id="user-content-thallium-microservice-template" class="anchor"
    aria-hidden="true" href="#thallium-microservice-template"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Thallium Microservice Template</h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Thallium.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/02_thallium.html" rel="nofollow">here</a>.</p>

    <p>To use this template:</p>

    <ul>

    <li>Click on the green "Use this template" button at the top.</li>

    <li>Give a name to your project.</li>

    <li>Once your project repository is created, go to Settings &gt; Actions &gt;
    General and give "Read and write permissions" under <em>Workflow permissions</em>.</li>

    <li>Finally, edit the initial-setup.json file and push the changes to your repo.</li>

    </ul>

    <p>Editing the initial-setup.json file with trigger a github action that will

    cleanup your repository and rename files, namespaces, functions, etc. according

    to the name of your service and the resources it manages.</p>

    <p>Enjoy working with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1649080284.0
pdidev/test_env:
  data_format: 2
  description: Testing environment for PDI
  filenames:
  - spack/1b-spack/spack.yaml
  full_name: pdidev/test_env
  latest_release: null
  readme: '<h1><a id="user-content-docker-images" class="anchor" aria-hidden="true"
    href="#docker-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Docker
    images:</h1>

    <p>A set of related Docker images to build and test PDI.</p>

    <p>We provide images based on:</p>

    <ul>

    <li>Spack recipes,</li>

    <li>Binary packages.</li>

    </ul>

    <h2><a id="user-content-spack-based-images" class="anchor" aria-hidden="true"
    href="#spack-based-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack-based
    images</h2>

    <p>These images are based on a minimal Ubuntu 18.08, with spack and all dependencies
    installed through

    spack.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/spack/${deps_version}/${compiler}/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>deps_version</code>:

    <ul>

    <li>

    <code>oldest</code>: dependencies use the oldest versions supported by PDI,</li>

    <li>

    <code>latest</code>: dependencies use the latest versions available in spack at
    the time of generation,</li>

    </ul>

    </li>

    <li>

    <code>compiler</code>:

    <ul>

    <li>

    <code>gcc</code>:   using GCC compiler,</li>

    <li>

    <code>clang</code>: using clang for C/C++ and gfortran for Fortran,</li>

    </ul>

    </li>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image.</li>

    </ul>

    </li>

    </ul>

    <h2><a id="user-content-binary-package-based-images" class="anchor" aria-hidden="true"
    href="#binary-package-based-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binary
    package based images</h2>

    <p>These images are based on Ubuntu 18.08, with all dependencies installed through
    packages.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/ubuntu/bionic/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>mpich</code>: using mpich implementation of MPI,</li>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image,</li>

    <li>

    <code>pdi</code>: PDI is included in the image.</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1641653805.0
range3/chfs-containers:
  data_format: 2
  description: null
  filenames:
  - spack/envs/chfs-master/spack.yaml
  full_name: range3/chfs-containers
  latest_release: null
  readme: '<h1><a id="user-content-chfs-containers" class="anchor" aria-hidden="true"
    href="#chfs-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>chfs-containers</h1>

    <h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>example</h2>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    explicitly pull the latest chfs image </span>

    docker pull range3/chfs:master


    git clone https://github.com/range3/chfs-containers

    <span class="pl-c1">cd</span> chfs-containers


    <span class="pl-c"><span class="pl-c">#</span> start servers</span>

    docker-compose up -d


    <span class="pl-c"><span class="pl-c">#</span> start another container for client</span>

    docker run -it --rm --network chfs_net --privileged range3/chfs:master bash

    <span class="pl-c"><span class="pl-c">#</span> set CHFS_SERVER env</span>

    <span class="pl-k">export</span> CHFS_SERVER=<span class="pl-s"><span class="pl-pds">$(</span>chlist
    -c -s ofi+sockets://172.30.0.3:50000<span class="pl-pds">)</span></span>


    <span class="pl-c"><span class="pl-c">#</span> list chfs servers</span>

    chlist


    <span class="pl-c"><span class="pl-c">#</span> mount chfs via FUSE</span>

    mkdir /tmp/m

    chmkdir /tmp/m

    chfuse -o direct_io,modules=subdir,subdir=<span class="pl-s"><span class="pl-pds">"</span>/tmp/m<span
    class="pl-pds">"</span></span> /tmp/m


    <span class="pl-c"><span class="pl-c">#</span> &lt;ctrl-D&gt;</span>

    <span class="pl-c"><span class="pl-c">#</span> the client container is removed</span>


    <span class="pl-c"><span class="pl-c">#</span> stop and remove server containers</span>

    docker-compose down</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652094301.0
robertu94/libpressio_opt:
  data_format: 2
  description: A optimizing autotuing plugin for libpressio
  filenames:
  - spack.yaml
  full_name: robertu94/libpressio_opt
  latest_release: 0.11.0
  readme: "<h1><a id=\"user-content-libpressioopt\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#libpressioopt\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>LibPressioOpt</h1>\n<p>LibPressioOpt provides a plugin for libpressio\
    \ that provides optimization routines to configure compressors.</p>\n<h2><a id=\"\
    user-content-using-libpressioopt\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #using-libpressioopt\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Using LibPressioOpt</h2>\n<p>Please see <code>./test/opt_example_c.c</code>\
    \ for an example of the API.</p>\n<h2><a id=\"user-content-getting-started\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#getting-started\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>LibPressioOpt\
    \ provides three new major features on top of LibPressio:</p>\n<ul>\n<li>the <code>opt</code>\
    \ meta compressor which allows for searching for the optimal configuration of\
    \ the compressor</li>\n<li>\n<code>pressio_search</code> modules which allow for\
    \ searching for an optimal set of configuration of parameters</li>\n<li>\n<code>pressio_search_metrics</code>\
    \ modules which compute properties of the search process itself</li>\n</ul>\n\
    <p>See [Opt Configuration](@ref optoptions) for more information on the configuration\
    \ options.</p>\n<h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Dependencies</h2>\n<ul>\n<li>\n<code>cmake</code> version <code>3.13</code>\
    \ or later</li>\n<li>either:\n<ul>\n<li>\n<code>gcc-8.3.0</code> or later</li>\n\
    <li>\n<code>clang-9.0.0</code> or later</li>\n</ul>\n</li>\n<li>LibDistributed\
    \ version 0.0.8 or later</li>\n<li>LibPressio version 0.40.1 or later</li>\n<li>An\
    \ MPI implementation supporting MPI-3 or later.  Tested on OpenMPI 4.0.2</li>\n\
    <li>Dlib after commit <code>95271cfe43ffceeadeb1a73bf033794b501e86f4</code> (after\
    \ release 19.21)</li>\n</ul>\n<h2><a id=\"user-content-installing-libpressioopt-using-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-libpressioopt-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ LibPressioOpt using Spack</h2>\n<p>LibPressioOpt can be built using <a href=\"\
    https://github.com/spack/spack/\">spack</a>.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>git clone https://github.com/robertu94/spack_packages robertu94_packages\n\
    spack repo add robertu94_packages\nspack install libpressio-opt</pre></div>\n\
    <p>You can substantially reduce install times by not installing ImageMagick and\
    \ PETSc support for libpressio.</p>\n<pre><code>spack install libpressio-opt ^libpressio~magick~petsc\n\
    </code></pre>\n<h2><a id=\"user-content-building-and-installing-libpressioopt-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#building-and-installing-libpressioopt-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ and Installing LibPressioOpt Manually</h2>\n<p>LibPressioOpt uses CMake to configure\
    \ build options.  See CMake documentation to see how to configure options</p>\n\
    <ul>\n<li>\n<code>CMAKE_INSTALL_PREFIX</code> - install the library to a local\
    \ directory prefix</li>\n<li>\n<code>BUILD_DOCS</code> - build the project documentation</li>\n\
    <li>\n<code>BUILD_TESTING</code> - build the test cases</li>\n</ul>\n<div class=\"\
    highlight highlight-source-shell\"><pre>BUILD_DIR=build\nmkdir <span class=\"\
    pl-smi\">$BUILD_DIR</span>\n<span class=\"pl-c1\">cd</span> <span class=\"pl-smi\"\
    >$BUILD_DIR</span>\ncmake ..\nmake\nmake <span class=\"pl-c1\">test</span>\nmake\
    \ install</pre></div>\n<p>To build the documentation:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>BUILD_DIR=build\nmkdir <span class=\"pl-smi\"\
    >$BUILD_DIR</span>\n<span class=\"pl-c1\">cd</span> <span class=\"pl-smi\">$BUILD_DIR</span>\n\
    cmake .. -DBUILD_DOCS=ON\nmake docs\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> the html docs can be found in $BUILD_DIR/html/index.html</span>\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> the man pages can be found in $BUILD_DIR/man/</span></pre></div>\n\
    <h2><a id=\"user-content-stability\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #stability\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Stability</h2>\n\
    <p>As of version 1.0.0, LibPressioOpt will follow the following API stability\
    \ guidelines:</p>\n<ul>\n<li>The functions defined in files in <code>./include</code>\
    \ are to considered stable</li>\n<li>The functions defined in files or its subdirectories\
    \ in <code>./include/libpressio_opt_ext/</code> considered unstable.</li>\n</ul>\n\
    <p>Stable means:</p>\n<ul>\n<li>New APIs may be introduced with the increase of\
    \ the minor version number.</li>\n<li>APIs may gain additional overloads for C++\
    \ compatible interfaces with an increase in the minor version number.</li>\n<li>An\
    \ API may change the number or type of parameters with an increase in the major\
    \ version number.</li>\n<li>An API may be removed with the change of the major\
    \ version number</li>\n</ul>\n<p>Unstable means:</p>\n<ul>\n<li>The API may change\
    \ for any reason with the increase of the minor version number</li>\n</ul>\n<p>Additionally,\
    \ the performance of functions, memory usage patterns may change for both stable\
    \ and unstable code with the increase of the patch version.</p>\n<h2><a id=\"\
    user-content-bug-reports\" class=\"anchor\" aria-hidden=\"true\" href=\"#bug-reports\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bug Reports</h2>\n\
    <p>Please files bugs to the Github Issues page on the robertu94 github repository.</p>\n\
    <p>Please read this post on <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\"\
    \ rel=\"nofollow\">how to file a good bug report</a>.\_ After reading this post,\
    \ please provide the following information specific to LibPressioOpt:</p>\n<ul>\n\
    <li>Your OS version and distribution information, usually this can be found in\
    \ <code>/etc/os-release</code>\n</li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n\
    </li>\n<li>the version of each of LibPressioOpts's dependencies listed in the\
    \ README that you have installed. Where possible, please provide the commit hashes.</li>\n\
    </ul>\n<h2><a id=\"user-content-cite\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #cite\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Cite</h2>\n\
    <p>If you find this work useful, please consider citing</p>\n<div class=\"highlight\
    \ highlight-text-bibtex\"><pre><span class=\"pl-k\">@article</span>{<span class=\"\
    pl-en\">underwood2022optzconfig</span>,\n  <span class=\"pl-s\">title</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>OptZConfig: Efficient Parallel\
    \ Optimization of Lossy Compression Configuration<span class=\"pl-pds\">}</span></span>,\n\
    \  <span class=\"pl-s\">author</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>Underwood, Robert and Calhoun, Jon C and Di, Sheng and Apon, Amy and\
    \ Cappello, Franck<span class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\"\
    >journal</span>=<span class=\"pl-s\"><span class=\"pl-pds\">{</span>IEEE Transactions\
    \ on Parallel and Distributed Systems<span class=\"pl-pds\">}</span></span>,\n\
    \  <span class=\"pl-s\">year</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>2022<span class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\">publisher</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>IEEE<span class=\"pl-pds\">}</span></span>\n\
    }</pre></div>\n<p>or if you only optimize compression ratio</p>\n<div class=\"\
    highlight highlight-text-bibtex\"><pre><span class=\"pl-k\">@inproceedings</span>{<span\
    \ class=\"pl-en\">underwood2020fraz</span>,\n  <span class=\"pl-s\">title</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>Fraz: A generic high-fidelity\
    \ fixed-ratio lossy compression framework for scientific floating-point data<span\
    \ class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\">author</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>Underwood, Robert and Di, Sheng\
    \ and Calhoun, Jon C and Cappello, Franck<span class=\"pl-pds\">}</span></span>,\n\
    \  <span class=\"pl-s\">booktitle</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>2020 IEEE International Parallel and Distributed Processing Symposium\
    \ (IPDPS)<span class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\">pages</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>567--577<span class=\"pl-pds\"\
    >}</span></span>,\n  <span class=\"pl-s\">year</span>=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">{</span>2020<span class=\"pl-pds\">}</span></span>,\n  <span\
    \ class=\"pl-s\">organization</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>IEEE<span class=\"pl-pds\">}</span></span>\n}\n</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1636674438.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<h1><a id="user-content-roibin-sz-experiments" class="anchor" aria-hidden="true"
    href="#roibin-sz-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>ROIBIN-SZ
    Experiments</h1>

    <h2><a id="user-content-system-information" class="anchor" aria-hidden="true"
    href="#system-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>System
    Information</h2>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <h2><a id="user-content-where-is-the-implementation-of-roibin-sz3" class="anchor"
    aria-hidden="true" href="#where-is-the-implementation-of-roibin-sz3"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Where is the implementation of ROIBIN-SZ3?</h2>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <h3><a id="user-content-obtaining-data" class="anchor" aria-hidden="true" href="#obtaining-data"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining Data</h3>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <h3><a id="user-content-quality-assessment" class="anchor" aria-hidden="true"
    href="#quality-assessment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quality
    Assessment</h3>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <h3><a id="user-content-container-install-for-ease-of-setup" class="anchor" aria-hidden="true"
    href="#container-install-for-ease-of-setup"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Container Install (for ease of setup)</h3>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <h4><a id="user-content-singularity" class="anchor" aria-hidden="true" href="#singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h4>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <h4><a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h4>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <h3><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    href="#building-the-container"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <h3><a id="user-content-manual-install-for-scale" class="anchor" aria-hidden="true"
    href="#manual-install-for-scale"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    Install (for scale)</h3>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <h2><a id="user-content-running-the-experiments" class="anchor" aria-hidden="true"
    href="#running-the-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Experiments</h2>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <h3><a id="user-content-example-output" class="anchor" aria-hidden="true" href="#example-output"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example Output</h3>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <h2><a id="user-content-results-for-figures" class="anchor" aria-hidden="true"
    href="#results-for-figures"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results
    for Figures</h2>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1648861627.0
scifihpc/scibuilder:
  data_format: 2
  description: New build system for building scientific software.
  filenames:
  - examples/build-image/spack_example_hy-alma8/spack.yaml
  - examples/without-image/spack_example_ubuntu22.04/spack.yaml
  full_name: scifihpc/scibuilder
  latest_release: null
  readme: "<h1><a id=\"user-content-scibuilder\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#scibuilder\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Scibuilder</h1>\n<p>Scibuilder is a tool for helping with automated\
    \ builds</p>\n<h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>Scibuilder is a Python module and it needs an\
    \ environment with various packages.</p>\n<p>We recommend using <code>mamba</code>\
    \ for faster installation.\n<a href=\"https://github.com/conda-forge/miniforge#install\"\
    >Mambaforge</a> is an excellent way\nof getting <code>mamba</code>.</p>\n<p>Creating\
    \ environment:</p>\n<div class=\"highlight highlight-source-shell\"><pre>mamba\
    \ env create --file environment.yml\n<span class=\"pl-c1\">source</span> activate\
    \ scibuilder</pre></div>\n<h2><a id=\"user-content-running-scibuilder-example\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-scibuilder-example\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running scibuilder\
    \ example</h2>\n<h3><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h3>\n<p>This example build works on Ubuntu 22.04. It installs\
    \ cmake as an example.</p>\n<div class=\"highlight highlight-source-shell\"><pre>git\
    \ clone https://github.com/spack/spack.git\n<span class=\"pl-c1\">.</span> spack/share/spack/setup-env.sh\n\
    python -m scibuilder spack build examples/without-image/spackbuilder_example.yml</pre></div>\n\
    <h3><a id=\"user-content-mamba\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #mamba\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mamba</h3>\n\
    <p>This example build will work on any linux system. It creates two conda environments:\n\
    one with gpu-enabled packgages and one without.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python -m scibuilder mamba build examples/without-image/mambabuilder_example.yml</pre></div>\n\
    <h2><a id=\"user-content-scibuilder-build-image\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#scibuilder-build-image\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>scibuilder-build-image</h2>\n<p>Scibuilder can be\
    \ run in a docker/podman images.</p>\n<p>See image <a href=\"dockerfiles/scibuilder-build-image/README.md\"\
    >README.md</a> for more information.</p>\n<h2><a id=\"user-content-configuring-builds\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-builds\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Configuring builds</h2>\n<h3><a\
    \ id=\"user-content-spack-1\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-1\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>Spack builds are configured by creating a YAML-file that describes what environments\
    \ we\nwant to build and the compilers we want to use for building them.</p>\n\
    <p>Let's look at <a href=\"examples/without-image/spackbuilder_example.yml\">examples/without-image/spackbuilder_example.yml</a>:</p>\n\
    <div class=\"highlight highlight-source-yaml\"><pre><span class=\"pl-ent\">environments</span>:\n\
    \  - <span class=\"pl-ent\">name</span>: <span class=\"pl-s\">spack_example</span>\n\
    \    <span class=\"pl-ent\">tags</span>:\n      - <span class=\"pl-s\">spack</span>\n\
    \      - <span class=\"pl-s\">main</span>\n    <span class=\"pl-ent\">environment_file</span>:\
    \ <span class=\"pl-s\">examples/without-image/spack_example_ubuntu22.04/spack.yaml</span>\n\
    \    <span class=\"pl-ent\">system_compiler</span>: <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>gcc@11.3.0<span class=\"pl-pds\">\"</span></span>\n\
    \    <span class=\"pl-ent\">compilers</span>:\n      - <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>gcc@11.3.0<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>The list <code>environments</code> consist of multiple independent build with\
    \ the following\nattributes:</p>\n<ul>\n<li>\n<code>name</code> - Name of the\
    \ environment</li>\n<li>\n<code>tags</code> - List of arbitrary tags that can\
    \ be used to limit the builder to only these\nbuilds via the <code>--tags=TAGS</code>-parameter.</li>\n\
    <li>\n<code>environmnet_file</code> - A spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">environement file</a>\nthat contains information on what packages\
    \ we want to install and where we want to install them.</li>\n<li>\n<code>system_compiler</code>\
    \ - A compiler present in the system that the builder will try to locate for\n\
    spack to use as an initial compiler.</li>\n<li>\n<code>compilers</code>: List\
    \ of compilers that spack will try to locate and build with the system compiler\n\
    before building the environment in full.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1678697646.0
scs-lab/ChronoLog_FrontEnd:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: scs-lab/ChronoLog_FrontEnd
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1680281813.0
sundials-codes/sundials-manyvector-demo:
  data_format: 2
  description: Demonstration application for Multirate+ManyVector capabilities
  filenames:
  - docker/spack-latest.yaml
  - docker/spack-develop.yaml
  - spack/spack-summit.yaml
  full_name: sundials-codes/sundials-manyvector-demo
  latest_release: null
  readme: "<h1><a id=\"user-content-sundials-manyvectormultirate-demonstration-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#sundials-manyvectormultirate-demonstration-code\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SUNDIALS\
    \ ManyVector+Multirate Demonstration Code</h1>\n<p>[Note: this project is in active\
    \ development.]</p>\n<p>This is a <a href=\"https://github.com/LLNL/sundials\"\
    >SUNDIALS</a>-based demonstration\napplication to assess and demonstrate the large-scale\
    \ parallel performance of\nnew capabilities that have been added to SUNDIALS in\
    \ recent years. Namely:</p>\n<ol>\n<li>\n<p>The new SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html#the-nvector-mpimanyvector-module\"\
    \ rel=\"nofollow\">MPIManyVector</a>\nimplementation, that enables flexibility\
    \ in how a solution data is\npartitioned across computational resources e.g.,\
    \ CPUs and GPUs.</p>\n</li>\n<li>\n<p>The new <a href=\"https://sundials.readthedocs.io/en/latest/arkode/index.html\"\
    \ rel=\"nofollow\">ARKODE</a>\nmultirate integration module, MRIStep, allowing\
    \ high-order accurate\ncalculations that subcycle \"fast\" processes within \"\
    slow\" ones.</p>\n</li>\n<li>\n<p>The new flexible SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/sunlinsol/index.html\"\
    \ rel=\"nofollow\">SUNLinearSolver</a>\ninterfaces, to enable streamlined use\
    \ of problem specific and scalable\nlinear solver libraries e.g., SuiteSparse\
    \ and MAGMA.</p>\n</li>\n</ol>\n<h2><a id=\"user-content-model-equations\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#model-equations\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Model Equations</h2>\n<p>This code\
    \ simulates a 3D nonlinear inviscid compressible Euler equation with\nadvection\
    \ and reaction of chemical species,</p>\n<p>$$w_t = -\\nabla\\cdot F(w) + G(X,t,w),$$</p>\n\
    <p>for independent variables $(X,t) = (x,y,z,t) \\in \\Omega \\times [t_0, t_f]$\n\
    where the spatial domain is a three-dimensional cube,\n$\\Omega = [x_l, x_r] \\\
    times [y_l, y_r] \\times [z_l, z_r]$.</p>\n<p>The differential equation is completed\
    \ using initial condition\n$w(X,t_0) = w_0(X)$ and face-specific boundary conditions\
    \ may be periodic (0),\nhomogeneous Neumann (1), homogeneous Dirichlet (2), or\
    \ reflecting (3) under the\nrestriction that if any boundary is set to \"periodic\"\
    \ then the opposite face\nmust also indicate a periodic condition.</p>\n<p>The\
    \ system state vector $w$ is</p>\n<p>$$w = \\begin{bmatrix} \\rho &amp; \\rho\
    \ v_x &amp; \\rho v_y &amp; \\rho v_z &amp; e_t &amp; \\mathbf{c} \\end{bmatrix}^T\
    \ = \\begin{bmatrix} \\rho &amp; m_x &amp; m_y &amp; m_z &amp; e_t &amp; \\mathbf{c}\
    \ \\end{bmatrix}^T$$</p>\n<p>corresponding to the density, momentum in the x,\
    \ y, and z directions, total\nenergy per unit volume, and any number of chemical\
    \ densities\n$\\mathbf{c}\\in\\mathbb{R}^{nchem}$ that are advected along with\
    \ the fluid. The\nfluxes are given by</p>\n<p>$$F_x(w) = \\begin{bmatrix} \\rho\
    \ v_x &amp; \\rho v_x^2 + p &amp; \\rho v_x v_y &amp; \\rho v_x v_z &amp; v_x\
    \ (e_t+p) &amp; \\mathbf{c} v_x \\end{bmatrix}^T,$$</p>\n<p>$$F_y(w) = \\begin{bmatrix}\
    \ \\rho v_y &amp; \\rho v_x v_y &amp; \\rho v_y^2 + p &amp; \\rho v_y v_z &amp;\
    \ v_y (e_t+p) &amp; \\mathbf{c} v_y \\end{bmatrix}^T,$$</p>\n<p>$$F_z(w) = \\\
    begin{bmatrix} \\rho v_z &amp; \\rho v_x v_z &amp; \\rho v_y v_z &amp; \\rho v_z^2\
    \ + p &amp; v_z (e_t+p) &amp; \\mathbf{c} v_z \\end{bmatrix}^T.$$</p>\n<p>The\
    \ external force $G(X,t,w)$ is test-problem-dependent, and the ideal gas\nequation\
    \ of state gives $p = \\frac{R}{c_v}(e_t - \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2))$\n\
    and $e_t = \\frac{pc_v}{R} + \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$\nor equivalently,\
    \ $p = (\\gamma-1) (e_t - \\frac{\\rho}{2} (v_x^2 + v_y^2 + v_z^2))$\nand $e_t\
    \ = \\frac{p}{\\gamma - 1}\\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$.</p>\n<p>We\
    \ have the physical parameters:</p>\n<ul>\n<li>\n<p>$R$ is the specific ideal\
    \ gas constant (287.14 J/kg/K),</p>\n</li>\n<li>\n<p>$c_v$ is the specific heat\
    \ capacity at constant volume (717.5 J/kg/K),</p>\n</li>\n<li>\n<p>$\\gamma =\
    \ c_p/c_v = 1 + R/c_v$ is the ratio of specific heats (1.4),</p>\n</li>\n</ul>\n\
    <p>corresponding to air (predominantly an ideal diatomic gas). The speed\nof sound\
    \ in the gas is then given by $c = \\sqrt{\\dfrac{\\gamma p}{\\rho}}$.</p>\n<p>The\
    \ fluid variables above are non-dimensionalized; in standard SI units\nthese would\
    \ be:</p>\n<ul>\n<li>\n<p>$[\\rho] = kg / m^3$,</p>\n</li>\n<li>\n<p>$[v_x] =\
    \ [v_y] = [v_z] = m/s$, which implies $[m_x] = [m_y] = [m_z] = kg / m^2 / s$</p>\n\
    </li>\n<li>\n<p>$[e_t] = kg / m / s^2$, and</p>\n</li>\n<li>\n<p>$[\\mathbf{c}_i]\
    \ = kg / m^3$</p>\n</li>\n</ul>\n<p>Note: the fluid portion of the description\
    \ above follows the presentation\n<a href=\"https://www.theoretical-physics.net/dev/fluid-dynamics/euler.html\"\
    \ rel=\"nofollow\">here</a>\nin sections 7.3.1 - 7.3.3.</p>\n<h2><a id=\"user-content-discretization\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#discretization\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Discretization</h2>\n<p>We discretize\
    \ this problem using the method of lines, where we first semi-discretize\nin space\
    \ using a regular finite volume grid with dimensions <code>nx</code> x <code>ny</code>\
    \ x <code>nz</code>, with\nfluxes at cell faces calculated using a 5th-order FD-WENO\
    \ reconstruction.  MPI\nparallelization is achieved using a standard 3D domain\
    \ decomposition, using <code>nprocs</code>\nMPI ranks, with layout <code>npx</code>\
    \ x <code>npy</code> x <code>npz</code> defined automatically via the\n<code>MPI_Dims_create</code>\
    \ utility routine.  The minimum size for any dimension is 3, so\nto run a two-dimensional\
    \ test in the yz-plane, one could specify <code>nx = 3</code> and\n<code>ny =\
    \ nz = 200</code>.  When run in parallel, only \"active\" spatial dimensions (those\n\
    with extent greater than 3) will be parallelized.</p>\n<p>The fluid fields $\\\
    rho$, $m_x$, $m_y$, $m_z$, and $e_t$ are stored in separate serial\n<code>N_Vector</code>\
    \ objects on each MPI rank. The chemical species at all spatial locations over\n\
    each MPI rank are collocated into a single serial or RAJA <code>N_Vector</code>\
    \ object when\nrunning on the CPU or GPU respectively. The five fluid vectors\
    \ and the chemical\nspecies vector are combined together to form the full \"solution\"\
    \ vector $w$ using\nthe <code>MPIManyVector</code> <code>N_Vector</code> module.</p>\n\
    <p>After spatial semi-discretization, we are faced with a large IVP system,</p>\n\
    <p>$$w'(t) = f_1(w) + f_2(w), \\quad w(t_0)=w_0,$$</p>\n<p>where $f_1(w)$ and\
    \ $f_2(w)$ contain the spatially discretized forms of\n$-\\nabla\\cdot F(w)$ and\
    \ $G(X,t,w)$, respectively.</p>\n<p>For non-reactive flows, the resulting initial-value\
    \ problem is evolved in time\nusing an adaptive step explicit Runge-Kutta method\
    \ from the ARKStep module in\nARKODE. For problems involving (typically stiff)\
    \ chemical reactions, the problem\nmay be solved using one of two approaches.</p>\n\
    <ol>\n<li>\n<p>It may be treated as a multirate initial-value problem, that is\
    \ solved using\nthe MRIStep module in ARKODE, wherein the gas dynamics equations\
    \ are evolved\nexplicitly at the slow time scale, while the chemical kinetics\
    \ are evolved\nat a faster time scale using a temporally-adaptive, diagonally-implicit\n\
    Runge-Kutta method from the ARKStep module.</p>\n</li>\n<li>\n<p>It may be treated\
    \ using mixed implicit-explicit (IMEX) methods at a single\ntime scale.  Here,\
    \ the gas dynamics equations are treated explicitly, while\nthe chemical kinetics\
    \ are treated implicitly, using an additive Runge-Kutta\nmethod from the ARKStep\
    \ module.</p>\n</li>\n</ol>\n<p>For (1) we use SUNDIALS' modified Newton solver\
    \ to handle the global nonlinear\nalgebraic systems arising at each implicit stage\
    \ of each time step.  Since only\n$f_2$ is treated implicitly and the reactions\
    \ are purely local in space, the\nNewton linear systems are block-diagonal. As\
    \ such, we provide a custom\n<code>SUNLinearSolver</code> implementation that\
    \ solves each MPI rank-local linear system\nindependently. The portion of the\
    \ Jacobian matrix on each rank is itself\nblock-diagonal. We further leverage\
    \ this structure by solving each rank-local\nlinear system using either the sparse\
    \ KLU (CPU-only) or batched dense MAGMA\n(GPU-enabled) SUNDIALS <code>SUNLinearSolver</code>\
    \ implementations.</p>\n<p>The multirate approach (2) can leverage the structure\
    \ of $f_2$ at a higher\nlevel. Since the MRI method applied to this problem evolves\
    \ \"fast\" sub-problems\nof the form</p>\n<p>$$v'(t) = f_2(t,v) + r_i(t), \\quad\
    \ i=2,\\ldots,s,$$</p>\n<p>and all MPI communication necessary to construct the\
    \ forcing functions, $r_i(t)$,\nhas already been performed, each sub-problem consists\
    \ of <code>nx</code> x <code>ny</code> x <code>nz</code>\nspatially-decoupled\
    \ fast IVPs. We construct a custom fast integrator that groups\nall the independent\
    \ fast IVPs on an MPI rank together as a single system evolved\nusing a rank-local\
    \ ARKStep instance.  The code for this custom integrator itself\nis minimal, primarily\
    \ consisting of steps to access the local subvectors in $w$\non a given MPI rank\
    \ and wrapping them in MPI-unaware ManyVectors provided to the\nlocal ARKStep\
    \ instance. The collection of independent local IVPs also leads to a\nblock diagonal\
    \ Jacobian, and we again utilize the <code>SUNLinearSolver</code> modules listed\n\
    above for linear systems that arise within the modified Newton iteration.</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The following steps describe how to build the\
    \ demonstration code in a Linux or\nOS X environment.</p>\n<h3><a id=\"user-content-gettting-the-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#gettting-the-code\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Gettting the Code</h3>\n<p>To\
    \ obtain the code, clone this repository with Git:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  git clone https://github.com/sundials-codes/sundials-manyvector-demo.git</pre></div>\n\
    <h3><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Requirements</h3>\n<p>To compile the code you will need:</p>\n<ul>\n\
    <li>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\">CMake</a> 3.20 or newer</p>\n\
    </li>\n<li>\n<p>modern C and C++ compilers</p>\n</li>\n<li>\n<p>the NVIDIA <a\
    \ href=\"https://developer.nvidia.com/cuda-toolkit\" rel=\"nofollow\">CUDA Toolkit</a>\
    \ (when\nusing the CUDA backend)</p>\n</li>\n<li>\n<p>an MPI library e.g., <a\
    \ href=\"https://www.open-mpi.org/\" rel=\"nofollow\">OpenMPI</a>,\n<a href=\"\
    https://www.mpich.org/\" rel=\"nofollow\">MPICH</a>, etc.</p>\n</li>\n<li>\n<p>the\
    \ <a href=\"https://www.hdfgroup.org/\" rel=\"nofollow\">HDF5</a> high-performance\
    \ data management and\nstorage suite</p>\n</li>\n<li>\n<p>the <a href=\"https://github.com/LLNL/RAJA\"\
    >RAJA</a> performance portability library</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://computing.llnl.gov/projects/sundials\" rel=\"nofollow\">SUNDIALS</a> library\
    \ of time\nintegrators and nonlinear solvers</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://people.engr.tamu.edu/davis/suitesparse.html\" rel=\"nofollow\">SuiteSparse</a>\
    \ library\nof sparse direct linear solvers (when using a CPU backend)</p>\n</li>\n\
    <li>\n<p>the <a href=\"https://icl.utk.edu/magma/\" rel=\"nofollow\">MAGMA</a>\
    \ dense linear solver library (when\nusing a GPU backend)</p>\n</li>\n</ul>\n\
    <h4><a id=\"user-content-installing-dependencies-with-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#installing-dependencies-with-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing Dependencies with\
    \ Spack</h4>\n<p>Many of the above dependencies can be installed using the\n<a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> package manager. For information\
    \ on using Spack see\nthe getting started <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#getting-started\"\
    \ rel=\"nofollow\">guide</a>.\nThe instructions below were formulated from Spack\
    \ v0.19.0, although newer versions should also work.</p>\n<p>Once Spack is setup,\
    \ we recommend creating a Spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html#\"\
    \ rel=\"nofollow\">environment</a>\nwith the required dependencies e.g., on a\
    \ system with Pascal GPUs and CUDA\n11.4.2 installed:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack env create --with-view <span class=\"pl-k\"\
    >~</span>/views/sundials-demo sundials-demo\nspack env activate sundials-demo\n\
    spack add sundials@6.2.0 +openmp +mpi +logging-mpi +klu +magma +raja +cuda cuda_arch=60\
    \ ^cuda@11.4.2 ^magma@2.6.1 +cuda cuda_arch=60 ^raja@0.13.0 +cuda cuda_arch=60\
    \ ^suite-sparse@5.8.1\nspack add hdf5@1.10.7 +hl +mpi\nspack install</pre></div>\n\
    <p>To assist in building the dependencies on select systems the <a href=\"./spack\"\
    >spack</a>\ndirectory contains environment files leveraging software already available\
    \ on\nthe system. For example, on the OLCF Summit system:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>module load gcc/10.2.0 cuda/11.4.2 cmake/3.21.3\n\
    <span class=\"pl-c1\">cd</span> spack\nspack env create sundials-demo spack-summit.yaml\n\
    spack env activate sundials-demo\nspack install</pre></div>\n<h4><a id=\"user-content-using-docker-containers\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-docker-containers\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Docker\
    \ Containers</h4>\n<p>It also possible to use the Docker containers from the <a\
    \ href=\"https://github.com/orgs/sundials-codes/packages?repo_name=sundials-manyvector-demo\"\
    >GitHub Container Registry</a>\nwith the necessary dependencies preinstalled for\
    \ CPU-only testing. Two images\nare provided:</p>\n<ul>\n<li>\n<p>sundials-demo-spack-latest\
    \ -- based on the latest Spack release (currently\nv0.19.0)</p>\n</li>\n<li>\n\
    <p>sundials-demo-spack-develop -- based on the Spack develop branch and updated\n\
    monthly</p>\n</li>\n</ul>\n<p>Pull the image(s) using <a href=\"https://www.docker.com/\"\
    \ rel=\"nofollow\">Docker</a> (or <a href=\"https://podman.io\" rel=\"nofollow\"\
    >Podman</a>).\nFor example, the <code>run</code> command below will pull the image\
    \ and start the container\nand the <code>exec</code> command will start a bash\
    \ shell inside the container.</p>\n<pre><code>docker run -t -d --name sundialsci-demo-spack-latest\
    \ ghcr.io/sundials-codes/sundials-demo-spack-latest:spack-latest\ndocker exec\
    \ -it sundials-demo-spack-lateset bash\n</code></pre>\n<p>Then clone this repository\
    \ with Git and configure/build the code as described\nbelow. The Spack installed\
    \ dependencies are available from the <code>/opt/view</code>\ndirectory.</p>\n\
    <h3><a id=\"user-content-configuration-options\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#configuration-options\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Configuration Options</h3>\n<p>Once the necessary\
    \ dependencies are installed, the following CMake variables can\nbe used to configure\
    \ the demonstration code build:</p>\n<ul>\n<li>\n<p><code>CMAKE_INSTALL_PREFIX</code>\
    \ - the path where executables and input files should be\ninstalled e.g., <code>my/install/path</code>.\
    \ The executables will be installed in the\n<code>bin</code> directory and input\
    \ files in the <code>tests</code> directory under the given path.</p>\n</li>\n\
    <li>\n<p><code>CMAKE_C_COMPILER</code> - the C compiler to use e.g., <code>mpicc</code>.\
    \ If not set, CMake\nwill attempt to automatically detect the C compiler.</p>\n\
    </li>\n<li>\n<p><code>CMAKE_C_FLAGS</code> - the C compiler flags to use e.g.,\
    \ <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_C_STANDARD</code> - the\
    \ C standard to use, defaults to <code>99</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_COMPILER</code>\
    \ - the C++ compiler to use e.g., <code>mpicxx</code>. If not set,\nCMake will\
    \ attempt to automatically detect the C++ compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_FLAGS</code>\
    \ - the C++ flags to use e.g., <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_STANDARD</code>\
    \ - the C++ standard to use, defaults to <code>11</code>.</p>\n</li>\n<li>\n<p><code>RAJA_ROOT</code>\
    \ - the root directory of the RAJA installation, defaults to the\nvalue of the\
    \ <code>RAJA_ROOT</code> environment variable. If not set, CMake will attempt\n\
    to automatically locate a RAJA install on the system.</p>\n</li>\n<li>\n<p><code>RAJA_BACKEND</code>\
    \ - the RAJA backend to use with the demonstration code, defaults\nto <code>SERIAL</code>.\
    \ Supported options are <code>SERIAL</code>, <code>OPENMP</code> and <code>CUDA</code>.\
    \  Note that this\nonly applies to on-node parallelism that is used when evaluating\
    \ chemistry-based\ncomponents associated with $f_2(w)$.</p>\n</li>\n<li>\n<p><code>SUNDIALS_ROOT</code>\
    \ - the root directory of the SUNDIALS installation, defaults to\nthe value of\
    \ the <code>SUNDIALS_ROOT</code> environment variable. If not set, CMake will\n\
    attempt to automatically locate a SUNDIALS install on the system.</p>\n</li>\n\
    <li>\n<p><code>ENABLE_HDF5</code> - build with HDF5 I/O support, defaults to <code>OFF</code>.</p>\n\
    </li>\n<li>\n<p><code>HDF5_ROOT</code> - the root directory of the HDF5 installation,\
    \ defaults to the\nvalue of the <code>HDF5_ROOT</code> environment variable. If\
    \ not set, CMake will attempt\nto automatically locate a HDF5 install on the system.</p>\n\
    </li>\n</ul>\n<p>When RAJA is installed with CUDA support enabled, the following\
    \ additional\nvariables may also be set:</p>\n<ul>\n<li>\n<p><code>CMAKE_CUDA_COMPILER</code>\
    \ - the CUDA compiler to use e.g., <code>nvcc</code>. If not set,\nCMake will\
    \ attempt to automatically detect the CUDA compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_FLAGS</code>\
    \ - the CUDA compiler flags to use.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_ARCHITECTURES</code>\
    \ - the CUDA architecture to target e.g., <code>70</code>.</p>\n</li>\n</ul>\n\
    <h3><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h3>\n\
    <p>In-source builds are not permitted, as such the code should be configured and\n\
    built from a separate build directory e.g.,</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  <span class=\"pl-c1\">cd</span> sundials-manyvector-demo\n  mkdir build\n\
    \  <span class=\"pl-c1\">cd</span> build\n  cmake ../. \\\n    -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>[install-path]<span class=\"\
    pl-pds\">\"</span></span> \\\n    -DRAJA_BACKEND=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>SERIAL<span class=\"pl-pds\">\"</span></span> \\\n    -DENABLE_HDF5=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DHDF5_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span> \\\n    -DRAJA_ROOT=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>[spack-view-path]<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DSUNDIALS_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span>\n  make\n  make install</pre></div>\n<p>where\
    \ <code>[install-path]</code> is the path to where the binary and test input files\n\
    should be installed and <code>[spack-view-path]</code> is the path to the Spack\
    \ environment\nview, <code>~/views/sundials-demo</code> when following the Spack\
    \ instructions above or\n<code>/opt/view</code> when using the Docker containers.</p>\n\
    <h2><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n\
    <p>Several test cases are included with the code and the necessary input files\
    \ for\neach case are contained in the subdirectories within the <a href=\"./tests\"\
    >tests</a>\ndirectory. Each input file is internally documented to discuss all\
    \ possible\ninput parameters (in case some have been added since this <code>README</code>\
    \ was last\nupdated).</p>\n<p>The input files contain parameters to set up the\
    \ physical problem:</p>\n<ul>\n<li>\n<p>spatial domain, $\\Omega$ -- <code>xl</code>,\
    \ <code>xr</code>, <code>yl</code>, <code>yr</code>, <code>zl</code>, <code>zr</code></p>\n\
    </li>\n<li>\n<p>time interval, $[t_0, t_f]$ -- <code>t0</code>, <code>tf</code></p>\n\
    </li>\n<li>\n<p>the ratio of specific heats, $\\gamma$ -- <code>gamma</code></p>\n\
    </li>\n<li>\n<p>spatial discretization dimensions -- <code>nx</code>, <code>ny</code>,\
    \ <code>nz</code></p>\n</li>\n<li>\n<p>boundary condition types -- <code>xlbc</code>,\
    \ <code>xrbc</code>, <code>ylbc</code>, <code>yrbc</code>, <code>zlbc</code>,\
    \ <code>zrbc</code></p>\n</li>\n</ul>\n<p>Parameters to control the execution\
    \ of the code:</p>\n<ul>\n<li>\n<p>desired CFL fraction -- <code>cfl</code> (if\
    \ set to zero, then the time step is chosen purely using temporal adaptivity).</p>\n\
    </li>\n<li>\n<p>number of desired solution outputs -- <code>nout</code></p>\n\
    </li>\n<li>\n<p>a flag to enable optional output of RMS averages for each field\
    \ at the frequency specified via <code>nout</code> -- <code>showstats</code></p>\n\
    </li>\n</ul>\n<p>Numerous parameters are also provided to control how time integration\
    \ is\nperformed (these are passed directly to ARKODE). For further information\
    \ on the\nARKODE solver parameters and the meaning of individual values, see the\n\
    <a href=\"https://sundials.readthedocs.io/en/latest/index.html\" rel=\"nofollow\"\
    >ARKODE documentation</a>.</p>\n<p>To specify an input file to the executable,\
    \ the input filename should be\nprovided using the <code>-f</code> flag e.g.,</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> -f <span class=\"pl-k\">&lt;</span>input_file<span\
    \ class=\"pl-k\">&gt;</span></pre></div>\n<p>Additionally, any input parameters\
    \ may also be specified on the\ncommand line e.g.,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> --nx=100 --ny=100 --nz=400</pre></div>\n<p>For example,\
    \ continuing with the Summit case from above, the primordial blast\ntest can be\
    \ run on one Summit node using four cores and four GPUs with the\nfollowing commands:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">${MEMBERWORK}</span>/[projid]/sundials-demo/tests/primordial_blast\n\
    \  bsub -q debug -nnodes 1 -W 0:10 -P [projid] -Is <span class=\"pl-smi\">$SHELL</span>\n\
    \  jsrun -n4 -a1 -c1 -g1 ../../bin/primordial_blast_mr.exe -f input_primordial_blast_mr_gpu.txt</pre></div>\n\
    <p>The <code>bsub</code> command above will submit a request for an interactive\
    \ job to the\ndebug queue allocating one node for 10 minutes with the compute\
    \ time charged to\n<code>[projid]</code>. Once the interactive session starts\
    \ the test case is launched using\nthe <code>jsrun</code> command. Solutions are\
    \ output to disk using parallel HDF5, solution\nstatistics are optionally output\
    \ to the screen at specified frequencies, and run\nstatistics are printed at the\
    \ end of the simulation.</p>\n<p>The parallel HDF5 solution snapshots are written\
    \ at the frequency specified by\n<code>nout</code>.  Accompanying these <code>output-#######.hdf5</code>\
    \ files is an automatically\ngenerated input file, <code>restart_parameters.txt</code>\
    \ that stores a complete set of\ninput parameters to restart the simulation from\
    \ the most recently generated\noutput file. This is a \"warm\" restart, in that\
    \ it will pick up the calculation\nwhere the previous one left off, using the\
    \ same initial time step size as\nARKStep would use. This restart may differ slightly\
    \ from an uninterrupted run\nsince other internal ARKStep time adaptivity parameters\
    \ cannot be reused.  We\nnote that the restart must use the same spatial grid\
    \ size and number of chemical\ntracers as the original run, but it may use a different\
    \ number of MPI tasks if\ndesired.</p>\n<h2><a id=\"user-content-adding-new-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-tests\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Adding New Tests</h2>\n<p>Individual\
    \ test problems are uniquely specified through an input file and\nauxiliary source\
    \ code file(s) that should be linked with the main routine at\ncompile time. By\
    \ default, all codes are built with no chemical species; however,\nthis may be\
    \ controlled at compilation time using the <code>NVAR</code> preprocessor\ndirective,\
    \ corresponding to the number of unknowns at any spatial location.\nHence, the\
    \ (default) minimum value for <code>NVAR</code> is 5, so for a calculation with\
    \ 4\nchemical species the code should be compiled with the preprocessor directive\n\
    <code>NVAR=9</code>. See <a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ for examples of how to\nspecify <code>NVAR</code> when adding a new test/executable.</p>\n\
    <p>The auxiliary source code files for creating a new test must contain three\n\
    functions. Each of these must return an integer flag indicating success (0) or\n\
    failure (nonzero). The initial condition function $w_0(X)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">initial_conditions</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector w, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>and the forcing function $G(X,t,w)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">external_forces</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector G, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>Additionally, a function must be supplied to compute/output\
    \ any\ndesired solution diagnostic information with the signature</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span> <span\
    \ class=\"pl-en\">output_diagnostics</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, <span class=\"pl-k\">const</span> N_Vector w, <span class=\"\
    pl-k\">const</span> UserData&amp; udata);</pre></div>\n<p>If no diagnostics information\
    \ is desired, then this routine may just return 0.</p>\n<p>Here, the <code>initial_conditions</code>\
    \ routine will be called once when the simulation\nbegins, <code>external_forces</code>\
    \ will be called on every evaluation of the ODE\nright-hand side function for\
    \ the Euler equations (it is assumed that this does\nnot require the results from\
    \ (<code>UserData::ExchangeStart</code>\n/ <code>UserData::ExchangeEnd</code>),\
    \ and <code>output_diagnostics</code> will be called at the same\nfrequency as\
    \ the solution is output to disk.</p>\n<p>To add a new executable using these\
    \ auxiliary source code file(s), update\n<a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ to include a new call to\n<code>sundemo_add_executable</code> in a similar manner\
    \ as the existing test problems e.g.,\n<code>hurricane_yz.exe</code>.</p>\n<h2><a\
    \ id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" href=\"#authors\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n\
    <p><a href=\"https://people.smu.edu/dreynolds\" rel=\"nofollow\">Daniel R. Reynolds</a>\
    \ and\n<a href=\"https://people.llnl.gov/gardner48\" rel=\"nofollow\">David J.\
    \ Gardner</a></p>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1655924113.0
supercontainers/isc-tutorial:
  data_format: 2
  description: ISC 2022 -- Getting Started with Containers on HPC
  filenames:
  - exercises/spack_contenerize/spack.yaml
  - files/spack_contenerize/spack.yaml
  full_name: supercontainers/isc-tutorial
  latest_release: null
  readme: '<h1><a id="user-content-getting-started-with-containers-on-hpc" class="anchor"
    aria-hidden="true" href="#getting-started-with-containers-on-hpc"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Getting Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/isc-tutorial/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2><a id="user-content-ecp-supercontainers-tutorial-session" class="anchor" aria-hidden="true"
    href="#ecp-supercontainers-tutorial-session"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>ECP Supercontainers Tutorial Session</h2>

    <p><a target="_blank" rel="noopener noreferrer" href="fig/ecp.jpg"><img src="fig/ecp.jpg"
    width="250" style="max-width: 100%;"></a><a target="_blank" rel="noopener noreferrer"
    href="fig/pawsey.jpeg"><img src="fig/pawsey.jpeg" width="250" style="max-width:
    100%;"></a></p>

    <h2><a id="user-content-details" class="anchor" aria-hidden="true" href="#details"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Half-day Tutorial Session</p>

    <p>Venue: International Supercomputing Conference (ISC 2022)</p>

    <p>Date: 29 May 2022 2:00pm - 6:00pm, Central European Summer Time CEST (GMT+2)</p>

    <p>Location: Hamburg, Germany</p>

    <p>Link: <a href="https://app.swapcard.com/widget/event/isc-high-performance-2022/planning/UGxhbm5pbmdfODYxMTU3"
    rel="nofollow">ISC 2022 Schedule</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2><a id="user-content-ec2-login" class="anchor" aria-hidden="true" href="#ec2-login"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EC2 Login</h2>

    <p>These will be provided the day of the tutorial.</p>

    <h2><a id="user-content-abstract" class="anchor" aria-hidden="true" href="#abstract"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Container computing has revolutionized the way applications are developed and
    delivered.  It offers opportunities that never existed before for significantly
    improving efficiency of scientific workflows and easily moving these workflows
    from the laptop to the supercomputer.  Tools like Docker, Shifter, Singularity,
    Charliecloud and Podman enable a new paradigm for scientific and technical computing.  However,
    to fully unlock its potential, users and administrators need to understand how
    to utilize these new approaches.  This tutorial will introduce attendees to the
    basics of creating container images, explain best practices, and cover more advanced
    topics such as creating images to be run on HPC platforms using various container
    runtimes.  The tutorial will also explain how research scientists can utilize
    container-based computing to accelerate their research and how these tools can
    boost the impact of their research by enabling better reproducibility and sharing
    of their scientific process without compromising security.</p>

    <p>This is an updated version of the highly successful tutorial presented at SC16-21
    and ISC19-21.</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This is a hands-on tutorial.  Participants should bring a laptop and load or
    pre-install a terminal and/or ssh client in advance to make best use of time during
    the tutorial.  We will be providing training user accounts to both pre-configured
    EC2 instances.</p>

    <div><a target="_blank" rel="noopener noreferrer" href="fig/AWS_logo.png"><img
    src="fig/AWS_logo.png" width="250" style="max-width: 100%;"></a></div>

    <p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards.  EC2
    images and temporary login credentials will be distributed onsite at the tutorial.</p>

    <p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2
    to run through the tutorial again. We recommend you use your own EC2 key and change
    the password.</p>

    <p>US-West-Oregon: ami-0fe12765123c6a840</p>

    <h3><a id="user-content-optional-prerequisites" class="anchor" aria-hidden="true"
    href="#optional-prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optional
    Prerequisites</h3>

    <p>Users can also install Docker and Singularity prior to attending the tutorial
    session.  Here, it may be beneficial to create Docker and Sylabs (Singularity)
    accounts in advance at <a href="https://cloud.docker.com/" rel="nofollow">https://cloud.docker.com/</a>
    and <a href="https://cloud.sylabs.io/" rel="nofollow">https://cloud.sylabs.io/</a>.  These
    accounts will be needed to create images on Docker Cloud/Dockerhub and Sylabs
    Cloud.</p>

    <p><a href="https://sylabs.io/guides/3.7/user-guide/" rel="nofollow">Install Singularity
    on Linux</a></p>

    <p><a href="https://repo.sylabs.io/desktop/" rel="nofollow">Install Singularity
    on Mac</a> (Alpha)</p>

    <p><a href="https://www.docker.com/products/docker-desktop" rel="nofollow">Install
    Docker for Desktop</a></p>

    <h2><a id="user-content-questions" class="anchor" aria-hidden="true" href="#questions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-schedule-see-the-git-pages-site-for-the-autogenerated-version"
    class="anchor" aria-hidden="true" href="#schedule-see-the-git-pages-site-for-the-autogenerated-version"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Schedule (See the git
    pages site for the autogenerated version)</h2>

    <p>14:00 - 14:15 Introduction to containers in HPC (Shane)<br>

    Including defining jargon (containers, images, registries/repos,..)</p>

    <p>14:15 - 14:55 Build and run your first container (Eduardo)<br>

    Basic of containers and understanding the OCI Image Spec</p>

    <p>14:55 - 15:30 Deploy containers on a supercomputer (Alexis)</p>

    <p>15:30 - 16:00 High-performance containers (Alexis)</p>

    <p>16:00 - 16:30 BREAK</p>

    <p>16:30 - 17:05 Best practices (Shane)</p>

    <p>17:05 - 17:35 E4S containers initiative (Sameer)</p>

    <p>17:35 - 17:55 Advanced container builds (Eduardo)</p>

    <p>17:55 - 18:00 Wrap-up and final Q&amp;A</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics:
  - hpc
  - containers
  - singularity-container
  - singularity
  - shifter
  - docker
  - tutorial
  - supercomputer
  updated_at: 1659454820.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2023.04.07
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2023.04.07\"\
    ><img src=\"https://camo.githubusercontent.com/1075d0d0a3915bcdcc9642e16d668c29457ccd144349bc246e4b784d55281747/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032332e30342e30372d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2023.04.07-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.7809262\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d875e8ed4280e04d1d499effc3e4d504fba9d6f67b21da5b9d1120fd9009cd8b/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e373830393236322e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.7809262.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#what-is-spectre\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>What is SpECTRE?</h2>\n<p>SpECTRE\
    \ is an open-source code for multi-scale, multi-physics problems\nin astrophysics\
    \ and gravitational physics. In the future, we hope that\nit can be applied to\
    \ problems across discipline boundaries in fluid\ndynamics, geoscience, plasma\
    \ physics, nuclear physics, and\nengineering. It runs at petascale and is designed\
    \ for future exascale\ncomputers.</p>\n<p>SpECTRE is being developed in support\
    \ of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into\
    \ the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae,\
    \ and\ngamma-ray bursts.</p>\n<h2><a id=\"user-content-citing-spectre\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#citing-spectre\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Citing SpECTRE</h2>\n<p>Please cite\
    \ SpECTRE in any publications that make use of its code or data. Cite\nthe latest\
    \ version that you use in your publication. The DOI for this version\nis:</p>\n\
    <ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.7809262\" rel=\"nofollow\"\
    >10.5281/zenodo.7809262</a>\n</li>\n</ul>\n<p>You can cite this BibTeX entry in\
    \ your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"><pre><span\
    \ class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and H\\'ebert, Fran\\c{c}ois and Moxon,\
    \ Jordan and Armaza, Crist\\'obal and</span>\n<span class=\"pl-s\">Bonilla, Marceline\
    \ S. and Kim, Yoonsoo and Kumar, Prayush and Lovelace, Geoffrey</span>\n<span\
    \ class=\"pl-s\">and Macedo, Alexandra and Nelli, Kyle C. and O'Shea, Eamonn and\
    \ Pfeiffer, Harald</span>\n<span class=\"pl-s\">P. and Scheel, Mark A. and Teukolsky,\
    \ Saul A. and Wittek, Nikolas A. and</span>\n<span class=\"pl-s\">others<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> =\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2023.04.07}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2023.04.07<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">publisher</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Zenodo<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">doi</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>10.5281/zenodo.7809262<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>https://spectre-code.org<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">howpublished</span> =\n<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.7809262}{10.5281/zenodo.7809262}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2023<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>4<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2><a id=\"\
    user-content-viewing-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #viewing-documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Viewing Documentation</h2>\n<p>The documentation can be viewed at\
    \ <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 122
  subscribers_count: 14
  topics: []
  updated_at: 1680540221.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - chifflot/v100/spack.yaml
  - thetagpu/spack.yaml
  - local/spack.yaml
  - cooley/spack.yaml
  - chifflot/p100/spack.yaml
  - gemini/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1><a id="user-content-spack-envs" class="anchor" aria-hidden="true" href="#spack-envs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-envs</h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2><a id="user-content-locally" class="anchor" aria-hidden="true" href="#locally"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Locally</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: $spack/opt/spack</span>

    <span class="pl-c1">build_stage: $user_cache_path/stage</span>


    <span class="pl-c1">spack env activate ~/Dev/spack-envs/local</span>

    <span class="pl-c1">spack install</span></pre></div>

    <h2><a id="user-content-g5k" class="anchor" aria-hidden="true" href="#g5k"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>G5k</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: /mnt/spack</span>

    <span class="pl-c1">build_stage: /tmp/spack-stage</span></pre></div>

    <h2><a id="user-content-anl" class="anchor" aria-hidden="true" href="#anl"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ANL</h2>

    <h3><a id="user-content-cooley" class="anchor" aria-hidden="true" href="#cooley"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Cooley</h3>

    <p>Before using Spack to compile stuff on Cooley, we recommend to run <code>use_build_cooley</code>
    to get access to newer gcc, cmake, and mvapich versions.</p>

    <h3><a id="user-content-thetagpu" class="anchor" aria-hidden="true" href="#thetagpu"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ThetaGPU</h3>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678891926.0
tpeterka/mpas-o-standalone:
  data_format: 2
  description: null
  filenames:
  - mpas_spack.yaml
  full_name: tpeterka/mpas-o-standalone
  latest_release: null
  readme: '<h1><a id="user-content-instructions-for-building-mpas-ocean-as-a-standalone-code-no-workflow"
    class="anchor" aria-hidden="true" href="#instructions-for-building-mpas-ocean-as-a-standalone-code-no-workflow"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Instructions for Building
    MPAS-Ocean as a Standalone Code (no workflow)</h1>

    <p>Installation is done through Spack. If you don''t have Spack installed or if
    Spack is new to you, go <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">here</a>
    first.</p>

    <p>Clone this repository and cd into it. These instructions assume there is a
    top-level directory called climate.</p>

    <pre><code>mkdir ~/climate

    cd ~/climate

    git clone https://github.com/tpeterka/mpas-o-standalone

    cd mpas-o-standalone

    </code></pre>

    <hr>

    <h2><a id="user-content-setting-up-spack-environment" class="anchor" aria-hidden="true"
    href="#setting-up-spack-environment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Setting
    up Spack environment</h2>

    <h3><a id="user-content-first-time-create-and-load-the-spack-environment-for-mpas-ocean"
    class="anchor" aria-hidden="true" href="#first-time-create-and-load-the-spack-environment-for-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    and load the Spack environment for MPAS-Ocean</h3>

    <pre><code>cd ~/climate/mpas-o-standalone

    source ./create-mpas.sh     # requires being in the same directory to work properly

    </code></pre>

    <h3><a id="user-content-subsequent-times-load-the-spack-environment-for-mpas-ocean"
    class="anchor" aria-hidden="true" href="#subsequent-times-load-the-spack-environment-for-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Subsequent times: load
    the Spack environment for MPAS-Ocean</h3>

    <pre><code>source ~/climate/mpas-o-standalone/load-mpas.sh

    </code></pre>

    <hr>

    <h2><a id="user-content-building-mpas-ocean" class="anchor" aria-hidden="true"
    href="#building-mpas-ocean"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    MPAS-Ocean</h2>

    <h3><a id="user-content-first-time-clone-mpas-ocean" class="anchor" aria-hidden="true"
    href="#first-time-clone-mpas-ocean"><span aria-hidden="true" class="octicon octicon-link"></span></a>First
    time: clone MPAS-Ocean</h3>

    <pre><code>cd ~/climate

    git clone https://github.com/E3SM-Project/E3SM

    cd E3SM

    git submodule update --init --recursive

    </code></pre>

    <h3><a id="user-content-build-mpas-ocean" class="anchor" aria-hidden="true" href="#build-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build MPAS-Ocean</h3>

    <pre><code>cd ~/climate/E3SM/components/mpas-ocean

    make clean              # if dirty

    make -j gfortran

    </code></pre>

    <p>This will take ~ 5 minutes to compile.</p>

    <hr>

    <h2><a id="user-content-setting-up-a-test-case-to-execute" class="anchor" aria-hidden="true"
    href="#setting-up-a-test-case-to-execute"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Setting up a test case to execute</h2>

    <p>Compass is an E3SM system for generating and running test cases for MPAS-Ocean,
    and relies on conda environments. The instructions below assume you have conda
    or miniconda already installed. If not, go <a href="https://docs.conda.io/en/latest/miniconda.html"
    rel="nofollow">here</a> first.</p>

    <h3><a id="user-content-first-time-install-compass-and-create-compass-environment"
    class="anchor" aria-hidden="true" href="#first-time-install-compass-and-create-compass-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: install
    Compass and create Compass environment</h3>

    <pre><code>cd ~

    git clone https://github.com/MPAS-Dev/compass.git compass-env-only

    cd ~/compass-env-only

    git submodule update --init --recursive

    ./conda/configure_compass_env.py --conda ~/miniconda3 --env_only

    source load_dev_compass_1.2.0-alpha.4.sh        # load_dev_compass-1.2.0-alpha.4.sh
    is the script created by the previous command

    </code></pre>

    <h3><a id="user-content-first-time-create-a-compass-configuration-file-for-a-new-machine"
    class="anchor" aria-hidden="true" href="#first-time-create-a-compass-configuration-file-for-a-new-machine"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    a compass configuration file for a new machine</h3>

    <p>Assumes the config file is named ~/compass-env-only/compass.cfg and has these
    contents, or similar (yours may vary)</p>

    <pre><code># This file contains some common config options you might want to set


    # The paths section describes paths to databases and shared compass environments

    [paths]


    # A root directory where MPAS standalone data can be found

    database_root = /home/tpeterka/compass/mpas_standalonedata


    # The parallel section describes options related to running tests in parallel

    [parallel]


    # parallel system of execution: slurm or single_node

    system = single_node


    # whether to use mpirun or srun to run the model

    parallel_executable = mpiexec


    # cores per node on the machine, detected automatically by default

    # cores_per_node = 4

    </code></pre>

    <h3><a id="user-content-first-time-create-test-case-for-the-executable" class="anchor"
    aria-hidden="true" href="#first-time-create-test-case-for-the-executable"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    test case for the executable</h3>

    <p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code> is the name of
    the conda environment load script created initially</p>

    <pre><code>source ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh

    compass setup -t ocean/baroclinic_channel/10km/default -w ~/spack-baroclinic-test
    -p ~/climate/E3SM/components/mpas-ocean -f ~/compass-env-only/compass.cfg

    </code></pre>

    <h3><a id="user-content-run-the-test-case" class="anchor" aria-hidden="true" href="#run-the-test-case"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run the test case</h3>

    <p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code> is the name of
    the conda environment load script created initially</p>

    <pre><code>source ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh

    source ~/climate/mpas-o-standalone/load-mpas.sh

    cd ~/spack-baroclinic-test/ocean/baroclinic_channel/10km/default

    compass run

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1680793507.0
tpeterka/mpas-o-workflow:
  data_format: 2
  description: null
  filenames:
  - mpas_spack.yaml
  full_name: tpeterka/mpas-o-workflow
  latest_release: null
  readme: '<h1><a id="user-content-instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow"
    class="anchor" aria-hidden="true" href="#instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Instructions for Building
    MPAS-Ocean to Run in a Wilkins Workflow</h1>

    <p>Installation is done through Spack. If you don''t have Spack installed or if
    Spack is new to you, go <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">here</a>
    first.</p>

    <p>Clone this repository and cd into it. These instructions assume there is a
    top-level directory called climate.</p>

    <pre><code>mkdir ~/climate

    cd ~/climate

    git clone https://github.com/tpeterka/mpas-o-workflow

    cd mpas-o-workflow

    </code></pre>

    <hr>

    <h2><a id="user-content-setting-up-spack-environment" class="anchor" aria-hidden="true"
    href="#setting-up-spack-environment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Setting
    up Spack environment</h2>

    <h3><a id="user-content-first-time-create-and-load-the-spack-environment-for-mpas-ocean"
    class="anchor" aria-hidden="true" href="#first-time-create-and-load-the-spack-environment-for-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    and load the Spack environment for MPAS-Ocean</h3>

    <pre><code>cd ~/climate/mpas-o-workflow

    source ./create-mpas.sh     # requires being in the same directory to work properly

    </code></pre>

    <h3><a id="user-content-subsequent-times-load-the-spack-environment-for-mpas-ocean"
    class="anchor" aria-hidden="true" href="#subsequent-times-load-the-spack-environment-for-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Subsequent times: load
    the Spack environment for MPAS-Ocean</h3>

    <pre><code>source ~/climate/mpas-o-workflow/load-mpas.sh

    </code></pre>

    <hr>

    <h2><a id="user-content-building-mpas-ocean" class="anchor" aria-hidden="true"
    href="#building-mpas-ocean"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    MPAS-Ocean</h2>

    <h3><a id="user-content-first-time-clone-mpas-ocean" class="anchor" aria-hidden="true"
    href="#first-time-clone-mpas-ocean"><span aria-hidden="true" class="octicon octicon-link"></span></a>First
    time: clone MPAS-Ocean</h3>

    <pre><code>cd ~/climate

    git clone https://github.com/E3SM-Project/E3SM

    cd E3SM

    git submodule update --init --recursive

    </code></pre>

    <h2><a id="user-content-first-time-modify-mpas-ocean-makefiles-to-link-to-henson"
    class="anchor" aria-hidden="true" href="#first-time-modify-mpas-ocean-makefiles-to-link-to-henson"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: modify
    MPAS-Ocean makefiles to link to Henson</h2>

    <p>Edit ~climate/E3SM/components/mpas-ocean/Makefile:</p>

    <p>Insert at line 596:

    <code>LIBS += -L $(HENSON)/lib -lhenson</code></p>

    <p>Insert at line 732:

    <code>LDFLAGS += -shared</code></p>

    <p>Edit line 1002 to add .so to executable name: <code>$(EXE_NAME).so</code></p>

    <h3><a id="user-content-build-mpas-ocean" class="anchor" aria-hidden="true" href="#build-mpas-ocean"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build MPAS-Ocean</h3>

    <pre><code>cd ~/climate/E3SM/components/mpas-ocean

    make clean              # if dirty

    make -j gfortran

    </code></pre>

    <p>This will take ~ 5 minutes to compile.</p>

    <h3><a id="user-content-create-a-run-script-for-mpas-ocean" class="anchor" aria-hidden="true"
    href="#create-a-run-script-for-mpas-ocean"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Create a run script for MPAS-Ocean</h3>

    <p>Edit (create) <code>~/climate/E3SM/components/mpas-ocean/ocean_model</code>:</p>

    <p><code>python3 ~/climate/mpas-o-workflow/mpas-henson.py</code></p>

    <p>Set permissions of <code>ocean_model</code> to executable:</p>

    <p><code>chmod 755 ~/climate/E3SM/components/mpas-ocean/ocean_model</code></p>

    <hr>

    <h2><a id="user-content-setting-up-a-test-case-to-execute" class="anchor" aria-hidden="true"
    href="#setting-up-a-test-case-to-execute"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Setting up a test case to execute</h2>

    <p>Compass is an E3SM system for generating and running test cases for MPAS-Ocean,
    and relies on conda environments. The instructions below assume you have cond
    or miniconda already installed. If not, go <a href="https://docs.conda.io/en/latest/miniconda.html"
    rel="nofollow">here</a> first.</p>

    <h3><a id="user-content-first-time-install-compass-and-create-compass-environment"
    class="anchor" aria-hidden="true" href="#first-time-install-compass-and-create-compass-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: install
    Compass and create Compass environment</h3>

    <pre><code>cd ~

    git clone https://github.com/MPAS-Dev/compass.git compass-env-only

    cd ~/compass-env-only

    git submodule update --init --recursive

    ./conda/configure_compass_env.py --conda ~/miniconda3 --env_only

    source load_dev_compass_1.2.0-alpha.4.sh        # load_dev_compass-1.2.0-alpha.4.sh
    is the script created by the previous command

    </code></pre>

    <h3><a id="user-content-first-time-create-a-compass-configuration-file-for-a-new-machine"
    class="anchor" aria-hidden="true" href="#first-time-create-a-compass-configuration-file-for-a-new-machine"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    a compass configuration file for a new machine</h3>

    <p>Assumes the config file is named ~/compass-env-only/compass.cfg and has these
    contents, or similar (yours may vary)</p>

    <pre><code># This file contains some common config options you might want to set


    # The paths section describes paths to databases and shared compass environments

    [paths]


    # A root directory where MPAS standalone data can be found

    database_root = /home/tpeterka/compass/mpas_standalonedata


    # The parallel section describes options related to running tests in parallel

    [parallel]


    # parallel system of execution: slurm or single_node

    system = single_node


    # whether to use mpirun or srun to run the model

    parallel_executable = mpiexec


    # cores per node on the machine, detected automatically by default

    # cores_per_node = 4

    </code></pre>

    <h3><a id="user-content-first-time-create-test-case-for-the-executable" class="anchor"
    aria-hidden="true" href="#first-time-create-test-case-for-the-executable"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>First time: create
    test case for the executable</h3>

    <p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code> is the name of
    the conda environment load script created initially</p>

    <pre><code>source ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh

    compass setup -t ocean/baroclinic_channel/10km/default -w ~/spack-baroclinic-test
    -p ~/climate/E3SM/components/mpas-ocean -f ~/compass-env-only/compass.cfg

    </code></pre>

    <h3><a id="user-content-run-the-test-case" class="anchor" aria-hidden="true" href="#run-the-test-case"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run the test case</h3>

    <p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code> is the name of
    the conda environment load script created initially</p>

    <pre><code>source ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh

    source ~/climate/mpas-o-workflow/load-mpas.sh

    cd ~/spack-baroclinic-test/ocean/baroclinic_channel/10km/default

    compass run

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679076329.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/hpccf/franklin/r-stack/spack.yaml
  - environments/hpccf/franklin/omics/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<h1><a id="user-content-spack--uc-davis" class="anchor" aria-hidden="true"
    href="#spack--uc-davis"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    @ UC Davis</h1>

    <h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters" class="anchor"
    aria-hidden="true" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack repos and configs
    for UC Davis HPCCF Clusters</h2>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1676322811.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - benchmarks/spack/tursa/cpu/spack.yaml
  - benchmarks/spack/isambard-cascadelake/compute-node/spack.yaml
  - benchmarks/spack/github-actions/default/spack.yaml
  - benchmarks/spack/csd3-icelake/compute-node/spack.yaml
  - benchmarks/spack/dial3/compute-node/spack.yaml
  - benchmarks/spack/myriad/compute-node/spack.yaml
  - benchmarks/spack/csd3-skylake/compute-node/spack.yaml
  - benchmarks/spack/archer2/compute-node/spack.yaml
  - benchmarks/spack/cosma8/compute-node/spack.yaml
  - benchmarks/spack/isambard-xci/compute-node/spack.yaml
  - benchmarks/spack/tesseract/compute-node/spack.yaml
  - benchmarks/spack/isambard-a64fx/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1><a id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#excalibur-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks and regression tests\
    \ for the ExCALIBUR project.</p>\n<p>These benchmarks are based on a similar project\
    \ by\n<a href=\"https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2><a\
    \ id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>It is recommended to install the <strong>excalibur-tests</strong> package with\
    \ <code>pip</code> by</p>\n<div class=\"highlight highlight-source-shell\"><pre>pip\
    \ install <span class=\"pl-c1\">.</span></pre></div>\n<p>On most systems, it is\
    \ recommended to install the package in a virtual environment.\nFor example, using\
    \ the python3 <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow\"\
    >built-in virtual environment tool <code>venv</code></a>,\ncreate an environment\
    \ called <code>my_environment</code> with</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python3 -m venv ./my_environment</pre></div>\n<p>and activate it with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">source</span>\
    \ ./my_environment/bin/activate</pre></div>\n<p>For <a href=\"https://setuptools.pypa.io/en/latest/userguide/development_mode.html\"\
    \ rel=\"nofollow\">development</a>,\npass the <code>-e/--editable</code> flag\
    \ to <code>pip</code> to link the installed package to the files in the local\n\
    directory, instead of copying, to be able to make changes to the installed package.</p>\n\
    <h2><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Requirements</h2>\n<p>The pip install will install a compatible version\
    \ of <strong>ReFrame</strong> from\n<a href=\"https://pypi.org/project/ReFrame-HPC/\"\
    \ rel=\"nofollow\">PyPi</a>. However, you will have to\nmanually provide an installation\
    \ of <strong>Spack</strong>.</p>\n<h3><a id=\"user-content-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack</h3>\n<p><a href=\"https://spack.io/\" rel=\"\
    nofollow\">Spack</a> is a package manager specifically designed for HPC\nfacilities.\
    \ In some HPC facilities there may be already a central Spack installation available.\n\
    However, the version installed is most likely too old to support all the features\n\
    used by this package. Therefore we recommend you install the latest version locally,\n\
    following the instructions below.</p>\n<p><em><strong>Note</strong>: if you have\
    \ already installed spack locally and you want to upgrade to\na newer version,\
    \ you might first have to clear the cache to avoid conflicts:\n<code>spack clean\
    \ -m</code></em></p>\n<p>Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official instructions</a>\nto install the latest version of\
    \ Spack (summarised here for convenience, but not guaranteed to be\nup-to-date):</p>\n\
    <ul>\n<li>git clone spack:\n<code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code>\n\
    </li>\n<li>run spack setup script: <code>source ./spack/share/spack/setup-env.sh</code>\n\
    </li>\n<li>check spack is in <code>$PATH</code>, for example <code>spack --version</code>\n\
    </li>\n</ul>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable. This\
    \ is taken care of by the <code>setup-env.sh</code>\nscript as above, and you\
    \ can have your shell init script (e.g. <code>.bashrc</code>)\ndo that automatically\
    \ in every session, by adding the following lines to it:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame also requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRAC projects in\n\
    <a href=\"https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack\"\
    >https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack/</a>.\n\
    If you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system if known, otherwise it will automatically\ncreate a very basic environment\
    \ (see \"Usage on unsupported systems\" section below).</p>\n<h3><a id=\"user-content-reframe\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reframe\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>ReFrame</h3>\n<p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\"\
    \ rel=\"nofollow\">ReFrame</a> is a high-level\nframework for writing regression\
    \ tests for HPC systems.  For our tests we\nrequire ReFrame v4.1.0.</p>\n<p>If\
    \ you need to manually install ReFrame, follow the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall this package.  Note\
    \ that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a\
    \ specific module to have this version of Python available.</p>\n<p>We provide\
    \ a ReFrame configuration file with the settings of some systems that\nare part\
    \ of the ExCALIBUR or DiRAC projects.  You can point ReFrame to this file by\n\
    setting the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILE</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILE=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${PWD}</span>/benchmarks/reframe_config.py<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>If you want to use a different ReFrame configuration file, for example because\n\
    you use a different system, you can set this environment variable to the path\
    \ of\nthat file.</p>\n<p><strong>Note</strong>: in order to use the Spack build\
    \ system in ReFrame, the <code>spack</code>\nexecutable must be in the <code>PATH</code>\
    \ also on the compute nodes of a cluster, if\nyou want to run your benchmarks\
    \ on them. This is taken care of by adding it\nto your init file (see spack section\
    \ above).</p>\n<p>However, you will also need to set the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ (<code>export RFM_USE_LOGIN_SHELL=\"Yes\"</code>) in order to make ReFrame use</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">!</span><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash -l</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a> line, which would load\nthe user's init script.</p>\n<h2><a id=\"\
    user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <p>Once you have set up Spack and ReFrame, you can execute a benchmark with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/BENCH_NAME\
    \ -r --performance-report</pre></div>\n<p>where <code>benchmarks/apps/BENCH_NAME</code>\
    \ is the directory where the benchmark is.  The command\nabove assumes you have\
    \ the program <code>reframe</code> in your PATH.  If you have followed the instructions\n\
    to install using <code>pip</code> into the default directory, it should have been\
    \ automatically added.\nIf it is not the case, call <code>reframe</code> with\
    \ its relative or absolute path.</p>\n<p>For example, to run the Sombrero benchmark\
    \ in the <code>benchmarks/apps/sombrero</code> directory you can\nuse</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/sombrero\
    \ -r --performance-report</pre></div>\n<p>For benchmarks that use the Spack build\
    \ system, the tests define a default Spack specification\nto be installed in the\
    \ environment, but users can change it when invoking ReFrame on the\ncommand line\
    \ with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3><a id=\"user-content-setting-environment-variables\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#setting-environment-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting\
    \ environment variables</h3>\n<p>All the built-in fields of ReFrame regression\
    \ classes can be set on a per-job basis using the\n<code>-S</code> command-line\
    \ option. One useful such field is\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.env_vars\"\
    \ rel=\"nofollow\"><code>env_vars</code></a>,\nwhich controls the environment\
    \ variables used in a job.\nThe syntax to set dictionary items, like for <code>env_vars</code>,\
    \ is a comma-separated list of <code>key:value</code> pairs: <code>-S dict=key_1:value_1,key_2:value_2</code>.\n\
    For example</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S env_vars=OMP_PLACES:threads\n</code></pre>\n<p>runs the <code>benchmarks/apps/sombrero</code>\
    \ benchmark setting the environment variable <code>OMP_PLACES</code>\nto <code>threads</code>.</p>\n\
    <h3><a id=\"user-content-selecting-system-and-queue-access-options\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#selecting-system-and-queue-access-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  To avoid this, you can use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3><a id=\"user-content-usage-on-unsupported-systems\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#usage-on-unsupported-systems\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage on\
    \ unsupported systems</h3>\n<p>The configuration provided in <a href=\"./reframe_config.py\"\
    ><code>reframe_config.py</code></a> lets you run the\nbenchmarks on pre-configured\
    \ HPC systems.  However you\ncan use this framework on any system by choosing\
    \ the \"generic\" system with <code>--system generic</code>, or by using your\
    \ own ReFrame configuration.  You can use the \"generic\" system to run\nbenchmarks\
    \ in ReFrame without using a queue manager or an MPI launcher (e.g. on a personal\
    \ workstation).</p>\n<p>If you choose the \"generic\" system and a benchmark using\
    \ the Spack build system,\na new empty Spack environment will be automatically\
    \ created in\n<code>spack-environments/generic</code> when ReFrame is launched\
    \ for the first time.\nYou should populate the environment with the packages already\
    \ installed on your system\nbefore running Spack to avoid excessively rebuilding\
    \ system packages. See the\n<em>Spack configuration</em> section of <a href=\"\
    ./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on how\n\
    to set up a Spack environment.\nIn particular, make sure that at least a compiler\
    \ and an MPI library are added into the environment.\nAfter the Spack environment\
    \ is set up, tell ReFrame to use it by setting the environment\nvariable <code>EXCALIBUR_SPACK_ENV</code>,\
    \ as described above.</p>\n<h3><a id=\"user-content-system-specific-flags\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#system-specific-flags\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>System-specific flags</h3>\n\
    <p>While the aim is to automate as much system-specific configuration as possible,\
    \ there are some options that have to be provided by the user, such as accounting\
    \ details, and unfortunately the syntax can vary.\nThe file <a href=\"./SYSTEMS.md\"\
    ><code>SYSTEMS.md</code></a> contains information about the use of this framework\
    \ on specific systems.</p>\n<h2><a id=\"user-content-contributing-new-systems-or-benchmarks\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing-new-systems-or-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\
    \ <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 8
  subscribers_count: 7
  topics: []
  updated_at: 1680953656.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/crusher/PrgEnv-gnu/spack.yaml
  - platformFiles/crusher/PrgEnv-cray/spack.yaml
  - platformFiles/polaris/gcc-11.2.0/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1><a id="user-content-useful-supplementary-materials-for-installing-the-xsdk"
    class="anchor" aria-hidden="true" href="#useful-supplementary-materials-for-installing-the-xsdk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful supplementary
    materials for installing the xSDK</h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics: []
  updated_at: 1669065329.0
yosef-zlochower/cactusamrex_copy:
  data_format: 2
  description: null
  filenames:
  - utils/Docker/cpu/make-image/spack.yaml
  - utils/Docker/gpu/make-image-gpu/spack.yaml
  full_name: yosef-zlochower/cactusamrex_copy
  latest_release: null
  readme: '<h1><a id="user-content-cactusamrex" class="anchor" aria-hidden="true"
    href="#cactusamrex"><span aria-hidden="true" class="octicon octicon-link"></span></a><a
    href="https://bitbucket.org/eschnett/cactusamrex" rel="nofollow">CactusAMReX</a></h1>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/carpetx.png"><img
    src="figures/carpetx.png" alt="CarpetX logo" style="max-width: 100%;"></a></p>

    <p><strong>CarpetX</strong> is a <a href="https://cactuscode.org/" rel="nofollow">Cactus</a>
    driver based on <a href="https://amrex-codes.github.io" rel="nofollow">AMReX</a>,
    a software framework for block-structured AMR (adaptive mesh refinement). CarpetX
    is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>.</p>

    <ul>

    <li>

    <a href="https://bitbucket.org/eschnett/cactusamrex" rel="nofollow">Bitbucket</a>:
    Source code repository</li>

    <li>

    <a href="https://dev.azure.com/schnetter/CactusAMReX/_build" rel="nofollow">Azure   Pipelines</a>:
    Build Status <a href="https://dev.azure.com/schnetter/CactusAMReX/_build/latest?definitionId=6&amp;branchName=master"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c376f6da8aa212a12313b10b09f29b30a096a8f4bc59b67c7baf9a5aaa2ad8a1/68747470733a2f2f6465762e617a7572652e636f6d2f7363686e65747465722f436163747573414d5265582f5f617069732f6275696c642f7374617475732f436163747573414d5265582d43493f6272616e63684e616d653d6d6173746572"
    alt="Build Status" data-canonical-src="https://dev.azure.com/schnetter/CactusAMReX/_apis/build/status/CactusAMReX-CI?branchName=master"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>CarpetX is almost ready for production. (The only missing feature is

    checkpointing/recovery.) You are welcome to give it a try, to look at

    what changes your code might need to benefit from CarpetX''s new

    features, and to give us feedback.</p>

    <p>The recorded talk <a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html"
    rel="nofollow">"Using CarpetX: A Guide for Early

    Adopters"</a>.

    This presentation provides an overview of the current capabilities of

    CarpetX and showcases how to write Cactus code using it.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>Here are instructions for downloading the Einstein Toolkit including

    CarpetX, building, and running an example.</p>

    <h3><a id="user-content-download-and-setup" class="anchor" aria-hidden="true"
    href="#download-and-setup"><span aria-hidden="true" class="octicon octicon-link"></span></a>Download
    and Setup</h3>

    <p>Download the Einstein Toolkit, including CarpetX. This will create a

    new directory <code>Cactus</code> that will contain the code:</p>

    <div class="highlight highlight-source-shell"><pre>curl -kLO https://raw.githubusercontent.com/gridaphobe/CRL/master/GetComponents

    perl GetComponents --parallel https://bitbucket.org/eschnett/cactusamrex/raw/master/manifest/einsteintoolkit-carpetx.th

    <span class="pl-c1">cd</span> Cactus</pre></div>

    <p>We''re using a Docker image to provide dependencies (including AMReX)

    to simplify installation. However, the Einstein Toolkit source code

    does not reside in that image; it resides in the <code>Cactus</code> directory

    which you just created. This leads to the following workflow:</p>

    <ul>

    <li>To download, look at, edit, git add/commit/pull/push etc. the code,

    you use the regular tools you already have installed on your system.

    Docker is not involved in this in any way.</li>

    <li>To build and run, you create an emphemeral (stateless) Docker

    container running Bash, with our Docker image mounted. For

    convenience, there is a shell script for this:</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>./repos/cactusamrex/utils/Docker/cpu/run-container</pre></div>

    <p>The first time you run this script, Docker will download the Docker

    image with the dependencies, which might take a few minutes.</p>

    <p>Inside this container, the hostname is <code>carpetx-docker-cpu</code>, so
    that

    you know you''re inside the container. (You exit the container by

    exiting the shell, e.g. with the <code>exit</code> command.)</p>

    <p>Note: While the container (running the Bash shell) is thrown away

    after each use, the changes to the file system you make persist, since

    your home directory is mounted and thus available in the container.</p>

    <p>As usual, the first time you use the Einstein Toolkit, you have to

    configure Simfactory for your local machine:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim setup</pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>Let''s build the toolkit with CarpetX.</p>

    <p>The default option list doesn''t point to AMReX nor some other

    dependencies. We thus specify our own. (I assume this could be fixed

    in the thorns handling these external dependencies.)</p>

    <p>The default thorn list would build the regular Einstein Toolkit

    without CarpetX; we need to specify a particular thorn list which

    includes all CarpetX thorns. This thorn list also disables those

    thorns that do not yet work with CarpetX.</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim build
    --optionlist=repos/cactusamrex/utils/Docker/cpu/carpetx.cfg --thornlist=repos/cactusamrex/utils/Docker/cpu/carpetx.th</pre></div>

    <p>Of course, once you created your configuration with the command above,

    to re-build after changing some code, the command is simply</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim build</pre></div>

    <p>as usual.</p>

    <h3><a id="user-content-run" class="anchor" aria-hidden="true" href="#run"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run</h3>

    <p>Let''s run some examples!</p>

    <p>Starting slowly, here is a scalar wave:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim submit
    planewave --parfile=arrangements/CarpetX/WaveToyCPU/par/planewave.par --procs=8
    --num-threads=8</pre></div>

    <p>You want to adapt the number of cores (<code>--procs</code>) and threads

    (<code>--num-threads</code>) to your system.</p>

    <p>It seems that the default Simfactory setup that was created above

    buffers the output, so that there might be long periords of time where

    the simulation appears to hang. Use <code>top</code> to see whether it is still

    running, and check the output directory to see whether it is still

    producing output.</p>

    <p>We can also run a binary black hole merger:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim submit
    planewave --parfile=arrangements/CarpetX/Z4c/par/qc0.rpar --procs=40 --num-threads=10</pre></div>

    <p>This setup requires more memory and time. I''m running it with about

    200 GByte of memory on 40 cores for 24 hours.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1680543777.0
youwuyou/slimfly_collectives:
  data_format: 2
  description: null
  filenames:
  - ompi1-dev/spack.yaml
  full_name: youwuyou/slimfly_collectives
  latest_release: null
  readme: '<h1><a id="user-content-slim-fly-mpi-collective-optimization" class="anchor"
    aria-hidden="true" href="#slim-fly-mpi-collective-optimization"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Slim Fly MPI collective optimization</h1>

    <blockquote>

    <p>TODO: this repo is reset and needs to be put under source control with the
    new structure! Remember to add the <code>.github/workflows/ci.yml</code> as in
    the current git repo</p>

    </blockquote>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1671447123.0
