ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced electromagnetic Particle-In-Cell code.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '22.05'
  readme: '<h1>

    <a id="user-content-warpx" class="anchor" href="#warpx" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width:100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width:100%;"></a>

    <a href="https://warpx.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width:100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width:100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width:100%;"></a>

    <a href="https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667"
    alt="Gitter" data-canonical-src="https://badges.gitter.im/ECP-WarpX/community.svg"
    style="max-width:100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width:100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width:100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width:100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width:100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width:100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width:100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width:100%;"></a>

    <a href="https://doi.org/10.1016/j.parco.2021.102833" rel="nofollow"><img src="https://camo.githubusercontent.com/1f6ca17eba9f0dbca214c58a50e39d5e4d2c5513476e963147c57c7b9f40f378/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313031362f6a2e706172636f2e323032312e3130323833332d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1016/j.parco.2021.102833-blue.svg"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-overview" class="anchor" href="#overview" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced electromagnetic Particle-In-Cell code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our Gitter room at <a href="https://gitter.im/ECP-WarpX/community" rel="nofollow">https://gitter.im/ECP-WarpX/community</a></p>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 134
  subscribers_count: 14
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1650387872.0
ECP-WarpX/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/artemis
  latest_release: null
  readme: '<h1>

    <a id="user-content-artemis" class="anchor" href="#artemis" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2>

    <a id="user-content-overview" class="anchor" href="#overview" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a development
    fork of WarpX for modeling micromagnetics and electrodynamic waves in next-generation
    microelectornics.</p>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width:100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 5
  subscribers_count: 5
  topics: []
  updated_at: 1651015699.0
EnzymeAD/CMake-Template:
  data_format: 2
  description: A template for using Enzyme with CMake
  filenames:
  - spack.yaml
  full_name: EnzymeAD/CMake-Template
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-cmake-template\" class=\"anchor\" href=\"#cmake-template\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>CMake-Template</h1>\n<h2>\n<a id=\"user-content-usage\" class=\"anchor\"\
    \ href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Usage</h2>\n<h3>\n<a id=\"user-content-install-dependencies\"\
    \ class=\"anchor\" href=\"#install-dependencies\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Install dependencies</h3>\n<ul>\n\
    <li>cmake</li>\n<li>make</li>\n<li>llvm</li>\n<li>enzyme</li>\n</ul>\n<p>Using\
    \ spack:</p>\n<pre><code>spack env load .\nspack install\n</code></pre>\n<p>Using\
    \ homebrew:</p>\n<pre><code>brew bundle install\n</code></pre>\n<h3>\n<a id=\"\
    user-content-configure-and-build\" class=\"anchor\" href=\"#configure-and-build\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Configure and build</h3>\n<p>Configure the CMake project using the\
    \ version of Enzyme installed on the system:</p>\n<pre><code>mkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake\n</code></pre>\n<p>Configure the CMake project using\
    \ a custom Enzyme version:</p>\n<pre><code>mkdir build &amp;&amp; cd build\ncmake\
    \ -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics:
  - cmake
  - enzyme-ad
  updated_at: 1644417729.0
FTHPC/libpressio_tutorial:
  data_format: 2
  description: A Tutorial for LibPressio
  filenames:
  - spack.yaml
  full_name: FTHPC/libpressio_tutorial
  latest_release: null
  readme: '<h1>

    <a id="user-content-libpressio-tutorial" class="anchor" href="#libpressio-tutorial"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>LibPressio
    Tutorial</h1>

    <p>This repository contains a number of example applications to help you learn
    how

    to use LibPressio lossy compression.  The exercises are located in <code>exercises/</code>

    and have their own instructions in the README.md file.</p>

    <p>When cloning the repo, be sure to clone the submodules</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/FTHPC/libpressio_tutorial</pre></div>

    '
  stargazers_count: 2
  subscribers_count: 2
  topics: []
  updated_at: 1651839310.0
FluidNumerics/SELF:
  data_format: 2
  description: Spectral Element Library in Fortran
  filenames:
  - env/spack.yaml
  - docker/base/nvidia/spack.yaml
  full_name: FluidNumerics/SELF
  latest_release: null
  readme: '<h1>

    <a id="user-content-spectral-element-libraries-in-fortran-self" class="anchor"
    href="#spectral-element-libraries-in-fortran-self" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Spectral Element Libraries in Fortran
    (SELF)</h1>

    <p>Copyright 2020-2022 Fluid Numerics LLC</p>

    <p><a href="https://self.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2cdea5d87038eae2bd52034d42848bdf0381c26e2ffe70a7a973e360004a19f6/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73656c662f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/self/badge/?version=latest"
    style="max-width:100%;"></a>

    <a href="https://codecov.io/gh/FluidNumerics/SELF" rel="nofollow"><img src="https://camo.githubusercontent.com/190632c16f2de9b4028909a9987ec0987590d74593c0133a6346d70373fb45ca/68747470733a2f2f636f6465636f762e696f2f67682f466c7569644e756d65726963732f53454c462f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d414b4b534c3543574b36"
    alt="codecov" data-canonical-src="https://codecov.io/gh/FluidNumerics/SELF/branch/main/graph/badge.svg?token=AKKSL5CWK6"
    style="max-width:100%;"></a>

    <a href="https://www.youtube.com/channel/UCW5e-TavOnw1AABGH-VMbRg?sub_confirmation=1"
    rel="nofollow"><img src="https://camo.githubusercontent.com/241f818a7c9fbbe538a27ae90073f54004dc794a7d2cab7ef50cb01c76e62cef/68747470733a2f2f696d672e736869656c64732e696f2f796f75747562652f6368616e6e656c2f73756273637269626572732f55435735652d5461764f6e773141414247482d564d6252673f7374796c653d736f6369616c"
    alt="Youtube" data-canonical-src="https://img.shields.io/youtube/channel/subscribers/UCW5e-TavOnw1AABGH-VMbRg?style=social"
    style="max-width:100%;"></a>

    <a href="https://www.reddit.com/r/FluidNumerics/" rel="nofollow"><img src="https://camo.githubusercontent.com/86acef9558f5e18573c4b9b4275d2eb6f59608130be921982dd5b0377650324a/68747470733a2f2f696d672e736869656c64732e696f2f7265646469742f7375627265646469742d73756273637269626572732f666c7569646e756d65726963733f7374796c653d736f6369616c"
    alt="Reddit" data-canonical-src="https://img.shields.io/reddit/subreddit-subscribers/fluidnumerics?style=social"
    style="max-width:100%;"></a></p>

    <p>SELF is licensed for use under the <a href="./LICENSE">Anti-Corporatist Software
    License</a>. For other licensure, reach out to <a href="mailto:support@fluidnumerics.com">support@fluidnumerics.com</a>.</p>

    <h2>

    <a id="user-content-about" class="anchor" href="#about" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>About</h2>

    <p>SELF is an object-oriented Fortran library that support the implementation
    of Spectral Element Methods for solving partial differential equations.</p>

    <p>The SELF API is designed based on the assumption that SEM developers and researchers
    need to be able to implement derivatives in 1-D and divergence, gradient, and
    curl in 2-D and 3-D on scalar, vector, and tensor functions using spectral collocation,
    continuous galerkin, and discontinuous galerkin spectral element methods. Additionally,
    as we enter the exascale era, we are currently faced with a zoo of compute hardware
    that is available. Because of this, SELF routines provide support for GPU acceleration
    through AMD''s HIP and support for multi-core, multi-node, and multi-GPU platforms
    with MPI.</p>

    <h2>

    <a id="user-content-support" class="anchor" href="#support" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <h3>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h3>

    <ul>

    <li><a href="https://fluidnumerics.github.io/SELF/ford/" rel="nofollow"><strong>API
    Documentation</strong></a></li>

    <li><a href="https://self.readthedocs.io/en/latest/" rel="nofollow"><strong>ReadTheDocs</strong>
    <em>(Work in Progress)</em></a></li>

    </ul>

    <h3>

    <a id="user-content-community" class="anchor" href="#community" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Community</h3>

    <h4>

    <a id="user-content-open-collective" class="anchor" href="#open-collective" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Open Collective</h4>

    <p>SELF is part of the Higher Order Methods Collective, which is fiscally hosted
    by <a href="https://www.waterchange.org" rel="nofollow">WATERCHaNGE</a>.

    You can keep track of updates and announcements for livestreams and training events
    at the <a href="https://opencollective.com/higher-order-methods" rel="nofollow">**Higher
    Order Methods Open Collective **</a>.</p>

    <p>You can support SELF and related educational activities focused on numerical
    analysis and higher order methods for solving conservation laws by contributing
    to the Open Collective.

    <a href="https://opencollective.com/higher-order-methods/contribute" rel="nofollow"><img
    src="https://github.com/opencollective/opencollective-images/raw/main/src/static/images/contribute.svg"
    alt="Open Collective" style="max-width:100%;"></a></p>

    <h3>

    <a id="user-content-maintainers" class="anchor" href="#maintainers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Maintainers</h3>

    <ul>

    <li><a href="https://fluidnumerics.com/people/joe-schoonover" rel="nofollow">Joseph
    Schoonover, Fluid Numerics LLC</a></li>

    <li>

    <strong>You</strong> Want to become a maintainer ? Reach out to <a href="mailto:support@fluidnumerics.com">support@fluidnumerics.com</a>

    </li>

    </ul>

    <p>If you''d like to contribute, see <a href="./CONTRIBUTING.md">CONTRIBUTING.md</a>
    to get started.</p>

    <p>If you need help, <a href="https://github.com/FluidNumerics/SELF/issues/new">open
    an issue</a></p>

    '
  stargazers_count: 18
  subscribers_count: 5
  topics:
  - spectral-element-method
  - gpu-acceleration
  - gpu-computing
  - hpc
  - pde-solver
  updated_at: 1648285157.0
Game4Move78/dotfiles:
  data_format: 2
  description: null
  filenames:
  - spack/spack/var/spack/environments/base/spack.yaml
  full_name: Game4Move78/dotfiles
  latest_release: null
  readme: '<h1>

    <a id="user-content-dotfiles" class="anchor" href="#dotfiles" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>dotfiles</h1>

    <p>Invoke <code>git submodule update --init --recursive</code> first to install
    submodules</p>

    <p>Example usage: <code>stow -R spacemacs</code></p>

    <h2>

    <a id="user-content-spack" class="anchor" href="#spack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack</h2>

    <p>Spack comes with a ~/.spackenv dotfile that needs to be sourced from your shell
    of choice</p>

    <p>From then to build the base environment you have to run</p>

    <pre><code>spack install -j$(nproc)

    </code></pre>

    <p>If zsh changes may only take effect after running <code>rehash</code></p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1638195529.0
MichaelBrim/unify-olcf-scripts:
  data_format: 2
  description: null
  filenames:
  - crusher/spack-env/spack.yaml
  - summit/spack-env/spack.yaml
  full_name: MichaelBrim/unify-olcf-scripts
  latest_release: null
  readme: '<h1>

    <a id="user-content-unify-olcf-scripts" class="anchor" href="#unify-olcf-scripts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>unify-olcf-scripts</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649778838.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-22.02/spack.yaml
  - spack-configs/cori-e4s-21.05/spack.yaml
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/cori-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml
  - spack-configs/cori-e4s-21.02/prod/spack.yaml
  - spack-configs/cori-e4s-21.02/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-spack-infrastructure\" class=\"anchor\" href=\"\
    #spack-infrastructure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file.</p>\n<h2>\n<a id=\"user-content-spack-configuration\"\
    \ class=\"anchor\" href=\"#spack-configuration\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack Configuration</h2>\n<p>The\
    \ spack configuration can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<table>\n<thead>\n<tr>\n<th>system</th>\n\
    <th>status</th>\n<th>PIPELINE_NAME</th>\n<th>description</th>\n<th>spack.yaml</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>Perlmutter</td>\n<td><strong>IN-PROGRESS</strong></td>\n\
    <td><code>PERLMUTTER_SPACK_DEVELOP</code></td>\n<td>This spack configuration is\
    \ based on <code>spack@develop</code> branch to see what packages can be built.\
    \ We expect this pipeline will fail and we are not expected to fix build failure.\
    \ The main purpose of this project is to build as many packages across all the\
    \ compilers, mpi, blas providers of interest and see what works. Since we don't\
    \ know which package works during deployment, we will leverage data from this\
    \ pipeline to make informed decision what packages should be picked with given\
    \ compilers. This pipeline is our development and we should use this to experiment\
    \ new compilers. Note that we won't hardcode versions for packages since we want\
    \ to build with latest release. However we will hardcode externals depending on\
    \ how system is configured.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>IN-PROGRESS</strong></td>\n<td><code>CORI_SPACK_DEVELOP</code></td>\n\
    <td>This spack configuration will build E4S stack using spack <code>develop</code>\
    \ branch on Cori.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-spack-develop/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-spack-develop/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>CORI_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on Cori using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Gerty</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>GERTY_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on gerty using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11_DEPLOY</code></td>\n\
    <td>This spack configuration is deployment configuration for E4S/21.11. For more\
    \ details on this stack see  <a href=\"https://docs.nersc.gov/applications/e4s/perlmutter/21.11/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/perlmutter/21.11/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11</code></td>\n\
    <td>This spack configuration is used for development for building E4S/21.11 using\
    \ scheduled pipeline.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Muller</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>MULLER_E4S_21.11</code></td>\n\
    <td>This spack configuration was used to build E4S/21.11 on Muller using scheduled\
    \ pipeline. Once e4s/21.11 was built on Muller we followed up with building the\
    \ same spack configuration on Perlmutter.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.05\
    \ spack stack based on <a href=\"https://github.com/spack/spack/tree/e4s-21.05\"\
    >e4s-21.05</a> branch of spack. This stack can be accessed via <code>module load\
    \ e4s/21.05</code>.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration used for deployment purposes, this can be accessed via <code>module\
    \ load e4s/21.02</code> on Cori. For more details see <a href=\"https://docs.nersc.gov/applications/e4s/cori/21.02/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/21.02/</a>\n</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration that push to buildcache.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration that push to build cache using <code>spack ci</code>.  This\
    \ project lives in <a href=\"https://software.nersc.gov/NERSC/e4s-2010\" rel=\"\
    nofollow\">https://software.nersc.gov/NERSC/e4s-2010</a> and configuration was\
    \ copied over here.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration for Cori used for deployment purpose. This stack can be\
    \ accessed via <code>module load e4s/20.10</code>. This is documented at <a href=\"\
    https://docs.nersc.gov/applications/e4s/cori/20.10/\" rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/20.10/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml</a></td>\n\
    </tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-running-ci-pipelines\" class=\"\
    anchor\" href=\"#running-ci-pipelines\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>.</p>\n<table>\n<thead>\n\
    <tr>\n<th>System</th>\n<th>Runner Name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n</tr>\n<tr>\n<td>cori</td>\n\
    <td><code>cori-e4s</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    </tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n</tr>\n</tbody>\n\
    </table>\n<p>The runner configuration files are located in <code>~/.gitlab-runner</code>\
    \ for user <strong>e4s</strong>.</p>\n<p>The production pipelines are triggered\
    \ via web-interface which requires approval from a project maintainer. Production\
    \ pipelines should be run when we need to do full redeployment of stack.</p>\n\
    <h2>\n<a id=\"user-content-troubleshooting-gitlab-runner\" class=\"anchor\" href=\"\
    #troubleshooting-gitlab-runner\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Troubleshooting gitlab runner</h2>\n\
    <p>You will need to login as <code>e4s</code> user via <code>collabsu</code> command.\
    \ This will prompt you for password which is your <strong>NERSC password</strong>\
    \ for your username not <strong>e4s</strong> user.</p>\n<pre><code>collabsu e4s\n\
    </code></pre>\n<p>Once you are logged in, you can login to the desired system\
    \ to restart the runner. You can check the runner status by navigating to <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\" rel=\"\
    nofollow\">Settings &gt; CI/CD &gt; Runners</a>. If gitlab runner is down you\
    \ will need to restart the runner which is located in <code>$HOME/cron</code>\
    \ directory for e4s user.</p>\n<p>For instance, to access muller you will need\
    \ to login to Cori/DTN nodes and run <code>ssh login.muller.nersc.gov</code>.</p>\n\
    <p>The <code>gitlab-runner</code> command should be accessible with e4s user.\
    \ To register a runner you can run <code>gitlab-runner register</code> and follow\
    \ the prompt. The runner configuration will be written to <code>~/.gitlab-runner/config.toml</code>\
    \ however we recommend you create a separate config.toml or copy the file to separate\
    \ file. For instance if you want to register a runner for muller you can set <code>gitlab-runner\
    \ register -c ~/.gitlab-runner/muller.config.toml</code> when registering the\
    \ runner and it will write the runner configuration to <code>~/.gitlab-runner/muller.config.toml</code>.\
    \ For more details regarding runner register please see <a href=\"https://docs.gitlab.com/runner/register/\"\
    \ rel=\"nofollow\">https://docs.gitlab.com/runner/register/</a></p>\n<p>To restart\
    \ a runner you can run the script based on runner type</p>\n<pre><code># restart\
    \ gerty runner\nbash $HOME/cron/restart-gerty.sh\n\n# restart muller runner\n\
    bash $HOME/cron/restart-muller.sh\n\n# restart perlmutter runner\nbash $HOME/cron/restart-perlmutter.sh\n\
    \n# restart cori runner\nbash $HOME/cron/restart-cori.sh\n</code></pre>\n<p>In\
    \ order to access gerty, you will need to login to data transfer node and then\
    \ login to gerty as follows</p>\n<pre><code>ssh dtn01.nersc.gov\ncollabsu e4s\n\
    ssh gerty\n</code></pre>\n<h2>\n<a id=\"user-content-current-challenges\" class=\"\
    anchor\" href=\"#current-challenges\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have externals set to packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2>\n<a id=\"user-content-contact\" class=\"anchor\" href=\"#contact\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 1
  subscribers_count: 14
  topics: []
  updated_at: 1646024620.0
NOAA-EMC/WW3:
  data_format: 2
  description: WAVEWATCH III
  filenames:
  - model/ci/spack.yaml
  full_name: NOAA-EMC/WW3
  latest_release: 6.07.1
  readme: "<h1>\n<a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ href=\"#the-wavewatch-iii-framework\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2>\n<a id=\"user-content-general-features\" class=\"anchor\" href=\"#general-features\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2>\n<a id=\"user-content-disclaimer\" class=\"anchor\" href=\"#disclaimer\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 171
  subscribers_count: 41
  topics: []
  updated_at: 1651425035.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/apps/nco-wcoss2/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-stack" class="anchor" href="#spack-stack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>spack-stack is a collaborative effort between the NOAA Environmental Modeling
    Center (EMC), the UCAR Joint Center for Satellite Data Assimilation (JCSDA), and
    the Earth Prediction Innovation Center (EPIC). spack-stack is designed to support
    the various applications of the supporting agencies such as the Unified Forecast
    System (UFS) or the Joint Effort for Data assimilation Integration (JEDI). The
    stack can be installed on a range of platforms, from Linux and macOS laptops to
    HPC systems, and comes pre-configured for many systems. Users can install the
    necessary packages for a particular application and later add the missing packages
    for another application without having to rebuild the entire stack.</p>

    <p><a href="https://github.com/spack/spack">spack</a> is a community-supported,
    multi-platform, Python-based package manager originally developed by the Lawrence
    Livermore National Laboratory (LLNL; <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager"
    rel="nofollow">https://computing.llnl.gov/projects/spack-hpc-package-manager</a>).
    It is provided as a submodule so that a stable version can be referenced. <a href="https://spack.readthedocs.io/en/latest/"
    rel="nofollow">See the Spack Documentation for more information</a></p>

    <p>spack-stack is mainly a collection of Spack configuration files, but provides
    a few Python scripts to simplify the installation process:</p>

    <ul>

    <li>

    <code>create.py</code> is provided to copy common, site-specific, and application-specific
    configuration files into a coherent Spack environment and to create container
    recipes</li>

    <li>

    <code>meta_modules/setup_meta_modules.py</code> creates compiler, MPI and Python
    meta-modules for a convenient setup of a user environment using modules (lua and
    tcl)</li>

    </ul>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>Kyle Gerheiser (@kgerheiser), NOAA-EMC</li>

    <li>Dom Heinzeller (@climbfuji), JCSDA</li>

    <li>not yet appointed, EPIC</li>

    </ul>

    <p>Ready-to-use spack-stack installations are available on the following platforms:</p>

    <p><strong>Note: this versions are for early testers - use at your own risk</strong></p>

    <table>

    <thead>

    <tr>

    <th>System</th>

    <th>Location</th>

    <th>Maintained by (temporary)</th>

    <th>jedi-ewok tested</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>MSU Orion</td>

    <td><code>/work/noaa/gsd-hpcs/dheinzel/spack-stack-20220411-ewok-tmp</code></td>

    <td>Dom Heinzeller</td>

    <td>yes</td>

    </tr>

    <tr>

    <td>NASA Discover</td>

    <td><code>/discover/swdev/jcsda/spack-stack/spack-stack-v0.0.1/envs/jedi-all-intel-2022.0.1/install</code></td>

    <td>Dom Heinzeller</td>

    <td>yes</td>

    </tr>

    <tr>

    <td>NCAR-Wyoming Cheyenne</td>

    <td><code>/glade/work/jedipara/cheyenne/spack-stack/spack-stack-v0.0.1/envs/jedi-all-intel-2022.0.2/install</code></td>

    <td>Dom Heinzeller</td>

    <td>yes</td>

    </tr>

    <tr>

    <td>NOAA NCO WCOSS2</td>

    <td></td>

    <td></td>

    <td></td>

    </tr>

    <tr>

    <td>NOAA RDHPCS Gaea</td>

    <td><code>/lustre/f2/pdata/esrl/gsd/spack-stack/spack-stack-v0.0.1</code></td>

    <td>Dom Heinzeller</td>

    <td>yes</td>

    </tr>

    <tr>

    <td>NOAA RDHPCS Hera</td>

    <td></td>

    <td></td>

    <td></td>

    </tr>

    <tr>

    <td>NOAA RDHPCS Jet</td>

    <td></td>

    <td></td>

    <td></td>

    </tr>

    </tbody>

    </table>

    <p>For questions or problems, please consult the currently open <a href="https://github.com/noaa-emc/spack-stack/issues">issues</a>
    and the <a href="https://github.com/noaa-emc/spack-stack/discussions">current
    and past discussions</a> first.</p>

    <p><strong>Note. spack-stack is in early development and not yet ready for use.
    Instructions may be incomplete or invalid.</strong></p>

    <h2>

    <a id="user-content-quickstart" class="anchor" href="#quickstart" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Quickstart</h2>

    <pre><code>git clone https://github.com/NOAA-EMC/spack-stack.git

    cd spack-stack


    # Ensure Python 3.7+ is available and the default before sourcing spack


    # Sources Spack from submodule and sets ${SPACK_STACK_DIR}

    source setup.sh


    # Basic usage of create.py

    ./create.py -h

    </code></pre>

    <h3>

    <a id="user-content-create-local-environment" class="anchor" href="#create-local-environment"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Create
    local environment</h3>

    <pre><code># See a list of sites and apps

    ./create.py environment -h


    # Create a pre-configured Spack environment in envs/&lt;app&gt;.&lt;site&gt;

    # (copies site-specific, application-specific, and common config files into the
    environment directory)

    ./create.py environment --site hera --app jedi-fv3 --name jedi-fv3.hera


    # Activate the newly created environment

    # Optional: decorate the command line prompt using -p

    #     Note: in some cases, this can mess up long lines in bash

    #     because color codes are not escaped correctly. In this

    #     case, use export SPACK_COLOR=''never'' first.

    spack env activate [-p] envs/jedi-fv3.hera


    # Optionally edit config files (spack.yaml, packages.yaml compilers.yaml, site.yaml)

    emacs envs/jedi-fv3.hera/spack.yaml

    emacs envs/jedi-fv3.hera/common/*.yaml

    emacs envs/jedi-fv3.hera/site/*.yaml


    # Process the specs and install

    # Note: both steps will take some time!

    spack concretize

    spack install


    # Create lua module files

    spack module lmod refresh


    # Create meta-modules for compiler, mpi, python

    ./meta_modules/setup_meta_modules.py

    </code></pre>

    <h3>

    <a id="user-content-create-container" class="anchor" href="#create-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Create
    container</h3>

    <pre><code># See a list of preconfigured containers

    ./create.py container -h


    # Create container spack definition (spack.yaml) in directory envs/&lt;spec&gt;.&lt;config&gt;

    ./create.py container --config docker-ubuntu-gcc-openmpi --spec esmf


    # Descend into container environment directory

    cd envs/esmf.docker-ubuntu-gcc-openmpi


    # Optionally edit config file

    emacs spack.yaml


    # Docker: create Dockerfile and build container

    # See section "container" in spack.yaml for additional information

    spack containerize &gt; Dockerfile

    docker build -t myimage .

    docker run -it myimage

    </code></pre>

    <h2>

    <a id="user-content-generating-new-site-config" class="anchor" href="#generating-new-site-config"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Generating
    new site config</h2>

    <p>Recommended: Start with an empty (default) site config. Then run <code>spack
    external find</code> to locate common external packages such as git, Perl, CMake,
    etc., and run <code>spack compiler find</code> to locate compilers in your path.
    Compilers or external packages with modules need to be added manually.</p>

    <pre><code>./create.py environment --site default --app jedi-ufs --name jedi-ufs.mysite


    # Descend into site config directory

    cd envs/jedi-ufs.mysite/site


    # Find external packages and compilers, output the files here

    # (overwrites packages.yaml and compilers.yaml)

    SPACK_SYSTEM_CONFIG_PATH=`pwd` spack external find --all --scope system

    SPACK_SYSTEM_CONFIG_PATH=`pwd` spack compiler find --scope system


    # Optionally edit config files as above in the quickstart section


    # Optionally attempt to find additional packages by name,

    # for example: "spack external find wget"

    </code></pre>

    <p>It is also instructive to peruse the GitHub actions scripts in <code>.github/workflows</code>
    and <code>.github/actions</code> to see how automated spack-stack builds are configured
    for CI testing, as well as the existing site configs in <code>configs/sites</code>.</p>

    <h2>

    <a id="user-content-known-issues" class="anchor" href="#known-issues" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Known issues</h2>

    <h3>

    <a id="user-content-general" class="anchor" href="#general" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>General</h3>

    <ol>

    <li>First call to <code>spack concretize</code> fails with <code>[Errno 2] No
    such file or directory: ... .json</code>

    This can happen when <code>spack concretize</code> is called the very first time
    in a new spack-stack clone, during which the boostrapping (installation of clingo)
    is done first. Simply rerunning the command should solve the problem.</li>

    </ol>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 1
  subscribers_count: 6
  topics: []
  updated_at: 1644294917.0
NOAA-GFDL/AM4:
  data_format: 2
  description: null
  filenames:
  - container/spack_intel_gfdl_model.yaml
  full_name: NOAA-GFDL/AM4
  latest_release: '2021.03'
  readme: '<h1>

    <a id="user-content-gfdl-am4-model" class="anchor" href="#gfdl-am4-model" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL AM4 Model</h1>

    <p><a href="https://zenodo.org/badge/latestdoi/102487636" rel="nofollow"><img
    src="https://camo.githubusercontent.com/878db836b9000fd7d9ff531257cade7343f3a3fdf8f764b5a7f1e8ef6ccc6abe/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3130323438373633362e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/102487636.svg" style="max-width:100%;"></a></p>

    <p>This repository includes the public release of the GFDL AM4 model

    code.  The AM4 model is described in the

    <a href="https://doi.org/10.1002/2017MS001208" rel="nofollow">two</a>

    <a href="https://doi.org/10.1002/2017MS001209" rel="nofollow">articles</a> published
    in the

    <a href="https://agupubs.onlinelibrary.wiley.com/journal/19422466" rel="nofollow">Journal
    of Advances in Modeling Earth Systems

    (JAMES)</a>.

    More information on the model and access to the output is available on

    the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">AM4
    data and code

    site</a> at the

    <a href="https://www.gfdl.noaa.gov" rel="nofollow">Geophysical Fluid Dynamics
    Laboratory

    (GFDL)</a>.</p>

    <p>The layout of this package includes the following directories:</p>

    <ul>

    <li>src - The source code for the AM4 model</li>

    <li>exec - The build directory with Makefiles for building the AM4 model executable</li>

    <li>idealized_exec - The build directory with Makefiles for building the aquaplanet

    and doubly periodic executable</li>

    <li>run - Sample run script and updated files needed for running</li>

    <li>analysis - Sample analysis scripts</li>

    </ul>

    <h2>

    <a id="user-content-cloning-instructions" class="anchor" href="#cloning-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cloning
    Instructions</h2>

    <p>This repository uses <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"
    rel="nofollow">git

    submodules</a> to

    point to other repositories.  Thus, care should be taken when cloning,

    and updating the source to ensure all source.  To obtain all source,

    use the following git command</p>

    <pre><code>git clone --recursive https://github.com/NOAA-GFDL/AM4.git

    </code></pre>

    <p>The <code>--recursive</code> option to <code>git clone</code> instructs git
    to recursively

    clone all submodules.  In the event the repository was not cloned

    using the <code>--recursive</code> option, the following step must be taken to

    obtain all sources:</p>

    <pre><code># From within the AM4 parent directory

    git submodule update --init --recursive

    </code></pre>

    <h2>

    <a id="user-content-source-code" class="anchor" href="#source-code" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Code</h2>

    <p>All model source is contained in the <a href="src">src</a> directory.  GFDL

    tracks code using the git version control system.  This package

    includes a single version of the following GFDL model components.  The

    git hash listed corresponds to the commit hash in the internal GFDL

    git repository.</p>

    <table>

    <thead>

    <tr>

    <th>Component</th>

    <th>Commit Hash</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>atmos_drivers</td>

    <td>5ee95d6abf0879594551dd7e6635dff4004c4010</td>

    </tr>

    <tr>

    <td>atmos_param</td>

    <td>2e94acfd8621e85216bf822c395a8c3f15a511a5</td>

    </tr>

    <tr>

    <td>atmos_shared</td>

    <td>a557d4d7bab033ef1ad1d400a62fe07a97ccb477</td>

    </tr>

    <tr>

    <td>ice_param</td>

    <td>1553c8bc4f9a66791c89367b6f327147523155ed</td>

    </tr>

    <tr>

    <td>ice_sis</td>

    <td>ccc7328dcd79706dd5c17c8bab660222886fc80b</td>

    </tr>

    <tr>

    <td>land_lad2</td>

    <td>a220288ecb289bf9d793d051fc5076072874ce07</td>

    </tr>

    </tbody>

    </table>

    <p>The following components are available in the

    <a href="https://github.com/NOAA-GFDL">NOAA-GFDL</a> github organization:</p>

    <ul>

    <li><a href="https://github.com/NOAA-GFDL/MOM6">MOM6</a></li>

    <li><a href="https://github.com/NOAA-GFDL/coupler">coupler</a></li>

    <li>

    <a href="https://github.com/NOAA-GFDL/FMS">FMS</a> (as <a href="src/shared">shared</a>)</li>

    <li>

    <a href="https://github.com/NOAA-GFDL/GFDL_atmos_cubed_sphere">GFDL_atmos_cubed_sphere
    (tag AM4.0)</a> (as <a href="src/atmos_cubed_sphere">atmos_cubed_sphere</a>)</li>

    </ul>

    <h2>

    <a id="user-content-building-am4" class="anchor" href="#building-am4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building AM4</h2>

    <p>###Containers

    The <a href="container">container folder</a> provides example Dockerfiles and
    Signularity

    definition files to use to build AM4 containers using either GCC/GFORTAN or

    Intel oneAPI. There is a script that can be used to build the intel

    singularity containers, and the first step of this script can be used with the

    other GFDL climate models.</p>

    <h3>

    <a id="user-content-from-source" class="anchor" href="#from-source" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>From source</h3>

    <p>The <a href="exec">exec</a> directory contains Makefiles that can be used to

    build the AM4 executable.  These Makefiles were generated using the

    <a href="https://github.com/NOAA-GFDL/mkmf">Make Makefile (mkmf)</a> program.

    Included in the exec direcgtory is a sample make template file for the

    Intel compilers (<a href="exec/templates/intel.mk">intel.mk</a>).  This make

    template can be used on any system with a relatively recent version of

    the Intel compilers, the netCDF 4 library and the MPICH2 MPI library.

    Included in the <a href="exec/templates/intel.mk">intel.mk</a> file are

    additional settings that can be modified during the build.</p>

    <p>To run the default build (-O3 -msse2), go to the exec directory and

    enter the command</p>

    <pre><code>make

    </code></pre>

    <p>If you would like to change some of the compiler options, there are several
    different

    options to add to the make command.  For example</p>

    <pre><code>make ISA=-xhost BLD_TYPE=REPRO

    </code></pre>

    <p>will replace -msse with -xhost and -O3 with -O2.  The three options for

    <code>BLD_TYPE</code> are<br>

    <code>PROD</code> (-O3)<br>

    <code>REPRO</code> (-O2)<br>

    <code>DEBUG</code> (-O0 and other traps)<br>

    All of the make line options can be

    found in the <a href="exec/templates/intel.mk">intel.mk</a> file.</p>

    <h2>

    <a id="user-content-obtaining-the-input-data" class="anchor" href="#obtaining-the-input-data"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining
    the input data</h2>

    <p>The input data required for running the AM4 model can be found on

    <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">GFDL''s
    data

    portal</a> .</p>

    <p>The file <code>AM4.tar.gz</code> contains a configured run directory to run
    a

    sample experiment of the AM4 model.  Included in the tar file is a

    README.AM4_run with more instructions on how to configure the AM4 run

    directory.</p>

    <p>On Linux systems, the <code>wget</code> command is usually sufficient to download
    the data

    file:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz

    </code></pre>

    <p>To ensure the file downloaded is complete and not corrupted, download one of
    the two files:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sha256

    wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sig

    </code></pre>

    <p>and run the following command that corresponds to the signature file downloaded:</p>

    <pre><code>sha256sum -c AM4_run.tar.gz.sha256

    </code></pre>

    <pre><code>gpg --verify AM4_run.tar.gz.sig

    </code></pre>

    <h2>

    <a id="user-content-running-am4" class="anchor" href="#running-am4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running AM4</h2>

    <p>Included in the run directory is a sample run script for reference.

    To run the AM4 sample experiment, first download the data file

    mentioned in <a href="#obtaining-the-input-data">Obtaining the Input data</a>

    section.  Replace diag_table and input.nml in the top level of the

    untar''d directory with the corresponding files in the run directory

    of this repository. Modify the variables in the configuration section

    in the sample run script, and then run the script.</p>

    <p>The sample data and run script are configured to run on 216

    processors.  To run on a different number of processors, or modify the

    experiment, refer to the <code>README.AM4_run</code> file included in the AM4

    data tarball.</p>

    <p>Note: The <code>input.nml</code> file (found in the AM4 data tarball) contains

    Fortran namelists and namelist variables that modify, at run time, the

    model.  To learn more about the settings in the <code>input.nml</code> file,

    please refer to source code where the namelist/variable are defined.</p>

    <h2>

    <a id="user-content-analysis-scripts" class="anchor" href="#analysis-scripts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analysis
    Scripts</h2>

    <p>Some of the climate analysis scripts run at NOAA GFDL and used in the

    AM4 documentation papers are located in the analysis directory.

    Within each analysis suite, is a <a href="https://jupyter-notebook.readthedocs.io/en/stable/"
    rel="nofollow">jupyter

    notebook</a>, both

    readable and runnable from your local jupyter environment, provided

    all dependencies are installed.</p>

    <p>E.g.</p>

    <ul>

    <li><a href="analysis/cjs1/radiation_atmos_av_mon/radiation_atmos_av_mon.ipynb">Radiation
    processor</a></li>

    <li><a href="analysis/bw/bw_atmos_cru_ts_a1r/bw_atmos_monthly_cru_ts.1980-2014.ipynb">Long-term
    DJF seasonal mean</a></li>

    <li><a href="analysis/bw/bw_atmos_zm_atl_pac_a1r/bw_atmos_atl_pac.1980-2014.ipynb">Zonal_mean_zonal_wind_stress</a></li>

    <li><a href="analysis/pcmdimetrics/portraitPlot-AM4.AMIP.ipynb">PCMDI Metrics
    Portrait Plot</a></li>

    </ul>

    <h2>

    <a id="user-content-model-output-and-other-references" class="anchor" href="#model-output-and-other-references"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model
    output and Other References</h2>

    <p>Please refer to the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/"
    rel="nofollow">AM4 data and code

    site</a> for details

    about where to find model and OBS data used in the papers.</p>

    <p>For all analysis figures and pertaining data, please use the AM4

    documentation papers as the original reference.</p>

    <p>Please direct your questions and feedback to

    <a href="mailto:gfdl.climate.model.info@noaa.gov">gfdl.climate.model.info@noaa.gov</a></p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an ''as is'' basis and the user assumes responsibility for

    its use.  DOC has relinquished control of the information and no

    longer has responsibility to protect the integrity, confidentiality,

    or availability of the information.  Any claims against the Department

    of Commerce stemming from the use of its GitHub project will be

    governed by all applicable Federal law.  Any reference to specific

    commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply

    their endorsement, recommendation or favoring by the Department of

    Commerce.  The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <p>This project code is made available through GitHub but is managed by

    NOAA-GFDL at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 11
  subscribers_count: 7
  topics:
  - fortran
  - jupyter-notebook
  - shell-script
  - ncl
  updated_at: 1645229928.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Configuration files for Spack at Pawsey
  filenames:
  - setonix/environments/env_s3_clients/spack.yaml
  - setonix/environments/env_benchmarking/spack.yaml
  - setonix/environments/env_apps/spack.yaml
  - setonix/environments/env_wrf/spack.yaml
  - setonix/environments/env_python/spack.yaml
  - setonix/environments/env_langs/spack.yaml
  - setonix/environments/env_astro/spack.yaml
  - setonix/environments/env_num_libs/spack.yaml
  - setonix/environments/env_roms/spack.yaml
  - setonix/environments/env_vis/spack.yaml
  - setonix/environments/env_utils/spack.yaml
  - setonix/environments/env_io_libs/spack.yaml
  - setonix/environments/env_bio/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1>

    <a id="user-content-pawsey-spack-config" class="anchor" href="#pawsey-spack-config"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>pawsey-spack-config</h1>

    <p>Configuration files for Spack at Pawsey.</p>

    <h2>

    <a id="user-content-setonix-setup" class="anchor" href="#setonix-setup" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setonix setup</h2>

    <p>This can be found in the <code>setonix/</code> directory.<br>

    See <code>README.md</code> in there for further information.</p>

    <h2>

    <a id="user-content-other-setups" class="anchor" href="#other-setups" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Other setups</h2>

    <ul>

    <li>

    <code>examples/</code>: deployment examples and tests</li>

    <li>

    <code>examples/joey_sprint/</code>: team sprints on Joey</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 10
  topics: []
  updated_at: 1641801068.0
SC-SGS/CPPuddle:
  data_format: 2
  description: Utility library to handle small, reusable pools of both device memory
    buffers (via allocators) and device executors (with multiple scheduling policies).
  filenames:
  - spack.yaml
  full_name: SC-SGS/CPPuddle
  latest_release: v0.1.0
  readme: "<h3>\n<a id=\"user-content-cppuddle\" class=\"anchor\" href=\"#cppuddle\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>CPPuddle</h3>\n<p><a href=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml\"\
    ><img src=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml/badge.svg\"\
    \ alt=\"ctest\" style=\"max-width:100%;\"></a>\n<a href=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/view/Octo-Tiger%20and%20Dependencies/job/CPPuddle/job/master/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f85055028a87ff41032206704d36fede5e5cc779d3369a6650f02d9d46676a45/68747470733a2f2f73696d7367732e696e666f726d6174696b2e756e692d7374757474676172742e64652f6a656e6b696e732f6275696c645374617475732f69636f6e3f6a6f623d4350507564646c652532466d617374657226636f6e6669673d616c6c6275696c6473\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=CPPuddle%2Fmaster&amp;config=allbuilds\"\
    \ style=\"max-width:100%;\"></a></p>\n<h4>\n<a id=\"user-content-purpose\" class=\"\
    anchor\" href=\"#purpose\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Purpose</h4>\n<p>This repository was initially\
    \ created to explore how to best use HPX and Kokkos together!\nFor fine-grained\
    \ GPU tasks, we needed a way to avoid excessive allocations of one-usage GPU buffers\
    \ (as allocations block the device for all streams) and creation/deletion of GPU\
    \ executors (as those are usually tied to a stream which is expensive to create\
    \ as well).</p>\n<p>We currently test/use CPPuddle in <a href=\"https://github.com/STEllAR-GROUP/octotiger\"\
    >Octo-Tiger</a>, together with <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\
    >HPX-Kokkos</a>.\nIn this use-case, allocating GPU buffers for all sub-grids in\
    \ advance would have wasted a lot of memory. On the other hand, unified memory\
    \ would have caused unnecessary GPU to CPU page migrations (as the old input data\
    \ gets overwritten anyway). Allocating buffers on-the-fly would have blocked the\
    \ device. Hence, we currently test this buffer management solution!</p>\n<h4>\n\
    <a id=\"user-content-tools-provided-by-this-repository\" class=\"anchor\" href=\"\
    #tools-provided-by-this-repository\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Tools provided by this repository</h4>\n\
    <ul>\n<li>Allocators that reuse previousely allocated buffers if available (works\
    \ with normal heap memory, pinned memory, aligned memory, CUDA/HIP device memory,\
    \ and Kokkos Views). Note that separate buffers do not coexist on a single chunk\
    \ of continuous memory, but use different allocations.</li>\n<li>Executor pools\
    \ and various scheduling policies (round robin, priority queue, multi-gpu), which\
    \ rely on reference counting to gauge the current load of a executor instead of\
    \ querying the device itself. Tested with CUDA, HIP and Kokkos executors provided\
    \ by HPX / HPX-Kokkos.</li>\n</ul>\n<h4>\n<a id=\"user-content-requirements\"\
    \ class=\"anchor\" href=\"#requirements\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Requirements</h4>\n<ul>\n<li>C++14</li>\n\
    <li>CMake (&gt;= 3.11)</li>\n<li>Optional (for the header-only utilities / test):\
    \ CUDA, Boost, <a href=\"https://github.com/STEllAR-GROUP/hpx\">HPX</a>, <a href=\"\
    https://github.com/kokkos/kokkos\">Kokkos</a>, <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\
    >HPX-Kokkos</a>\n</li>\n</ul>\n<p>The submodules can be used to obtain the optional\
    \ dependencies which are required for testing the header-only utilities. If these\
    \ tests are not required, the submodule (and the respective buildscripts in /scripts)\
    \ can be ignored safely.</p>\n<h4>\n<a id=\"user-content-build--install\" class=\"\
    anchor\" href=\"#build--install\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Build / Install</h4>\n<pre><code>\
    \  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle\
    \ -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF                     \
    \                                        \n  cmake --build /path/to/build -- -j4\
    \ VERBOSE=1                                                                  \
    \                                                                            \
    \                                                            \n  cmake --build\
    \ /path/to/build --target install  \n</code></pre>\n<p>If installed correctly,\
    \ cppuddle can be used in other cmake-based projects via</p>\n<pre><code>find_package(CPPuddle\
    \ REQUIRED)\n</code></pre>\n"
  stargazers_count: 1
  subscribers_count: 4
  topics: []
  updated_at: 1647424834.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/archived/rhel7-runner-ppc64le/spack.yaml
  - docker-recipes/ubuntu20.04-runner-x86_64/spack.yaml
  - docker-recipes/archived/special/superlu-sc/spack.yaml
  - docker-recipes/archived/rhel7-runner-x86_64/spack.yaml
  - docker-recipes/rhel8-runner-x86_64/spack.yaml
  - docker-recipes/ubuntu20.04-runner-ppc64le/spack.yaml
  - docker-recipes/rhel8-runner-ppc64le/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a href="figures/SDKdefinition1.png" target="_blank" rel="noopener noreferrer"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width:100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 18
  subscribers_count: 6
  topics: []
  updated_at: 1644561389.0
akarmas/sample-ebrains-component:
  data_format: 2
  description: showcase how to mirror from github to EBRAINS Gitlab
  filenames:
  - .ebrains/spack/component-name_spack.yaml
  full_name: akarmas/sample-ebrains-component
  latest_release: v0.1
  readme: '<h1>

    <a id="user-content-sample-ebrains-component" class="anchor" href="#sample-ebrains-component"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>sample-ebrains-component</h1>

    <p>The project aims to showcase i) how to set up a mirror code repository from
    Github to

    EBRAINS Gitlab and ii) the necessary configurations to allow the automated update
    of

    the mirror on certain events.

    It can be used to facilitate the initial integration requirements that an EBRAINS
    component

    team has to fulfill.

    The steps that need to be followed to achieve this are detailed below and all
    the files in

    the present project can be used as an example and reference.

    Let''s assume that we want to mirror a code repository from Github (source_repo)
    to EBRAINS

    Gitlab (mirror=destination_repo).</p>

    <p>The goal is to set up the destination_repo and configure the source_repo to
    automatically

    update the destination_repo when certain events occur.

    In this example the event that triggers the automated update is a push event in
    the master branch.</p>

    <p>At the EBRAINS Gitlab perform the following steps:</p>

    <ol>

    <li>Create an empty project at gitlab.ebrains.eu (destination_repo_name)</li>

    <li>Create a gitlab service account on the new project (detailed documentation
    <a href="https://docs.gitlab.com/ee/user/project/settings/project_access_tokens.html"
    rel="nofollow">here</a>)

    From the left-side menu navigate to:<br>

    Settings &gt; Access tokens and<br>

    i) set the name variable of the service account (here, Name: ghpusher)<br>

    ii) set the expiration date of the project access token to be created (here, Expire
    Date: leave empty to never expire)<br>

    iii) select all the scopes<br>

    and then click the "Create project access token" button<br>

    The new project access token will be created and you need to save the new project
    access

    token because you will not be able to access it again (you will need the project
    access token

    later in the process of setting up the mirror)</li>

    <li>Then navigate again from the left-side menu to<br>

    Settings &gt; Repository &gt; Protected branches<br>

    and set "Allow force push" to On, for the branches you want to sync from the source_repo
    to

    the destination_repo (for this particular example only the master branch will
    be available)</li>

    </ol>

    <p>Then at Github perform the following steps:</p>

    <ol start="4">

    <li>Navigate to the source_repo that you want to mirror to EBRAINS</li>

    <li>Navigate from the horizontal menu to:<br>

    Settings &gt; Secrets &gt; New repository secret<br>

    i) Set the name of the secret (here EBRAINS_GITLAB_ACCESS_TOKEN)<br>

    ii) Set as the value of the secret the token that you created and saved at step
    2.<br>

    iii) Click the "Add secret" button</li>

    <li>Create the .github/workflows directories in the source_repo (detailed documentation
    <a href="https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions">here</a>)</li>

    <li>In the .github/workflows directory create a yml file (here ebrains.yml)

    and define the rules for synching the destination_repo with Github Actions</li>

    </ol>

    <p>Note that the file ebrains_explanation.yml aims to explain the ebrains.yml
    and

    facilitate the reader to use it as a template.</p>

    <h2>

    <a id="user-content-acknowledgments" class="anchor" href="#acknowledgments" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgments</h2>

    <p>Credits to the Arbor team for initially implementing the flow (ebrains mirror
    <a href="https://gitlab.ebrains.eu/arbor-sim/arbor" rel="nofollow">here</a>).</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1633429913.0
antoine-morvan/spack-offline-env:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: antoine-morvan/spack-offline-env
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1644310043.0
boutproject/BOUT-configs:
  data_format: 2
  description: Configuration scripts for BOUT++
  filenames:
  - lassen/spack_env/bout/spack.yaml
  - lassen/spack_env/bout_petsc_with_hypre/spack.yaml
  full_name: boutproject/BOUT-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-configuration-scripts" class="anchor" href="#configuration-scripts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configuration
    scripts</h1>

    <p>The CMake and autotools (configure/make) scripts supplied with BOUT++

    should be able to automatically find and configure BOUT++ in most

    cases. Where a complex configuration is desired, for example including

    many dependencies (esp. complex dependencies like PETSc), or compiling

    for GPUs, configuration can be quite complex.</p>

    <p>The files in this directory are intended to be convenient shortcuts for

    configuration on particular machines. Where there are many scripts, these

    are put into sub-directories (e.g. "cori" and "lassen").</p>

    <h2>

    <a id="user-content-environment" class="anchor" href="#environment" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Environment</h2>

    <p>Scripts which set up the environment, for example loading and unloading

    modules, start with <code>setup</code> or <code>setup-env</code>. These are typically
    modifying

    shell environments and so should be invoked with <code>source</code>.</p>

    <h2>

    <a id="user-content-bout-configuration" class="anchor" href="#bout-configuration"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>BOUT++
    configuration</h2>

    <p>The wrappers around CMake (or configure) start with <code>config</code> or
    <code>config-bout</code>.

    These are shell scripts which can be run without <code>source</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1638261451.0
cayrols/internal_fiber:
  data_format: 2
  description: 'Purpose: PR'
  filenames:
  - .github/CI/spack.yaml
  full_name: cayrols/internal_fiber
  latest_release: null
  readme: "<p><a href=\"https://camo.githubusercontent.com/95208d9a920443b4cae72a2560512aad27c686017c663cb71aa8f434c86f0b08/68747470733a2f2f6269746275636b65742e6f72672f616179616c6133322f6c6f676f732f7261772f646530386466336333626664396435393535383762663834306633316166636234356436303139632f66696265722e706e67\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/95208d9a920443b4cae72a2560512aad27c686017c663cb71aa8f434c86f0b08/68747470733a2f2f6269746275636b65742e6f72672f616179616c6133322f6c6f676f732f7261772f646530386466336333626664396435393535383762663834306633316166636234356436303139632f66696265722e706e67\"\
    \ alt=\"FBI_banner\" data-canonical-src=\"https://bitbucket.org/aayala32/logos/raw/de08df3c3bfd9d595587bf840f31afcb45d6019c/fiber.png\"\
    \ style=\"max-width:100%;\"></a></p>\n<p><strong>FFT Benchmarking Initiative</strong></p>\n\
    <p><strong>Innovative Computing Laboratory</strong></p>\n<p><strong>University\
    \ of Tennessee</strong></p>\n<hr>\n<h1>\n<a id=\"user-content-about\" class=\"\
    anchor\" href=\"#about\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>About</h1>\n<p>The FFT Infrastructure Benchmark\
    \ for Exascale Research (FIBER) provides a framework for Fast Fourier Transform\
    \ (FFT) benchmarks targeting exascale computing systems. It evaluates performance\
    \ and scalability of distributed FFTs on different architectures. Furthermore,\
    \ it analyzes the effect on applications that directly depend on FFTs. It can\
    \ also stress and test the overall network of a supercomputer, give an indication\
    \ on bisection bandwidth, noise, and other network and MPI collectives limitations\
    \ that are of interest to many other ECP applications.</p>\n<p>The current harness\
    \ software puts together FFT libraries supporting distributed 3-D complex-to-complex\
    \ and real-to-complex FFTs.</p>\n<hr>\n<h1>\n<a id=\"user-content-setting-up\"\
    \ class=\"anchor\" href=\"#setting-up\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up</h1>\n<p>Create a\
    \ folder; e.g., <code>Benchmarks_FFT</code>, and install the FFT libraries to\
    \ benchmark; or load them as modules.</p>\n<pre><code>-- Benchmarks_FFT\n    \
    \    |-- heFFTe\n        |-- fftMPI\n        |-- AccFFT\n        |-- P3DFFT\n\
    \        |-- FFTE\n        |-- SWFFT\n        |-- 2DECOMP&amp;FFT\n        |--\
    \ nb3dFFT\n        |-- FFTW\n        |-- FFTW++\n</code></pre>\n<p>Current libraries\
    \ targeted by FIBER:</p>\n<ul>\n<li>\n<p>CPU support: <a href=\"https://lammps.github.io/fftmpi/\"\
    \ rel=\"nofollow\">fftMPI</a>, <a href=\"https://xgitlab.cels.anl.gov/hacc/SWFFT\"\
    \ rel=\"nofollow\">SWFFT</a>,\n<a href=\"https://github.com/sdsc/p3dfft.3\">P3DFFT</a>,\n\
    <a href=\"https://gitlab.jsc.fz-juelich.de/goebbert/nb3dfft\" rel=\"nofollow\"\
    >nb3dFFT</a>,\n<a href=\"http://www.2decomp.org/download.html\" rel=\"nofollow\"\
    >2DECOMP&amp;FFT</a>, <a href=\"http://www.fftw.org/\" rel=\"nofollow\">FFTW</a>,\
    \ <a href=\"fftwpp.sourceforge.net/\">FFTW++</a></p>\n</li>\n<li>\n<p>CPU-GPU\
    \ support: <a href=\"https://bitbucket.org/icl/heffte\" rel=\"nofollow\">heFFTe</a>,\
    \ <a href=\"https://github.com/amirgholami/accfft\">AccFFT</a>,   <a href=\"http://www.ffte.jp/\"\
    \ rel=\"nofollow\">FFTE</a></p>\n</li>\n</ul>\n<h1>\n<a id=\"user-content-compilation\"\
    \ class=\"anchor\" href=\"#compilation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compilation</h1>\n<p>Next clone\
    \ this repository and create  build folder, and execute the <code>cmake</code>\
    \ commands.\nIn the following example, we install FIBER with heFFTe and fftMPI\
    \ backends:</p>\n<pre><code>mkdir build; cd $_\nbuild/\ncmake -DFIBER_FFT_LIB_DIRS=\"\
    /home/Benchmarks_FFT/fftmpi/src;/home/heffte/build/lib\"\n-DFIBER_FFT_INCLUDE_DIRS=\"\
    /home/Benchmarks_FFT/fftmpi/src;/home/heffte/build/include\"\n-DFIBER_ENABLE_HEFFTE=ON\
    \ -DFIBER_ENABLE_FFTMPI=ON\n-DMPI_DIR=/sw/openmpi/4.0.0/ .. \nmake -j\n</code></pre>\n\
    <p>List the <code>lib</code> and <code>include</code> folders of libraries to\
    \ test, respectively, in <code>FIBER_FFT_LIB_DIRS</code> and <code>FIBER_FFT_INCLUDE_DIRS</code>.</p>\n\
    <h1>\n<a id=\"user-content-testing-integration\" class=\"anchor\" href=\"#testing-integration\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Testing integration</h1>\n<p>Run tests as follows:</p>\n<pre><code>cd\
    \ build/benchmarks\nmpirun -n 2 ./test3D_CPU_C2C &lt;library&gt;\nmpirun -n 2\
    \ ./test3D_CPU_R2C &lt;library&gt;\n</code></pre>\n<p>If FIBER was build linked\
    \ to GPU enabled libraries:</p>\n<pre><code>cd build/benchmarks\nmpirun -n 2 ./test3D_GPU_C2C\
    \ &lt;gpu_library&gt;\nmpirun -n 2 ./test3D_GPU_R2C &lt;gpu_library&gt;\n</code></pre>\n\
    <h1>\n<a id=\"user-content-running-benchmarks\" class=\"anchor\" href=\"#running-benchmarks\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running benchmarks</h1>\n<pre><code>cd build/benchmarks\nmpirun -n\
    \ $NUM_RANKS ./test3D_C2C -lib &lt;library&gt; -backend &lt;1D_backend&gt; -size\
    \ &lt;nx&gt; &lt;ny&gt; &lt;nz&gt; -pgrid &lt;p&gt; &lt;q&gt;\n</code></pre>\n\
    <p>where <code>library</code> has to be replaced by one of the nine available\
    \ libraries, provided user has it installed.\nOnce a parallel FFT library has\
    \ been correctly integrated to heFFTe, running these benchmarks should report\
    \ a correct validation output.</p>\n<h1>\n<a id=\"user-content-documentation\"\
    \ class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<ul>\n<li>Installation\
    \ and a Doxygen documentation will be available shortly.</li>\n</ul>\n<hr>\n<h1>\n\
    <a id=\"user-content-getting-help\" class=\"anchor\" href=\"#getting-help\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting\
    \ Help</h1>\n<p>For assistance with the FIBER project, email <em><a href=\"mailto:fiber@icl.utk.edu\"\
    >fiber@icl.utk.edu</a></em> or start a GitHub issue.</p>\n<p>Contributions are\
    \ very welcome, please create a pull request.</p>\n<h1>\n<a id=\"user-content-resources\"\
    \ class=\"anchor\" href=\"#resources\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Resources</h1>\n<ul>\n<li>Visit\
    \ the <a href=\"http://icl.utk.edu/fiber/\" rel=\"nofollow\">FIBER website</a>\
    \ for more information about the HeFFTe project.</li>\n<li>Visit the <a href=\"\
    https://exascaleproject.org\" rel=\"nofollow\">ECP website</a> to find out more\
    \ about the DOE Exascale Computing Initiative.</li>\n</ul>\n<hr>\n<h1>\n<a id=\"\
    user-content-acknowledgments\" class=\"anchor\" href=\"#acknowledgments\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h1>\n\
    <p>This research was supported by the United States Exascale Computing Project.</p>\n\
    <hr>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>License</h1>\n<pre><code>Copyright (c) 2022, University of Tennessee\n\
    All rights reserved.\n\nRedistribution and use in source and binary forms, with\
    \ or without\nmodification, are permitted provided that the following conditions\
    \ are met:\n    * Redistributions of source code must retain the above copyright\n\
    \      notice, this list of conditions and the following disclaimer.\n    * Redistributions\
    \ in binary form must reproduce the above copyright\n      notice, this list of\
    \ conditions and the following disclaimer in the\n      documentation and/or other\
    \ materials provided with the distribution.\n    * Neither the name of the University\
    \ of Tennessee nor the\n      names of its contributors may be used to endorse\
    \ or promote products\n      derived from this software without specific prior\
    \ written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\
    \ CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT\
    \ NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\
    \ PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL UNIVERSITY OF TENNESSEE\
    \ BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\
    \ DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\
    \ SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\
    \ CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\
    \ OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\
    \ OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1645724748.0
charmoniumQ/astrophysics-project:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: charmoniumQ/astrophysics-project
  latest_release: null
  readme: '<h1>

    <a id="user-content-neural-network-superresolving-for-cosmological-simulations"
    class="anchor" href="#neural-network-superresolving-for-cosmological-simulations"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Neural
    Network Superresolving for Cosmological Simulations</h1>

    <p>In this repository, I attempt to reproduce the analysis of <a href="https://arxiv.org/pdf/2111.06393.pdf"
    rel="nofollow">Schaurecker et

    al. 2021</a> on Enzo data (they use Illustris).</p>

    <h1>

    <a id="user-content-to-reproduce" class="anchor" href="#to-reproduce" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>To reproduce</h1>

    <p>The code <code>main.py</code> is intended to be run locally. It sends commands
    to the

    remote. You will need to modify this with your site-specific parameters. It

    should be the only file you need to modify.</p>

    <p>To set up the remote machine (should be capable of Slurm):</p>

    <div class="highlight highlight-source-shell"><pre>remote$ <span class="pl-c"><span
    class="pl-c">#</span> Install Spack on the remote</span>

    remote$ git clone -c feature.manyFiles=true https://github.com/spack/spack.git


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy spack.lock to the
    remote</span>

    remote$ spack/bin/spack environment create main4 spack.lock

    remote$ spack/bin/spack environment activate main4

    remote$ spack/bin/spack concretize

    remote$ spack/bin/spack install


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy envirment.yaml ot
    the remote</span>

    remote$ spack/bin/spack activate main4

    remote$ conda install --name main3 --file environment,yaml


    remote$ <span class="pl-c"><span class="pl-c">#</span> Ensure that Slurm works</span>

    remote$ sbatch --help</pre></div>

    <p>To set up the local machine:</p>

    <div class="highlight highlight-source-shell"><pre>locla$ <span class="pl-c"><span
    class="pl-c">#</span> Install conda</span>

    locla$ <span class="pl-c"><span class="pl-c">#</span> Install conda environment</span>

    local$ conda install --name main3 --file environment,yaml</pre></div>

    <p>You will need to configure SSH keys to the remote.</p>

    <p>Then you should be to run <code>main.py</code>. <code>main.py</code> runs the
    entire workflow. It is

    smart about not running a certain step if the data already exists. It also

    hashes the input parameters in the filename of the data, so it is unlikely to

    return stale data.</p>

    <p>The end result will end up in <code>output</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1650312591.0
cinemascienceworkflows/exawind-naluwind:
  data_format: 2
  description: Exawind Naluwind workflow
  filenames:
  - inputs/spack/spack.yaml
  full_name: cinemascienceworkflows/exawind-naluwind
  latest_release: null
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643754675.0
cinemascienceworkflows/miniapp:
  data_format: 2
  description: Ascent-based miniapp workflows
  filenames:
  - inputs/spack/spack.yaml
  full_name: cinemascienceworkflows/miniapp
  latest_release: null
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1646254492.0
eugeneswalker/clacc-ci:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/clacc-ci
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1643137385.0
floquet/builds:
  data_format: 2
  description: Notes and scripts for building applications on HPCs
  filenames:
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/reaper/2022-02-17_14,48/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-03-04_09,42/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-01-31_21,26/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-01-31_21,26/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-03-04_09,42/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-03-04_09,42/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/reaper/2022-02-17_14,48/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-03-04_09,42/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-03-04_09,42/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-03-04_09,42/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  full_name: floquet/builds
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641760136.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-clang/spack.yaml
  - ubuntu-gcc/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1>

    <a id="user-content-synergia2-containers" class="anchor" href="#synergia2-containers"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for x86-haswell ISA and these
    containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1646758059.0
goma/goma:
  data_format: 2
  description: A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport
  filenames:
  - spack.yaml
  full_name: goma/goma
  latest_release: v7.0.5
  readme: '<h1>

    <a id="user-content-goma" class="anchor" href="#goma" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Goma</h1>

    <p>A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport</p>

    <p>For more information see the <a href="https://www.gomafem.com" rel="nofollow">Goma
    website</a></p>

    <h2>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Most of the documentation can be found at <a href="https://www.gomafem.com/documentation.html"
    rel="nofollow">https://www.gomafem.com/documentation.html</a></p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>See <a href="LICENSE">LICENSE</a> file. Some cmake modules under <code>cmake/</code>
    were modified from the Eigen library

    and are noted at the top of the cmake file.</p>

    <h2>

    <a id="user-content-major-changes" class="anchor" href="#major-changes" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Major Changes</h2>

    <p>See <a href="CHANGES.md">CHANGES.md</a></p>

    <h2>

    <a id="user-content-build-instructions" class="anchor" href="#build-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Instructions</h2>

    <p>See <a href="BUILD.md">BUILD.md</a></p>

    <h2>

    <a id="user-content-spack-package" class="anchor" href="#spack-package" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack package</h2>

    <p>The Spack package manager <a href="https://spack.io/" rel="nofollow">https://spack.io</a>
    can be used to install

    Goma and all of Goma''s third party libraries</p>

    <p>Currently available on the <code>develop</code> branch of spack.</p>

    <p>Example for a bash-like shell:</p>

    <pre><code>git clone https://github.com/spack/spack.git

    . spack/share/spack/setup-env.sh

    spack install goma

    </code></pre>

    <p>For more information on build options see:</p>

    <pre><code>spack info goma

    </code></pre>

    <p>For more information on using spack see the <a href="https://spack.readthedocs.io/en/latest/"
    rel="nofollow">spack documentation</a>.</p>

    <h2>

    <a id="user-content-third-party-libraries" class="anchor" href="#third-party-libraries"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Third
    party libraries</h2>

    <ul>

    <li>Metis 5.1.0 (Optional)</li>

    <li>SEACAS 2022-01-27 (Required: Exodus and Aprepro)</li>

    <li>BLAS/LAPACK (Configured through Trilinos)</li>

    <li>Trilinos matrix solvers 13.0.1 and up (Required: AztecOO, Amesos, Epetra,
    TPL LAPACK; Optional: Stratimikos [with Teko, Ifpack, Belos, Tpetra])</li>

    <li>PETSc matrix solvers (KSP, PC)</li>

    <li>MUMPS 5.4.0 (through Trilinos or PETSc only)</li>

    <li>Superlu_dist 7.2.0 (through Trilinos or PETSc only, Trilinos requires parmetis
    build)</li>

    <li>UMFPACK, SuiteSparse 5.10.1 (Optional)</li>

    <li>ARPACK/arpack-ng 3.8.0 (Optional)</li>

    <li>sparse 1.4b (Optional)</li>

    <li>Catch2 (Optional testing)</li>

    </ul>

    <h3>

    <a id="user-content-run-the-tutorial" class="anchor" href="#run-the-tutorial"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Run
    the tutorial</h3>

    <p>To get started with Goma, use the following:</p>

    <ul>

    <li><a href="https://docs.gomafem.com/files/goma-beginners-tutorial.pdf" rel="nofollow">Tutorial
    instructions</a></li>

    <li><a href="https://docs.gomafem.com/files/goma_beginners_tutorial.tar.gz" rel="nofollow">Tutorial
    files tarball</a></li>

    </ul>

    '
  stargazers_count: 79
  subscribers_count: 22
  topics:
  - finite-elements
  - finite-element-analysis
  - simulation
  - parallel
  - multiphysics
  - fem
  - snl-applications
  updated_at: 1647130875.0
gyselax/gyselalibxx:
  data_format: 2
  description: Gyselalib++ is a collection of C++ components for writing gyrokinetic
    semi-lagrangian codes and similar
  filenames:
  - spack.yaml
  full_name: gyselax/gyselalibxx
  latest_release: null
  readme: '<h1>

    <a id="user-content-gyselalib" class="anchor" href="#gyselalib" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Gyselalib++</h1>

    <p>Gyselalib++ is a collection of C++ components for writing gyrokinetic semi-lagrangian
    codes and

    similar as well as a collection of such codes.</p>

    <h2>

    <a id="user-content-compilation" class="anchor" href="#compilation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h2>

    <p>to compile voice++:</p>

    <pre><code>git clone --recurse-submodules git@gitlab.maisondelasimulation.fr:gysela-developpers/voicexx.git

    cd voicexx

    mkdir build

    cd build

    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-Wall -Wno-sign-compare" ..

    make

    </code></pre>

    <h2>

    <a id="user-content-execution" class="anchor" href="#execution" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Execution</h2>

    <p>to run the tests:</p>

    <pre><code>ctest --output-on-failure

    </code></pre>

    <p>Then, just have a look at <code>tests/landau/growthrate_t0.0to45.0.png</code>:</p>

    <p><a href="https://camo.githubusercontent.com/b767f6df1712f338f85a7b0b813f7452888524845e8a67bf6223a02a8ca6dc83/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f67726f777468726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/b767f6df1712f338f85a7b0b813f7452888524845e8a67bf6223a02a8ca6dc83/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f67726f777468726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/growthrate_t0.0to45.0.png" title="Landau damping rate" data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/growthrate_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width:100%;"></a></p>

    <p>and <code>tests/landau/frequency_t0.0to45.0.png</code>:</p>

    <p><a href="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/frequency_t0.0to45.0.png" title="Landau damping frequency"
    data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/frequency_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>To install dependencies through spack, first follow the the 3 first steps of

    <a href="https://github.com/pdidev/spack">https://github.com/pdidev/spack</a></p>

    <p>Then execute the following:</p>

    <div class="highlight highlight-source-shell"><pre>spack env create voice spack.yaml

    spack env activate voice

    spack concretize --reuse

    spack install</pre></div>

    <p>For example, you can find a Dockerfile installing these dependencies on ubuntu
    in

    <code>voicexx_env/Dockerfile</code>.</p>

    '
  stargazers_count: 3
  subscribers_count: 1
  topics:
  - hpc
  - numerical-simulation
  - gyrokinetic
  - poisson-solver
  - vlasov-solver
  - plasma-physics
  - ddc
  updated_at: 1646130547.0
hepnos/HEPnOS:
  data_format: 2
  description: HEPnOS is a distributed object store for high energy physics applications,
    developed at Argonne National Laboratory.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS
  latest_release: v0.6.4
  readme: '<h1>

    <a id="user-content-hepnos" class="anchor" href="#hepnos" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS</h1>

    <p>HEPnOS is the <em>High-Energy Physics''s new Object Store</em>, a distributed
    storage

    system specially designed for HEP experiments and workflows for the FermiLab.

    HEPnOS relies on libraries developed at Argonne National Laboratory within the

    context of the Mochi project (ANL, CMU, LANL, HDF Group).</p>

    <p>For information on copyright and licensing, see the COPYRIGHT file.

    For information on how to use, see the <a href="https://xgitlab.cels.anl.gov/sds/HEPnOS/wikis/home"
    rel="nofollow">wiki</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641296454.0
hepnos/HEPnOS-Dataloader:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-Dataloader
  latest_release: v0.5.2
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1643644851.0
hppritcha/spack_ompix:
  data_format: 2
  description: null
  filenames:
  - intel_master_x86_64/spack.yaml
  - gnu_master_x86_64/spack.yaml
  full_name: hppritcha/spack_ompix
  latest_release: null
  readme: '<p>Project for using Gitlab CI to test spack builds of Open MPI master
    and release tarballs.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1640037910.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/eagle/compilers/spack.yaml
  - configs/eagle/utilities/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    configuration files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1651762796.0
justbennet/biospack:
  data_format: 2
  description: Setting up Spack to provide Bioinformatics packages
  filenames:
  - environments/arc/spack.yaml
  full_name: justbennet/biospack
  latest_release: null
  readme: '<h1>

    <a id="user-content-biospack" class="anchor" href="#biospack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Biospack</h1>

    <p>These are files that provide local customization for the Spack installation

    that is used to provide Bioinformatics packages on the Great Lakes and

    Armis clusters.  This was all intended for use on Red Hat 8 systems, and

    the Spack installation will cohabit software installed in the traditional

    manner.  We are consciously restricting ourselves to non-MPI software,

    and only for Bioinformatics.</p>

    <p>The presumption is that these will be used to set up the test Spack for a

    new contributor, so all the settings in the configuration files presume a

    root directory of <code>/var/software/$USER</code>, and that all Spack created
    files

    (including temporary files) will be in directories beneath it.</p>

    <p>The files in the repository can be modified to create a Spack installation

    to provide the production installation intended for real users.  The targets

    should be</p>

    <p>Software:  <code>/sw/pkgs/bio</code>

    Modules:  <code>/sw/modules/bio/spack</code></p>

    <p>To set up a new installation, first run the <code>start_new_biospack</code>
    script.

    That will create the <code>/var/software/$USER/bio</code> directory, clone Spack

    itself into it, prompt you for the version of Spack to set, create the

    directories used for Spack temporary and cache files.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1650732078.0
lcompilers/lpython:
  data_format: 2
  description: Python compiler
  filenames:
  - spack.yaml
  full_name: lcompilers/lpython
  latest_release: null
  readme: '<h1>

    <a id="user-content-lpython" class="anchor" href="#lpython" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LPython</h1>

    <p>LPython is a Python compiler. It is in heavy development, currently in

    pre-alpha stage. Some of the goals of LPython:</p>

    <ul>

    <li>The best possible performance for numerical array oriented code</li>

    <li>Run on all platforms</li>

    <li>Compile a subset of Python and be Python compatible</li>

    <li>Explore how to design it so that it can be eventually used with any Python

    code</li>

    <li>Fast compilation</li>

    <li>Excellent user friendly diagnostic messages: error, warnings, hints, notes,

    etc.</li>

    <li>Ahead of time compilation to binaries and interactive usage (Jupyter

    notebook)</li>

    <li>Able to transform the Python code to C++, Fortran and other languages</li>

    </ul>

    <p>And more.</p>

    <h1>

    <a id="user-content-installation" class="anchor" href="#installation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h1>

    <p>LPython works on Windows, macOS and Linux.</p>

    <h2>

    <a id="user-content-install-conda" class="anchor" href="#install-conda" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Install Conda</h2>

    <p>If you do not have Conda already installed, please follow the instructions

    here to install Conda on your platform:</p>

    <p><a href="https://github.com/conda-forge/miniforge/#download">https://github.com/conda-forge/miniforge/#download</a></p>

    <h2>

    <a id="user-content-compile-lpython" class="anchor" href="#compile-lpython" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compile LPython</h2>

    <p>Install required packages (Linux - 64 bit):</p>

    <div class="highlight highlight-source-shell"><pre>sudo apt install binutils-dev</pre></div>

    <p>Clone LPython</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/lcompilers/lpython.git

    <span class="pl-c1">cd</span> lpython</pre></div>

    <p>Create a Conda environment using the preexisting environment.yml file:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment.yml

    conda activate lp</pre></div>

    <p>Create autogenerated files (choose the command for your platform):</p>

    <div class="highlight highlight-source-shell"><pre>./build0.sh      <span class="pl-c"><span
    class="pl-c">#</span> macOS/Linux</span>

    call build0.bat  <span class="pl-c"><span class="pl-c">#</span> Windows</span></pre></div>

    <p>Compile LPython:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -DCMAKE_BUILD_TYPE=Debug
    -DWITH_LLVM=yes -DWITH_STACKTRACE=yes -DWITH_LFORTRAN_BINARY_MODFILES=no <span
    class="pl-c1">.</span>

    cmake --build <span class="pl-c1">.</span> -j16</pre></div>

    <h2>

    <a id="user-content-tests" class="anchor" href="#tests" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Tests:</h2>

    <p>Run tests:</p>

    <div class="highlight highlight-source-shell"><pre>ctest

    ./run_tests.py</pre></div>

    <p>Also, run the integration tests:</p>

    <div class="highlight highlight-source-shell"><pre>./integration_tests/run_tests.py</pre></div>

    <h2>

    <a id="user-content-examples" class="anchor" href="#examples" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Examples</h2>

    <p>You can run the following examples by hand in a terminal:</p>

    <div class="highlight highlight-source-shell"><pre>./src/bin/lpython examples/expr2.py

    ./a.out

    ./src/bin/lpython --show-ast examples/expr2.py

    ./src/bin/lpython --show-asr examples/expr2.py

    ./src/bin/lpython --show-cpp examples/expr2.py

    ./src/bin/lpython --show-llvm examples/expr2.py</pre></div>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>We welcome contributions from anyone, even if you are new to open source. It

    might sound daunting to contribute to a compiler at first, but please do, it is

    not complicated. We will help you with any technical issues and help improve

    your contribution so that it can be merged.</p>

    <p>To contribute, submit a Pull Request (PR) against our repository at:</p>

    <p><a href="https://github.com/lcompilers/lpython">https://github.com/lcompilers/lpython</a></p>

    <p>Please report any bugs you may find at our issue tracker: <a href="https://github.com/lcompilers/lpython/issues">https://github.com/lcompilers/lpython/issues</a>.

    Or, even better, fork the repository on GitHub and create a PR. We welcome all
    changes, big or small, and we will help you make a PR if you are new to git.</p>

    <p>If you have any questions or need help, please ask us at Zulip (<a href="https://lfortran.zulipchat.com/"
    rel="nofollow"><img src="https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667"
    alt="project chat" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg"
    style="max-width:100%;"></a>) or our

    <a href="https://groups.io/g/lfortran" rel="nofollow">mailinglist</a>.</p>

    <p>See the <a href="CONTRIBUTING.md">CONTRIBUTING</a> document for more information.</p>

    '
  stargazers_count: 33
  subscribers_count: 5
  topics: []
  updated_at: 1651650529.0
mochi-hpc-experiments/mochi-xfer-benchmark:
  data_format: 2
  description: Mochi transfer benchmark
  filenames:
  - spack.yaml
  full_name: mochi-hpc-experiments/mochi-xfer-benchmark
  latest_release: null
  readme: '<h1>

    <a id="user-content-mochi-xfer-benchmark" class="anchor" href="#mochi-xfer-benchmark"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    Xfer Benchmark</h1>

    <p>This benchmark is specifically designed to answer one question:

    what is the best way to transfer N bytes from a client to a server

    in Mochi, on a given platform? Its tests includes relying on RPC

    arguments, registering a different buffer at every operation for

    RDMA, or re-using a preregistered buffer (which for clients

    means copying the payload to it).</p>

    <h2>

    <a id="user-content-installing" class="anchor" href="#installing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <p>This program can be installed using spack, provided that you have

    the <a href="https://github.com/mochi-hpc/mochi-spack-packages">Mochi repository</a>

    added to your spack installation.</p>

    <pre><code>$ spack install mochi-xfer-benchmark

    </code></pre>

    <h2>

    <a id="user-content-using-the-benchmark" class="anchor" href="#using-the-benchmark"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    the benchmark</h2>

    <p>Once installed, the <code>mochi-xfer-benchmark</code> can be used as a two-process

    MPI program. It provides the following options:</p>

    <ul>

    <li>

    <code>-p/--protocol</code> (required): protocol to use (<code>na+sm</code>, <code>ofi+tcp</code>,
    etc.).</li>

    <li>

    <code>-o/--output</code> (required): name of the output CSV file.</li>

    <li>

    <code>-i/--iterations</code>: number of repetitions of each operation.</li>

    <li>

    <code>-c/--client-protocol</code>: protocol for the client to use, if different

    from that of the server.</li>

    <li>

    <code>-v/--verbose</code>: logging level (trace, debug, info, warning, error,
    critical, off).</li>

    <li>

    <code>--client-use-progress-thread</code>: if provided, the client will use a
    dedicated

    progress thread.</li>

    <li>

    <code>--server-use-progress-thread</code>: if provided, the server will use a
    dedicated

    progress thread.</li>

    <li>

    <code>--server-num-handler-threads</code>: number of handler threads (0, 1, or
    -1).

    With 0, RPCs will execute in the primary ES. With 1, they will execute in

    a dedicated ES. With -1, they will execute in the ES in which the progress

    loop runs.</li>

    <li>The remaining, non-labelled arguments forms the list of transfer sizes.</li>

    </ul>

    <p>The benchmark will output a CSV file containing the results of the following

    operations. "Send" and "Receive" are understood from the point of view of the

    server (e.g. <code>recv-args</code> means that the server will receive the payload
    via

    RPC arguments).</p>

    <h3>

    <a id="user-content-recv-args" class="anchor" href="#recv-args" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>recv-args</h3>

    <p>The client sends the payload as an RPC argument.</p>

    <h3>

    <a id="user-content-recv-rdma-xy" class="anchor" href="#recv-rdma-xy" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>recv-rdma-(x,y)</h3>

    <p>The server uses RDMA PULL to get the payload from the client.</p>

    <p><code>x</code> may be <code>new</code> (new registration) or <code>pre</code>
    (pre-registered bulk).

    In the former case, the client creates a bulk handle to expose its

    payload at every iteration. In the latter case, the client uses a

    pre-allocated buffer and pre-registered bulk handle, and does a

    <code>memcpy</code> of its payload in this buffer prior to sending the RPC.</p>

    <p>Similarly <code>y</code> may be <code>new</code> or <code>pre</code>. In the
    former case, at every

    operation the server will allocate a new buffer and register it

    before doing a PULL. In the latter case, the server will rely on

    a pre-allocated buffer and a corresponding pre-registered bulk

    handle. No memcpy is performed in this case.</p>

    <h3>

    <a id="user-content-send-resp" class="anchor" href="#send-resp" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>send-resp</h3>

    <p>The server sends its payload as an RPC response.</p>

    <h3>

    <a id="user-content-send-rdma-xy" class="anchor" href="#send-rdma-xy" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>send-rdma-(x,y)</h3>

    <p>The server uses RDMA PUSH to send its payload to the client.</p>

    <p><code>x</code> may be <code>new</code> or <code>pre</code>. In the former case,
    the client creates

    a bulk handle to expose the buffer in which it wants the data to

    be placed. In the latter case, it relies on a pre-allocated buffer

    and associated pre-registered bulk handle, and does a memcpy once

    the data has arrived.</p>

    <p>Similarly, <code>y</code> may be <code>new</code> or <code>pre</code>. In the
    former case, at every

    operation the server allocates a new buffer and registers it

    before doing a PUSH. In the latter case, the server will rely on

    a pre-allocated buffer and a corresponding pre-registered bulk

    handle.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1637930437.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - NERSC/Perlmutter/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1>

    <a id="user-content-platform-configurations-for-mochi" class="anchor" href="#platform-configurations-for-mochi"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Platform
    configurations for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <h2>

    <a id="user-content-using-spackyaml-files" class="anchor" href="#using-spackyaml-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2>

    <a id="user-content-contributing-to-this-repository" class="anchor" href="#contributing-to-this-repository"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing
    to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1641290694.0
mochi-hpc/mochi-bedrock:
  data_format: 2
  description: Mochi bootstrapping service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bedrock
  latest_release: v0.4.1
  readme: '<h1>

    <a id="user-content-bedrock" class="anchor" href="#bedrock" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bedrock</h1>

    <p>Bedrock is Mochi''s service bootstrapping mechanism.

    For documentations and tutorials, please see

    <a href="https://mochi.readthedocs.io/en/latest/bedrock.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640527359.0
mochi-hpc/mochi-mona:
  data_format: 2
  description: Mochi messaging over NA
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-mona
  latest_release: v0.1.1
  readme: '<h1>

    <a id="user-content-mona---messaging-over-na" class="anchor" href="#mona---messaging-over-na"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>MoNA
    - Messaging over NA</h1>

    <p>MoNA is a Mochi library combining the NA layer of Mercury with

    the Argobots threading library, in a way similar to how Margo

    combines Mercury with Argobots. It provides a low-level messaging

    interface and hides the NA progress loop into Argobots ULTs.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633974549.0
mpbelhorn/olcf-spack:
  data_format: 2
  description: Spack fork used on OLCF resources
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  full_name: mpbelhorn/olcf-spack
  latest_release: null
  readme: "<h1>\n<a id=\"user-content--spack\" class=\"anchor\" href=\"#-spack\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width:100%;\"></a> Spack</h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions?query=workflow%3A%22macOS+builds+nightly%22\"\
    ><img src=\"https://github.com/spack/spack/workflows/macOS%20builds%20nightly/badge.svg?branch=develop\"\
    \ alt=\"macOS Builds (nightly)\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://spack.readthedocs.io\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/4bbdc2b44561be6dfffe64e15730e1c5a2bed9c4efe6f9942638091a4ce3ede2/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width:100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2>\n<a id=\"user-content-documentation\"\
    \ class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p><a href=\"\
    https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <h2>\n<a id=\"user-content-tutorial\" class=\"anchor\" href=\"#tutorial\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tutorial</h2>\n\
    <p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<h2>\n<a id=\"user-content-community\" class=\"anchor\" href=\"\
    #community\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Community</h2>\n<p>Spack is an open source project.  Questions, discussion,\
    \ and\ncontributions are welcome. Contributions can be anything from new\npackages\
    \ to bugfixes, documentation, or even new core features.</p>\n<p>Resources:</p>\n\
    <ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<strong>Mailing\
    \ list</strong>: <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\"\
    >groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>: <a\
    \ href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<h2>\n<a id=\"user-content-contributing\"\
    \ class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Contributing\
    \ to Spack is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2>\n<a id=\"user-content-releases\" class=\"anchor\" href=\"#releases\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Releases</h2>\n\
    <p>For multi-user site deployments or other use cases that need very stable\n\
    software installations, we recommend using Spack's\n<a href=\"https://github.com/spack/spack/releases\"\
    >stable releases</a>.</p>\n<p>Each Spack release series also has a corresponding\
    \ branch, e.g.\n<code>releases/v0.14</code> has <code>0.14.x</code> versions of\
    \ Spack, and <code>releases/v0.13</code> has\n<code>0.13.x</code> versions. We\
    \ backport important bug fixes to these branches but\nwe do not advance the package\
    \ versions or make other changes that would\nchange the way Spack concretizes\
    \ dependencies within a release branch.\nSo, you can base your Spack deployment\
    \ on a release branch and <code>git pull</code>\nto get fixes, without the package\
    \ churn that comes with <code>develop</code>.</p>\n<p>The latest release is always\
    \ available with the <code>releases/latest</code> tag.</p>\n<p>See the <a href=\"\
    https://spack.readthedocs.io/en/latest/developer_guide.html#releases\" rel=\"\
    nofollow\">docs on releases</a>\nfor more details.</p>\n<h2>\n<a id=\"user-content-code-of-conduct\"\
    \ class=\"anchor\" href=\"#code-of-conduct\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Code of Conduct</h2>\n<p>Please\
    \ note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"><strong>Code of\
    \ Conduct</strong></a>. By participating in\nthe Spack community, you agree to\
    \ abide by its rules.</p>\n<h2>\n<a id=\"user-content-authors\" class=\"anchor\"\
    \ href=\"#authors\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Authors</h2>\n<p>Many thanks go to Spack's <a href=\"\
    https://github.com/spack/spack/graphs/contributors\">contributors</a>.</p>\n<p>Spack\
    \ was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\">tgamblin@llnl.gov</a>.</p>\n\
    <h3>\n<a id=\"user-content-citing-spack\" class=\"anchor\" href=\"#citing-spack\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing Spack</h3>\n<p>If you are referencing Spack in a publication,\
    \ please cite the following paper:</p>\n<ul>\n<li>Todd Gamblin, Matthew P. LeGendre,\
    \ Michael R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de Supinski, and\
    \ W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<h2>\n<a id=\"user-content-license\"\
    \ class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed\
    \ under the terms of both the MIT license and the\nApache License (Version 2.0).\
    \ Users may choose either license, at their\noption.</p>\n<p>All new contributions\
    \ must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"\
    https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n<a\
    \ href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1580743748.0
ndevelder/cmb:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: ndevelder/cmb
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1647450577.0
panosc-eu/spack-repo:
  data_format: 2
  description: EuXFEL Spack Package Repository
  filenames:
  - .docker/opt/spack/etc/spack/spack.yaml
  full_name: panosc-eu/spack-repo
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1648151763.0
pdidev/test_env:
  data_format: 2
  description: Testing environment for PDI
  filenames:
  - spack/2-spack/spack.yaml
  full_name: pdidev/test_env
  latest_release: null
  readme: '<h1>

    <a id="user-content-docker-images" class="anchor" href="#docker-images" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker images:</h1>

    <p>A set of related Docker images to build and test PDI.</p>

    <p>We provide images based on:</p>

    <ul>

    <li>Dask recipes,</li>

    <li>Binary packages.</li>

    </ul>

    <h2>

    <a id="user-content-dask-based-images" class="anchor" href="#dask-based-images"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dask-based
    images</h2>

    <p>These images are based on a minimal Ubuntu 18.08, with spack and all dependencies
    installed through

    spack.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/spack/${deps_version}/${compiler}/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>deps_version</code>:

    <ul>

    <li>

    <code>oldest</code>: dependencies use the oldest versions supported by PDI,</li>

    <li>

    <code>latest</code>: dependencies use the latest versions available in spack at
    the time of generation,</li>

    </ul>

    </li>

    <li>

    <code>compiler</code>:

    <ul>

    <li>

    <code>gcc</code>:   using GCC compiler,</li>

    <li>

    <code>clang</code>: using clang for C/C++ and gfortran for Fortran,</li>

    </ul>

    </li>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image.</li>

    </ul>

    </li>

    </ul>

    <h2>

    <a id="user-content-binary-package-based-images" class="anchor" href="#binary-package-based-images"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binary
    package based images</h2>

    <p>These images are based on Ubuntu 18.08, with all dependencies installed through
    packages.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/ubuntu/bionic/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>mpich</code>: using mpich implementation of MPI,</li>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image,</li>

    <li>

    <code>pdi</code>: PDI is included in the image.</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1641653805.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<h1>

    <a id="user-content-roibin-sz-experiments" class="anchor" href="#roibin-sz-experiments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ROIBIN-SZ
    Experiments</h1>

    <h2>

    <a id="user-content-system-information" class="anchor" href="#system-information"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>System
    Information</h2>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <h2>

    <a id="user-content-where-is-the-implementation-of-roibin-sz3" class="anchor"
    href="#where-is-the-implementation-of-roibin-sz3" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Where is the implementation of ROIBIN-SZ3?</h2>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <h2>

    <a id="user-content-getting-started" class="anchor" href="#getting-started" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <h3>

    <a id="user-content-obtaining-data" class="anchor" href="#obtaining-data" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining Data</h3>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <h3>

    <a id="user-content-quality-assessment" class="anchor" href="#quality-assessment"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quality
    Assessment</h3>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <h3>

    <a id="user-content-container-install-for-ease-of-setup" class="anchor" href="#container-install-for-ease-of-setup"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Container
    Install (for ease of setup)</h3>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <h4>

    <a id="user-content-singularity" class="anchor" href="#singularity" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h4>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <h4>

    <a id="user-content-docker" class="anchor" href="#docker" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h4>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <h3>

    <a id="user-content-building-the-container" class="anchor" href="#building-the-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <h3>

    <a id="user-content-manual-install-for-scale" class="anchor" href="#manual-install-for-scale"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    Install (for scale)</h3>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <h2>

    <a id="user-content-running-the-experiments" class="anchor" href="#running-the-experiments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Experiments</h2>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <h3>

    <a id="user-content-example-output" class="anchor" href="#example-output" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example Output</h3>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <h2>

    <a id="user-content-results-for-figures" class="anchor" href="#results-for-figures"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results
    for Figures</h2>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1648861627.0
salotz/raylib-scopes:
  data_format: 2
  description: Raylib wrapper for the Scopes language
  filenames:
  - spack.yaml
  full_name: salotz/raylib-scopes
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-scopes-raylib\" class=\"anchor\" href=\"#scopes-raylib\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>scopes-raylib</h1>\n<p>Bindings of <a href=\"https://github.com/raysan5/raylib\"\
    >Raylib</a> for the\n<a href=\"https://scopes.rocks\" rel=\"nofollow\">Scopes</a>\
    \ programming language.</p>\n<p>This is an incredibly thin wrapper as such and\
    \ you can basically use\nthe Raylib C-API with Scopes notation. Some of the naming\
    \ prefixes\nhave been scrubbed to make calling things less verbose.</p>\n<p>There\
    \ are a few macros added for \"begin-end\" type constructs that you\ncan see in\
    \ use in the examples, but you don't need to use them.</p>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The module\
    \ is under <code>src/raylib</code>. You can copy this subtree into your\nproject\
    \ and then add it to the <code>package.path</code> in your Scopes\n<code>_project.sc</code>\
    \ file.</p>\n<h3>\n<a id=\"user-content-with-spack\" class=\"anchor\" href=\"\
    #with-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>With Spack</h3>\n<p>This module is available as the\
    \ <code>scopes-raylib</code> package in the\n<a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> repository. This will pull in the necessary dependencies\nincluding\
    \ Scopes.</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spack install\
    \ scopes-raylib</pre></div>\n<p>See the <a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> documentation for more best practices of installing.</p>\n<h2>\n\
    <a id=\"user-content-development-environment\" class=\"anchor\" href=\"#development-environment\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development Environment</h2>\n<p>We use <a href=\"https://spack.io/\"\
    \ rel=\"nofollow\">Spack</a> to install dependencies. First install Spack.</p>\n\
    <p>Then you'll need our custom repo of build recipes:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  mkdir -p <span class=\"pl-s\"><span class=\"\
    pl-pds\">`</span>/.spack/repos</span>\n<span class=\"pl-s\">  git clone git@github.com:salotz/snailpacks.git\
    \ <span class=\"pl-pds\">`</span></span>/.spack/repos/snailpacks\n  spack repo\
    \ add <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  spack env create -d <span class=\"pl-c1\">.</span></pre></div>\n<p>Activate\
    \ the environment (i.e. set the environment variables\nappropriately) and install\
    \ the packages:</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spacktivate\
    \ <span class=\"pl-c1\">.</span>\n  spack install</pre></div>\n<p>To exit the\
    \ environment (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - raylib
  - scopes-lang
  updated_at: 1648089749.0
salotz/scopes-chipmunk2d:
  data_format: 2
  description: Scopes language wrapper of Chipmunk2D
  filenames:
  - spack.yaml
  full_name: salotz/scopes-chipmunk2d
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-scopes-chipmunk2d\" class=\"anchor\" href=\"\
    #scopes-chipmunk2d\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>scopes-chipmunk2d</h1>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The module\
    \ is under <code>src/chipmunk2d</code>. You can copy this subtree into your\n\
    project and then add it to the <code>package.path</code> in your Scopes\n<code>_project.sc</code>\
    \ file.</p>\n<h3>\n<a id=\"user-content-with-spack\" class=\"anchor\" href=\"\
    #with-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>With Spack</h3>\n<p>This module is available as the\
    \ <code>scopes-chipmunk2d</code> package in the\n<a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> repository. This will pull in the necessary dependencies\nincluding\
    \ Scopes.</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spack install\
    \ scopes-chipmunk2d</pre></div>\n<p>See the <a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> documentation for more best practices of installing.</p>\n<h2>\n\
    <a id=\"user-content-development-environment\" class=\"anchor\" href=\"#development-environment\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development Environment</h2>\n<p>We use <a href=\"https://spack.io/\"\
    \ rel=\"nofollow\">Spack</a> to install dependencies. First install Spack.</p>\n\
    <p>Then you'll need our custom repo of build recipes:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  mkdir -p <span class=\"pl-s\"><span class=\"\
    pl-pds\">`</span>/.spack/repos</span>\n<span class=\"pl-s\">  git clone git@github.com:salotz/snailpacks.git\
    \ <span class=\"pl-pds\">`</span></span>/.spack/repos/snailpacks\n  spack repo\
    \ add <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  spack env create -d <span class=\"pl-c1\">.</span></pre></div>\n<p>Activate\
    \ the environment (i.e. set the environment variables\nappropriately) and install\
    \ the packages:</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spacktivate\
    \ <span class=\"pl-c1\">.</span>\n  spack install</pre></div>\n<p>To exit the\
    \ environment (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - scopes-lang
  - chipmunk2d
  updated_at: 1648788744.0
salotz/scopes-lib_copier-template:
  data_format: 2
  description: Copier template for a Scopes library
  filenames:
  - template/spack.yaml
  full_name: salotz/scopes-lib_copier-template
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-project-template-for-a-scopes-lang-library\"\
    \ class=\"anchor\" href=\"#project-template-for-a-scopes-lang-library\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Project\
    \ Template for a Scopes Lang Library</h1>\n<p>This is a project template generator\
    \ and updater using the\n<a href=\"https://github.com/copier-org/copier/\">copier</a>\
    \ tool for creating libraries for the <a href=\"http://scopes.rocks\" rel=\"nofollow\"\
    >Scopes</a> programming language.</p>\n<p>Please install from the latest copier\
    \ for this to work, not the latest\nstable release. Currently I am using\n<a href=\"\
    https://github.com/pypa/pipx\">pipx</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pipx install git+https://github.com/copier-org/copier.git@e98314063246993532048ba2ecf80a049154d2f6</pre></div>\n\
    <h2>\n<a id=\"user-content-generating-a-project\" class=\"anchor\" href=\"#generating-a-project\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Generating a Project</h2>\n<p>Then you can generate your project:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>copier <span class=\"pl-s\"\
    ><span class=\"pl-pds\">'</span>gh:salotz/scopes-lib_copier-template<span class=\"\
    pl-pds\">'</span></span> ./</pre></div>\n<p>This should generate the following\
    \ (<code>repo_name = my-lib</code>):</p>\n<pre><code>my-lib\n\u251C\u2500\u2500\
    \ __env.sc\n\u251C\u2500\u2500 Makefile\n\u251C\u2500\u2500 README.md\n\u251C\u2500\
    \u2500 spack.yaml\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 my-lib\n   \
    \     \u251C\u2500\u2500 init.sc\n        \u2514\u2500\u2500 sanity.sc\n</code></pre>\n\
    <h2>\n<a id=\"user-content-development-environment\" class=\"anchor\" href=\"\
    #development-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Development Environment</h2>\n<p>Create a <a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> environment and install\n\
    dependencies</p>\n<pre><code>cd my-lib\nspack env create -d .\nspacktivate .\n\
    spack install\n</code></pre>\n<p>If you need more you can add them to <code>spack.yaml</code>.</p>\n\
    <p>Then you should be able to run the sanity check:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>scopes -e -m my-lib.sanity</pre></div>\n<p>Start\
    \ coding!</p>\n<h2>\n<a id=\"user-content-libraries-using-this-template\" class=\"\
    anchor\" href=\"#libraries-using-this-template\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Libraries Using this Template</h2>\n\
    <ul>\n<li><a href=\"https://github.com/salotz/raylib-scopes\">scopes-raylib</a></li>\n\
    <li><a href=\"https://github.com/salotz/scopes-chipmunk2d\">scopes-chipmunk2d</a></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - copier-template
  - scopes-lang
  updated_at: 1648781021.0
scs-lab/ChronoLog:
  data_format: 2
  description: 'ChronoLog: A High-Performance Storage Infrastructure for Activity
    and Log Workloads'
  filenames:
  - CI/enviroment/spack.yaml
  full_name: scs-lab/ChronoLog
  latest_release: null
  readme: '<h1>

    <a id="user-content-chronolog" class="anchor" href="#chronolog" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ChronoLog</h1>

    <p>ChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads
    (NSF CSSI 2104013)</p>

    <h2>

    <a id="user-content-chronolog-project-synopsis" class="anchor" href="#chronolog-project-synopsis"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ChronoLog
    Project Synopsis</h2>

    <p>This project will design and implement ChronoLog, a distributed and tiered
    shared log storage ecosystem. ChronoLog uses physical time to distribute log entries
    while providing total log ordering. It also utilizes multiple storage tiers to
    elastically scale the log capacity (i.e., auto-tiering). ChronoLog will serve
    as a foundation for developing scalable new plugins, including a SQL-like query
    engine for log data, a streaming processor leveraging the time-based data distribution,
    a log-based key-value store, and a log-based TensorFlow module.</p>

    <h2>

    <a id="user-content-workloads-and-applications" class="anchor" href="#workloads-and-applications"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Workloads
    and Applications</h2>

    <p>Modern applications spanning from Edge to High Performance Computing (HPC)
    systems, produce and process log data and create a plethora of workload characteristics
    that rely on a common storage model: <strong>the distributed shared log</strong>.</p>

    <p><a href="/doc/images/log_centric_paradigm.svg" target="_blank" rel="noopener
    noreferrer"><img src="/doc/images/log_centric_paradigm.svg" alt="Log centric paradigm"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-features" class="anchor" href="#features" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Features</h2>

    <p><a href="/doc/images/feature-matrix.png" target="_blank" rel="noopener noreferrer"><img
    src="/doc/images/feature-matrix.png" alt="Feature matrix" style="max-width:100%;"></a></p>

    <hr>

    <h1>

    <a id="user-content-coming-soon-" class="anchor" href="#coming-soon-" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Coming soon ...</h1>

    <p>For more details about the ChronoLog project, please visit our website <a href="http://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html"
    rel="nofollow">http://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1646325735.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - OLCF/crusher/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configs" class="anchor" href="#spack-configs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 40
  subscribers_count: 22
  topics: []
  updated_at: 1651600520.0
srini009/serviz-installation-instructions:
  data_format: 2
  description: Repository containing the installation instructions and customization
    scripts
  filenames:
  - spack_environment_recipe/spack.yaml
  full_name: srini009/serviz-installation-instructions
  latest_release: null
  readme: '<p>Repository containing the installation instructions and customization
    scripts for SC 2022 paper427: "SERVIZ: A Shared In Situ Visualization Service"</p>

    <h2>

    <a id="user-content-note-it-is-important-to-follow-these-steps-in-the-exact-order-specified-to-correctly-set-up-the-software-components-for-reproducibility"
    class="anchor" href="#note-it-is-important-to-follow-these-steps-in-the-exact-order-specified-to-correctly-set-up-the-software-components-for-reproducibility"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Note:
    It is important to follow these steps in the exact order specified to correctly
    set up the software components for reproducibility.</h2>

    <h2>

    <a id="user-content-note-the-instructions-here-assume-that-you-are-logged-in-to-the-theta-cluster-at-alcf"
    class="anchor" href="#note-the-instructions-here-assume-that-you-are-logged-in-to-the-theta-cluster-at-alcf"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Note:
    The instructions here assume that you are logged in to the Theta cluster at ALCF</h2>

    <h2>

    <a id="user-content-note-it-is-assumed-that-the-directory-structure-looks-like-the-following"
    class="anchor" href="#note-it-is-assumed-that-the-directory-structure-looks-like-the-following"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Note:
    It is assumed that the directory structure looks like the following:</h2>

    <ul>

    <li>$HOME/serviz-installation-instructions/</li>

    <li>$HOME/amr-wind/</li>

    <li>$HOME/serviz/</li>

    <li>$HOME/amr-wind-experiments/</li>

    <li>$HOME/mochi-spack-packages/</li>

    </ul>

    <h3>

    <a id="user-content-step-1-installation-of-radical-pilot-components" class="anchor"
    href="#step-1-installation-of-radical-pilot-components" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Step 1: Installation
    of radical-pilot components:</h3>

    <p>First, go over the installation instructions: <a href="https://radicalpilot.readthedocs.io/en/stable/installation.html"
    rel="nofollow">https://radicalpilot.readthedocs.io/en/stable/installation.html</a>.
    The following instructions assume that you have already installed and have a working
    MongoDB installation, Python, Conda,

    and other requirements for radical-pilot setup and working. The instructions that
    follow are only for customizing radical-pilot for SERVIZ.</p>

    <ol>

    <li>Install radical-saga@1.12.0 using the command: <code>pip install radical.saga==1.12.0</code>

    </li>

    <li>Install radical-utils@1.12.0 using the command: <code>pip install radical.utils==1.12.0</code>

    </li>

    <li>The third component, radical-pilot would require a custom installation. For
    this:

    <ul>

    <li>First download the radical.pilot github repo locally using git: <code>git
    clone https://github.com/radical-cybertools/radical.pilot.git@v1.12.0</code>

    </li>

    <li>Run: <code>cd radical-pilot &amp;&amp; cp ../serviz-installation-instructions/radical-pilot-customization/aprun.py
    ./src/radical/pilot/agent/launch_method/aprun.py</code>

    </li>

    <li>Run: <code>vi ./src/radical/pilot/agent/launch_method/aprun.py</code>, and
    look for the line that says "REPLACEME". You would need to create a protection
    domain on Theta and use that protection domain name here.</li>

    <li>Assuming you are still in $HOME/radical-pilot, run: <code>pip install .</code>

    </li>

    <li>That should install the "modified" radical-pilot stack. Check that the entire
    radical-stack has installed correctly at version 1.12.0 by running <code>radical-stack</code>

    </li>

    <li>Copy the Theta resource JSON config: <code>cp ../serviz-installation-instructions/radical-pilot-customization/resource_anl.json
    ~/.radical/pilot/configs/resource_anl.json</code>. This would override the default
    JSON configuration file to tell radical-pilot to only use 60 out of the total
    64 cores on each Theta KNL node.</li>

    <li>At this point, run a small test program to ensure that you are able to use
    radical-pilot along with the MongoDB installation to submit and run a batch job
    ensemble on Theta.</li>

    </ul>

    </li>

    </ol>

    <h3>

    <a id="user-content-step-2-installation-of-custom-spack-and-mochi-spack-packages"
    class="anchor" href="#step-2-installation-of-custom-spack-and-mochi-spack-packages"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    2: Installation of custom spack and mochi-spack-packages:</h3>

    <ol>

    <li>Download and install spack: <a href="https://spack.io/" rel="nofollow">https://spack.io/</a>

    </li>

    <li>Assuming that spack is download at $HOME/spack, <code>cd $HOME/spack</code>.</li>

    <li>What we need to do next is to customize some spack built-in packages. The
    recipe for the spack built-in packages are found in <code>$HOME/spack/var/spack/repos/builtin/packages/*</code>

    </li>

    <li>For each of the three packages (ascent, conduit, and vtk-h) in <code>../serviz-installation-instructions/spack_builtin_repo_customization/</code>,
    copy-paste the <code>package.py</code> inside each of them to the corresponding
    spack built-in package directories in <code>$HOME/spack/var/spack/repos/builtin/packages/*</code>

    </li>

    <li>Add the custom mochi-spack-packages repo: <code>cd ../mochi-spack-packages
    &amp;&amp; git checkout experimental &amp;&amp; spack repo add .</code>

    </li>

    <li>Note that the <code>experimental</code> branch for this repo needs to be used.
    Verify that the spack repo got added successfully by running: <code>spack info
    mochi-symbiomon</code>. If you see some valid output, you are good to go!</li>

    </ol>

    <h3>

    <a id="user-content-step-3-installation-of-serviz-microservice-and-its-dependencies"
    class="anchor" href="#step-3-installation-of-serviz-microservice-and-its-dependencies"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    3: Installation of SERVIZ microservice and its dependencies:</h3>

    <h4>

    <a id="user-content-note-at-this-point-make-sure-your-environment-has-the-right-compilers-gcc930-conda-programming-environments-and-spack-environments-correctly-loaded-to-look-at-a-reference-file-see-homeserviz-installation-instructionsspack_environment_recipetheta_sourcemesh"
    class="anchor" href="#note-at-this-point-make-sure-your-environment-has-the-right-compilers-gcc930-conda-programming-environments-and-spack-environments-correctly-loaded-to-look-at-a-reference-file-see-homeserviz-installation-instructionsspack_environment_recipetheta_sourcemesh"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Note:
    At this point, make sure your environment has the right compilers (gcc@9.3.0),
    Conda programming environments, and spack environments correctly loaded. To look
    at a reference file, see <code>$HOME/serviz-installation-instructions/spack_environment_recipe/theta_sourceme.sh</code>

    </h4>

    <ol>

    <li>Go to the SERVIZ github directory: <code>cd ../serviz</code>

    </li>

    <li>Create a spack environment using the already-provided spack.yaml file: <code>spack
    env create serviz spack.yaml</code>

    </li>

    <li>Install the environment using: ```spack install``</li>

    <li>Install the SERVIZ microservice using: ``mkdir build &amp;&amp; cd build &amp;&amp;
    cmake .. -DENABLE_TESTS=OFF -DENABLE_EXAMPLES=ON -DENABLE_BEDROCK=OFF```</li>

    <li>Login to the cmake shell: <code>cd build &amp;&amp; ccmake .</code>

    </li>

    <li>We would need to add the spack-installed <code>include</code> and <code>library</code>
    directories to <code>CMAKE_CXX_FLAGS</code>, <code>CMAKE_C_FLAGS</code>, <code>CMAKE_EXE_LINKER_FLAGS</code>,
    and <code>CMAKE_SHARED_LINKER_FLAGS</code> respectively. To see an example of
    what content to add, look inside <code>$HOME/serviz-installation-instructions/spack_environment_recipe/theta.cmake_options</code>

    </li>

    <li>Once this is done, run: <code>make -j20 &amp;&amp; make install</code>.</li>

    </ol>

    <h3>

    <a id="user-content-step-4-installation-of-custom-amr-wind" class="anchor" href="#step-4-installation-of-custom-amr-wind"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    4: Installation of custom AMR-WIND:</h3>

    <ol>

    <li><code>mkdir -p $HOME/AMR_WIND_INSTALL</code></li>

    <li><code>cd $HOME/amr-wind</code></li>

    <li><code>mkdir build &amp;&amp; cd build</code></li>

    <li><code>cmake -DAMR_WIND_ENABLE_TESTS:BOOL=ON -DAMR_WIND_ENABLE_ASCENT:BOOL=ON
    -DAscent_DIR:PATH="/spack/path/to/ascent/install/lib/cmake/ascent"" -DConduit_DIR:PATH="/spack/path/to/conduit/install"
    -DAMR_WIND_ENABLE_MPI:BOOL=ON ..</code></li>

    <li><code>make -j20 &amp;&amp; make install</code></li>

    </ol>

    <h3>

    <a id="user-content-step-5-run-amr-wind-experiments-using-serviz-and-radical-pilot"
    class="anchor" href="#step-5-run-amr-wind-experiments-using-serviz-and-radical-pilot"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    5: Run AMR-WIND experiments using SERVIZ and RADICAL-PILOT</h3>

    <ol>

    <li>At this point you should have all the software components successfully installed
    and ready to run.</li>

    <li>Go to the amr-wind-experiments repo: <code>cd $HOME/amr-wind-experiments/</code>
    and start running the experiments by making adjustments to the  Python run scripts
    as necessary. These scripts are numbered based on the configurations that they
    represent.</li>

    </ol>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649904535.0
srini009/soma:
  data_format: 2
  description: 'SPINCER: A Shared Performance Analysis and Monitoring Microservice'
  filenames:
  - spack.yaml
  full_name: srini009/soma
  latest_release: null
  readme: '<h1>

    <a id="user-content-soma-a-service-based-observability-monitoring-and-analytics-framework-for-hpc"
    class="anchor" href="#soma-a-service-based-observability-monitoring-and-analytics-framework-for-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SOMA:
    A Service-based Observability, Monitoring, and Analytics Framework for HPC</h1>

    <p>This is an experimental repo containing a performance monitoring and analysis
    microservice

    for the TAU performance system. SOMA is designed using the Mochi software stack.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649960405.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/intelmpi/bpmf-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-mpi_isend/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-gpi/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-mpi_isend/spack.yaml
  - var/spack/environments/karolina/bpmf-gpi/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1635166163.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - spack-environments/cosma8/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-excalibur-tests\" class=\"anchor\" href=\"#excalibur-tests\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks and regression tests\
    \ for the ExCALIBUR project.</p>\n<p>These benchmarks are based on a similar project\
    \ by\n<a href=\"https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2>\n\
    <a id=\"user-content-requirements\" class=\"anchor\" href=\"#requirements\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h2>\n\
    <h3>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><em><strong>Note</strong>: in some HPC facilities there may be already a central\
    \ Spack\ninstallation available.  In principle you should be able to use that\
    \ one (you\nonly need to set the <code>SPACK_ROOT</code> environment variable),\
    \ but you may need an\nup-to-date version of Spack in order to install some packages.\
    \  Instructions\nbelow show you how to install Spack locally.</em></p>\n<p><a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager specifically\
    \ designed for HPC\nfacilities.  Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall the latest version of\
    \ Spack.</p>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable.  This\
    \ can be achieved for instance by running\nthe commands to get shell support described\
    \ in Spack documentation, which you\ncan also add to your shell init script to\
    \ do it automatically in every session.\nFor example, if you use a shell of the\
    \ family bash/zsh/sh you can add to your\ninit script:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR project.  If you want to\
    \ use a different Spack environment, set the\nenvironment variable <code>EXCALIBUR_SPACK_ENV</code>\
    \ to the path of the directory where\nthe environment is.  If this is not set,\
    \ ReFrame will try to use the environment\nfor the current system, if known, otherwise\
    \ it will automatically create a very\nbasic environment.</p>\n<h3>\n<a id=\"\
    user-content-reframe\" class=\"anchor\" href=\"#reframe\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ReFrame</h3>\n\
    <p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\" rel=\"nofollow\"\
    >ReFrame</a> is a high-level\nframework for writing regression tests for HPC systems.\
    \  For our tests we\nrequire ReFrame 3.8.0.  Follow the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall this package.  Note\
    \ that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a\
    \ specific module to have this version of Python available.</p>\n<p>We provide\
    \ a ReFrame configuration file with the settings of some systems that\nare part\
    \ of the ExCALIBUR project.  You can point ReFrame to this file by\nsetting the\n\
    <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILE</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILE=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${PWD}</span>/reframe_config.py<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>If you want to use a different ReFrame configuration file, for example because\n\
    you use a different system, you can set this environment variable to the path\
    \ of\nthat file.</p>\n<p><strong>Note</strong>: in order to use the Spack build\
    \ system in ReFrame, the <code>spack</code>\nexecutable must be in the <code>PATH</code>,\
    \ also on the computing nodes of a cluster, if\nyou want to run your benchmarks\
    \ on them.  Note that by default ReFrame uses</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a>, which would not load\nthe user's init script.  If you have added\
    \ Spack to your <code>PATH</code> within your init\nscript, you may want to set\
    \ the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ in order to make ReFrame use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash\
    \ -l</span></pre></div>\n<p>as shebang line, instead.</p>\n<h3>\n<a id=\"user-content-extra-python-modules\"\
    \ class=\"anchor\" href=\"#extra-python-modules\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Extra Python modules</h3>\n<p>The\
    \ benchmarks in this suite will additionally need the following Python modules:</p>\n\
    <ul>\n<li><a href=\"https://matplotlib.org/\" rel=\"nofollow\"><code>matplotlib</code></a></li>\n\
    <li><a href=\"https://pandas.pydata.org/\" rel=\"nofollow\"><code>pandas</code></a></li>\n\
    </ul>\n<p>Check the recommended way to install Python modules in your system,\
    \ it may be\nfor example by using <code>pip</code>, or creating environments with\
    \ <code>pyenv</code> or\nConda/Anaconda. For example, see <a href=\"https://docs.hpc.cam.ac.uk/hpc/software-tools/python.html\"\
    \ rel=\"nofollow\">the guide for CSD3</a>.</p>\n<h2>\n<a id=\"user-content-usage\"\
    \ class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<p>Once you have set up\
    \ Spack and ReFrame, you can execute a benchmark with</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/BENCH_NAME -r --performance-report</pre></div>\n\
    <p>where <code>apps/BENCH_NAME</code> is the directory where the benchmark is.\
    \  The command\nabove supposes you have the program <code>reframe</code> in your\
    \ PATH, if it is not the\ncase you can also call <code>reframe</code> with its\
    \ relative or absolute path.  For\nexample, to run the Sombrero benchmark in the\
    \ <code>apps/sombrero</code> directory you can\nuse</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/sombrero -r --performance-report</pre></div>\n\
    <p>For benchmark using the Spack build system, the tests define a default Spack\
    \ specification\nto be installed in the environment, but users can change it when\
    \ invoking ReFrame on the\ncommand line with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c apps/sombrero -r --performance-report -S\
    \ spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3>\n<a id=\"user-content-selecting-system-and-queue-access-options\"\
    \ class=\"anchor\" href=\"#selecting-system-and-queue-access-options\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  You can always use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3>\n<a id=\"user-content-unsupported-systems\"\
    \ class=\"anchor\" href=\"#unsupported-systems\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Unsupported systems</h3>\n<p>The\
    \ configuration provided in <a href=\"./reframe_config.py\"><code>reframe_config.py</code></a>\
    \ lets you run the\nbenchmarks on systems for which the configuration has been\
    \ already contributed.  However you\ncan still use this framework on any system\
    \ by choosing the \"generic\" system with <code>--system generic</code>, or using\
    \ your own ReFrame configuration.  Note, however, that if you use the\n\"generic\"\
    \ system, ReFrame will not know anything about the queue manager of your system,\
    \ if\nany, or the MPI launcher.  For the benchmarks using the Spack build system,\
    \ if you choose\nthe \"generic\" system, a new empty Spack environment will be\
    \ automatically created in\n<code>spack-environments/generic</code>.  In any case,\
    \ you can always make the benchmarks use a\ndifferent Spack environment by setting\
    \ the environment variable <code>EXCALIBUR_SPACK_ENV</code>\ndescribed above.</p>\n\
    <h2>\n<a id=\"user-content-contributing-new-systems-or-benchmarks\" class=\"anchor\"\
    \ href=\"#contributing-new-systems-or-benchmarks\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\n\
    <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1638371749.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-374/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: 0.8.0
  stargazers_count: 10
  subscribers_count: 5
  topics:
  - jupyter
  - jupyter-notebooks
  - jupyter-kernels
  - ipython
  - ipywidgets
  - ipython-widget
  - spack
  - pipenv
  - dvc
  - data-science
  - pandas
  updated_at: 1641756482.0
wangzhezhe/Gorilla:
  data_format: 2
  description: The Gorilla framework which provides distributed in-memory data management
    service
  filenames:
  - spack_cpu.yaml
  - spack.yaml
  full_name: wangzhezhe/Gorilla
  latest_release: null
  readme: "<h2>\n<a id=\"user-content-motivation\" class=\"anchor\" href=\"#motivation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Motivation</h2>\n<p>Gorilla framework is a in-memory data management\
    \ servie. The name of the framework comes from the brand \"gorilla glue\", since\
    \ we are basically gluing different components together. It mainly supoorts follwing\
    \ capabilities:</p>\n<p>(1) suppot M:N data put/get for data based on grid mesh.</p>\n\
    <p>(2)User can use customized trigger to express the logic flow of the task executions.\
    \ The implementation of in-memory data storage service layer is inspired by the\
    \ <a href=\"https://github.com/philip-davis/dataspaces\">DataSpaces</a> and the\
    \ <a href=\"https://github.com/ornladios/ADIOS2\">ADIOS</a> projects. [adios test\
    \ case is deprecated]</p>\n<p>(3)There is specific event queue binded with the\
    \ trigger to support the data-driven task executions, the properties of the data\
    \ can be captured and client can acquire the metadata of the raw data by poll\
    \ events. The idea of data driven approach mainly comes from the <a href=\"https://www.osti.gov/biblio/1493245\"\
    \ rel=\"nofollow\">OSTI technical report</a>.</p>\n<p><strong>More key design\
    \ strategies can be found at the designDoc/scratch.md</strong></p>\n<h2>\n<a id=\"\
    user-content-compiling-and-running-the-server\" class=\"anchor\" href=\"#compiling-and-running-the-server\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Compiling and running the server</h2>\n<p>this is an eample to compile\
    \ the gorilla server on cori cluster</p>\n<pre><code>source ~/.gorilla\ncmake\
    \ ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=~/cworkspace/src/VTK/build/\
    \ -DUSE_GNI=ON\n</code></pre>\n<p>If the paraveiw is used for particular test</p>\n\
    <pre><code>old one\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc\
    \ -DVTK_DIR=$SCRATCH/build_paraview_matthieu_release/ -DUSE_GNI=ON -DParaView_DIR=$SCRATCH/build_paraview_matthieu/\
    \ -DBUILD_SHARED_LIBS=ON -DAMReX_DIR=/global/cscratch1/sd/zw241/build_amrex/install/lib/cmake/AMReX\n\
    </code></pre>\n<pre><code>new one (the cray based MPI can be detected and used\
    \ in this case when we use the cc and CC)\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC\
    \ -DCMAKE_C_COMPILER=cc -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0\
    \ -DUSE_GNI=ON\n</code></pre>\n<p>this is the content of the <code>~/.gorilla_cpu</code>\
    \ file on cori cluster:</p>\n<pre><code>#!/bin/bash\n\nsource ~/.color\nmodule\
    \ load cmake/3.18.2\nmodule load spack\n#spack load cmake@3.18.2%gcc@8.2.0\n\n\
    module swap PrgEnv-intel PrgEnv-gnu\n# ssg works well for gcc 9.3.0\nmodule swap\
    \ gcc/8.3.0 gcc/9.3.0\n\nspack load -r mochi-thallium%gcc@9.3.0\n#spack load mochi-cfg\n\
    spack load -r mochi-abt-io%gcc@9.3.0\n\nexport CRAYPE_LINK_TYPE=dynamic\n# we\
    \ do not use GPU and vtkm for this version\ncd $SCRATCH/build_Gorilla_cpu\n\n\n\
    export MPICH_GNI_NDREG_ENTRIES=1024 \n# get more mercury info\nexport HG_NA_LOG_LEVEL=debug\n\
    \n# avoid argobot thred pool issue, and set this to 2M\n# this may helps avoid\
    \ segfault when we use the processing and IO in large amount\n# export ABT_THREAD_STACKSIZE=2097152\n\
    # to make sure ther eis enough stack and not oom\nexport ABT_THREAD_STACKSIZE=1048576\n\
    </code></pre>\n<p>refer to the ./scripts dir to check exmaples of running multiple\
    \ servers. The configuration of the server contains item such as protocol used\
    \ by communication layer, the log level, the global domain and if the trigger\
    \ is started and so on. The example of the configuration is in ./server/settings.json</p>\n\
    <h3>\n<a id=\"user-content-build-on-gpu-nodes\" class=\"anchor\" href=\"#build-on-gpu-nodes\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>build on gpu nodes</h3>\n<p>this is the content of the <code>~/.gorilla_gpu</code>\
    \ file on cori cluster:</p>\n<pre><code>#!/bin/bash\nsource ~/.color\n\nsource\
    \ ~/cworkspace/src/spack/share/spack/setup-env.sh\nmodule swap PrgEnv-intel PrgEnv-gnu\n\
    module swap gcc/8.3.0 gcc/9.3.0\n# cuda can not use this cray-mpich\nmodule unload\
    \ cray-mpich/7.7.10\nmodule load cgpu cuda openmpi\nmodule load cmake/3.20.5\n\
    \n# jump to the gpu node\nsalloc -C gpu -t 60 -c 8 -G 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\
    \n# for thallium\nspack load -r mochi-thallium%gcc@9.3.0\nspack load -r mochi-abt-io%gcc@9.3.0\n\
    \nexport CRAYPE_LINK_TYPE=dynamic\n</code></pre>\n<p>build</p>\n<p>(associated\
    \ vtkm accelarator should be enabled when building vtk in this case)\n(we do not\
    \ need extra vtkm build when there is vtk integration?)\n(we use vtkm associated\
    \ with vtk)</p>\n<pre><code>cmake ~/cworkspace/src/Gorilla/ -DCMAKE_CUDA_COMPILER=nvcc\
    \ -DCMAKE_CXX_COMPILER=g++ -DCMAKE_C_COMPILER=gcc -DVTKm_DIR=/global/cscratch1/sd/zw241/build_vtkm/lib/cmake/vtkm-1.6\
    \ -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0 -DUSE_GNI=ON\
    \ -DUSE_GPU=ON -DBUILD_SHARED_LIBS=ON -DVTKm_ENABLE_CUDA=ON -DVTKm_CUDA_Architecture=volta\n\
    </code></pre>\n<p>example to run the test</p>\n<pre><code>srun -C gpu -n 1 --gpus-per-task=1\
    \  nvprof ./test/test_insitu_ana\n</code></pre>\n<h3>\n<a id=\"user-content-using-the-spack-env\"\
    \ class=\"anchor\" href=\"#using-the-spack-env\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using the spack env</h3>\n<p>if\
    \ we use the spack env, it means that we do not set the public packages.yaml file.\
    \ We also need to set the customized spack env for the Gorilla repo.</p>\n<p>set\
    \ up env (we use the spack installed by the colza-experiments)</p>\n<pre><code>source\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nspack\
    \ env create gorilla ~/cworkspace/src/Gorilla/spack.yaml\nspack repo add --scope\
    \ env:gorilla /global/cscratch1/sd/zw241/colza-experiments/cori/vtk/sw/mochi-spack-packages/\n\
    spack env update gorilla \nspack install -y\n</code></pre>\n<p>if the spack env\
    \ is installed successfully</p>\n<pre><code>#!/bin/bash\nsource ~/.color\n\nsource\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nmodule\
    \ swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\n# cuda can not\
    \ use this cray-mpich\nmodule unload cray-mpich/7.7.10\nmodule load cgpu cuda\
    \ openmpi\nmodule load cmake/3.20.5\n\n# activate env for the thallium\nspack\
    \ env activate gorilla\n\n# jump to the gpu node\nsalloc -C gpu -t 60 -c 8 -G\
    \ 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\nexport CRAYPE_LINK_TYPE=dynamic\n\
    </code></pre>\n<h3>\n<a id=\"user-content-run\" class=\"anchor\" href=\"#run\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>run</h3>\n<p>exmaple on cori</p>\n<pre><code>srun -C haswell -n 8\
    \ ./unimos_server ~/cworkspace/src/Gorilla/server/settings_gni.json\n</code></pre>\n\
    <p>remember to set the env if MPICH is used</p>\n<pre><code>MPICH_GNI_NDREG_ENTRIES=1024\n\
    </code></pre>\n<p>simple example to put the data</p>\n<pre><code>srun -C haswell\
    \ -n 16 ./example/gray-scott-stg ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ gni\n</code></pre>\n<p>simple example to get the data for further processing</p>\n\
    <pre><code>srun -n 4 ./example/isosurface ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ 10 0.5 gni\n</code></pre>\n<h3>\n<a id=\"user-content-version-info\" class=\"\
    anchor\" href=\"#version-info\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Version info</h3>\n<p>v0.1</p>\n<p>M:N\
    \ put get for Cartesian grid</p>\n<p>memory and file backend\n(file backend will\
    \ be used when there is not enough mem space)</p>\n<p>in-memory data trigger (experimental)</p>\n\
    <h3>\n<a id=\"user-content-related-issue\" class=\"anchor\" href=\"#related-issue\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>related issue</h3>\n<pre><code>/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so:\
    \ undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023'\n</code></pre>\n\
    <p>try this:</p>\n<p>SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")</p>\n\
    <p>refer to</p>\n<p><a href=\"https://github.com/halide/Halide/issues/1112\">https://github.com/halide/Halide/issues/1112</a></p>\n\
    <p>make -j may hide some potential cmake mistakes, try to use make if there is\
    \ specific link issue</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1641259621.0
wr-hamburg/eurosys2022-cheops-compression:
  data_format: 2
  description: Data-Aware Compression for HPC using Machine Learning
  filenames:
  - library/spack.yaml
  full_name: wr-hamburg/eurosys2022-cheops-compression
  latest_release: null
  readme: '<h1>

    <a id="user-content-readme" class="anchor" href="#readme" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Readme</h1>

    <h2>

    <a id="user-content-library-for-tracing-and-inferencing-library" class="anchor"
    href="#library-for-tracing-and-inferencing-library" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Library for tracing and inferencing (/library)</h2>

    <h3>

    <a id="user-content-dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

    <p><code>spack env activate .</code></p>

    <p><code>spack install</code></p>

    <h3>

    <a id="user-content-build" class="anchor" href="#build" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p><code>meson bld &amp;&amp; ninja -C bld</code></p>

    <h3>

    <a id="user-content-configuration" class="anchor" href="#configuration" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Configuration</h3>

    <table>

    <thead>

    <tr>

    <th>Option</th>

    <th>Description</th>

    <th align="center">Mode</th>

    <th align="center">Inferencing mode</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td></td>

    <td></td>

    <td align="center">Sampling</td>

    <td align="center">Inferencing</td>

    </tr>

    <tr>

    <td>-m, --min-size=9</td>

    <td>Min size of chunks to analyze in bytes</td>

    <td align="center">X</td>

    <td align="center">X</td>

    </tr>

    <tr>

    <td>-r, --repeat=3</td>

    <td>Number of times to repeat measurements</td>

    <td align="center">X</td>

    <td align="center"></td>

    </tr>

    <tr>

    <td>-p, --meta-path=/tmp/meta.h5</td>

    <td>Path for metadata storage</td>

    <td align="center">X</td>

    <td align="center">X</td>

    </tr>

    <tr>

    <td>-t, --tracing</td>

    <td>Activates tracing of MPI-Calls</td>

    <td align="center">X</td>

    <td align="center"></td>

    </tr>

    <tr>

    <td>-s, --store-chunks</td>

    <td>Activates chunk storage</td>

    <td align="center">X</td>

    <td align="center"></td>

    </tr>

    <tr>

    <td>-c, --chunk-path=/tmp/chunks/</td>

    <td>Storage path of chunks for later analysis</td>

    <td align="center">X</td>

    <td align="center"></td>

    </tr>

    <tr>

    <td>-e, --test-compression</td>

    <td>Activates compression tests according to metrics</td>

    <td align="center">X</td>

    <td align="center"></td>

    </tr>

    <tr>

    <td>-x, --model-path</td>

    <td>Path to exported ONNX model</td>

    <td align="center"></td>

    <td align="center">X</td>

    </tr>

    <tr>

    <td>-o, --settings-path</td>

    <td>Path to exported ONNX settings</td>

    <td align="center"></td>

    <td align="center">X</td>

    </tr>

    <tr>

    <td>-i, --inferencing</td>

    <td>Run inferencing</td>

    <td align="center"></td>

    <td align="center">X</td>

    </tr>

    <tr>

    <td>-d, --decompression</td>

    <td>Measure decompression</td>

    <td align="center">X</td>

    <td align="center"></td>

    </tr>

    </tbody>

    </table>

    <h3>

    <a id="user-content-usage-example" class="anchor" href="#usage-example" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage example</h3>

    <p><code>export IOA_OPTIONS="--repeat=3 --tracing --decompression --test-compression
    --meta-path=meta.h5 --chunk-path=chunks/</code>

    <code>G_MESSAGES_DEBUG=all LD_PRELOAD=bld/libmpi-preload.so mpiexec -np 2 application</code></p>

    <h3>

    <a id="user-content-usage-inferencing" class="anchor" href="#usage-inferencing"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage
    inferencing</h3>

    <p>Specify model and model settings files used in training step</p>

    <p><code>export IOA_OPTIONS="--min-size=9 --meta-path=evaluation.h5 --inferencing
    --model-path=compression-CR.onnx --settings-path=compression-CR-settings.txt</code></p>

    <h1>

    <a id="user-content-training-and-evaluation-compressionml-pytorch" class="anchor"
    href="#training-and-evaluation-compressionml-pytorch" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Training and evaluation
    (/CompressionML-PyTorch)</h1>

    <h2>

    <a id="user-content-dependencies-1" class="anchor" href="#dependencies-1" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <ul>

    <li>Uses <a href="https://python-poetry.org/docs/basic-usage/" rel="nofollow">Poetry</a>
    for dependency management</li>

    </ul>

    <p><code>poetry shell &amp;&amp; poetry install</code></p>

    <h2>

    <a id="user-content-usage" class="anchor" href="#usage" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h2>

    <p>Allows for hyperparameter tuning, as well as final model creation with the
    discovered parameters.</p>

    <h3>

    <a id="user-content-tuningpy" class="anchor" href="#tuningpy" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><code>tuning.py</code>

    </h3>

    <ul>

    <li>Specify meta.h5 and metric within file</li>

    <li>Run file and discover parameters, e.g by using <a href="https://www.tensorflow.org/tensorboard"
    rel="nofollow">Tensorboard</a>

    </li>

    </ul>

    <h3>

    <a id="user-content-trainingipynb" class="anchor" href="#trainingipynb" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><code>training.ipynb</code>

    </h3>

    <ul>

    <li>Use discovered parameters from previous step and train final model</li>

    </ul>

    <h2>

    <a id="user-content-evaluate" class="anchor" href="#evaluate" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Evaluate</h2>

    <h3>

    <a id="user-content-confusionipynb" class="anchor" href="#confusionipynb" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><code>confusion.ipynb</code>

    </h3>

    <ul>

    <li>Set meta path to <em>evaluation.h5</em> output path specified in <code>IOA_OPTIONS</code>
    when inferencing</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649004657.0
