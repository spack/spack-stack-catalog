AMReX-Codes/pyamrex:
  data_format: 2
  description: '[Experimental] AMReX Python Bindings'
  filenames:
  - spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: null
  readme: '<h1><a id="user-content-pyamrex" class="anchor" aria-hidden="true" href="#pyamrex"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>pyAMReX</h1>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width: 100%;"></a> <a target="_blank" rel="noopener noreferrer nofollow"
    href="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"><img
    src="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"
    alt="Python3 API: Pre-Alpha" title="Status: Pre-Alpha" data-canonical-src="https://img.shields.io/badge/phase-pre--alpha-yellowgreen"
    style="max-width: 100%;"></a>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License AMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a><br>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    alt="linux" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    alt="macos" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    alt="windows" style="max-width: 100%;"></a></p>

    <p>pyAMReX is part of AMReX.</p>

    <p>Due to its <strong>highly experimental</strong> nature, we develop it currently
    in a separate respository.</p>

    <p>We will add further information here once first development versions are ready
    for testing.</p>

    <h2><a id="user-content-users" class="anchor" aria-hidden="true" href="#users"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Users</h2>

    <p><em>to do</em></p>

    <ul>

    <li>pip/pypa</li>

    <li>conda-forge</li>

    <li>spack</li>

    <li>brew</li>

    <li>...</li>

    </ul>

    <h3><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h3>

    <p><em>to do</em></p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <h2><a id="user-content-developers" class="anchor" aria-hidden="true" href="#developers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Developers</h2>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <h3><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B17" rel="nofollow">C++17</a>
    compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.20.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.10.1+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.7+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://www.openmp.org" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (for
    CUDA support, needs 3.7.9+ and 4.2+ is recommended)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <p>Optional CUDA-capable dependencies for tests include:</p>

    <ul>

    <li>

    <a href="https://github.com/cupy/cupy#installation">cupy</a> 11.2+</li>

    <li>

    <a href="https://numba.readthedocs.io/en/stable/user/installing.html" rel="nofollow">numba</a>
    0.56+</li>

    <li>

    <a href="https://pytorch.org/get-started/locally/" rel="nofollow">torch</a> 1.12+</li>

    </ul>

    <h3><a id="user-content-install-dependencies" class="anchor" aria-hidden="true"
    href="#install-dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Install
    Dependencies</h3>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.20.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional:                                    --user</span>

    python3 -m pip install -U pip setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <h3><a id="user-content-configure-your-compiler" class="anchor" aria-hidden="true"
    href="#configure-your-compiler"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configure
    your compiler</h3>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    python3 -m pip install -U -r requirements.txt

    python3 -m pip install -v --force-reinstall --no-deps <span class="pl-c1">.</span></pre></div>

    <p>If you are iterating on builds, it will faster to rely on <code>ccache</code>
    and to let CMake call the <code>pip</code> install logic:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build

    cmake --build build --target pip_install -j 8</pre></div>

    <h3><a id="user-content-test" class="anchor" aria-hidden="true" href="#test"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Test</h3>

    <p>After successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests</span>

    python3 -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python3 -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python3 -m pytest tests/test_intvect.py::test_iv_conversions


    <span class="pl-c"><span class="pl-c">#</span> Run all tests, do not capture "print"
    output and be verbose</span>

    python3 -m pytest -s -vvvv tests/</pre></div>

    <h3><a id="user-content-build-options" class="anchor" aria-hidden="true" href="#build-options"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Options</h3>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>1/2/<strong>3</strong>

    </td>

    <td>Dimension of AMReX</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>PYBIND11_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    <tr>

    <td><code>PYAMREX_LIBDIR</code></td>

    <td><em>None</em></td>

    <td>If set, search for pre-built a pyAMReX library</td>

    </tr>

    <tr>

    <td><code>PYINSTALLOPTIONS</code></td>

    <td><em>None</em></td>

    <td>Additional options for <code>pip install</code>, e.g., <code>-v --user</code>

    </td>

    </tr>

    </tbody>

    </table>

    <p>For example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgements</h2>

    <p>This work was supported by the Laboratory Directed Research and Development
    Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy
    Contract No. DE-AC02-05CH11231.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>pyAMReX Copyright (c) 2021-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for pyamrex can be found at <a href="LICENSE">LICENSE</a>.</p>

    '
  stargazers_count: 16
  subscribers_count: 15
  topics:
  - amrex
  - python
  updated_at: 1675190655.0
AMReX-Microelectronics/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronic
  filenames:
  - Docs/spack.yaml
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" href="#artemis"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a development
    fork of WarpX for modeling micromagnetics and electrodynamic waves in next-generation
    microelectornics.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1665515384.0
CUP-ECS/ping-pong-gpu:
  data_format: 2
  description: null
  filenames:
  - configs/unm-hopper/spack-mpich+yaksa.yaml
  - configs/llnl-lassen/spack-mvapich.yaml
  - build-xlc/spack-xlc-mvapich.yaml
  - configs/llnl-lassen/spack-spectrum.yaml
  - configs/unm-hopper/spack-mpich+yaksa+ucx.yaml
  - build-xlc/spack-xlc-spectrum.yaml
  - configs/unm-hopper/spack-openmpi+ucx.yaml
  - build-mvapich/spack-mvapich.yaml
  - build-lassen-spectrum/spack.yaml
  - build-hpctoolkit/spack-spectrum.yaml
  full_name: CUP-ECS/ping-pong-gpu
  latest_release: null
  readme: '<h1><a id="user-content-gpu-ping-pong-benchmark" class="anchor" aria-hidden="true"
    href="#gpu-ping-pong-benchmark"><span aria-hidden="true" class="octicon octicon-link"></span></a>GPU
    Ping Pong Benchmark</h1>

    <p>Basic regular mesh ping pong benchmark for GPUs written in Kokkos. Baseline
    for

    comparison is a Kokkos parallel loop that packs the data prior to sending. Mesh

    data structure extracted from UNM Fiesta CFD application.</p>

    <h2><a id="user-content-running" class="anchor" aria-hidden="true" href="#running"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running</h2>

    <p>Arguments:</p>

    <ul>

    <li>-n: Length of one face of the mesh being communicated (resulting communciation
    is n * n * 5 * 3 doubles</li>

    <li>-i: Number of iterations to perform</li>

    <li>-d: Face of mesh to communicate (0 = y/z, 1 = x/z, 2 = x/y)</li>

    <li>-m: Mode to use for sending and receiving (0 = MPI datatypes, 1 = Hand gpu
    pack, gpu-aware MPI, 2 = Hand gpu pack, host memory send)</li>

    </ul>

    <p>Example command line:

    <code>srun --mpi=pmi2 --ntasks 2 --gpus-per-task=1 --tasks-per-node=1 -p cup-ecs
    ping_pong -n 200 -i 100 -d 1 -m 0</code></p>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Spack configuration files for different MPIs are in the configs/ directory.
    Generally

    we create spack environments for building, use a setup script to load any necessary

    modules (generally the compiler, which the spack environment doesn''t necessarily

    provide), and activate the spack environment for the buiuld</p>

    <h2><a id="user-content-future-features" class="anchor" aria-hidden="true" href="#future-features"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Future features</h2>

    <ol>

    <li>Option to pack into pinned host memory instead of GPU memory</li>

    <li>Restructure to support other ping pong of data structures extracted from

    other applications.</li>

    <li>Option to change number of ghost cell layers sent</li>

    </ol>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1667693779.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/22.11/oneapi-x86_64/spack.yaml
  - environments/22.08/oneapi.spack.yaml
  - environments/22.11/cuda-x86_64/spack.yaml
  - environments/22.11/cuda-ppc64le/spack.yaml
  - environments/22.08/rocm.spack.yaml
  - environments/22.08/cuda-ppc64le.spack.yaml
  - environments/22.11/rocm-x86_64/spack.yaml
  - environments/22.08/cuda-aarch64.spack.yaml
  - environments/22.11/cuda-aarch64/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#e4s\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n<ul>\n<li>User\
    \ Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\">https://e4s.readthedocs.io</a>\n\
    </li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub: <a href=\"https://github.com/E4S-Project/\"\
    >https://github.com/E4S-Project/</a>\n</li>\n<li>Slack Channel: <a href=\"https://e4s-project.slack.com\"\
    \ rel=\"nofollow\">https://e4s-project.slack.com</a>\n</li>\n<li>E4S Dashboard:\
    \ <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\
    >E4S-Project/E4S-Project.github.io</a> - E4S Documentation repo that is hosted\
    \ on <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 16
  subscribers_count: 10
  topics: []
  updated_at: 1663940188.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, time-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/desktop/spack-macos-openmp.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '23.01'
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" href="#warpx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667"
    alt="Gitter" data-canonical-src="https://badges.gitter.im/ECP-WarpX/community.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1016/j.parco.2021.102833" rel="nofollow"><img src="https://camo.githubusercontent.com/1f6ca17eba9f0dbca214c58a50e39d5e4d2c5513476e963147c57c7b9f40f378/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313031362f6a2e706172636f2e323032312e3130323833332d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1016/j.parco.2021.102833-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our Gitter room at <a href="https://gitter.im/ECP-WarpX/community" rel="nofollow">https://gitter.im/ECP-WarpX/community</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 168
  subscribers_count: 16
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1675040717.0
ExCALIBUR-NEPTUNE/NESO:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: ExCALIBUR-NEPTUNE/NESO
  latest_release: null
  readme: "<p>This is a test implementation of a PIC solver for 1+1D Vlasov Poisson,\
    \ written\nin C++/DPC++.\nThis is primarily designed to test the use of multiple\
    \ repos/workflows for\ndifferent code components.</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>CMake</li>\n\
    <li>Boost &gt;= 1.74 (for tests)</li>\n<li>SYCL implementation Hipsycl and fftw\
    \ or OneAPI and MKL.</li>\n<li>Nektar++</li>\n<li>NESO-Particles</li>\n</ul>\n\
    <h3><a id=\"user-content-building-with-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#building-with-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Building with Spack</h3>\n<p>The easiest way to install\
    \ NESO is using the\n<a href=\"https://spack.readthedocs.io/en/latest/index.html\"\
    \ rel=\"nofollow\">Spack package manager</a>, although\nthis can take a few hours\
    \ the first time you do it or if you change\ncompilers. This repository has been\
    \ set up so you can use a\nvariation of the <a href=\"https://spack-tutorial.readthedocs.io/en/latest/tutorial_developer_workflows.html\"\
    \ rel=\"nofollow\">Spack developer\nworkflow</a>. Simply\nrun the following commands\
    \ at the top level of the repository:</p>\n<p>If you don't already have Spack\
    \ available on your computer, install it\naccording to the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">official documentation</a>, or as follows:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Ensure all prerequisites are installed</span>\napt update <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> For Ubuntu; other distros have their own\
    \ commands</span>\napt install build-essential ca-certificates coreutils curl\
    \ environment-modules gfortran git gpg lsb-release python3 python3-distutils python3-venv\
    \ unzip zip\n\ngit clone -c feature.manyFiles=true -b v0.19.0 https://github.com/spack/spack.git\
    \ <span class=\"pl-smi\">$HOME</span>/.spack\n<span class=\"pl-c1\">echo</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">'</span>export SPACK_ROOT=$HOME/.spack<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span\
    \ class=\"pl-smi\">$HOME</span>/.bashrc\n<span class=\"pl-c1\">echo</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span>source $SPACK_ROOT/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span\
    \ class=\"pl-smi\">$HOME</span>/.bashrc\n<span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-smi\">$HOME</span>/.spack\n<span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$SPACK_ROOT</span>/share/spack/setup-env.sh</pre></div>\n<p>Next,\
    \ install the Intel compilers if they are not already present on\nyour computer.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>spack install intel-oneapi-compilers\n\
    spack load intel-oneapi-compilers\nspack compiler find\nspack unload intel-oneapi-compilers</pre></div>\n\
    <p>Now, activate the NESO development environment and build it and its\ndependencies.\
    \ This must be done from the top level of this\nrepository.</p>\n<pre><code>git\
    \ submodule update --init\n. activate\nspack install\n</code></pre>\n<p>The <code>activate</code>\
    \ script sets some useful environment variables and runs\n<code>spack activate\
    \ ...</code>. This activates an <a href=\"https://spack.readthedocs.io/en/latest/environments.html#anonymous-environments\"\
    \ rel=\"nofollow\">anonymous Spack\nenvironment</a>\nbased on the settings in\
    \ <a href=\"spack.yaml\">the spack.yaml file</a>. These\nconfigurations tell Spack\
    \ to install NESO and all of its\ndependencies. Rather than pulling fresh NESO\
    \ and Nektar++ source code\nfrom GitHub, it will use the copy of the code in your\
    \ current working\ndirectory and the Nektar++ submodule (respectively). You can\
    \ leave\nthis environment at any time by running <code>deactivate</code>.</p>\n\
    <p><code>spack install</code> will build two copies of NESO: one with\nGCC/hipSYCL/FFTW3\
    \ and one with Intel's OneAPI/DPC++/MKL. These\npackages and their dependencies\
    \ will be installed in the usual Spack\nlocations. They will also be linked into\
    \ <a href=\"https://spack.readthedocs.io/en/latest/environments.html#filesystem-views\"\
    \ rel=\"nofollow\">\"filesystem\nviews\"</a>\n<code>view/gcc-hipsycl</code> and\
    \ <code>view/oneapi-dpcpp</code>. The NESO builds will be\ndone in directories\
    \ called something like <code>spack-build-abc1234</code> (the\nhashes at the end\
    \ will differ). If you change your spack installation\nin some way (e.g., upgrading\
    \ the version of a dependency) then the\nhash will change and NESO and/or Nektar++\
    \ will be rebuilt. The\nactivation provides the convenience command <code>cleanup</code>\
    \ to delete these\nold builds.</p>\n<p>In order to tell which build is which,\
    \ symlinks <code>builds/gcc-hipsycl</code>\nand <code>builds/oneapi-dpcpp</code>\
    \ are provided. As Nektar++ is being built\nfrom the submodule, its build trees\
    \ are located at\n<code>nektar/spack-build-abc1234</code> (the hashes at the end\
    \ will differ) and\ncan be accessed with symlinks <code>nektar/builds/gcc</code>\
    \ and\n<code>nektar/builds/oneapi</code>. Test binaries will be contained within\n\
    these build directories. The activation script launches a background\ntask which\
    \ regularly checks whether the hashes of your NESO and\nNektar++ builds has changed.\
    \ If they have, it will update the\nsymlinks. They will also be checked whenever\
    \ the environment is\nactivated or deactivated.</p>\n<p>It has been found that\
    \ the oneAPI and clang\ncompilers struggle to build NumPy and Boost due to very\
    \ large memory\nrequirements. As such, the oneAPI build of NESO compiles these\n\
    dependencies using another compiler  (the Intel Classic compilers by default).\
    \ Feel free to\nexperiment with changing these or seeing if there is a way to\
    \ make the\nbuilds work with oneAPI.</p>\n<h4><a id=\"user-content-developing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#developing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Developing</h4>\n<p>As you develop\
    \ the code, there are a few options for how you\nrecompile. One is simply to run\
    \ <code>spack install</code> again. This will reuse\nthe existing build directory\
    \ and reinstall the results of the\nbuild. The build environment used is determined\
    \ by the package\nconfiguration for NESO (as specificed in the NESO <a href=\"\
    https://github.com/ExCALIBUR-NEPTUNE/NESO-Spack\">package\nrepository</a> and\
    \ is\nthe same as if you were doing a traditional Spack installation of a\nnamed\
    \ version of NESO. This has the particular advantage of building\nwith all toolchaings\
    \ (i.e., GCC, OneAPI) at one time. It also works\nwell if you are developing NESO\
    \ and Nektar++ simultaneously, as it\nwill rebuild both. The main disadvantage\
    \ of this approach is that\nSpack hides the output of CMake during the build process\
    \ and will only\nshow you any information on the build if there is an error. This\
    \ means\nyou will likely miss any compiler warnings, unless you check the build\n\
    logs. There is also some overhead associated with running Spack, which\nmakes\
    \ the build a little slow.</p>\n<p>An alternative approach is to prefix your usual\
    \ build commands with\n<code>spack build-env neso%gcc</code> or <code>spack build-env\
    \ neso%oneapi</code> (depending\non which compiler you want to use). This will\
    \ cause the commands to be run in the\nsame build environment as when installing\
    \ that version of NESO. For example, you\ncould run</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack build-env neso%gcc cmake <span class=\"\
    pl-c1\">.</span> -B build\nspack build-env neso%gcc cmake --build build</pre></div>\n\
    <p>This would cause the build to occur in the directory <code>build</code>. This\n\
    approach works quite well. A slight downside is the commands are\na bit cumbersome.\
    \ It also won't build for both compilers at once,\nalthough you might not want\
    \ to do that anyway, early during the development\nof a new feature.</p>\n<p>Finally,\
    \ you could take advantage of the filesystem views created\nwhen you installed\
    \ the environment and which give you access\nto all of the resources for the build\
    \ that you need. For example, you\ncould run</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -DCMAKE_PREFIX_PATH=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span\
    \ class=\"pl-pds\">)</span></span>/gcc-hipsycl <span class=\"pl-c1\">.</span>\
    \ -B build\ncmake --build build</pre></div>\n<p>CMake will automatically be able\
    \ to find all of the packages it needs\nin <code>gcc-hipsycl</code>. The downside\
    \ of this approach is that there is a\nrisk CMake will end up using a different\
    \ compiler or compiler version\nthan intended. This is especially likely if not\
    \ using a system\ncompiler. You should ensure you are aware of what compilers\
    \ you have\ninstalled and, if necessary, explicitly specify to CMake which you\n\
    want to use.</p>\n<p>In general, it is recommended to use the <code>spack build-env\
    \ ...</code>\ncommand for compiling earlier in the development process (if you\n\
    aren't simultaneously making changes to Nektar++), to ensure you see\nany warnings\
    \ and so you aren't spending extra times compiling things\ntwice. Once you believe\
    \ you have a working implementation with one\ncompiler (of if you are working\
    \ on NESO and Nektar++ simultaneously),\nyou can use <code>spack install</code>\
    \ to test the build against other\ncompilers. It is <em>not</em> recommended to\
    \ use the Spack views, as building\nthis way is less likely to be reproducible.</p>\n\
    <h3><a id=\"user-content-manually-installing-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#manually-installing-dependencies\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Manually Installing Dependencies</h3>\n<h4><a\
    \ id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"#cmake\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CMake</h4>\n\
    <p>Ensure a recent version of <a href=\"https://cmake.org/download/\" rel=\"nofollow\"\
    >CMake</a> is available.\nIf necessary, install with</p>\n<pre><code>wget https://github.com/Kitware/CMake/releases/download/v3.23.1/cmake-3.23.1.tar.gz\n\
    tar xvf cmake-3.23.1.tar.gz\ncd cmake-3.23.1/\n./configure\nmake\n</code></pre>\n\
    <h4><a id=\"user-content-boost\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #boost\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Boost</h4>\n\
    <p>The test suite requires the <a href=\"https://www.boost.org/\" rel=\"nofollow\"\
    >Boost library</a> (version &gt;= 1.74).\nIf this is not available on your system,\
    \ it can be built from source by doing</p>\n<pre><code>wget https://boostorg.jfrog.io/artifactory/main/release/1.79.0/source/boost_1_79_0.tar.gz\n\
    tar xvf boost_1_79_0.tar.gz\ncd boost_1_79_0/\n./bootstrap.sh\n./b2\n</code></pre>\n\
    <p>If the install is not automatically found by cmake, specify the path to the\n\
    install dir at configure time:</p>\n<pre><code>cmake -DBoost_INCLUDE_DIR=/path/to/boost_1_79_0/\
    \ . -B build\n</code></pre>\n<h4><a id=\"user-content-nektar\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#nektar\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Nektar++</h4>\n<p>To build with Nektar++, ensure that\
    \ Nektar++ is installed on your system.\nDetailed instructions can be found in\
    \ the <a href=\"https://doc.nektar.info/userguide/latest/user-guidese3.html#x7-60001.3\"\
    \ rel=\"nofollow\">Nektar user guide</a>,\nbut briefly,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>git clone https://gitlab.nektar.info/nektar/nektar\n\
    <span class=\"pl-c1\">cd</span> nektar\nmkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build\ncmake .. \ncmake --build <span class=\"\
    pl-c1\">.</span>\nmake install</pre></div>\n<p>should install Nektar++.</p>\n\
    <p>To build NESO with Nektar++, set the <code>Nektar++_DIR</code> flag in cmake,\
    \ e.g.</p>\n<pre><code>cmake -DNektar++_DIR=/path/to/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>where <code>/path/to/nektar/build/dist/lib64/nektar++/cmake</code>\
    \ is the folder containing\nthe <code>Nektar++Config.cmake</code> file.\nNote\
    \ that for this file to exist, you must do <code>make install</code> at the end\
    \ of the\nNektar++ build.</p>\n<h3><a id=\"user-content-neso-particles\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#neso-particles\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>NESO-Particles</h3>\n<p>Install NESO-Particles\
    \ by following the installation instructions at <a href=\"https://github.com/ExCALIBUR-NEPTUNE/NESO-Particles\"\
    >https://github.com/ExCALIBUR-NEPTUNE/NESO-Particles</a>. Additional configuration\
    \ options for NESO-Particles can be passed when NESO is configured through cmake.</p>\n\
    <h3><a id=\"user-content-neso\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #neso\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>NESO</h3>\n\
    <h3><a id=\"user-content-manually-building-neso\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#manually-building-neso\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Manually building NESO</h3>\n<p>To build the code\
    \ and the tests, do</p>\n<pre><code>cmake . -B build\ncmake --build build\n</code></pre>\n\
    <p>It may be necessary to tell CMake the location of dependencies:</p>\n<ul>\n\
    <li>Boost by setting <code>-DBoost_INCLUDE_DIR</code>\n</li>\n<li>SYCL compiler\
    \ by setting <code>-DCMAKE_CXX_COMPILER</code>\n</li>\n<li>Nektar++ by setting\
    \ the location of <code>Nektar++Config.cmake</code> using <code>-DNektar++_DIR</code>\n\
    </li>\n</ul>\n<p>For example:</p>\n<pre><code>cmake -DCMAKE_CXX_COMPILER=dpcpp\
    \ -DBoost_INCLUDE_DIR=/root/code/boost_1_78_0 -DNektar++_DIR=/root/code/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>The executable <code>NESO</code>\
    \ is created in <code>bin</code>.</p>\n<h2><a id=\"user-content-handling-submodules-when-developing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#handling-submodules-when-developing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Handling\
    \ Submodules when Developing</h2>\n<p>This repository contains some git submodules,\
    \ for code which is likely\nto undergo development tightly-coupled with NESO (e.g.,\
    \ Nektar) or\nwhich it is convenient to distribute this way (NESO-spack). When\n\
    checking out different branches, on which submodules are at different\ncommits,\
    \ it can be easy to end up with working against different\nversions of submodules\
    \ than you think. This can cause headaches when\ntrying to reproduce certain behaviour.\
    \ Run <code>git submodule update --recursive</code> to ensure everything is at\
    \ the correct commit. You can\navoid this issue altogether by using <code>git\
    \ checkout --recurse-submodules</code>. You can also set this as a default for\
    \ your\ncopy of the repository by running <code>git config --local submodule.recurse\
    \ true</code>. Note, however, that these latter two options\ncan cause git to\
    \ complain if trying to switch between two branches,\nonly one of which contains\
    \ a submodule.</p>\n<h2><a id=\"user-content-system-specific-information\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#system-specific-information\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>System-specific information</h2>\n\
    <h3><a id=\"user-content-dirac-csd3--cambridge\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#dirac-csd3--cambridge\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Dirac (CSD3 @ Cambridge)</h3>\n<pre><code>module unload\
    \ intel/compilers/2017.4\nmodule unload intel/mkl/2017.4\nmodule load gcc/11\n\
    module load intel/oneapi/2022.1.0/compiler\nmodule load intel/oneapi/2022.1.0/mkl\n\
    module load intel/oneapi/2022.1.0/tbb\nexport  LD_LIBRARY_PATH=/usr/local/software/intel/oneapi/2022.1/compiler/latest/linux/lib:$LD_LIBRARY_PATH\n\
    </code></pre>\n<h2><a id=\"user-content-testing\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#testing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Testing</h2>\n<p>CMake also builds a suite unit tests (e.g. <code>&lt;build_dir&gt;/test/unitTests</code>)\n\
    and integration tests (<code>&lt;build_dir&gt;/test/integrationTests</code>).\
    \ The build\ndirectories are <code>builds/gcc-hipsycl</code> and <code>builds/oneapi-dpcpp</code>.</p>\n\
    <p>A subset of the tests may be run using appropriate flags:\ne.g. <code>path/to/testExecutable\
    \ --gtest_filter=TestSuiteName.TestName</code>.\nSee the <a href=\"http://google.github.io/googletest/\"\
    \ rel=\"nofollow\">googletest user guide</a>\nfor more info, especially with regards\
    \ to running <a href=\"https://google.github.io/googletest/advanced.html#selecting-tests\"\
    \ rel=\"nofollow\">specific\ntests</a>.</p>\n<p>Alternatively, you can call\n\
    <a href=\"https://cmake.org/cmake/help/latest/manual/ctest.1.html\" rel=\"nofollow\"\
    >CTest</a> from\nwithin the build directory to execute your tests.</p>\n<h1><a\
    \ id=\"user-content-solvers\" class=\"anchor\" aria-hidden=\"true\" href=\"#solvers\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Solvers</h1>\n\
    <p>Each solver has</p>\n<ul>\n<li>Source code: <code>solvers/&lt;solver_name&gt;</code>\n\
    </li>\n<li>Integration tests: <code>test/integration/solvers/&lt;solver_name&gt;</code>\n\
    </li>\n<li>Examples: <code>examples/&lt;solver_name&gt;/&lt;example_name&gt;</code>\n\
    </li>\n</ul>\n<p>To run a solver example:</p>\n<pre><code>./scripts/run_eg.sh\
    \  [solver_name] [example_name] &lt;-n num_MPI&gt; &lt;-b build_dir&gt;\n</code></pre>\n\
    <p>which will look for the solver executable in the most recently modified spack-build-*\
    \ directory, unless one is supplied with <code>-b</code>.  Output is generated\
    \ in <code>example-runs/&lt;solver_name&gt;/&lt;example_name&gt;</code>.</p>\n\
    <h2><a id=\"user-content-address-sanitizers\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#address-sanitizers\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Address Sanitizers</h2>\n<p>To debug for memory leaks,\
    \ compile with the options</p>\n<pre><code>cmake . -B -DENABLE_SANITIZER_ADDRESS=on\
    \ -DENABLE_SANITIZER_LEAK=on\n</code></pre>\n<h2><a id=\"user-content-licence\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#licence\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Licence</h2>\n<p>This is licenced\
    \ under MIT.</p>\n<p>In order to comply with the licences of dependencies, this\
    \ software is not to be released as a binary.</p>\n"
  stargazers_count: 2
  subscribers_count: 6
  topics: []
  updated_at: 1675192754.0
FTHPC/Correlation_Compressibility:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: FTHPC/Correlation_Compressibility
  latest_release: v0.1
  readme: "<h1><a id=\"user-content-compressibility-analysis-correlation_compressibility\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#compressibility-analysis-correlation_compressibility\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compressibility\
    \ Analysis (Correlation_Compressibility)</h1>\n<h2><a id=\"user-content-statement-of-purpose\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#statement-of-purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Statement of Purpose</h2>\n<p>This\
    \ repo contains scripts to perform compressibility analysis on several leading\
    \ lossy compressors.\nThe compressibility analysis relies on deriving statistics\
    \ on scientific data and explore their relationships to their compression ratios\
    \ from various lossy compressors (based on various compression scheme).\nThe extracted\
    \ relationships between compression ratios and statistical predictors are modeled\
    \ via regression models, which provide a statistical framework to predict compression\
    \ ratios for the different studied lossy compressors.</p>\n<p>This repo contains\
    \ an automatic framework of scripts that perform the compression of scientific\
    \ datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding and Bit\
    \ Grooming), the derivation of the statistical predictors of compression ratios\
    \ (SVD, standard deviation, quantized entropy), and scripts to perform the training\
    \ of the regression models (linear and spline regressions) as well as the validation\
    \ of the regression predictions.\nA runtime analysis is also performed and associated\
    \ codes are provided.</p>\n<h3><a id=\"user-content-main-code-structures\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#main-code-structures\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Main code structures</h3>\n<p>Compression\
    \ metrics, including compression ratios, and derivation of statistical predictors\
    \ (SVD, standard deviation, quantized entropy) codes are found in <code>compress_package</code>\
    \ and are run via <code>scripts/run.sh</code> as described in the section \"How\
    \ to compute statistical predictors and compression analysis on datasets\".\n\
    Linear and spline regressions training and validation (functions <code>cr_regression_linreg</code>\
    \ and <code>cr_regression_gam</code> from the script <code>replicate_figures/functions_paper.R</code>).\n\
    Codes for the different runtime analysis are found in the folder <code>runtime_analysis</code>\
    \ and are automated with the script <code>runtime.sh</code>, the study includes\
    \ compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled)\
    \ variogram and local (tiled) variogram, and runtime for training and prediction\
    \ of the regressions.<br>\nFinally, the script <code>replicate_figures/graphs_paper_container.R</code>\
    \ replicates and saves all the figures from the paper ad as well as numbers from\
    \ the tables.</p>\n<p>For each dataset in the <code>dataset</code> folder, slicing\
    \ is performed for each variable field (e.g. density in Miranda), each slice is\
    \ stored in a class. The class is updated as compressions with the 8 compressors\
    \ is performed and updated as the statistical predictors are derived. Results\
    \ of each class are stored in a .csv file (example of csv files can be found at\
    \ <code>replicate_figures/generated_data/</code>).\nAll the datasets stored in\
    \ the <code>dataset</code> folder can be analyzed with the given set of codes,\
    \ one needs to source <code>scripts/config.json</code> with the appropriate dataset\
    \ name as described in the below section \"How to compute statistical predictors\
    \ and compression analysis on datasets\".\nThe regression analysis and its prediction\
    \ is then performed on R dataframes based on the aforementioned .csv files.</p>\n\
    <h2><a id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#system-information\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>System Information</h2>\n<p>The hardware and software\
    \ versions used for the performance evaluations can be found in the table below.\
    \ These nodes come from Clemson University's Palmetto Cluster.</p>\n<p>These nodes\
    \ have:</p>\n<table>\n<thead>\n<tr>\n<th>component</th>\n<th>version</th>\n<th>component</th>\n\
    <th>version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CPU</td>\n<td>Intel Xeon\
    \ 6148G (40 cores)</td>\n<td>sz2</td>\n<td>2.1.12.2</td>\n</tr>\n<tr>\n<td>GPU</td>\n\
    <td>2 Nvidia v100</td>\n<td>sz3</td>\n<td>3.1.3.1</td>\n</tr>\n<tr>\n<td>Memory</td>\n\
    <td>372GB</td>\n<td>zfp</td>\n<td>0.5.5</td>\n</tr>\n<tr>\n<td>Network</td>\n\
    <td>2 Mellanox MT27710 (HDR)</td>\n<td>mgard</td>\n<td>1.0.0</td>\n</tr>\n<tr>\n\
    <td>FileSystem</td>\n<td>BeeGFS 7.2.3 (24 targets)</td>\n<td>bit grooming</td>\n\
    <td>2.1.9</td>\n</tr>\n<tr>\n<td>Compiler</td>\n<td>GCC 8.4.1</td>\n<td>digit\
    \ rounding</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>OS</td>\n<td>CentOS 8.2.2004</td>\n\
    <td>R</td>\n<td>4.1.3</td>\n</tr>\n<tr>\n<td>MPI</td>\n<td>OpenMPI 4.0.5</td>\n\
    <td>Python</td>\n<td>3.9.12</td>\n</tr>\n<tr>\n<td>LibPressio</td>\n<td>0.83.4</td>\n\
    <td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-first-time-setup\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-setup\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>First time setup</h2>\n<h3><a\
    \ id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#container-installation-for-ease-of-setup\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Container Installation\
    \ (for ease of setup)</h3>\n<p>We provide a container for <code>x86_64</code>\
    \ image for ease of installation.</p>\n<p>This container differs from our experimental\
    \ setup slightly. The production build used <code>-march=native -mtune=native</code>\
    \ for architecture optimized builds where as the container does not use these\
    \ flags to maximize compatibility across <code>x86_64</code> hardware.</p>\n<p>NOTE\
    \ this file is &gt;= 11 GB , download with caution.</p>\n<h4><a id=\"user-content-docker\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#docker\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Docker</h4>\n<p>Many other systems\
    \ can use podman or docker.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>docker pull ghcr.io/fthpc/correlation_compressibility:latest\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>most systems</span>\ndocker run -it --rm ghcr.io/fthpc/correlation_compressibility:latest\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> if running on a SeLinux enforcing\
    \ system</span>\ndocker run -it --rm --security-opt label=disable ghcr.io/fthpc/correlation_compressibility:latest</pre></div>\n\
    <h3><a id=\"user-content-building-the-container\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#building-the-container\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Building the Container</h3>\n<p>You can build the\
    \ container yourself as follows:\nNOTE this process takes 3+ hours on a modern\
    \ laptop, and most clusters do not\nprovide sufficient permissions to run container\
    \ builds on the cluster.</p>\n<p>Additionally compiling MGRAD -- one of the compressors\
    \ we use takes &gt;= 4GB RAM per core, be cautious\nwith systems with low RAM.\
    \  You may be able compensate by using fewer cores by changing the spack install\n\
    instruction in the Dockerfile to have a <code>-j N</code> where <code>N</code>\
    \ is the number of cores you wish to use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> install/module load git-lfs,\
    \ needed to download example_data for building the container</span>\nsudo dnf\
    \ install git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span>Fedora/CentOS\
    \ Stream 8</span>\nsudo apt-get install git-lfs <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Ubuntu</span>\nspack install git-lfs<span class=\"pl-k\">;</span>\
    \ spack load git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> using\
    \ spack</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> clone this\
    \ repository</span>\ngit clone --recursive https://github.com/FTHPC/Correlation_Compressibility\n\
    <span class=\"pl-c1\">cd</span> Correlation_Compressibility\ndocker build <span\
    \ class=\"pl-c1\">.</span> -t correlation_compressibility</pre></div>\n<h3><a\
    \ id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#manual-installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Manual Installation</h3>\n<p>By default, it is recommended to follow\
    \ the install locations that are indicated on the top of <code>scripts/run.sh</code>\n\
    and the top of <code>config.json</code>. These two files provide the configuration\
    \ options to get the program running.</p>\n<p>Spack should be installed in the\
    \ following location: <code>$HOME/spack/</code></p>\n<p>This Github repo should\
    \ be cloned in the following location: <code>$HOME/Correlation_Compressibility/</code>\n\
    This location is also referenced as the <code>COMPRESS_HOME</code> environment\
    \ variable.</p>\n<p>A dataset folder called 'datasets' should be in the following\
    \ location: <code>$HOME/Correlation_Compressibility/datasets/</code>.</p>\n<p>Clone\
    \ the repo but make sure to install or load <code>git-lfs</code> first.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> install/module load git-lfs, needed to download example_data\
    \ for building the container</span>\nsudo dnf install git-lfs <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>Fedora/CentOS Stream 8</span>\nsudo apt-get install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ubuntu</span>\nspack\
    \ install git-lfs<span class=\"pl-k\">;</span> spack load git-lfs <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> clone this repository</span>\ngit clone https://github.com/FTHPC/Correlation_Compressibility\
    \ <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility</pre></div>\n\
    <p>If you forgot to install <code>git-lfs</code> before and have an empty file\
    \ in the  <code>datasets</code> folder, you should install <code>git-lfs</code>\n\
    and then run the following:</p>\n<pre><code>git lfs fetch\ngit lfs checkout\n\
    </code></pre>\n<p>Once Spack is installed, there is a <code>spack.yaml</code>\
    \ configuration file containing the Spack environment necessary to run the program.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">$HOME</span>\ngit clone --depth=1 https://github.com/spack/spack\n\
    git clone --depth=1 https://github.com/robertu94/spack_packages \n<span class=\"\
    pl-c1\">source</span> ./spack/share/spack/setup-env.sh \nspack compiler find\n\
    spack external find \nspack repo add --scope=site ./spack_packages \n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ \nspack env activate <span class=\"pl-c1\">.</span>\nspack install\n<span class=\"\
    pl-k\">export</span> COMPRESS_HOME=<span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ </pre></div>\n<p>These commands will install the environment. The environment\
    \ only needs to be installed once.\nIf you are using an older &lt; gcc11, then\
    \ you will need to add the following to the <code>spack.yaml</code> file:</p>\n\
    <pre><code>^libstdcompat+boost\n</code></pre>\n<p>after <code>^mgard@robertu94+cuda</code>\
    \ but before the <code>,</code>.</p>\n<h2><a id=\"user-content-replication-of-results\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-results\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication of\
    \ Results</h2>\n<h3><a id=\"user-content-how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to compute\
    \ statistical predictors and compression metrics on datasets</h3>\n<p>In order\
    \ to run the statistical analysis that computes the statistical predictors (SVD,\
    \ standard deviation, quantized entropy) of compression ratios, a dataset and\
    \ a configuration file must be specified.\nTEST is a dataset that is specified\
    \ within the <code>config.json</code> file.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh scripts/run.sh -c config.json -d TEST -n 2</pre></div>\n<p>The command\
    \ above performs the computation of statistical predictors and writes output to\
    \ the output file specified in the configuration file.\nThis will use local hardware\
    \ without a scheduler. Use <code>-n</code> to specify the MPI processes on your\
    \ local system. Default value is 32.\nIt is recommended that this value matches\
    \ your CPU core count.</p>\n<p>If one has the PBS scheduler and runs outside of\
    \ the container, feel free to use flags <code>-p</code> or <code>-s</code> for\
    \ job execution.\n<code>-p</code> will schedule multiple jobs based on the quantized\
    \ error bounds and error bound types for a specified dataset.\n<code>-s</code>\
    \ will schedule a single job grouping all the analysis for a specified dataset.</p>\n\
    <p>See <code>-h</code> for more options or help with syntax.</p>\n<p>If a dataset\
    \ is wanted to run, the <code>config.json</code> file provides options to add\
    \ datasets.\nThe following options must be added when adding another dataset in\
    \ the configuration file:</p>\n<div class=\"highlight highlight-source-json\"\
    ><pre><span class=\"pl-ent\">\"_comment\"</span> : \n{\n    <span class=\"pl-ent\"\
    >\"folder\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>folder containing h5 or binary files<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"data_dimensions\"</span>   : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>dimensions of the datasets within dataset_folder.\
    \ Either 1x2 or 1x3. EX: '1028, 1028'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"slice_dimensions\"</span>  : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>list of the dimensions wanted: EX: 'None' or\
    \ 'X, Y, Z'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\"\
    >\"output\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>name of the output csv file: EX: 'test.csv'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"dtype\"</span>             : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>data type. can be 'float32' or 'float64'<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\">\"parse_info\"\
    </span>        : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type of\
    \ parsing needed: 'None', 'slice', 'gaussian', 'gaussian_multi', 'spatialweight',\
    \ or 'scalarweight'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"\
    pl-ent\">\"dataset_name\"</span>      : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>necessary accessing 2D HDF5 files: 'standard' if not custom. custom\
    \ EX: 'Z'<span class=\"pl-pds\">\"</span></span>\n} </pre></div>\n<p>From this\
    \ section, .csv files are generated for each dataset and contain all the statistical\
    \ predictors described in the paper as well as compression metrcis including compresison\
    \ ratios for the 8 lossy compressors and 4 error bounds.</p>\n<h3><a id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To run the\
    \ training and prediction timing analysis demonstration</h3>\n<p>In order to run\
    \ the timing analysis, a dataset must be specified.\nThere are two datasets setup\
    \ within this demonstration.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh runtime_analysis/runtime.sh -d [DATASET]</pre></div>\n<p>[DATASET] can\
    \ be either [NYX] or [SCALE]</p>\n<p>After running the above script, an *.RData\
    \ file(s) will be produced giving the approprirate timing information of\nthe\
    \ training and prediction for the regression models.</p>\n<p>Note: A quicker and\
    \ more efficient quantized entropy method is demonstrated in <code>qentropy.cc</code></p>\n\
    <h4><a id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-following-below-runs-qentropycc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The following below runs <code>qentropy.cc</code>\n\
    </h4>\n<div class=\"highlight highlight-source-shell\"><pre>g++ -std=c++2a -O3\
    \ qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy</pre></div>\n\
    <p>Note: Please run the runtime analysis for both datasets before running the\
    \ following section.</p>\n<h3><a id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication\
    \ of figures: how to run statistical prediction of compression ratios and the\
    \ prediction validation</h3>\n<p>The script <code>graphs_paper_container.R</code>\
    \  saves the graphs presented in the paper and provides associated validation\
    \ metrics (correlation and median absolute error percentage).</p>\n<p>The script\
    \ <code>graphs_paper_container.R</code> will source the scripts  <code>load_dataset_paper.R</code>\
    \ and <code>functions_paper.R</code> that respectively load the dataset of interest\
    \ and perform the regression analysis (training and prediction in cross-validation).\n\
    As a consequence the scripts  <code>load_dataset_paper.R</code> and <code>functions_paper.R</code>\
    \ do not need to be run by the user.</p>\n<p>The script <code>graphs_paper_container.R</code>\
    \  is run via the command:\n<code>bash sh replicate.sh</code></p>\n<p>From running\
    \ the script once, it will save all Figures 1, 3, 4 and 5 into .png files from\
    \ the paper as well as corresponding validation metrics.\nFigure 2 is not saved\
    \ as it provides a simple vizualization of slices of the datasets.\nSlices of\
    \ the datasets are generated in the Section \"How to compute statistical predictors\
    \ and compression metrics\" and can be stored, however we do not save them here\
    \ to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in\
    \ the R console.\nAll printed validation metrics are save into a file named <code>figure_replication.log</code>.\n\
    Figures and the log-file are saved in the same folder as the one where R script\
    \ is run and the filename structure is <code>figY_*.png</code> with Y is the figure\
    \ number reference in the paper and <code>*</code> provides additional informnation\
    \ about the data and the compressor.<br>\nNumbers for Table 4 are saved in the\
    \ last section in .txt files <code>statistic_benchmark_runtime_X.txt</code> with\
    \ X the studied dataset (NYX or SCALE).</p>\n<p>In order to limit the container\
    \ size to aid reproducibility, we only added a restricted number of scientific\
    \ datasets in the container and we rely on csv files from our production runs\
    \ (saved as described above in the Section \"How to compute statistical predictors\
    \ on datasets\").\nMore datasets are available on <a href=\"https://sdrbench.github.io\"\
    \ rel=\"nofollow\">SDRBench</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1648227729.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1658856345.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 22.08/0.19.0/spack.yaml
  - 22.08/0.18.1/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-for-lumi" class="anchor"
    aria-hidden="true" href="#spack-configuration-files-for-lumi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Spack configuration files for LUMI</h1>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 12
  topics: []
  updated_at: 1661775740.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Sat Dec 17 18:52:51 MST 2022</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>9f557cbfe06b92815bc29b92e7cf4eff09917601</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>22.12</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td>165cd55980572fc3ccef5f322ad8ad8b3e5dd3db</td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/22.12</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/22.12/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 3
  subscribers_count: 12
  topics: []
  updated_at: 1675287321.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-22.05/prod/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/gcc/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/perlmutter-user-spack/spack.yaml
  - docs/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/nvhpc/spack.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/prod/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cce/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file. The documentation is available at\
    \ <a href=\"https://nersc-spack-infrastructure.rtfd.io/\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io/</a></p>\n\
    <h2><a id=\"user-content-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-configuration\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Configuration</h2>\n<p>The spack configuration\
    \ can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<h2><a id=\"user-content-running-ci-pipelines\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-ci-pipelines\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>. Please make sure you\
    \ login to the appropriate hostname when starting the gitlab runner.</p>\n<table>\n\
    <thead>\n<tr>\n<th>System</th>\n<th>Runner Name</th>\n<th>Hostname</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n\
    <td><code>login27</code></td>\n</tr>\n<tr>\n<td>cori</td>\n<td><code>cori-e4s</code></td>\n\
    <td><code>cori02</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    <td><code>login02</code></td>\n</tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n\
    <td><code>gert01</code></td>\n</tr>\n</tbody>\n</table>\n<p>The runner configuration\
    \ files are located in <code>~/.gitlab-runner</code> for user <strong>e4s</strong>.</p>\n\
    <p>The production pipelines are triggered via web-interface which requires approval\
    \ from a project maintainer. Production pipelines should be run when we need to\
    \ do full redeployment of stack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#current-challenges\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have external packages set for packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li><strong>Erik Palmer (<a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>)</strong></li>\n\
    <li><strong>Justin Cook (<a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 8
  subscribers_count: 13
  topics: []
  updated_at: 1673545287.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 41
  subscribers_count: 19
  topics: []
  updated_at: 1675188883.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<h1><a id="user-content-gsi-utils" class="anchor" aria-hidden="true" href="#gsi-utils"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GSI-Utils</h1>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 1
  subscribers_count: 8
  topics: []
  updated_at: 1660063597.0
NOAA-EMC/NCEPLIBS-grib_util:
  data_format: 2
  description: This is a collection of NCEP GRIB related utilities.
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/NCEPLIBS-grib_util
  latest_release: v1.2.4
  readme: '<h1><a id="user-content-nceplibs-grib_util" class="anchor" aria-hidden="true"
    href="#nceplibs-grib_util"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCEPLIBS-grib_util</h1>

    <p>This is a collection of NCEP GRIB related utilities. This is related

    to the <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> project.</p>

    <p>For complete documentation see

    <a href="https://noaa-emc.github.io/NCEPLIBS-grib_util/" rel="nofollow">https://noaa-emc.github.io/NCEPLIBS-grib_util/</a>.
    For the NCEP WMO GRIB2

    Documentation see

    <a href="https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/" rel="nofollow">https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/</a>.</p>

    <h2><a id="user-content-related-nceplibs-projects" class="anchor" aria-hidden="true"
    href="#related-nceplibs-projects"><span aria-hidden="true" class="octicon octicon-link"></span></a>Related
    NCEPLIBS Projects</h2>

    <table>

    <thead>

    <tr>

    <th>Repository</th>

    <th>Notes</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2c">NCEPLIBS-g2c</a></td>

    <td>C implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></td>

    <td>Fortran implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></td>

    <td>Utilities for GRIB2 templates</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <table>

    <thead>

    <tr>

    <th>Utility</th>

    <th>Author(s)</th>

    <th>User(s)</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>cnvgrib</td>

    <td>Stephen Gilbert, Gordon, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>copygb</td>

    <td>Mark Iredell, Stephen Gilbert, Trojan, Boi Vuong</td>

    <td>UFS_UTILS</td>

    </tr>

    <tr>

    <td>copygb2</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>degrib2</td>

    <td>Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grb2index</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grbindex</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong, W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    <tr>

    <td>tocgrib</td>

    <td>Stephen Gilbert, Boi Vuong, Farley, R. E. Jones</td>

    <td>RAP for FAA</td>

    </tr>

    <tr>

    <td>tocgrib2</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>tocgrib2super</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>wgrib</td>

    <td>W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    </tbody>

    </table>

    <p>Code Manager : Hang Lei, Edward Hartnett</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This package requires the following third party libraries:</p>

    <ul>

    <li><a href="http://www.ece.uvic.ca/~mdadams/jasper/" rel="nofollow">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="http://www.gzip.org/zlib/" rel="nofollow">libz</a></li>

    </ul>

    <p>This package requires the folling NCEPLIBS libraries:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a> (before
    version 1.3.0)</li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a> (starting
    version 1.3.0)</li>

    </ul>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <pre><code>mkdir build

    cd build

    cmake -DCMAKE_INSTALL_PREFIX=/path/to/install -DCMAKE_PREFIX_PATH=/path/to/dependencies
    ..

    make -j4

    make install

    </code></pre>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 6
  subscribers_count: 3
  topics: []
  updated_at: 1656698184.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: upp-srw-v2.1.0
  readme: '<h1><a id="user-content-unified-post-processing-upp" class="anchor" aria-hidden="true"
    href="#unified-post-processing-upp"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unified
    Post-Processing (UPP)</h1>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecasting System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Application

    Forecasting System (HAFS), and the Medium Range Weather (MRW) and Short

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model

    derived brightness temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages, or for

    further downstream post-processing, e.g. statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <h2><a id="user-content-user-support" class="anchor" aria-hidden="true" href="#user-support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>User Support</h2>

    <p>Support for the UFS UPP is provided through <a href="https://github.com/NOAA-EMC/UPP/discussions">GitHub
    Discussions</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>User Guide for latest public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <h2><a id="user-content-developer-information" class="anchor" aria-hidden="true"
    href="#developer-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>Developer
    Information</h2>

    <p>Please see review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Kate Fossell</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>The UPP requires certain NCEPLIB packages to be installed via

    the HPC-Stack project.</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-gfsio">NCEPLIBS-gfsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">libz</a></li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for Regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 22
  subscribers_count: 14
  topics: []
  updated_at: 1675185894.0
NOAA-EMC/WW3:
  data_format: 2
  description: WAVEWATCH III
  filenames:
  - model/ci/spack_intel.yaml
  - model/ci/spack_gnu.yaml
  full_name: NOAA-EMC/WW3
  latest_release: 6.07.1
  readme: "<h1><a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2><a id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#general-features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 190
  subscribers_count: 50
  topics: []
  updated_at: 1674700227.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/skylab-dev/spack.yaml
  - configs/templates/gfs-v16.2/spack.yaml
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/skylab-no-python-dev/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/hpc-stack-dev/spack.yaml
  - configs/templates/ufs-weather-model-static/spack.yaml
  - configs/templates/hpc-dev-v1/spack.yaml
  - configs/templates/jedi-ufs-all/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: spack-stack-1.2.0
  readme: '<h1><a id="user-content-spack-stack" class="anchor" aria-hidden="true"
    href="#spack-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>Spack-stack enables the installation of software required

    for HPC system deployments of NOAA''s Unified Forecast System (UFS) and

    other weather and climate models, including components of the Joint

    Effort for Data assimilation Integration (JEDI).</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>.</li>

    </ul>

    <p>Spack-stack is a thin layer around a fork of the

    <a href="https://github.com/spack/spack">spack</a> repository. Spack is a

    community-supported, multi-platform, Python-based package manager

    originally developed by the Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about spack see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for

    spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack

    documentation</a>.</p>

    <p>The stack can be installed on a range of platforms, from Linux and

    macOS laptops to HPC systems, and comes pre-configured for many

    systems. Users can install the necessary packages for a particular

    application and later add the missing packages for another application

    without having to rebuild the entire stack.</p>

    <p>spack-stack is mainly a collection of Spack configuration files, but

    provides a Spack extension to simplify the installation process:</p>

    <ul>

    <li>

    <p><code>spack stack create</code> is provided to copy common, site-specific,
    and

    application-specific configuration files into a coherent Spack

    environment and to create container recipes</p>

    </li>

    <li>

    <p><code>spack stack setup-meta-modules</code> creates compiler, MPI and Python

    meta-modules for a convenient setup of a user environment using

    modules (lua and tcl)</p>

    </li>

    </ul>

    <p>Documentation for installing and using spack-stack can be found here:

    <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a></p>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>

    <p><a href="https://www.github.com/AlexanderRichert-NOAA">Alex Richert</a>, <a
    href="https://www.github.com/Hang-Lei-NOAA">Hang

    Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed

    Hartnett</a> NOAA-EMC</p>

    </li>

    <li>

    <p><a href="https://www.github.com/climbfuji">Dom Heinzeller</a>, JCSDA</p>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 13
  subscribers_count: 6
  topics: []
  updated_at: 1675192557.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Configuration files for Spack at Pawsey
  filenames:
  - systems/setonix/environments/env_s3_clients/spack.yaml
  - systems/setonix/environments/env_devel/spack.yaml
  - systems/setonix/environments/env_wrf/spack.yaml
  - systems/setonix/environments/env_num_libs/spack.yaml
  - systems/setonix/environments/env_io_libs/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-pawsey-spack-configuration" class="anchor" aria-hidden="true"
    href="#pawsey-spack-configuration"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pawsey
    Spack Configuration</h1>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_DAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <h3><a id="user-content-singularity" class="anchor" aria-hidden="true" href="#singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h3>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <h3><a id="user-content-software-stack-modulefile" class="anchor" aria-hidden="true"
    href="#software-stack-modulefile"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    stack modulefile</h3>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <h2><a id="user-content-repository-structure" class="anchor" aria-hidden="true"
    href="#repository-structure"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    structure</h2>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <h2><a id="user-content-the-scripts-directory" class="anchor" aria-hidden="true"
    href="#the-scripts-directory"><span aria-hidden="true" class="octicon octicon-link"></span></a>The
    <code>scripts</code> directory</h2>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <h2><a id="user-content-the-systemssystem-directory" class="anchor" aria-hidden="true"
    href="#the-systemssystem-directory"><span aria-hidden="true" class="octicon octicon-link"></span></a>The
    <code>systems/&lt;system&gt;</code> directory</h2>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <h2><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h2>

    <h3><a id="user-content-module-categories-in-use" class="anchor" aria-hidden="true"
    href="#module-categories-in-use"><span aria-hidden="true" class="octicon octicon-link"></span></a>Module
    categories in use</h3>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <h3><a id="user-content-testing-modules" class="anchor" aria-hidden="true" href="#testing-modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Testing Modules</h3>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1641801068.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.18.1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#rhel7-spack-config\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#useful-commands\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack\
    \ module lmod refresh\n</code></pre>\n<h2><a id=\"user-content-installing-new-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-new-packages\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new\
    \ packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack\
    \ package updates could result in additional installation of packages with little\
    \ or no package source code changes.  These additional installs can be avoided\
    \ when installing new packages by first examining the output of the <code>spack\
    \ spec -I</code> command.  If a utility/infrastructure level package, such as\
    \ cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column\
    \ then it means that the existing install will be used.  If spack does not default\
    \ to using the existing install you can append the hash of the package to the\
    \ spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi\
    \ install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\n\
    Input spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\n\
    Concretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo\
    \ ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]     \
    \ ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64\
    \ \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64\
    \ \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]  \
    \        ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]  \
    \            ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643231013.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/runner/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu22.04-aarch64/spack.yaml
  - docker-recipes/runner/_archived/ubuntu18.04-x86_64/spack.yaml
  - docker-recipes/runner/_archived/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64-oneapi/spack.yaml
  - docker-recipes/runner/ubuntu20.04-aarch64/spack.yaml
  - docker-recipes/runner/rhel8-x86_64/spack.yaml
  - docker-recipes/runner/rhel8-aarch64/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 20
  subscribers_count: 6
  topics: []
  updated_at: 1673374590.0
actions-marketplace-validations/haampie-spack_setup-spack:
  data_format: 2
  description: null
  filenames:
  - example-environment/spack.yaml
  full_name: actions-marketplace-validations/haampie-spack_setup-spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1669840356.0
antoine-morvan/spack-offline-env:
  data_format: 2
  description: null
  filenames:
  - compilers_env/spack.yaml
  - simple_env/spack.yaml
  - matrixtest_env/spack.yaml
  - complete_env/spack.yaml
  full_name: antoine-morvan/spack-offline-env
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1644310043.0
bfovet/config:
  data_format: 2
  description: My personal configuration files
  filenames:
  - spack-env/linux-ubuntu22.04-skylake/spack.yaml
  full_name: bfovet/config
  latest_release: null
  readme: '<h1><a id="user-content-config" class="anchor" aria-hidden="true" href="#config"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>config</h1>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1658465316.0
bsurc/spack-configs:
  data_format: 2
  description: spack configuration settings used at BSU research computing
  filenames:
  - BOISESTATE/falcon/environments/applications/gromacs-cp2k/_spack.yaml
  - BOISESTATE/falcon/environments/applications/vacuumms/_spack.yaml
  full_name: bsurc/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1660257692.0
buildtesters/buildtest-nersc:
  data_format: 2
  description: null
  filenames:
  - buildspecs/apps/e4s/22.05/spack.yaml
  - buildspecs/apps/e4s/22.02/spack.yaml
  full_name: buildtesters/buildtest-nersc
  latest_release: null
  readme: '<h1><a id="user-content-buildtest-nersc" class="anchor" aria-hidden="true"
    href="#buildtest-nersc"><span aria-hidden="true" class="octicon octicon-link"></span></a>buildtest-nersc</h1>

    <p>This repository contains tests for Cori and Perlmutter using the <a href="https://buildtest.readthedocs.io/en/devel/"
    rel="nofollow">buildtest</a> framework.</p>

    <h2><a id="user-content-useful-links" class="anchor" aria-hidden="true" href="#useful-links"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful Links</h2>

    <ul>

    <li>CDASH: <a href="https://my.cdash.org/index.php?project=buildtest-nersc" rel="nofollow">https://my.cdash.org/index.php?project=buildtest-nersc</a>

    </li>

    <li>Upstream Repo: <a href="https://software.nersc.gov/NERSC/buildtest-nersc"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc</a>

    </li>

    <li>Github Mirror Repo: <a href="https://github.com/buildtesters/buildtest-nersc">https://github.com/buildtesters/buildtest-nersc</a>

    </li>

    </ul>

    <h2><a id="user-content-buildtest-references" class="anchor" aria-hidden="true"
    href="#buildtest-references"><span aria-hidden="true" class="octicon octicon-link"></span></a>Buildtest
    References</h2>

    <ul>

    <li>Documentation: <a href="https://buildtest.readthedocs.io/en/devel/" rel="nofollow">https://buildtest.readthedocs.io/en/devel/</a>

    </li>

    <li>Schema Docs: <a href="https://buildtesters.github.io/buildtest/" rel="nofollow">https://buildtesters.github.io/buildtest/</a>

    </li>

    <li>Slack Channel: <a href="https://hpcbuildtest.slack.com" rel="nofollow">https://hpcbuildtest.slack.com</a>

    </li>

    <li>Getting Started: <a href="https://buildtest.readthedocs.io/en/devel/getting_started.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/getting_started.html</a>

    </li>

    <li>Writing Buildspecs: <a href="https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html</a>

    </li>

    <li>Contributing Guide: <a href="https://buildtest.readthedocs.io/en/devel/contributing.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/contributing.html</a>

    </li>

    </ul>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <p>To get started, please <a href="https://docs.nersc.gov/connect/" rel="nofollow">connect
    to NERSC system</a> and clone this repo and buildtest:</p>

    <pre><code>git clone https://github.com/buildtesters/buildtest

    git clone https://software.nersc.gov/NERSC/buildtest-nersc

    </code></pre>

    <p>Note if you don''t have access to Gitlab server you may clone the mirror on
    Github:</p>

    <pre><code>git clone https://github.com/buildtesters/buildtest-nersc

    </code></pre>

    <p>You will need python 3.7 or higher to <a href="https://buildtest.readthedocs.io/en/devel/installing_buildtest.html"
    rel="nofollow">install buildtest</a>, on Cori/Perlmutter this can be done by loading
    <strong>python</strong>

    module and create a conda environment as shown below.</p>

    <pre><code>module load python

    conda create -n buildtest

    conda activate buildtest

    </code></pre>

    <p>Now let''s install buildtest, assuming you have cloned buildtest in $HOME directory
    source the setup script. For csh users you need to source <strong>setup.csh</strong></p>

    <pre><code>source ~/buildtest/setup.sh


    # csh users

    source ~/buildtest/setup.csh

    </code></pre>

    <p>Next, navigate to <code>buildtest-nersc</code> directory and set environment
    <code>BUILDTEST_CONFIGFILE</code> to point to <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/config.yml"
    rel="nofollow">config.yml</a> which is the configuration file for NERSC system.</p>

    <pre><code>cd buildtest-nersc

    export BUILDTEST_CONFIGFILE=$(pwd)/config.yml

    </code></pre>

    <p>Make sure the configuration is valid, this can be done by running the following.
    buildtest will validate the configuration file with the JSON schema :</p>

    <pre><code>buildtest config validate

    </code></pre>

    <p>Please make sure you are using tip of <a href="https://github.com/buildtesters/buildtest/tree/devel">devel</a>
    branch of buildtest when writing tests. You should sync your local devel branch
    with upstream

    fork, for more details see <a href="https://buildtest.readthedocs.io/en/devel/contributing/code_contribution_guide.html"
    rel="nofollow">contributing guide</a>.</p>

    <p>First time around you should discover all buildspecs this can be done via <code>buildtest
    buildspec find</code>.  The command below will find

    and validate all buildspecs in the <strong>buildtest-nersc</strong> repo and load
    them in buildspec cache. Note that one needs to specify <code>--root</code> to
    specify location where

    all buildspecs are located, we have not configured <a href="https://buildtest.readthedocs.io/en/devel/configuring_buildtest/overview.html#buildspec-roots"
    rel="nofollow">buildspec_root</a> in the configuration file since we don''t have
    a central location where this repo will reside.</p>

    <pre><code>cd buildtest-nersc

    buildtest buildspec find --root buildspecs --rebuild -q

    </code></pre>

    <p>The buildspecs are loaded in buildspec cache file (JSON) that is used by <code>buildtest
    buildspec find</code> for querying cache. Subsequent runs will

    read from cache.  For more details see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/buildspecs_interface.html"
    rel="nofollow">buildspec interface</a>.</p>

    <h2><a id="user-content-building-tests" class="anchor" aria-hidden="true" href="#building-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building Tests</h2>

    <p><strong>Note: All tests are written in YAML using .yml extension</strong></p>

    <p>To build tests use <code>buildtest build</code> command for example we build
    all tests in <code>system</code> directory as follows</p>

    <pre><code>buildtest build -b system/

    </code></pre>

    <p>You can specify multiple buildspecs either files or directory via <code>-b</code>
    option</p>

    <pre><code>buildtest build -b slurm/partition.yml -b slurmutils/

    </code></pre>

    <p>You can exclude a buildspec via <code>-x</code> option this behaves same way
    as <code>-b</code> option so you can specify

    a directory or filepath which could be absolute path, or relative path. This is
    useful when

    you want to run multiple tests grouped in directory but exclude a few.</p>

    <pre><code>buildtest build -b slurm -x slurm/sinfo.yml

    </code></pre>

    <p>buildtest can run tests via tags which can be useful when grouping tests, to
    see a list of available tags you

    can run: <code>buildtest buildspec find --tags</code></p>

    <p>For instance if you want to run all <code>lustre</code> tests you can run the
    following:</p>

    <pre><code>buildtest build --tags lustre

    </code></pre>

    <p>For more details on buildtest test please see the <a href="https://buildtest.readthedocs.io/en/devel/getting_started.html"
    rel="nofollow">buildtest tutorial</a></p>

    <h2><a id="user-content-tags-breakdown" class="anchor" aria-hidden="true" href="#tags-breakdown"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Tags Breakdown</h2>

    <p>When you write buildspecs, please make sure you attach one or more <code>tags</code>
    to the test that way your test will get picked up during one of the CI checks.
    Shown

    below is a summary of tag description</p>

    <ul>

    <li>

    <strong>daily</strong> - this tag is used for running daily system checks using
    gitlab CI. Tests should run relatively quick</li>

    <li>

    <strong>system</strong> - this tag is used for classifying all system tests that
    may include: system configuration, servers, network, cray tests. This tag should
    be used</li>

    <li>

    <strong>slurm</strong> - this tag is used for slurm test that includes slurm utility
    check, slurm controller, etc... This tag <strong>shouldn''t</strong> be used for
    job submission that is managed by <strong>jobs</strong> tag. The <code>slurm</code>
    tag tests should be short running test that use a Local Executor.</li>

    <li>

    <strong>jobs</strong> - this tag is used for testing slurm policies by submitting
    jobs to scheduler.</li>

    <li>

    <strong>compile</strong> - this tag is used for compilation of application (OpenMP,
    MPI, OpenACC, CUDA, upc, bupc, etc...)</li>

    <li>

    <strong>e4s</strong> - this tag is used for running tests for E4S stack via <code>spack
    test</code> or <a href="https://github.com/E4S-Project/testsuite">E4S Testsuite</a>.</li>

    <li>

    <strong>module</strong> - this tag is used for testing module system</li>

    <li>

    <strong>benchmark</strong> - this tag is used for benchmark tests. This can be
    application benchmarks, mini-benchmarks, kernels, etc...</li>

    </ul>

    <p>You can see breakdown of tags and buildspec summary with the following commands</p>

    <pre><code>buildtest buildspec summary

    buildtest buildspec find --group-by-tags

    </code></pre>

    <h2><a id="user-content-querying-tests" class="anchor" aria-hidden="true" href="#querying-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Querying Tests</h2>

    <p>You can use <code>buildtest report</code> and <code>buildtest inspect</code>
    to query tests. The commands differ slightly and data is

    represented differently. The <code>buildtest report</code> command will show output
    in tabular form and only show some of the metadata,

    if you want to access the entire test record use <code>buildtest inspect</code>
    command which displays the content in JSON format.

    For more details on querying tests see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a></p>

    <h2><a id="user-content-ci-setup" class="anchor" aria-hidden="true" href="#ci-setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CI Setup</h2>

    <p>Tests are run on schedule basis with one schedule corresponding to one gitlab
    job in <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/.gitlab-ci.yml"
    rel="nofollow">.gitlab-ci.yml</a>. The scheduled pipelines are configured in

    <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules</a>.
    Each schedule has a variable <code>TESTNAME</code> defined to control which pipeline

    is run since we have multiple gitlab jobs. In the <code>.gitlab-ci.yml</code>
    we make use of conditional rules using <a href="https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic"
    rel="nofollow">only</a>.</p>

    <p>The scheduled jobs are run at different intervals (1x/day, 1x/week, etc...)
    at different times of day to avoid overloading the system. The gitlab jobs

    will run jobs based on tags, alternately some tests may be defined by running
    all tests in a directory (<code>buildtest build -b apps</code>). If you want to
    add a new

    scheduled job, please define a <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules/new"
    rel="nofollow">new schedule</a> with an appropriate time. The

    <code>target branch</code> should be <code>devel</code> and define a unique variable
    used to distinguish scheduled jobs. Next, create a job in <code>.gitlab-ci.yml</code>
    that references the scheduled job and define variable <code>TESTNAME</code> in
    the scheduled pipeline.</p>

    <h2><a id="user-content-integrations" class="anchor" aria-hidden="true" href="#integrations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Integrations</h2>

    <p>This project has integration with Slack to notify CI builds to <a href="https://hpcbuildtest.slack.com"
    rel="nofollow">buildtest Slack</a> at <strong>#buildtest-nersc</strong> workspace.
    The integrations can be

    found at <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations</a>.</p>

    <p>This project has setup a push mirror to <a href="https://github.com/buildtesters/buildtest-nersc">https://github.com/buildtesters/buildtest-nersc</a>
    which can be seen at <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository</a>

    under <strong>Mirroring Repositories</strong>. If the push mirror is not setup,
    please add the mirror.</p>

    <h2><a id="user-content-cdash" class="anchor" aria-hidden="true" href="#cdash"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CDASH</h2>

    <p>buildtest will push test results to <a href="https://www.cdash.org/" rel="nofollow">CDASH</a>
    server

    at <a href="https://my.cdash.org/index.php?project=buildtest-nersc" rel="nofollow">https://my.cdash.org/index.php?project=buildtest-nersc</a>
    using <code>buildtest cdash upload</code> command.</p>

    <h2><a id="user-content-contributing-guide" class="anchor" aria-hidden="true"
    href="#contributing-guide"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing
    Guide</h2>

    <p>To contribute back you will want to make sure your buildspec is validated before
    you contribute back, this could be

    done by running test manually <code>buildtest build</code> or see if buildspec
    is valid via <code>buildtest buildspec find</code>. It

    would be good to run your test and make sure it is working as expected, you can
    view test detail using <code>buildtest inspect name &lt;testname&gt;</code> or
    <code>buildtest inspect query &lt;testname&gt;</code>. For more

    details on querying test please see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a>.</p>

    <p>If you want to contribute your tests, please see <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/CONTRIBUTING.md"
    rel="nofollow">CONTRIBUTING.md</a></p>

    <h2><a id="user-content-submitting-an-issue" class="anchor" aria-hidden="true"
    href="#submitting-an-issue"><span aria-hidden="true" class="octicon octicon-link"></span></a>Submitting
    an Issue</h2>

    <p>Please submit all issues to <a href="https://github.com/buildtesters/buildtest-nersc/issues">https://github.com/buildtesters/buildtest-nersc/issues</a>.
    When creating an issue, please see the <a href="https://github.com/buildtesters/buildtest-nersc/labels">labels</a>

    and try to select one or more labels to categorize issue. Please use the following
    labels depending on the type of issue you are reporting</p>

    <ul>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/bug">Bug</a>:
    When creating an issue related to a test bug</li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/new-test">new-test</a>:
    An issue for adding a new test</li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/E4S-Testsuite">E4S-Testsuite</a>:
    Issues related to <a href="https://github.com/E4S-Project/testsuite">E4S testsuite
    project</a>

    </li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/spack">spack</a>:
    Issues related to <code>spack test</code>

    </li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/documentation">documentation</a>:
    Issues with documentation such as README.md, CONTRIBUTING.md</li>

    <li>

    <a href="https://github.com/buildtesters/buildtest-nersc/labels/gitlab-ci">gitlab-ci</a>:
    Issues with Gitlab CI/CD</li>

    </ul>

    '
  stargazers_count: 6
  subscribers_count: 4
  topics:
  - buildtest
  updated_at: 1671402594.0
charmoniumQ/wf-reg-test:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: charmoniumQ/wf-reg-test
  latest_release: null
  readme: "<h1><a id=\"user-content-wf-reg-test\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#wf-reg-test\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>wf-reg-test</h1>\n<p>Software tends to break or \"collapse\" over\
    \ time, even if it is unchanged, due to non-obvious changes in the computational\
    \ environment.\nCollapse in computational experiments undermines long-term credibility\
    \ and hinders day-to-day operations.\nWe propose to create the first public dataset\
    \ of automatically executable scientific experiments.\nThis data could be used\
    \ to identify best practices, make continuous testing feasible, and repair broken\
    \ programs.\nThese techniques increase the replicability of computational experiments.</p>\n\
    <p>Conceptually, we intend to collect the following:</p>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">registry</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >registries</span>:\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\"\
    >experiment</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">registry</span>:\n\
    \        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">version</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">experiment</span>:\n \
    \           <span class=\"pl-k\">for</span> <span class=\"pl-s1\">i</span> <span\
    \ class=\"pl-c1\">in</span> <span class=\"pl-en\">range</span>(<span class=\"\
    pl-s1\">num_repetitions</span>):\n                <span class=\"pl-s1\">execution</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-en\">execute</span>(<span class=\"\
    pl-s1\">version</span>)\n                <span class=\"pl-s1\">data</span>.<span\
    \ class=\"pl-en\">append</span>((\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">date</span>,   <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">output</span>,\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">logs</span>,   <span class=\"pl-s1\">execuiton</span>.<span\
    \ class=\"pl-s1\">res_usage</span>,\n                    <span class=\"pl-s1\"\
    >version</span>.<span class=\"pl-s1\">date</span>,     <span class=\"pl-s1\">version</span>.<span\
    \ class=\"pl-s1\">code</span>,\n                    <span class=\"pl-s1\">experiment</span>.<span\
    \ class=\"pl-s1\">name</span>,  <span class=\"pl-s1\">registry</span>.<span class=\"\
    pl-s1\">name</span>,\n                ))</pre></div>\n<h1><a id=\"user-content-todo-list\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#todo-list\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>TODO list</h1>\n<ul>\n<li>\n\
    <p>Registries of computational experiments</p>\n<ul>\n<li>[x] <a href=\"https://nf-co.re/\"\
    \ rel=\"nofollow\">nf-core</a>: Nextflow</li>\n<li>[x] <a href=\"https://snakemake.github.io/snakemake-workflow-catalog/\"\
    \ rel=\"nofollow\">Snakemake Catalog</a>: Snakemake</li>\n<li>[ ] SAW ECMF: SAW\
    \ NGW</li>\n<li>[ ] <a href=\"https://workflowhub.eu/\" rel=\"nofollow\">WorkflowHub</a>:\
    \ Galaxy, CWL, Nextflow, Snakemake, KNIME</li>\n<li>[ ] <a href=\"https://dockstore.org/\"\
    \ rel=\"nofollow\">Dockstore</a>: WDL, CWL, Nextflow, Galaxy</li>\n<li>[ ] <a\
    \ href=\"https://pegasushub.io\" rel=\"nofollow\">PegasusHub</a>: Pegasus</li>\n\
    <li>[ ] <a href=\"https://github.com/wfcommons\">WfCommons</a>: Pegasus, Makeflow,\
    \ Nextlfow</li>\n<li>[ ] <a href=\"https://www.myexperiment.org/\" rel=\"nofollow\"\
    >myExperiment</a>: Taverna, RapidMiner, Kepler, Bioclipse, LONI, GWorkflowDL,\
    \ BioExtract</li>\n<li>[ ] GitHub?</li>\n</ul>\n</li>\n<li>\n<p>Computational\
    \ experiment runtimes</p>\n<ul>\n<li>[x] <a href=\"https://nextflow.io\" rel=\"\
    nofollow\">Nextflow</a>\n</li>\n<li>[x] <a href=\"https://snakemake.github.io/\"\
    \ rel=\"nofollow\">Snakemake</a>\n</li>\n<li>[ ] SAW NGW (proprietary)</li>\n\
    <li>[ ] Galaxy</li>\n<li>[ ] WDL</li>\n<li>[ ] Common Workflow Language (CWL)</li>\n\
    <li>[ ] Pegasus</li>\n<li>[ ] Makefile</li>\n</ul>\n</li>\n<li>\n<p>Tests</p>\n\
    <ul>\n<li>[x] Repeatable crash-freedom?</li>\n<li>[ ] If crashes, repeatable error-message?</li>\n\
    <li>[ ] If not crashes, repeatable bitwise-equivalent with holding zero, one,\
    \ two, three, or four of {/dev/{,u}random, datetime, ASL, single-core}?</li>\n\
    <li>[ ] Repeatable 5--95%-ile interval?</li>\n</ul>\n</li>\n<li>\n<p>Code analysis</p>\n\
    <ul>\n<li>[ ] SLoC by type</li>\n<li>[ ] Code-to-comment by type</li>\n<li>[ ]\
    \ Cyclomatic</li>\n<li>[ ] Function length distribution</li>\n<li>[ ] Dependency\
    \ graph?\n<ul>\n<li>Imports per file</li>\n<li>Total transitive dependencies</li>\n\
    </ul>\n</li>\n<li>[ ] Component graph?</li>\n<li>[ ] Similarity of experiments?</li>\n\
    <li>[ ] Detect presence of best practices?\n<ul>\n<li>Tools for reproducibility</li>\n\
    <li>Dependency count, transitive dependency count</li>\n<li>SLoC count by language,\
    \ transitive SLoC count by language</li>\n<li>Documentation to code ratio</li>\n\
    </ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Data analysis assumptions:</p>\n<ul>\n<li>Assumption:\
    \ Time symmetry</li>\n<li>Assumption: Group and problem identity is constant and\
    \ one-dimensional</li>\n<li>Assumption: Versions are indistinguishable\n<ul>\n\
    <li>Except possibly last version?</li>\n</ul>\n</li>\n<li>Caveat: predictor !=\
    \ intervention</li>\n<li>Caveat: predictor only works with unawareness of its\
    \ use as a predictor\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\"\
    \ rel=\"nofollow\">https://en.wikipedia.org/wiki/Goodhart%27s_law</a></li>\n<li><a\
    \ href=\"https://en.wikipedia.org/wiki/Lucas_critique\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Lucas_critique</a></li>\n\
    </ul>\n</li>\n<li>Analysis question: Do input variables predict rate of decay\
    \ or do input variables + staleness predict failure?</li>\n<li>Analysis question:\
    \ between levels of reproducibility\n<ul>\n<li>Set of factors are necessary and\
    \ sufficient for reproducibility</li>\n<li>Successful termination</li>\n<li>{Faketime,\
    \ fake random, ASLR}</li>\n<li>Multi-threaded</li>\n</ul>\n</li>\n<li>Analysis\
    \ question: Model infant mortality or constant rate of failure?</li>\n</ul>\n\
    </li>\n<li>\n<p>Data analysis:</p>\n<ul>\n<li>[ ] Measure rate of collapse over\
    \ time?\n<ul>\n<li>Coefficient of staleness on successful termination</li>\n</ul>\n\
    </li>\n<li>[ ] Predictive accuracy of collapse over time based on staleness, code\
    \ anaylsis, and optionally history?\n<ul>\n<li>How to use information from other\
    \ simultaneously failing workflows?</li>\n</ul>\n</li>\n<li>[ ] How effective\
    \ is each non-determinism mitigation?\n<ul>\n<li>\n<code>R</code> / <code>total</code>\n\
    </li>\n<li>\n<code>R_easy</code> / <code>total</code>\n</li>\n<li>\n<code>R_multi</code>\
    \ / <code>total</code>\n</li>\n<li>\n<code>R_all</code> / <code>total</code>\n\
    </li>\n</ul>\n</li>\n<li>[ ] Improve efficiency of continuous testing in simulation?\n\
    <ul>\n<li>Generate time-to-collapse</li>\n<li>How to use information from other\
    \ simultaneously failing workflows?</li>\n</ul>\n</li>\n<li>[ ] Code best practices\n\
    <ul>\n<li>Influence of code metrics on decay rate, <code>R_easy</code>, (<code>R_all</code>\
    \ given not <code>R_easy</code>)</li>\n<li>Interaction between code metrics on\
    \ rate of decay?</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Other questions:</p>\n\
    <ul>\n<li>[ ] Cluster error messages?</li>\n<li>[ ] Replicate Zhao's categories?</li>\n\
    <li>[ ] Design automatic fixes?</li>\n<li>[ ] Outcome preserving input minimization?\n\
    <ul>\n<li><a href=\"https://seg.inf.unibe.ch/papers/ase22.pdf\" rel=\"nofollow\"\
    >https://seg.inf.unibe.ch/papers/ase22.pdf</a></li>\n</ul>\n</li>\n<li>[ ] How\
    \ many failures occur in a unit-testable component?</li>\n<li>[ ] Compositional\
    \ testing?</li>\n</ul>\n</li>\n</ul>\n<p>See <a href=\"CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a>\
    \ for instructions on setting up a development environment.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1673287421.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<h1><a id=\"user-content-d-seams\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#d-seams\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>d-SEAMS</h1>\n<p><strong>Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations</strong></p>\n<p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82b492dd4f94cd6fe1783f1065487d3dbc0602c2a65b1717a5613df3b6e8f65f/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <h1><a id=\"user-content-citation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #citation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citation</h1>\n\
    <ul>\n<li>\n<p>This has been published at the <a href=\"https://doi.org/10.1021/acs.jcim.0c00031\"\
    \ rel=\"nofollow\">Journal of Chemical Information and Modeling\n(JCIM)</a></p>\n\
    </li>\n<li>\n<p>You may also read <a href=\"https://arxiv.org/abs/1909.09830\"\
    \ rel=\"nofollow\">the preprint on arXiv</a></p>\n</li>\n</ul>\n<p>If you use\
    \ this software please cite the following:</p>\n<pre><code>Goswami, R., Goswami,\
    \ A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations. Journal of Chemical Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n\
    </code></pre>\n<p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<h1><a id=\"\
    user-content-compilation\" class=\"anchor\" aria-hidden=\"true\" href=\"#compilation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compilation</h1>\n\
    <p>We use a deterministic build system to generate both bug reports and uniform\n\
    usage statistics. This also handles the <code>lua</code> scripting engine.</p>\n\
    <p>\\note The lua functions are documented on the <a href=\"https://docs.dseams.info/md_markdown_luafunctions\"\
    \ rel=\"nofollow\">on the API Docs</a></p>\n<p>We also provide a <code>conda</code>\
    \ environment as a fallback, which is also recommended for MacOS users.</p>\n\
    <h2><a id=\"user-content-build\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build</h2>\n\
    <h3><a id=\"user-content-conda\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #conda\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conda</h3>\n\
    <p>Although we strongly suggest using <code>nix</code>, for MacOS systems, the\
    \ following\ninstructions may be more suitable. We will assume the presence of\
    \ <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\" rel=\"\
    nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>micromamba create -f environment.yml\nmicromamba activate dseams</pre></div>\n\
    <p>Now the installation can proceed.</p>\n<p>\\note we do not install a new version\
    \ of <code>cmake</code> within the <code>conda</code> environment because of conflicts\
    \ with <code>lua</code></p>\n<div class=\"highlight highlight-source-shell\"><pre>mkdir\
    \ build\n<span class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span class=\"\
    pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span class=\"\
    pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake install</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<h3><a\
    \ id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>Manually this can be done in a painful way as follows:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack install eigen@3.3.9 lua@5.2\nspack install\
    \ catch2 fmt yaml-cpp openblas boost cmake ninja meson\nspack load catch2 fmt\
    \ yaml-cpp openblas boost cmake ninja meson eigen@3.3.9 lua@5.2\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span\
    \ class=\"pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> After loading the packages</span>\nluarocks install luafilesystem</pre></div>\n\
    <p>Now we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<h3><a id=\"user-content-nix\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#nix\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Nix</h3>\n<p>Since this project is\
    \ built with <code>nix</code>, we can simply do the following from the\nroot directory\
    \ (longer method):</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Make sure there are no artifacts</span>\n\
    rm -rf build\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> This will take\
    \ a long time the first time as it builds the dependencies</span>\nnix-build <span\
    \ class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Optional</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Install\
    \ into your path</span>\nnix-env -if <span class=\"pl-c1\">.</span> <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>A faster method of building the software is by using the <a href=\"https://dseams.cachix.org/\"\
    \ rel=\"nofollow\">cachix binary cache</a> as shown:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install cachix</span>\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Use the binary cache</span>\n\
    cachix use dseams\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with\
    \ the cache than building from scratch</span>\nnix-build <span class=\"pl-c1\"\
    >.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <h3><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h3>\n\
    <p>Having installed the <code>yodaStruct</code> binary and library, we can now\
    \ use it.</p>\n<div class=\"highlight highlight-source-shell\"><pre>yodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>\\note The paths in the <code>.yml</code>\
    \ should be <strong>relative to the folder from which the binary is called</strong>.</p>\n\
    <p>If you're confused about how to handle the relative paths, run the command\
    \ <code>yodaStruct -c lua_inputs/config.yml</code> in the top-level directory,\
    \ and set the paths relative to the top-level directory. This is the convention\
    \ used in the examples as well.</p>\n<h3><a id=\"user-content-language-server-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#language-server-support\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Language Server\
    \ Support</h3>\n<p>To generate a <code>compile_commands.json</code> file for working\
    \ with a language server\nlike <a href=\"https://github.com/MaskRay/ccls\">ccls</a>\
    \ use the following commands:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\n\
    nix-shell --pure\nmkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span\
    \ class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES\
    \ ../\ncp compile_commands.json ../</pre></div>\n<p>Note that there is no need\
    \ to actually compile the project if you simply need to\nget the compiler database\
    \ for the language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<h2><a id=\"user-content-development\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development</h2>\n<p>We can simply use the <code>nix</code> environment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> From the project root</span>\nnix-shell --pure</pre></div>\n\
    <h1><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n\
    <p>This is built completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install\
    \ systemwide\nnix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply\
    \ install the software, and ensure that <code>input/</code> is a child directory.</p>\n\
    <pre lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<h2><a id=\"user-content-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#tests\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Tests</h2>\n<p>Apart from the <a href=\"\
    https://docs.dseams.info/pages.html\" rel=\"nofollow\">examples</a>, the test-suite\n\
    can be run with the <code>yodaStruct_test</code> binary, which will drop into\
    \ the\n<code>nix</code> environment before building and executing <code>gdb</code>:</p>\n\
    <pre lang=\"{bash}\"><code># Just run this\n./testBuild.sh\n# quit gdb with quit\n\
    # Go run the test binary\ncd shellBuild\n./yodaStruct_test\n</code></pre>\n<p>Do\
    \ note that the regular installation via <code>nix-env</code> runs the tests before\
    \ the installation</p>\n<h1><a id=\"user-content-developer-documentation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#developer-documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Developer Documentation</h1>\n\
    \n<p>While developing, it is sometimes expedient to update the packages used.\
    \ It is\nthen useful to note that we use <a href=\"https://github.com/nmattia/niv/\"\
    >niv</a> to handle our pinned packages (apart from\nthe ones built from Github).\
    \ Thus, one might need, say:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>niv update nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with\
    \ nix:</p>\n<div class=\"highlight highlight-source-shell\"><pre>nix-build <span\
    \ class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Outputs are in ./result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ If you get a CMake error</span>\nrm -rf build\nnix-store --delete /nix/store/<span\
    \ class=\"pl-smi\">$whatever</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> $whatever is the derivation complaining</span>\nnix-collect-garbage\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> then try again [worst case\
    \ scenario]</span></pre></div>\n<h2><a id=\"user-content-leaks-and-performance\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#leaks-and-performance\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Leaks and performance</h2>\n\
    <p>While testing for leaks, use <code>clang</code> (for\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\"\
    >AddressSanitizer</a>\nand\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<h1><a id=\"user-content-overview\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Overview</h1>\n<p>As of Mon Jan\
    \ 20 15:57:18 2020, the lines of code calculated by\n<a href=\"http://cloc.sourceforge.net/\"\
    \ rel=\"nofollow\">cloc</a> are as follows:</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"><img src=\"images/cloc-2020-01-20_15-56.png\"\
    \ alt=\"Cloc Lines\" style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n<p>Please\
    \ ensure that all contributions are formatted according to the\n<a href=\"./clang-format\"\
    >clang-format</a> configuration file.</p>\n<p>Specifically, consider using the\
    \ following:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\"\
    >Sublime Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"\
    https://github.com/lassik/emacs-format-all-the-code\">format-all</a> for Emacs</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\">vim-clang-format</a>\
    \ for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <h2><a id=\"user-content-commit-hook\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #commit-hook\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Commit\
    \ Hook</h2>\n<p>Note that we expect compliance with the <code>clang-format</code>\
    \ as mentioned above, and this may be enforced by using the provided scripts for\
    \ a pre-commit hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<h1><a id=\"user-content-acknowledgements\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#acknowledgements\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h1>\n<p>The\
    \ following tools are used in this project:</p>\n<ul>\n<li>\n<a href=\"https://cmake.org/\"\
    \ rel=\"nofollow\">CMake</a> for compilation (<a href=\"https://github.com/cginternals/cmake-init\"\
    >cmake-init</a> was used as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\"\
    \ rel=\"nofollow\">Clang</a> because it is more descriptive with better tools</li>\n\
    <li>\n<a href=\"https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the\
    \ developer API</li>\n<li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\"\
    \ rel=\"nofollow\">clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"\
    https://github.com/barisione/clang-format-hooks\">clang-format-hooks</a> for <code>git</code>\
    \ hooks to enforce formatting</li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\"\
    \ rel=\"nofollow\">lua</a> for the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\"\
    \ rel=\"nofollow\">yaml</a> for the configuration</li>\n</ul>\n<h2><a id=\"user-content-third-party-libraries\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#third-party-libraries\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Third Party Libraries</h2>\n\
    <p>The libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n</ul>\n"
  stargazers_count: 26
  subscribers_count: 5
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1665839076.0
eic/containers:
  data_format: 2
  description: Container building infrastructure
  filenames:
  - spack.yaml
  full_name: eic/containers
  latest_release: null
  readme: '<h1><a id="user-content-eic-software-environment-container" class="anchor"
    aria-hidden="true" href="#eic-software-environment-container"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>EIC software environment container</h1>

    <p>For installation instructions of <code>eic-shell</code>, see <a href="https://github.com/eic/eic-shell">https://github.com/eic/eic-shell</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1669259240.0
eic/eic-spack-environments:
  data_format: 2
  description: Spack environments for the Electron Ion Collider
  filenames:
  - athena/spack.yaml
  full_name: eic/eic-spack-environments
  latest_release: null
  readme: '<h1><a id="user-content-eic-spack-environments" class="anchor" aria-hidden="true"
    href="#eic-spack-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>EIC
    Spack Environments</h1>

    <p>This repository contains <a href="https://spack.readthedocs.io/en/latest/index.html"
    rel="nofollow">Spack</a> environments for the EIC.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1661880440.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - env-bipp-izar/spack.yaml
  - bipp-jed-gcc/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<h1><a id="user-content-ska-spack-env" class="anchor" aria-hidden="true"
    href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a>ska-spack-env</h1>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - oneapi/spack.yaml
  - oneapi/failures/spack.yaml
  - nvhpc/failures/spack.yaml
  - nvhpc/spack.yaml
  - clang/spack.yaml
  - gnu/spack.yaml
  - gnu/failures/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675202595.0
eugeneswalker/noaa-prototyping:
  data_format: 2
  description: null
  filenames:
  - nvhpc/spack.yaml
  - gnu/spack.yaml
  - oneapi/spack.yaml
  full_name: eugeneswalker/noaa-prototyping
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666800656.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-clang/spack.yaml
  - ubuntu-gcc/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1><a id="user-content-synergia2-containers" class="anchor" aria-hidden="true"
    href="#synergia2-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1674725167.0
haampie/spack-docker-bootstrap:
  data_format: 2
  description: Build optimized docker images for Spack
  filenames:
  - spack.yaml
  full_name: haampie/spack-docker-bootstrap
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-in-docker-with-buildcache\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#spack-in-docker-with-buildcache\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack in Docker with buildcache</h1>\n\
    <p>This bootstraps Spack's own, optimized dependencies, as well as the\ncompiler\
    \ toolchain of the distro, so that in the end we just depend\non system libc.</p>\n\
    <p>See <a href=\"spack.yaml\">spack.yaml</a> for things that are built by Spack,\
    \ and\n<a href=\"Makefile\">Makefile</a> and <a href=\"Dockerfile\">Dockerfile</a>\
    \ for how it's built.</p>\n<p>Docker buildkit is required.</p>\n<p>Build with:</p>\n\
    <pre><code>DOCKER_BUILDKIT=1 docker build -f linux-ubuntu22.04-x86_64_v2/Dockerfile\
    \ -t spack-optimized --progress=plain .\n</code></pre>\n<p>Since this uses Python\
    \ 3.11 and clingo with some optimizations, it should\ngenerally be faster:</p>\n\
    <pre><code>Benchmark 1: docker run --rm spack-optimized spack spec hdf5\n  Time\
    \ (mean \xB1 \u03C3):      8.494 s \xB1  0.401 s    [User: 0.015 s, System: 0.008\
    \ s]\n  Range (min \u2026 max):    8.034 s \u2026  8.763 s    3 runs\n\nBenchmark\
    \ 2: docker run --rm spack/ubuntu-focal spec hdf5\n  Time (mean \xB1 \u03C3):\
    \     10.795 s \xB1  0.382 s    [User: 0.013 s, System: 0.009 s]\n  Range (min\
    \ \u2026 max):   10.355 s \u2026 11.030 s    3 runs\n\nSummary\n  'docker run\
    \ --rm spack-optimized spack spec hdf5' ran\n    1.27 \xB1 0.07 times faster than\
    \ 'docker run --rm spack/ubuntu-focal spec hdf5'\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674134786.0
hariharan-devarajan/tailorfs:
  data_format: 2
  description: null
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/tailorfs
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1663026017.0
hpc/mpifileutils:
  data_format: 2
  description: File utilities designed for scalability and performance.
  filenames:
  - spack.yaml
  full_name: hpc/mpifileutils
  latest_release: v0.11.1
  readme: '<h1><a id="user-content-mpifileutils" class="anchor" aria-hidden="true"
    href="#mpifileutils"><span aria-hidden="true" class="octicon octicon-link"></span></a>mpiFileUtils</h1>

    <p>mpiFileUtils provides both a library called <a href="src/common/README.md">libmfu</a>
    and a suite of MPI-based tools to manage large datasets, which may vary from large
    directory trees to large files. High-performance computing users often generate
    large datasets with parallel applications that run with many processes (millions
    in some cases). However those users are then stuck with single-process tools like
    cp and rm to manage their datasets. This suite provides MPI-based tools to handle
    typical jobs like copy, remove, and compare for such datasets, providing speedups
    of up to 20-30x.  It also provides a library that simplifies the creation of new
    tools or can be used in applications.</p>

    <p>Documentation is available on <a href="http://mpifileutils.readthedocs.io"
    rel="nofollow">ReadTheDocs</a>.</p>

    <h2><a id="user-content-daos-support" class="anchor" aria-hidden="true" href="#daos-support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>DAOS Support</h2>

    <p>mpiFileUtils supports a DAOS backend for dcp, dsync, and dcmp. Custom serialization
    and deserialization for DAOS containers to and from a POSIX filesystem is provided
    with daos-serialize and daos-deserialize. Details and usage examples are provided
    in <a href="DAOS-Support.md">DAOS Support</a>.</p>

    <h2><a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributors</h2>

    <p>We welcome contributions to the project.  For details on how to help, see our
    <a href="CONTRIBUTING.md">Contributor Guide</a></p>

    <h3><a id="user-content-copyrights" class="anchor" aria-hidden="true" href="#copyrights"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Copyrights</h3>

    <p>Copyright (c) 2013-2015, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory

    CODE-673838</p>

    <p>Copyright (c) 2006-2007,2011-2015, Los Alamos National Security, LLC.

    (LA-CC-06-077, LA-CC-10-066, LA-CC-14-046)</p>

    <p>Copyright (2013-2015) UT-Battelle, LLC under Contract No.

    DE-AC05-00OR22725 with the Department of Energy.</p>

    <p>Copyright (c) 2015, DataDirect Networks, Inc.</p>

    <p>All rights reserved.</p>

    <h2><a id="user-content-build-status" class="anchor" aria-hidden="true" href="#build-status"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Status</h2>

    <p>The current status of the mpiFileUtils master branch is <a href="https://travis-ci.org/hpc/mpifileutils"
    rel="nofollow"><img src="https://camo.githubusercontent.com/76717f664d99534173ac7e9fb8e904b0e4bd14fbd51ac6969a88de2e6e86a94f/68747470733a2f2f7472617669732d63692e6f72672f6870632f6d706966696c657574696c732e706e673f6272616e63683d6d6173746572"
    alt="Build Status" data-canonical-src="https://travis-ci.org/hpc/mpifileutils.png?branch=master"
    style="max-width: 100%;"></a>.</p>

    '
  stargazers_count: 134
  subscribers_count: 25
  topics: []
  updated_at: 1674881096.0
hppritcha/spack_ompix:
  data_format: 2
  description: null
  filenames:
  - intel_master_x86_64/spack.yaml
  - gnu_release_x86_64/spack.yaml
  - intel_release_x86_64/spack.yaml
  - gnu_master_x86_64/spack.yaml
  full_name: hppritcha/spack_ompix
  latest_release: null
  readme: '<p>Project for using Gitlab CI to test spack builds of Open MPI master
    and release tarballs.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1640037910.0
iarspider/cms-spack-repo:
  data_format: 2
  description: null
  filenames:
  - environments/CMSSW_12_6_X/spack.yaml
  full_name: iarspider/cms-spack-repo
  latest_release: null
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1638894331.0
j-woz/SV-CP-2022-11-23:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: j-woz/SV-CP-2022-11-23
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669233200.0
jaykalinani/AsterX:
  data_format: 2
  description: 'AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes'
  filenames:
  - compile-notes/frontera/CPU/spack.yaml
  - compile-notes/frontera/GPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<h1><a id="user-content-asterx" class="anchor" aria-hidden="true" href="#asterx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>AsterX</h1>

    <p>AsterX: a new open-source GPU-accelerated GRMHD code for dynamical spacetimes</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674662724.0
jeffersonscientific/cees_spack_configs:
  data_format: 2
  description: CEES spack configurations (take 3). Focus on environments only (or
    mostly), and modular configs.
  filenames:
  - spack_env_files/paraview_spack.yaml
  - spack_env_files/pflotran_spack.yaml
  - spack_env_files/cees_seissol_spack.yaml
  - spack_env_files/cees_zen2-beta_spack.yaml
  - spack_env_files/cees_kimlab_spack.yaml
  - spack_env_files/pflotran_ompi_sif_spack.yaml
  - dev_configs/paraview_spack.yaml
  - dev_configs/cees-x86-oneapi_spack.yaml
  - spack_env_files/dev_py-bottleneck_spack.yaml
  - spack_env_files/dev_paraview_spack.yaml
  - dev_configs/py-bottleneck_spack.yaml
  - dev_configs/cees-x86-intel_spack.yaml
  - spack_env_files/dev_cees-x86-intel_spack.yaml
  - spack_env_files/cees-x86-oneapi_spack.yaml
  - spack_env_files/py-bottleneck_spack.yaml
  - dev_configs/pflotran_spack.yaml
  - spack_env_files/cees-x86-intel_spack.yaml
  - spack_env_files/cees_skylake-beta_spack.yaml
  - spack_env_files/cees_compilers_spack.yaml
  - spack_env_files/dev_cees-x86-oneapi_spack.yaml
  - spack_env_files/cees_x86_64-beta_spack.yaml
  - spack_env_files/pflotran_sif_spack.yaml
  - configs/spack_petsc_mod.yaml
  full_name: jeffersonscientific/cees_spack_configs
  latest_release: null
  readme: "<h1><a id=\"user-content-cees_spack_configs\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#cees_spack_configs\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>cees_spack_configs</h1>\n<p>CEES spack configurations\
    \ (take 3). Focus on environments only (or mostly), and modular configs.</p>\n\
    <p>This constitutes a continued effort to find a way to Git-Support and modularize\
    \ Spack setups. While knowledge is much improved, success\nis arguably limited\
    \ -- alas. The idea is to be able to easily maintain a list of SW that is then\
    \ compiled over a suite of compiler, mpi,\narchitecture types.</p>\n<p>A few points:</p>\n\
    <ul>\n<li>Using environments is key.</li>\n<li>Using an <code>include:</code>\
    \ section can help. For example,</li>\n</ul>\n<pre><code>  include:\n  - $spack/../configs/packages_petsc.yaml\n\
    \  - $spack/../configs/compilers_sherlock_O2.yaml\n</code></pre>\n<p>might be\
    \ useful to build <code>petsc</code> environments for multiple architectures or\
    \ compilers. Unfortunatly -- at least at this time, not all sections\ncan be satisfied\
    \ as <code>include</code> files.</p>\n<ul>\n<li>Compilers remain a challenge...</li>\n\
    <li>If <code>providers</code> are specified, optimal (and functional) choices\
    \ will likely vary for different compilers.</li>\n</ul>\n<p>CONVENTIONS:</p>\n\
    <ul>\n<li>Configuration components indicated with <code>_inc</code> in name, eg\
    \ <code>packages_inc.yaml</code>. These files should stand alone for non-environment\
    \ builds\n(not recommended...) or can be included in an <code>include:</code>\
    \ clause of an environment.</li>\n<li>Environment files may be tagged with <code>_mod</code>\
    \ in the name, to indicate a \"modular\" envorinment, that uses an <code>include:</code>\
    \ section.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641864561.0
jeffersonscientific/seissol_compile:
  data_format: 2
  description: Compile (and similar) script for SeisSol
  filenames:
  - ss_spack_env_template.yaml
  full_name: jeffersonscientific/seissol_compile
  latest_release: null
  readme: '<h1><a id="user-content-seissol_compile" class="anchor" aria-hidden="true"
    href="#seissol_compile"><span aria-hidden="true" class="octicon octicon-link"></span></a>seissol_compile</h1>

    <p>Compile (and similar) script for SeisSol</p>

    <h1></h1>

    <p>To date, these scripts can be used to install SeisSol on Stanford Research
    Computing''s Sherlock HPC. The <code>compile_seissol_spack.sh</code> script primarily
    uses a <code>spack</code> built environment, and so can be adapted to another
    HPC relatively easily.</p>

    <p>The <code>compile_seissol_sherlock.sh</code> script might be refrenced as a
    template -- the idea being to use pre-built SW modules to build SeisSol, but it
    ultimately crashes and burns prety spetacularly. One issue is that the various
    components may have differend dependencies. Namely, some packages are built from
    a <code>gcc/10.1.0</code> toolchain and another from <code>gcc/12.1.0</code>.</p>

    <p>Files:</p>

    <ul>

    <li>

    <code>build_spack_env.sh</code>: a generic batchable bash script to build a spack
    environment.</li>

    <li>

    <code>ss_env.yaml</code>: Should be the einvironment file we use to define the
    <code>seissol</code> spack environment. Note that the environment includes some
    external package definitions and Sherlock''s built in <code>gcc</code> compilers,
    including the primary <code>gcc@12.1.0</code>. These will need to be modified
    to deploy on a different HPC. Compilers can be built natively in Spack, then automagically
    discovered and added, but ultimately it will still likely be neessary to modify
    their definition in the environment file.</li>

    <li>

    <code>compile_seissol_spack.sh</code>: Working (on Sherlock HPC) compile script.
    will build all the non-Spack components</li>

    <li>

    <code>compile_seissol_cees_sherlock</code>: An older compile script that attempts
    to use Sherlock''s standard SW to compile. It ultimately crashes and burns, but
    might be referenced as a template.</li>

    <li>

    <code>install_ss_spack.sh</code>: An early template to build the Spack environment
    from scratch, including building, and <code>find</code>ing compilers in Spack.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666893798.0
jkbk2004/src:
  data_format: 2
  description: null
  filenames:
  - src/ufs-weather-model/WW3/model/ci/spack.yaml
  - src/UPP/ci/spack.yaml
  full_name: jkbk2004/src
  latest_release: null
  readme: "<h1><a id=\"user-content-ufs-short-range-weather-application\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#ufs-short-range-weather-application\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UFS Short-Range\
    \ Weather Application</h1>\n<p>The Unified Forecast System (UFS) is a community-based,\
    \ coupled, comprehensive Earth modeling system. It is designed to be the source\
    \ system for NOAA\u2019s operational numerical weather prediction applications\
    \ while enabling research, development, and contribution opportunities for the\
    \ broader weather enterprise. For more information about the UFS, visit the UFS\
    \ Portal at <a href=\"https://ufscommunity.org/\" rel=\"nofollow\">https://ufscommunity.org/</a>.</p>\n\
    <p>The UFS includes multiple applications (see a complete list at <a href=\"https://ufscommunity.org/science/aboutapps/\"\
    \ rel=\"nofollow\">https://ufscommunity.org/science/aboutapps/</a>) that support\
    \ different forecast durations and spatial domains. This documentation describes\
    \ the development branch of the UFS Short-Range Weather (SRW) Application, which\
    \ targets predictions of atmospheric behavior on a limited spatial domain and\
    \ on time scales from minutes to several days. The development branch of the application\
    \ is continually evolving as the system undergoes open development. The latest\
    \ SRW App release (v2.0.0) represents a snapshot of this continuously evolving\
    \ system.</p>\n<p>The UFS SRW App User's Guide associated with the development\
    \ branch is at: <a href=\"https://ufs-srweather-app.readthedocs.io/en/develop/\"\
    \ rel=\"nofollow\">https://ufs-srweather-app.readthedocs.io/en/develop/</a>, while\
    \ the guide specific to the SRW App v2.0.0 release can be found at: <a href=\"\
    https://ufs-srweather-app.readthedocs.io/en/release-public-v2/\" rel=\"nofollow\"\
    >https://ufs-srweather-app.readthedocs.io/en/release-public-v2/</a>. The repository\
    \ is at: <a href=\"https://github.com/ufs-community/ufs-srweather-app\">https://github.com/ufs-community/ufs-srweather-app</a>.</p>\n\
    <p>For instructions on how to clone the repository, build the code, and run the\
    \ workflow, see:\n<a href=\"https://github.com/ufs-community/ufs-srweather-app/wiki/Getting-Started\"\
    >https://github.com/ufs-community/ufs-srweather-app/wiki/Getting-Started</a></p>\n\
    <p>UFS Development Team. (2022, June 23). Unified Forecast System (UFS) Short-Range\
    \ Weather (SRW) Application (Version v2.0.0). Zenodo. <a href=\"https://doi.org/10.5281/zenodo.6505854\"\
    \ rel=\"nofollow\">https://doi.org/10.5281/zenodo.6505854</a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1661692471.0
jkbk2004/ww3-vis:
  data_format: 2
  description: null
  filenames:
  - model/ci/spack.yaml
  full_name: jkbk2004/ww3-vis
  latest_release: null
  readme: "<h1><a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2><a id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#general-features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1661796370.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - ornl/crusher/crusher.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-nightlies-rootmod/spack.yaml
  - environments/key4hep-nightlies/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    href="#repository-contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    href="#central-installations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 9
  subscribers_count: 9
  topics: []
  updated_at: 1673125688.0
lanl/CELLAR:
  data_format: 2
  description: The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based
    adaptive mesh refinement data structures and execution for parallel computing
    architectures.
  filenames:
  - spack/default/spack.yaml
  - spack/snow/spack.yaml
  - spack/ci/spack.yaml
  - spack/darwin-power9/spack.yaml
  - spack/agaspar/spack.yaml
  full_name: lanl/CELLAR
  latest_release: null
  readme: '<h1><a id="user-content-cellar-----eap-core" class="anchor" aria-hidden="true"
    href="#cellar-----eap-core"><span aria-hidden="true" class="octicon octicon-link"></span></a>CELLAR  -  EAP
    Core</h1>

    <p>CELLAR is a C++ project that forms the foundation of cell based AMR for applications</p>

    <p>It provides the following:</p>

    <ul>

    <li>AMR Mesh Datastructure</li>

    <li>AMR Mesh Reconstruction</li>

    <li>Communication Patterns</li>

    <li>C++ Error Handling and Tracing</li>

    <li>Performance Monitoring</li>

    <li>C++/Fortran Interop</li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>The easiest way to install dependencies is using <a href="https://spack.io"
    rel="nofollow">Spack</a>.

    After

    <a href="https://spack.readthedocs.io/en/latest/getting_started.html" rel="nofollow">installing
    Spack</a>,

    you can start build dependencies.</p>

    <p>The following instructions assume that you have Spack 0.13 or newer. You can
    check your

    Spack version like so:</p>

    <pre><code>$ spack --version

    0.13.0

    </code></pre>

    <p>First, add <a href="https://github.com/lanl/cellar-spack">lanl/cellar-spack</a>

    to your list of spack repos.</p>

    <p>Once you have the <code>lanl/cellar-spack</code> installed, then you can install
    all

    dependencies using

    <a href="https://spack.readthedocs.io/en/latest/tutorial_environments.html#" rel="nofollow">Spack
    environments</a>.

    You''ll need to use a modern-ish C++ compiler that supports C++14:</p>

    <pre><code>$ module load gcc/9.3.0

    $ spack compiler find

    $ cd path/to/eap-core

    </code></pre>

    <p>Then issue the following commands. This will build all of eap-core''s dependencies.:</p>

    <pre><code>$ spack env create -d spack/default

    $ spack env activate -d $PWD/spack/default

    $ spack install

    </code></pre>

    <p>Any time you open a new shell, you''ll need to re-activate the Spack environment:</p>

    <pre><code>$ spack env activate -d $PWD/spack/default

    </code></pre>

    <p>Now you''re ready to build eap-core. First configure the project using CMake:</p>

    <pre><code>mkdir build &amp;&amp; cd build

    cmake ..

    </code></pre>

    <p>And then build:</p>

    <pre><code>make -j

    </code></pre>

    <p>For snow, substitute in spack/snow in the above instructions in place of spack/default.
    If you need

    to change the environment use "spack env deactivate".</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Code contributors should read the <a href="DEVELOPERS.md">Developers Guide</a>
    prior to

    sending a pull request.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1667253429.0
lanl/cellar-gtest-mpi:
  data_format: 2
  description: null
  filenames:
  - spack/agaspar/spack.yaml
  full_name: lanl/cellar-gtest-mpi
  latest_release: null
  readme: "<h1><a id=\"user-content-google-test-for-mpi-gtest-mpi\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#google-test-for-mpi-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Google Test for MPI (gtest-mpi)</h1>\n\
    <p>This is a support library that helps users write Google Test unit tests that\n\
    rely on MPI.</p>\n<h2><a id=\"user-content-features\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Features</h2>\n<ul>\n<li>Serialized and rank-tagged Google Test output.</li>\n\
    <li>Rank-tagged failure reports.</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> is the easiest way\
    \ to install gtest-mpi. The gtest-mpi\npackage is available in\n<a href=\"https://gitlab.lanl.gov/agaspar/spack-repo\"\
    \ rel=\"nofollow\">agaspar/spack-repo</a>. Follow the\nREADME there to use that\
    \ spack repo. Once the agaspar-spack-repo repo is\ninstalled, installing gtest-mpi\
    \ is as simple as running:</p>\n<pre><code>spack install gtest-mpi\n</code></pre>\n\
    <p>When you want to use gtest-mpi, run <code>spack load gtest-mpi</code> to load\
    \ it into your\ncurrent environment.</p>\n<h3><a id=\"user-content-cmake\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>CMake</h3>\n<p>If you don't want to use spack,\
    \ you can install gtest-mpi directly using CMake.\ngtest-mpi uses CMake, so all\
    \ of your knowledge of CMake applies. gtest-mpi\nhas a dependency on Google Test,\
    \ and uses\n<a href=\"https://cmake.org/cmake/help/latest/module/FindGTest.html\"\
    \ rel=\"nofollow\">FindGTest.cmake</a> to\nfind it. Therefore, in order to install\
    \ gtest-mpi, you must first have a\nworking installation of <a href=\"https://github.com/google/googletest/\"\
    >Google Test</a>.</p>\n<p>Once you've installed Google Test, building and installing\
    \ gtest-mpi is just\nlike any other modern CMake package.</p>\n<pre><code>git\
    \ clone git@gitlab.lanl.gov:agaspar/gtest-mpi.git\ncd gtest-mpi\nmkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake install\n</code></pre>\n<h2><a id=\"user-content-using-gtest-mpi\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using gtest-mpi</h2>\n<h3><a\
    \ id=\"user-content-with-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #with-cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>With\
    \ CMake</h3>\n<p>If you don't need any custom startup logic, using gtest-mpi in\
    \ your own CMake\nproject is simple:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">find_package</span>(gtest-mpi 0.1 <span class=\"pl-k\"\
    >REQUIRED</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> gtest-mpi-main\
    \ provides a main function for you</span>\n<span class=\"pl-c1\">add_executable</span>(my-test\
    \ mytest.cpp)\n<span class=\"pl-c1\">target_link_libraries</span>(my-test gtest-mpi-main)</pre></div>\n\
    <p>Then you can write a Google Test just like you normally would:</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> mytest.cpp</span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-en\"\
    >TEST</span>(GTestMPI, Basic) {\n    <span class=\"pl-k\">int</span> rank;\n \
    \   <span class=\"pl-c1\">MPI_Comm_rank</span>(MPI_COMM_WORLD, &amp;rank);\n\n\
    \    <span class=\"pl-k\">bool</span> is_root = rank == <span class=\"pl-c1\"\
    >0</span>;\n\n    <span class=\"pl-k\">bool</span> is_anyone_root = <span class=\"\
    pl-c1\">false</span>;\n    <span class=\"pl-c1\">MPI_Allreduce</span>(\n     \
    \   &amp;is_root, &amp;is_anyone_root, <span class=\"pl-c1\">1</span>, MPI_CXX_BOOL,\
    \ MPI_LOR, MPI_COMM_WORLD);\n\n    <span class=\"pl-c1\">ASSERT_TRUE</span>(is_anyone_root);\n\
    }</pre></div>\n<p>If you need to write your own main function, that's also fairly\
    \ straighforward.\nIn your CMake project, you link against <code>gtest-mpi-lib</code>\
    \ instead of\n<code>gtest-mpi-main</code>. Then you must provide your own main\
    \ function:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> main.cpp</span>\n#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest-mpi/init.hpp<span\
    \ class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"\
    pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\
    \n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span> **argv) {\n    <span\
    \ class=\"pl-c1\">testing::InitGoogleTest</span>(&amp;argc, argv);\n    <span\
    \ class=\"pl-c1\">MPI_Init</span>(&amp;argc, &amp;argv);\n    <span class=\"pl-c1\"\
    >gtest_mpi::init</span>(&amp;argc, &amp;argv);\n\n    <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Your custom init logic goes here</span>\n\n    <span\
    \ class=\"pl-k\">int</span> exit_code = <span class=\"pl-c1\">RUN_ALL_TESTS</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Your custom finalize\
    \ logic goes here</span>\n\n    <span class=\"pl-c1\">gtest_mpi::finalize</span>();\n\
    \    <span class=\"pl-c1\">MPI_Finalize</span>();\n\n    <span class=\"pl-k\"\
    >return</span> exit_code;\n}</pre></div>\n<h3><a id=\"user-content-without-cmake\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#without-cmake\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Without CMake</h3>\n<p>CMake\
    \ is not required to use gtest-mpi, but it is recommended. If you wish to\nuse\
    \ a different build system, then adding <code>-lgtest-mpi-lib</code> and (optionally)\n\
    <code>-lgtest-mpi-main</code> to your link line will work.</p>\n<h2><a id=\"user-content-ctest\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#ctest\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>CTest</h2>\n<p>Here's an example of\
    \ adding a CTest using gtest-mpi to your CMake file:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">enable_testing</span>()\n\
    \n<span class=\"pl-c1\">add_test</span>(\n    <span class=\"pl-k\">NAME</span>\
    \ my-test\n    <span class=\"pl-k\">COMMAND</span>\n        <span class=\"pl-smi\"\
    >${MPIEXEC}</span> <span class=\"pl-smi\">${MPIEXEC_NUMPROC_FLAG}</span> 4 <span\
    \ class=\"pl-smi\">${MPIEXEC_PREFLAGS}</span>\n            $&lt;<span class=\"\
    pl-k\">TARGET_FILE</span>:my-test&gt; <span class=\"pl-smi\">${MPIEXEC_POSTFLAGS}</span>)</pre></div>\n\
    <p>These tests can be run using <code>ctest</code>.</p>\n"
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1668046366.0
laristra/ristra_spackages:
  data_format: 2
  description: 'A mirror of Ristra''s internal gitlab repository. '
  filenames:
  - .gitlab-ci/env/local-build/spack.yaml
  - .gitlab-ci/env/root-build/spack.yaml
  full_name: laristra/ristra_spackages
  latest_release: null
  readme: '<h1><a id="user-content-ristra-spackages" class="anchor" aria-hidden="true"
    href="#ristra-spackages"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ristra
    Spackages</h1>

    <p>This repository contains the custom spackage files for the repos in laristra
    family.</p>

    <h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Basic Usage</h2>

    <p>We assume the user wish to work in the home directory and already have a spack
    instance setup.  The minimum required version of spack is 0.15.2.</p>

    <p>To get the content of this repo</p>

    <pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git

    </code></pre>

    <p>To use the custom spackage files with your spack</p>

    <pre><code>$ spack repo add ristra_spackages/spack-repo

    ==&gt; Added repo with namespace ''lanl_ristra''.


    $ spack repo list

    ==&gt; 2 package repositories.

    lanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo

    builtin            /home/&lt;user&gt;/spack/var/spack/repos/builtin

    </code></pre>

    <p>[Optional]

    To ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code>
    into your spack config folder</p>

    <pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/

    </code></pre>

    <p>Please see the <a href="https://spack.readthedocs.io/en/latest/configuration.html"
    rel="nofollow">Spack documentation</a> for more detailed info.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1649449003.0
ma595/fenics-csd3-spack:
  data_format: 2
  description: Set up fenics spack on csd3
  filenames:
  - spack-icelake.yaml
  - spack-skylake.yaml
  full_name: ma595/fenics-csd3-spack
  latest_release: null
  readme: '<h1><a id="user-content-fenics-csd3-spack" class="anchor" aria-hidden="true"
    href="#fenics-csd3-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>fenics-csd3-spack</h1>

    <p>Follow instructions in icelake-spack-env.sh</p>

    <p>Or, copy existing <code>spack.yaml</code> files into cloned Spack repo. It
    is necessary to <code>module purge</code> environment first, otherwise the prepend
    path inside <code>spack.yaml</code> will lead to duplications.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667830944.0
marcodelapierre/toy-cowsay-nf:
  data_format: 2
  description: Toy pipeline for simple Nextflow tests
  filenames:
  - scripts/spack/spack.yaml
  - spack.yaml
  - scripts/containerize-spack/spack.yaml
  full_name: marcodelapierre/toy-cowsay-nf
  latest_release: null
  readme: '<h2><a id="user-content-toy-pipeline-for-simple-nextflow-tests" class="anchor"
    aria-hidden="true" href="#toy-pipeline-for-simple-nextflow-tests"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Toy pipeline for simple Nextflow tests</h2>

    <p>The purpose of this repo is to have a pipeline with features including:</p>

    <p>General:</p>

    <ul>

    <li>Simple</li>

    <li>Small (including required software)</li>

    <li>Quick to setup and run</li>

    </ul>

    <p>Pipeline:</p>

    <ul>

    <li>Requires a small package, that can be installed with Conda or Spack

    <ul>

    <li>Conda: <code>cowpy</code> (from <code>conda-forge</code>)</li>

    <li>Spack: <code>cowsay</code>

    </li>

    </ul>

    </li>

    <li>Reads/writes files</li>

    </ul>

    <p>Software options:</p>

    <ul>

    <li>Host</li>

    <li>Containers</li>

    <li>Conda</li>

    <li>Conda with Wave</li>

    <li>Spack</li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1675203057.0
mochi-hpc-experiments/example-yokan-poesie-composition:
  data_format: 2
  description: Example of Mochi service composing Poesie and Yokan via Bedrock
  filenames:
  - spack.yaml
  full_name: mochi-hpc-experiments/example-yokan-poesie-composition
  latest_release: null
  readme: '<h2><a id="user-content-example-yokanpoesie-composition" class="anchor"
    aria-hidden="true" href="#example-yokanpoesie-composition"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Example Yokan/Poesie composition</h2>

    <p>This repository contains an example of a <a href="https://mochi.readthedocs.io/en/latest/bedrock.html"
    rel="nofollow">Bedrock</a>

    configuration that spins up a Yokan provider for key/value storage and a Poesie
    provider for

    embedding a Python interpreter.</p>

    <p>The <em>test.cpp</em> file shows an example of first putting a key/value pair
    into the database

    using the Yokan API, then using the Poesie API to send a python code that retrieves
    said value.</p>

    <h3><a id="user-content-building-the-code" class="anchor" aria-hidden="true" href="#building-the-code"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building the code</h3>

    <p>The <em>spack.yaml</em> file in this repository allows creating a Spack environment
    with the

    required dependencies as follows, from inside the cloned repository (note that
    you must have installed

    <a href="https://github.com/mochi-hpc/mochi-spack-packages">mochi-spack-packages</a>
    as

    instructed <a href="https://mochi.readthedocs.io/en/latest/installing.html#installing-spack-and-the-mochi-repository"
    rel="nofollow">here</a>).</p>

    <pre><code>$ spack env create -d .

    $ spack env activate .

    $ spack install

    </code></pre>

    <p>You can then build the code as follows.</p>

    <pre><code>$ mkdir build

    $ cd build

    $ cmake ..

    $ make

    </code></pre>

    <h3><a id="user-content-running-the-code" class="anchor" aria-hidden="true" href="#running-the-code"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running the code</h3>

    <p>Open two terminals, making sure the Spack environment is activated in both.

    In the first termina, run the Bedrock daemon as follows.</p>

    <pre><code>$ bedrock na+sm -c src/config.json -v trace

    </code></pre>

    <p>Make a note of the address that the Bedrock server is reporting to be running
    on

    (e.g., <code>na+sm://15865-0</code>).</p>

    <p>In the second, run the <code>yokan-poesie-test</code> executable with the address
    as

    command-line argument, as follows.</p>

    <pre><code>$ ./yokan-poesie-test na+sm://15865-0

    </code></pre>

    <p>If everything goes well, the test program will print "some_value" before

    terminating.</p>

    <h3><a id="user-content-step-by-step-explanation" class="anchor" aria-hidden="true"
    href="#step-by-step-explanation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step-by-step
    explanation</h3>

    <p>The <em>config.json</em> file describes how our service should look like on
    one node.

    Our service contains a <a href="https://mochi.readthedocs.io/en/latest/yokan.html"
    rel="nofollow">Yokan</a>

    provider, which is the component that provides key/value storage.

    In the configuration of this component, we add a database called <em>my_kv_store</em>,

    of type <em>map</em>. This type corresponds to an in-memory, ordered map.</p>

    <p>The configuration then lists a Poesie provider, which is the component that
    will

    provide us with an embedded Python interpreter. Its configuration lists

    <em>my_python_vm</em> for this purpose.</p>

    <p>In the configuration of this VM, the <em>preamble</em> entry lets us provide
    some code

    to execute upon initializing the VM (i.e., when the server starts). We take

    advantage of this preamble to import <code>pyyokan_client</code>, the Python binding
    for

    Yokan''s client library, and create the <code>my_kv_store</code> variable of type

    <code>pyyokan_client.Database</code> to be a handle to the database managed by
    Yokan.

    The <code>__mid__</code> and <code>__address__</code> variables are added by Poesie
    automatically

    and respectively represents the Margo instance in use and the process'' own

    address.</p>

    <p>Moving over to the <em>test.c</em> file, the <code>write_with_yokan</code>
    function shows

    an example of using the Yokan C API to look up the database by its name

    to get its id, building a <code>yk_database_handle_t</code> to interact with the
    database,

    then putting "some_value" associated with the key "my_key" into the database.</p>

    <p>The <code>read_with_poesie</code> function uses the Poesie C API to create
    a

    <code>poesie_provider_handle_t</code>, look up the VM id by its name, then

    send over some Python code to be executed on the server.

    The Python code in question uses the <code>my_kv_store</code> variable, initialized

    in the preamble of the VM, to interact with the local database using

    Yokan''s Python API. Here it first gets the length of the value associated

    with "my_key", before actually fetching it into a <code>bytearray</code> buffer.</p>

    <p>The <code>__poesie_output__</code> variable is a special variable that the
    VM will

    lookup after executing the user code. Any object placed in this variable

    will be transformed into a string (using the object''s <code>__str__</code> method),

    before being sent back to the caller in as output. Poesie handles

    execution results this way because <code>return</code> cannot be called outside
    of

    functions. In the present exemple, the content of the key, which is a

    <code>bytearray</code>, is transformed into a unicode string using <code>.decode("utf-8")</code>.</p>

    <p>Note that if an exception is raised from the user code, Poesie will

    ignore the content of <code>__poesie_output__</code> and return the exception

    (converted into a string) as output instead.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1666024613.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ANL/ThetaGPU/spack.yaml
  - ANL/Theta/spack.yaml
  - ORNL/Summit/spack.yaml
  - ANL/Polaris/spack-ucx.yaml
  - NERSC/Perlmutter/ss11/spack.yaml
  - NERSC/Cori/spack.yaml
  - ANL/Polaris/spack.yaml
  - NERSC/Perlmutter/ss10/spack.yaml
  - ANL/Bebop/spack.yaml
  - ANL/Cooley/spack.yaml
  - ORNL/Crusher/spack.yaml
  - ANL/JLSE/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" href="#platform-configurations-for-mochi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Platform configurations for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    href="#contributing-to-this-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1670336727.0
mochi-hpc/mobject:
  data_format: 2
  description: Mobject is a prototype Mochi object storage system based on RADOS
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mobject
  latest_release: v0.6.1
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"mobject_logo.png\"\
    ><img src=\"mobject_logo.png\" alt=\"logo\" style=\"max-width: 100%;\"></a></p>\n\
    <h1><a id=\"user-content-mobject\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #mobject\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mobject</h1>\n\
    <p><a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml/badge.svg\"\
    \ alt=\"check spelling\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml/badge.svg\"\
    \ alt=\"spack mobject\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml\"\
    ><img src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml/badge.svg\"\
    \ alt=\"spack mobject+bedrock\" style=\"max-width: 100%;\"></a></p>\n<p>Mobject\
    \ is a distributed object storage system\nbuilt using a composition of <a href=\"\
    https://mochi.readthedocs.io\" rel=\"nofollow\">Mochi</a> components:</p>\n<ul>\n\
    <li>\n<a href=\"https://github.com/mochi-hpc/mochi-bake\">mochi-bake</a> (for\
    \ bulk storage)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-bedrock\"\
    >mochi-bedrock</a>\n(for configuration and bootstrapping)</li>\n<li>\n<a href=\"\
    https://github.com/mochi-hpc/mochi-sdskv\">mochi-sdskv</a>\n(for metadata and\
    \ log indexing)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-ssg\"\
    >mochi-ssg</a> (for group membership)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"\
    https://mochi.readthedocs.io/en/latest/installing.html#installing-spack-and-the-mochi-repository\"\
    \ rel=\"nofollow\">Install Spack and Mochi Spack Repository</a>.</p>\n<p>Then,\
    \ run the following command to install mobject.</p>\n<pre><code>   spack install\
    \ mobject\n</code></pre>\n<h2><a id=\"user-content-hdf5-and-mobject\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#hdf5-and-mobject\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>HDF5 and Mobject</h2>\n<p><a\
    \ href=\"/include/librados-mobject-store.h\">Mobject API</a> is a subset of the\n\
    <a href=\"https://github.com/ceph/ceph/blob/main/src/include/rados/librados.h\"\
    >RADOS API</a>\nfrom Ceph\u2019s object storage layer.\nTherefore, <a href=\"\
    https://github.com/HDFGroup/vol-rados\">HDF5 RADOS VOL plugin-in</a>\ncan use\
    \ Mobject.</p>\n<h2><a id=\"user-content-faq\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#faq\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>FAQ</h2>\n<p>See <a href=\"doc/FAQ.md\">doc/FAQ.md</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1640785210.0
mochi-hpc/mochi-bedrock:
  data_format: 2
  description: Mochi bootstrapping service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bedrock
  latest_release: v0.5.2
  readme: '<h1><a id="user-content-bedrock" class="anchor" aria-hidden="true" href="#bedrock"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bedrock</h1>

    <p>Bedrock is Mochi''s service bootstrapping mechanism.

    For documentations and tutorials, please see

    <a href="https://mochi.readthedocs.io/en/latest/bedrock.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640527359.0
mochi-hpc/mochi-margo:
  data_format: 2
  description: Argobots bindings for the Mercury RPC library
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-margo
  latest_release: v0.12
  readme: "<h1><a id=\"user-content-margo\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#margo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    ><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings\
    \ to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\"\
    \ rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\n\
    library optimized for use in HPC environments.  Its native API presents a\ncallback-oriented\
    \ interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\"\
    \ rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n\
    <p>Margo combines Mercury and Argobots to simplify development of distributed\n\
    services.  Mercury operations are presented as conventional blocking\noperations,\
    \ and RPC handlers are presented as sequential threads.  This\nconfiguration enables\
    \ high degree of concurrency while hiding the\ncomplexity associated with asynchronous\
    \ communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends\
    \ callers after issuing a Mercury operation, and\nautomatically resumes them when\
    \ the operation completes.  This allows\nother concurrent user-level threads to\
    \ make progress while Mercury\noperations are in flight without consuming operating\
    \ system threads.\nThe goal of this design is to combine the performance advantages\
    \ of\nMercury's native event-driven execution model with the progamming\nsimplicity\
    \ of a multi-threaded execution model.</p>\n<p>A companion library called abt-io\
    \ provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\"\
    >https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should\
    \ be compatible with any Mercury network\ntransport (NA plugin).  The documentation\
    \ assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury\
    \ for\nsimplicity.  This plugin is only valid for communication between\nprocesses\
    \ on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\"\
    >Using Margo with other Mercury NA\nplugins</a> for information\non other configuration\
    \ options.</p>\n<h2><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing\
    \ the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"\
    nofollow\">https://spack.io/</a>).</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury\
    \  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\"\
    >https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone\
    \ <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n\
    </ul>\n<h3><a id=\"user-content-recommended-mercury-build-options\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#recommended-mercury-build-options\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury build options</h3>\n\
    <ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable\
    \ the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should be compiled\
    \ with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path\
    \ for cases in which a Mercury service is linked into the same\nexecutable as\
    \ the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir\
    \ build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON\
    \ -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install\
    \ \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n\
    <h2><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n\
    <p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install\
    \ \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"\
    -g -Wall\"\n</code></pre>\n<h2><a id=\"user-content-running-examples\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#running-examples\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The\
    \ examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example\
    \ client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]:\
    \ an example RPC definition</li>\n</ul>\n<p>The following example shows how to\
    \ execute them.  Note that when the server starts it will display the address\
    \ that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server\
    \ na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with\
    \ input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val:\
    \ 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client\
    \ na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3]\
    \ running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\n\
    Got response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n\
    <p>The client will issue 4 concurrent RPCs to the server and wait for them to\n\
    complete.</p>\n<h2><a id=\"user-content-running-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#running-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running tests</h2>\n<p><code>make check</code></p>\n<h2><a id=\"user-content-using-margo-with-the-other-na-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-margo-with-the-other-na-plugins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Margo\
    \ with the other NA plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\"\
    \ rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible\
    \ with any Mercury transport and uses the same address\nformat.</p>\n<h2><a id=\"\
    user-content-debugging\" class=\"anchor\" aria-hidden=\"true\" href=\"#debugging\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Debugging</h2>\n\
    <p>See the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo\
    \ debugging\nfeatures and strategies.</p>\n<h2><a id=\"user-content-design-details\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#design-details\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Design details</h2>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"doc/fig/margo-diagram.png\"><img src=\"\
    doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>Margo provides Argobots-aware wrappers to common Mercury library\
    \ functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The\
    \ wrappers\nhave the same arguments as their native Mercury counterparts except\
    \ that no\ncallback function is specified.  Each function blocks until the operation\n\
    is complete.  The above diagram illustrates a typical control flow.</p>\n<p>Margo\
    \ launches a long-running user-level thread internally to drive\nprogress on Mercury\
    \ and execute Mercury callback functions (labeled\n<code>__margo_progress()</code>\
    \ above).  This thread can be assigned to a\ndedicated Argobots execution stream\
    \ (i.e., an operating system thread)\nto drive network progress with a dedicated\
    \ core.  Otherwise it will be\nautomatically scheduled when the caller's execution\
    \ stream is blocked\nwaiting for network events as shown in the above diagram.</p>\n\
    <p>Argobots eventual constructs are used to suspend and resume user-level\nthreads\
    \ while Mercury operations are in flight.</p>\n<p>Margo allows several different\
    \ threading/multicore configurations:</p>\n<ul>\n<li>The progress loop can run\
    \ on a dedicated operating system thread or not</li>\n<li>Multiple Margo instances\
    \ (and thus progress loops) can be\nexecuted on different operating system threads</li>\n\
    <li>(for servers) a single Margo instance can launch RPC handlers\non different\
    \ operating system threads</li>\n</ul>\n"
  stargazers_count: 18
  subscribers_count: 9
  topics: []
  updated_at: 1673864799.0
mochi-hpc/mochi-poesie:
  data_format: 2
  description: POESIE is a Mochi microservice designed to run interpreters of various
    scripting languages (currently Lua and Python) and make them accessible remotely.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-poesie
  latest_release: v0.2
  readme: "<h1><a id=\"user-content-poesie-embedding-scripting-languages-for-mochi-services\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#poesie-embedding-scripting-languages-for-mochi-services\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>POESIE:\
    \ Embedding Scripting Languages for Mochi Services</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>POESIE\
    \ can easily be installed using Spack:</p>\n<p><code>spack install mochi-poesie</code></p>\n\
    <p>This will install POESIE (and any required dependencies) with both\nPython\
    \ and Lua backends. Disabling one or the other can be done by\nappending <code>~lua</code>\
    \ or <code>~python</code>, for example:</p>\n<p><code>spack install poesie~lua</code></p>\n\
    <h2><a id=\"user-content-architecture\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#architecture\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Architecture</h2>\n<p>Like most mochi services, POESIE relies on a\
    \ client/provider architecture.\nA provider, identified by its <em>address</em>\
    \ and <em>provider id</em>, manages one or more\ninterpreters (called <em>virtual\
    \ machines</em>, or <em>VMs</em>), referenced externally\nby either their name\
    \ or their VM id.</p>\n<h2><a id=\"user-content-starting-a-daemon-using-bedrock\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#starting-a-daemon-using-bedrock\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting\
    \ a daemon using Bedrock</h2>\n<p>By installing POESIE with the <code>+bedrock</code>\
    \ variant, one can deploy a daemon\nby providing a JSON configuration like the\
    \ following to Bedrock.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\
    \    <span class=\"pl-ent\">\"libraries\"</span>: [\n        <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>libpoesie-bedrock-module.so<span class=\"pl-pds\"\
    >\"</span></span>\n    ],\n    <span class=\"pl-ent\">\"providers\"</span>: [\n\
    \        {\n            <span class=\"pl-ent\">\"name\"</span>: <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>my_poesie_provider<span class=\"pl-pds\"\
    >\"</span></span>,\n            <span class=\"pl-ent\">\"provider_id\"</span>:\
    \ <span class=\"pl-c1\">0</span>,\n            <span class=\"pl-ent\">\"config\"\
    </span>: {\n                <span class=\"pl-ent\">\"vms\"</span>: {\n       \
    \             <span class=\"pl-ent\">\"my_vm\"</span>: {\n                   \
    \     <span class=\"pl-ent\">\"language\"</span>: <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>python<span class=\"pl-pds\">\"</span></span>\n            \
    \        }\n                }\n            }\n        }\n    ]\n}</pre></div>\n\
    <h2><a id=\"user-content-client-api\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #client-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client\
    \ API</h2>\n<p>The client API is available in <em>poesie-client.h</em>.\nThe codes\
    \ in the <em>test</em> folder illustrate how to use it.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975197.0
mochi-hpc/mochi-remi:
  data_format: 2
  description: Mochi's REsource Migration Interface
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-remi
  latest_release: v0.3.2
  readme: '<h1><a id="user-content-resource-migration-interface" class="anchor" aria-hidden="true"
    href="#resource-migration-interface"><span aria-hidden="true" class="octicon octicon-link"></span></a>REsource
    Migration Interface</h1>

    <p>REMI is a Mochi microservice designed to handle the migration of sets of files

    from a node to another. It uses RDMA and memory mapping to efficiently transfer

    potentially large groups of files at once.</p>

    <h3><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>Just like all Mochi services, REMI can be installed using Spack. Once you have

    clone the <a href="https://xgitlab.cels.anl.gov/sds/sds-repo" rel="nofollow">sds-repo</a>
    package repository

    and added it to your spack installation, you can install REMI using the following

    command:</p>

    <pre><code>spack install mochi-remi

    </code></pre>

    <p>REMI depends on <a href="https://xgitlab.cels.anl.gov/sds/thallium/" rel="nofollow">Thallium</a>,
    which

    Spack will install (if needed) along with Thallium''s own dependencies. It also

    depends on Bedrock, unless the <code>bedrock</code> variant is disable when installing

    with Spack (i.e. passing <code>~bedrock</code> to the above command).</p>

    <h3><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h3>

    <p>REMI works with <em>filesets</em>. A fileset consists of a root directory and

    a set of file paths relative to this root directory. A fileset is also characterized

    by the name of its <em>migration class</em>.</p>

    <p>REMI clients create filesets to group files corresponding to a particular resource

    (e.g. a database''s files). They can then request the migration of fileset to

    a target provider.</p>

    <p>Uppon receiving a request for migration, a provider will recreate the tree
    of

    directories required to receive the files of the fileset, create the files,

    mmap them into memory, and issue an RDMA pull operation from the client''s files

    (themselves mmap-ed into the client''s memory).</p>

    <p>Following successful migration, the provider will call a user-supplied callback

    corresponding to the particular fileset''s migration class.</p>

    <p>For an example of code, please see the <a href="examples">examples</a>

    folder in the source tree.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975455.0
mochi-hpc/mochi-thallium:
  data_format: 2
  description: Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and
    providing an object-oriented way to use these libraries.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-thallium
  latest_release: v0.10.1
  readme: '<h1><a id="user-content-thallium" class="anchor" aria-hidden="true" href="#thallium"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Thallium</h1>

    <p>Thallium is a C++ interface to <a href="https://github.com/mochi-hpc/mochi-margo/">Margo</a>.

    It offers a modern, object-oriented way of developing HPC data services. More

    information can be found on <a href="https://mochi.readthedocs.io/en/latest/"
    rel="nofollow">Mochi''s readthedocs</a>

    website.</p>

    '
  stargazers_count: 8
  subscribers_count: 4
  topics: []
  updated_at: 1675262100.0
mochi-hpc/mochi-yokan:
  data_format: 2
  description: Remote Key/Value storage service for Mochi
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-yokan
  latest_release: v0.2.10
  readme: '<h1><a id="user-content-yokan---mochis-keyvalue-and-more-storage-service"
    class="anchor" aria-hidden="true" href="#yokan---mochis-keyvalue-and-more-storage-service"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Yokan - Mochi''s Key/Value
    (and more) storage service</h1>

    <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"><img
    src="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"
    alt="" style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/mochi-hpc/mochi-yokan" rel="nofollow"><img src="https://camo.githubusercontent.com/fc95c801bafa29b49219f4727f651b97e7385800c8dc4a4757a1dccadefe6611/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d796f6b616e2f6272616e63682f6d61696e2f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/mochi-hpc/mochi-yokan/branch/main/graph/badge.svg"
    style="max-width: 100%;"></a></p>

    <p>Please see documentation <a href="https://mochi.readthedocs.io/en/latest/yokan.html"
    rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641326484.0
mochi-hpc/ycsb-cpp-interface:
  data_format: 2
  description: Mochi-based DB backends for the YCSB benchmark
  filenames:
  - spack.yaml
  full_name: mochi-hpc/ycsb-cpp-interface
  latest_release: null
  readme: "<h1><a id=\"user-content-ycsb-c-interface\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#ycsb-c-interface\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>YCSB C++ Interface</h1>\n<p><a href=\"https://github.com/brianfrankcooper/YCSB\"\
    >YCSB</a> is one of the most popular Cloud\nstorage benchmark. However it is written\
    \ in Java, forcing databases implemented\nin other languages to provide a Java\
    \ wrapper. While <a href=\"https://github.com/ls4154/YCSB-cpp\">YCSC-cpp</a>\n\
    provides a reimplementation of YCSB in C++, to date it only supports three backends,\
    \ as\nopposed to 45 for the original YCSB.</p>\n<p><a href=\"https://github.com/mochi-hpc/ycsb-cpp-interface\"\
    >ycsb-cpp-interface</a>\ntakes a different approach from YCSB-cpp, providing a\
    \ Java/C++ library\nthat enables the use of C++ to write DB backends for YCSB.</p>\n\
    <p>ycsb-cpp-inteface works in a modular way, dynamically loading your C++ database\n\
    implementation from a library using a factory pattern.</p>\n<h2><a id=\"user-content-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n<h3><a id=\"\
    user-content-building-manually\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building-manually\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Building manually</h3>\n<p>To build this repository from source, you\
    \ will first need to have\nits dependencies installed and findable by CMake. These\
    \ dependencies\ninclude:</p>\n<ul>\n<li>Java Development Kit (e.g., OpenJDK)</li>\n\
    <li>YCSB</li>\n<li>cmake</li>\n</ul>\n<p>Make sure to set the <code>JAVA_HOME</code>\
    \ environment variable\nto point to where your JDK is installed so that CMake\
    \ can find it.\nIt is recommended to install a distribution of YCSB, rather than\n\
    the source.</p>\n<p>You can then build the source contained in this repository\
    \ as follows.</p>\n<pre><code>$ mkdir build\n$ cd build\n$ cmake .. -DYCSB_ROOT=&lt;path/to/where/ycsb/is/installed&gt;\
    \ \\\n           -DCMAKE_INSTALL_PREFIX=&lt;install/prefix&gt;\n$ make\n</code></pre>\n\
    <h3><a id=\"user-content-installing-using-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#installing-using-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Installing using Spack</h3>\n<p>You can install this\
    \ library using <a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a>.\nThe\
    \ <code>ycsb-cpp-interface</code> Spack package is available via the\n<a href=\"\
    https://github.com/mochi-hpc/mochi-spack-packages\">Mochi repository</a>,\nwhich\
    \ can be added to Spack as follows.</p>\n<pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git\n\
    $ spack repo add mochi-spack-packages\n</code></pre>\n<p>Once the <code>mochi-spack-packages</code>\
    \ repository has been made available to Spack,\nyou can install <code>ycsb-cpp-interface</code>\
    \ as follows.</p>\n<pre><code>$ spack install ycsb-cpp-interface\n</code></pre>\n\
    <h2><a id=\"user-content-testing\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #testing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Testing</h2>\n\
    <p>If you have installed ycsb-cpp-interface with Spack, make sure that\nthe package\
    \ is loaded (<code>spack load ycsb-cpp-interface</code>), then you\ncan start\
    \ the CLI for testing, as follows.</p>\n<pre><code>ycsb-cpp-cli\n</code></pre>\n\
    <p>When building from source, the CLI is located in the <code>bin</code> subdirectory\n\
    of your build folder.</p>\n<p>You will end up in YCBS's CLI, with the YcsbDBClient\
    \ loaded as the\nDB backend, itself using a test implementation of an in-memory\
    \ database\nwith which you can interact (type <code>help</code> to see a list\
    \ of available commands).</p>\n<h2><a id=\"user-content-writing-your-own-c-db-backend\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#writing-your-own-c-db-backend\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Writing\
    \ your own C++ DB backend</h2>\n<p>ycsb-cpp-interface provides a header file,\
    \ <code>YCSBCppInterface.hpp</code>, with\na <code>ycsb::DB</code> abstract class.\
    \ To implement your own C++ backend database,\nyou simply need to implement a\
    \ child class of the <code>ycsb::DB</code> class that\nimplements the required\
    \ virtual functions. You may look at <a href=\"src/TestDB.cpp\"></a>\nas an example\
    \ of such an implementation. Note the use of the\n<code>YCSB_CPP_REGISTER_DB_TYPE</code>\
    \ macro after the class definition. This macro\nmust be called in a .cpp file\
    \ to associate the name of your backend\n(e.g. <code>myawesomedb</code>) with\
    \ the class name to use (e.g., <code>MyAwesomeDB</code>).</p>\n<p>Once your database\
    \ class is ready, compile it into a shared library\n(e.g., <code>libmyawesomedb.so</code>).\
    \ Make sure the <code>LD_LIBRARY_PATH</code> environment\nvariable contains the\
    \ path to your dynamic library. You may then test\nyour backend with the CLI as\
    \ follows.</p>\n<pre><code>$ ycsb-cpp-cli -p ycsb.cpp.library=libmyawesomedb.so\
    \ -p ycsb.cpp.backend=myawesomedb\n</code></pre>\n<p>The <code>ycsb.cpp.library</code>\
    \ and <code>ycsb.cpp.backend</code> properties are the only properties\nneeded\
    \ by ycsb-cpp-interface. Any other properties provided will be propagated\nto\
    \ your database implementation in the form of an <code>std::unordered_map&lt;std::string,\
    \ std::string&gt;</code>.\nNote that <code>ycsb.cpp.library</code> may accept\
    \ a full path to your dynamic library,\nif you don't want to change the <code>LD_LIBRARY_PATH</code>\
    \ environment variable.</p>\n<h2><a id=\"user-content-running-ycsb-with-your-c-db-backend\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-ycsb-with-your-c-db-backend\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ YCSB with your C++ DB backend</h2>\n<p>ycsb-cpp-interface provides a convenience\
    \ script, <code>ycsb-cpp</code>, to run YCSB\nwith your own backend. It can be\
    \ used in a way similar to the original ycsb script,\nas follows.</p>\n<pre><code>$\
    \ ycsb-cpp load -p ycsb.cpp.library=libmyawesomedb.so -p ycsb.cpp.backend=myawesomedb\
    \ -P workloadfile\n$ ycsb-cpp run -p ycsb.cpp.library=libmyawesomedb.so -p ycsb.cpp.backend=myawesomedb\
    \ -P workloadfile\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1661162651.0
psakievich/Driver-Cylinder:
  data_format: 2
  description: Test problem for the Exawind-Driver designed for demo's and debugging
  filenames:
  - spack_e4s.yaml
  full_name: psakievich/Driver-Cylinder
  latest_release: null
  readme: '<h1><a id="user-content-exawind-demo-problem" class="anchor" aria-hidden="true"
    href="#exawind-demo-problem"><span aria-hidden="true" class="octicon octicon-link"></span></a>Exawind
    Demo Problem</h1>

    <p>Rotating laminar cyinder in a cross flow with nested refinement

    Eventually this should be turbulent/turn on turbulence models to test the same
    code paths used for turbine runs</p>

    <p>Nearbody meshes:</p>

    <ul>

    <li>cylinder3d_nearbody_2k.g (no refinement, what we have in the regression suite)</li>

    <li>cylinder3d_nearbody_18k.g (1 level of refinement)</li>

    <li>cylinder3d_nearbody_146k.g (2 level of refinement)</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1665545780.0
range3/fio-practice:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/fio-practice
  latest_release: null
  readme: '<h1><a id="user-content-fio-practice" class="anchor" aria-hidden="true"
    href="#fio-practice"><span aria-hidden="true" class="octicon octicon-link"></span></a>fio-practice</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1665547201.0
range3/kvs-evaluation:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/kvs-evaluation
  latest_release: null
  readme: "<h1><a id=\"user-content-kvs-evaluation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#kvs-evaluation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>kvs-evaluation</h1>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> external/YCSB-C\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> sudo\u3092\u4F7F\u3063\u3066libhiredis.so\u304C\
    /usr/local/lib\u306B\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB\u3055\u308C\u308B</span>\n\
    make\n<span class=\"pl-k\">export</span> LD_LIBRARY_PATH=/usr/local/lib\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> \u52D5\u4F5C\u78BA\u8A8D</span>\n\
    ./ycsbc -db basic -threads 1 -P workloads/workloada.spec</pre></div>\n<h1><a id=\"\
    user-content-ycsb-c\" class=\"anchor\" aria-hidden=\"true\" href=\"#ycsb-c\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>YCSB-C</h1>\n\
    <h2><a id=\"user-content-workload\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #workload\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>workload</h2>\n\
    <table>\n<thead>\n<tr>\n<th align=\"left\">workload</th>\n<th align=\"left\">description</th>\n\
    <th align=\"right\">read</th>\n<th align=\"right\">insert</th>\n<th align=\"right\"\
    >update</th>\n<th align=\"right\">scan</th>\n<th align=\"right\">R-M-W</th>\n\
    <th align=\"center\">distribution</th>\n<th align=\"center\">remarks</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td align=\"left\">A</td>\n<td align=\"left\">Update\
    \ heavy</td>\n<td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >B</td>\n<td align=\"left\">Read mostly</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">zipfian</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">C</td>\n<td align=\"left\">Read\
    \ only</td>\n<td align=\"right\">1</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\"></td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >D</td>\n<td align=\"left\">Read latest</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\">0.05</td>\n<td align=\"right\"></td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">latest</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">E</td>\n<td align=\"left\">Short\
    \ ranges</td>\n<td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"\
    right\"></td>\n<td align=\"right\">0.95</td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\">maxscanlength=100 random(uniform)</td>\n\
    </tr>\n<tr>\n<td align=\"left\">F</td>\n<td align=\"left\">Read-modify-write</td>\n\
    <td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.5</td>\n<td align=\"center\"\
    >zipfian</td>\n<td align=\"center\"></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-class-diagram-subset\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #class-diagram-subset\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>class diagram (subset)</h2>\n<div class=\"highlight highlight-source-mermaid\"\
    ><pre><span class=\"pl-k\">classDiagram</span>\n<span class=\"pl-k\">class</span>\
    \ <span class=\"pl-en\">DBFactory</span>\n<span class=\"pl-k\">class</span> <span\
    \ class=\"pl-en\">DB</span>\n<span class=\"pl-sg\">&lt;&lt;</span><span class=\"\
    pl-ent\">interface</span><span class=\"pl-sg\">&gt;&gt;</span> <span class=\"\
    pl-en\">DB</span>\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">HashtableDB</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">abstruct</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">HashtableDB</span>\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-en\">LockStlDB</span>\n<span class=\"\
    pl-k\">class</span> <span class=\"pl-en\">StringHashtable</span><span class=\"\
    pl-sg\">~</span><span class=\"pl-ent\">V</span><span class=\"pl-sg\">~</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">StringHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">KeyHashtable</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">KeyHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">FieldHashtable</span>\n\
    <span class=\"pl-sg\">&lt;&lt;</span><span class=\"pl-ent\">interface</span><span\
    \ class=\"pl-sg\">&gt;&gt;</span> <span class=\"pl-en\">FieldHashtable</span>\n\
    <span class=\"pl-k\">class</span> <span class=\"pl-en\">StlHashTable</span><span\
    \ class=\"pl-sg\">~</span><span class=\"pl-ent\">V</span><span class=\"pl-sg\"\
    >~</span>\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">StlHashTableKey</span>\
    \ <span class=\"pl-sg\">{</span>\n  <span class=\"pl-k\">std::unorderd_map</span><span\
    \ class=\"pl-sg\">~</span><span class=\"pl-ent\">String,FieldHashtable*</span><span\
    \ class=\"pl-sg\">~</span>\n<span class=\"pl-sg\">}</span>\n<span class=\"pl-k\"\
    >class</span> <span class=\"pl-en\">StlHashTableField</span> <span class=\"pl-sg\"\
    >{</span>\n  <span class=\"pl-k\">std::unorderd_map</span><span class=\"pl-sg\"\
    >~</span><span class=\"pl-ent\">String,const char*</span><span class=\"pl-sg\"\
    >~</span>\n<span class=\"pl-sg\">}</span>\n<span class=\"pl-k\">class</span> <span\
    \ class=\"pl-en\">LockStlHashtable</span><span class=\"pl-sg\">~</span><span class=\"\
    pl-ent\">T</span><span class=\"pl-sg\">~</span>\n<span class=\"pl-k\">class</span>\
    \ <span class=\"pl-en\">LockStlHashtableKey</span> <span class=\"pl-sg\">{</span>\n\
    \  <span class=\"pl-k\">std::mutex</span>\n<span class=\"pl-sg\">}</span>\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-en\">LockStlHashtableField</span>\
    \ <span class=\"pl-sg\">{</span>\n  <span class=\"pl-k\">std::mutex</span>\n<span\
    \ class=\"pl-sg\">}</span>\n\n<span class=\"pl-en\">DBFactory</span> <span class=\"\
    pl-k\">..&gt;</span> <span class=\"pl-en\">LockStlDB</span> <span class=\"pl-k\"\
    >:</span> <span class=\"pl-s\">create</span>\n<span class=\"pl-en\">LockStlDB</span>\
    \ <span class=\"pl-k\">*--</span> <span class=\"pl-en\">LockStlHashtableKey</span>\n\
    <span class=\"pl-en\">LockStlHashtableKey</span> <span class=\"pl-k\">o--</span>\
    \ <span class=\"pl-en\">LockStlHashtableField</span>\n<span class=\"pl-en\">LockStlDB</span>\
    \ <span class=\"pl-k\">..&gt;</span> <span class=\"pl-en\">LockStlHashtableField</span>\
    \ <span class=\"pl-k\">:</span> <span class=\"pl-s\">create</span>\n\n<span class=\"\
    pl-en\">DB</span> <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">HashtableDB</span>\n\
    <span class=\"pl-en\">HashtableDB</span> <span class=\"pl-k\">&lt;|..</span> <span\
    \ class=\"pl-en\">LockStlDB</span>\n<span class=\"pl-en\">StringHashtable</span>\
    \ <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">StlHashTable</span>\n\
    <span class=\"pl-en\">StlHashTable</span> <span class=\"pl-k\">&lt;|--</span><span\
    \ class=\"pl-en\">LockStlHashtable</span>\n\n<span class=\"pl-en\">StringHashtable</span>\
    \ <span class=\"pl-k\">..</span> <span class=\"pl-en\">FieldHashtable</span> <span\
    \ class=\"pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n<span class=\"\
    pl-en\">StringHashtable</span> <span class=\"pl-k\">..</span> <span class=\"pl-en\"\
    >KeyHashtable</span> <span class=\"pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n\
    <span class=\"pl-en\">StlHashTable</span> <span class=\"pl-k\">..</span> <span\
    \ class=\"pl-en\">StlHashTableKey</span> <span class=\"pl-k\">:</span> <span class=\"\
    pl-s\">instantiation</span>\n<span class=\"pl-en\">StlHashTable</span> <span class=\"\
    pl-k\">..</span> <span class=\"pl-en\">StlHashTableField</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n<span class=\"pl-en\"\
    >LockStlHashtable</span> <span class=\"pl-k\">..</span> <span class=\"pl-en\"\
    >LockStlHashtableKey</span> <span class=\"pl-k\">:</span> <span class=\"pl-s\"\
    >instantiation</span>\n<span class=\"pl-en\">LockStlHashtable</span> <span class=\"\
    pl-k\">..</span> <span class=\"pl-en\">LockStlHashtableField</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">instantiation</span>\n\n<span class=\"pl-en\"\
    >StlHashTableKey</span>  <span class=\"pl-k\">&lt;|--</span> <span class=\"pl-en\"\
    >LockStlHashtableKey</span>\n<span class=\"pl-en\">StlHashTableField</span>  <span\
    \ class=\"pl-k\">&lt;|--</span> <span class=\"pl-en\">LockStlHashtableField</span>\n\
    <span class=\"pl-en\">KeyHashtable</span> <span class=\"pl-k\">&lt;|..</span>\
    \ <span class=\"pl-en\">StlHashTableKey</span>\n<span class=\"pl-en\">FieldHashtable</span>\
    \ <span class=\"pl-k\">&lt;|..</span> <span class=\"pl-en\">StlHashTableField</span>\n\
    \n<span class=\"pl-en\">HashtableDB</span> <span class=\"pl-k\">..&gt;</span>\
    \ <span class=\"pl-en\">KeyHashtable</span> <span class=\"pl-k\">:</span> <span\
    \ class=\"pl-s\">use</span>\n<span class=\"pl-en\">HashtableDB</span> <span class=\"\
    pl-k\">..&gt;</span> <span class=\"pl-en\">FieldHashtable</span> <span class=\"\
    pl-k\">:</span> <span class=\"pl-s\">use</span></pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667533964.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<h1><a id=\"user-content-libpressio\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#libpressio\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>LibPressio</h1>\n<p><em>the stable version of this code is found at\
    \ <a href=\"https://github.com/CODARcode/libpressio\">at the CODARCode organization</a>\
    \ it is updated about anually</em></p>\n<p>Pressio is latin for compression. \
    \ LibPressio is a C++ library with C compatible bindings to abstract between different\
    \ lossless and lossy compressors and their configurations.  It solves the problem\
    \ of having to having to write separate application level code for each lossy\
    \ compressor that is developed.  Instead, users write application level code using\
    \ LibPressio, and the library will make the correct underlying calls to the compressors.\
    \  It provides interfaces to represent data, compressors settings, and compressors.</p>\n\
    <p>Documentation for the <code>master</code> branch can be <a href=\"https://robertu94.github.io/libpressio/\"\
    \ rel=\"nofollow\">found here</a></p>\n<h1><a id=\"user-content-using-libpressio\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-libpressio\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using LibPressio</h1>\n<p>Example\
    \ using the CLI from <a href=\"https://github.com/robertu94/pressio-tools\"><code>pressio-tools</code></a>\n\
    We also have C, C++, Rust, Julia, and Python bindings.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pressio -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<h2><a id=\"user-content-getting-started\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#getting-started\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>After skimming\
    \ the example, LibPressio has 6 major headers that you will need to use:</p>\n\
    <table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>pressio.h</code></td>\n<td>Error reporting and aquiring handles\
    \ to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<h2><a id=\"user-content-supported-compressors-and-metrics\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#supported-compressors-and-metrics\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ Compressors and Metrics</h2>\n<p>Libpressio provides a number of builtin compressor\
    \ and metrics modules.\nAll of these are <strong>disabled by default</strong>.\n\
    They can be enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code>\
    \ variable to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information\
    \ on writing a compressor plugin see [Writing a Compressor Plugin](@ref writingacompressor)\n\
    For information on writing a metrics plugin see [Writing a Metrics Plugin](@ref\
    \ writingametric)</p>\n<h3><a id=\"user-content-compressor-plugins\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#compressor-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compressor Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the [compressor settings page](@ref compressors)\
    \ for information on how to configure them.</p>\n<h3><a id=\"user-content-metrics-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#metrics-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Metrics Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the [metrics results page](@ref metrics)\
    \ for information on what they produce</p>\n<h3><a id=\"user-content-io-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#io-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>IO Plugins</h3>\n<p>1st party\
    \ compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the [io settings page](@ref io) for information\
    \ on how to configure them</p>\n<h1><a id=\"user-content-installation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Installation</h1>\n<h2><a id=\"user-content-installing-libpressio-using-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-libpressio-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ LibPressio using Spack</h2>\n<p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\"\
    >spack</a>.  This example will install libpressio with only the SZ3 plugin.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<h2><a id=\"user-content-doing-a-development-build-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#doing-a-development-build-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Doing a\
    \ development build with spack</h2>\n<p>The easiest way to do a development build\
    \ of libpressio is to use Spack envionments.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> one time setup: create\
    \ an envionment</span>\nspack env create -d mydevenviroment\nspack env activate\
    \ mydevenvionment\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one time\
    \ setup: install libpressio-tools and checkout </span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> libpressio for development</span>\nspack add libpressio-tools\n\
    spack develop libpressio@git.master\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> compile and install (repeat as needed)</span>\nspack install </pre></div>\n\
    <h2><a id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#manual-installation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Manual Installation</h2>\n<p>Libpressio unconditionally\
    \ requires:</p>\n<ul>\n<li><code>cmake</code></li>\n<li><code>pkg-config</code></li>\n\
    <li><a href=\"https://github.com/robertu94/std_compat\"><code>std_compat</code></a></li>\n\
    <li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code> or later</li>\n<li>\n<code>clang-7.0.0</code>\
    \ or later using either <code>libc++</code> or <code>libstdc++</code>.  Beware\
    \ that system libraries may need to be recompiled with <code>libc++</code> if\
    \ using <code>libc++</code>\n</li>\n</ul>\n</li>\n</ul>\n<p>Dependency versions\
    \ and optional dependencies are documented <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<h2><a id=\"user-content-configuring-libpressio-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-libpressio-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ LibPressio Manually</h2>\n<p>LibPressio uses a fairly standard CMake buildsystem.\n\
    For more information on <a href=\"https://robertu94.github.io/learning/cmake\"\
    \ rel=\"nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration\
    \ options for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\n\
    For information on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<h1><a id=\"user-content-api-stability\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#api-stability\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>API Stability</h1>\n<p>Please refer to <a href=\"\
    docs/stability.md\">docs/stability.md</a>.</p>\n<h1><a id=\"user-content-how-to-contribute\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-contribute\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to Contribute</h1>\n<p>Please\
    \ refer to <a href=\"CONTRIBUTORS.md\">CONTRIBUTORS.md</a> for a list of contributors,\
    \ sponsors, and contribution guidelines.</p>\n<h1><a id=\"user-content-bug-reports\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#bug-reports\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Bug Reports</h1>\n<p>Please files\
    \ bugs to the Github Issues page on the CODARCode libpressio repository.</p>\n\
    <p>Please read this post on <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\"\
    \ rel=\"nofollow\">how to file a good bug report</a>.\_ After reading this post,\
    \ please provide the following information specific to libpressio:</p>\n<ul>\n\
    <li>Your OS version and distribution information, usually this can be found in\
    \ <code>/etc/os-release</code>\n</li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n\
    </li>\n<li>the version of each of libpressio's dependencies listed in the README\
    \ that you have installed. Where possible, please provide the commit hashes.</li>\n\
    </ul>\n<h1><a id=\"user-content-citing-libpressio\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#citing-libpressio\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Citing LibPressio</h1>\n<p>If you find LibPressio\
    \ useful, please cite this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n\
    \  title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n\
    \  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di,\
    \ Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on\
    \ Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n\
    \  year={2021},\n  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 16
  subscribers_count: 5
  topics: []
  updated_at: 1673367032.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<h1><a id="user-content-roibin-sz-experiments" class="anchor" aria-hidden="true"
    href="#roibin-sz-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>ROIBIN-SZ
    Experiments</h1>

    <h2><a id="user-content-system-information" class="anchor" aria-hidden="true"
    href="#system-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>System
    Information</h2>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <h2><a id="user-content-where-is-the-implementation-of-roibin-sz3" class="anchor"
    aria-hidden="true" href="#where-is-the-implementation-of-roibin-sz3"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Where is the implementation of ROIBIN-SZ3?</h2>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <h3><a id="user-content-obtaining-data" class="anchor" aria-hidden="true" href="#obtaining-data"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining Data</h3>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <h3><a id="user-content-quality-assessment" class="anchor" aria-hidden="true"
    href="#quality-assessment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quality
    Assessment</h3>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <h3><a id="user-content-container-install-for-ease-of-setup" class="anchor" aria-hidden="true"
    href="#container-install-for-ease-of-setup"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Container Install (for ease of setup)</h3>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <h4><a id="user-content-singularity" class="anchor" aria-hidden="true" href="#singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h4>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <h4><a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h4>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <h3><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    href="#building-the-container"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <h3><a id="user-content-manual-install-for-scale" class="anchor" aria-hidden="true"
    href="#manual-install-for-scale"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    Install (for scale)</h3>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <h2><a id="user-content-running-the-experiments" class="anchor" aria-hidden="true"
    href="#running-the-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Experiments</h2>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <h3><a id="user-content-example-output" class="anchor" aria-hidden="true" href="#example-output"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example Output</h3>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <h2><a id="user-content-results-for-figures" class="anchor" aria-hidden="true"
    href="#results-for-figures"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results
    for Figures</h2>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1648861627.0
robertu94/sz-zfp-zchecker:
  data_format: 2
  description: container for the ISC/SC compression tutorial
  filenames:
  - spack.yaml
  full_name: robertu94/sz-zfp-zchecker
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1652997619.0
salotz/scoot:
  data_format: 2
  description: Boost/STL for Scopes
  filenames:
  - spack.yaml
  full_name: salotz/scoot
  latest_release: null
  readme: "<h1><a id=\"user-content-scoot\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#scoot\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>scoot</h1>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The module is under <code>src/scoot</code>.\
    \ You can copy this subtree into your\nproject and then add it to the <code>package.path</code>\
    \ in your Scopes\n<code>_project.sc</code> file.</p>\n<h3><a id=\"user-content-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#with-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>With Spack</h3>\n<p>This module\
    \ is available as the <code>scoot</code> package in the\n<a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> repository. This will pull in the necessary dependencies\nincluding\
    \ Scopes.</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spack install\
    \ scoot</pre></div>\n<p>See the <a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> documentation for more best practices of installing.</p>\n<h2><a\
    \ id=\"user-content-development-environment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development-environment\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Development Environment</h2>\n<p>We use <a href=\"\
    https://spack.io/\" rel=\"nofollow\">Spack</a> to install dependencies. First\
    \ install Spack.</p>\n<p>Then you'll need our custom repo of build recipes:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  mkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">`</span>/.spack/repos</span>\n<span class=\"pl-s\"\
    >  git clone git@github.com:salotz/snailpacks.git <span class=\"pl-pds\">`</span></span>/.spack/repos/snailpacks\n\
    \  spack repo add <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc., this will create this and\ninstall the packages:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  make init</pre></div>\n\
    <p>Then you can activate the environment to get started:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  spacktivate <span class=\"pl-c1\">.</span></pre></div>\n\
    <p>Run some commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> run the sanity entrypoint</span>\n\
    make sanity\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> run the tests</span>\n\
    make <span class=\"pl-c1\">test</span></pre></div>\n<p>To exit the environment\
    \ (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1661112922.0
salotz/scopes-lib_copier-template:
  data_format: 2
  description: Copier template for a Scopes library
  filenames:
  - template/spack.yaml
  full_name: salotz/scopes-lib_copier-template
  latest_release: null
  readme: "<h1><a id=\"user-content-project-template-for-a-scopes-lang-library\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#project-template-for-a-scopes-lang-library\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Project\
    \ Template for a Scopes Lang Library</h1>\n<p>This is a project template generator\
    \ and updater using the\n<a href=\"https://github.com/copier-org/copier/\">copier</a>\
    \ tool for creating libraries for the <a href=\"http://scopes.rocks\" rel=\"nofollow\"\
    >Scopes</a> programming language.</p>\n<p>Please install from the latest copier\
    \ for this to work, not the latest\nstable release. Currently I am using\n<a href=\"\
    https://github.com/pypa/pipx\">pipx</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pipx install copier</pre></div>\n<h2><a id=\"user-content-generating-and-updating-a-project\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#generating-and-updating-a-project\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Generating\
    \ and Updating a Project</h2>\n<p>Then you can generate your project:</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>copier <span class=\"pl-s\"\
    ><span class=\"pl-pds\">'</span>gh:salotz/scopes-lib_copier-template<span class=\"\
    pl-pds\">'</span></span> name-of-folder</pre></div>\n<p>This should generate something\
    \ like the following (<code>repo_name = my-lib</code>):</p>\n<pre><code>name-of-folder\n\
    \u251C\u2500\u2500 __env.sc\n\u251C\u2500\u2500 Makefile\n\u251C\u2500\u2500 README.md\n\
    \u251C\u2500\u2500 spack.yaml\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500\
    \ my-lib\n        \u251C\u2500\u2500 init.sc\n        \u2514\u2500\u2500 ...\n\
    </code></pre>\n<p>You can update the project with:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> name-of-folder\n\
    copier update</pre></div>\n<p>See documentation of copier for more details.</p>\n\
    <h2><a id=\"user-content-development-environment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development-environment\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Development Environment</h2>\n<p>See the docs in <code>template/README.md.jinja</code>\
    \ that will be generated for\neach project.</p>\n<h2><a id=\"user-content-libraries-using-this-template\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#libraries-using-this-template\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Libraries\
    \ Using this Template</h2>\n<ul>\n<li><a href=\"https://github.com/salotz/raylib-scopes\"\
    >scopes-raylib</a></li>\n<li><a href=\"https://github.com/salotz/scopes-chipmunk2d\"\
    >scopes-chipmunk2d</a></li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - copier-template
  - scopes-lang
  updated_at: 1648781021.0
sayefsakin/auto_profiler:
  data_format: 2
  description: null
  filenames:
  - py_src/spack.yaml
  full_name: sayefsakin/auto_profiler
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1659512207.0
simonpintarelli/acclapack-tests:
  data_format: 2
  description: null
  filenames:
  - spack-envs/cuda/spack.yaml
  - spack-envs/rocm/spack.yaml
  full_name: simonpintarelli/acclapack-tests
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667393188.0
spack/gitlab-runners:
  data_format: 2
  description: Images used to run Gitlab pipelines in the cloud
  filenames:
  - spack.yaml
  full_name: spack/gitlab-runners
  latest_release: v2022-03-21
  readme: '<p>This repository contains images that are used to run Gitlab pipelines
    to validate PRs in Spack.</p>

    <p>The recipes have been modified from ones in: <a href="https://github.com/UO-OACISS/e4s">https://github.com/UO-OACISS/e4s</a></p>

    '
  stargazers_count: 1
  subscribers_count: 8
  topics: []
  updated_at: 1675192423.0
sundials-codes/sundials-manyvector-demo:
  data_format: 2
  description: Demonstration application for Multirate+ManyVector capabilities
  filenames:
  - docker/spack-latest.yaml
  - spack/spack-summit.yaml
  - docker/spack-develop.yaml
  full_name: sundials-codes/sundials-manyvector-demo
  latest_release: null
  readme: "<h1><a id=\"user-content-sundials-manyvectormultirate-demonstration-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#sundials-manyvectormultirate-demonstration-code\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SUNDIALS\
    \ ManyVector+Multirate Demonstration Code</h1>\n<p>[Note: this project is in active\
    \ development.]</p>\n<p>This is a <a href=\"https://github.com/LLNL/sundials\"\
    >SUNDIALS</a>-based demonstration\napplication to assess and demonstrate the large-scale\
    \ parallel performance of\nnew capabilities that have been added to SUNDIALS in\
    \ recent years. Namely:</p>\n<ol>\n<li>\n<p>The new SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html#the-nvector-mpimanyvector-module\"\
    \ rel=\"nofollow\">MPIManyVector</a>\nimplementation, that enables flexibility\
    \ in how a solution data is\npartitioned across computational resources e.g.,\
    \ CPUs and GPUs.</p>\n</li>\n<li>\n<p>The new <a href=\"https://sundials.readthedocs.io/en/latest/arkode/index.html\"\
    \ rel=\"nofollow\">ARKODE</a>\nmultirate integration module, MRIStep, allowing\
    \ high-order accurate\ncalculations that subcycle \"fast\" processes within \"\
    slow\" ones.</p>\n</li>\n<li>\n<p>The new flexible SUNDIALS <a href=\"https://sundials.readthedocs.io/en/latest/sunlinsol/index.html\"\
    \ rel=\"nofollow\">SUNLinearSolver</a>\ninterfaces, to enable streamlined use\
    \ of problem specific and scalable\nlinear solver libraries e.g., SuiteSparse\
    \ and MAGMA.</p>\n</li>\n</ol>\n<h2><a id=\"user-content-model-equations\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#model-equations\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Model Equations</h2>\n<p>This code\
    \ simulates a 3D nonlinear inviscid compressible Euler equation with\nadvection\
    \ and reaction of chemical species,</p>\n<p>$$w_t = -\\nabla\\cdot F(w) + G(X,t,w),$$</p>\n\
    <p>for independent variables $(X,t) = (x,y,z,t) \\in \\Omega \\times [t_0, t_f]$\n\
    where the spatial domain is a three-dimensional cube,\n$\\Omega = [x_l, x_r] \\\
    times [y_l, y_r] \\times [z_l, z_r]$.</p>\n<p>The differential equation is completed\
    \ using initial condition\n$w(X,t_0) = w_0(X)$ and face-specific boundary conditions\
    \ may be periodic (0),\nhomogeneous Neumann (1), homogeneous Dirichlet (2), or\
    \ reflecting (3) under the\nrestriction that if any boundary is set to \"periodic\"\
    \ then the opposite face\nmust also indicate a periodic condition.</p>\n<p>The\
    \ system state vector $w$ is</p>\n<p>$$w = \\begin{bmatrix} \\rho &amp; \\rho\
    \ v_x &amp; \\rho v_y &amp; \\rho v_z &amp; e_t &amp; \\mathbf{c} \\end{bmatrix}^T\
    \ = \\begin{bmatrix} \\rho &amp; m_x &amp; m_y &amp; m_z &amp; e_t &amp; \\mathbf{c}\
    \ \\end{bmatrix}^T$$</p>\n<p>corresponding to the density, momentum in the x,\
    \ y, and z directions, total\nenergy per unit volume, and any number of chemical\
    \ densities\n$\\mathbf{c}\\in\\mathbb{R}^{nchem}$ that are advected along with\
    \ the fluid. The\nfluxes are given by</p>\n<p>$$F_x(w) = \\begin{bmatrix} \\rho\
    \ v_x &amp; \\rho v_x^2 + p &amp; \\rho v_x v_y &amp; \\rho v_x v_z &amp; v_x\
    \ (e_t+p) &amp; \\mathbf{c} v_x \\end{bmatrix}^T,$$</p>\n<p>$$F_y(w) = \\begin{bmatrix}\
    \ \\rho v_y &amp; \\rho v_x v_y &amp; \\rho v_y^2 + p &amp; \\rho v_y v_z &amp;\
    \ v_y (e_t+p) &amp; \\mathbf{c} v_y \\end{bmatrix}^T,$$</p>\n<p>$$F_z(w) = \\\
    begin{bmatrix} \\rho v_z &amp; \\rho v_x v_z &amp; \\rho v_y v_z &amp; \\rho v_z^2\
    \ + p &amp; v_z (e_t+p) &amp; \\mathbf{c} v_z \\end{bmatrix}^T.$$</p>\n<p>The\
    \ external force $G(X,t,w)$ is test-problem-dependent, and the ideal gas\nequation\
    \ of state gives $p = \\frac{R}{c_v}(e_t - \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2))$\n\
    and $e_t = \\frac{pc_v}{R} + \\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$\nor equivalently,\
    \ $p = (\\gamma-1) (e_t - \\frac{\\rho}{2} (v_x^2 + v_y^2 + v_z^2))$\nand $e_t\
    \ = \\frac{p}{\\gamma - 1}\\frac{\\rho}{2}(v_x^2 + v_y^2 + v_z^2)$.</p>\n<p>We\
    \ have the physical parameters:</p>\n<ul>\n<li>\n<p>$R$ is the specific ideal\
    \ gas constant (287.14 J/kg/K),</p>\n</li>\n<li>\n<p>$c_v$ is the specific heat\
    \ capacity at constant volume (717.5 J/kg/K),</p>\n</li>\n<li>\n<p>$\\gamma =\
    \ c_p/c_v = 1 + R/c_v$ is the ratio of specific heats (1.4),</p>\n</li>\n</ul>\n\
    <p>corresponding to air (predominantly an ideal diatomic gas). The speed\nof sound\
    \ in the gas is then given by $c = \\sqrt{\\dfrac{\\gamma p}{\\rho}}$.</p>\n<p>The\
    \ fluid variables above are non-dimensionalized; in standard SI units\nthese would\
    \ be:</p>\n<ul>\n<li>\n<p>$[\\rho] = kg / m^3$,</p>\n</li>\n<li>\n<p>$[v_x] =\
    \ [v_y] = [v_z] = m/s$, which implies $[m_x] = [m_y] = [m_z] = kg / m^2 / s$</p>\n\
    </li>\n<li>\n<p>$[e_t] = kg / m / s^2$, and</p>\n</li>\n<li>\n<p>$[\\mathbf{c}_i]\
    \ = kg / m^3$</p>\n</li>\n</ul>\n<p>Note: the fluid portion of the description\
    \ above follows the presentation\n<a href=\"https://www.theoretical-physics.net/dev/fluid-dynamics/euler.html\"\
    \ rel=\"nofollow\">here</a>\nin sections 7.3.1 - 7.3.3.</p>\n<h2><a id=\"user-content-discretization\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#discretization\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Discretization</h2>\n<p>We discretize\
    \ this problem using the method of lines, where we first semi-discretize\nin space\
    \ using a regular finite volume grid with dimensions <code>nx</code> x <code>ny</code>\
    \ x <code>nz</code>, with\nfluxes at cell faces calculated using a 5th-order FD-WENO\
    \ reconstruction.  MPI\nparallelization is achieved using a standard 3D domain\
    \ decomposition, using <code>nprocs</code>\nMPI ranks, with layout <code>npx</code>\
    \ x <code>npy</code> x <code>npz</code> defined automatically via the\n<code>MPI_Dims_create</code>\
    \ utility routine.  The minimum size for any dimension is 3, so\nto run a two-dimensional\
    \ test in the yz-plane, one could specify <code>nx = 3</code> and\n<code>ny =\
    \ nz = 200</code>.  When run in parallel, only \"active\" spatial dimensions (those\n\
    with extent greater than 3) will be parallelized.</p>\n<p>The fluid fields $\\\
    rho$, $m_x$, $m_y$, $m_z$, and $e_t$ are stored in separate serial\n<code>N_Vector</code>\
    \ objects on each MPI rank. The chemical species at all spatial locations over\n\
    each MPI rank are collocated into a single serial or RAJA <code>N_Vector</code>\
    \ object when\nrunning on the CPU or GPU respectively. The five fluid vectors\
    \ and the chemical\nspecies vector are combined together to form the full \"solution\"\
    \ vector $w$ using\nthe <code>MPIManyVector</code> <code>N_Vector</code> module.</p>\n\
    <p>After spatial semi-discretization, we are faced with a large IVP system,</p>\n\
    <p>$$w'(t) = f_1(w) + f_2(w), \\quad w(t_0)=w_0,$$</p>\n<p>where $f_1(w)$ and\
    \ $f_2(w)$ contain the spatially discretized forms of\n$-\\nabla\\cdot F(w)$ and\
    \ $G(X,t,w)$, respectively.</p>\n<p>For non-reactive flows, the resulting initial-value\
    \ problem is evolved in time\nusing an adaptive step explicit Runge-Kutta method\
    \ from the ARKStep module in\nARKODE. For problems involving (typically stiff)\
    \ chemical reactions, the problem\nmay be solved using one of two approaches.</p>\n\
    <ol>\n<li>\n<p>It may be treated as a multirate initial-value problem, that is\
    \ solved using\nthe MRIStep module in ARKODE, wherein the gas dynamics equations\
    \ are evolved\nexplicitly at the slow time scale, while the chemical kinetics\
    \ are evolved\nat a faster time scale using a temporally-adaptive, diagonally-implicit\n\
    Runge-Kutta method from the ARKStep module.</p>\n</li>\n<li>\n<p>It may be treated\
    \ using mixed implicit-explicit (IMEX) methods at a single\ntime scale.  Here,\
    \ the gas dynamics equations are treated explicitly, while\nthe chemical kinetics\
    \ are treated implicitly, using an additive Runge-Kutta\nmethod from the ARKStep\
    \ module.</p>\n</li>\n</ol>\n<p>For (1) we use SUNDIALS' modified Newton solver\
    \ to handle the global nonlinear\nalgebraic systems arising at each implicit stage\
    \ of each time step.  Since only\n$f_2$ is treated implicitly and the reactions\
    \ are purely local in space, the\nNewton linear systems are block-diagonal. As\
    \ such, we provide a custom\n<code>SUNLinearSolver</code> implementation that\
    \ solves each MPI rank-local linear system\nindependently. The portion of the\
    \ Jacobian matrix on each rank is itself\nblock-diagonal. We further leverage\
    \ this structure by solving each rank-local\nlinear system using either the sparse\
    \ KLU (CPU-only) or batched dense MAGMA\n(GPU-enabled) SUNDIALS <code>SUNLinearSolver</code>\
    \ implementations.</p>\n<p>The multirate approach (2) can leverage the structure\
    \ of $f_2$ at a higher\nlevel. Since the MRI method applied to this problem evolves\
    \ \"fast\" sub-problems\nof the form</p>\n<p>$$v'(t) = f_2(t,v) + r_i(t), \\quad\
    \ i=2,\\ldots,s,$$</p>\n<p>and all MPI communication necessary to construct the\
    \ forcing functions, $r_i(t)$,\nhas already been performed, each sub-problem consists\
    \ of <code>nx</code> x <code>ny</code> x <code>nz</code>\nspatially-decoupled\
    \ fast IVPs. We construct a custom fast integrator that groups\nall the independent\
    \ fast IVPs on an MPI rank together as a single system evolved\nusing a rank-local\
    \ ARKStep instance.  The code for this custom integrator itself\nis minimal, primarily\
    \ consisting of steps to access the local subvectors in $w$\non a given MPI rank\
    \ and wrapping them in MPI-unaware ManyVectors provided to the\nlocal ARKStep\
    \ instance. The collection of independent local IVPs also leads to a\nblock diagonal\
    \ Jacobian, and we again utilize the <code>SUNLinearSolver</code> modules listed\n\
    above for linear systems that arise within the modified Newton iteration.</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The following steps describe how to build the\
    \ demonstration code in a Linux or\nOS X environment.</p>\n<h3><a id=\"user-content-gettting-the-code\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#gettting-the-code\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Gettting the Code</h3>\n<p>To\
    \ obtain the code, clone this repository with Git:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  git clone https://github.com/sundials-codes/sundials-manyvector-demo.git</pre></div>\n\
    <h3><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Requirements</h3>\n<p>To compile the code you will need:</p>\n<ul>\n\
    <li>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\">CMake</a> 3.20 or newer</p>\n\
    </li>\n<li>\n<p>modern C and C++ compilers</p>\n</li>\n<li>\n<p>the NVIDIA <a\
    \ href=\"https://developer.nvidia.com/cuda-toolkit\" rel=\"nofollow\">CUDA Toolkit</a>\
    \ (when\nusing the CUDA backend)</p>\n</li>\n<li>\n<p>an MPI library e.g., <a\
    \ href=\"https://www.open-mpi.org/\" rel=\"nofollow\">OpenMPI</a>,\n<a href=\"\
    https://www.mpich.org/\" rel=\"nofollow\">MPICH</a>, etc.</p>\n</li>\n<li>\n<p>the\
    \ <a href=\"https://www.hdfgroup.org/\" rel=\"nofollow\">HDF5</a> high-performance\
    \ data management and\nstorage suite</p>\n</li>\n<li>\n<p>the <a href=\"https://github.com/LLNL/RAJA\"\
    >RAJA</a> performance portability library</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://computing.llnl.gov/projects/sundials\" rel=\"nofollow\">SUNDIALS</a> library\
    \ of time\nintegrators and nonlinear solvers</p>\n</li>\n<li>\n<p>the <a href=\"\
    https://people.engr.tamu.edu/davis/suitesparse.html\" rel=\"nofollow\">SuiteSparse</a>\
    \ library\nof sparse direct linear solvers (when using a CPU backend)</p>\n</li>\n\
    <li>\n<p>the <a href=\"https://icl.utk.edu/magma/\" rel=\"nofollow\">MAGMA</a>\
    \ dense linear solver library (when\nusing a GPU backend)</p>\n</li>\n</ul>\n\
    <h4><a id=\"user-content-installing-dependencies-with-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#installing-dependencies-with-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing Dependencies with\
    \ Spack</h4>\n<p>Many of the above dependencies can be installed using the\n<a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> package manager. For information\
    \ on using Spack see\nthe getting started <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#getting-started\"\
    \ rel=\"nofollow\">guide</a>.\nThe instructions below were formulated from Spack\
    \ v0.19.0, although newer versions should also work.</p>\n<p>Once Spack is setup,\
    \ we recommend creating a Spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html#\"\
    \ rel=\"nofollow\">environment</a>\nwith the required dependencies e.g., on a\
    \ system with Pascal GPUs and CUDA\n11.4.2 installed:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack env create --with-view <span class=\"pl-k\"\
    >~</span>/views/sundials-demo sundials-demo\nspack env activate sundials-demo\n\
    spack add sundials@6.2.0 +openmp +mpi +logging-mpi +klu +magma +raja +cuda cuda_arch=60\
    \ ^cuda@11.4.2 ^magma@2.6.1 +cuda cuda_arch=60 ^raja@0.13.0 +cuda cuda_arch=60\
    \ ^suite-sparse@5.8.1\nspack add hdf5@1.10.7 +hl +mpi\nspack install</pre></div>\n\
    <p>To assist in building the dependencies on select systems the <a href=\"./spack\"\
    >spack</a>\ndirectory contains environment files leveraging software already available\
    \ on\nthe system. For example, on the OLCF Summit system:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>module load gcc/10.2.0 cuda/11.4.2 cmake/3.21.3\n\
    <span class=\"pl-c1\">cd</span> spack\nspack env create sundials-demo spack-summit.yaml\n\
    spack env activate sundials-demo\nspack install</pre></div>\n<h4><a id=\"user-content-using-docker-containers\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-docker-containers\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Docker\
    \ Containers</h4>\n<p>It also possible to use the Docker containers from the <a\
    \ href=\"https://github.com/orgs/sundials-codes/packages?repo_name=sundials-manyvector-demo\"\
    >GitHub Container Registry</a>\nwith the necessary dependencies preinstalled for\
    \ CPU-only testing. Two images\nare provided:</p>\n<ul>\n<li>\n<p>sundials-demo-spack-latest\
    \ -- based on the latest Spack release (currently\nv0.19.0)</p>\n</li>\n<li>\n\
    <p>sundials-demo-spack-develop -- based on the Spack develop branch and updated\n\
    monthly</p>\n</li>\n</ul>\n<p>Pull the image(s) using <a href=\"https://www.docker.com/\"\
    \ rel=\"nofollow\">Docker</a> (or <a href=\"https://podman.io\" rel=\"nofollow\"\
    >Podman</a>).\nFor example, the <code>run</code> command below will pull the image\
    \ and start the container\nand the <code>exec</code> command will start a bash\
    \ shell inside the container.</p>\n<pre><code>docker run -t -d --name sundialsci-demo-spack-latest\
    \ ghcr.io/sundials-codes/sundials-demo-spack-latest:spack-latest\ndocker exec\
    \ -it sundials-demo-spack-lateset bash\n</code></pre>\n<p>Then clone this repository\
    \ with Git and configure/build the code as described\nbelow. The Spack installed\
    \ dependencies are available from the <code>/opt/view</code>\ndirectory.</p>\n\
    <h3><a id=\"user-content-configuration-options\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#configuration-options\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Configuration Options</h3>\n<p>Once the necessary\
    \ dependencies are installed, the following CMake variables can\nbe used to configure\
    \ the demonstration code build:</p>\n<ul>\n<li>\n<p><code>CMAKE_INSTALL_PREFIX</code>\
    \ - the path where executables and input files should be\ninstalled e.g., <code>my/install/path</code>.\
    \ The executables will be installed in the\n<code>bin</code> directory and input\
    \ files in the <code>tests</code> directory under the given path.</p>\n</li>\n\
    <li>\n<p><code>CMAKE_C_COMPILER</code> - the C compiler to use e.g., <code>mpicc</code>.\
    \ If not set, CMake\nwill attempt to automatically detect the C compiler.</p>\n\
    </li>\n<li>\n<p><code>CMAKE_C_FLAGS</code> - the C compiler flags to use e.g.,\
    \ <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_C_STANDARD</code> - the\
    \ C standard to use, defaults to <code>99</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_COMPILER</code>\
    \ - the C++ compiler to use e.g., <code>mpicxx</code>. If not set,\nCMake will\
    \ attempt to automatically detect the C++ compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_FLAGS</code>\
    \ - the C++ flags to use e.g., <code>-g -O2</code>.</p>\n</li>\n<li>\n<p><code>CMAKE_CXX_STANDARD</code>\
    \ - the C++ standard to use, defaults to <code>11</code>.</p>\n</li>\n<li>\n<p><code>RAJA_ROOT</code>\
    \ - the root directory of the RAJA installation, defaults to the\nvalue of the\
    \ <code>RAJA_ROOT</code> environment variable. If not set, CMake will attempt\n\
    to automatically locate a RAJA install on the system.</p>\n</li>\n<li>\n<p><code>RAJA_BACKEND</code>\
    \ - the RAJA backend to use with the demonstration code, defaults\nto <code>SERIAL</code>.\
    \ Supported options are <code>SERIAL</code>, <code>OPENMP</code> and <code>CUDA</code>.\
    \  Note that this\nonly applies to on-node parallelism that is used when evaluating\
    \ chemistry-based\ncomponents associated with $f_2(w)$.</p>\n</li>\n<li>\n<p><code>SUNDIALS_ROOT</code>\
    \ - the root directory of the SUNDIALS installation, defaults to\nthe value of\
    \ the <code>SUNDIALS_ROOT</code> environment variable. If not set, CMake will\n\
    attempt to automatically locate a SUNDIALS install on the system.</p>\n</li>\n\
    <li>\n<p><code>ENABLE_HDF5</code> - build with HDF5 I/O support, defaults to <code>OFF</code>.</p>\n\
    </li>\n<li>\n<p><code>HDF5_ROOT</code> - the root directory of the HDF5 installation,\
    \ defaults to the\nvalue of the <code>HDF5_ROOT</code> environment variable. If\
    \ not set, CMake will attempt\nto automatically locate a HDF5 install on the system.</p>\n\
    </li>\n</ul>\n<p>When RAJA is installed with CUDA support enabled, the following\
    \ additional\nvariables may also be set:</p>\n<ul>\n<li>\n<p><code>CMAKE_CUDA_COMPILER</code>\
    \ - the CUDA compiler to use e.g., <code>nvcc</code>. If not set,\nCMake will\
    \ attempt to automatically detect the CUDA compiler.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_FLAGS</code>\
    \ - the CUDA compiler flags to use.</p>\n</li>\n<li>\n<p><code>CMAKE_CUDA_ARCHITECTURES</code>\
    \ - the CUDA architecture to target e.g., <code>70</code>.</p>\n</li>\n</ul>\n\
    <h3><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h3>\n\
    <p>In-source builds are not permitted, as such the code should be configured and\n\
    built from a separate build directory e.g.,</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  <span class=\"pl-c1\">cd</span> sundials-manyvector-demo\n  mkdir build\n\
    \  <span class=\"pl-c1\">cd</span> build\n  cmake ../. \\\n    -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>[install-path]<span class=\"\
    pl-pds\">\"</span></span> \\\n    -DRAJA_BACKEND=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>SERIAL<span class=\"pl-pds\">\"</span></span> \\\n    -DENABLE_HDF5=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DHDF5_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span> \\\n    -DRAJA_ROOT=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>[spack-view-path]<span class=\"pl-pds\">\"</span></span>\
    \ \\\n    -DSUNDIALS_ROOT=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[spack-view-path]<span\
    \ class=\"pl-pds\">\"</span></span>\n  make\n  make install</pre></div>\n<p>where\
    \ <code>[install-path]</code> is the path to where the binary and test input files\n\
    should be installed and <code>[spack-view-path]</code> is the path to the Spack\
    \ environment\nview, <code>~/views/sundials-demo</code> when following the Spack\
    \ instructions above or\n<code>/opt/view</code> when using the Docker containers.</p>\n\
    <h2><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n\
    <p>Several test cases are included with the code and the necessary input files\
    \ for\neach case are contained in the subdirectories within the <a href=\"./tests\"\
    >tests</a>\ndirectory. Each input file is internally documented to discuss all\
    \ possible\ninput parameters (in case some have been added since this <code>README</code>\
    \ was last\nupdated).</p>\n<p>The input files contain parameters to set up the\
    \ physical problem:</p>\n<ul>\n<li>\n<p>spatial domain, $\\Omega$ -- <code>xl</code>,\
    \ <code>xr</code>, <code>yl</code>, <code>yr</code>, <code>zl</code>, <code>zr</code></p>\n\
    </li>\n<li>\n<p>time interval, $[t_0, t_f]$ -- <code>t0</code>, <code>tf</code></p>\n\
    </li>\n<li>\n<p>the ratio of specific heats, $\\gamma$ -- <code>gamma</code></p>\n\
    </li>\n<li>\n<p>spatial discretization dimensions -- <code>nx</code>, <code>ny</code>,\
    \ <code>nz</code></p>\n</li>\n<li>\n<p>boundary condition types -- <code>xlbc</code>,\
    \ <code>xrbc</code>, <code>ylbc</code>, <code>yrbc</code>, <code>zlbc</code>,\
    \ <code>zrbc</code></p>\n</li>\n</ul>\n<p>Parameters to control the execution\
    \ of the code:</p>\n<ul>\n<li>\n<p>desired CFL fraction -- <code>cfl</code> (if\
    \ set to zero, then the time step is chosen purely using temporal adaptivity).</p>\n\
    </li>\n<li>\n<p>number of desired solution outputs -- <code>nout</code></p>\n\
    </li>\n<li>\n<p>a flag to enable optional output of RMS averages for each field\
    \ at the frequency specified via <code>nout</code> -- <code>showstats</code></p>\n\
    </li>\n</ul>\n<p>Numerous parameters are also provided to control how time integration\
    \ is\nperformed (these are passed directly to ARKODE). For further information\
    \ on the\nARKODE solver parameters and the meaning of individual values, see the\n\
    <a href=\"https://sundials.readthedocs.io/en/latest/index.html\" rel=\"nofollow\"\
    >ARKODE documentation</a>.</p>\n<p>To specify an input file to the executable,\
    \ the input filename should be\nprovided using the <code>-f</code> flag e.g.,</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> -f <span class=\"pl-k\">&lt;</span>input_file<span\
    \ class=\"pl-k\">&gt;</span></pre></div>\n<p>Additionally, any input parameters\
    \ may also be specified on the\ncommand line e.g.,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  <span class=\"pl-k\">&lt;</span>executable<span\
    \ class=\"pl-k\">&gt;</span> --nx=100 --ny=100 --nz=400</pre></div>\n<p>For example,\
    \ continuing with the Summit case from above, the primordial blast\ntest can be\
    \ run on one Summit node using four cores and four GPUs with the\nfollowing commands:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  <span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">${MEMBERWORK}</span>/[projid]/sundials-demo/tests/primordial_blast\n\
    \  bsub -q debug -nnodes 1 -W 0:10 -P [projid] -Is <span class=\"pl-smi\">$SHELL</span>\n\
    \  jsrun -n4 -a1 -c1 -g1 ../../bin/primordial_blast_mr.exe -f input_primordial_blast_mr_gpu.txt</pre></div>\n\
    <p>The <code>bsub</code> command above will submit a request for an interactive\
    \ job to the\ndebug queue allocating one node for 10 minutes with the compute\
    \ time charged to\n<code>[projid]</code>. Once the interactive session starts\
    \ the test case is launched using\nthe <code>jsrun</code> command. Solutions are\
    \ output to disk using parallel HDF5, solution\nstatistics are optionally output\
    \ to the screen at specified frequencies, and run\nstatistics are printed at the\
    \ end of the simulation.</p>\n<p>The parallel HDF5 solution snapshots are written\
    \ at the frequency specified by\n<code>nout</code>.  Accompanying these <code>output-#######.hdf5</code>\
    \ files is an automatically\ngenerated input file, <code>restart_parameters.txt</code>\
    \ that stores a complete set of\ninput parameters to restart the simulation from\
    \ the most recently generated\noutput file. This is a \"warm\" restart, in that\
    \ it will pick up the calculation\nwhere the previous one left off, using the\
    \ same initial time step size as\nARKStep would use. This restart may differ slightly\
    \ from an uninterrupted run\nsince other internal ARKStep time adaptivity parameters\
    \ cannot be reused.  We\nnote that the restart must use the same spatial grid\
    \ size and number of chemical\ntracers as the original run, but it may use a different\
    \ number of MPI tasks if\ndesired.</p>\n<h2><a id=\"user-content-adding-new-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-tests\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Adding New Tests</h2>\n<p>Individual\
    \ test problems are uniquely specified through an input file and\nauxiliary source\
    \ code file(s) that should be linked with the main routine at\ncompile time. By\
    \ default, all codes are built with no chemical species; however,\nthis may be\
    \ controlled at compilation time using the <code>NVAR</code> preprocessor\ndirective,\
    \ corresponding to the number of unknowns at any spatial location.\nHence, the\
    \ (default) minimum value for <code>NVAR</code> is 5, so for a calculation with\
    \ 4\nchemical species the code should be compiled with the preprocessor directive\n\
    <code>NVAR=9</code>. See <a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ for examples of how to\nspecify <code>NVAR</code> when adding a new test/executable.</p>\n\
    <p>The auxiliary source code files for creating a new test must contain three\n\
    functions. Each of these must return an integer flag indicating success (0) or\n\
    failure (nonzero). The initial condition function $w_0(X)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">initial_conditions</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector w, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>and the forcing function $G(X,t,w)$ must have the signature</p>\n\
    <div class=\"highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">external_forces</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, N_Vector G, <span class=\"pl-k\">const</span> UserData&amp;\
    \ udata);</pre></div>\n<p>Additionally, a function must be supplied to compute/output\
    \ any\ndesired solution diagnostic information with the signature</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre>  <span class=\"pl-k\">int</span> <span\
    \ class=\"pl-en\">output_diagnostics</span>(<span class=\"pl-k\">const</span>\
    \ realtype&amp; t, <span class=\"pl-k\">const</span> N_Vector w, <span class=\"\
    pl-k\">const</span> UserData&amp; udata);</pre></div>\n<p>If no diagnostics information\
    \ is desired, then this routine may just return 0.</p>\n<p>Here, the <code>initial_conditions</code>\
    \ routine will be called once when the simulation\nbegins, <code>external_forces</code>\
    \ will be called on every evaluation of the ODE\nright-hand side function for\
    \ the Euler equations (it is assumed that this does\nnot require the results from\
    \ (<code>UserData::ExchangeStart</code>\n/ <code>UserData::ExchangeEnd</code>),\
    \ and <code>output_diagnostics</code> will be called at the same\nfrequency as\
    \ the solution is output to disk.</p>\n<p>To add a new executable using these\
    \ auxiliary source code file(s), update\n<a href=\"./src/CMakeLists.txt\">src/CMakeLists.txt</a>\
    \ to include a new call to\n<code>sundemo_add_executable</code> in a similar manner\
    \ as the existing test problems e.g.,\n<code>hurricane_yz.exe</code>.</p>\n<h2><a\
    \ id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" href=\"#authors\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n\
    <p><a href=\"https://people.smu.edu/dreynolds\" rel=\"nofollow\">Daniel R. Reynolds</a>\
    \ and\n<a href=\"https://people.llnl.gov/gardner48\" rel=\"nofollow\">David J.\
    \ Gardner</a></p>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1655924113.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2023.01.13
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2023.01.13\"\
    ><img src=\"https://camo.githubusercontent.com/fbfe6539bae8689c96891c59048633d118e72a437c46fd271ee37b925cbe021c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032332e30312e31332d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2023.01.13-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.7535144\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ba6cf6236b990a475d29675163e2011968e79e5cd1f77324b27bea99c56833b0/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e373533353134342e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.7535144.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#what-is-spectre\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>What is SpECTRE?</h2>\n<p>SpECTRE\
    \ is an open-source code for multi-scale, multi-physics problems\nin astrophysics\
    \ and gravitational physics. In the future, we hope that\nit can be applied to\
    \ problems across discipline boundaries in fluid\ndynamics, geoscience, plasma\
    \ physics, nuclear physics, and\nengineering. It runs at petascale and is designed\
    \ for future exascale\ncomputers.</p>\n<p>SpECTRE is being developed in support\
    \ of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into\
    \ the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae,\
    \ and\ngamma-ray bursts.</p>\n<h2><a id=\"user-content-citing-spectre\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#citing-spectre\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Citing SpECTRE</h2>\n<p>Please cite\
    \ SpECTRE in any publications that make use of its code or data. Cite\nthe latest\
    \ version that you use in your publication. The DOI for this version\nis:</p>\n\
    <ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.7535144\" rel=\"nofollow\"\
    >10.5281/zenodo.7535144</a>\n</li>\n</ul>\n<p>You can cite this BibTeX entry in\
    \ your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"><pre><span\
    \ class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and H\\'ebert, Fran\\c{c}ois and Moxon,\
    \ Jordan and Armaza, Crist\\'obal and</span>\n<span class=\"pl-s\">Bonilla, Gabriel\
    \ S. and Kim, Yoonsoo and Kumar, Prayush and Lovelace, Geoffrey</span>\n<span\
    \ class=\"pl-s\">and Macedo, Alexandra and Nelli, Kyle C. and O'Shea, Eamonn and\
    \ Pfeiffer, Harald</span>\n<span class=\"pl-s\">P. and Scheel, Mark A. and Teukolsky,\
    \ Saul A. and Wittek, Nikolas A. and</span>\n<span class=\"pl-s\">others<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> =\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2023.01.13}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2023.01.13<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">publisher</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Zenodo<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">doi</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>10.5281/zenodo.7535144<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>https://spectre-code.org<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">howpublished</span> =\n<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.7535144}{10.5281/zenodo.7535144}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2023<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>1<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2><a id=\"\
    user-content-viewing-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #viewing-documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Viewing Documentation</h2>\n<p>The documentation can be viewed at\
    \ <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 120
  subscribers_count: 14
  topics: []
  updated_at: 1675183745.0
tgamblin/cali-container:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: tgamblin/cali-container
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1667175253.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - cooley/spack.yaml
  - gemini/spack.yaml
  - local/spack.yaml
  - chifflot/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1><a id="user-content-spack-envs" class="anchor" aria-hidden="true" href="#spack-envs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-envs</h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2><a id="user-content-locally" class="anchor" aria-hidden="true" href="#locally"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Locally</h2>

    <pre><code>spack config --scope defaults edit config

    install_tree: $spack/opt/spack

    build_stage: $user_cache_path/stage


    spack env activate ~/Dev/spack-envs/local

    spack install

    </code></pre>

    <h2><a id="user-content-g5k" class="anchor" aria-hidden="true" href="#g5k"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>G5k</h2>

    <pre><code>spack config --scope defaults edit config

    install_tree: /mnt/spack

    build_stage: /tmp/spack-stage

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1673281960.0
toxa81/se:
  data_format: 2
  description: Software environments
  filenames:
  - catalog-config/compilers/gcc-11.3.0/spack.yaml
  - catalog-config/core/spack.yaml
  - catalog-config/compilers/nvhpc-22.9/spack.yaml
  - catalog-config/libxc-5.2.3/spack.yaml
  full_name: toxa81/se
  latest_release: null
  readme: '<h1><a id="user-content-software-environments" class="anchor" aria-hidden="true"
    href="#software-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    environments</h1>

    <p>Deployment steps</p>

    <ul>

    <li>clone spack <code>git clone https://github.com/spack/spack.git</code>

    </li>

    <li>enable spack <code>source enable-spack</code>

    </li>

    <li>srun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16</li>

    <li>install gcc-11.3.0 view <code>spack -e  ./env-spec/gcc-11.3.0/ install</code>

    </li>

    <li>install nvhpc-22.9 <code>srun -N1 --partition=nvgpu spack -e . install -j64</code>

    </li>

    </ul>

    <p>spack compiler find $(spack find --format {prefix.bin} gcc@11)</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669195550.0
trilinos/ForTrilinos:
  data_format: 2
  description: ForTrilinos provides portable object-oriented Fortran interfaces to
    Trilinos C++ packages.
  filenames:
  - scripts/spack.yaml
  full_name: trilinos/ForTrilinos
  latest_release: v2.2.0
  readme: '<h1><a id="user-content-fortrilinos" class="anchor" aria-hidden="true"
    href="#fortrilinos"><span aria-hidden="true" class="octicon octicon-link"></span></a>ForTrilinos</h1>

    <p><a href="https://cloud.cees.ornl.gov/jenkins-ci/job/ForTrilinos-master-continuous"
    rel="nofollow"><img src="https://camo.githubusercontent.com/857fffb6b672ed62abe998b01a81c3932111fcba10541918cb2f938f414440e6/68747470733a2f2f636c6f75642e636565732e6f726e6c2e676f762f6a656e6b696e732d63692f6275696c645374617475732f69636f6e3f6a6f623d466f725472696c696e6f732d6d61737465722d636f6e74696e756f7573"
    alt="Build Status" data-canonical-src="https://cloud.cees.ornl.gov/jenkins-ci/buildStatus/icon?job=ForTrilinos-master-continuous"
    style="max-width: 100%;"></a>

    <a href="http://fortrilinos.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/e261f09cffcfcbf7e647f541614bf7912e3018ccd3a085f035a1219a854f5867/687474703a2f2f72656164746865646f63732e6f72672f70726f6a656374732f666f727472696c696e6f732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="http://readthedocs.org/projects/fortrilinos/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/trilinos/ForTrilinos/branch/develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/fbeea009914f87218441791dba76a1a512b7c287749f94ff47d7b76f49902d23/68747470733a2f2f636f6465636f762e696f2f67682f7472696c696e6f732f466f725472696c696e6f732f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/trilinos/ForTrilinos/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a></p>

    <p><a href="http://trilinos.org/packages/fortrilinos" rel="nofollow">ForTrilinos</a>
    is a part of the <a href="http://trilinos.org" rel="nofollow">Trilinos</a> project
    and provides object-oriented Fortran interfaces to Trilinos C++ packages.</p>

    <p>This is the new effort to provide Fortran interfaces to Trilinos through

    automatic code generation using SWIG. The previous effort (ca. 2008-2012) can

    be obtained by downloading Trilinos releases prior to 12.12. See <a href="https://fortrilinos.readthedocs.io/en/latest/install.html#version-compatibility"
    rel="nofollow">the

    documentation</a> for details on version compatibility.</p>

    <h2><a id="user-content-provided-functionality" class="anchor" aria-hidden="true"
    href="#provided-functionality"><span aria-hidden="true" class="octicon octicon-link"></span></a>Provided
    functionality</h2>

    <p>ForTrilinos provides Fortran interfaces for the following capabilities:</p>

    <ul>

    <li>Parameter lists and XML parsers (through Teuchos);</li>

    <li>Distributed linear algebra object including sparse graphs, sparse matrices,
    and dense vectors (through Tpetra);</li>

    <li>Linear solvers and preconditioners (through Stratimikos, Ifpack2, Belos, MueLu);</li>

    <li>Eigen solvers (through Anasazi).</li>

    </ul>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <ul>

    <li>

    <p><a href="https://fortrilinos.readthedocs.org" rel="nofollow">Documentation</a></p>

    </li>

    <li>

    <p><a href="https://trilinos.github.io/ForTrilinos/" rel="nofollow">Summary</a></p>

    </li>

    </ul>

    <h2><a id="user-content-installing-fortrilinos" class="anchor" aria-hidden="true"
    href="#installing-fortrilinos"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing
    ForTrilinos</h2>

    <p>Please consult the documentation available <a href="https://fortrilinos.readthedocs.io/en/latest/install.html"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-questions-bug-reporting-and-issue-tracking" class="anchor"
    aria-hidden="true" href="#questions-bug-reporting-and-issue-tracking"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Questions, Bug Reporting, and Issue Tracking</h2>

    <p>Questions, bug reporting and issue tracking are provided by GitHub. Please

    report all bugs by creating a new issue with the bug tag. You can ask

    questions by creating a new issue with the question tag.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>We encourage you to contribute to ForTrilinos! Please check out the

    <a href="CONTRIBUTING.md">guidelines</a> about how to proceed.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>ForTrilinos is licensed under a BSD license.</p>

    '
  stargazers_count: 24
  subscribers_count: 10
  topics:
  - trilinos
  - fortran
  - swig
  - scientific-computing
  updated_at: 1654781824.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/intelmpi/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1635166163.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/hpccf/franklin/omics/spack.yaml
  - environments/hpccf/franklin/cryoem/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<h1><a id="user-content-spack--uc-davis" class="anchor" aria-hidden="true"
    href="#spack--uc-davis"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    @ UC Davis</h1>

    <h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters" class="anchor"
    aria-hidden="true" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack repos and configs
    for UC Davis HPCCF Clusters</h2>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666297706.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - spack-environments/archer2/compute-node/spack.yaml
  - spack-environments/isambard-cascadelake/compute-node/spack.yaml
  - spack-environments/tursa/cpu/spack.yaml
  - spack-environments/csd3-icelake/compute-node/spack.yaml
  - spack-environments/myriad/compute-node/spack.yaml
  - spack-environments/isambard-a64fx/compute-node/spack.yaml
  - spack-environments/tesseract/compute-node/spack.yaml
  - spack-environments/github-actions/default/spack.yaml
  - spack-environments/dial3/compute-node/spack.yaml
  - spack-environments/csd3-skylake/compute-node/spack.yaml
  - spack-environments/cosma8/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1><a id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#excalibur-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks and regression tests\
    \ for the ExCALIBUR project.</p>\n<p>These benchmarks are based on a similar project\
    \ by\n<a href=\"https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2><a\
    \ id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h2>\n\
    <h3><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><em><strong>Note</strong>: we require Spack 0.18.  In some HPC facilities there\
    \ may be already a\ncentral Spack installation available.  In principle you should\
    \ be able to use a\nsystem installation of Spack (you only need to have <code>spack</code>\
    \ in the <code>PATH</code>), but\nyou need to make sure the version is recent\
    \ enough to install the required\npackages and understand the provided environments.\
    \  Instructions below show you\nhow to install Spack locally.</em></p>\n<p><a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager specifically\
    \ designed for HPC\nfacilities.  Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall the latest version of\
    \ Spack.</p>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable.  This\
    \ can be achieved for instance by running\nthe commands to get shell support described\
    \ in Spack documentation, which you\ncan also add to your shell init script to\
    \ do it automatically in every session.\nFor example, if you use a shell of the\
    \ family bash/zsh/sh you can add to your\ninit script:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRac projects.  If\
    \ you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system, if known, otherwise it will automatically\ncreate a very basic environment.</p>\n\
    <h3><a id=\"user-content-reframe\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #reframe\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ReFrame</h3>\n\
    <p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\" rel=\"nofollow\"\
    >ReFrame</a> is a high-level\nframework for writing regression tests for HPC systems.\
    \  For our tests we\nrequire ReFrame 3.11.0.  Follow the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall this package.  Note\
    \ that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a\
    \ specific module to have this version of Python available.</p>\n<p>We provide\
    \ a ReFrame configuration file with the settings of some systems that\nare part\
    \ of the ExCALIBUR project.  You can point ReFrame to this file by\nsetting the\n\
    <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILE</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILE=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${PWD}</span>/reframe_config.py<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>If you want to use a different ReFrame configuration file, for example because\n\
    you use a different system, you can set this environment variable to the path\
    \ of\nthat file.</p>\n<p><strong>Note</strong>: in order to use the Spack build\
    \ system in ReFrame, the <code>spack</code>\nexecutable must be in the <code>PATH</code>,\
    \ also on the computing nodes of a cluster, if\nyou want to run your benchmarks\
    \ on them.  Note that by default ReFrame uses</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a>, which would not load\nthe user's init script.  If you have added\
    \ Spack to your <code>PATH</code> within your init\nscript, you may want to set\
    \ the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ in order to make ReFrame use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash\
    \ -l</span></pre></div>\n<p>as shebang line, instead.</p>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<p>Once you have set up\
    \ Spack and ReFrame, you can execute a benchmark with</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/BENCH_NAME -r --performance-report</pre></div>\n\
    <p>where <code>apps/BENCH_NAME</code> is the directory where the benchmark is.\
    \  The command\nabove supposes you have the program <code>reframe</code> in your\
    \ PATH, if it is not the\ncase you can also call <code>reframe</code> with its\
    \ relative or absolute path.  For\nexample, to run the Sombrero benchmark in the\
    \ <code>apps/sombrero</code> directory you can\nuse</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/sombrero -r --performance-report</pre></div>\n\
    <p>For benchmark using the Spack build system, the tests define a default Spack\
    \ specification\nto be installed in the environment, but users can change it when\
    \ invoking ReFrame on the\ncommand line with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c apps/sombrero -r --performance-report -S\
    \ spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<p>Note that the <code>-S</code>\
    \ option can be used to set from the command line on a per-job\nbasis the built-in\
    \ fields of ReFrame regressions classes, e.g.\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.variables\"\
    \ rel=\"nofollow\"><code>variables</code></a>,\nwhich controls the environment\
    \ variables used in a job.  For example</p>\n<pre><code>reframe -c apps/sombrero\
    \ -r --performance-report -S variables=OMP_PLACES:threads\n</code></pre>\n<p>runs\
    \ the <code>apps/sombrero</code> benchmark setting the environment variable <code>OMP_PLACES</code>\n\
    to <code>threads</code>.</p>\n<h3><a id=\"user-content-selecting-system-and-queue-access-options\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#selecting-system-and-queue-access-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  You can always use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3><a id=\"user-content-unsupported-systems\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#unsupported-systems\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Unsupported systems</h3>\n<p>The\
    \ configuration provided in <a href=\"./reframe_config.py\"><code>reframe_config.py</code></a>\
    \ lets you run the\nbenchmarks on systems for which the configuration has been\
    \ already contributed.  However you\ncan still use this framework on any system\
    \ by choosing the \"generic\" system with <code>--system generic</code>, or using\
    \ your own ReFrame configuration.  Note, however, that if you use the\n\"generic\"\
    \ system, ReFrame will not know anything about the queue manager of your system,\
    \ if\nany, or the MPI launcher.  For the benchmarks using the Spack build system,\
    \ if you choose\nthe \"generic\" system, a new empty Spack environment will be\
    \ automatically created in\n<code>spack-environments/generic</code>.  In any case,\
    \ you can always make the benchmarks use a\ndifferent Spack environment by setting\
    \ the environment variable <code>EXCALIBUR_SPACK_ENV</code>\ndescribed above.</p>\n\
    <h2><a id=\"user-content-contributing-new-systems-or-benchmarks\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#contributing-new-systems-or-benchmarks\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\n\
    <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 8
  subscribers_count: 7
  topics: []
  updated_at: 1673444405.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-374/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: 0.8.0
  stargazers_count: 17
  subscribers_count: 5
  topics:
  - jupyter
  - jupyter-notebooks
  - jupyter-kernels
  - ipython
  - ipywidgets
  - ipython-widget
  - spack
  - pipenv
  - dvc
  - data-science
  - pandas
  updated_at: 1673277702.0
wangzhezhe/Gorilla:
  data_format: 2
  description: The Gorilla framework which provides distributed in-memory data management
    service
  filenames:
  - spack_cpu.yaml
  - spack.yaml
  full_name: wangzhezhe/Gorilla
  latest_release: null
  readme: "<h2><a id=\"user-content-motivation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#motivation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Motivation</h2>\n<p>Gorilla framework is a in-memory data management\
    \ servie. The name of the framework comes from the brand \"gorilla glue\", since\
    \ we are basically gluing different components together. It mainly supoorts follwing\
    \ capabilities:</p>\n<p>(1) suppot M:N data put/get for data based on grid mesh.</p>\n\
    <p>(2)User can use customized trigger to express the logic flow of the task executions.\
    \ The implementation of in-memory data storage service layer is inspired by the\
    \ <a href=\"https://github.com/philip-davis/dataspaces\">DataSpaces</a> and the\
    \ <a href=\"https://github.com/ornladios/ADIOS2\">ADIOS</a> projects. [adios test\
    \ case is deprecated]</p>\n<p>(3)There is specific event queue binded with the\
    \ trigger to support the data-driven task executions, the properties of the data\
    \ can be captured and client can acquire the metadata of the raw data by poll\
    \ events. The idea of data driven approach mainly comes from the <a href=\"https://www.osti.gov/biblio/1493245\"\
    \ rel=\"nofollow\">OSTI technical report</a>.</p>\n<p><strong>More key design\
    \ strategies can be found at the designDoc/scratch.md</strong></p>\n<h2><a id=\"\
    user-content-compiling-and-running-the-server\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#compiling-and-running-the-server\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Compiling and running the server</h2>\n<p>this\
    \ is an eample to compile the gorilla server on cori cluster</p>\n<pre><code>source\
    \ ~/.gorilla\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc\
    \ -DVTK_DIR=~/cworkspace/src/VTK/build/ -DUSE_GNI=ON\n</code></pre>\n<p>If the\
    \ paraveiw is used for particular test</p>\n<pre><code>old one\ncmake ~/cworkspace/src/Gorilla/\
    \ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=$SCRATCH/build_paraview_matthieu_release/\
    \ -DUSE_GNI=ON -DParaView_DIR=$SCRATCH/build_paraview_matthieu/ -DBUILD_SHARED_LIBS=ON\
    \ -DAMReX_DIR=/global/cscratch1/sd/zw241/build_amrex/install/lib/cmake/AMReX\n\
    </code></pre>\n<pre><code>new one (the cray based MPI can be detected and used\
    \ in this case when we use the cc and CC)\ncmake ~/cworkspace/src/Gorilla/ -DCMAKE_CXX_COMPILER=CC\
    \ -DCMAKE_C_COMPILER=cc -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0\
    \ -DUSE_GNI=ON\n</code></pre>\n<p>this is the content of the <code>~/.gorilla_cpu</code>\
    \ file on cori cluster:</p>\n<pre><code>#!/bin/bash\n\nsource ~/.color\nmodule\
    \ load cmake/3.18.2\nmodule load spack\n#spack load cmake@3.18.2%gcc@8.2.0\n\n\
    module swap PrgEnv-intel PrgEnv-gnu\n# ssg works well for gcc 9.3.0\nmodule swap\
    \ gcc/8.3.0 gcc/9.3.0\n\nspack load -r mochi-thallium%gcc@9.3.0\n#spack load mochi-cfg\n\
    spack load -r mochi-abt-io%gcc@9.3.0\n\nexport CRAYPE_LINK_TYPE=dynamic\n# we\
    \ do not use GPU and vtkm for this version\ncd $SCRATCH/build_Gorilla_cpu\n\n\n\
    export MPICH_GNI_NDREG_ENTRIES=1024 \n# get more mercury info\nexport HG_NA_LOG_LEVEL=debug\n\
    \n# avoid argobot thred pool issue, and set this to 2M\n# this may helps avoid\
    \ segfault when we use the processing and IO in large amount\n# export ABT_THREAD_STACKSIZE=2097152\n\
    # to make sure ther eis enough stack and not oom\nexport ABT_THREAD_STACKSIZE=1048576\n\
    </code></pre>\n<p>refer to the ./scripts dir to check exmaples of running multiple\
    \ servers. The configuration of the server contains item such as protocol used\
    \ by communication layer, the log level, the global domain and if the trigger\
    \ is started and so on. The example of the configuration is in ./server/settings.json</p>\n\
    <h3><a id=\"user-content-build-on-gpu-nodes\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#build-on-gpu-nodes\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>build on gpu nodes</h3>\n<p>this is the content of\
    \ the <code>~/.gorilla_gpu</code> file on cori cluster:</p>\n<pre><code>#!/bin/bash\n\
    source ~/.color\n\nsource ~/cworkspace/src/spack/share/spack/setup-env.sh\nmodule\
    \ swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\n# cuda can not\
    \ use this cray-mpich\nmodule unload cray-mpich/7.7.10\nmodule load cgpu cuda\
    \ openmpi\nmodule load cmake/3.20.5\n\n# jump to the gpu node\nsalloc -C gpu -t\
    \ 60 -c 8 -G 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\n# for thallium\n\
    spack load -r mochi-thallium%gcc@9.3.0\nspack load -r mochi-abt-io%gcc@9.3.0\n\
    \nexport CRAYPE_LINK_TYPE=dynamic\n</code></pre>\n<p>build</p>\n<p>(associated\
    \ vtkm accelarator should be enabled when building vtk in this case)\n(we do not\
    \ need extra vtkm build when there is vtk integration?)\n(we use vtkm associated\
    \ with vtk)</p>\n<pre><code>cmake ~/cworkspace/src/Gorilla/ -DCMAKE_CUDA_COMPILER=nvcc\
    \ -DCMAKE_CXX_COMPILER=g++ -DCMAKE_C_COMPILER=gcc -DVTKm_DIR=/global/cscratch1/sd/zw241/build_vtkm/lib/cmake/vtkm-1.6\
    \ -DVTK_DIR=/global/cscratch1/sd/zw241/build_vtk/lib64/cmake/vtk-9.0 -DUSE_GNI=ON\
    \ -DUSE_GPU=ON -DBUILD_SHARED_LIBS=ON -DVTKm_ENABLE_CUDA=ON -DVTKm_CUDA_Architecture=volta\n\
    </code></pre>\n<p>example to run the test</p>\n<pre><code>srun -C gpu -n 1 --gpus-per-task=1\
    \  nvprof ./test/test_insitu_ana\n</code></pre>\n<h3><a id=\"user-content-using-the-spack-env\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-the-spack-env\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using the spack env</h3>\n<p>if\
    \ we use the spack env, it means that we do not set the public packages.yaml file.\
    \ We also need to set the customized spack env for the Gorilla repo.</p>\n<p>set\
    \ up env (we use the spack installed by the colza-experiments)</p>\n<pre><code>source\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nspack\
    \ env create gorilla ~/cworkspace/src/Gorilla/spack.yaml\nspack repo add --scope\
    \ env:gorilla /global/cscratch1/sd/zw241/colza-experiments/cori/vtk/sw/mochi-spack-packages/\n\
    spack env update gorilla \nspack install -y\n</code></pre>\n<p>if the spack env\
    \ is installed successfully</p>\n<pre><code>#!/bin/bash\nsource ~/.color\n\nsource\
    \ $SCRATCH/colza-experiments/cori/vtk/sw/spack/share/spack/setup-env.sh\nmodule\
    \ swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\n# cuda can not\
    \ use this cray-mpich\nmodule unload cray-mpich/7.7.10\nmodule load cgpu cuda\
    \ openmpi\nmodule load cmake/3.20.5\n\n# activate env for the thallium\nspack\
    \ env activate gorilla\n\n# jump to the gpu node\nsalloc -C gpu -t 60 -c 8 -G\
    \ 1 -q interactive\n\ncd $SCRATCH/build_Gorilla_gpu\n\nexport CRAYPE_LINK_TYPE=dynamic\n\
    </code></pre>\n<h3><a id=\"user-content-run\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#run\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>run</h3>\n<p>exmaple on cori</p>\n<pre><code>srun -C haswell -n 8\
    \ ./unimos_server ~/cworkspace/src/Gorilla/server/settings_gni.json\n</code></pre>\n\
    <p>remember to set the env if MPICH is used</p>\n<pre><code>MPICH_GNI_NDREG_ENTRIES=1024\n\
    </code></pre>\n<p>simple example to put the data</p>\n<pre><code>srun -C haswell\
    \ -n 16 ./example/gray-scott-stg ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ gni\n</code></pre>\n<p>simple example to get the data for further processing</p>\n\
    <pre><code>srun -n 4 ./example/isosurface ~/cworkspace/src/Gorilla/example/gssimulation/settings.json\
    \ 10 0.5 gni\n</code></pre>\n<h3><a id=\"user-content-version-info\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#version-info\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Version info</h3>\n<p>v0.1</p>\n<p>M:N\
    \ put get for Cartesian grid</p>\n<p>memory and file backend\n(file backend will\
    \ be used when there is not enough mem space)</p>\n<p>in-memory data trigger (experimental)</p>\n\
    <h3><a id=\"user-content-related-issue\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#related-issue\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>related issue</h3>\n<pre><code>/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so:\
    \ undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023'\n</code></pre>\n\
    <p>try this:</p>\n<p>SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")</p>\n\
    <p>refer to</p>\n<p><a href=\"https://github.com/halide/Halide/issues/1112\">https://github.com/halide/Halide/issues/1112</a></p>\n\
    <p>make -j may hide some potential cmake mistakes, try to use make if there is\
    \ specific link issue</p>\n"
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1641259621.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/crusher/PrgEnv-gnu/spack.yaml
  - platformFiles/crusher/PrgEnv-cray/spack.yaml
  - platformFiles/polaris/gcc-11.2.0/spack.yaml
  - platformFiles/lassen/spack.yaml
  - platformFiles/summit/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1><a id="user-content-useful-supplementary-materials-for-installing-the-xsdk"
    class="anchor" aria-hidden="true" href="#useful-supplementary-materials-for-installing-the-xsdk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful supplementary
    materials for installing the xSDK</h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics: []
  updated_at: 1669065329.0
youwuyou/slimfly_collectives:
  data_format: 2
  description: null
  filenames:
  - ompi1-dev/spack.yaml
  full_name: youwuyou/slimfly_collectives
  latest_release: null
  readme: '<h1><a id="user-content-slim-fly-mpi-collective-optimization" class="anchor"
    aria-hidden="true" href="#slim-fly-mpi-collective-optimization"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Slim Fly MPI collective optimization</h1>

    <blockquote>

    <p>TODO: this repo is reset and needs to be put under source control with the
    new structure! Remember to add the <code>.github/workflows/ci.yml</code> as in
    the current git repo</p>

    </blockquote>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1671447123.0
