AMReX-Microelectronics/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Docs/spack.yaml
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" tabindex="-1"
    href="#artemis"><span aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    '
  stargazers_count: 10
  subscribers_count: 5
  topics: []
  updated_at: 1696392722.0
AMReX-Microelectronics/artemis_bakup:
  data_format: 2
  description: null
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis_bakup
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" tabindex="-1"
    href="#artemis"><span aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a code
    for modeling micromagnetics and electrodynamic waves in next-generation microelectornics.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1688585950.0
C2SM/spack-c2sm:
  data_format: 2
  description: Repository for c2sm spack config and repo files
  filenames:
  - upstreams/daint/icon-dsl/spack.yaml
  - upstreams/daint/icon-rttov/spack.yaml
  full_name: C2SM/spack-c2sm
  latest_release: v0.20.1.0
  readme: '<h1><a id="user-content-the-spack-extension-of-c2sm-and-mch" class="anchor"
    aria-hidden="true" tabindex="-1" href="#the-spack-extension-of-c2sm-and-mch"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>The spack extension
    of C2SM and MCH</h1>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/67d98f3f50b1ad629290b2fc5a38331fc19df5a656363fb14bdd892b371dcf0e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616e7369636f6c6f72746167732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/ansicolortags/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is the package manager used by C2SM and MeteoSwiss to install and deploy
    software on supercomputers, local machines and the cloud.</p>

    <h2><a id="user-content-documentations" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentations</h2>

    <p><strong>Infos about c2sm-supported software and machines</strong></p>

    <ul>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow">spack-c2sm
    latest</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.0" rel="nofollow">spack-c2sm
    v0.20.1.0</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.12" rel="nofollow">spack-c2sm
    v0.18.1.12</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.10" rel="nofollow">spack-c2sm
    v0.18.1.10</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.9" rel="nofollow">spack-c2sm
    v0.18.1.9</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.8" rel="nofollow">spack-c2sm
    v0.18.1.8</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.7" rel="nofollow">spack-c2sm
    v0.18.1.7</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.6" rel="nofollow">spack-c2sm
    v0.18.1.6</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.5" rel="nofollow">spack-c2sm
    v0.18.1.5</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.4" rel="nofollow">spack-c2sm
    v0.18.1.4</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.3" rel="nofollow">spack-c2sm
    v0.18.1.3</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.2" rel="nofollow">spack-c2sm
    v0.18.1.2</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.1" rel="nofollow">spack-c2sm
    v0.18.1.1</a> [deprecated]</p>

    </li>

    </ul>

    <p><strong>General infos about spack</strong></p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/v0.20.1/" rel="nofollow">Official
    spack v0.20.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/v0.18.1/" rel="nofollow">Official
    spack v0.18.1</a></li>

    </ul>

    <h2><a id="user-content-workflow" class="anchor" aria-hidden="true" tabindex="-1"
    href="#workflow"><span aria-hidden="true" class="octicon octicon-link"></span></a>Workflow</h2>

    <p>With spack v0.18 we suggest local/individual spack instances and the use of
    spack environments.</p>

    <p>A user clones the spack repo</p>

    <div class="highlight highlight-source-shell"><pre>git clone --depth 1 --recurse-submodules
    --shallow-submodules -b v0.20.1.0 https://github.com/C2SM/spack-c2sm.git</pre></div>

    <p>gets spack in the command line</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">.</span>
    spack-c2sm/setup-env.sh</pre></div>

    <p>activates an environment</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate <span class="pl-k">&lt;</span>path_to_env<span
    class="pl-k">&gt;</span></pre></div>

    <p>and starts exploring</p>

    <div class="highlight highlight-source-shell"><pre>spack info <span class="pl-k">&lt;</span>package<span
    class="pl-k">&gt;</span>

    spack spec <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>and building</p>

    <div class="highlight highlight-source-shell"><pre>spack install <span class="pl-k">&lt;</span>spec<span
    class="pl-k">&gt;</span>

    spack dev-build <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>a package.</p>

    <p>Updating spack-c2sm is in the hands of the user.</p>

    <div class="highlight highlight-source-shell"><pre>git pull

    git submodule update --recursive</pre></div>

    <p>After an update we advice to clean</p>

    <div class="highlight highlight-source-shell"><pre>spack uninstall -a

    spack clean -a

    rm -rf <span class="pl-k">~</span>/.spack</pre></div>

    <p>and rebuild.</p>

    <h2><a id="user-content-command-cheat-sheet" class="anchor" aria-hidden="true"
    tabindex="-1" href="#command-cheat-sheet"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Command cheat sheet</h2>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Clone</td>

    <td><code>git clone --depth 1 --recurse-submodules --shallow-submodules -b &lt;branch/tag&gt;
    https://github.com/C2SM/spack-c2sm.git</code></td>

    </tr>

    <tr>

    <td>Load</td>

    <td>

    <code>. spack-c2sm/setup-env.sh</code> autodetects machine <br>or<br><code>. spack-c2sm/setup-env.sh
    &lt;machine&gt;</code> forces machine<br>or<br><code>. spack-c2sm/setup-env.sh
    unknown</code> uses blank config<br><code>spack compiler find</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-compiler-find"
    rel="nofollow">autodetects compilers</a><br><code>spack external find --all</code>
    <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-external-find"
    rel="nofollow">autodetects externally installed packages</a>

    </td>

    </tr>

    <tr>

    <td>Update</td>

    <td>

    <code>git pull</code><br><code>git submodule update --recursive</code>

    </td>

    </tr>

    <tr>

    <td>Clean</td>

    <td>

    <code>spack uninstall -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-uninstall"
    rel="nofollow">uninstalls all packages</a><br><code>spack clean -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-clean"
    rel="nofollow">cleans all misc caches</a><br><code>rm -rf ~/.spack</code> removes
    user scope data</td>

    </tr>

    </tbody>

    </table>

    <p><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><strong>Spec syntax</strong></a>: <code>&lt;package&gt;</code><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#version-specifier"
    rel="nofollow"><code>@&lt;version&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-specifier"
    rel="nofollow"><code>%&lt;compiler&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#variants"
    rel="nofollow"><code>+&lt;variant&gt; ~&lt;variant&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><code>^&lt;sub-package&gt; +&lt;sub-package-variant&gt;</code></a><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-flags"
    rel="nofollow"><code>&lt;compiler flags&gt;</code></a></p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Find</td>

    <td>

    <code>spack find</code> lists all installed packages. <br><code>spack find &lt;spec&gt;</code>
    lists all installed packages that match the spec.</td>

    </tr>

    <tr>

    <td>Info</td>

    <td><code>spack info &lt;package&gt;</code></td>

    </tr>

    <tr>

    <td>Spec</td>

    <td>

    <code>spack spec &lt;spec&gt;</code> concretizes abstract spec (unspecfied variant
    = <strong>any</strong>)<br><em>Spack is not required to use the default of an
    unspecified variant. The default value is only a tiebreaker for the concretizer.</em>

    </td>

    </tr>

    <tr>

    <td>Install</td>

    <td><code>spack install &lt;spec&gt;</code></td>

    </tr>

    <tr>

    <td>Locate</td>

    <td>

    <code>spack location --install-dir &lt;spec&gt;</code> prints location of <strong>all</strong>
    installs that satisfy the spec</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-load"
    rel="nofollow">Load env</a></td>

    <td>

    <code>spack load &lt;spec&gt;</code> loads run environment</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Activate
    env</a></td>

    <td><code>spack env activate &lt;env_name&gt;</code></td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Deactivate
    env</a></td>

    <td><code>spack deactivate</code></td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 6
  subscribers_count: 17
  topics: []
  updated_at: 1699975415.0
CHIP-SPV/chipStar-Spack:
  data_format: 2
  description: Support for building chipStar and related libraries via Spack
  filenames:
  - Environments/LevelZero/spack.yaml
  - Environments/ROCm/spack.yaml
  full_name: CHIP-SPV/chipStar-Spack
  latest_release: null
  readme: '

    <h1><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h1>

    <p><a href="https://github.com/CHIP-SPV/chipStar">chipStar</a> (formerly CHIP-SPV)

    is software that allows software written to use the

    <a href="https://https://github.com/ROCm-Developer-Tools/HIP" rel="nofollow">Heterogeneous-compute
    Interface for Portability

    (HIP)</a>

    interface and kernel language to target GPUs via the

    <a href="https://registry.khronos.org/spir" rel="nofollow">SPIR-V</a> intermediate
    language.

    chipStar can use either the Intel Level Zero runtime or an OpenCL

    runtime as a backend.</p>

    <p>This repository contains support for building chipStar and its

    dependencies via the <a href="https://github.com/spack/spack">Spack</a> package

    manager.</p>

    <p>Note: most development to date has been done with the Level Zero

    environment, and it is expected that substantial work is needed for

    the environment targeting the OpenCL backend to work.</p>

    <h1><a id="user-content-prerequisites" class="anchor" aria-hidden="true" tabindex="-1"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h1>

    <ul>

    <li>An x86_64 system running a common Linux distribution.  OpenSLES 15 is

    the best tested to date.</li>

    <li>A working Spack installation.</li>

    <li>A recent Clang installation that is registered with Spack as a compiler.

    Versions 15 and 16 are best tested, but 14 might work.  We suggest

    installing the compiler via Spack (i.e., by installing something like

    <code>llvm@16.0.2</code> and then using <code>spack compiler add</code> with the
    llvm

    package''s install location), because the <code>chipstar</code> package defined

    in this repository depends on the <code>llvm</code> package anyway.</li>

    <li>A recent (at least version 2023.1) Intel OneAPI compiler installation

    that is registered with Spack as a compiler.  The recommended way

    of doing this is by installing the Spack <code>intel-oneapi-compilers</code>

    package, then registering the location of its compilers with Spack.

    E.g.,</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>$ spack install intel-oneapi-compilers@2023

    $ spack compiler add <span class="pl-s"><span class="pl-pds">$(</span>spack location
    -i intel-oneapi-compilers@2023<span class="pl-pds">)</span></span>/compiler/latest/linux</pre></div>

    <h1><a id="user-content-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h1>

    <ol start="0">

    <li>Clone this repository to the target system.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ git clone https://github.com/CHIP-SPV/CHIP-SPV-Spack</pre></div>

    <ol start="2">

    <li>Activate the environment you want to build.  E.g., for the

    environment that just builds chipStar with Level Zero backend:</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ <span class="pl-c1">cd</span>
    CHIP-SPV-Spack/Environments/LevelZero

    $ spack env activate <span class="pl-c1">.</span></pre></div>

    <ol start="3">

    <li>Concretize the active environment.  (In Spack terminology,

    "to concretize" means to let Spack examine the package specifications

    it has been asked to build, plus the available package repositories,

    resolve dependencies and check constraints, and decide exactly which

    packages it will build, in which order, and with which configuration.)</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack concretize -f -U</pre></div>

    <p>We suggest examining the output from running the <code>spack concretize</code>

    command to make sure that Spack''s concretizer has truly decided to

    use the configuration options and especially the compilers that you

    want it to use.  Note that the environment and related configuration

    are purposefully not overly constrained to use the given compiler

    for every dependency package, so even though there are some packages

    that must be built with <code>%clang</code>, there are others that may be

    built (or re-used from already-installed packages) using <code>%gcc</code> such

    as the system''s GCC installation.</p>

    <p>If Spack''s concretizer  didn''t do what you want, you can re-concretize

    the environment and be more explicit about what you want using command-line

    configuration options (recommended) or by editing the environment''s

    <code>spack.yaml</code> file or other configuration options that your Spack installation

    is using.  (Use <code>spack config blame</code> to see which configuration files
    Spack is

    using.)  For instance, if you have both <code>clang@16.0.2</code> and <code>clang@15.0.7</code>

    installed and registered as Spack compilers, and you want to build

    using <code>clang@15.0.7</code>, you may have to use a concretize command like
    the

    following:</p>

    <div class="highlight highlight-source-shell"><pre>$ spack -c <span class="pl-s"><span
    class="pl-pds">"</span>packages:chipstar:require:''%clang@15.0.7''<span class="pl-pds">"</span></span>
    concretize -f -U</pre></div>

    <p>As before, verify from the output of the <code>spack concretize</code> command
    that it

    is using the compiler version you want, <code>clang@15.0.7</code> in this example.</p>

    <ol start="4">

    <li>Build the environment.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack install</pre></div>

    <p>Spack supports some options for controlling the build and installation,

    such as <code>-j</code> to limit the number of processes used for parallel builds,

    useful for being a good citizen on shared systems by not allowing Spack

    to use all available cores (its default).  See the Spack documentation for

    more information.</p>

    <p>Assuming all goes well with the build and install, a <code>spack find</code>

    should show the packages that you just built.</p>

    <ol start="5">

    <li>Use the installed software.  There are several ways you might

    update your environment to use the software, including:</li>

    </ol>

    <ul>

    <li><code>spack load chipstar</code></li>

    <li>Activating the environment that you used to build the software</li>

    <li>If your Spack configuration is such that it can generate module files

    and module files have been generated for the software you built

    via this environment, <code>module load chipstar</code>

    </li>

    </ul>

    <p>Note that you may need to modify your environment to be able to run

    programs produced using chipStar and the H4I libraries built

    using this Spack repository.  For instance, on some systems,

    one must load the <code>intel_compute_runtime</code> module before being

    able to run programs that use the Intel Level Zero runtime.</p>

    <h1><a id="user-content-todo" class="anchor" aria-hidden="true" tabindex="-1"
    href="#todo"><span aria-hidden="true" class="octicon octicon-link"></span></a>TODO</h1>

    <ul>

    <li>Clean up and verify the OpenCL-based environment.</li>

    <li>Ensure the OpenCL-based environment can use any OpenCL implementation.</li>

    <li>Incorporate H4I HIP libraries like H4I-HipBLAS into an environments.</li>

    <li>Support using the software installed by the environment via

    <code>module</code> command.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1687550793.0
CUP-ECS/beatnik:
  data_format: 2
  description: Initial Cabana/Cajita Low/High-order Z-model Interface Solver. Benchmark
    for evaluating the performance of algorithms requiring global communication. Beatnik
    is also a precursor to potential later a High Performance Parallel Interface solver.
  filenames:
  - configs/llnl/quartz/spack.yaml
  - configs/llnl/tioga/spack.yaml
  - configs/llnl/lassen/spack.yaml
  full_name: CUP-ECS/beatnik
  latest_release: v1.0.0
  readme: '<h1><a id="user-content-beatnik---a-prototype-high-performance-parallel-interface-benchmark"
    class="anchor" aria-hidden="true" tabindex="-1" href="#beatnik---a-prototype-high-performance-parallel-interface-benchmark"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Beatnik - A Prototype
    High Performance Parallel Interface Benchmark</h1>

    <h2><a id="user-content-description" class="anchor" aria-hidden="true" tabindex="-1"
    href="#description"><span aria-hidden="true" class="octicon octicon-link"></span></a>Description</h2>

    <p>Beatnik is a benchmark for global communication based on Pandya and Shkoller''s
    3D fluid interace "Z-Model" in the Cabana/Cajita mesh framework [1]. The goals

    of Beatnik are to:</p>

    <ol>

    <li>Provide an interesting and meaningful benchmark for numerical methods that
    require global communication, for example for far-field force calculations. This
    includes fast fourier transforms, distance sort cutoff-based methods, and (eventually)
    fast multi-pole methods.</li>

    <li>Understand the performance characteristics of different parallel decompositions
    of the Z-Model based on both a 2D decomposition based on logical mesh location
    location and a space-filling curve mesh decomposition.</li>

    <li>Provide a working prototype parallel implementation of the fluid interface
    model that other codes can use to create multi-scale models and codes.</li>

    </ol>

    <p>Beatnik uses a simple mesh-based representation of the surface manifold as
    a Cabana grid 2D mesh in I/J space and a regular block 2D decomposition of this
    manifold. The physical position of each element in the mesh is stored as a separate
    vector in the nodes of the mesh. This design results in simple and efficient computation
    and communication strategies for surface normals, artificial viscosity, and Fourier
    transforms elements. However, it complicates methods where the data decomposition
    and communication is based on the spatial location of manifold points, requiring
    them to either maintain a separate spatial decomposition of the surface or to
    continually construct a spatial decomposition. A surface mesh that decomposed
    the mesh by spatial location would be an interesting alternative but would have
    the opposite issue - communication for surface calculations would be more complex
    but the (expensive) far force methods that rely on spatial decompositions (e.g.
    distance sort and spatial tree methods like the fast multi-pole method) would
    be less expensive.</p>

    <h2><a id="user-content-building-beatnik" class="anchor" aria-hidden="true" tabindex="-1"
    href="#building-beatnik"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    Beatnik</h2>

    <p>Beatnik relies on multiple external packages to build, including:</p>

    <ul>

    <li>ECP CoPA''s Cabana/Grid particle and mesh framework [2]</li>

    <li>UT-Knoxville''s HeFFTe fast fourier transform library [3]</li>

    <li>A high-performance GPU-aware MPI implementation such as OpenMPI, MPICH, or
    MVAPICH</li>

    </ul>

    <p>To ease building Beatnik, the configs/ directory includes Spack configuration
    files for building in spack environments on multiple systems and test case run
    scripts for a variety of systems. In addition, the latest version of Spack includes
    a package description for directly building Beatnik. More information on building
    Beatnik can be found in the README.md file in the configs/ directory.</p>

    <h2><a id="user-content-running-beatnik" class="anchor" aria-hidden="true" tabindex="-1"
    href="#running-beatnik"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    Beatnik</h2>

    <p>By default, Beatnik solves a simple multi-mode rocket rig problem sized for
    a single serial CPU core with approximately 4GB of memory. It also includes command
    line options to change initial problem state, I/O frequency, and to weak-scale
    scale up the initial problem to larger number of processes. It also includes problem-specific
    command line parameters; setting these parameters accurately generally requires
    expertise in fluid interface models. However, we provide several useful examples
    drawn from the ZModel papers that recreate the results in those papers.</p>

    <h3><a id="user-content-general-command-line-parameters" class="anchor" aria-hidden="true"
    tabindex="-1" href="#general-command-line-parameters"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>General command line parameters</h3>

    <ul>

    <li>

    <code>-x [cuda|threads|serial]</code> - The node-level parallelism/accelerator
    backend to use</li>

    <li>

    <code>-F [write-frequency]</code> - Interval between timesteps when I/O is written</li>

    <li>

    <code>-O [solution order]</code> - Order of solver to use (''high'', ''medium'',
    or ''low''). ''low'' is the default.</li>

    <li>`-w [weak scaling factor] - Scale up the problem specification, including
    the x/y bounding box, to be N times larger</li>

    </ul>

    <h3><a id="user-content-problem-specific-command-line-parameters" class="anchor"
    aria-hidden="true" tabindex="-1" href="#problem-specific-command-line-parameters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Problem-specific command
    line parameters</h3>

    <ul>

    <li>

    <code>-n [i/j mesh dimension ]</code> - Number of points on the interface manifold
    in the I and J dimensions</li>

    <li>`-t [timesteps] - number of timesteps to simulate</li>

    <li>

    <code>-I [interface initialization]</code> - Function to use for interface initial
    condition. Currently only ''cos'' and ''sech2'' are supported.</li>

    <li>

    <code>-m [magnitude]</code> - The maximum magnitude of the initialization function.</li>

    <li>

    <code>-p [period]</code> - The number of periods of the interface in the initial
    bounding box</li>

    <li>

    <code>-a [atwood]</code> - Atwood''s constant for the difference in pressure between
    the two fluids</li>

    <li>

    <code>-g [gravity]</code> - Gravitational acceleration in the -Z direction</li>

    <li>

    <code>-a [atwood]</code> -  Atwood''s constant for the difference in pressure
    between the two fluids</li>

    <li>

    <code>-M [mu]</code> - Mu, the artificial viscosity constant used in the Z-Model</li>

    <li>

    <code>-e [epsilon]</code> - Epsilon, the desingularization constant used in the
    Z-Model expressed as a fraction of the distance between interface mesh points</li>

    </ul>

    <h3><a id="user-content-example-1-periodic-multi-mode-rocket-rig" class="anchor"
    aria-hidden="true" tabindex="-1" href="#example-1-periodic-multi-mode-rocket-rig"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example 1: Periodic
    Multi-mode Rocket Rig</h3>

    <p>The simplest test case and the one to which the rocketrig example program defaults
    is an initial interface distributed according to a cosine function. Simple usage
    examples:</p>

    <ol>

    <li>Serial execution: <code>bin/rocketrig -x serial</code>

    </li>

    <li>Cuda execution (on systems with GPUs) with a 512x512 mesh: <code>bin/rocketrig
    -x cuda -n 512</code>

    </li>

    <li>Cuda execution with a 1024x1024 problem scaled up to be sixteen times as large
    in terms of bounding box and number of total points with no I/O: bin/rocketrig
    -x cuda -n 1024 -F 0 -w 16`</li>

    </ol>

    <h3><a id="user-content-example-2-non-periodic-single-mode-gaussian-rollup" class="anchor"
    aria-hidden="true" tabindex="-1" href="#example-2-non-periodic-single-mode-gaussian-rollup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example 2: Non-periodic
    Single-mode Gaussian Rollup</h3>

    <p>Another test case is a single-mode rollup test where the intitial interface
    is set according to a hyperbolic secant function. This testcase recreates the
    the Gaussian perturbation results in Panda and Shkoller''s paper from sections
    2.3 and 2.4.  To run this testcase with a high-order model, use the following
    command line parameters. Note that this works best with a GPU accelerator, as
    the exact high-order far field force solver is very compute intensive and is generally
    impractical for non-trivial mesh sizes without GPU acceleration:

    <code>bin/rocketrig -x cuda -O high -n 64 -I sech2 -m 0.1 -p 9.0 -b free -a 0.15
    -M 2 -e 2</code></p>

    <h2><a id="user-content-planned-development-steps" class="anchor" aria-hidden="true"
    tabindex="-1" href="#planned-development-steps"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Planned Development Steps</h2>

    <p>Beatnik is being implemented in multiple distinct steps, with associated planned
    releases:</p>

    <ul>

    <li>

    <p>Version 1.0 Features</p>

    <ol>

    <li>A low-order model implementation that relies on Cabana Grid/HeFFTe Fourier
    transforms for estimating velocity interface at mesh points.</li>

    <li>A high-order model implementation based on brute-force exact computation of
    long-range forces</li>

    <li>A medium-order model that uses the Fourier transform for estimating interface
    velocity and the far-field force solver for estimating how the vorticity changes
    at each interface point.</li>

    <li>Support for periodic boundary conditions and free boundary conditions</li>

    <li>Simple benchmark examples including a single-mode Gaussian roll-up test and
    the multi-mode rocket rig experiment.</li>

    <li>Direct support for weak scaling of benchmarks through command line arguments</li>

    </ol>

    </li>

    <li>

    <p>Version 1.X Planned Features</p>

    <ol>

    <li>Rearchitecting of the z-model solve into explicitly-coupled surface mesh and
    spatial mesh solvers</li>

    <li>A spatial mesh cutoff-based approach for calculating far-field forces using
    the Cabana particle framework. The goal of this work is to understand the accuracy/performance
    tradeoffs in the Z-Model, particularly in the medium-order</li>

    <li>Improved timestep, desingularization, and artificial viscosity parameter handling.
    The goal of this is to provide good defaults when other input parameters are changed.</li>

    <li>Additional interface initialization options, including Gaussian random and
    file-based interface initialization (also useful for checkpointing)</li>

    <li>Support for coupling with other applications through either I/O (e.g. ADIOS)
    or Communication (e.g. Portage)</li>

    <li>Additional test case definitions</li>

    </ol>

    </li>

    <li>

    <p>Potential later (e.g. &gt;=2.0) features</p>

    <ol>

    <li>Direct fast multi-pole or P3M solver for scalable, high precision high-order
    model solves.</li>

    <li>Support for multiple interface manifolds in a single simulation.</li>

    </ol>

    </li>

    </ul>

    <h2><a id="user-content-acknowledgment-contributors-and-copyright-information"
    class="anchor" aria-hidden="true" tabindex="-1" href="#acknowledgment-contributors-and-copyright-information"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgment, Contributors,
    and Copyright Information</h2>

    <p>Beatnik is primarily available as open source under a 3-Clause BSD License.
    It is being developed at the University of New Mexico, Tennessee Tech University,
    and the University of Alabama under funding the U.S. Department of Energy''s Predictive
    Science Academic Alliance Partnership III (PSAAP-III) program. Contributors to
    Beatnik development include:</p>

    <ul>

    <li>Patrick G. Bridges (<a href="mailto:patrickb@unm.edu">patrickb@unm.edu</a>)</li>

    <li>Thomas Hines (<a href="mailto:tmhines3@ua.edu">tmhines3@ua.edu</a>)</li>

    <li>Jered Dominguez-Trujillo (<a href="mailto:jereddt@unm.edu">jereddt@unm.edu</a>)</li>

    <li>Jacob McCullough (<a href="mailto:jmccullough12@unm.edu">jmccullough12@unm.edu</a>)</li>

    <li>Jason Stewart (<a href="mailto:jastewart@unm.edu">jastewart@unm.edu</a>)</li>

    </ul>

    <p>The general structure of Beatnik and the rocketrig examples were taken from
    the ExaMPM proxy application (<a href="https://github.com/ECP-copa/ExaMPM">https://github.com/ECP-copa/ExaMPM</a>)
    developed by the ECP Center for Particle Applications (CoPA), which was also available
    under a 3-Clause BSD License when used for creating application structure.</p>

    <h2><a id="user-content-references" class="anchor" aria-hidden="true" tabindex="-1"
    href="#references"><span aria-hidden="true" class="octicon octicon-link"></span></a>References</h2>

    <ol>

    <li>

    <p>Gavin Pandya and Steve Shkoller. "3d Interface Models for Raleigh-Taylor Instability."
    Published as arxiv.org preprint <a href="https://arxiv.org/abs/2201.04538" rel="nofollow">https://arxiv.org/abs/2201.04538</a>,
    2022.</p>

    </li>

    <li>

    <p><a href="https://github.com/ECP-copa/Cabana/">https://github.com/ECP-copa/Cabana/</a></p>

    </li>

    <li>

    <p>Innovative Computing Laboratory. "heFFTe." URL: <a href="https://icl.utk.edu/fft/"
    rel="nofollow">https://icl.utk.edu/fft/</a></p>

    </li>

    </ol>

    '
  stargazers_count: 4
  subscribers_count: 4
  topics: []
  updated_at: 1696885371.0
ComputationalRadiationPhysics/picongpu:
  data_format: 2
  description: 'Performance-Portable Particle-in-Cell Simulations for the Exascale
    Era :sparkles:'
  filenames:
  - etc/picongpu/karolina-it4i/spack/spack.yaml
  full_name: ComputationalRadiationPhysics/picongpu
  latest_release: 0.7.0
  readme: "<h1><a id=\"user-content-picongpu---particle-in-cell-simulations-for-the-exascale-era\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#picongpu---particle-in-cell-simulations-for-the-exascale-era\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>PIConGPU\
    \ - Particle-in-Cell Simulations for the Exascale Era</h1>\n<p><a href=\"https://gitlab.com/hzdr/crp/picongpu/pipelines/dev/latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7f31bbb5197c9ebcecdbd3bd3adcc493557b1b49c328c892119ad955d38f90d0/68747470733a2f2f6769746c61622e636f6d2f687a64722f6372702f7069636f6e6770752f6261646765732f6465762f706970656c696e652e7376673f6b65795f746578743d646576\"\
    \ alt=\"Code Status dev\" data-canonical-src=\"https://gitlab.com/hzdr/crp/picongpu/badges/dev/pipeline.svg?key_text=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"http://picongpu.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/dd84c49cf1a8e134ca1a5a87517257a4317eecc4a80ff90195b2d2eebeeb7ced/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7069636f6e6770752f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/picongpu/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"http://computationalradiationphysics.github.io/picongpu\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/bea8b749e6bc63f677e6ccfc18ae8a6a4a4e39d55e3aac6c872acc8d1ecdc22b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c75652e737667\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://isocpp.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\"\
    \ alt=\"Language\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/gpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d9724a7d6c0aab25ad100b9c974369e2ea7585e6d0d0b87b66aa5bd34f6c2abe/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c76332d626c75652e7376673f6c6162656c3d5049436f6e475055\"\
    \ alt=\"License PIConGPU\" data-canonical-src=\"https://img.shields.io/badge/license-GPLv3-blue.svg?label=PIConGPU\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d8685de1336e9f80f82625f4271fbd11d00beaf91013768daef9ac1a62e6fe2b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c75652e7376673f6c6162656c3d504d616363\"\
    \ alt=\"License PMacc\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue.svg?label=PMacc\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"http://www.youtube.com/watch?v=nwZuG-XtUDE\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/be7eb258510f59135b17c487a2bd50e76f186e1c71e56ab87f5cd1afe4df35d3/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6e775a75472d58745544452f302e6a7067\"\
    \ alt=\"PIConGPU Presentation Video\" data-canonical-src=\"http://img.youtube.com/vi/nwZuG-XtUDE/0.jpg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"http://www.youtube.com/watch?v=nwZuG-XtUDE\"\
    \ rel=\"nofollow\"><img src=\"docs/logo/pic_logo_vert_158x360.png\" alt=\"PIConGPU\
    \ Release\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-introduction\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#introduction\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Introduction</h2>\n\
    <p>PIConGPU is a fully relativistic,\n<a href=\"https://en.wikipedia.org/wiki/Manycore_processor\"\
    \ rel=\"nofollow\">manycore</a>,\n3D3V particle-in-cell (<a href=\"http://en.wikipedia.org/wiki/Particle-in-cell\"\
    \ rel=\"nofollow\">PIC</a>)\ncode. The Particle-in-Cell algorithm is a central\
    \ tool in plasma physics.\nIt describes the dynamics of a plasma by computing\
    \ the motion of\nelectrons and ions in the plasma based on\n<a href=\"http://en.wikipedia.org/wiki/Maxwell%27s_equations\"\
    \ rel=\"nofollow\">Maxwell's equations</a>.</p>\n<p>PIConGPU implements various\
    \ numerical schemes to solve the PIC cycle.\nIts features for the electro-magnetic\
    \ PIC algorithm include:</p>\n<ul>\n<li>a central or Yee-lattice for fields</li>\n\
    <li>particle pushers that solve the equation of motion for charged and neutral\n\
    particles, e.g., the <em>Boris-</em> and the\n<a href=\"http://dx.doi.org/10.1063/1.2837054\"\
    \ rel=\"nofollow\"><em>Vay-Pusher</em></a>\n</li>\n<li>Maxwell field solvers,\
    \ e.g.\n<a href=\"http://dx.doi.org/10.1109/TAP.1966.1138693\" rel=\"nofollow\"\
    ><em>Yee's</em></a> and\n<a href=\"http://dx.doi.org/10.1103/PhysRevSTAB.16.021301\"\
    \ rel=\"nofollow\"><em>Lehe's</em></a> scheme</li>\n<li>rigorously charge conserving\
    \ current deposition schemes, such as\n<a href=\"http://dx.doi.org/10.1016/S0010-4655%2800%2900228-9\"\
    \ rel=\"nofollow\"><em>Esirkepov</em></a>\nand <em>EZ</em> (Esirkepov meets ZigZag)</li>\n\
    <li>macro-particle form factors ranging from NGP (0th order), CIC (1st),\nTSC\
    \ (2nd), PQS (3rd) to PCS (4th)</li>\n</ul>\n<p>and the electro-magnetic PIC algorithm\
    \ is further self-consistently coupled to:</p>\n<ul>\n<li>classical radiation\
    \ reaction\n(<a href=\"http://dx.doi.org/10.1016/j.cpc.2016.04.002\" rel=\"nofollow\"\
    >DOI:10.1016/j.cpc.2016.04.002</a>)</li>\n<li>advanced field ionization methods\n\
    (<a href=\"http://dx.doi.org/10.1103/PhysRevA.59.569\" rel=\"nofollow\">DOI:10.1103/PhysRevA.59.569</a>,\n\
    <a href=\"http://www.jetp.ac.ru/cgi-bin/dn/e_020_05_1307.pdf\" rel=\"nofollow\"\
    >LV Keldysh</a>, BSI)</li>\n</ul>\n<p>Besides the electro-magnetic PIC algorithm\
    \ and extensions to it, we developed\na wide range of tools and diagnostics, e.g.:</p>\n\
    <ul>\n<li>online, far-field radiation diagnostics for coherent and incoherent\
    \ radiation\nemitted by charged particles</li>\n<li>full restart and output capabilities\
    \ via <a href=\"http://openPMD.org\" rel=\"nofollow\">openPMD</a>,\nincluding\
    \ <a href=\"http://hdfgroup.org/\" rel=\"nofollow\">parallel HDF5</a>\n</li>\n\
    <li>2D and 3D live view and diagnostics tools</li>\n<li>a large selection of extensible\n\
    <a href=\"http://picongpu.readthedocs.io/en/latest/usage/plugins.html\" rel=\"\
    nofollow\">online-plugins</a>\n</li>\n</ul>\n<p>As one of our supported compute\
    \ platforms, GPUs provide a computational\nperformance of several\n<a href=\"\
    http://en.wikipedia.org/wiki/FLOPS\" rel=\"nofollow\">TFLOP/s</a> at considerable\
    \ lower invest and\nmaintenance costs compared to multi CPU-based compute architectures\
    \ of similar\nperformance. The latest high-performance systems\n(<a href=\"http://www.top500.org/\"\
    \ rel=\"nofollow\">TOP500</a>) are enhanced by accelerator hardware that\nboost\
    \ their peak performance up to the multi-PFLOP/s level. With its\noutstanding\
    \ performance and scalability to more than 18'000 GPUs,\nPIConGPU was one of the\
    \ <strong>finalists</strong> of the 2013\n<a href=\"http://sc13.supercomputing.org/content/acm-gordon-bell-prize\"\
    \ rel=\"nofollow\">Gordon Bell Prize</a>.</p>\n<p>PIConGPU is developed and maintained\
    \ by the\n<a href=\"https://www.hzdr.de/db/Cms?pNid=2097\" rel=\"nofollow\">Computational\
    \ Radiation Physics Group</a>\nat the <a href=\"http://www.hzdr.de/db/Cms?pNid=132\"\
    \ rel=\"nofollow\">Institute for Radiation Physics</a>\nat <a href=\"http://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> in close collaboration with the Center\nfor Information\
    \ Services and High Performance Computing\n(<a href=\"http://tu-dresden.de/die_tu_dresden/zentrale_einrichtungen/zih\"\
    \ rel=\"nofollow\">ZIH</a>) of the\nTechnical University Dresden (<a href=\"http://www.tu-dresden.de\"\
    \ rel=\"nofollow\">TUD</a>). We are a\nmember of the <a href=\"http://ccoe-dresden.de/\"\
    \ rel=\"nofollow\">Dresden GPU Center of Excellence</a> that\ncooperates on a\
    \ broad range of scientific GPU and manycore applications,\nworkshops and teaching\
    \ efforts.</p>\n<h2><a id=\"user-content-attribution\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#attribution\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Attribution</h2>\n<p>PIConGPU is a <em>scientific\
    \ project</em>. If you <strong>present and/or publish</strong> scientific\nresults\
    \ that used PIConGPU, you should set a <strong>reference</strong> to show your\
    \ support.</p>\n<p>Our according <strong>up-to-date publication</strong> at <strong>the\
    \ time of your publication</strong>\nshould be inquired from:</p>\n<ul>\n<li><a\
    \ href=\"https://raw.githubusercontent.com/ComputationalRadiationPhysics/picongpu/master/REFERENCE.md\"\
    \ rel=\"nofollow\">REFERENCE.md</a></li>\n</ul>\n<p>Please also consider adding\
    \ yourself to our <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu-communitymap\"\
    >community map</a>.\nWe would love to hear from you!</p>\n<h2><a id=\"user-content-oral-presentations\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#oral-presentations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Oral Presentations</h2>\n\
    <p>The following slide should be part of <strong>oral presentations</strong>.\
    \ It is intended to\nacknowledge the team maintaining PIConGPU and to support\
    \ our community:</p>\n<p>(<em>coming soon</em>) presentation_picongpu.pdf\n(svg\
    \ version, key note version, png version: 1920x1080 and 1024x768)</p>\n<h2><a\
    \ id=\"user-content-software-license\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#software-license\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Software License</h2>\n<p><em>PIConGPU</em> is licensed under the\
    \ <strong>GPLv3+</strong>. Furthermore, you can develop your\nown particle-mesh\
    \ algorithms based on our general library <em>PMacc</em> that is\nshipped alongside\
    \ PIConGPU. <em>PMacc</em> is <em>dual licensed</em> under both the\n<strong>GPLv3+\
    \ and LGPLv3+</strong>.\nFor a detailed description, please refer to <a href=\"\
    LICENSE.md\">LICENSE.md</a></p>\n<hr>\n<h2><a id=\"user-content-install\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#install\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Install</h2>\n<p>See our notes\
    \ in <a href=\"INSTALL.rst\">INSTALL.rst</a>.</p>\n<h2><a id=\"user-content-users\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#users\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Users</h2>\n\
    <p>Dear User, we hereby emphasize that we are still actively developing PIConGPU\
    \ at great\nspeed and do, from time to time, break backwards compatibility.</p>\n\
    <p>When using this software, please stick to the latest release or use the <code>dev</code>\
    \ branch containing the\nlatest changes. It also contains a file <code>CHANGELOG.md</code>\
    \ with the\nlatest changes (and how to update your simulations). Read it first\
    \ before\nupdating between two versions! Also, we add a git <code>tag</code> according\
    \ to a version\nnumber for each release.</p>\n<p>For any questions regarding the\
    \ usage of PIConGPU please <strong>do not</strong> contact the\ndevelopers and\
    \ maintainers directly.</p>\n<p>Instead, please <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/issues/new\"\
    >open an issue on GitHub</a>.</p>\n<p>Before you post a question, browse the PIConGPU\n\
    <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/search?l=markdown\"\
    >documentation</a>,\n<a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/wiki\"\
    >wiki</a> and the\n<a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/issues\"\
    >issue tracker</a>\nto see if your question has been answered, already.</p>\n\
    <p>PIConGPU is a collaborative project.\nWe thus encourage users to engage in\
    \ answering questions of other users and post solutions to problems to the list.\n\
    A problem you have encountered might be the future problem of another user.</p>\n\
    <p>In addition, please consider using the collaborative features of GitHub if\
    \ you have questions or comments on code or documentation.\nThis will allow other\
    \ users to see the piece of code or documentation you are referring to.</p>\n\
    <p>Main ressources are in our <a href=\"https://picongpu.readthedocs.io\" rel=\"\
    nofollow\">online manual</a>, the <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/wiki\"\
    >user section</a> of our wiki, documentation files in <a href=\"http://commonmark.org/help/\"\
    \ rel=\"nofollow\"><code>.md</code> (Markdown)</a> and <a href=\"http://www.sphinx-doc.org/en/stable/rest.html\"\
    \ rel=\"nofollow\"><code>.rst</code> (reStructuredText)</a> format in this repository\
    \ and a <a href=\"http://www.youtube.com/watch?v=7ybsD8G4Rsk\" rel=\"nofollow\"\
    >getting started video</a>.\nFeel free to visit <a href=\"http://picongpu.hzdr.de\"\
    \ rel=\"nofollow\">picongpu.hzdr.de</a> to learn more about the PIC algorithm.</p>\n\
    <h2><a id=\"user-content-software-upgrades\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#software-upgrades\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Software Upgrades</h2>\n<p>PIConGPU ships new\
    \ and frequent changes to the code in the development branch <code>dev</code>.</p>\n\
    <p>From time to time we publish a new release\nof PIConGPU. Before you pull the\
    \ changes in, please read our\n<a href=\"CHANGELOG.md\">ChangeLog</a>!\nYou may\
    \ have to update some of your simulation <code>.param</code> and <code>.cfg</code>\
    \ files by\nhand since PIConGPU is an active project and new features often require\
    \ changes\nin input files. Additionally, a full description of new features and\
    \ fixed bugs\nin comparison to the previous release is provided in that file.</p>\n\
    <p>In case you decide to use <em>new, potentially buggy and experimental</em>\
    \ features\nfrom our <code>dev</code> branch, be aware that you must participate\
    \ or at least follow the development yourself.\nSyntax changes and in-development\
    \ bugs will <em>not</em> be announced outside of their according pull\nrequests\
    \ and issues.</p>\n<p>Before drafting a new release, we open a new <code>release-*</code>\
    \ branch from <code>dev</code> with\nthe <code>*</code> being the version number\
    \ of the upcoming release. This branch only\nreceives bug fixes (feature freeze)\
    \ and users are welcome to try it out\n(however, the change log and a detailed\
    \ announcement might still be missing in\nit).</p>\n<h2><a id=\"user-content-developers\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#developers\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developers</h2>\n\
    <h3><a id=\"user-content-how-to-participate\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#how-to-participate\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>How to participate</h3>\n<p>See <a\
    \ href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a></p>\n<p>If you like to jump in\
    \ right away, see<br>\n<a href=\"https://github.com/ComputationalRadiationPhysics/picongpu/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22\"\
    ><img src=\"https://camo.githubusercontent.com/32b730b309ff90c1713e8ae39a73ae2145c4cceb0b7e72bacef523db9fc85d62/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d7261772f436f6d7075746174696f6e616c526164696174696f6e506879736963732f7069636f6e6770752f676f6f64253230666972737425323069737375652e7376673f636f6c6f723d353663626566\"\
    \ alt=\"open &quot;good first issue&quot; issues\" data-canonical-src=\"https://img.shields.io/github/issues-raw/ComputationalRadiationPhysics/picongpu/good%20first%20issue.svg?color=56cbef\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-active-team\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#active-team\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Active Team</h2>\n\
    <h3><a id=\"user-content-scientific-supervision\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#scientific-supervision\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Scientific Supervision</h3>\n<ul>\n\
    <li>Dr. Michael Bussmann</li>\n</ul>\n<h3><a id=\"user-content-maintainers-and-core-developers\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#maintainers-and-core-developers\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Maintainers*\
    \ and core developers</h3>\n<ul>\n<li>Dr. Sergei Bastrakov*</li>\n<li>Finn-Ole\
    \ Carstens</li>\n<li>Dr. Alexander Debus</li>\n<li>Dr. Marco Garten*</li>\n<li>Dr.\
    \ Axel Huebl*</li>\n<li>Brian Edward Marre</li>\n<li>Pawel Ordyna</li>\n<li>Dr.\
    \ Richard Pausch*</li>\n<li>Franz Poeschel</li>\n<li>Dr. Klaus Steiniger*</li>\n\
    <li>Rene Widera*</li>\n</ul>\n<h3><a id=\"user-content-former-members-contributions-and-thanks\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#former-members-contributions-and-thanks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Former Members,\
    \ Contributions and Thanks</h3>\n<p>The PIConGPU Team expresses its gratitude\
    \ to:</p>\n<p>Florian Berninger, Heiko Burau, Fabia Dietrich, Robert Dietrich,\
    \ Carlchristian Eckert,\nSimeon Ehrig, Wen Fu, Ph.D., Alexander Grund, Sebastian\
    \ Hahn, Anton Helm, Wolfgang Hoehnig,\nDr.-Ing. Guido Juckeland, Jeffrey Kelling,\
    \ Maximilian Knespel, Dr. Remi Lehe,\nFelix Schmitt, Frank Winkler, Benjamin Schneider,\
    \ Joseph Schuchart, Conrad Schumann,\nStefan Tietze, Marija Vranic, Ph.D., Benjamin\
    \ Worpitz, Erik Zenker,\nSophie Rudat, Sebastian Starke, Alexander Matthes, Kseniia\
    \ Bastrakova,\nBernhard Manfred Gruber, Jakob Trojok, Anton Lebedev, Nils Prinz,\n\
    Felix Meyer, Lennert Sprenger, Manhui Wang, Maxence Thevenet, Ilja Goethel,\n\
    Mika Soren Vo\xDF, Lei Bifeng, Andrei Berceanu, Felix Meyer,\nLennert Sprenger\
    \ and Nico Wrobel.</p>\n<p>Kudos to everyone, mentioned or unmentioned, who contributed\
    \ further in any\nway!</p>\n<hr>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"docs/images/lwfa_iso.png\"><img src=\"docs/images/lwfa_iso.png\" alt=\"\
    image of an lwfa\" title=\"LWFA\" style=\"max-width: 100%;\"></a>\n<a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"docs/images/StrongScalingPIConGPU_log.png\"\
    ><img src=\"docs/images/StrongScalingPIConGPU_log.png\" alt=\"image of our strong\
    \ scaling\" title=\"Strong Scaling\" style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 654
  subscribers_count: 49
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - physics-simulation
  - gpu-computing
  - particle-accelerator
  - particle-in-cell
  - pic
  - research
  updated_at: 1701122139.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/23.08/cuda-x86_64/spack.yaml
  - environments/21.05/spack.yaml
  - environments/23.11/cuda-ppc64le/spack.yaml
  - environments/22.05/rocm.spack.yaml
  - environments/23.05/cuda-x86_64/spack.yaml
  - environments/23.11/cuda-x86_64/spack.yaml
  - environments/21.08/spack.yaml
  - environments/23.08/cuda-aarch64/spack.yaml
  - environments/23.08/oneapi-x86_64/spack.yaml
  - environments/23.02/cuda-ppc64le/spack.yaml
  - environments/22.05/cuda-x86_64.spack.yaml
  - environments/23.05/rocm-x86_64/spack.yaml
  - environments/23.02/cuda-x86_64/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: v23.11
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#e4s\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#useful-links\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n\
    <ul>\n<li>User Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\"\
    >https://e4s.readthedocs.io</a>\n</li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub:\
    \ <a href=\"https://github.com/E4S-Project/\">https://github.com/E4S-Project/</a>\n\
    </li>\n<li>E4S Slack Channel: <a href=\"https://e4s-project.slack.com\" rel=\"\
    nofollow\">https://e4s-project.slack.com</a>\n</li>\n<li>Slack Channel Invitation:\
    \ <a href=\"https://communityinviter.com/apps/e4s-project/e4s\" rel=\"nofollow\"\
    >https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n<li>E4S Dashboard:\
    \ <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"\
    https://github.com/E4S-Project/E4S-Project.github.io\">E4S-Project/E4S-Project.github.io</a>\
    \ - E4S Documentation repo that is hosted on <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>E4S is released as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 21
  subscribers_count: 10
  topics: []
  updated_at: 1700727642.0
ECP-CANDLE/Supervisor:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: ECP-CANDLE/Supervisor
  latest_release: null
  stargazers_count: 7
  subscribers_count: 11
  topics:
  - nci-doe-collaboration-capability
  updated_at: 1690319274.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, time-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '23.11'
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" tabindex="-1"
    href="#warpx"><span aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/discussions"><img src="https://camo.githubusercontent.com/dcbb262bbe27c41e6885c404f5cac70d3a21a42b6499e931fed8c874879b7ef6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667"
    alt="Discussions" data-canonical-src="https://img.shields.io/badge/chat-discussions-turquoise.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1109/SC41404.2022.00008" rel="nofollow"><img src="https://camo.githubusercontent.com/2be0ab9ceaff22581aac9ee5d5eac9cc73cae7e4bad2c69bcf0ffd6713337293/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our discussions page at <a href="https://github.com/ECP-WarpX/WarpX/discussions">https://github.com/ECP-WarpX/WarpX/discussions</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-copyright-notice" class="anchor" aria-hidden="true" tabindex="-1"
    href="#copyright-notice"><span aria-hidden="true" class="octicon octicon-link"></span></a>Copyright
    Notice</h2>

    <p>WarpX Copyright (c) 2018, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>Please see the full license agreement in <a href="LICENSE.txt">LICENSE.txt</a>.

    The SPDX license identifier is <code>BSD-3-Clause-LBNL</code>.</p>

    '
  stargazers_count: 224
  subscribers_count: 13
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1701250095.0
ExCALIBUR-NEPTUNE/NESO:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: ExCALIBUR-NEPTUNE/NESO
  latest_release: null
  readme: "<h1><a id=\"user-content-neso-neptune-exploratory-software\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#neso-neptune-exploratory-software\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>NESO (Neptune\
    \ Exploratory SOftware)</h1>\n<p>This is a work-in-progress respository for exploring\
    \ the implementation of\na series of tokamak exhaust relevant models combining\
    \ high order finite\nelements with particles, written in C++ and SYCL.</p>\n<h2><a\
    \ id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Dependencies</h2>\n<ul>\n<li>CMake</li>\n<li>Boost &gt;= 1.74 (for\
    \ tests)</li>\n<li>SYCL implementation Hipsycl and fftw or OneAPI and MKL.</li>\n\
    <li>Nektar++</li>\n<li>NESO-Particles</li>\n</ul>\n<h3><a id=\"user-content-building-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ with Spack</h3>\n<p>The easiest way to install NESO is using the\n<a href=\"\
    https://spack.readthedocs.io/en/latest/index.html\" rel=\"nofollow\">Spack package\
    \ manager</a>, although\nthis can take a few hours the first time you do it or\
    \ if you change\ncompilers. This repository has been set up so you can use a\n\
    variation of the <a href=\"https://spack-tutorial.readthedocs.io/en/latest/tutorial_developer_workflows.html\"\
    \ rel=\"nofollow\">Spack developer\nworkflow</a>. Simply\nrun the following commands\
    \ at the top level of the repository:</p>\n<p>If you don't already have Spack\
    \ available on your computer, install it\naccording to the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">official documentation</a>, or as follows:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Ensure all prerequisites are installed</span>\napt update <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> For Ubuntu; other distros have their own\
    \ commands</span>\napt install build-essential ca-certificates coreutils curl\
    \ environment-modules gfortran git gpg lsb-release python3 python3-distutils python3-venv\
    \ unzip zip\n\ngit clone -c feature.manyFiles=true -b v0.19.0 https://github.com/spack/spack.git\
    \ <span class=\"pl-smi\">$HOME</span>/.spack\n<span class=\"pl-c1\">echo</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">'</span>export SPACK_ROOT=$HOME/.spack<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span\
    \ class=\"pl-smi\">$HOME</span>/.bashrc\n<span class=\"pl-c1\">echo</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span>source $SPACK_ROOT/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span\
    \ class=\"pl-smi\">$HOME</span>/.bashrc\n<span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-smi\">$HOME</span>/.spack\n<span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$SPACK_ROOT</span>/share/spack/setup-env.sh</pre></div>\n<p>Next,\
    \ install the Intel compilers if they are not already present on\nyour computer.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>spack install intel-oneapi-compilers\n\
    spack load intel-oneapi-compilers\nspack compiler find\nspack unload intel-oneapi-compilers</pre></div>\n\
    <p>Now, activate the NESO development environment and build it and its\ndependencies.\
    \ This must be done from the top level of this\nrepository.</p>\n<pre><code>git\
    \ submodule update --init\n. activate\nspack install\n</code></pre>\n<p>The <code>activate</code>\
    \ script sets some useful environment variables and runs\n<code>spack activate\
    \ ...</code>. This activates an <a href=\"https://spack.readthedocs.io/en/latest/environments.html#anonymous-environments\"\
    \ rel=\"nofollow\">anonymous Spack\nenvironment</a>\nbased on the settings in\
    \ <a href=\"spack.yaml\">the spack.yaml file</a>. These\nconfigurations tell Spack\
    \ to install NESO and all of its\ndependencies. Rather than pulling fresh NESO\
    \ and Nektar++ source code\nfrom GitHub, it will use the copy of the code in your\
    \ current working\ndirectory and the Nektar++ submodule (respectively). You can\
    \ leave\nthis environment at any time by running <code>deactivate</code>.</p>\n\
    <p><code>spack install</code> will build two copies of NESO: one with\nGCC/hipSYCL/FFTW3\
    \ and one with Intel's OneAPI/DPC++/MKL. These\npackages and their dependencies\
    \ will be installed in the usual Spack\nlocations. They will also be linked into\
    \ <a href=\"https://spack.readthedocs.io/en/latest/environments.html#filesystem-views\"\
    \ rel=\"nofollow\">\"filesystem\nviews\"</a>\n<code>view/gcc-hipsycl</code> and\
    \ <code>view/oneapi-dpcpp</code>. The NESO builds will be\ndone in directories\
    \ called something like <code>spack-build-abc1234</code> (the\nhashes at the end\
    \ will differ). If you change your spack installation\nin some way (e.g., upgrading\
    \ the version of a dependency) then the\nhash will change and NESO and/or Nektar++\
    \ will be rebuilt. The\nactivation provides the convenience command <code>cleanup</code>\
    \ to delete these\nold builds.</p>\n<p>In order to tell which build is which,\
    \ symlinks <code>builds/gcc-hipsycl</code>\nand <code>builds/oneapi-dpcpp</code>\
    \ are provided. As Nektar++ is being built\nfrom the submodule, its build trees\
    \ are located at\n<code>nektar/spack-build-abc1234</code> (the hashes at the end\
    \ will differ) and\ncan be accessed with symlinks <code>nektar/builds/gcc</code>\
    \ and\n<code>nektar/builds/oneapi</code>. Test binaries will be contained within\n\
    these build directories. The activation script launches a background\ntask which\
    \ regularly checks whether the hashes of your NESO and\nNektar++ builds has changed.\
    \ If they have, it will update the\nsymlinks. They will also be checked whenever\
    \ the environment is\nactivated or deactivated.</p>\n<p>It has been found that\
    \ the oneAPI and clang\ncompilers struggle to build NumPy and Boost due to very\
    \ large memory\nrequirements. As such, the oneAPI build of NESO compiles these\n\
    dependencies using another compiler  (the Intel Classic compilers by default).\
    \ Feel free to\nexperiment with changing these or seeing if there is a way to\
    \ make the\nbuilds work with oneAPI.</p>\n<h4><a id=\"user-content-developing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#developing\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developing</h4>\n\
    <p>As you develop the code, there are a few options for how you\nrecompile. One\
    \ is simply to run <code>spack install</code> again. This will reuse\nthe existing\
    \ build directory and reinstall the results of the\nbuild. The build environment\
    \ used is determined by the package\nconfiguration for NESO (as specificed in\
    \ the NESO <a href=\"https://github.com/ExCALIBUR-NEPTUNE/NESO-Spack\">package\n\
    repository</a> and is\nthe same as if you were doing a traditional Spack installation\
    \ of a\nnamed version of NESO. This has the particular advantage of building\n\
    with all toolchaings (i.e., GCC, OneAPI) at one time. It also works\nwell if you\
    \ are developing NESO and Nektar++ simultaneously, as it\nwill rebuild both. The\
    \ main disadvantage of this approach is that\nSpack hides the output of CMake\
    \ during the build process and will only\nshow you any information on the build\
    \ if there is an error. This means\nyou will likely miss any compiler warnings,\
    \ unless you check the build\nlogs. There is also some overhead associated with\
    \ running Spack, which\nmakes the build a little slow.</p>\n<p>An alternative\
    \ approach is to prefix your usual build commands with\n<code>spack build-env\
    \ neso%gcc</code> or <code>spack build-env neso%oneapi</code> (depending\non which\
    \ compiler you want to use). This will cause the commands to be run in the\nsame\
    \ build environment as when installing that version of NESO. For example, you\n\
    could run</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack build-env\
    \ neso%gcc cmake <span class=\"pl-c1\">.</span> -B build\nspack build-env neso%gcc\
    \ cmake --build build</pre></div>\n<p>This would cause the build to occur in the\
    \ directory <code>build</code>. This\napproach works quite well. A slight downside\
    \ is the commands are\na bit cumbersome. It also won't build for both compilers\
    \ at once,\nalthough you might not want to do that anyway, early during the development\n\
    of a new feature.</p>\n<p>Finally, you could take advantage of the filesystem\
    \ views created\nwhen you installed the environment and which give you access\n\
    to all of the resources for the build that you need. For example, you\ncould run</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>cmake -DCMAKE_PREFIX_PATH=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span class=\"pl-pds\">)</span></span>/gcc-hipsycl\
    \ <span class=\"pl-c1\">.</span> -B build\ncmake --build build</pre></div>\n<p>CMake\
    \ will automatically be able to find all of the packages it needs\nin <code>gcc-hipsycl</code>.\
    \ The downside of this approach is that there is a\nrisk CMake will end up using\
    \ a different compiler or compiler version\nthan intended. This is especially\
    \ likely if not using a system\ncompiler. You should ensure you are aware of what\
    \ compilers you have\ninstalled and, if necessary, explicitly specify to CMake\
    \ which you\nwant to use.</p>\n<p>In general, it is recommended to use the <code>spack\
    \ build-env ...</code>\ncommand for compiling earlier in the development process\
    \ (if you\naren't simultaneously making changes to Nektar++), to ensure you see\n\
    any warnings and so you aren't spending extra times compiling things\ntwice. Once\
    \ you believe you have a working implementation with one\ncompiler (of if you\
    \ are working on NESO and Nektar++ simultaneously),\nyou can use <code>spack install</code>\
    \ to test the build against other\ncompilers. It is <em>not</em> recommended to\
    \ use the Spack views, as building\nthis way is less likely to be reproducible.</p>\n\
    <h3><a id=\"user-content-manually-installing-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#manually-installing-dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manually Installing Dependencies</h3>\n\
    <h4><a id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>CMake</h4>\n<p>Ensure a recent version of <a href=\"https://cmake.org/download/\"\
    \ rel=\"nofollow\">CMake</a> is available.\nIf necessary, install with</p>\n<pre><code>wget\
    \ https://github.com/Kitware/CMake/releases/download/v3.23.1/cmake-3.23.1.tar.gz\n\
    tar xvf cmake-3.23.1.tar.gz\ncd cmake-3.23.1/\n./configure\nmake\n</code></pre>\n\
    <h4><a id=\"user-content-boost\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#boost\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Boost</h4>\n<p>The test suite requires the <a href=\"https://www.boost.org/\"\
    \ rel=\"nofollow\">Boost library</a> (version &gt;= 1.74).\nIf this is not available\
    \ on your system, it can be built from source by doing</p>\n<pre><code>wget https://boostorg.jfrog.io/artifactory/main/release/1.79.0/source/boost_1_79_0.tar.gz\n\
    tar xvf boost_1_79_0.tar.gz\ncd boost_1_79_0/\n./bootstrap.sh\n./b2\n</code></pre>\n\
    <p>If the install is not automatically found by cmake, specify the path to the\n\
    install dir at configure time:</p>\n<pre><code>cmake -DBoost_INCLUDE_DIR=/path/to/boost_1_79_0/\
    \ . -B build\n</code></pre>\n<h4><a id=\"user-content-nektar\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#nektar\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Nektar++</h4>\n<p>To build with Nektar++,\
    \ ensure that Nektar++ is installed on your system.\nDetailed instructions can\
    \ be found in the <a href=\"https://doc.nektar.info/userguide/latest/user-guidese3.html#x7-60001.3\"\
    \ rel=\"nofollow\">Nektar user guide</a>,\nbut briefly,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>git clone https://gitlab.nektar.info/nektar/nektar\n\
    <span class=\"pl-c1\">cd</span> nektar\nmkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build\ncmake .. \ncmake --build <span class=\"\
    pl-c1\">.</span>\nmake install</pre></div>\n<p>should install Nektar++.</p>\n\
    <p>To build NESO with Nektar++, set the <code>Nektar++_DIR</code> flag in cmake,\
    \ e.g.</p>\n<pre><code>cmake -DNektar++_DIR=/path/to/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>where <code>/path/to/nektar/build/dist/lib64/nektar++/cmake</code>\
    \ is the folder containing\nthe <code>Nektar++Config.cmake</code> file.\nNote\
    \ that for this file to exist, you must do <code>make install</code> at the end\
    \ of the\nNektar++ build.</p>\n<h3><a id=\"user-content-neso-particles\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#neso-particles\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>NESO-Particles</h3>\n<p>Install\
    \ NESO-Particles by following the installation instructions at <a href=\"https://github.com/ExCALIBUR-NEPTUNE/NESO-Particles\"\
    >https://github.com/ExCALIBUR-NEPTUNE/NESO-Particles</a>. Additional configuration\
    \ options for NESO-Particles can be passed when NESO is configured through cmake.</p>\n\
    <h3><a id=\"user-content-neso\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#neso\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>NESO</h3>\n<h3><a id=\"user-content-manually-building-neso\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#manually-building-neso\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manually\
    \ building NESO</h3>\n<p>To build the code and the tests, do</p>\n<pre><code>cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>It may be necessary to tell\
    \ CMake the location of dependencies:</p>\n<ul>\n<li>Boost by setting <code>-DBoost_INCLUDE_DIR</code>\n\
    </li>\n<li>SYCL compiler by setting <code>-DCMAKE_CXX_COMPILER</code>\n</li>\n\
    <li>Nektar++ by setting the location of <code>Nektar++Config.cmake</code> using\
    \ <code>-DNektar++_DIR</code>\n</li>\n</ul>\n<p>For example:</p>\n<pre><code>cmake\
    \ -DCMAKE_CXX_COMPILER=dpcpp -DBoost_INCLUDE_DIR=/root/code/boost_1_78_0 -DNektar++_DIR=/root/code/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>The executable <code>NESO</code>\
    \ is created in <code>bin</code>.</p>\n<h2><a id=\"user-content-handling-submodules-when-developing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#handling-submodules-when-developing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Handling\
    \ Submodules when Developing</h2>\n<p>This repository contains some git submodules,\
    \ for code which is likely\nto undergo development tightly-coupled with NESO (e.g.,\
    \ Nektar) or\nwhich it is convenient to distribute this way (NESO-spack). When\n\
    checking out different branches, on which submodules are at different\ncommits,\
    \ it can be easy to end up with working against different\nversions of submodules\
    \ than you think. This can cause headaches when\ntrying to reproduce certain behaviour.\
    \ Run <code>git submodule update --recursive</code> to ensure everything is at\
    \ the correct commit. You can\navoid this issue altogether by using <code>git\
    \ checkout --recurse-submodules</code>. You can also set this as a default for\
    \ your\ncopy of the repository by running <code>git config --local submodule.recurse\
    \ true</code>. Note, however, that these latter two options\ncan cause git to\
    \ complain if trying to switch between two branches,\nonly one of which contains\
    \ a submodule.</p>\n<h2><a id=\"user-content-system-specific-information\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#system-specific-information\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System-specific\
    \ information</h2>\n<h3><a id=\"user-content-dirac-csd3--cambridge\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#dirac-csd3--cambridge\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dirac (CSD3\
    \ @ Cambridge)</h3>\n<pre><code>module unload intel/compilers/2017.4\nmodule unload\
    \ intel/mkl/2017.4\nmodule load gcc/11\nmodule load intel/oneapi/2022.1.0/compiler\n\
    module load intel/oneapi/2022.1.0/mkl\nmodule load intel/oneapi/2022.1.0/tbb\n\
    export  LD_LIBRARY_PATH=/usr/local/software/intel/oneapi/2022.1/compiler/latest/linux/lib:$LD_LIBRARY_PATH\n\
    </code></pre>\n<h2><a id=\"user-content-testing\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#testing\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Testing</h2>\n<p>CMake also builds a suite unit tests\
    \ (e.g. <code>&lt;build_dir&gt;/test/unitTests</code>)\nand integration tests\
    \ (<code>&lt;build_dir&gt;/test/integrationTests</code>). The build\ndirectories\
    \ are <code>builds/gcc-hipsycl</code> and <code>builds/oneapi-dpcpp</code>.</p>\n\
    <p>A subset of the tests may be run using appropriate flags:\ne.g. <code>path/to/testExecutable\
    \ --gtest_filter=TestSuiteName.TestName</code>.\nSee the <a href=\"http://google.github.io/googletest/\"\
    \ rel=\"nofollow\">googletest user guide</a>\nfor more info, especially with regards\
    \ to running <a href=\"https://google.github.io/googletest/advanced.html#selecting-tests\"\
    \ rel=\"nofollow\">specific\ntests</a>.</p>\n<p>Alternatively, you can call\n\
    <a href=\"https://cmake.org/cmake/help/latest/manual/ctest.1.html\" rel=\"nofollow\"\
    >CTest</a> from\nwithin the build directory to execute your tests.</p>\n<h1><a\
    \ id=\"user-content-solvers\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#solvers\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Solvers</h1>\n<p>Each solver has</p>\n<ul>\n<li>Source code: <code>solvers/&lt;solver_name&gt;</code>\n\
    </li>\n<li>Integration tests: <code>test/integration/solvers/&lt;solver_name&gt;</code>\n\
    </li>\n<li>Examples: <code>examples/&lt;solver_name&gt;/&lt;example_name&gt;</code>\n\
    </li>\n</ul>\n<p>To run a solver example:</p>\n<pre><code>./scripts/run_eg.sh\
    \  [solver_name] [example_name] &lt;-n num_MPI&gt; &lt;-b build_dir&gt;\n</code></pre>\n\
    <p>which will look for the solver executable in the most recently modified spack-build-*\
    \ directory, unless one is supplied with <code>-b</code>.  Output is generated\
    \ in <code>example-runs/&lt;solver_name&gt;/&lt;example_name&gt;</code>.</p>\n\
    <h2><a id=\"user-content-address-sanitizers\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#address-sanitizers\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Address Sanitizers</h2>\n<p>To debug\
    \ for memory leaks, compile with the options</p>\n<pre><code>cmake . -B -DENABLE_SANITIZER_ADDRESS=on\
    \ -DENABLE_SANITIZER_LEAK=on\n</code></pre>\n<h2><a id=\"user-content-licence\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#licence\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Licence</h2>\n\
    <p>This is licenced under MIT.</p>\n<p>In order to comply with the licences of\
    \ dependencies, this software is not to be released as a binary.</p>\n"
  stargazers_count: 4
  subscribers_count: 7
  topics: []
  updated_at: 1688873161.0
Exawind/exawind-builder:
  data_format: 2
  description: Scripts to help building Exawind codes on various systems
  filenames:
  - etc/spack/nrel-eagle/spack.yaml
  - etc/spack/spack/spack.yaml
  full_name: Exawind/exawind-builder
  latest_release: v0.1.0
  readme: '<h1><a id="user-content-exawind-code-builder" class="anchor" aria-hidden="true"
    tabindex="-1" href="#exawind-code-builder"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>ExaWind Code Builder</h1>

    <p><a href="https://exawind.github.io/exawind-builder" rel="nofollow">Documentation</a></p>

    <p>ExaWind Builder is a collection of bash scripts to configure and compile the

    codes used within the <a href="https://github.com/exawind">ExaWind</a> project
    on various

    high-performance computing (HPC) systems. The builder provides the following</p>

    <ul>

    <li>

    <p><strong>Platform configuration</strong>: Provides the minimal set of modules
    that must be

    loaded when compiling with different compilers and MPI libraries on different

    HPC systems.</p>

    </li>

    <li>

    <p><strong>Software configuration</strong>: Provides baseline CMake configuration
    that can be

    used to configure the various options when building a <em>project</em>, e.g.,

    enable/disable optional modules, automate specification of paths to various

    libraries, configure release vs. debug builds.</p>

    </li>

    <li>

    <p><strong>Build script generation</strong>: Generates an executable end-user
    script for a

    combination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>

    </li>

    <li>

    <p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific

    script that allows the user to recreate the exact environment used to build

    the codes during runtime.</p>

    </li>

    </ul>

    <p>The build scripts are intended for developers who might want to compile the

    codes with different configuration options, build different branches during

    their development cycle, or link to a different development version of a library

    that is currently not available in the standard installation on the system. Please
    see the

    <a href="https://exawind.github.io/exawind-builder" rel="nofollow">documentation</a>
    for

    details on how to use this to build ExaWind software.</p>

    <h2><a id="user-content-installation-and-usage" class="anchor" aria-hidden="true"
    tabindex="-1" href="#installation-and-usage"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Installation and usage</h2>

    <h3><a id="user-content-using-exawind-builder-with-pre-installed-exawind-environment"
    class="anchor" aria-hidden="true" tabindex="-1" href="#using-exawind-builder-with-pre-installed-exawind-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using exawind-builder
    with pre-installed ExaWind environment</h3>

    <p>ExaWind Builder is already installed and setup on OLCF Summit, NREL

    Eagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly

    to using build scripts from the central installation. Please consult <a href="https://exawind.github.io/exawind-builder/basic.html#basic-usage"
    rel="nofollow">user

    manual</a> to

    learn how to use the scripts.</p>

    <h3><a id="user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions"
    class="anchor" aria-hidden="true" tabindex="-1" href="#bootstrapping-exawind-builder-with-pre-configured-system-definitions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bootstrapping exawind-builder
    with pre-configured system definitions</h3>

    <p>ExaWind builder has <a href="https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems"
    rel="nofollow">pre-built

    configurations</a>

    for several systems. On these systems you can use the <code>bootstrap</code> script
    to

    quickly get up and running. Please consult <a href="https://exawind.github.io/exawind-builder/installation.html"
    rel="nofollow">installation

    manual</a>. The

    relevant steps are shown below.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Download bootstrap script</span>

    curl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Make it executable</span>

    chmod a+x bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Execute bootstrap and provide system/compiler
    combination</span>

    ./bootstrap.sh -s [SYSTEM] -c [COMPILER]


    <span class="pl-c"><span class="pl-c">#</span> Examples</span>

    ./bootstrap.sh -s spack -c clang       <span class="pl-c"><span class="pl-c">#</span>
    On MacOS with homebrew</span>

    ./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system

    ./bootstrap.sh -s eagle -c gcc         <span class="pl-c"><span class="pl-c">#</span>
    NREL Eagle</span>

    ./bootstrap.sh -s cori -c intel        <span class="pl-c"><span class="pl-c">#</span>
    NERSC Cori</span>

    ./bootstrap.sh -s snl-ascicgpu -c gcc  <span class="pl-c"><span class="pl-c">#</span>
    SNL GPU development machine</span></pre></div>

    <h3><a id="user-content-creating-new-system-configuration" class="anchor" aria-hidden="true"
    tabindex="-1" href="#creating-new-system-configuration"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Creating new system configuration</h3>

    <p>You can add new system definitions to exawind-builder for use on new systems

    that are not used by ExaWind team. Please see <a href="https://exawind.github.io/exawind-builder/advanced.html"
    rel="nofollow">manual

    installation</a> and

    <a href="https://exawind.github.io/exawind-builder/newsys.html" rel="nofollow">adding
    a new system</a>

    sections in the user manual.</p>

    <h2><a id="user-content-links" class="anchor" aria-hidden="true" tabindex="-1"
    href="#links"><span aria-hidden="true" class="octicon octicon-link"></span></a>Links</h2>

    <ul>

    <li><a href="https://www.exawind.org" rel="nofollow">ExaWind</a></li>

    <li><a href="https://github.com/exawind">ExaWind GitHub Organization</a></li>

    <li><a href="https://a2e.energy.gov/about/hfm" rel="nofollow">A2e HFM</a></li>

    </ul>

    '
  stargazers_count: 3
  subscribers_count: 5
  topics:
  - cmake
  - build
  - exawind
  - hpc
  - exawind-builder
  updated_at: 1643028069.0
FTHPC/Correlation_Compressibility:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: FTHPC/Correlation_Compressibility
  latest_release: v0.1
  readme: "<h1><a id=\"user-content-compressibility-analysis-correlation_compressibility\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#compressibility-analysis-correlation_compressibility\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compressibility\
    \ Analysis (Correlation_Compressibility)</h1>\n<h2><a id=\"user-content-statement-of-purpose\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#statement-of-purpose\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Statement\
    \ of Purpose</h2>\n<p>This repo contains scripts to perform compressibility analysis\
    \ on several leading lossy compressors.\nThe compressibility analysis relies on\
    \ deriving statistics on scientific data and explore their relationships to their\
    \ compression ratios from various lossy compressors (based on various compression\
    \ scheme).\nThe extracted relationships between compression ratios and statistical\
    \ predictors are modeled via regression models, which provide a statistical framework\
    \ to predict compression ratios for the different studied lossy compressors.</p>\n\
    <p>This repo contains an automatic framework of scripts that perform the compression\
    \ of scientific datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding\
    \ and Bit Grooming), the derivation of the statistical predictors of compression\
    \ ratios (SVD, standard deviation, quantized entropy), and scripts to perform\
    \ the training of the regression models (linear and spline regressions) as well\
    \ as the validation of the regression predictions.\nA runtime analysis is also\
    \ performed and associated codes are provided.</p>\n<h3><a id=\"user-content-main-code-structures\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#main-code-structures\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Main code\
    \ structures</h3>\n<p>Compression metrics, including compression ratios, and derivation\
    \ of statistical predictors (SVD, standard deviation, quantized entropy) codes\
    \ are found in <code>compress_package</code> and are run via <code>scripts/run.sh</code>\
    \ as described in the section \"How to compute statistical predictors and compression\
    \ analysis on datasets\".\nLinear and spline regressions training and validation\
    \ (functions <code>cr_regression_linreg</code> and <code>cr_regression_gam</code>\
    \ from the script <code>replicate_figures/functions_paper.R</code>).\nCodes for\
    \ the different runtime analysis are found in the folder <code>runtime_analysis</code>\
    \ and are automated with the script <code>runtime.sh</code>, the study includes\
    \ compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled)\
    \ variogram and local (tiled) variogram, and runtime for training and prediction\
    \ of the regressions.<br>\nFinally, the script <code>replicate_figures/graphs_paper_container.R</code>\
    \ replicates and saves all the figures from the paper ad as well as numbers from\
    \ the tables.</p>\n<p>For each dataset in the <code>dataset</code> folder, slicing\
    \ is performed for each variable field (e.g. density in Miranda), each slice is\
    \ stored in a class. The class is updated as compressions with the 8 compressors\
    \ is performed and updated as the statistical predictors are derived. Results\
    \ of each class are stored in a .csv file (example of csv files can be found at\
    \ <code>replicate_figures/generated_data/</code>).\nAll the datasets stored in\
    \ the <code>dataset</code> folder can be analyzed with the given set of codes,\
    \ one needs to source <code>scripts/config.json</code> with the appropriate dataset\
    \ name as described in the below section \"How to compute statistical predictors\
    \ and compression analysis on datasets\".\nThe regression analysis and its prediction\
    \ is then performed on R dataframes based on the aforementioned .csv files.</p>\n\
    <h2><a id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#system-information\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>System Information</h2>\n<p>The hardware\
    \ and software versions used for the performance evaluations can be found in the\
    \ table below. These nodes come from Clemson University's Palmetto Cluster.</p>\n\
    <p>These nodes have:</p>\n<table>\n<thead>\n<tr>\n<th>component</th>\n<th>version</th>\n\
    <th>component</th>\n<th>version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CPU</td>\n\
    <td>Intel Xeon 6148G (40 cores)</td>\n<td>sz2</td>\n<td>2.1.12.2</td>\n</tr>\n\
    <tr>\n<td>GPU</td>\n<td>2 Nvidia v100</td>\n<td>sz3</td>\n<td>3.1.3.1</td>\n</tr>\n\
    <tr>\n<td>Memory</td>\n<td>372GB</td>\n<td>zfp</td>\n<td>0.5.5</td>\n</tr>\n<tr>\n\
    <td>Network</td>\n<td>2 Mellanox MT27710 (HDR)</td>\n<td>mgard</td>\n<td>1.0.0</td>\n\
    </tr>\n<tr>\n<td>FileSystem</td>\n<td>BeeGFS 7.2.3 (24 targets)</td>\n<td>bit\
    \ grooming</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>Compiler</td>\n<td>GCC 8.4.1</td>\n\
    <td>digit rounding</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>OS</td>\n<td>CentOS\
    \ 8.2.2004</td>\n<td>R</td>\n<td>4.1.3</td>\n</tr>\n<tr>\n<td>MPI</td>\n<td>OpenMPI\
    \ 4.0.5</td>\n<td>Python</td>\n<td>3.9.12</td>\n</tr>\n<tr>\n<td>LibPressio</td>\n\
    <td>0.83.4</td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-first-time-setup\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#first-time-setup\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>First time setup</h2>\n<h3><a id=\"user-content-container-installation-for-ease-of-setup\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#container-installation-for-ease-of-setup\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Container\
    \ Installation (for ease of setup)</h3>\n<p>We provide a container for <code>x86_64</code>\
    \ image for ease of installation.</p>\n<p>This container differs from our experimental\
    \ setup slightly. The production build used <code>-march=native -mtune=native</code>\
    \ for architecture optimized builds where as the container does not use these\
    \ flags to maximize compatibility across <code>x86_64</code> hardware.</p>\n<p>NOTE\
    \ this file is &gt;= 11 GB , download with caution.</p>\n<h3><a id=\"user-content-manual-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#manual-installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manual Installation</h3>\n\
    <p>By default, it is recommended to follow the install locations that are indicated\
    \ on the top of <code>scripts/run.sh</code>\nand the top of <code>config.json</code>.\
    \ These two files provide the configuration options to get the program running.</p>\n\
    <p>Spack should be installed in the following location: <code>$HOME/spack/</code></p>\n\
    <p>This Github repo should be cloned in the following location: <code>$HOME/Correlation_Compressibility/</code>\n\
    This location is also referenced as the <code>COMPRESS_HOME</code> environment\
    \ variable.</p>\n<p>A dataset folder called 'datasets' should be in the following\
    \ location: <code>$HOME/Correlation_Compressibility/datasets/</code>.</p>\n<p>Clone\
    \ the repo but make sure to install or load <code>git-lfs</code> first.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> install/module load git-lfs, needed to download example_data\
    \ for building the container</span>\nsudo dnf install git-lfs <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>Fedora/CentOS Stream 8</span>\nsudo apt-get install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ubuntu</span>\nspack\
    \ install git-lfs<span class=\"pl-k\">;</span> spack load git-lfs <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> clone this repository</span>\ngit clone https://github.com/FTHPC/Correlation_Compressibility\
    \ <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility</pre></div>\n\
    <p>If you forgot to install <code>git-lfs</code> before and have an empty file\
    \ in the  <code>datasets</code> folder, you should install <code>git-lfs</code>\n\
    and then run the following:</p>\n<pre><code>git lfs fetch\ngit lfs checkout\n\
    </code></pre>\n<p>Once Spack is installed, there is a <code>spack.yaml</code>\
    \ configuration file containing the Spack environment necessary to run the program.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">$HOME</span>\ngit clone --depth=1 https://github.com/spack/spack\n\
    git clone --depth=1 https://github.com/robertu94/spack_packages \n<span class=\"\
    pl-c1\">source</span> ./spack/share/spack/setup-env.sh \nspack compiler find\n\
    spack external find \nspack repo add --scope=site ./spack_packages \n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ \nspack env activate <span class=\"pl-c1\">.</span>\nspack install\n<span class=\"\
    pl-k\">export</span> COMPRESS_HOME=<span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ </pre></div>\n<p>These commands will install the environment. The environment\
    \ only needs to be installed once.\nIf you are using an older &lt; gcc11, then\
    \ you will need to add the following to the <code>spack.yaml</code> file:</p>\n\
    <pre><code>^libstdcompat+boost\n</code></pre>\n<p>after <code>^mgard@robertu94+cuda</code>\
    \ but before the <code>,</code>.</p>\n<h3><a id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To run the\
    \ training and prediction timing analysis demonstration</h3>\n<p>In order to run\
    \ the timing analysis, a dataset must be specified.\nThere are two datasets setup\
    \ within this demonstration.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh runtime_analysis/runtime.sh -d [DATASET]</pre></div>\n<p>[DATASET] can\
    \ be either [NYX] or [SCALE]</p>\n<p>After running the above script, an *.RData\
    \ file(s) will be produced giving the approprirate timing information of\nthe\
    \ training and prediction for the regression models.</p>\n<p>Note: A quicker and\
    \ more efficient quantized entropy method is demonstrated in <code>qentropy.cc</code></p>\n\
    <h4><a id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-following-below-runs-qentropycc\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The following\
    \ below runs <code>qentropy.cc</code>\n</h4>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>g++ -std=c++2a -O3 qentropy.cc -o qentropy -march=native -mtune=native\n\
    ./qentropy</pre></div>\n<p>Note: Please run the runtime analysis for both datasets\
    \ before running the following section.</p>\n<h3><a id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication\
    \ of figures: how to run statistical prediction of compression ratios and the\
    \ prediction validation</h3>\n<p>The script <code>graphs_paper_container.R</code>\
    \  saves the graphs presented in the paper and provides associated validation\
    \ metrics (correlation and median absolute error percentage).</p>\n<p>The script\
    \ <code>graphs_paper_container.R</code> will source the scripts  <code>load_dataset_paper.R</code>\
    \ and <code>functions_paper.R</code> that respectively load the dataset of interest\
    \ and perform the regression analysis (training and prediction in cross-validation).\n\
    As a consequence the scripts  <code>load_dataset_paper.R</code> and <code>functions_paper.R</code>\
    \ do not need to be run by the user.</p>\n<p>The script <code>graphs_paper_container.R</code>\
    \  is run via the command:\n<code>bash sh replicate.sh</code></p>\n<p>From running\
    \ the script once, it will save all Figures 1, 3, 4 and 5 into .png files from\
    \ the paper as well as corresponding validation metrics.\nFigure 2 is not saved\
    \ as it provides a simple vizualization of slices of the datasets.\nSlices of\
    \ the datasets are generated in the Section \"How to compute statistical predictors\
    \ and compression metrics\" and can be stored, however we do not save them here\
    \ to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in\
    \ the R console.\nAll printed validation metrics are save into a file named <code>figure_replication.log</code>.\n\
    Figures and the log-file are saved in the same folder as the one where R script\
    \ is run and the filename structure is <code>figY_*.png</code> with Y is the figure\
    \ number reference in the paper and <code>*</code> provides additional informnation\
    \ about the data and the compressor.<br>\nNumbers for Table 4 are saved in the\
    \ last section in .txt files <code>statistic_benchmark_runtime_X.txt</code> with\
    \ X the studied dataset (NYX or SCALE).</p>\n<p>In order to limit the container\
    \ size to aid reproducibility, we only added a restricted number of scientific\
    \ datasets in the container and we rely on csv files from our production runs\
    \ (saved as described above in the Section \"How to compute statistical predictors\
    \ on datasets\").\nMore datasets are available on <a href=\"https://sdrbench.github.io\"\
    \ rel=\"nofollow\">SDRBench</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1675473427.0
FZJ-INM1-BDA/siibra-python:
  data_format: 2
  description: Software interfaces for interacting with brain atlases - Python client
  filenames:
  - .ebrains/spack/siibra-spack.yaml
  full_name: FZJ-INM1-BDA/siibra-python
  latest_release: null
  stargazers_count: 44
  subscribers_count: 8
  topics:
  - brain
  - atlas
  - neuroscience
  - bigbrain
  - bigbrainproject
  - humanbrainproject
  updated_at: 1699439990.0
FairRootGroup/FairMQ:
  data_format: 2
  description: C++ Message Queuing Library and Framework
  filenames:
  - spack.yaml
  full_name: FairRootGroup/FairMQ
  latest_release: v1.8.4
  readme: '

    <h1><a id="user-content-fairmq" class="anchor" aria-hidden="true" tabindex="-1"
    href="#fairmq"><span aria-hidden="true" class="octicon octicon-link"></span></a>FairMQ</h1>

    <p><a href="COPYRIGHT"><img src="https://camo.githubusercontent.com/c137674b017e381c618ebcabdecb42821c3cd3671e32cee8d1ed60ccc192a1dd/68747470733a2f2f616c66612d63692e6773692e64652f736869656c64732f62616467652f6c6963656e73652d4c47504c2d2d332e302d6f72616e67652e737667"
    alt="license" data-canonical-src="https://alfa-ci.gsi.de/shields/badge/license-LGPL--3.0-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.1689985" rel="nofollow"><img src="https://camo.githubusercontent.com/ae672eef12e67029da460aa41e43e31ddfca7b5256fe67b40b40650a68a24b2e/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e313638393938352e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.1689985.svg"
    style="max-width: 100%;"></a>

    <a href="https://bestpractices.coreinfrastructure.org/projects/6915" rel="nofollow"><img
    src="https://camo.githubusercontent.com/ebabb62e89af2e9bcd77f32d83b953d214f7205c40c56a27e7380ec178b9470d/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f363931352f6261646765"
    alt="OpenSSF Best Practices" data-canonical-src="https://bestpractices.coreinfrastructure.org/projects/6915/badge"
    style="max-width: 100%;"></a>

    <a href="https://github.com/FairRootGroup/FairMQ/actions/workflows/fair-software.yml"><img
    src="https://camo.githubusercontent.com/1993428095da072cadfe3cade519c683f681bc22e2ef72ffd4fe215e2ce083d0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666169722d2d736f6674776172652e65752d2545322539372538462532302532302545322539372538462532302532302545322539372538422532302532302545322539372538462532302532302545322539372538462d79656c6c6f77"
    alt="fair-software.eu" data-canonical-src="https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B%20%20%E2%97%8F%20%20%E2%97%8F-yellow"
    style="max-width: 100%;"></a>

    <a href="https://repology.org/project/fairmq/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/f8657b44c2c7ad0eaf3d60e9c29f3c79b98340e31ebc957e0a2371cbe7a7a2a6/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f76657273696f6e2d666f722d7265706f2f737061636b2f666169726d712e737667"
    alt="Spack package" data-canonical-src="https://repology.org/badge/version-for-repo/spack/fairmq.svg"
    style="max-width: 100%;"></a></p>

    <p>C++ Message Queuing Library and Framework</p>

    <p>Docs: <a href="https://github.com/FairRootGroup/FairMQ/blob/dev/README.md#documentation">Book</a></p>

    <p>Find all FairMQ releases <a href="https://github.com/FairRootGroup/FairMQ/releases">here</a>.</p>

    <h2><a id="user-content-introduction" class="anchor" aria-hidden="true" tabindex="-1"
    href="#introduction"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

    <p>FairMQ is designed to help implementing large-scale data processing workflows
    needed in next-generation Particle Physics experiments. FairMQ is written in C++
    and aims to</p>

    <ul>

    <li>provide <strong>an asynchronous message passing abstraction</strong> of different
    data transport technologies,</li>

    <li>provide a reasonably <strong>efficient data transport</strong> service (zero-copy,
    high throughput),</li>

    <li>be <strong>data format agnostic</strong>, and</li>

    <li>provide <strong>basic building blocks</strong> that can be used to implement
    higher level data processing workflows.</li>

    </ul>

    <p>The core of FairMQ provides an abstract asynchronous message passing API with
    scalability protocols

    inspired by <a href="https://github.com/zeromq/libzmq">ZeroMQ</a> (e.g. PUSH/PULL,
    PUB/SUB).

    FairMQ provides multiple implementations for its API (so-called "transports",

    e.g. <code>zeromq</code> and <code>shmem</code> (latest release of the <code>ofi</code>
    transport in v1.4.56, removed since v1.5+)) to cover

    a variety of use cases

    (e.g. inter-thread, inter-process, inter-node communication) and machines (e.g.
    Ethernet, Infiniband).

    In addition to this core functionality FairMQ provides a framework for creating
    "devices" - actors which

    are communicating through message passing. FairMQ does not only allow the user
    to use different transport

    but also to mix them; i.e: A Device can communicate using different transport
    on different channels at the

    same time. Device execution is modelled as a simple state machine that shapes
    the integration points for

    the user task. Devices also incorporate a plugin system for runtime configuration
    and control.

    Next to the provided <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/devices">devices</a>
    and

    <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/plugins">plugins</a>
    the user can extend FairMQ

    by developing his own plugins to integrate his devices with external configuration
    and control services.</p>

    <p>FairMQ has been developed in the context of its mother project <a href="https://github.com/FairRootGroup/FairRoot">FairRoot</a>
    -

    a simulation, reconstruction and analysis framework.</p>

    <h2><a id="user-content-installation-from-source" class="anchor" aria-hidden="true"
    tabindex="-1" href="#installation-from-source"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Installation from Source</h2>

    <p>Recommended:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/FairRootGroup/FairMQ
    fairmq_source

    cmake -S fairmq_source -B fairmq_build -GNinja -DCMAKE_BUILD_TYPE=Release

    cmake --build fairmq_build

    ctest --test-dir fairmq_build --output-on-failure --schedule-random -j<span class="pl-k">&lt;</span>ncpus<span
    class="pl-k">&gt;</span>

    cmake --install fairmq_build --prefix <span class="pl-s"><span class="pl-pds">$(</span>pwd<span
    class="pl-pds">)</span></span>/fairmq_install</pre></div>

    <p>Please consult the <a href="https://cmake.org/cmake/help/latest/manual/cmake.1.html"
    rel="nofollow">manpages of your CMake version</a> for more options.</p>

    <p>If dependencies are not installed in standard system directories, you can hint
    the installation location via

    <code>-DCMAKE_PREFIX_PATH=...</code> or per dependency via <code>-D{DEPENDENCY}_ROOT=...</code>
    (<code>*_ROOT</code> variables can also be environment variables).</p>

    <h2><a id="user-content-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h2>

    <p>FairMQ ships as a CMake package, so in your <code>CMakeLists.txt</code> you
    can discover it like this:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">find_package</span>(FairCMakeModules
    1.0 <span class="pl-k">REQUIRED</span>)

    <span class="pl-c1">include</span>(FairFindPackage2)

    find_package2(FairMQ)

    find_package2_implicit_dependencies()</pre></div>

    <p>The <a href="https://fairrootgroup.github.io/FairCMakeModules/latest/module/FairFindPackage2.html"
    rel="nofollow"><code>FairFindPackage2</code> module</a> is part of the <a href="https://fairrootgroup.github.io/FairCMakeModules"
    rel="nofollow"><code>FairCMakeModules</code> package</a>.</p>

    <p>If FairMQ is not installed in system directories, you can hint the installation:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">list</span>(PREPEND
    CMAKE_PREFIX_PATH /path/to/fairmq_install)</pre></div>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <ul>

    <li><a href="https://www.boost.org/" rel="nofollow">Boost</a></li>

    <li><a href="https://cmake.org/" rel="nofollow">CMake</a></li>

    <li><a href="http://www.doxygen.org/" rel="nofollow">Doxygen</a></li>

    <li>

    <a href="https://github.com/FairRootGroup/FairCMakeModules">FairCMakeModules</a>
    (optionally bundled)</li>

    <li><a href="https://github.com/FairRootGroup/FairLogger">FairLogger</a></li>

    <li>

    <a href="https://github.com/google/googletest">GTest</a> (optionally bundled)</li>

    <li><a href="http://zeromq.org/" rel="nofollow">ZeroMQ</a></li>

    </ul>

    <p>Which dependencies are required depends on which components are built.</p>

    <p>Supported platform is Linux. macOS is supported on a best-effort basis.</p>

    <h2><a id="user-content-cmake-options" class="anchor" aria-hidden="true" tabindex="-1"
    href="#cmake-options"><span aria-hidden="true" class="octicon octicon-link"></span></a>CMake
    options</h2>

    <p>On command line:</p>

    <ul>

    <li>

    <code>-DDISABLE_COLOR=ON</code> disables coloured console output.</li>

    <li>

    <code>-DBUILD_TESTING=OFF</code> disables building of tests.</li>

    <li>

    <code>-DBUILD_EXAMPLES=OFF</code> disables building of examples.</li>

    <li>

    <code>-DBUILD_DOCS=ON</code> enables building of API docs.</li>

    <li>

    <code>-DFAIRMQ_CHANNEL_DEFAULT_AUTOBIND=OFF</code> disable channel <code>autoBind</code>
    by default</li>

    <li>You can hint non-system installations for dependent packages, see the #installation-from-source
    section above</li>

    </ul>

    <p>After the <code>find_package(FairMQ)</code> call the following CMake variables
    are defined:</p>

    <table>

    <thead>

    <tr>

    <th>Variable</th>

    <th>Info</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>${FairMQ_PACKAGE_DEPENDENCIES}</code></td>

    <td>the list of public package dependencies</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_VERSION}</code></td>

    <td>the minimum <code>&lt;dep&gt;</code> version FairMQ requires</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_COMPONENTS}</code></td>

    <td>the list of <code>&lt;dep&gt;</code> components FairMQ depends on</td>

    </tr>

    <tr>

    <td><code>${FairMQ_PACKAGE_COMPONENTS}</code></td>

    <td>the list of components FairMQ consists of</td>

    </tr>

    <tr>

    <td><code>${FairMQ_#COMPONENT#_FOUND}</code></td>

    <td>

    <code>TRUE</code> if this component was built</td>

    </tr>

    <tr>

    <td><code>${FairMQ_VERSION}</code></td>

    <td>the version in format <code>MAJOR.MINOR.PATCH</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_GIT_VERSION}</code></td>

    <td>the version in the format returned by <code>git describe --tags --dirty --match
    "v*"</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_PREFIX}</code></td>

    <td>the actual installation prefix</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BINDIR}</code></td>

    <td>the installation bin directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_INCDIR}</code></td>

    <td>the installation include directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_LIBDIR}</code></td>

    <td>the installation lib directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_DATADIR}</code></td>

    <td>the installation data directory (<code>../share/fairmq</code>)</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CMAKEMODDIR}</code></td>

    <td>the installation directory of shipped CMake find modules</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BUILD_TYPE}</code></td>

    <td>the value of <code>CMAKE_BUILD_TYPE</code> at build-time</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CXX_FLAGS}</code></td>

    <td>the values of <code>CMAKE_CXX_FLAGS</code> and <code>CMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE}</code>
    at build-time</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <ol>

    <li>

    <a href="docs/Device.md#1-device">Device</a>

    <ol>

    <li><a href="docs/Device.md#11-topology">Topology</a></li>

    <li><a href="docs/Device.md#12-communication-patterns">Communication Patterns</a></li>

    <li><a href="docs/Device.md#13-state-machine">State Machine</a></li>

    <li><a href="docs/Device.md#15-multiple-devices-in-the-same-process">Multiple
    devices in the same process</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Transport.md#2-transport-interface">Transport Interface</a>

    <ol>

    <li>

    <a href="docs/Transport.md#21-message">Message</a>

    <ol>

    <li><a href="docs/Transport.md#211-ownership">Ownership</a></li>

    </ol>

    </li>

    <li><a href="docs/Transport.md#22-channel">Channel</a></li>

    <li><a href="docs/Transport.md#23-poller">Poller</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Configuration.md#3-configuration">Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#31-device-configuration">Device Configuration</a></li>

    <li>

    <a href="docs/Configuration.md#32-communication-channels-configuration">Communication
    Channels Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#321-json-parser">JSON Parser</a></li>

    <li><a href="docs/Configuration.md#322-suboptparser">SuboptParser</a></li>

    </ol>

    </li>

    <li><a href="docs/Configuration.md#33-introspection">Introspection</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Development.md#4-development">Development</a>

    <ol>

    <li><a href="docs/Development.md#41-testing">Testing</a></li>

    <li>

    <a href="docs/Development.md#42-static-analysis">Static Analysis</a>

    <ol>

    <li><a href="docs/Development.md#421-cmake-integration">CMake Integration</a></li>

    <li><a href="docs/Development.md#422-extra-compiler-arguments">Extra Compiler
    Arguments</a></li>

    </ol>

    </li>

    </ol>

    </li>

    <li>

    <a href="docs/Logging.md#5-logging">Logging</a>

    <ol>

    <li><a href="docs/Logging.md#51-log-severity">Log severity</a></li>

    <li><a href="docs/Logging.md#52-log-verbosity">Log verbosity</a></li>

    <li><a href="docs/Logging.md#53-color">Color for console output</a></li>

    <li><a href="docs/Logging.md#54-file-output">File output</a></li>

    <li><a href="docs/Logging.md#55-custom-sinks">Custom sinks</a></li>

    </ol>

    </li>

    <li><a href="docs/Examples.md#6-examples">Examples</a></li>

    <li>

    <a href="docs/Plugins.md#7-plugins">Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#71-usage">Usage</a></li>

    <li><a href="docs/Plugins.md#72-development">Development</a></li>

    <li>

    <a href="docs/Plugins.md#73-provided-plugins">Provided Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#731-pmix">PMIx</a></li>

    </ol>

    </li>

    </ol>

    </li>

    </ol>

    '
  stargazers_count: 77
  subscribers_count: 10
  topics:
  - fairroot
  - fairmq
  - zeromq
  - shmem
  - c-plus-plus
  updated_at: 1700279035.0
FairRootGroup/FairSoft:
  data_format: 2
  description: Repository for installation routines of the external software required
    by FairRoot
  filenames:
  - test/env/jun19_fairroot_18_4/spack.yaml
  full_name: FairRootGroup/FairSoft
  latest_release: nov22p1
  readme: "<h1><a id=\"user-content-fairsoft\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#fairsoft\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>FairSoft</h1>\n<p>The FairSoft distribution provides\
    \ the software packages needed to compile and run the <a href=\"https://github.com/FairRootGroup/FairRoot\"\
    >FairRoot framework</a> and experiment packages based on FairRoot. FairSoft is\
    \ a source distribution with recurring releases for macOS and Linux.</p>\n<h2><a\
    \ id=\"user-content-installation-from-source\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#installation-from-source\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation from Source</h2>\n\
    <p>Choose between the classic (called \"Legacy\") installation method or the new\
    \ Spack-based one:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Legacy (Recommended)</strong></th>\n\
    <th><strong>Spack (EXPERIMENTAL)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>This is the classic bash/cmake based setup system.</td>\n<td>This is an ongoing\
    \ standardization and modernization effort based on Spack (which itself is still\
    \ under heavy development). Most things are already working. For early adopters.</td>\n\
    </tr>\n<tr>\n<td>Releases are reflected in the git history via tags and branches,\
    \ e.g.: <code>nov22</code>, <code>apr21p2</code>, <code>apr21_patches</code>\n\
    </td>\n<td>Always use the latest <code>dev</code> branch. Multiple releases are\
    \ described within the metadata contained in the repo (read on in the Installation\
    \ instructions on how to select a release).</td>\n</tr>\n<tr>\n<td>\u25BA <a href=\"\
    legacy/README.md\">continue</a>\n</td>\n<td>\u25BA <a href=\"docs/README.md\"\
    >continue</a>\n</td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-installation-of-pre-compiled-binaries\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation-of-pre-compiled-binaries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ of pre-compiled Binaries</h2>\n<p><em>Note</em>: FairSoft is primarily a source\
    \ distribution. Availability of latest releases as pre-compiled binaries may be\
    \ delayed.</p>\n<h3><a id=\"user-content-gsi-virgo-cluster\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#gsi-virgo-cluster\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>GSI Virgo Cluster</h3>\n<p>For\
    \ all <a href=\"https://hpc.gsi.de/virgo/platform/software.html#application-environment\"\
    \ rel=\"nofollow\">VAEs</a> at <code>/cvmfs/fairsoft.gsi.de/&lt;vae-os&gt;/fairsoft/&lt;release&gt;</code>.\
    \ Use by exporting the <code>SIMPATH</code> environment variable pointing to one\
    \ of the directories.</p>\n<h3><a id=\"user-content-macos-beta\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#macos-beta\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>macOS (beta)</h3>\n<p>Tested:\
    \ <code>macOS 11 (x86_64)</code>, <code>macOS 12 (x86_64)</code>, <code>macOS\
    \ 12 (arm64)</code> with <em>Command Line Tools for Xcode</em> <code>13</code></p>\n\
    <p>FairSoft config: <a href=\"FairSoftConfig.cmake\">default</a>, no other configs\
    \ planned</p>\n<ol>\n<li>Install <em>Command Line Tools for Xcode</em> from <a\
    \ href=\"https://developer.apple.com/downloads\" rel=\"nofollow\">https://developer.apple.com/downloads</a>\
    \ (requires Apple account)</li>\n<li>Install <a href=\"https://brew.sh/\" rel=\"\
    nofollow\">Homebrew</a>\n</li>\n<li>Run <code>brew update &amp;&amp; brew doctor</code>\
    \ and fix potential issues reported by these commands until <code>Your system\
    \ is ready to brew.</code>\n</li>\n<li>Run</li>\n</ol>\n<pre><code>brew tap fairrootgroup/fairsoft\n\
    brew install fairsoft@22.11\n</code></pre>\n<ol start=\"5\">\n<li>Use via <code>export\
    \ SIMPATH=$(brew --prefix fairsoft@22.11)</code>\n</li>\n</ol>\n<p><em>Note</em>:\
    \ macOS is a fast moving target and it is possible the packages will stop working\
    \ from one day to another after some system component was updated. We try our\
    \ best to keep up, one great way to help is to provide detailed problem reports\
    \ <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\">here on github</a>.</p>\n\
    <h3><a id=\"user-content-other-platforms\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#other-platforms\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Other platforms</h3>\n<p>Binary packages for\
    \ non-GSI Linux as well as Spack binary caches and/or pre-populated install trees\
    \ are planned for the future.</p>\n<h2><a id=\"user-content-contributing\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Please\
    \ ask your questions, request features, and report issues by <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\
    >creating a github issue</a>.</p>\n"
  stargazers_count: 14
  subscribers_count: 13
  topics: []
  updated_at: 1683613174.0
FemusPlatform/NumericPlatform:
  data_format: 2
  description: Official repository of open-source code based Numerical Platform
  filenames:
  - spack_env/spack.yaml
  full_name: FemusPlatform/NumericPlatform
  latest_release: null
  readme: '<h1><a id="user-content-numericplatform" class="anchor" aria-hidden="true"
    tabindex="-1" href="#numericplatform"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NumericPlatform</h1>

    <p>Official repository of open-source code based Numerical Platform</p>

    <p>The Numerical Platform has been developed as an environment where several numerical

    codes can be run together, allowing to model complex physical phenomena on different

    physical scales.</p>

    <p>The platform is organized into a hierarchical set of levels, namely</p>

    <ul>

    <li>

    <p>Level 0: main level of the Numerical Platform where the different components
    are gathered</p>

    </li>

    <li>

    <p>Level 1: differentiation of Numerical Platform main components into:</p>

    <ul>

    <li>

    <p>PLAT_BUILD: level where installing scripts are gathered and components are
    built</p>

    </li>

    <li>

    <p>PLAT_THIRD_PARTY: components needed to run the numerical codes</p>

    </li>

    <li>

    <p>PLAT_CODES: the numerical codes</p>

    </li>

    <li>

    <p>PLAT_VISU: software for post processing and data visualization</p>

    </li>

    <li>

    <p>PLAT_USERS: level where applications are run</p>

    </li>

    </ul>

    </li>

    <li>

    <p>Level 2: differentiation of the main components. Up to now the following packages
    can be installed</p>

    <ul>

    <li>

    <p>PLAT_THIRD_PARTY:

    <a href="http://www.salome-platform.org/" rel="nofollow">Salome platform</a>,

    <a href="https://www.open-mpi.org/" rel="nofollow">OpenMPI library</a>,

    <a href="https://www.mcs.anl.gov/petsc/" rel="nofollow">Petsc library</a>,

    <a href="http://libmesh.github.io/" rel="nofollow">Libmesh code</a>,

    <a href="http://www.salome-platform.org/user-section/about/med" rel="nofollow">med
    data format library</a>,

    <a href="http://docs.salome-platform.org/latest/dev/MEDCoupling/index.html" rel="nofollow">MedCoupling
    library</a></p>

    </li>

    <li>

    <p>PLAT_CODES:

    FEMuS code,

    <a href="https://openfoamwiki.net/index.php/Main_Page" rel="nofollow">OpenFOAM
    extend</a>,

    <a href="http://www.oecd-nea.org/tools/abstract/detail/uscd1234/" rel="nofollow">Dragon
    code</a>,

    Donjon code</p>

    </li>

    <li>

    <p>PLAT_VISU:

    Paraview, as Salome package</p>

    </li>

    </ul>

    </li>

    </ul>

    <p>This repository represents Level 0 and it can be used to perform a complete
    Numerical Platform installation from scratch.

    For a complete platform installation gcc7 and cmake (vesion &gt; 3.10) are required.</p>

    '
  stargazers_count: 5
  subscribers_count: 3
  topics: []
  updated_at: 1693291617.0
GoogleCloudPlatform/ramble:
  data_format: 2
  description: A multi-platform experimentation framework written in python.
  filenames:
  - etc/ramble/defaults/spack.yaml
  full_name: GoogleCloudPlatform/ramble
  latest_release: v0.2.1
  readme: "<p>Ramble is a multi-platform experimentation framework to increase exploration\n\
    productivity and improve reproducibility. Ramble is capable of driving software\n\
    installation, acquire input files, configure experiments, and extract results.\n\
    It works on Linux, macOS, and many supercomputers.</p>\n<p>Ramble can be used\
    \ to configure a variety of experiments for applications.\nThese can include anything\
    \ from:</p>\n<ul>\n<li>Scientific parameter sweeps</li>\n<li>Performance focused\
    \ scalaing studies</li>\n<li>Compiler flag sweeps</li>\n</ul>\n<p>To install ramble\
    \ and configure your experiment workspace, make sure you have\nPython, and Ramble\u2019\
    s dependencies are installed as per the dependency section\nbelow.\nThen:</p>\n\
    <pre><code>$ git clone -c feature.manyFiles=true https://github.com/GoogleCloudPlatform/ramble.git\n\
    $ cd ramble/bin\n$ ./ramble workspace create -d test_workspace -c ../examples/basic_hostname_config.yaml\n\
    </code></pre>\n<h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Dependencies</h2>\n<p>Ramble\u2019s python dependencies\
    \ can be installed using the included requirements.txt file.</p>\n<p>e.g.</p>\n\
    <pre><code>$ pip install -r requirements.txt\n</code></pre>\n<p>Outside of these\
    \ requirements, ramble requires an existing installation of\nspack for some application\
    \ definition. See\n<a href=\"https://github.com/spack/spack#-spack\">Spack\u2019\
    s documentation</a> to install Spack.</p>\n<h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p>Ramble\u2019s documentation can be viewed at\n<a href=\"https://googlecloudplatform.github.io/ramble/\"\
    \ rel=\"nofollow\">https://googlecloudplatform.github.io/ramble/</a>.</p>\n<p>For\
    \ help with Ramble\u2019s commands, run <code>ramble help</code> or <code>ramble\
    \ help --all</code>.</p>\n<p>For more information on concepts in Ramble, see Ramble\u2019\
    s\n<a href=\"./lib/ramble/docs/getting_started.rst\">Getting Started</a> guide.</p>\n\
    <p>Example configuration files are also contained in the\n<a href=\"./examples\"\
    >examples</a> directory.</p>\n<h2><a id=\"user-content-community\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#community\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Community</h2>\n<p>Ramble is\
    \ an open source project.  Questions, discussion, and\ncontributions are welcome.\
    \ Contributions can be anything from new\npackages to bugfixes, documentation,\
    \ or even new core features.</p>\n<p>Resources:</p>\n<ul>\n<li>\n<a href=\"https://github.com/GoogleCloudPlatform/ramble/discussions\"\
    ><strong>Github Discussions</strong></a>: not just for discussions, also Q&amp;A.</li>\n\
    </ul>\n<h2><a id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Contributing</h2>\n<p>Contributing to Ramble\
    \ is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/GoogleCloudPlatform/ramble\"\
    >Ramble repository</a>.</p>\n<p>Your PR must pass Ramble's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.</p>\n\
    <p>These tests can be run locally through test runners in the share/ramble/qa/\n\
    directory. Alternatively, <a href=\"https://pre-commit.com/#install\" rel=\"nofollow\"\
    >pre-commit</a> can be\nused to manage our git hooks. To install the hooks, simply\
    \ run:</p>\n<ul>\n<li>pre-commit install</li>\n</ul>\n<p>For additional requirements\
    \ about contributing, including Google\u2019s CLA, see our\n<a href=\".github/CONTRIBUTING.md\"\
    >Contribution Guide</a>.</p>\n<p>Ramble's <code>develop</code> branch has the\
    \ latest contributions. Pull requests\nshould target <code>develop</code>, and\
    \ users who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2><a id=\"user-content-releases\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Releases</h2>\n<p>Each Ramble release series also has a corresponding\
    \ branch, e.g.\n<code>releases/v0.1</code> has <code>0.1.x</code> versions of\
    \ Ramble, and <code>releases/v0.2</code> has\n<code>0.2.x</code> versions. We\
    \ backport important bug fixes to these branches but\nwe do not advance the application\
    \ definitions or make other changes that would\nchange the way experiments Ramble\
    \ would create within a release branch.\nSo, you can base your Ramble deployment\
    \ on a release branch subsequent updates\ncan be considered non-breaking.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<h2><a id=\"user-content-code-of-conduct\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#code-of-conduct\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Code of Conduct</h2>\n<p>Please note that Ramble\
    \ has a\n<a href=\".github/CODE_OF_CONDUCT.md\"><strong>Code of Conduct</strong></a>.\
    \ By participating in\nthe Ramble community, you agree to abide by its rules.</p>\n\
    <h2><a id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#authors\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Authors</h2>\n<p>Many thanks go to Ramble's <a href=\"https://github.com/GoogleCloudPlatform/ramble/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Ramble was created by Doug Jacobsen, <a href=\"mailto:dwjacobsen@google.com\"\
    >dwjacobsen@google.com</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>This software\
    \ is distributed under the terms of both the MIT license and the\nApache License\
    \ (Version 2.0).</p>\n<p>See LICENSE for details.</p>\n<p>SPDX-License-Identifier:\
    \ (Apache-2.0 OR MIT)</p>\n"
  stargazers_count: 26
  subscribers_count: 7
  topics: []
  updated_at: 1701269271.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1658856345.0
HenryWinterbottom-NOAA/ufs_containers:
  data_format: 2
  description: This repository contains Docker and spack recipes for building Docker
    containers supporting UFS related applications.
  filenames:
  - configs/ufs_utils.spack.yaml
  full_name: HenryWinterbottom-NOAA/ufs_containers
  latest_release: null
  readme: "<p><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_pyutils/blob/develop/LICENSE\"\
    ><img src=\"https://camo.githubusercontent.com/f1c8066ffa900d7f28fbf9dac53ecae9536d5f2d712acf5d28169053f7126d7a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76322e312d626c61636b\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/License-LGPL_v2.1-black\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/11283100b6bb6ad86286bbc513074be499d32590d1ac0683bb1fd225ba941e3c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e75782d7562756e747525374363656e746f732d6c6967687467726579\"\
    ><img src=\"https://camo.githubusercontent.com/11283100b6bb6ad86286bbc513074be499d32590d1ac0683bb1fd225ba941e3c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e75782d7562756e747525374363656e746f732d6c6967687467726579\"\
    \ alt=\"Linux\" data-canonical-src=\"https://img.shields.io/badge/Linux-ubuntu%7Ccentos-lightgrey\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/3178d3cf7f933dd9f799626e2a38c7b48b9e7ea19a8da1503c06b684d7aaf5d3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e35253743332e36253743332e372d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/3178d3cf7f933dd9f799626e2a38c7b48b9e7ea19a8da1503c06b684d7aaf5d3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e35253743332e36253743332e372d626c7565\"\
    \ alt=\"Python Version\" data-canonical-src=\"https://img.shields.io/badge/Python-3.5%7C3.6%7C3.7-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/84aeb27d17875b4119b3e6e584034bdfe7c2458434c8fbc41bda46f975d27451/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f64652532305374796c652d626c61636b2d707572706c652e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/Code%20Style-black-purple.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_containers/actions/workflows/pycodestyle.yaml\"\
    ><img src=\"https://github.com/HenryWinterbottom-NOAA/ufs_containers/actions/workflows/pycodestyle.yaml/badge.svg\"\
    \ alt=\"Python Coding Standards\" style=\"max-width: 100%;\"></a></p>\n<h1><a\
    \ id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#overview\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Overview</h1>\n<p>This repository contains Docker and spack recipes\
    \ for building Docker\ncontainers supporting Unified Forecast System (UFS) related\n\
    applications.</p>\n<ul>\n<li>\n<strong>Authors:</strong> <a href=\"mailto:henry.winterbottom@noaa.gov\"\
    >Henry R. Winterbottom</a>\n</li>\n<li>\n<strong>Maintainers:</strong> Henry R.\
    \ Winterbottom</li>\n<li>\n<strong>Version:</strong> 0.0.1</li>\n<li>\n<strong>License:</strong>\
    \ LGPL v2.1</li>\n<li>\n<strong>Copyright</strong>: Henry R. Winterbottom</li>\n\
    </ul>\n<h1><a id=\"user-content-cloning\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#cloning\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Cloning</h1>\n<p>This repository utilizes several\
    \ sub-modules from various sources. To\nobtain the entire system, do as follows.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>user@host:$ git clone --recursive\
    \ https://github.com/HenryWinterbottom-NOAA/ufs_containers /path/to/ufs_containers</pre></div>\n\
    <h1><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Dependencies</h1>\n<p>The package dependencies and\
    \ the respective repository and manual\ninstallation attributes are provided in\
    \ the table below.</p>\n<div align=\"left\">\n<table>\n<thead>\n<tr>\n<th align=\"\
    center\">Dependency Package</th>\n<th align=\"center\"><div align=\"left\">Installation\
    \ Instructions</div></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"\
    ><div align=\"left\"><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_pyutils\"\
    ><code>ufs_pyutils</code></a></div></td>\n<td align=\"center\"><div align=\"left\"\
    ><code>git+https://www.github.com/HenryWinterbottom-NOAA/ufs_pyutils.git</code></div></td>\n\
    </tr>\n</tbody>\n</table>\n<h1><a id=\"user-content-installing-package-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-package-dependencies\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ Package Dependencies</h1>\n<p>In order to install the respective Python packages\
    \ upon which\n<code>ufs_diags</code> is dependent, do as follows.</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>user@host:$ <span class=\"pl-c1\">cd</span>\
    \ /path/to/ufs_containers\nuser@host:$ /path/to/pip install update\nuser@host:$\
    \ /path/to/pip install -r /path/to/ufs_containers/requirements.txt</pre></div>\n\
    <p>For additional information using <code>pip</code> and <code>requirements.txt</code>\
    \ type files, see <a href=\"https://pip.pypa.io/en/stable/reference/requirements-file-format/\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h1><a id=\"user-content-building-spack-configuration-files\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-spack-configuration-files\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ Spack Configuration Files</h1>\n<p>To build the configuration files that <code>spack</code>\
    \ requires, an application\nhas been provided and can be executed as described\
    \ below.</p>\n<div class=\"highlight highlight-source-shell\"><pre>user@host:$\
    \ <span class=\"pl-c1\">cd</span> /path/to/ufs_containers/scripts\nuser@host:$\
    \ ./build_specs.py -h\n\nUsage: build_specs.py [-h] [--spack_yaml SPACK_YAML]\
    \ yaml\n\nSpack stack package specification(s) application interface.\n\nPositional\
    \ Arguments:\n  yaml                  YAML-formatted file containing the Spack\
    \ containerized stack package specification.\n\nOptional Arguments:\n  -h, --help\
    \            show this <span class=\"pl-c1\">help</span> message and <span class=\"\
    pl-c1\">exit</span>\n  --spack_yaml, -out SPACK_YAML\n                       \
    \ A YAML-formatted file containing the spack specification attributes.\n\nuser@host:$\
    \ ./build_specs.py /path/to/ufs_containers/parm/spack_demo.yaml --spack_yaml /path/to/ufs_containers/scripts/spack.yaml</pre></div>\n\
    <p>The resulting YAML-formatted file containing the <code>spack</code> instructions\n\
    described within the <code>/path/to/ufs_containers/parm/spack_demo.yaml</code>\
    \ in\nthe previous step will appear as follows.</p>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre><span class=\"pl-ent\">spack</span>:\n  <span class=\"pl-ent\">container</span>:\n\
    \    <span class=\"pl-ent\">format</span>: <span class=\"pl-s\">docker</span>\n\
    \  <span class=\"pl-ent\">specs</span>:\n  - <span class=\"pl-s\">package_1</span>\n\
    \  - <span class=\"pl-s\">package_2</span>\n  - <span class=\"pl-s\">package_3</span></pre></div>\n\
    <p>Additional, supported applications, can be found beneath\n<code>/path/to/ufs_containers/parm</code>.</p>\n\
    <h1><a id=\"user-content-building-using-docker-services\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#building-using-docker-services\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building Using Docker Services</h1>\n\
    <p>To <code>build</code>, <code>push</code>, and <code>cleanup</code> all Docker\
    \ services images, do as follows.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>user@host:$ <span class=\"pl-c1\">cd</span> /path/to/ufs_containers/scripts\n\
    user@host:$ ./docker_services.py --help\n\nUsage: docker_services.py [-h] [-build]\
    \ [-cleanup] [-push] compose env\n\nDocker services interface.\n\nPositional Arguments:\n\
    \  compose     Docker compose YAML-formatted services file.\n  env         Docker\
    \ compose YAML-formatted environment configuration file.\n\nOptional Arguments:\n\
    \  -h, --help  show this <span class=\"pl-c1\">help</span> message and <span class=\"\
    pl-c1\">exit</span>\n  -build      Build the specified Docker service images.\n\
    \  -cleanup    Cleanup <span class=\"pl-k\">local</span> services images.\n  -push\
    \       Push existing images to their respective repositories.\n\nuser@host:$\
    \ ./docker_services.py /path/to/ufs_containers/Docker/docker_services.yaml /path/to/ufs_containers/Docker/docker_services_env.yaml\
    \ --build --push --cleanup</pre></div>\n<h1><a id=\"user-content-forking\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#forking\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Forking</h1>\n<p>If a user wishes\
    \ to contribute modifications done within their\nrespective fork(s) to the authoritative\
    \ repository, we request that\nthe user first submit an issue and that the fork\
    \ naming conventions\nfollow those listed below.</p>\n<ul>\n<li>\n<p><code>docs/user_fork_name</code>:\
    \ Documentation additions and/or corrections for the application(s).</p>\n</li>\n\
    <li>\n<p><code>feature/user_fork_name</code>: Additions, enhancements, and/or\
    \ upgrades for the application(s).</p>\n</li>\n<li>\n<p><code>fix/user_fork_name</code>:\
    \ Bug-type fixes for the application(s) that do not require immediate attention.</p>\n\
    </li>\n<li>\n<p><code>hotfix/user_fork_name</code>: Bug-type fixes which require\
    \ immediate attention to fix issues that compromise the integrity of the respective\
    \ application(s).</p>\n</li>\n</ul>\n</div>"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - docker
  - spack
  - docker-services
  updated_at: 1696729175.0
JCSDA/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/unified-dev/spack.yaml
  - configs/templates/ufs-weather-model-static/spack.yaml
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/skylab-dev/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/ufs-weather-model/spack.yaml
  full_name: JCSDA/spack-stack
  latest_release: 1.5.1
  readme: '<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"><img
    src="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"
    width="425" style="max-width: 100%;"></a></p>

    <p>Spack-stack is a framework for installing software libraries to support

    NOAA''s Unified Forecast System (UFS) applications and the

    Joint Effort for Data assimilation Integration (JEDI) coupled to

    several Earth system prediction models (MPAS, NEPTUNE, UM, FV3, GEOS, UFS).</p>

    <p>Spack-stack supports installations on a range of R&amp;D and operational platforms.

    It provides a set of installation templates (package lists), default package settings,

    system configurations for a range of <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">macOS and Linux workstation, HPC, and cloud

    platforms</a>, and Spack extensions, and uses a fork of the

    <a href="https://github.com/spack/spack">Spack repository</a>. <a href="https://spack.io/"
    rel="nofollow">Spack</a> is a

    community-supported, multi-platform package manager

    developed by Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about Spack, see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for Spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">Spack
    documentation</a>.</p>

    <p><strong>To get started with spack-stack</strong>, either by using an existing

    installation on a <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">supported platform</a>

    or by <a href="https://spack-stack.readthedocs.io/en/latest/CreatingEnvironments.html"
    rel="nofollow">creating a new installation</a>, see the

    <a href="https://spack-stack.readthedocs.io/en/latest/Overview.html#getting-started"
    rel="nofollow">Getting Started</a> documentation page.

    Full documentation with table of contents can be found at <a href="https://spack-stack.readthedocs.io/en/latest/"
    rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a>.</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li>

    <a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a>: <a href="https://www.github.com/AlexanderRichert-NOAA">Alex
    Richert</a>, <a href="https://www.github.com/Hang-Lei-NOAA">Hang Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed
    Hartnett</a>

    </li>

    <li>

    <a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a>: <a href="https://www.github.com/climbfuji">Dom
    Heinzeller</a>, <a href="https://github.com/srherbener">Steve Herbener</a>

    </li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>: <a href="https://github.com/ulmononian">Cam Book</a>, <a href="https://github.com/natalie-perlin">Natalie
    Perlin</a>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    '
  stargazers_count: 17
  subscribers_count: 9
  topics: []
  updated_at: 1695997145.0
JuliaPelzer/Phd_simulation_groundtruth:
  data_format: 2
  description: pflotran .in-files for testcases
  filenames:
  - installs/spack.yaml
  full_name: JuliaPelzer/Phd_simulation_groundtruth
  latest_release: null
  readme: '<h1><a id="user-content-prerequisite-installs" class="anchor" aria-hidden="true"
    tabindex="-1" href="#prerequisite-installs"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Prerequisite (installs)</h1>

    <ul>

    <li>pflotran (explanation below)</li>

    <li>python 3.8.10 or newer (tested with this version)</li>

    <li>python packages (installation via pip possible): numpy, noise</li>

    <li>bash 5.0.17 or newer (tested with this version)</li>

    </ul>

    <h2><a id="user-content-how-to-install-pflotran-using-spack" class="anchor" aria-hidden="true"
    tabindex="-1" href="#how-to-install-pflotran-using-spack"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>How to install Pflotran using spack:</h2>

    <p><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code></p>

    <p><code>. spack/share/spack/setup-env.sh</code></p>

    <p>copy <code>spack.yaml</code> (pflotran specific) to folder and go there (e.g.
    "cd test_nn/installs/")</p>

    <p><code>spack env activate .</code></p>

    <p><code>spack install</code> / <code>spack install pflotran</code></p>

    <blockquote>

    <p><strong>Note</strong>

    need internet access for it</p>

    </blockquote>

    <h3><a id="user-content-next-login" class="anchor" aria-hidden="true" tabindex="-1"
    href="#next-login"><span aria-hidden="true" class="octicon octicon-link"></span></a>next
    login:</h3>

    <p><code>cd ../</code>

    <code>. spack/share/spack/setup-env.sh</code></p>

    <p>go to folder with <code>spack.yaml</code> (e.g. test_nn/installs)</p>

    <p><code>spack env activate .</code></p>

    <p><code>spack install pflotran</code></p>

    <h1><a id="user-content-phd_simulation_groundtruth" class="anchor" aria-hidden="true"
    tabindex="-1" href="#phd_simulation_groundtruth"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Phd_simulation_groundtruth</h1>

    <p>builds datasets with definable number of data points; based on one pflotran.in
    file, varying pressure gradients in external <code>.txt</code> file (and varying
    permeability fields based on <code>perlin_noise</code> in external <code>.h5</code>
    files)</p>

    <h2><a id="user-content-if-you-use-this-script-on-a-new-computer" class="anchor"
    aria-hidden="true" tabindex="-1" href="#if-you-use-this-script-on-a-new-computer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>If you use this script
    on a new computer</h2>

    <ul>

    <li>remember to copy all (!) required files (see <code>/dummy_dataset</code> +
    <code>*.sh</code> bash-script + <code>/scripts</code> and <code>test_*.py</code>)</li>

    <li>if you run the script for a varying permeability field, check that you have
    all required files in dummy_dataset:

    <ul>

    <li><code>pflotran_vary_perm.in</code></li>

    <li><code>settings.yaml</code></li>

    </ul>

    </li>

    <li>set the <code>$PFLOTRAN_DIR</code> (in <code>~/.zshrc</code> or <code>~/.bashrc</code>
    or similar)</li>

    </ul>

    <h2><a id="user-content-how-to-run-the-script" class="anchor" aria-hidden="true"
    tabindex="-1" href="#how-to-run-the-script"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>How to run the script</h2>

    <ul>

    <li>always start from the dataset-directory where dummy_dataset, bash-script and
    scripts are located</li>

    <li>the datasets you want to simulate will be created in a subfolder</li>

    <li>run script via <code>bash &lt;name_of_script&gt;</code> (here <code>&lt;name_of_script&gt;</code>
    is <code>make_dataset_vary_perm.sh</code>) <code>&lt;CLA_NUMBER_VARIATIONS_PRESSURE&gt;
    &lt;CLA_PRESSURE_CASE&gt; &lt;CLA_NUMBER_VARIATIONS_PERMEABILITY&gt; &lt;CLA_PERM_CASE&gt;
    &lt;CLA_DIMENSIONS&gt; &lt;CLA_NAME&gt; &lt;CLA_VISUALISATION&gt;</code> with
    the respective commandline arguments

    -CLA_NUMBER_VARIATIONS_PRESSURE and CLA_NUMBER_VARIATIONS_PERMEABILITY: number
    of variations of pressure and permeability field (e.g. 10 10)

    <ul>

    <li>CLA_PRESSURE_CASE currently has two options: "1D" creates a dataset with a
    constant pressure field that only varies in the y-component (MOST LIKELY WHAT
    YOU WANT); "2D" creates a dataset with a constant pressure field that varies in
    the x- and y-component</li>

    <li>CLA_PERM_CASE currently has two options: "vary" creates a dataset with a varying
    permeability field (through perlin noise); "iso" creates a dataset with a constant
    permeability field</li>

    <li>CLA_DIMENSIONS: whether the dataset should be 2D or 3D</li>

    <li>CLA_NAME is the name of the dataset to create, i.e. of the subfolder to create
    in the current directory</li>

    <li>CLA_VISULISATION is an <strong>optional</strong> commandline argument defining
    whether to produce some automated pictures (selfmade in python) : if you want
    it, write "vis" as CLA_VISUALISATION, else leave it empty</li>

    </ul>

    </li>

    </ul>

    <h2><a id="user-content-if-you-encounter-an-unexpected-error" class="anchor" aria-hidden="true"
    tabindex="-1" href="#if-you-encounter-an-unexpected-error"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>If you encounter an unexpected error</h2>

    <ul>

    <li>you can see that e.g. if a file fort.86 is produced</li>

    <li>comment <code>-screen_output off</code> out in the bash-script to get a log
    output from pflotran</li>

    </ul>

    <h2><a id="user-content-how-to-change-the-size-of-the-domain" class="anchor" aria-hidden="true"
    tabindex="-1" href="#how-to-change-the-size-of-the-domain"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>How to change the size of the domain</h2>

    <ul>

    <li>

    <code>pflotran.in</code> :

    <ul>

    <li>adapt <code>REGION all</code> if domain should be larger than 200x2000x100m</li>

    </ul>

    </li>

    <li>change the <code>size</code> and <code>ncells</code> in <code>settings.yaml</code>

    </li>

    <li>check whether the heat pump is still located reasonably and if you change
    that position, remember to adapt the visualization and slicing as well</li>

    <li>you probably also want to change the frequency (for the permeability field)
    in <code>settings.yaml</code> <code>settings.frequency = (4,4,2)</code>

    </li>

    </ul>

    <h2><a id="user-content-how-to-get-vtk-output-to-view-in-paraview" class="anchor"
    aria-hidden="true" tabindex="-1" href="#how-to-get-vtk-output-to-view-in-paraview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to get vtk output
    to view in paraview</h2>

    <ul>

    <li>in <code>pflotran.in</code> change the following line:

    <ul>

    <li>

    <code>FORMAT VTK</code> (approx. line 213)</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 3
  subscribers_count: 1
  topics: []
  updated_at: 1698937369.0
LLNL/DiHydrogen:
  data_format: 2
  description: null
  filenames:
  - .gitlab/spack/environments/quartz/spack.yaml
  - .gitlab/spack/environments/corona/spack.yaml
  - .gitlab/spack/environments/pascal/spack.yaml
  full_name: LLNL/DiHydrogen
  latest_release: v0.3.0
  readme: '<h1><a id="user-content-dihydrogen" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dihydrogen"><span aria-hidden="true" class="octicon octicon-link"></span></a>DiHydrogen</h1>

    <p>DiHydrogen is the second version of the

    <a href="https://github.com/llnl/elemental">Hydrogen</a> fork of the well-known

    distributed linear algebra library,

    <a href="https://github.com/elemental/elemental">Elemental</a>.  DiHydrogen aims

    to be a basic distributed multilinear algebra interface with a

    particular emphasis on the needs of the distributed machine learning

    effort, <a href="https://github.com/llnl/lbann">LBANN</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>DiHydrogen is distributed under the terms of the Apache License (Version 2.0).</p>

    <p>All new contributions must be made under the Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/LLNL/DiHydrogen/blob/develop/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/NOTICE">NOTICE</a> for
    details.</p>

    <p>SPDX-License-Identifier: Apache-2.0</p>

    <p>LLNL-CODE-800100</p>

    '
  stargazers_count: 4
  subscribers_count: 11
  topics:
  - cpp
  - math-physics
  updated_at: 1680394625.0
LLNL/Tribol:
  data_format: 2
  description: Modular interface physics library featuring state-of-the-art contact
    physics methods.
  filenames:
  - scripts/spack/configs/toss_4_x86_64_ib/spack.yaml
  full_name: LLNL/Tribol
  latest_release: null
  readme: '<h1><a id="user-content-tribol-contact-interface-physics-library" class="anchor"
    aria-hidden="true" tabindex="-1" href="#tribol-contact-interface-physics-library"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Tribol: Contact Interface
    Physics Library</h1>

    <p>High fidelity simulations modeling complex interactions of moving bodies require

    specialized contact algorithms to enforce constraints between surfaces that come

    into contact in order to prevent penetration and to compute the associated contact

    response forces. Tribol aims to provide a unified interface for various contact

    algorithms, specifically, contact detection and enforcement, and serve as a

    common infrastructure enabling the research and development of advanced contact

    algorithms.</p>

    <h2><a id="user-content-quick-start-guide" class="anchor" aria-hidden="true" tabindex="-1"
    href="#quick-start-guide"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quick
    Start Guide</h2>

    <h3><a id="user-content-clone-the-repository" class="anchor" aria-hidden="true"
    tabindex="-1" href="#clone-the-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Clone the repository</h3>

    <pre><code>git clone --recursive git@github.com:LLNL/Tribol.git

    </code></pre>

    <h3><a id="user-content-setup-for-development" class="anchor" aria-hidden="true"
    tabindex="-1" href="#setup-for-development"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Setup for Development</h3>

    <p>Development tools can optionally be installed through the Spack package manager.

    The command to do this is</p>

    <pre><code>python3 scripts/uberenv/uberenv.py --project-json=scripts/spack/devtools.json
    --spack-config-dir=scripts/spack/configs/&lt;platform&gt; --prefix=../tribol_devtools

    </code></pre>

    <p>Please verify the <code>compilers.yaml</code> and <code>packages.yaml</code>
    files in

    <code>scripts/spack/configs/&lt;platform&gt;</code> match your system configuration.  In

    particular, local versions of <code>pyshroud</code> and <code>pysphinx</code>
    are assumed present.</p>

    <h3><a id="user-content-installing-dependencies" class="anchor" aria-hidden="true"
    tabindex="-1" href="#installing-dependencies"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Installing dependencies</h3>

    <p>Tribol dependency installation is managed through uberenv, which invokes a
    local

    instance of the spack package manager to install and manage dependencies.  To

    install dependencies, run</p>

    <pre><code>python3 scripts/uberenv/uberenv.py --spack-config-dir=scripts/spack/configs/&lt;platform&gt;
    --prefix=../tribol_libs

    </code></pre>

    <p>See additional options by running</p>

    <pre><code>python3 scripts/uberenv/uberenv.py --help

    </code></pre>

    <p>Tribol is tested on three platforms:</p>

    <ul>

    <li>Ubuntu 20.04 LTS (via Windows WSL 2)</li>

    <li>TOSS 3</li>

    <li>BlueOS</li>

    </ul>

    <p>Note, running on Ubuntu 20.04 LTS requires inspecting and tailoring the

    <code>compilers.yaml</code> and <code>packages.yaml</code> files for your specific
    system.</p>

    <p>See <code>scripts/spack/packages/tribol/package.py</code> for possible variants
    in the

    spack spec. The file <code>scripts/spack/specs.json</code> lists spack specs which
    are

    known to build successfully on different platforms.  Note the development tools

    can be built with dependencies using the <code>+devtools</code> variant.</p>

    <h3><a id="user-content-build-the-code" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build-the-code"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    the code</h3>

    <p>After running uberenv, a host config file is created in the tribol repo root

    directory.  Use the <code>config-build.py</code> script to create build and install

    directories and invoke CMake.</p>

    <pre><code>python3 ./config-build.py -hc &lt;host-config&gt;

    </code></pre>

    <p>Enter the build directory and run</p>

    <pre><code>make -j

    </code></pre>

    <p>to build Tribol.</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>The Tribol contact physics library requires:</p>

    <ul>

    <li>CMake 3.14 or higher</li>

    <li>C++11 compiler</li>

    <li>MPI</li>

    <li>mfem</li>

    <li>axom</li>

    </ul>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Tribol is distributed under the terms of the MIT license. All new contributions
    must be

    made under this license.</p>

    <p>See <a href="LICENSE">LICENSE</a> and <a href="NOTICE">NOTICE</a> for details.</p>

    <p>SPDX-License-Identifier: MIT</p>

    <p>LLNL-CODE-846697</p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spdx-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPDX
    usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as MIT contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (MIT)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" tabindex="-1"
    href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>External
    Packages</h2>

    <p>Tribol bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 14
  subscribers_count: 8
  topics:
  - math-physics
  updated_at: 1700920906.0
LLNL/Umpire:
  data_format: 2
  description: An application-focused API for memory management on NUMA & GPU architectures
  filenames:
  - .spack_env/darwin/spack.yaml
  full_name: LLNL/Umpire
  latest_release: v2023.06.0
  readme: '<h1><a id="user-content---umpire-v2023060" class="anchor" aria-hidden="true"
    tabindex="-1" href="#--umpire-v2023060"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/81bd6212d0dd884f5a1d99f54f5b792596f42ad2d6643791a885b7ff42aad41e/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"><img
    src="https://camo.githubusercontent.com/81bd6212d0dd884f5a1d99f54f5b792596f42ad2d6643791a885b7ff42aad41e/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"
    width="128" valign="middle" alt="Umpire" data-canonical-src="https://cdn.rawgit.com/LLNL/Umpire/develop/share/umpire/logo/umpire-logo.png"
    style="max-width: 100%;"></a>  Umpire v2023.06.0</h1>

    <p><a href="https://travis-ci.com/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/36f0f474aacbade149e980682a28b1b97aa3ea7737006edce896fa4ebbc9ffa7/68747470733a2f2f7472617669732d63692e636f6d2f4c4c4e4c2f556d706972652e7376673f6272616e63683d646576656c6f70"
    alt="Travis Build Status" data-canonical-src="https://travis-ci.com/LLNL/Umpire.svg?branch=develop"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/davidbeckingsale/Umpire/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/615ebc663bd8e7bce0a236693071d360c1f3d4b04bfabb454ba50068b0bac3c0/68747470733a2f2f6465762e617a7572652e636f6d2f64617669646265636b696e6773616c652f556d706972652f5f617069732f6275696c642f7374617475732f4c4c4e4c2e556d706972653f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/davidbeckingsale/Umpire/_apis/build/status/LLNL.Umpire?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://umpire.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/7fd7eef5a102528cae391ff45e9ae1026690d979c1413498b1604b23febeffaf/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756d706972652f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/umpire/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/d567cb288d0416a63a2faa83e8b2d5265860c1a3e9af604f4b6730340fa830c7/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f556d706972652f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/Umpire/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a> <a href="https://gitter.im/LLNL/Umpire?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/d812b594e8c008b20bc4b4e508035cb3ffd814a168debe18107da92e6c7e5f88/68747470733a2f2f6261646765732e6769747465722e696d2f4c4c4e4c2f556d706972652e737667"
    alt="Join the chat at https://gitter.im/LLNL/Umpire" data-canonical-src="https://badges.gitter.im/LLNL/Umpire.svg"
    style="max-width: 100%;"></a></p>

    <p>Umpire is a resource management library that allows the discovery, provision,

    and management of memory on machines with multiple memory devices like NUMA and
    GPUs.</p>

    <p>Umpire uses CMake and BLT to handle builds. Since BLT is included as a

    submodule, first make sure you run:</p>

    <pre><code>$ git submodule init &amp;&amp; git submodule update

    </code></pre>

    <p>Then, make sure that you have a modern compiler loaded, and the configuration
    is as

    simple as:</p>

    <pre><code>$ mkdir build &amp;&amp; cd build

    $ cmake ..

    </code></pre>

    <p>CMake will provide output about which compiler is being used. Once CMake has

    completed, Umpire can be built with Make:</p>

    <pre><code>$ make

    </code></pre>

    <p>For more advanced configuration you can use standard CMake variables.</p>

    <h1><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>Both user and code documentation is available <a href="http://umpire.readthedocs.io/"
    rel="nofollow">here</a>.</p>

    <p>The Umpire <a href="https://umpire.readthedocs.io/en/develop/sphinx/tutorial.html"
    rel="nofollow">tutorial</a> provides a step by step introduction to Umpire features.</p>

    <p>If you have build problems, we have comprehensive <a href="https://umpire.readthedocs.io/en/develop/sphinx/advanced_configuration.html"
    rel="nofollow">build system documentation</a> too!</p>

    <h1><a id="user-content-getting-involved" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-involved"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Involved</h1>

    <p>Umpire is an open-source project, and we welcome contributions from the community.</p>

    <h2><a id="user-content-mailing-list" class="anchor" aria-hidden="true" tabindex="-1"
    href="#mailing-list"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mailing
    List</h2>

    <p>The Umpire mailing list is hosted on Google Groups, and is a great place to
    ask questions:</p>

    <ul>

    <li><a href="https://groups.google.com/forum/#!forum/umpire-users" rel="nofollow">Umpire
    Users Google Group</a></li>

    </ul>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits; it''s all great!</p>

    <p>To contribute, make a <a href="https://github.com/LLNL/Umpire/compare">pull
    request</a>, with <code>develop</code> as the destination branch.

    We use Travis to run CI tests, and your branch must pass these tests before being
    merged.</p>

    <p>For more information, see the <a href="https://github.com/LLNL/Umpire/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h1><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h1>

    <p>Thanks to all of Umpire''s

    <a href="https://github.com/LLNL/Umpire/graphs/contributors">contributors</a>.</p>

    <p>Umpire was created by David Beckingsale (<a href="mailto:david@llnl.gov">david@llnl.gov</a>).</p>

    <h2><a id="user-content-citing-umpire" class="anchor" aria-hidden="true" tabindex="-1"
    href="#citing-umpire"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citing
    Umpire</h2>

    <p>If you are referencing Umpire in a publication, please use the following citation:</p>

    <ul>

    <li>D. Beckingsale, M. Mcfadden, J. Dahm, R. Pankajakshan and R. Hornung, <a href="https://ieeexplore.ieee.org/document/8907404"
    rel="nofollow">"Umpire: Application-Focused Management and Coordination of Complex
    Hierarchical Memory,"</a> in IBM Journal of Research and Development. 2019. doi:
    10.1147/JRD.2019.2954403</li>

    </ul>

    <h1><a id="user-content-release" class="anchor" aria-hidden="true" tabindex="-1"
    href="#release"><span aria-hidden="true" class="octicon octicon-link"></span></a>Release</h1>

    <p>Umpire is released under an MIT license. For more details, please see the

    <a href="./LICENSE">LICENSE</a> and <a href="./RELEASE">RELEASE</a> files.</p>

    <p><code>LLNL-CODE-747640</code>

    <code>OCEC-18-031</code></p>

    '
  stargazers_count: 277
  subscribers_count: 15
  topics:
  - hpc
  - memory-management
  - gpu
  - blt
  - portability
  - radiuss
  - cpp
  updated_at: 1701057648.0
LLNL/UnifyFS:
  data_format: 2
  description: 'UnifyFS: A file system for burst buffers'
  filenames:
  - .spack-env/unifyfs-lsf-gcc4_9_3/spack.yaml
  - .spack-env/unifyfs-slurm-gcc4_9_3/spack.yaml
  full_name: LLNL/UnifyFS
  latest_release: v1.1
  readme: "<h1><a id=\"user-content-unifyfs-a-distributed-burst-buffer-file-system\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#unifyfs-a-distributed-burst-buffer-file-system\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UnifyFS:\
    \ A Distributed Burst Buffer File System</h1>\n<p>Node-local burst buffers are\
    \ becoming an indispensable hardware resource on\nlarge-scale supercomputers to\
    \ buffer the bursty I/O from scientific\napplications. However, there is a lack\
    \ of software support for burst buffers to\nbe efficiently shared by applications\
    \ within a batch-submitted job and recycled\nacross different batch jobs. In addition,\
    \ burst buffers need to cope with a\nvariety of challenging I/O patterns from\
    \ data-intensive scientific\napplications.</p>\n<p>UnifyFS is a user-level burst\
    \ buffer file system under active development.\nUnifyFS supports scalable and\
    \ efficient aggregation of I/O bandwidth from burst\nbuffers while having the\
    \ same life cycle as a batch-submitted job. While UnifyFS\nis designed for N-N\
    \ write/read, UnifyFS compliments its functionality with the\nsupport for N-1\
    \ write/read. It efficiently accelerates scientific I/O based on\nscalable metadata\
    \ indexing, co-located I/O delegation, and server-side read\nclustering and pipelining.</p>\n\
    <h2><a id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#documentation\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Documentation</h2>\n<p>UnifyFS documentation\
    \ is at <a href=\"https://unifyfs.readthedocs.io\" rel=\"nofollow\">https://unifyfs.readthedocs.io</a>.</p>\n\
    <p>For instructions on how to build and install UnifyFS,\nsee <a href=\"http://unifyfs.readthedocs.io/en/dev/build.html\"\
    \ rel=\"nofollow\">Build UnifyFS</a>.</p>\n<h2><a id=\"user-content-build-status\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#build-status\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build Status</h2>\n\
    <p>Status of UnifyFS development branch (dev):</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    ><img src=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://unifyfs.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e83e6f0dfc2d353a5c6d482643646205f8fcc8e0b3327cb32dc9b27292e16823/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756e69667966732f62616467652f3f76657273696f6e3d646576\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/unifyfs/badge/?version=dev\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-unifyfs-citation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#unifyfs-citation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UnifyFS\
    \ Citation</h2>\n<p>We recommend that you use this citation for UnifyFS:</p>\n\
    <ul>\n<li>Michael Brim, Adam Moody, Seung-Hwan Lim, Ross Miller, Swen Boehm, Cameron\
    \ Stanavige, Kathryn Mohror, Sarp Oral, \u201CUnifyFS: A User-level Shared File\
    \ System for Unified Access to Distributed Local Storage,\u201D 37th IEEE International\
    \ Parallel &amp; Distributed Processing Symposium (IPDPS 2023), St. Petersburg,\
    \ FL, May 2023.</li>\n</ul>\n<h2><a id=\"user-content-contribute-and-develop\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contribute-and-develop\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contribute\
    \ and Develop</h2>\n<p>If you would like to help, please see our <a href=\"https://unifyfs.readthedocs.io/en/dev/contribute-ways.html\"\
    \ rel=\"nofollow\">contributing guidelines</a>.</p>\n"
  stargazers_count: 93
  subscribers_count: 20
  topics:
  - system-software
  - burst-buffers
  - file-system
  updated_at: 1698718098.0
LLNL/axom:
  data_format: 2
  description: CS infrastructure components for HPC applications
  filenames:
  - scripts/spack/devtools_configs/toss_3_x86_64_ib/spack.yaml
  - scripts/spack/configs/toss_3_x86_64_ib/spack.yaml
  - scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/linux_ubuntu_20/spack.yaml
  full_name: LLNL/axom
  latest_release: v0.8.1
  readme: '<h1><a id="" class="anchor" aria-hidden="true" tabindex="-1" href="#"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a target="_blank"
    rel="noopener noreferrer" href="/share/axom/logo/axom_logo_transparent.png?raw=true"><img
    src="/share/axom/logo/axom_logo_transparent.png?raw=true" width="250" valign="middle"
    alt="Axom" style="max-width: 100%;"></a></h1>

    <p><a href="https://dev.azure.com/axom/axom/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/1e537c454d83150c4b7bfb804bc21f0072b06abd9dfb3b512cda35bbd87cfa74/68747470733a2f2f6465762e617a7572652e636f6d2f61786f6d2f61786f6d2f5f617069732f6275696c642f7374617475732f4c4c4e4c2e61786f6d3f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/axom/axom/_apis/build/status/LLNL.axom?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://axom.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/0d1ad2943bef54d4b2dd8e5e6161872f93eb95a7b28498913b3b7c71c977b686/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f61786f6d2f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/axom/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/blob/develop/LICENSE"><img src="https://camo.githubusercontent.com/8ccf186e7288af6d88a1f6a930c0fcc4e7a8a9936b34e07629d815d1eab4d977/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/License-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/releases/latest"><img src="https://camo.githubusercontent.com/7e96e2e62e0ae13e391856d4c9a26779fb83684be5dd6274d812ce8c4c75e800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4c4c4e4c2f61786f6d2e737667"
    alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/LLNL/axom.svg"
    style="max-width: 100%;"></a></p>

    <p>Axom provides robust, flexible software infrastructure for the development
    of multi-physics applications and computational tools.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Latest docs on Develop branch: <a href="https://axom.readthedocs.io" rel="nofollow">https://axom.readthedocs.io</a></p>

    <p>To access docs for other versions: <a href="https://readthedocs.org/projects/axom/"
    rel="nofollow">https://readthedocs.org/projects/axom/</a></p>

    <h2><a id="user-content-getting-involved" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-involved"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Involved</h2>

    <p>Axom is an open-source project and we welcome contributions from the community.</p>

    <h2><a id="user-content-mailing-list" class="anchor" aria-hidden="true" tabindex="-1"
    href="#mailing-list"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mailing
    List</h2>

    <p>The project maintains two email lists:</p>

    <ul>

    <li>''<a href="mailto:axom-users@llnl.gov">axom-users@llnl.gov</a>'' is how Axom
    users can contact developers for questions, report issues, etc.</li>

    <li>''<a href="mailto:axom-dev@llnl.gov">axom-dev@llnl.gov</a>'' is for communication
    among team members.</li>

    </ul>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits.</p>

    <p>To contribute, make a <a href="https://github.com/llnl/axom/compare">pull request</a>,
    with <code>develop</code>

    as the destination branch. We use CI testing and your branch must pass these tests
    before

    being merged.</p>

    <p>For more information, see the <a href="https://github.com/llnl/axom/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Thanks to all of Axom''s

    <a href="https://github.com/llnl/axom/graphs/contributors">contributors</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Copyright (c) 2017-2023, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Axom project are retained by contributors.

    No copyright assignment is required to contribute to Axom.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution

    <code>LLNL-CODE-741217</code> <code>OCEC-17-187</code></p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spdx-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPDX
    usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" tabindex="-1"
    href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>External
    Packages</h2>

    <p>Axom bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: CLI11<br>

    PackageHomePage: <a href="https://github.com/CLIUtils/CLI11">https://github.com/CLIUtils/CLI11</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: fmt<br>

    PackageHomePage: <a href="https://github.com/fmtlib/fmt">https://github.com/fmtlib/fmt</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sol<br>

    PackageHomePage: <a href="https://github.com/ThePhD/sol2">https://github.com/ThePhD/sol2</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sparsehash<br>

    PackageHomePage: <a href="https://github.com/sparsehash/sparsehash">https://github.com/sparsehash/sparsehash</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 120
  subscribers_count: 22
  topics:
  - hpc
  - parallel-computing
  - llnl
  - cpp
  - c-plus-plus
  - app-infrastructure
  - radiuss
  - fortran
  updated_at: 1701234338.0
LLNL/benchpark:
  data_format: 2
  description: An open collaborative repository for cross site benchmarking environments
  filenames:
  - configs/cts1/spack.yaml
  - configs/AWS-x86-ParallelCluster-3.7.2/spack.yaml
  - configs/ats2/spack.yaml
  - configs/x86/spack.yaml
  full_name: LLNL/benchpark
  latest_release: null
  stargazers_count: 18
  subscribers_count: 9
  topics:
  - benchmark
  - hpc
  updated_at: 1700877146.0
LLNL/hiop:
  data_format: 2
  description: HPC solver for nonlinear optimization problems
  filenames:
  - scripts/platforms/newell/spack.yaml
  - scripts/platforms/summit/spack.yaml
  - scripts/platforms/marianas/spack.yaml
  full_name: LLNL/hiop
  latest_release: v1.0.1
  readme: "<h1><a id=\"user-content-hiop---hpc-solver-for-optimization\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#hiop---hpc-solver-for-optimization\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>HiOp - HPC\
    \ solver for optimization</h1>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\"><img src=\"\
    https://github.com/LLNL/hiop/workflows/tests/badge.svg\" alt=\"tests\" style=\"\
    max-width: 100%;\"></a></p>\n<p>HiOp is an optimization solver for solving certain\
    \ mathematical optimization problems expressed as nonlinear programming problems.\
    \ HiOp is a lightweight HPC solver that leverages application's existing data\
    \ parallelism to parallelize the optimization iterations by using specialized\
    \ parallel linear algebra kernels.</p>\n<p>Please cite the user manual whenever\
    \ HiOp is used:</p>\n<pre><code>@TECHREPORT{hiop_techrep,\n  title={{HiOp} --\
    \ {U}ser {G}uide},\n  author={Petra, Cosmin G. and Chiang, NaiYuan and Jingyi\
    \ Wang},\n  year={2018},\n  institution = {Center for Applied Scientific Computing,\
    \ Lawrence Livermore National Laboratory},\n  number = {LLNL-SM-743591}\n}\n</code></pre>\n\
    <p>In addition, when using the quasi-Newton solver please cite:</p>\n<pre><code>@ARTICLE{Petra_18_hiopdecomp,\n\
    title = {A memory-distributed quasi-Newton solver for nonlinear programming problems\
    \ with a small number of general constraints},\njournal = {Journal of Parallel\
    \ and Distributed Computing},\nvolume = {133},\npages = {337-348},\nyear = {2019},\n\
    issn = {0743-7315},\ndoi = {https://doi.org/10.1016/j.jpdc.2018.10.009},\nurl\
    \ = {https://www.sciencedirect.com/science/article/pii/S0743731518307731},\nauthor\
    \ = {Cosmin G. Petra},\n}\n</code></pre>\n<p>and when using the the PriDec solver\
    \ please cite:</p>\n<pre><code>@article{wang2023,\n  archivePrefix = {arXiv},\n\
    \  author = {J. Wang and C. G. Petra},\n  title = {A Sequential Quadratic Programming\
    \ Algorithm for Nonsmooth Problems with Upper-$\\mathcal{C}^2$ Objective},\n \
    \ journal = {SIAM Journal on Optimization},\n  volume = {33},\n  number = {3},\n\
    \  pages = {2379-2405},\n  year = {2023},\n  doi = {10.1137/22M1490995}\n}\n@INPROCEEDINGS{wang2021,\n\
    \  author={J. Wang and N. Chiang and C. G. Petra},\n  booktitle={2021 20th International\
    \ Symposium on Parallel and Distributed Computing (ISPDC)}, \n  title={An asynchronous\
    \ distributed-memory optimization solver for two-stage stochastic programming\
    \ problems}, \n  year={2021},\n  volume={},\n  number={},\n  pages={33-40},\n\
    \  doi={10.1109/ISPDC52870.2021.9521613}}\n }\n</code></pre>\n<h2><a id=\"user-content-buildinstall-instructions\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#buildinstall-instructions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build/install\
    \ instructions</h2>\n<p>HiOp uses a CMake-based build system. A standard build\
    \ can be done by invoking in the 'build' directory the following</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> cmake\
    \ ..\n$<span class=\"pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span>\
    \ make <span class=\"pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make\
    \ install</pre></div>\n<p>This sequence will build HiOp, run integrity and correctness\
    \ tests, and install the headers and the library in the directory '_dist-default-build'\
    \ in HiOp's root directory.</p>\n<p>Command <code>make test</code> runs extensive\
    \ tests of the various modules of HiOp to check integrity and correctness. The\
    \ tests suite range from unit testing to solving concrete optimization problems\
    \ and checking the performance of HiOp solvers on these problems against known\
    \ solutions. By default <code>make test</code> runs <code>mpirun</code> locally,\
    \ which may not work on some HPC machines. For these HiOp allows using <code>bsub</code>\
    \ to schedule <code>make test</code> on the compute nodes; to enable this, the\
    \ use should use <em>-DHIOP_TEST_WITH_BSUB=ON</em> with cmake when building and\
    \ run <code>make test</code> in a bsub shell session, for example,</p>\n<pre><code>bsub\
    \ -P your_proj_name -nnodes 1 -W 30\nmake test\nCTRL+D\n</code></pre>\n<p>The\
    \ installation can be customized using the standard CMake options. For example,\
    \ one can provide an alternative installation directory for HiOp by using</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span>\
    \ cmake -DCMAKE_INSTALL_PREFIX=/usr/lib/hiop ..<span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span></span></pre></div>\n<h3><a id=\"user-content-selected-hiop-specific-build-options\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#selected-hiop-specific-build-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selected\
    \ HiOp-specific build options</h3>\n<ul>\n<li>Enable/disable MPI: <em>-DHIOP_USE_MPI=[ON/OFF]</em>\
    \ (by default ON)</li>\n<li>GPU support: <em>-DHIOP_USE_GPU=ON</em>. MPI can be\
    \ either off or on. For more build system options related to GPUs, see \"Dependencies\"\
    \ section below.</li>\n<li>Enable/disable \"developer mode\" build that enforces\
    \ more restrictive compiler rules and guidelines: <em>-DHIOP_DEVELOPER_MODE=ON</em>.\
    \ This option is by default off.</li>\n<li>Additional checks and self-diagnostics\
    \ inside HiOp meant to detect abnormalities and help to detect bugs and/or troubleshoot\
    \ problematic instances: <em>-DHIOP_DEEPCHECKS=[ON/OFF]</em> (by default ON).\
    \ Disabling HIOP_DEEPCHECKS usually provides 30-40% execution speedup in HiOp.\
    \ For full strength, it is recommended to use HIOP_DEEPCHECKS with debug builds.\
    \ With non-debug builds, in particular the ones that disable the assert macro,\
    \ HIOP_DEEPCHECKS does not perform all checks and, thus, may overlook potential\
    \ issues.</li>\n</ul>\n<p>For example:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_MPI=ON -DHIOP_DEEPCHECKS=ON\
    \ ..\n$<span class=\"pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span>\
    \ make <span class=\"pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make\
    \ install</pre></div>\n<h3><a id=\"user-content-other-useful-options-to-use-with-cmake\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#other-useful-options-to-use-with-cmake\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other useful\
    \ options to use with CMake</h3>\n<ul>\n<li>\n<em>-DCMAKE_BUILD_TYPE=Release</em>\
    \ will build the code with the optimization flags on</li>\n<li>\n<em>-DCMAKE_CXX_FLAGS=\"\
    -O3\"</em> will enable a high level of compiler code optimization</li>\n</ul>\n\
    <h3><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Dependencies</h3>\n<p>A complete list of dependencies\
    \ is maintained <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/hiop/package.py\"\
    >here</a>.</p>\n<p>For a minimal build, HiOp requires LAPACK and BLAS. These dependencies\
    \ are automatically detected by the build system. MPI is optional and by default\
    \ enabled. To disable use cmake option '-DHIOP_USE_MPI=OFF'.</p>\n<p>HiOp has\
    \ support for NVIDIA <strong>GPU-based computations</strong> via CUDA and Magma.\
    \ To enable the use of GPUs, use cmake with '-DHIOP_USE_GPU=ON'. The build system\
    \ will automatically search for CUDA Toolkit. For non-standard CUDA Toolkit installations,\
    \ use '-DHIOP_CUDA_LIB_DIR=/path' and '-DHIOP_CUDA_INCLUDE_DIR=/path'. For \"\
    very\" non-standard CUDA Toolkit installations, one can specify the directory\
    \ of cuBlas libraries as well with '-DHIOP_CUBLAS_LIB_DIR=/path'.</p>\n<h3><a\
    \ id=\"user-content-using-raja-and-umpire-portability-libraries\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#using-raja-and-umpire-portability-libraries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using RAJA\
    \ and Umpire portability libraries</h3>\n<p>Portability libraries allow running\
    \ HiOp's linear algebra either on host (CPU) or a device (GPU). RAJA and Umpire\
    \ are disabled by default. You can turn them on together by passing <code>-DHIOP_USE_RAJA=ON</code>\
    \ to CMake. If the two libraries are not automatically found, specify their installation\
    \ directories like this:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_RAJA=ON -DRAJA_DIR=/path/to/raja/dir\
    \ -Dumpire_DIR=/path/to/umpire/dir</pre></div>\n<p>If the GPU support is enabled,\
    \ RAJA will run all HiOp linear algebra kernels on GPU, otherwise RAJA will run\
    \ the kernels on CPU using an OpenMP execution policy.</p>\n<h3><a id=\"user-content-support-for-gpu-computations\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#support-for-gpu-computations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Support\
    \ for GPU computations</h3>\n<p>When GPU support is on, HiOp requires Magma linear\
    \ solver library and CUDA Toolkit. Both are detected automatically in most cases.\
    \ The typical cmake command to enable GPU support in HiOp is</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> cmake\
    \ -DHIOP_USE_GPU=ON ..</pre></div>\n<p>When Magma is not detected, one can specify\
    \ its location by passing <code>-DHIOP_MAGMA_DIR=/path/to/magma/dir</code> to\
    \ cmake.</p>\n<p>For custom CUDA Toolkit installations, the locations to the (missing/not\
    \ found) CUDA libraries can be specified to cmake via <code>-DNAME=/path/cuda/directory/lib</code>,\
    \ where <code>NAME</code> can be any of</p>\n<pre><code>CUDA_cublas_LIBRARY\n\
    CUDA_CUDART_LIBRARY\nCUDA_cudadevrt_LIBRARY\nCUDA_cusparse_LIBRARY\nCUDA_cublasLt_LIBRARY\n\
    CUDA_nvblas_LIBRARY\nCUDA_culibos_LIBRARY\n</code></pre>\n<p>Below is an example\
    \ for specifiying <code>cuBlas</code>, <code>cuBlasLt</code>, and <code>nvblas</code>\
    \ libraries, which were <code>NOT_FOUND</code> because of a non-standard CUDA\
    \ Toolkit instalation:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span\
    \ class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_GPU=ON -DCUDA_cublas_LIBRARY=/usr/local/cuda-10.2/targets/x86_64-linux/lib/lib64\
    \ -DCUDA_cublasLt_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ -DCUDA_nvblas_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>A detailed example on how to compile HiOp straight\
    \ of the box on <code>summit.olcf.ornl.gov</code> is available <a href=\"README_summit.md\"\
    >here</a>.</p>\n<p>RAJA and UMPIRE dependencies are usually detected by HiOp's\
    \ cmake build system.</p>\n<h3><a id=\"user-content-kron-reduction\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#kron-reduction\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Kron reduction</h3>\n<p>Kron\
    \ reduction functionality of HiOp is disabled by default. One can enable it by\
    \ using</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span class=\"\
    pl-k\">&gt;</span> rm -rf <span class=\"pl-k\">*</span><span class=\"pl-k\">;</span>\
    \ cmake -DHIOP_WITH_KRON_REDUCTION=ON -DUMFPACK_DIR=/Users/petra1/work/installs/SuiteSparse-5.7.1\
    \ -DMETIS_DIR=/Users/petra1/work/installs/metis-4.0.3 .. <span class=\"pl-k\"\
    >&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span> make install</pre></div>\n\
    <p>Metis is usually detected automatically and needs not be specified under normal\
    \ circumstances.</p>\n<p>UMFPACK (part of SuiteSparse) and METIS need to be provided\
    \ as shown above.</p>\n<h1><a id=\"user-content-interfacing-with-hiop\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#interfacing-with-hiop\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Interfacing\
    \ with HiOp</h1>\n<p>HiOp supports three types of optimization problems, each\
    \ with a separate input formats in the form of the C++ interfaces <code>hiopInterfaceDenseConstraints</code>,<code>hiopInterfaceSparse</code>\
    \ and <code>hiopInterfaceMDS</code>. These interfaces are specified in <a href=\"\
    src/Interface/hiopInterface.hpp\">hiopInterface.hpp</a> and documented and discussed\
    \ as well in the <a href=\"doc/hiop_usermanual.pdf\">user manual</a>.</p>\n<p><em><code>hiopInterfaceDenseConstraints</code>\
    \ interface</em> supports NLPs with <strong>billions</strong> of variables with\
    \ and without bounds but only limited number (&lt;100) of general, equality and\
    \ inequality constraints. The underlying algorithm is a limited-memory quasi-Newton\
    \ interior-point method and generally scales well computationally (but it may\
    \ not algorithmically) on thousands of cores. This interface uses MPI for parallelization</p>\n\
    <p><em><code>hiopInterfaceSparse</code> interface</em> supports general sparse\
    \ and large-scale NLPs. This functionality is similar to that of the state-of-the-art\
    \ <a href=\"https://github.com/coin-or/Ipopt\">Ipopt</a> (without being as robust\
    \ and flexible as Ipopt is). Acceleration for this class of problems can be achieved\
    \ via OpenMP or CUDA, however, this is work in progress and you are encouraged\
    \ to contact HiOp's developers for up-to-date information.</p>\n<p><em><code>hiopInterfaceMDS</code>\
    \ interface</em> supports mixed dense-sparse NLPs and achives parallelization\
    \ using GPUs and RAJA portability abstraction layer.</p>\n<p>More information\
    \ on the HiOp interfaces are <a href=\"src/Interface/README.md\">here</a>.</p>\n\
    <h2><a id=\"user-content-running-hiop-tests-and-applications\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#running-hiop-tests-and-applications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ HiOp tests and applications</h2>\n<p>HiOp is using NVBlas library when built\
    \ with CUDA support. If you don't specify\nlocation of the <code>nvblas.conf</code>\
    \ configuration file, you may get an annoying\nwarnings. HiOp provides default\
    \ <code>nvblas.conf</code> file and installs it at the same\nlocation as HiOp\
    \ libraries. To use it, set environment variable as</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$ <span class=\"pl-k\">export</span> NVBLAS_CONFIG_FILE=<span\
    \ class=\"pl-k\">&lt;</span>hiop install dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n\
    <p>or, if you are using C-shell, as</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ setenv NVBLAS_CONFIG_FILE <span class=\"pl-k\">&lt;</span>hiop install\
    \ dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n<h2><a id=\"\
    user-content-existing-issues\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#existing-issues\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Existing issues</h2>\n<p>Users are highly encouraged to report any\
    \ issues they found from using HiOp.\nOne known issue is that there is some minor\
    \ inconsistence between HiOp and linear package STRUMPACK.\nWhen STRUMPACK is\
    \ compiled with MPI (and Scalapack), user must set flag <code>HIOP_USE_MPI</code>\
    \ to <code>ON</code> when compiling HiOp.\nOtherwise HiOp won't load MPI module\
    \ and will return an error when links to STRUMPACK, since the later one requires\
    \ a valid MPI module.\nSimilarly, if both Magma and STRUMPACK are linked to HiOp,\
    \ user must guarantee the all the packages are compiled by the same CUDA compiler.\n\
    User can check other issues and their existing status from <a href=\"https://github.com/LLNL/hiop\"\
    >https://github.com/LLNL/hiop</a></p>\n<h2><a id=\"user-content-acknowledgments\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#acknowledgments\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h2>\n\
    <p>HiOp has been developed under the financial support of:</p>\n<ul>\n<li>Department\
    \ of Energy, Office of Advanced Scientific Computing Research (ASCR): Exascale\
    \ Computing Program (ECP) and Applied Math Program.</li>\n<li>Department of Energy,\
    \ Advanced Research Projects Agency-Energy (ARPA\u2011E)</li>\n<li>Lawrence Livermore\
    \ National Laboratory Institutional Scientific Capability Portfolio (ISCP)</li>\n\
    <li>Lawrence Livermore National Laboratory, through the LDRD program</li>\n</ul>\n\
    <h1><a id=\"user-content-contributors\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#contributors\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Contributors</h1>\n<p>HiOp is written by Cosmin G.\
    \ Petra (<a href=\"mailto:petra1@llnl.gov\">petra1@llnl.gov</a>), Nai-Yuan Chiang\
    \ (<a href=\"mailto:chiang7@llnl.gov\">chiang7@llnl.gov</a>), and Jingyi \"Frank\"\
    \ Wang (<a href=\"mailto:wang125@llnl.gov\">wang125@llnl.gov</a>) from LLNL and\
    \ has received important contributions from Asher Mancinelli (PNNL), Slaven Peles\
    \ (ORNL), Cameron Rutherford (PNNL), Jake K. Ryan (PNNL), and Michel Schanen (ANL).</p>\n\
    <h1><a id=\"user-content-copyright\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#copyright\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Copyright</h1>\n<p>Copyright (c) 2017-2021, Lawrence Livermore National\
    \ Security, LLC. All rights reserved. Produced at the Lawrence Livermore National\
    \ Laboratory. LLNL-CODE-742473. HiOp is free software; you can modify it and/or\
    \ redistribute it under the terms of the BSD 3-clause license. See <a href=\"\
    /COPYRIGHT\">COPYRIGHT</a> and <a href=\"/LICENSE\">LICENSE</a> for complete copyright\
    \ and license information.</p>\n"
  stargazers_count: 200
  subscribers_count: 16
  topics:
  - hpc
  - nonlinear-optimization
  - nonlinear-programming
  - nonlinear-programming-algorithms
  - interior-point-method
  - parallel-programming
  - mpi
  - bfgs
  - quasi-newton
  - constrained-optimization
  - solver
  - optimization
  - acopf
  - gpu-support
  - cuda
  - math-physics
  - radiuss
  - interior-point-optimizer
  - nonsmooth-optimization
  - rocm
  updated_at: 1701224371.0
LLNL/radiuss-spack-testing:
  data_format: 2
  description: Gitlab CI automation of Spack testing with RADIUSS projects builds.
  filenames:
  - spack-environments/raja-suite/spack.yaml
  full_name: LLNL/radiuss-spack-testing
  latest_release: null
  readme: '<h1><a id="user-content-radiuss-spack-testing" class="anchor" aria-hidden="true"
    tabindex="-1" href="#radiuss-spack-testing"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>RADIUSS Spack Testing</h1>

    <p>The RADIUSS project promotes and supports key High Performance Computing (HPC)
    open-source software developed at the LLNL. These tools and libraries cover a
    wide range of features a team would need to develop a modern simulation code targeting
    HPC plaftorms.</p>

    <p>RADIUSS Spack Testing is a sub-project from the RADIUSS initiative providing
    a

    testing infrastructure to test Spack Packages automatically in GitLab while

    tracking changes in Spack.</p>

    <p>Access the <a href="https://radiuss-spack-testing.readthedocs.io/" rel="nofollow">documentation</a>.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started</h2>

    <p>The primary goal of this repo is to be used in Gitlab. The Gitlab CI configuration
    is such that it will use Spack pipeline feature to generate and run a pipeline
    that builds one of the environments in the <code>spack-environments</code> directory.</p>

    <p>The specific environment to be built is controlled by the CI variable <code>ENV_NAME</code>.</p>

    <h3><a id="user-content-installing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>This project requires no installation.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Please read <a href="https://github.com/LLNL/radiuss-spack-testing/CONTRIBUTING.md">CONTRIBUTING.md</a>
    for details on our code of conduct, and the process for submitting pull requests
    to us.</p>

    <h2><a id="user-content-versioning" class="anchor" aria-hidden="true" tabindex="-1"
    href="#versioning"><span aria-hidden="true" class="octicon octicon-link"></span></a>Versioning</h2>

    <p>version: 1.0.0</p>

    <p>TODO: Not even sure how to handle versioning here.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Adrien M Bernede</p>

    <p>See also the list of <a href="https://github.com/LLNL/radiuss-spack-testing/contributors">contributors</a>
    who participated in this project.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a>
    file for details</p>

    <p>All new contributions must be made under the MIT License.</p>

    <p>See <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (MIT)</p>

    <p>LLNL-CODE-793462</p>

    <h2><a id="user-content-acknowledgments" class="anchor" aria-hidden="true" tabindex="-1"
    href="#acknowledgments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgments</h2>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics:
  - radiuss
  updated_at: 1679009672.0
LLNL/serac:
  data_format: 2
  description: Serac is a high order nonlinear thermomechanical simulation code
  filenames:
  - scripts/spack/devtools_configs/blueos_3_ppc64le_ib_p9/spack.yaml
  - scripts/spack/configs/docker/ubuntu20/spack.yaml
  - scripts/spack/configs/darwin/spack.yaml
  full_name: LLNL/serac
  latest_release: null
  readme: '<h1><a id="" class="anchor" aria-hidden="true" tabindex="-1" href="#"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a target="_blank"
    rel="noopener noreferrer" href="/share/serac/logo/serac-logo-blue.png?raw=true"><img
    src="/share/serac/logo/serac-logo-blue.png?raw=true" width="150" alt="Serac" style="max-width:
    100%;"></a></h1>

    <p><a href="https://dev.azure.com/llnl-serac/serac/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/32116a71164a7fb6a2fcfe0a7c886af91fec3370119490e45e69481936df0830/68747470733a2f2f6465762e617a7572652e636f6d2f6c6c6e6c2d73657261632f73657261632f5f617069732f6275696c642f7374617475732f4c4c4e4c2e73657261633f6272616e63684e616d653d646576656c6f70"
    alt="Build Status" data-canonical-src="https://dev.azure.com/llnl-serac/serac/_apis/build/status/LLNL.serac?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://serac.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/b98a52491f8df53cc2e655f7f1ad48d32a2e3ccca2c3eee393b16cd34e237c5e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73657261632f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/serac/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/serac" rel="nofollow"><img src="https://camo.githubusercontent.com/e6930e8581d65cfcd5b1d2a091d1260ffd65fbd0a61235d5eac8bc8914abbb09/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f73657261632f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d444f344b464d504e4d30"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/serac/branch/develop/graph/badge.svg?token=DO4KFMPNM0"
    style="max-width: 100%;"></a>

    <a href="./LICENSE"><img src="https://camo.githubusercontent.com/3d6a8874ec039bb1f4d9ab5f71e22b2cbd98b9005f413da1066664ef444ec780/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/license-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>Serac is a 3D implicit nonlinear thermal-structural simulation code. Its primary
    purpose is to investigate multiphysics

    abstraction strategies and implicit finite element-based algorithm development
    for emerging computing architectures.

    It also serves as a proxy-app for LLNL''s Smith code and heavily leverages the
    <a href="https://mfem.org/" rel="nofollow">MFEM finite element library</a>.</p>

    <blockquote>

    <p>This project is under heavy development and is currently a pre-alpha release.
    Functionality and interfaces may change rapidly

    as development progresses.</p>

    </blockquote>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Build, run, and design documentation can be found at <a href="https://serac.readthedocs.io"
    rel="nofollow">readthedocs</a>.</p>

    <p>Source documentation can be found <a href="https://serac.readthedocs.io/en/latest/doxygen/html/index.html"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, and documentation
    edits.</p>

    <p>For more information, see the <a href="./CONTRIBUTING.md">contributing guide</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Copyright (c) 2019-2023, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Serac project are retained by contributors.

    No copyright assignment is required to contribute to Serac.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution<br>

    <code>LLNL-CODE-805541</code></p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spdx-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPDX
    usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" tabindex="-1"
    href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>External
    Packages</h2>

    <p>Serac bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: Axom<br>

    PackageHomePage: <a href="https://github.com/LLNL/axom">https://github.com/LLNL/axom</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: MFEM<br>

    PackageHomePage: <a href="https://github.com/mfem/mfem">https://github.com/mfem/mfem</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 142
  subscribers_count: 12
  topics:
  - math-physics
  - finite-elements
  - proxy-application
  - simulation
  - cpp
  updated_at: 1701248958.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/spack-nightly/int32-double/spack.yaml
  - docker/sundials-ci/spack-nightly/int64-double/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int64-single/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.6.2
  readme: '<h1><a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" aria-hidden="true" tabindex="-1" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SUNDIALS: SUite of
    Nonlinear and DIfferential/ALgebraic equation Solvers</h1>

    <h3><a id="user-content-version-662-nov-2023" class="anchor" aria-hidden="true"
    tabindex="-1" href="#version-662-nov-2023"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Version 6.6.2 (Nov 2023)</h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form

    $$M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form

    $$y'' = f(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form

    $$y'' = f(t,y,p), \quad y(t_0) = y_0(p)$$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form

    $$F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0''$$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form

    $$F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p)$$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form

    $$F(u) = 0 \quad \text{or} \quad G(u) = u$$</p>

    </li>

    </ul>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#support"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2><a id="user-content-citing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#citing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Yu Pan, Slaven Peles, Cosmin Petra, Steven B. Roberts, H. Hunter Schwartz,

    Jean M. Sexton, Dan Shumaker, Steve G. Smith, Shahbaj Sohal, Allan G. Taylor,

    Hilari C. Tiedeman, Chris White, Ting Yan, and Ulrike M. Yang.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 414
  subscribers_count: 35
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1701270565.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 23.03/0.19.2/spack.yaml
  - 22.08/0.19.0/spack.yaml
  - 22.08/0.18.1/spack.yaml
  - 23.03/0.20.0/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-for-lumi" class="anchor"
    aria-hidden="true" tabindex="-1" href="#spack-configuration-files-for-lumi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files for LUMI</h1>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1675956191.0
MuonColliderSoft/mucoll-spack:
  data_format: 2
  description: Muon Collider software repository for Spack
  filenames:
  - environments/mucoll-common/spack.yaml
  - environments/mucoll-release/spack.yaml
  full_name: MuonColliderSoft/mucoll-spack
  latest_release: v2.8
  readme: "<h1><a id=\"user-content-spack-package-repository-for-muon-collider-software-stack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spack-package-repository-for-muon-collider-software-stack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n<a href=\"\
    https://github.com/spack/spack\">Spack</a> package repository for Muon Collider\
    \ software stack</h1>\n<p>This repository holds a set of Spack recipes for Muon\
    \ Collider software (under namespace <code>mucoll</code>) based on <a href=\"\
    https://key4hep.github.io/key4hep-doc/\" rel=\"nofollow\">Key4hep</a> stack. It\
    \ extends the corresponding <a href=\"https://github.com/key4hep/key4hep-spack\"\
    >key4hep-stack</a> repository, which is required for installation, overriding\
    \ several packages by the ones customised for Muon Collider simulation studies.</p>\n\
    <p>After installing <a href=\"https://github.com/key4hep/spack\">Spack</a> and\
    \ downloading the <a href=\"https://github.com/key4hep/key4hep-spack\">key4hep-spack</a>\
    \ and <a href=\"https://github.com/MuonColliderSoft/mucoll-spack\">mucoll-spack</a>\
    \ repositories, the whole software stack can be installed using the following\
    \ commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Add repositories</span>\nspack repo add ./key4hep-spack\n\
    spack repo add ./mucoll-spack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a Spack environment</span>\nspack env create sim\nspack env activate\
    \ sim\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy package configurations</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Install the software stack</span>\nspack add mucoll-stack\nspack\
    \ concretize --reuse\nspack install --fail-fast\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Load the Muon Collider environment</span>\n<span class=\"\
    pl-c1\">source</span> <span class=\"pl-smi\">$MUCOLL_STACK</span></pre></div>\n\
    <h2><a id=\"user-content-setting-up-the-environment\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#setting-up-the-environment\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up the environment</h2>\n\
    <p>When signing in to a machine with the installed sofware stack (VM or Docker\
    \ container), it has to be loaded into the environment:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack env activate sim\n<span class=\"pl-c1\"\
    >source</span> <span class=\"pl-smi\">$MUCOLL_STACK</span></pre></div>\n<h2><a\
    \ id=\"user-content-package-versioning\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#package-versioning\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Package versioning</h2>\n<p>Preferred convention\
    \ for version names in Spack is numbers separated by dots, without leading zeros,\
    \ e.g. <code>1.2.13</code>.\nConversion to tag names in <code>mucoll</code> packages\
    \ is provided by <code>MCIlcsoftpackage</code> class defined in <code>packages/mucoll-stack/mucoll_utils.py</code>,\
    \ e.g. for <a href=\"https://github.com/MuonColliderSoft/lcgeo/releases/tag/v00-17-MC\"\
    ><code>lcgeo</code></a> package version <code>0.17</code> corresponds to tag name\
    \ <code>v00-17-MC</code>.</p>\n<h2><a id=\"user-content-adding-new-versions-for-individual-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#adding-new-versions-for-individual-packages\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new\
    \ versions for individual packages</h2>\n<p>After a new tag for the package is\
    \ created, e.g. <code>v00-17-MC</code> in <code>lcgeo</code> repository, it can\
    \ be added to this Spack repository in two steps:</p>\n<ol>\n<li>Get the archive\
    \ checksum for the new tag</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack checksum lcgeo 0.17\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Validates archive URL and returns the checksum</span>\n    version(<span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>0.17<span class=\"pl-pds\">'</span></span>,\
    \ sha256=<span class=\"pl-s\"><span class=\"pl-pds\">'</span>5ab33aaf5bc37deba82c2dde78cdce6c0041257222ed7ea052ecdd388a41cf9b<span\
    \ class=\"pl-pds\">'</span></span>)</pre></div>\n<ol start=\"2\">\n<li>Add the\
    \ returned version definition to the corresponding package file: <a href=\"packages/lcgeo/package.py\"\
    ><code>packages/lcgeo/package.py</code></a>\n</li>\n</ol>\n<blockquote>\n<p>NOTE:\
    \ This repository only contains packages maintained by the Muon Collider collaboration.\n\
    If the version of interest is missing from Spack for some other package, the line\
    \ with a new version definition should be added to the package file in the corresponding\
    \ repository.<br>\nTo see locations of other repositories: <code>spack repo list</code></p>\n\
    </blockquote>\n<h2><a id=\"user-content-creating-a-new-stack-release\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#creating-a-new-stack-release\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ a new stack release</h2>\n<p>To introduce a new release version for the whole\
    \ software stack, update the version number in <a href=\"packages/mucoll-stack/package.py\"\
    ><code>packages/mucoll-stack/package.py</code></a> and then update versions of\
    \ all the relevant packages in [environments/mucoll-release/packages.yaml].<br>\n\
    Test this new configuration in a fresh environment:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a development environment</span>\nspack env create dev\nspack env activate\
    \ dev\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy the package configuration</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Add stack with updated version to the environment</span>\nspack\
    \ add mucoll-stack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Check\
    \ which packages would be installed</span>\nspack spec --reuse -NIt</pre></div>\n\
    <p>Packages that are already installed in the <code>sim</code> environment are\
    \ known to Spack and will be reused, providing a clear indication of which part\
    \ of the dependency tree will be modified by the new release.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1679435634.0
NCAR/spack-derecho:
  data_format: 2
  description: Spack production user software stack on the Derecho system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-derecho
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NCAR Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>derecho</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Wed May 31 08:38:35 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>efdf06a3cf590b751676e9ebdf3114f9f1e86d47</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.06</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/derecho/23.06</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/derecho/23.06/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 3
  subscribers_count: 9
  topics: []
  updated_at: 1695826459.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NCAR Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Thu Mar 30 18:51:24 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fd3fc5c8cd67abe692e5e38bae52f29fb32700a3</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.04</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/23.04</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/23.04/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 5
  subscribers_count: 13
  topics: []
  updated_at: 1698301923.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-21.11/prod/spack.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-23.08/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/data/spack.yaml
  - spack-configs/perlmutter-e4s-23.08/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/tools/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/data/spack.yaml
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/base/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/gcc/spack.yaml
  - spack-configs/perlmutter-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/gcc/spack.yaml
  - spack-configs/cori-e4s-21.02/prod/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/math-libs/spack.yaml
  - spack-configs/perlmutter-e4s-23.08/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The\
    \ Spack Infrastructure Project makes use of <a href=\"https://spack.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">spack package manager</a> to install spack software stack on\
    \ NERSC systems. This project contains spack configuration (<code>spack.yaml</code>)\
    \ required to build the spack stacks. The spack stack is based on <a href=\"https://e4s.io/\"\
    \ rel=\"nofollow\">Extreme-Scale Scientific Software Stack</a> (E4S) where we\
    \ install spack packages provided by E4S and use the recommended spack branch.\
    \ We leverage <a href=\"https://docs.gitlab.com/ee/ci/\" rel=\"nofollow\">Gitlab\
    \ CI</a> to automate deployment to ensure reproducible and automated builds. For\
    \ more details about this project you can see the documentation at <a href=\"\
    https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <h2><a id=\"user-content-software-deployment-overview\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#software-deployment-overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Software Deployment Overview</h2>\n\
    <p>The software deployment consist of the following steps</p>\n<ol>\n<li>Acquire\
    \ Spack Configuration from E4S project <a href=\"https://github.com/E4S-Project/e4s\"\
    >https://github.com/E4S-Project/e4s</a>\n</li>\n<li>Create one or more spack configuration\
    \ files (spack.yaml) with list of E4S packages and integrate spack configuration\
    \ for NERSC system</li>\n<li>Create a Gitlab Job to trigger the pipeline for TDS\
    \ and Deployment system</li>\n<li>Create a Modulefile as entry point to stack</li>\n\
    <li>Write User Documentation</li>\n<li>Share spack configuration with open-source\
    \ community</li>\n<li>Send announcement to all NERSC users</li>\n</ol>\n<h3><a\
    \ id=\"user-content-step-1-acquire-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-1-acquire-spack-configuration\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 1: Acquire Spack Configuration</h3>\n\
    <p>At NERSC, we plan our software deployment with E4S releases which is typically\
    \ every 3 months however we perform deployment every 6 months. Once E4S has released\
    \ the spack configuration we acquire the spack configuration which is typically\
    \ found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >https://github.com/E4S-Project/e4s/tree/master/environments</a>. We also acquire\
    \ the spack <a href=\"https://github.com/spack/spack/branches\">branch</a> used\
    \ by E4S team as our baseline, this would be documented in the release notes.\
    \ The name of branch map to the E4S version so version 23.05 will have a branch\
    \ <a href=\"https://github.com/spack/spack/tree/e4s-23.05\">e4s-23.05</a>.</p>\n\
    <p>Next, we copy the packages into our project and create the spack configuration</p>\n\
    <h3><a id=\"user-content-step-2-create-spack-configuration\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-2-create-spack-configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 2:\
    \ Create Spack Configuration</h3>\n<p>In this step we create the spack configuration.\
    \ First we create a sub-directory in <em>spack-configs</em> with the naming convention\
    \ to distinguish E4S version. This typically includes the\nname of the system\
    \ such as <code>cori</code> or <code>perlmutter</code> followed by name of e4s\
    \ version such as <code>e4s-23.05</code>.</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">tree -L 1 spack-configs</span>\n<span class=\"pl-c1\"\
    >spack-configs</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-20.10</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-21.02</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 cori-e4s-21.05</span>\n<span class=\"pl-c1\">\u251C\
    \u2500\u2500 cori-e4s-22.02</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-21.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.05</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\"\
    >\u251C\u2500\u2500 perlmutter-e4s-23.05</span>\n<span class=\"pl-c1\">\u251C\u2500\
    \u2500 perlmutter-spack-develop</span>\n<span class=\"pl-c1\">\u2514\u2500\u2500\
    \ perlmutter-user-spack</span>\n\n<span class=\"pl-c1\">10 directories, 0 files</span></pre></div>\n\
    <p>Inside one of the stacks, you will see several sub-directories that are used\
    \ for defining a sub-stack. These sub-stacks correspond to <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">spack environments</a>. The <code>prod</code> directory is\
    \ used for production deployment to install from the buildcache.</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">tree -L\
    \ 3 spack-configs/perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\">spack-configs/perlmutter-e4s-22.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cce</span>\n<span class=\"pl-c1\">\u2502\
    \_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500\
    \ cuda</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 definitions.yaml</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"\
    pl-c1\">\u2514\u2500\u2500 prod</span>\n<span class=\"pl-c1\">    \u251C\u2500\
    \u2500 cce</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">    \u251C\u2500\u2500 cuda</span>\n<span class=\"pl-c1\"\
    >    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\"> \
    \   \u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">    \u2514\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">        \u2514\u2500\u2500 spack.yaml</span>\n\n<span class=\"\
    pl-c1\">9 directories, 9 files</span></pre></div>\n<p>We create a special file\
    \ named <code>definitions.yaml</code> that is used for declaring definitions that\
    \ is referenced in <code>spack.yaml</code>. This file is appended to all spack\
    \ configuration. We do this\nto ensure all specs are defined in one place.</p>\n\
    <p>During this step, we will create the spack configuration and specify our preferred\
    \ compilers and package preference. We install software in buildcache so it can\
    \ be relocated to production path. In order to accomplish this task, we use <a\
    \ href=\"https://spack.readthedocs.io/en/latest/pipelines.html\" rel=\"nofollow\"\
    >spack pipelines</a> that uses <code>spack ci generate</code> and <code>spack\
    \ ci rebuild</code> to perform parallel pipeline execution. During this step,\
    \ we determine which packages to install from E4S and add our own packages to\
    \ comply with our site preference.</p>\n<h3><a id=\"user-content-step-3-create-gitlab-job-for-automation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-3-create-gitlab-job-for-automation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 3:\
    \ Create Gitlab Job for Automation</h3>\n<p>Once spack configuration is written,\
    \ we create a gitlab job to trigger the pipeline. This can be done by specifying\
    \ a job in <a href=\"https://github.com/NERSC/spack-infrastructure/blob/main/.gitlab-ci.yml\"\
    >.gitlab-ci.yml</a>.</p>\n<p>The gitlab job can be triggered through <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\" rel=\"\
    nofollow\">scheduled pipelines</a>, <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web-interface</a>, or merge request to the project. A typical\
    \ gitlab job will look something like this. Shown below is for E4S 23.05 generate\
    \ job. We make use of gitlab feature named <a href=\"https://docs.gitlab.com/ee/ci/yaml/index.html#extends\"\
    \ rel=\"nofollow\">extends</a> which allows us to reuse configuration. The <code>spack\
    \ ci generate</code> command will be the same for each substack. There is two\
    \ jobs, first is the generate step performed by <code>spack ci generate</code>\
    \ and this triggers the downstream job created by spack.</p>\n<div class=\"highlight\
    \ highlight-source-yaml\"><pre><span class=\"pl-ent\">.perlmutter-e4s-23.05-generate</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">generate</span>\n\
    \  <span class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    ]</span>\n  <span class=\"pl-ent\">tags</span>: <span class=\"pl-s\">[perlmutter-e4s]</span>\n\
    \  <span class=\"pl-ent\">interruptible</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">allow_failure</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">rules</span>:\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"schedule\" || $CI_PIPELINE_SOURCE\
    \ == \"web\") &amp;&amp; ($PIPELINE_NAME == \"PERLMUTTER_E4S_23.05\")</span>\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"merge_request_event\")</span>\n      <span class=\"pl-ent\">changes</span>:\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/$STACK_NAME/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">before_script</span>:\n    <span class=\"pl-s\">- *copy_perlmutter_settings</span>\n\
    \    <span class=\"pl-s\">- *startup_modules</span>\n  <span class=\"pl-ent\"\
    >script</span>:\n    <span class=\"pl-s\">- *e4s_23_05_setup </span>\n    - <span\
    \ class=\"pl-s\">cd $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/$STACK_NAME</span>\n\
    \    - <span class=\"pl-s\">cat $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/definitions.yaml\
    \ &gt;&gt; spack.yaml</span>\n    - <span class=\"pl-s\">spack env activate --without-view\
    \  .</span>\n    - <span class=\"pl-s\">spack env st</span>\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>- spack -d concretize -f | tee $CI_PROJECT_DIR/concretize.log\
    \    </span>\n    - <span class=\"pl-s\">spack -d ci generate --check-index-only\
    \ --artifacts-root \"$CI_PROJECT_DIR/jobs_scratch_dir\" --output-file \"${CI_PROJECT_DIR}/jobs_scratch_dir/pipeline.yml\"\
    </span>\n  <span class=\"pl-ent\">artifacts</span>: \n    <span class=\"pl-ent\"\
    >paths</span>:\n    - <span class=\"pl-s\">${CI_PROJECT_DIR}/jobs_scratch_dir</span>\n\
    \n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-generate</span>:\n  <span\
    \ class=\"pl-ent\">extends</span>: <span class=\"pl-s\">.perlmutter-e4s-23.05-generate</span>\n\
    \  <span class=\"pl-ent\">variables</span>:\n    <span class=\"pl-ent\">STACK_NAME</span>:\
    \ <span class=\"pl-s\">cce</span>\n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-build</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">build</span>\n  <span\
    \ class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    , \"perlmutter-e4s-23.05-cce-generate\"]</span>\n  <span class=\"pl-ent\">allow_failure</span>:\
    \ <span class=\"pl-c1\">true</span>\n  <span class=\"pl-ent\">rules</span>:\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"schedule\" || $CI_PIPELINE_SOURCE == \"web\") &amp;&amp; ($PIPELINE_NAME\
    \ == \"PERLMUTTER_E4S_23.05\")</span>\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"merge_request_event\")</span>\n\
    \      <span class=\"pl-ent\">changes</span>:\n      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/cce/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">trigger</span>:\n    <span class=\"pl-ent\">include</span>:\n\
    \      - <span class=\"pl-ent\">artifact</span>: <span class=\"pl-s\">jobs_scratch_dir/pipeline.yml</span>\n\
    \        <span class=\"pl-ent\">job</span>: <span class=\"pl-s\">perlmutter-e4s-23.05-cce-generate</span>\n\
    \    <span class=\"pl-ent\">strategy</span>: <span class=\"pl-s\">depend</span></pre></div>\n\
    <h3><a id=\"user-content-step-4-create-modulefile\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-4-create-modulefile\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 4: Create Modulefile</h3>\n\
    <p>In this step, we create a modulefile as entry point to software stack and setup\
    \ <code>spack</code>. We do not create spack generated modules for spack packages,\
    \ instead one is expected to use <code>spack load</code>.  Shown below are the\
    \ modulefiles available on NERSC system, they are typically called <code>e4s/&lt;version&gt;</code>\
    \ with a symbolic link to module <code>spack/e4s-&lt;version&gt;</code></p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml -t av e4s</span>\n<span\
    \ class=\"pl-c1\">/global/common/software/nersc/pm-2022.12.0/extra_modulefiles:</span>\n\
    <span class=\"pl-c1\">e4s/22.05</span>\n<span class=\"pl-c1\">e4s/22.11</span>\n\
    <span class=\"pl-c1\">spack/e4s-22.05</span>\n<span class=\"pl-c1\">spack/e4s-22.11</span></pre></div>\n\
    <p>Shown below is the content of our modulefile, the setup is subject to change</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml --raw show e4s</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">   /global/common/software/nersc/pm-2022.12.0/extra_modulefiles/e4s/22.11.lua:</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">whatis([[</span>\n<span class=\"pl-c1\">        The Extreme-scale\
    \ Scientific Software Stack (E4S) is a collection of open source software packages\
    \ for running scientific applications on high-performance computing (HPC) platforms.</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n<span class=\"pl-c1\">help([[ The Extreme-scale\
    \ Scientific Software Stack (E4S) is a community effort to provide open source\
    \ software packages for developing, deploying and running scientific applications\
    \ on high-performance computing (HPC) platforms. E4S provides from-source builds\
    \ and containers of a broad collection of HPC software packages.</span>\n\n<span\
    \ class=\"pl-c1\">References:</span>\n<span class=\"pl-c1\">  - E4S User Docs:\
    \ https://e4s.readthedocs.io/en/latest/index.html</span>\n<span class=\"pl-c1\"\
    >  - E4S 22.11 Docs: https://docs.nersc.gov/applications/e4s/perlmutter/22.11/</span>\n\
    <span class=\"pl-c1\">  - E4S Homepage: https://e4s-project.github.io/</span>\n\
    <span class=\"pl-c1\">  - E4S GitHub: https://github.com/E4S-Project/e4s</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n\n<span class=\"pl-c1\">local root =\
    \ \"/global/common/software/spackecp/perlmutter/e4s-22.11/default/spack\"</span>\n\
    \n<span class=\"pl-c1\">setenv(\"SPACK_GNUPGHOME\", pathJoin(os.getenv(\"HOME\"\
    ), \".gnupg\"))</span>\n<span class=\"pl-c1\">setenv(\"SPACK_SYSTEM_CONFIG_PATH\"\
    , \"/global/common/software/spackecp/perlmutter/spack_settings\")</span>\n<span\
    \ class=\"pl-c1\">-- setup spack shell functionality</span>\n<span class=\"pl-c1\"\
    >local shell = myShellType()</span>\n<span class=\"pl-c1\">if (mode() == \"load\"\
    ) then</span>\n<span class=\"pl-c1\">    local spack_setup = ''</span>\n<span\
    \ class=\"pl-c1\">    if (shell == \"sh\" or shell == \"bash\" or shell == \"\
    zsh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.sh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"csh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.csh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"fish\")  then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.fish\")</span>\n<span class=\"pl-c1\">    end</span>\n\
    \n<span class=\"pl-c1\">    -- If we are unable to find spack setup script let's\
    \ terminate now.</span>\n<span class=\"pl-c1\">    if not isFile(spack_setup)\
    \ then</span>\n<span class=\"pl-c1\">        LmodError(\"Unable to find spack\
    \ setup script \" .. spack_setup .. \"\\n\")</span>\n<span class=\"pl-c1\">  \
    \  end</span>\n\n<span class=\"pl-c1\">    execute{cmd=\"source \" .. spack_setup,\
    \ modeA={\"load\"}}</span>\n\n<span class=\"pl-c1\">    LmodMessage([[</span>\n\
    <span class=\"pl-c1\">    _______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">     The Extreme-Scale Scientific Software Stack (E4S) is\
    \ accessible via the Spack package manager.</span>\n\n<span class=\"pl-c1\"> \
    \    In order to access the production stack, you will need to load a spack environment.\
    \ Here are some tips to get started:</span>\n\n\n<span class=\"pl-c1\">     'spack\
    \ env list' - List all Spack environments</span>\n<span class=\"pl-c1\">     'spack\
    \ env activate gcc' - Activate the \"gcc\" Spack environment</span>\n<span class=\"\
    pl-c1\">     'spack env status' - Display the active Spack environment</span>\n\
    <span class=\"pl-c1\">     'spack load amrex' - Load the \"amrex\" Spack package\
    \ into your user environment</span>\n\n<span class=\"pl-c1\">     For additional\
    \ support, please refer to the following references:</span>\n\n<span class=\"\
    pl-c1\">       NERSC E4S Documentation: https://docs.nersc.gov/applications/e4s/</span>\n\
    <span class=\"pl-c1\">       E4S Documentation: https://e4s.readthedocs.io</span>\n\
    <span class=\"pl-c1\">       Spack Documentation: https://spack.readthedocs.io/en/latest/</span>\n\
    <span class=\"pl-c1\">       Spack Slack: https://spackpm.slack.com</span>\n\n\
    <span class=\"pl-c1\">    ______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">    ]])</span>\n<span class=\"pl-c1\">-- To remove spack\
    \ from shell we need to remove a few environment variables, alias and remove $SPACK_ROOT/bin\
    \ from $PATH</span>\n<span class=\"pl-c1\">elseif (mode() == \"unload\" or mode()\
    \ == \"purge\") then</span>\n<span class=\"pl-c1\">    if (shell == \"sh\" or\
    \ shell == \"bash\" or shell == \"zsh\") then</span>\n<span class=\"pl-c1\"> \
    \     execute{cmd=\"unset SPACK_ENV\",modeA={\"unload\"}}</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unset SPACK_ROOT\",modeA={\"unload\"}}</span>\n<span\
    \ class=\"pl-c1\">      execute{cmd=\"unset -f spack\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">    elseif (shell == \"csh\") then</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unsetenv SPACK_ENV\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">      execute{cmd=\"unsetenv SPACK_ROOT\",modeA={\"unload\"\
    }}</span>\n<span class=\"pl-c1\">      execute{cmd=\"unalias spack\",modeA={\"\
    unload\"}}</span>\n<span class=\"pl-c1\">    end</span>\n\n<span class=\"pl-c1\"\
    >    -- Need to remove $SPACK_ROOT/bin from $PATH which removes the 'spack' command</span>\n\
    <span class=\"pl-c1\">    remove_path(\"PATH\", pathJoin(root, \"bin\"))</span>\n\
    \n<span class=\"pl-c1\">    -- Remove alias spacktivate. Need to pipe to /dev/null\
    \ as invalid alias can report error to stderr</span>\n<span class=\"pl-c1\"> \
    \   execute{cmd=\"unalias spacktivate &gt; /dev/null\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">end</span></pre></div>\n<h3><a id=\"user-content-step-5-user-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-5-user-documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 5:\
    \ User Documentation</h3>\n<p>User documentation is fundamental to help assist\
    \ users with using E4S at NERSC. We document every E4S release with its <em>Release\
    \ Date</em> and <em>End of Support</em> date along with a documentation page outlining\
    \ the software stack. Our E4S documentation is available at <a href=\"https://docs.nersc.gov/applications/e4s/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/</a>. The release date\
    \ is when documentation is live. We perform this action in conjunction with release\
    \ of modulefile so that user gain access to software stack.</p>\n<p>Upon completion\
    \ of this task, we are ready to make announcement to our NERSC users</p>\n<h3><a\
    \ id=\"user-content-step-6-sharing-spack-configuration-with-open-source-community\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-6-sharing-spack-configuration-with-open-source-community\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 6:\
    \ Sharing spack configuration with open-source community</h3>\n<p>In this step,\
    \ we share our spack configuration with open-source community that may benefit\
    \ the wider community. We share our spack configuration at <a href=\"https://github.com/spack/spack-configs\"\
    >https://github.com/spack/spack-configs</a>. In addition, we update the <a href=\"\
    https://e4s.readthedocs.io/en/latest/facility_e4s.html\" rel=\"nofollow\">E4S\
    \ Facility Dashboard</a> that shows all the E4S deployments across all the facilities.</p>\n\
    <h3><a id=\"user-content-step-7-public-announcement\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-7-public-announcement\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 7: Public Announcement</h3>\n\
    <p>This is the final step of the deployment process, where we make a public announcement\
    \ in NERSC weekly email, along with various slack channels such as Nersc User\
    \ Group (NUG), Spack, ECP and E4S slack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#current-challenges\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Current\
    \ Challenges</h2>\n<p>There are several challenges with building spack stack at\
    \ NERSC which can be summarized as follows</p>\n<ul>\n<li>\n<p><strong>System\
    \ OS + Cray Programming Environment (CPE) changes</strong>: A system upgrade such\
    \ as change to <code>glibc</code> or upgrades in CPE can lead to full software\
    \ stack rebuild, especially if you have external packages set for packages like\
    \ <code>cray-mpich</code>, <code>cray-libsci</code> which generally change between\
    \ versions</p>\n</li>\n<li>\n<p><strong>Incompatibile compilers</strong>: Some\
    \ packages can't be built with certain compilers (<code>nvhpc</code>, <code>aocc</code>)\
    \ which could be due to several factors.</p>\n<ul>\n<li>An application doesn't\
    \ have support though it was be added in newer version but you don't have it in\
    \ your spack release used for deployment</li>\n<li>Lack of support in spack package\
    \ recipe or spack-core base including spack-cray detection. This may require getting\
    \ fix and cherry-pick commit or waiting for new version</li>\n<li>Spack Cray detection\
    \ is an important part in build errors including how one specifies externals via\
    \ <code>modules</code> vs <code>prefix</code> both could be provided and it requires\
    \ experimentation. An example of this is trying to get <code>cray-mpich</code>\
    \ external one could set something like this with modules or prefix</li>\n</ul>\n\
    <div class=\"highlight highlight-source-yaml\"><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n\
    \    <span class=\"pl-ent\">buildable</span>: <span class=\"pl-c1\">false</span>\n\
    \    <span class=\"pl-ent\">externals</span>:\n    - <span class=\"pl-ent\">spec</span>:\
    \ <span class=\"pl-s\">cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"\
    pl-ent\">prefix</span>: <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n\
    \      <span class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<p>If you need elevated privledge or assistance with\
    \ this project please contact one of the maintainers:</p>\n<ul>\n<li>Shahzeb Siddiqui\
    \ - <a href=\"mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>\n</li>\n\
    <li>Erik Palmer - <a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>\n</li>\n\
    <li>Justin Cook - <a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>\n</li>\n\
    <li>E4S Team: Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\">sameer@cs.uoregon.edu</a>),\
    \ Christopher Peyralans (<a href=\"mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>),\
    \ Wyatt Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>),\
    \ Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</li>\n\
    </ul>\n"
  stargazers_count: 8
  subscribers_count: 14
  topics: []
  updated_at: 1673545287.0
NERSC/timemory:
  data_format: 2
  description: 'Modular C++ Toolkit for Performance Analysis and Logging. Profiling
    API and Tools for C, C++, CUDA, Fortran, and Python. The C++ template API is essentially
    a framework to creating tools: it is designed to provide a unifying interface
    for recording various performance measurements alongside data logging and interfaces
    to other tools.'
  filenames:
  - docker/cpu/spack.yaml
  full_name: NERSC/timemory
  latest_release: v3.2.3
  readme: "<h1><a id=\"user-content-timemory\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#timemory\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>timemory</h1>\n<h2><a id=\"user-content-timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Timing +\
    \ Memory + Hardware Counter Utilities for C / C++ / CUDA / Python</h2>\n<p><a\
    \ href=\"https://travis-ci.org/NERSC/timemory\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9505e1c9d1da422846396830ac218c61bb3343ebe5402ffb3b05b52558266d67/68747470733a2f2f7472617669732d63692e6f72672f4e455253432f74696d656d6f72792e7376673f6272616e63683d6d6173746572\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/NERSC/timemory.svg?branch=master\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/jrmadsen/timemory/branch/master\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4a833ca1c608ec560c59f2db36c4ea6c9c466102cba6505d53e6fcd6deaa3d7c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38786b37326f6f7477736566693863312f6272616e63682f6d61737465723f7376673d74727565\"\
    \ alt=\"Build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/8xk72ootwsefi8c1/branch/master?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/NERSC/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/87983d45b3e2381d7edd4ba6c892d41b4aeddd939663bcf2fb8cc60d29d4496f/68747470733a2f2f636f6465636f762e696f2f67682f4e455253432f74696d656d6f72792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/NERSC/timemory/branch/master/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/NERSC/timemory\"\
    >timemory on GitHub (Source code)</a></p>\n<p><a href=\"https://timemory.readthedocs.io\"\
    \ rel=\"nofollow\">timemory General Documentation (ReadTheDocs)</a></p>\n<p><a\
    \ href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\
    >timemory Source Code Documentation (Doxygen)</a></p>\n<p><a href=\"https://cdash.nersc.gov/index.php?project=TiMemory\"\
    \ rel=\"nofollow\">timemory Testing Dashboard (CDash)</a></p>\n<p><a href=\"https://github.com/NERSC/timemory-tutorials\"\
    >timemory Tutorials</a></p>\n<ul>\n<li>\n<p><a href=\"https://www.youtube.com/watch?v=K1Pazcw7zVo\"\
    \ rel=\"nofollow\">ECP 2021 Tutorial Day 1 (YouTube)</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://www.youtube.com/watch?v=-zIpZDiwrmI\" rel=\"nofollow\">ECP 2021\
    \ Tutorial Day 2 (YouTube)</a></p>\n</li>\n</ul>\n<p><a href=\"https://github.com/NERSC/timemory/wiki\"\
    >timemory Wiki</a></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>GitHub</td>\n<td><code>git clone https://github.com/NERSC/timemory.git</code></td>\n\
    </tr>\n<tr>\n<td>PyPi</td>\n<td><code>pip install timemory</code></td>\n</tr>\n\
    <tr>\n<td>Spack</td>\n<td><code>spack install timemory</code></td>\n</tr>\n<tr>\n\
    <td>conda-forge</td>\n<td><code>conda install -c conda-forge timemory</code></td>\n\
    </tr>\n<tr>\n<td></td>\n<td><a href=\"https://anaconda.org/conda-forge/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/33319eee64e9e77e6164e27e48c8d3e752580de537246f0108c2613a392c44d2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265636970652d74696d656d6f72792d677265656e2e737667\"\
    \ alt=\"Conda Recipe\" data-canonical-src=\"https://img.shields.io/badge/recipe-timemory-green.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/a9c6e0aeed14f60203f554ea93bf6b34a4c8f041c16d2e88bc3e2ab2c0e786bd/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/336c5f6fee8494649e0e14802c2fa61d049a0fc4d3c424a9b8f0626aa4b27f78/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/4db6b05734f08002f400c6aaefe6579f74282758c11efbe421981e8200bd2c6d/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f706e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/conda/pn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"></a></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-purpose\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #purpose\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Purpose</h2>\n\
    <p>The goal of timemory is to create an open-source performance measurement and\
    \ analyis package\nwith modular and reusable components which can be used to adapt\
    \ to any existing C/C++\nperformance measurement and analysis API and is arbitrarily\
    \ extendable by users within their\napplication.\nTimemory is not just another\
    \ profiling tool, it is a profling <em>toolkit</em> which streamlines building\
    \ custom\nprofiling tools through modularity and then utilizes the toolkit to\
    \ provides several pre-built tools.</p>\n<p>In other words, timemory provides\
    \ many pre-built tools, libraries, and interfaces but, due to it's modularity,\n\
    codes can re-use only individual pieces -- such as the classes for measuring different\
    \ timing intervals, memory usage,\nand hardware counters -- without the timemory\
    \ \"runtime management\".</p>\n<h2><a id=\"user-content-building-and-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-and-installing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ and Installing</h2>\n<p>Timemory uses a standard CMake installation.\nSeveral\
    \ installation examples can be found in the <a href=\"https://github.com/NERSC/timemory/wiki/Installation-Examples\"\
    >Wiki</a>. See the <a href=\"https://timemory.readthedocs.io/en/develop/installation.html\"\
    \ rel=\"nofollow\">installation documentation</a> for detailed information on\
    \ the CMake options.</p>\n<h2><a id=\"user-content-documentation\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p>The full\
    \ documentation is available at <a href=\"https://timemory.readthedocs.io\" rel=\"\
    nofollow\">timemory.readthedocs.io</a>.\nDetailed source documentation is provided\
    \ in the <a href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"\
    nofollow\">doygen</a>\nsection of the full documentation.\nTutorials are available\
    \ in the <a href=\"https://github.com/NERSC/timemory-tutorials\">github.com/NERSC/timemory-tutorials</a>.</p>\n\
    <h2><a id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#overview\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Overview</h2>\n<p><strong><em>The primary objective of the timemory\
    \ is the development of a common framework for binding together software\nmonitoring\
    \ code (i.e. performance analysis, debugging, logging) into a compact and highly-efficient\
    \ interface.</em></strong></p>\n<p>Timemory arose out of the need for a universal\
    \ adapator kit for the various APIs provided several existing tools\nand a straight-forward\
    \ and intuitive method for creating new tools. Timemory makes it possible to bundle\n\
    together deterministic performance measurements, statistical performance\nmeasurements\
    \ (i.e. sampling), debug messages, data logging, and data validation into the\
    \ same interface for\ncustom application-specific software monitoring interfaces,\
    \ easily building tools like <code>time</code>,\n<code>netstat</code>, instrumentation\
    \ profilers, sampling profilers, and writing implementations for MPI-P, MPI-T,\
    \ OMPT,\nKokkosP, etc. Furthermore, timemory can forward its markers to several\
    \ third-party profilers such as\n<a href=\"https://github.com/RRZE-HPC/likwid\"\
    >LIKWID</a>, <a href=\"https://github.com/LLNL/Caliper\">Caliper</a>,\n<a href=\"\
    https://www.cs.uoregon.edu/research/tau/home.php\" rel=\"nofollow\">TAU</a>, <a\
    \ href=\"https://github.com/gperftools/gperftools\">gperftools</a>,\n<a href=\"\
    https://perfetto.dev/docs/\" rel=\"nofollow\">Perfetto</a>, VTune, Allinea-MAP,\
    \ CrayPAT, Nsight-Systems, Nsight-Compute, and NVProf.</p>\n<p>Timemory provides\
    \ a front-end <a href=\"https://timemory.readthedocs.io/en/develop/api/library.html\"\
    \ rel=\"nofollow\">C/C++/Fortran API</a>\nand <a href=\"https://timemory.readthedocs.io/en/develop/api/python.html\"\
    \ rel=\"nofollow\">Python API</a> which allows arbitrary selection\nof 50+ different\
    \ components from timers to hardware counters to interfaces with third-party tools.\
    \ This is all\nbuilt generically from the toolkit API with type-safe bundles of\
    \ tools such as:\n<code>component_tuple&lt;wall_clock, papi_vector, nvtx_marker,\
    \ user_bundle&gt;</code>\nwhere <code>wall_clock</code> is a wall-clock timer,\n\
    <code>papi_vector</code> is a handle for hardware counters,\n<code>nvxt_marker</code>\
    \ creates notations in the NVIDIA CUDA profilers, and\n<code>user_bundle</code>\
    \ is a generic component which downstream users can insert more components into\
    \ at runtime.</p>\n<p>Performance measurement components written with timemory\
    \ are arbitrarily scalable up to any number of threads and\nprocesses and fully\
    \ support intermixing different measurements at different locations within the\
    \ program -- this\nuniquely enables timemory to be deployed to collect performance\
    \ data at scale in HPC because highly detailed collection can\noccur at specific\
    \ locations within the program where ubiquitous collection would simulatenously\
    \ degrade performance\nsignificantly and require a prohibitive amount of memory.</p>\n\
    <p>Timemory can be used as a backend to bundle instrumentation and sampling tools\
    \ together, support serialization to JSON/XML,\nand provide statistics among other\
    \ uses. It can also be utilized as a front-end to invoke\ncustom instrumentation\
    \ and sampling tools. Timemory uses the abstract term \"component\" for a structure\n\
    which encapsulates some performance analysis operation. The structure might encapsulate\
    \ function\ncalls to another tool, record timestamps for timing, log values provided\
    \ by the application,\nprovide a operator for replacing a function in the code\
    \ dynamically, audit the incoming arguments\nand/or outgoing return value from\
    \ function, or just provide stubs which can be overloaded by the linker.</p>\n\
    <h3><a id=\"user-content-visualization-and-analysis\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#visualization-and-analysis\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Visualization and Analysis</h3>\n\
    <p>The native output format of timemory is JSON and text; other output formats\
    \ such as XML are also supported.\nThe text format is intended to be human readable.\
    \ The JSON data\nis intended for analysis and comes in two flavors: hierarchical\
    \ and flat. Basic plotting capabilities are\navailable via <code>timemory-plotting</code>\
    \ but users are highly encouraged to use <a href=\"https://github.com/hatchet/hatchet\"\
    >hatchet</a>\nfor analyzing the heirarchical JSON data in pandas dataframes. <a\
    \ href=\"https://github.com/hatchet/hatchet\">Hatchet</a> supports\nfiltering,\
    \ unions, addition, subtractions, output to <code>dot</code> and flamegraph formats,\
    \ and an interactive Jupyter notebook.\nAt present, timemory supports 45+ metric\
    \ types for analysis in Hatchet.</p>\n<h3><a id=\"user-content-categories\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#categories\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Categories</h3>\n<p>There are\
    \ 4 primary categories in timemory: components, operations, bundlers, and storage.\
    \ Components provide\nthe specifics of how to perform a particular behavior, operations\
    \ provide the scaffold for requesting that\na component perform an operation in\
    \ complex scenarios, bundlers group components into a single generic handle,\n\
    and storage manages data collection over the lifetime of the application. When\
    \ all four categories are combined,\ntimemory effectively resembles a standard\
    \ performance analysis tool which passively collects data and provides\nreports\
    \ and analysis at the termination of the application. Timemory, however, makes\
    \ it <em>very easy</em> to subtract\nstorage from the equation and, in doing so,\
    \ transforms timemory into a toolkit for customized data collection.</p>\n<ol>\n\
    <li>\n<strong><em>Components</em></strong>\n<ul>\n<li>Individual classes which\
    \ encapsulate one or more measurement, analysis, logging, or third-party library\
    \ action(s)</li>\n<li>Any data specific to one instance of performing the action\
    \ is stored within the instance of the class</li>\n<li>Any configuration data\
    \ specific to that type is typically stored within static member functions which\
    \ return a reference to the configuration data</li>\n<li>These classes are designed\
    \ to support direct usage within other tools, libraries, etc.</li>\n<li>Examples\
    \ include:\n<ul>\n<li>\n<code>tim::component::wall_clock</code> : a simple wall-clock\
    \ timer</li>\n<li>\n<code>tim::component::vtune_profiler</code> : a simple component\
    \ which turns the VTune Profiler on and off (when VTune is actively profiling\
    \ application)</li>\n<li>\n<code>tim::component::data_tracker_integer</code> :\
    \ associates an integer values with a label as the application executes (e.g.\
    \ number of loop iterations used somewhere)</li>\n<li>\n<code>tim::component::papi_vector</code>\
    \ : uses the PAPI library to collect hardware-counters values</li>\n<li>\n<code>tim::component::user_bundle</code>\
    \ : encapsulates an array of components which the user can dynamically manipulate\
    \ during runtime</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Operations</em></strong>\n\
    <ul>\n<li>Templated classes whose primary purpose is to provide the implementation\
    \ for performing some action on a component, e.g. <code>tim::operation::start&lt;wall_clock&gt;</code>\
    \ will attempt to call the <code>start()</code> member function on a <code>wall_clock</code>\
    \ component instance</li>\n<li>Default implementations generally have one or two\
    \ public functions: a constructor and/or a function call operator\n<ul>\n<li>These\
    \ generally accept any/all arguments and use SFINAE to determine whether the operation\
    \ can be performed with or without the given arguments (i.e. does <code>wall_clock</code>\
    \ have a <code>store(int)</code> function? <code>store()</code>?)</li>\n</ul>\n\
    </li>\n<li>Operations are (generally) not directly utilized by the user and are\
    \ typically optimized out of the binary</li>\n<li>Examples include:\n<ul>\n<li>\n\
    <code>tim::operation::start</code> : instruct a component to start collection</li>\n\
    <li>\n<code>tim::operation::sample</code> : instruct a component to take individual\
    \ measurement</li>\n<li>\n<code>tim::operation::derive</code> : extra data from\
    \ other components if it is available</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n\
    <strong><em>Bundlers</em></strong>\n<ul>\n<li>Provide a generic handle for multiple\
    \ components</li>\n<li>Member functions generally accept any/all arguments and\
    \ use operations classes to correctly to handle differences between different\
    \ capabilities of the components it is bundling</li>\n<li>Examples include:\n\
    <ul>\n<li><code>tim::auto_tuple</code></li>\n<li><code>tim::component_tuple</code></li>\n\
    <li><code>tim::component_list</code></li>\n<li><code>tim::lightweight_tuple</code></li>\n\
    </ul>\n</li>\n<li>Various flavors provide different implicit behaviors and allocate\
    \ memory differently\n<ul>\n<li>\n<code>auto_tuple</code> starts all components\
    \ when constructed and stops all components when destructed whereas <code>component_tuple</code>\
    \ requires an explicit start</li>\n<li>\n<code>component_tuple</code> allocates\
    \ all components on the stack and components are \"always on\" whereas <code>component_list</code>\
    \ allocates components on the heap and thus components can be activated/deactivated\
    \ at runtime</li>\n<li>\n<code>lightweight_tuple</code> does not implicitly perform\
    \ any expensive actions, such as call-stack tracking in \"Storage\"</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>\n<strong><em>Storage</em></strong>\n<ul>\n<li>Provides\
    \ persistent storage for multiple instances of components over the lifetime of\
    \ a thread in the application</li>\n<li>Responsible for maintaining the hierarchy\
    \ and order of component measurements, i.e. call-stack tracking</li>\n<li>Responsible\
    \ for combining component data from multiple threads and/or processes and outputting\
    \ the results</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: <code>tim::lightweight_tuple</code>\
    \ is the recommended bundle for those seeking to use timemory as a toolkit for\
    \ implementing custom tools and interfaces</p>\n</blockquote>\n<h2><a id=\"user-content-features\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#features\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Features</h2>\n\
    <ul>\n<li>C++ Template API\n<ul>\n<li>Modular and fully-customizable</li>\n<li>Adheres\
    \ to C++ standard template library paradigm of \"you don't pay for what you don't\
    \ use\"</li>\n<li>Simplifies and facilitates creation and implementation of performance\
    \ measurement tools\n<ul>\n<li>Create your own instrumentation profiler</li>\n\
    <li>Create your own instrumentation library</li>\n<li>Create your own sampling\
    \ profiler</li>\n<li>Create your own sampling library</li>\n<li>Create your own\
    \ execution wrappers</li>\n<li>Supplement timemory-provided tools with your own\
    \ custom component(s)</li>\n<li>Thread-safe data aggregation</li>\n<li>Aggregate\
    \ collection over multiple processes (MPI and UPC++ support)</li>\n<li>Serialization\
    \ to text, JSON, XML</li>\n</ul>\n</li>\n<li>Components are composable with other\
    \ components</li>\n<li>Variadic component bundlers which maintain complete type-safety\n\
    <ul>\n<li>Components can be bundled together into a single handle without abstractions</li>\n\
    </ul>\n</li>\n<li>Components can store data in any valid C++ data type</li>\n\
    <li>Components can return data in any valid C++ data type</li>\n</ul>\n</li>\n\
    <li>C / C++ / CUDA / Fortran Library API\n<ul>\n<li>Straight-forward collection\
    \ of functions and macros for creating built-in performance analysis to your code</li>\n\
    <li>Component collection can be arbitrarily inter-mixed\n<ul>\n<li>E.g. collect\
    \ \"A\" and \"B\" in one region, \"A\" and \"C\" in another region</li>\n</ul>\n\
    </li>\n<li>Component collection can be dynamically manipulated at runtime\n<ul>\n\
    <li>E.g. add/remove \"A\" at any point, on any thread, on any process</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>Python API\n<ul>\n<li>Decorators and context-managers\
    \ for functions or regions in code</li>\n<li>Python function profiling</li>\n\
    <li>Python line-by-line profiling</li>\n<li>Every component in <code>timemory-avail</code>\
    \ is provided as a stand-alone Python class\n<ul>\n<li>Provide low-overhead measurements\
    \ for building your own Python profiling tools</li>\n</ul>\n</li>\n</ul>\n</li>\n\
    <li>Python Analysis via <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\"\
    >pandas</a>\n</li>\n<li>Command-line Tools\n<ul>\n<li>\n<a href=\"source/tools/timemory-avail/README.md\"\
    >timemory-avail</a>\n<ul>\n<li>Provides available components, settings, and hardware\
    \ counters</li>\n<li>Quick API reference tool</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timem/README.md\">timem</a> (UNIX)\n<ul>\n<li>Extended version of\
    \ UNIX <code>time</code> command-line tool that includes additional information\
    \ on memory usage, context switches, and hardware counters</li>\n<li>Support collecting\
    \ hardware counters (Linux-only, requires PAPI)</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timemory-run/README.md\">timemory-run</a> (Linux)\n<ul>\n<li>Dynamic\
    \ instrumentation profiling tool</li>\n<li>Supports runtime instrumentation and\
    \ binary re-writing</li>\n</ul>\n</li>\n<li>\n<a href=\"source/tools/timemory-nvml/README.md\"\
    >timemory-nvml</a>\n<ul>\n<li>Data collection similar to <code>nvidia-smi</code>\n\
    </li>\n</ul>\n</li>\n<li>\n<code>timemory-python-profiler</code>\n<ul>\n<li>Python\
    \ function profiler supporting all timemory components</li>\n<li><code>from timemory.profiler\
    \ import Profile</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-trace</code>\n\
    <ul>\n<li>Python line-by-line profiler supporting all timemory components</li>\n\
    <li><code>from timemory.trace import Trace</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-line-profiler</code>\n\
    <ul>\n<li>Python line-by-line profiler based on <a href=\"https://pypi.org/project/line-profiler/\"\
    \ rel=\"nofollow\">line-profiler</a> package</li>\n<li>Extended to use components:\
    \ cpu-clock, memory-usage, context-switches, etc. (all components which collect\
    \ scalar values)</li>\n<li><code>from timemory.line_profiler import LineProfiler</code></li>\n\
    </ul>\n</li>\n</ul>\n</li>\n<li>Instrumentation Libraries\n<ul>\n<li>\n<a href=\"\
    source/tools/timemory-mpip/README.md\">timemory-mpip</a>: MPI Profiling Library\
    \ (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ncclp/README.md\">timemory-ncclp</a>:\
    \ NCCL Profiling Library (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ompt/README.md\"\
    >timemory-ompt</a>: OpenMP Profiling Library</li>\n<li>\n<a href=\"source/tools/timemory-compiler-instrument/README.md\"\
    >timemory-compiler-instrument</a>: Compiler instrumentation Library</li>\n<li>\n\
    <a href=\"source/tools/kokkos-connector/README.md\">kokkos-connector</a>: Kokkos\
    \ Profiling Libraries</li>\n</ul>\n</li>\n</ul>\n<h2><a id=\"user-content-samples\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#samples\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Samples</h2>\n\
    <p>Various macros are defined for C in <a href=\"source/timemory/timemory.h\"\
    >source/timemory/compat/timemory_c.h</a>\nand <a href=\"source/timemory/variadic/macros.hpp\"\
    >source/timemory/variadic/macros.hpp</a>. Numerous samples of\ntheir usage can\
    \ be found in the examples.</p>\n<h3><a id=\"user-content-sample-c-template-api\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#sample-c-template-api\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Sample C++\
    \ Template API</h3>\n<div class=\"highlight highlight-source-c++\"><pre>#<span\
    \ class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>timemory/timemory.hpp<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"\
    pl-k\">namespace</span> <span class=\"pl-en\">comp</span> <span class=\"pl-k\"\
    >=</span> tim::component;\n<span class=\"pl-k\">using</span> <span class=\"pl-k\"\
    >namespace</span> <span class=\"pl-en\">tim</span><span class=\"pl-k\">;</span>\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">//</span> specific set of components</span>\n\
    <span class=\"pl-k\">using</span> <span class=\"pl-c1\">specific_t</span> = component_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;;\n<span class=\"pl-k\">using</span> <span class=\"pl-c1\"\
    >generic_t</span>  = component_tuple&lt;comp::user_global_bundle&gt;;\n\n<span\
    \ class=\"pl-k\">int</span>\n<span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span>** argv)\n{\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> configure default settings</span>\n\
    \    <span class=\"pl-c1\">settings::flat_profile</span>() = <span class=\"pl-c1\"\
    >true</span>;\n    <span class=\"pl-c1\">settings::timing_units</span>() = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span class=\"pl-pds\">\"\
    </span></span>;\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> initialize\
    \ with cmd-line</span>\n    <span class=\"pl-c1\">timemory_init</span>(argc, argv);\n\
    \    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> add argparse support</span>\n\
    \    <span class=\"pl-c1\">timemory_argparse</span>(&amp;argc, &amp;argv);\n\n\
    \    <span class=\"pl-c\"><span class=\"pl-c\">//</span> create a region \"main\"\
    </span>\n    <span class=\"pl-c1\">specific_t</span> m{ <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span> };\n \
    \   m.<span class=\"pl-c1\">start</span>();\n    m.<span class=\"pl-c1\">stop</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">settings::enabled</span>() = <span\
    \ class=\"pl-c1\">false</span>;\n    <span class=\"pl-c1\">specific_t</span> h{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden<span class=\"pl-pds\"\
    >\"</span></span> };\n    h.<span class=\"pl-c1\">start</span>().<span class=\"\
    pl-c1\">stop</span>();\n    <span class=\"pl-c1\">settings::enabled</span>() =\
    \ <span class=\"pl-c1\">true</span>;\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Add peak_rss component to specific_t</span>\n    mpl::<span class=\"\
    pl-c1\">push_back_t</span>&lt;<span class=\"pl-c1\">specific_t</span>, comp::peak_rss&gt;\
    \ wprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>with peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n    \n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> create region collecting only peak_rss</span>\n    component_tuple&lt;comp::peak_rss&gt;\
    \ oprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>only peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> convert component_tuple to a type that starts/stops upon construction/destruction</span>\n\
    \    {\n        scope::config _scope{};\n        <span class=\"pl-k\">if</span>(<span\
    \ class=\"pl-c1\">true</span>)  _scope += scope::flat{};\n        <span class=\"\
    pl-k\">if</span>(<span class=\"pl-c1\">false</span>) _scope += scope::timeline{};\n\
    \        <span class=\"pl-c1\">convert_t</span>&lt;<span class=\"pl-c1\">specific_t</span>,\
    \ auto_tuple&lt;&gt;&gt; scoped{ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>scoped start/stop + flat<span class=\"pl-pds\">\"</span></span>, _scope\
    \ };\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> will yield auto_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;</span>\n    }\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of strings</span>\n    runtime::configure&lt;comp::user_global_bundle&gt;({\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> });\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of enumeration ids</span>\n\
    \    runtime::configure&lt;comp::user_global_bundle&gt;({ TIMEMORY_WALL_CLOCK,\
    \ TIMEMORY_CPU_CLOCK });\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ configure the generic bundle via component instances</span>\n    comp::user_global_bundle::configure&lt;comp::page_rss,\
    \ comp::papi_vector&gt;();\n    \n    <span class=\"pl-c1\">generic_t</span> g{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>generic<span class=\"pl-pds\"\
    >\"</span></span>, quirk::config&lt;quirk::auto_start&gt;{} };\n    g.<span class=\"\
    pl-c1\">stop</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3><a id=\"user-content-sample-c--c-library-api\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sample-c--c-library-api\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Sample C / C++ Library API</h3>\n\
    <div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/library.h<span\
    \ class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/timemory.h<span class=\"\
    pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">int</span>\n<span class=\"pl-en\"\
    >main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span>**\
    \ argv)\n{\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> configure\
    \ settings</span>\n    <span class=\"pl-k\">int</span> overwrite       = <span\
    \ class=\"pl-c1\">0</span>;\n    <span class=\"pl-k\">int</span> update_settings\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> default to flat-profile</span>\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_FLAT_PROFILE<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> force timing units</span>\n    overwrite\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_TIMING_UNITS<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> initialize with cmd-line</span>\n\
    \    <span class=\"pl-c1\">timemory_init_library</span>(argc, argv);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> check if inited, init with name</span>\n\
    \    <span class=\"pl-k\">if</span>(!<span class=\"pl-c1\">timemory_library_is_initialized</span>())\n\
    \        <span class=\"pl-c1\">timemory_named_init_library</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>ex-c<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> define the default set\
    \ of components</span>\n    <span class=\"pl-c1\">timemory_set_default</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock, cpu_clock<span class=\"\
    pl-pds\">\"</span></span>);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ create a region \"main\"</span>\n    <span class=\"pl-c1\">timemory_push_region</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>);\n    <span class=\"pl-c1\">timemory_pop_region</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">timemory_pause</span>();\n    <span\
    \ class=\"pl-c1\">timemory_push_region</span>(<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_pop_region</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_resume</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> Add/remove component(s) to the current set of components</span>\n \
    \   <span class=\"pl-c1\">timemory_add_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_remove_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> get an identifier for\
    \ a region and end it</span>\n    <span class=\"pl-c1\">uint64_t</span> idx =\
    \ <span class=\"pl-c1\">timemory_get_begin_record</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> assign an existing identifier for a region</span>\n\
    \    <span class=\"pl-c1\">timemory_begin_record</span>(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>indexed/2<span class=\"pl-pds\">\"</span></span>,\
    \ &amp;idx);\n    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n \
    \   <span class=\"pl-c\"><span class=\"pl-c\">//</span> create region collecting\
    \ a specific set of data</span>\n    <span class=\"pl-c1\">timemory_begin_record_enum</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>enum<span class=\"pl-pds\">\"\
    </span></span>, &amp;idx, TIMEMORY_PEAK_RSS, TIMEMORY_COMPONENTS_END);\n    <span\
    \ class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"pl-c1\"\
    >timemory_begin_record_types</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>types<span class=\"pl-pds\">\"</span></span>, &amp;idx, <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> replace current set of components and then\
    \ restore previous set</span>\n    <span class=\"pl-c1\">timemory_push_components</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\"\
    >\"</span></span>);\n    <span class=\"pl-c1\">timemory_pop_components</span>();\n\
    \n    <span class=\"pl-c1\">timemory_push_components_enum</span>(<span class=\"\
    pl-c1\">2</span>, TIMEMORY_WALL_CLOCK, TIMEMORY_CPU_CLOCK);\n    <span class=\"\
    pl-c1\">timemory_pop_components</span>();\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize_library</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3><a id=\"user-content-sample-fortran-api\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sample-fortran-api\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Sample Fortran API</h3>\n<div class=\"\
    highlight highlight-source-fortran\"><pre><span class=\"pl-k\">program</span>\
    \ fortran_example\n    use timemory\n    use iso_c_binding, only : C_INT64_T\n\
    \    <span class=\"pl-k\">implicit none</span>\n    <span class=\"pl-k\">integer</span>(C_INT64_T)\
    \ <span class=\"pl-k\">::</span> idx\n\n    ! initialize with explicit name\n\
    \    <span class=\"pl-k\">call</span> timemory_init_library(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>ex-fortran<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! initialize with name extracted from get_command_argument(<span class=\"\
    pl-c1\">0</span>, ...)\n    ! <span class=\"pl-k\">call</span> timemory_init_library(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! define the default set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_set_default(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock,\
    \ cpu_clock<span class=\"pl-pds\">\"</span></span>)\n\n    ! Start region <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! Add peak_rss <span class=\"pl-k\">to</span> the current\
    \ set of components\n    <span class=\"pl-k\">call</span> timemory_add_components(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\"\
    >\"</span></span>)\n\n    ! Nested region <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span> nested under <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! End the <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>inner<span class=\"pl-pds\">\"</span></span> region\n    <span class=\"\
    pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner<span class=\"pl-pds\">\"</span></span>)\n\n    ! remove peak_rss\n\
    \    <span class=\"pl-k\">call</span> timemory_remove_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! begin a region and get an identifier\n    idx <span class=\"pl-k\">=</span>\
    \ timemory_get_begin_record(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>indexed<span\
    \ class=\"pl-pds\">\"</span></span>)\n\n    ! replace current set of components\n\
    \    <span class=\"pl-k\">call</span> timemory_push_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Nested region <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> with only page_rss components\n    <span class=\"\
    pl-k\">call</span> timemory_push_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\n    ! <span\
    \ class=\"pl-k\">Stop</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> region with only page_rss components\n   \
    \ <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! restore previous set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_pop_components()\n\n    ! end the <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span> region\n    <span\
    \ class=\"pl-k\">call</span> timemory_end_record(idx)\n\n    ! End <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>\n\
    \    <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Output the results\n    <span class=\"pl-k\">call</span> timemory_finalize_library()\n\
    \n<span class=\"pl-k\">end program</span> fortran_example</pre></div>\n<h3><a\
    \ id=\"user-content-sample-python-api\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#sample-python-api\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Sample Python API</h3>\n<h4><a id=\"user-content-decorator\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#decorator\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Decorator</h4>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">bundle</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">marker</span>\n\n<span class=\"\
    pl-en\">@<span class=\"pl-en\">marker</span>([<span class=\"pl-s\">\"cpu_clock\"\
    </span>, <span class=\"pl-s\">\"peak_rss\"</span>])</span>\n<span class=\"pl-k\"\
    >def</span> <span class=\"pl-en\">foo</span>():\n    <span class=\"pl-k\">pass</span></pre></div>\n\
    <h4><a id=\"user-content-context-manager\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#context-manager\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Context Manager</h4>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">timemory</span>.<span class=\"pl-s1\">profiler</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-s1\">profile</span>\n\n<span class=\"pl-k\">def</span>\
    \ <span class=\"pl-en\">bar</span>():\n    <span class=\"pl-k\">with</span> <span\
    \ class=\"pl-en\">profile</span>([<span class=\"pl-s\">\"wall_clock\"</span>,\
    \ <span class=\"pl-s\">\"cpu_util\"</span>]):\n        <span class=\"pl-en\">foo</span>()</pre></div>\n\
    <h4><a id=\"user-content-individual-components\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#individual-components\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Individual Components</h4>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span\
    \ class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">component</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-v\">WallClock</span>\n\n<span\
    \ class=\"pl-k\">def</span> <span class=\"pl-en\">spam</span>():\n\n    <span\
    \ class=\"pl-s1\">wc</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >WallClock</span>(<span class=\"pl-s\">\"spam\"</span>)\n    <span class=\"pl-s1\"\
    >wc</span>.<span class=\"pl-en\">start</span>()\n\n    <span class=\"pl-en\">bar</span>()\n\
    \n    <span class=\"pl-s1\">wc</span>.<span class=\"pl-en\">stop</span>()\n  \
    \  <span class=\"pl-s1\">data</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">wc</span>.<span class=\"pl-en\">get</span>()\n    <span class=\"pl-en\"\
    >print</span>(<span class=\"pl-s1\">data</span>)</pre></div>\n<h4><a id=\"user-content-argparse-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#argparse-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Argparse\
    \ Support</h4>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"\
    pl-k\">import</span> <span class=\"pl-s1\">argparse</span>\n\n<span class=\"pl-s1\"\
    >parser</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">argparse</span>.<span\
    \ class=\"pl-v\">ArgumentParser</span>(<span class=\"pl-s\">\"example\"</span>)\n\
    <span class=\"pl-c\"># ...</span>\n<span class=\"pl-s1\">timemory</span>.<span\
    \ class=\"pl-en\">add_arguments</span>(<span class=\"pl-s1\">parser</span>)\n\n\
    <span class=\"pl-s1\">args</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">parser</span>.<span class=\"pl-en\">parse_args</span>()</pre></div>\n\
    <h4><a id=\"user-content-component-storage\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#component-storage\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Component Storage</h4>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">timemory</span>.<span class=\"pl-s1\">storage</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-v\">WallClockStorage</span>\n\n<span class=\"\
    pl-c\"># data for current rank</span>\n<span class=\"pl-s1\">data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">get</span>()\n<span class=\"pl-c\"># combined data on rank zero\
    \ but all ranks must call it</span>\n<span class=\"pl-s1\">dmp_data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">dmp_get</span>()</pre></div>\n<h2><a id=\"user-content-versioning\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#versioning\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Versioning</h2>\n\
    <p>Timemory originated as a very simple tool for recording timing and memory measurements\
    \ (hence the name) in C, C++, and Python and only supported\nthree modes prior\
    \ to the 3.0.0 release: a fixed set of timers, a pair of memory measurements,\
    \ and the combination of the two.\n<strong>Prior to the 3.0.0 release, timemory\
    \ was almost completely rewritten from scratch</strong> with the sole exceptions\
    \ of some C/C++ macro, e.g.\n<code>TIMEMORY_AUTO_TIMER</code>, and some Python\
    \ decorators and context-manager, e.g. <code>timemory.util.auto_timer</code>,\
    \ whose behavior were\nable to be fully replicated in the new release. Thus, while\
    \ it may appear that timemory is a mature project at v3.0+, it\nis essentially\
    \ still in it's first major release.</p>\n<h2><a id=\"user-content-citing-timemory\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-timemory\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citing timemory</h2>\n\
    <p>To reference timemory in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Madsen, J.R. et al. (2020) Timemory: Modular Performance Analysis for\
    \ HPC. In: Sadayappan P., Chamberlain B., Juckeland G., Ltaief H. (eds) High Performance\
    \ Computing. ISC High Performance 2020. Lecture Notes in Computer Science, vol\
    \ 12151. Springer, Cham</li>\n</ul>\n<h2><a id=\"user-content-additional-information\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#additional-information\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Additional\
    \ Information</h2>\n<p>For more information, refer to the <a href=\"https://timemory.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n"
  stargazers_count: 327
  subscribers_count: 17
  topics:
  - python
  - cpp
  - cplusplus
  - performance
  - c
  - cross-platform
  - cross-language
  - memory-measurements
  - mpi
  - cuda
  - papi
  - hardware-counters
  - analysis
  - roofline
  - performance-measurement
  - instrumentation-api
  - gotcha
  - cupti
  - modular-design
  updated_at: 1700854607.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 51
  subscribers_count: 20
  topics: []
  updated_at: 1700325894.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<h1><a id="user-content-gsi-utils" class="anchor" aria-hidden="true" tabindex="-1"
    href="#gsi-utils"><span aria-hidden="true" class="octicon octicon-link"></span></a>GSI-Utils</h1>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 2
  subscribers_count: 8
  topics: []
  updated_at: 1690297134.0
ORNL/ReSolve:
  data_format: 2
  description: Library of GPU-resident linear solvers
  filenames:
  - buildsystem/spack/incline/spack.yaml
  full_name: ORNL/ReSolve
  latest_release: null
  readme: "<h1><a id=\"user-content-resolve\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#resolve\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>ReSolve</h1>\n<p>ReSolve is a library of GPU-resident\
    \ linear solver. It contains iterative and direct linear solvers designed to run\
    \ on NVIDIA and AMD GPUs, as well as on CPU devices.</p>\n<p>ReadTheDocs Documentation\
    \ lives here <a href=\"https://ornl.github.io/ReSolve/\" rel=\"nofollow\">https://ornl.github.io/ReSolve/</a></p>\n\
    <h2><a id=\"user-content-getting-started\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#getting-started\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Getting started</h2>\n<p>Dependencies:</p>\n\
    <ul>\n<li>KLU, AMD and COLAMD libraries from SuiteSparse &gt;= 5.0</li>\n<li>CMake\
    \ &gt;= 3.22</li>\n<li>CUDA &gt;= 11.4 (optional)</li>\n<li>HIP/ROCm &gt;= 5.6\
    \ (optional)</li>\n</ul>\n<p>To build it:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ git clone https://github.com/ORNL/ReSolve.git\n$ mkdir build <span class=\"\
    pl-k\">&amp;&amp;</span> <span class=\"pl-c1\">cd</span> build\n$ cmake ../ReSolve\n\
    $ make</pre></div>\n<h2><a id=\"user-content-to-install-the-library\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#to-install-the-library\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To install\
    \ the library</h2>\n<p>In the directory where you built the library run</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ make install</pre></div>\n\
    <p>To change the install location please use the CMAkePresets.json file as mentioned\
    \ in <a href=\"#test-and-deploy\">test and deploy</a></p>\n<p>To run it, download\
    \ <a href=\"https://github.com/NREL/opf_matrices/tree/master/acopf/activsg10k\"\
    >test linear systems</a> and then edit script <a href=\"runResolve\"><code>runResolve</code></a>\
    \ to match locations of your linear systems and binary installation. The script\
    \ will emulate nonlinear solver calling the linear solver repeatedly.</p>\n<h2><a\
    \ id=\"user-content-to-use-the-resolve-library-in-your-own-project\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#to-use-the-resolve-library-in-your-own-project\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To use the\
    \ ReSolve library in your own project</h2>\n<p>Make sure Resolve library is installed\
    \ (see above)</p>\n<p>Below is an example CMakeList.txt file to use ReSolve library\
    \ in your project</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span\
    \ class=\"pl-c1\">cmake_minimum_required</span>(<span class=\"pl-k\">VERSION</span>\
    \ 3.20)\n<span class=\"pl-c1\">project</span>(my_app <span class=\"pl-k\">LANGUAGES</span>\
    \ CXX)\n\n<span class=\"pl-c1\">find_package</span>(ReSolve <span class=\"pl-k\"\
    >CONFIG</span> \n  <span class=\"pl-k\">PATHS</span> <span class=\"pl-smi\">${ReSolve_DIR}</span>\
    \ <span class=\"pl-smi\">${ReSolve_DIR}</span>/share/resolve/cmake\n  <span class=\"\
    pl-k\">ENV</span> <span class=\"pl-k\">LD_LIBRARY_PATH</span> <span class=\"pl-k\"\
    >ENV</span> DYLD_LIBRARY_PATH\n  <span class=\"pl-k\">REQUIRED</span>)\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Build your executable </span>\n\
    <span class=\"pl-c1\">add_executable</span>(my_app my_app.cpp)\n<span class=\"\
    pl-c1\">target_link_libraries</span>(my_app <span class=\"pl-k\">PRIVATE</span>\
    \ ReSolve::ReSolve)</pre></div>\n<h2><a id=\"user-content-contributing\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>For all\
    \ contributions to ReSolve please follow the <a href=\"CONTRIBUTING.md\">developer\
    \ guidelines</a></p>\n<h2><a id=\"user-content-test-and-deploy\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#test-and-deploy\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Test and Deploy</h2>\n<p>ReSolve\
    \ as a library is tested every merge request via Gitlab pipelines that execute\
    \ various library tests including a test of ReSolve being consumed as package\
    \ within an external project as mentioned in <a href=\"#to-use-the-resolve-library-in-your-own-project\"\
    >Using ReSolve in your own Project</a></p>\n<p>To test your own install of ReSolve\
    \ simply run from your ReSolve build directory</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ make <span class=\"pl-c1\">test</span></pre></div>\n<p>After you <code>make\
    \ install</code> you can test your installation by running</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$ make test_install</pre></div>\n<p>from\
    \ your build directory.</p>\n<h3><a id=\"user-content-important-notes\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#important-notes\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Important Notes</h3>\n\
    <p>You can find default Cmake Configurations in the CMakePresets.json file, which\
    \ allows for easy switching between different CMake Configs. To create your own\
    \ CMake Configuration we encourage you to utlize a CmakeUserPresets.json file.\
    \ To learn more about cmake-presets please checkout the cmake <a href=\"https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html\"\
    \ rel=\"nofollow\">docs</a></p>\n<p>For example if you wanted to build and install\
    \ ReSolve on a High Performance Computing Cluster such as PNNL's Deception or\
    \ ORNL's Ascent we encourage you to utilize our cluster preset. Using this preset\
    \ will set CMAKE_INSTALL_PREFIX to an install folder. To use this preset simply\
    \ call the preset flag in the cmake build step.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -B build --preset cluster</pre></div>\n<h2><a id=\"user-content-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#support\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Support</h2>\n\
    <p>For technical questions or to report a bug please submit a <a href=\"https://github.com/ORNL/ReSolve/issues\"\
    >GitHub issue</a>.\nFor non-technical issues please contact Kasia \u015Awirydowicz\
    \ <a href=\"mailto:kasia.swirydowicz@pnnl.gov\">kasia.swirydowicz@pnnl.gov</a>\
    \ or Slaven Peles <a href=\"mailto:peless@ornl.gov\">peless@ornl.gov</a>.</p>\n\
    <h2><a id=\"user-content-authors-and-acknowledgment\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#authors-and-acknowledgment\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Authors and acknowledgment</h2>\n\
    <p>Primary authors of this project are Kasia \u015Awirydowicz and Slaven Peles.</p>\n\
    <p>ReSolve project would not be possible without significant contributions from\
    \ (in alphabetic order):</p>\n<ul>\n<li>Maksudul Alam</li>\n<li>Ryan Danehy</li>\n\
    <li>Nicholson Koukpaizan</li>\n<li>Jaelyn Litzinger</li>\n<li>Phil Roth</li>\n\
    <li>Cameron Rutherford</li>\n</ul>\n<p>Development of this code was supported\
    \ by the Exascale Computing Project (ECP), Project Number: 17-SC-20-SC,\na collaborative\
    \ effort of two DOE organizations\u2014the Office of Science and the National\
    \ Nuclear Security\nAdministration\u2014responsible for the planning and preparation\
    \ of a capable exascale ecosystem\u2014including software,\napplications, hardware,\
    \ advanced system engineering, and early testbed platforms\u2014to support the\
    \ nation's exascale\ncomputing imperative.</p>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>Copyright \xA9 2023, UT-Battelle, LLC, and Battelle Memorial Institute.</p>\n\
    <p>ReSolve is a free software distributed under a BSD-style license. See the\n\
    <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> files for details.\
    \ All new\ncontributions to ReSolve must be made under the smae licensing terms.</p>\n\
    <p><strong>Please Note</strong> If you are using ReSolve with any third party\
    \ libraries linked\nin (e.g., KLU), be sure to review the respective license of\
    \ the package as that\nlicense may have more restrictive terms than the ReSolve\
    \ license.</p>\n"
  stargazers_count: 18
  subscribers_count: 6
  topics: []
  updated_at: 1700711649.0
PawseySC/hpc-container-training:
  data_format: 2
  description: 'Training material on using containers in an HPC setting. '
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/hpc-container-training
  latest_release: null
  readme: '<h1><a id="user-content-readme" class="anchor" aria-hidden="true" tabindex="-1"
    href="#readme"><span aria-hidden="true" class="octicon octicon-link"></span></a>Readme</h1>

    '
  stargazers_count: 4
  subscribers_count: 5
  topics:
  - docker
  - singularity
  - hpc
  - pawsey
  - training-materials
  updated_at: 1682469853.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Automated deployment system for the scientific software stack in use
    at Pawsey
  filenames:
  - systems/setonix/environments/wrf/spack.yaml
  - systems/setonix/environments/bench/spack.yaml
  - systems/setonix/environments/astro/spack.yaml
  - systems/setonix/environments/utils/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-pawsey-spack-configuration" class="anchor" aria-hidden="true"
    tabindex="-1" href="#pawsey-spack-configuration"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Pawsey Spack Configuration</h1>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_TAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <h3><a id="user-content-singularity" class="anchor" aria-hidden="true" tabindex="-1"
    href="#singularity"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h3>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <h3><a id="user-content-software-stack-modulefile" class="anchor" aria-hidden="true"
    tabindex="-1" href="#software-stack-modulefile"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Software stack modulefile</h3>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <h2><a id="user-content-repository-structure" class="anchor" aria-hidden="true"
    tabindex="-1" href="#repository-structure"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Repository structure</h2>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <h2><a id="user-content-the-scripts-directory" class="anchor" aria-hidden="true"
    tabindex="-1" href="#the-scripts-directory"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>The <code>scripts</code> directory</h2>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <h2><a id="user-content-the-systemssystem-directory" class="anchor" aria-hidden="true"
    tabindex="-1" href="#the-systemssystem-directory"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>The <code>systems/&lt;system&gt;</code> directory</h2>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <h2><a id="user-content-notes" class="anchor" aria-hidden="true" tabindex="-1"
    href="#notes"><span aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h2>

    <h3><a id="user-content-module-categories-in-use" class="anchor" aria-hidden="true"
    tabindex="-1" href="#module-categories-in-use"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Module categories in use</h3>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <h3><a id="user-content-testing-modules" class="anchor" aria-hidden="true" tabindex="-1"
    href="#testing-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a>Testing
    Modules</h3>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1687655533.0
RMeli/my-spack:
  data_format: 2
  description: Spack environments
  filenames:
  - envs/local/cp2k-dlaf/mkl-mt-mpich-cuda/spack.yaml
  - envs/local/dlaf/mkl-mt-mpich-cuda-scalapack-pika/spack.yaml
  - envs/alps/cp2k-dlaf/mkl-cuda/spack.yaml
  - envs/alps/dlaf/mkl-mt/spack.yaml
  - envs/alps/dlaf/oneapi-mt/spack.yaml
  full_name: RMeli/my-spack
  latest_release: null
  readme: '<h1><a id="user-content-my-spack" class="anchor" aria-hidden="true" tabindex="-1"
    href="#my-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>My
    Spack</h1>

    <p>Spack-related stuff for @RMeli.</p>

    <h2><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    tabindex="-1" href="#package-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Package Repository</h2>

    <p><a href="https://spack.readthedocs.io/en/latest/repositories.html" rel="nofollow">Spack
    Package Repositories</a></p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679671251.0
ResearchComputing/core-software:
  data_format: 2
  description: Documentation and automation for provisioning the core software environment
    at University of Colorado Boulder Research Computing
  filenames:
  - spack/environments/develop/spack.yaml
  full_name: ResearchComputing/core-software
  latest_release: null
  readme: '<p>The Research Computing core software environment provides compilers,

    mpi, libraries, language environments, and applications that are of

    general use to the CU Boulder Research Computing user community.</p>

    <h2><a id="user-content-manual-installation-procedures" class="anchor" aria-hidden="true"
    tabindex="-1" href="#manual-installation-procedures"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Manual installation procedures</h2>

    <p>Manual software installation procedures are available in the <code>Summit</code>

    and <code>Blanca</code> directories, organized by

    <code>Cluster/SoftwareName/VersionNumber</code>. The <code>VersionNumber</code>
    file

    contains build notes (bash commands, notes, instructions etc.) to

    install that software package for each compiler and MPI.</p>

    <h2><a id="user-content-spack" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack</h2>

    <p>Spack, when deployed as intended, will be a central part of the

    provisioning of our Core Software service. Included here is the

    configuration and installation script for Spack as installed and

    presented at CU Boulder Research Computing.</p>

    '
  stargazers_count: 1
  subscribers_count: 8
  topics: []
  updated_at: 1649960895.0
SC-SGS/CPPuddle:
  data_format: 2
  description: Utility library to handle small, reusable pools of both device memory
    buffers (via allocators) and device executors (with multiple scheduling policies).
  filenames:
  - spack.yaml
  full_name: SC-SGS/CPPuddle
  latest_release: v0.3.1
  readme: "<h3><a id=\"user-content-cppuddle\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#cppuddle\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>CPPuddle</h3>\n<p><a href=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml\"\
    ><img src=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml/badge.svg\"\
    \ alt=\"ctest\" style=\"max-width: 100%;\"></a>\n<a href=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/view/Octo-Tiger%20and%20Dependencies/job/CPPuddle/job/master/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f85055028a87ff41032206704d36fede5e5cc779d3369a6650f02d9d46676a45/68747470733a2f2f73696d7367732e696e666f726d6174696b2e756e692d7374757474676172742e64652f6a656e6b696e732f6275696c645374617475732f69636f6e3f6a6f623d4350507564646c652532466d617374657226636f6e6669673d616c6c6275696c6473\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=CPPuddle%2Fmaster&amp;config=allbuilds\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h4><a id=\"user-content-purpose\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Purpose</h4>\n<p>This repository\
    \ was initially created to explore how to best use HPX and Kokkos together!\n\
    For fine-grained GPU tasks, we needed a way to avoid excessive allocations of\
    \ one-usage GPU buffers (as allocations block the device for all streams) and\
    \ creation/deletion of GPU executors (as those are usually tied to a stream which\
    \ is expensive to create as well).</p>\n<p>We currently test/use CPPuddle in <a\
    \ href=\"https://github.com/STEllAR-GROUP/octotiger\">Octo-Tiger</a>, together\
    \ with <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>.\n\
    In this use-case, allocating GPU buffers for all sub-grids in advance would have\
    \ wasted a lot of memory. On the other hand, unified memory would have caused\
    \ unnecessary GPU to CPU page migrations (as the old input data gets overwritten\
    \ anyway). Allocating buffers on-the-fly would have blocked the device. Hence,\
    \ we currently test this buffer management solution!</p>\n<h4><a id=\"user-content-tools-provided-by-this-repository\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#tools-provided-by-this-repository\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tools provided\
    \ by this repository</h4>\n<ul>\n<li>Allocators that reuse previousely allocated\
    \ buffers if available (works with normal heap memory, pinned memory, aligned\
    \ memory, CUDA/HIP device memory, and Kokkos Views). Note that separate buffers\
    \ do not coexist on a single chunk of continuous memory, but use different allocations.</li>\n\
    <li>Executor pools and various scheduling policies (round robin, priority queue,\
    \ multi-gpu), which rely on reference counting to gauge the current load of a\
    \ executor instead of querying the device itself. Tested with CUDA, HIP and Kokkos\
    \ executors provided by HPX / HPX-Kokkos.</li>\n<li>Special Executors/Allocators\
    \ for on-the-fly work GPU aggregation (using HPX).</li>\n</ul>\n<h4><a id=\"user-content-requirements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#requirements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h4>\n\
    <ul>\n<li>C++17</li>\n<li>CMake (&gt;= 3.16)</li>\n<li>Optional (for the header-only\
    \ utilities / test): CUDA, Boost, <a href=\"https://github.com/STEllAR-GROUP/hpx\"\
    >HPX</a>, <a href=\"https://github.com/kokkos/kokkos\">Kokkos</a>, <a href=\"\
    https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>\n</li>\n</ul>\n<p>The\
    \ submodules can be used to obtain the optional dependencies which are required\
    \ for testing the header-only utilities. If these tests are not required, the\
    \ submodule (and the respective buildscripts in /scripts) can be ignored safely.</p>\n\
    <h4><a id=\"user-content-build--install\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#build--install\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Build / Install</h4>\n<ul>\n<li>\n<p>A spack\
    \ package for CPPuddle is available in the <a href=\"https://github.com/G-071/octotiger-spack\"\
    >octotiger-spack repository</a></p>\n</li>\n<li>\n<p>Basic CMake build</p>\n</li>\n\
    </ul>\n<pre><code>  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF\
    \                                                             \n  cmake --build\
    \ /path/to/build --target install  \n</code></pre>\n<p>If installed correctly,\
    \ CPPuddle can be used in other CMake-based projects via</p>\n<pre><code>find_package(CPPuddle\
    \ REQUIRED)\n</code></pre>\n<ul>\n<li>Recommended CMake build:</li>\n</ul>\n<pre><code>\
    \  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle\
    \ -DCPPUDDLE_WITH_HPX=ON -DCPPUDDLE_WITH_HPX_AWARE_ALLOCATORS=ON -DCPPUDDLE_WITH_TESTS=OFF\
    \ -DCPPUDDLE_WITH_COUNTERS=OFF                                               \
    \              \n</code></pre>\n"
  stargazers_count: 6
  subscribers_count: 4
  topics: []
  updated_at: 1696743120.0
SCOREC/centos7-spack-config:
  data_format: 2
  description: spack config for erp cluster
  filenames:
  - v0190_gcc910/spack.yaml
  - v0201_1/spack.yaml
  - openFoam24/spack.yaml
  full_name: SCOREC/centos7-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-centos7-spack-config" class="anchor" aria-hidden="true"
    tabindex="-1" href="#centos7-spack-config"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>centos7-spack-config</h1>

    <p>centos7 spack configuration and scripts</p>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list

    config.yaml - global config

    install.sh - package installation commands

    modules.yaml - hierarchical layout for lua modules

    packages.yaml - system installed packages

    README.md - this file

    setupSpack.sh - env needed for executing spack commands</p>

    '
  stargazers_count: 1
  subscribers_count: 5
  topics: []
  updated_at: 1696768501.0
SCOREC/dcs-spack-config:
  data_format: 2
  description: Spack config for CCI DCS (AiMOS) system
  filenames:
  - rhel8NvhpcWdmapp/spack.yaml
  - spack.yaml
  full_name: SCOREC/dcs-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-dcs-spack-config" class="anchor" aria-hidden="true"
    tabindex="-1" href="#dcs-spack-config"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>dcs-spack-config</h1>

    <p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies

    with the IBM XL compilers and Spectrum-MPI.</p>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list</p>

    <p>config.yaml - global config</p>

    <p>install.sh - package installation commands</p>

    <p>modules.yaml - hierarchical layout for lua modules</p>

    <p>packages.yaml - system installed packages</p>

    <p>README.md - this file</p>

    <p>setupSpack.sh - env needed for executing spack commands</p>

    <p>spack.yaml - list of packages to install</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" tabindex="-1"
    href="#setup"><span aria-hidden="true" class="octicon octicon-link"></span></a>setup</h2>

    <pre><code>git clone git@github.com:spack/spack.git spack

    cd !$

    git checkout v0.13.3

    # add the simmetrix-simmodsuite package from the develop branch

    git cherry-pick 5ddf5e2

    # create the environment

    spack env create v0133

    spack env activate v0133

    # copy the yaml files into the v0133

    cp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.

    # copy the compiler yaml file into the spack etc dir

    cp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.

    </code></pre>

    <h2><a id="user-content-install-cmake" class="anchor" aria-hidden="true" tabindex="-1"
    href="#install-cmake"><span aria-hidden="true" class="octicon octicon-link"></span></a>install
    cmake</h2>

    <p>The bootstrap step of the cmake install fails with the XL compilers.  I

    installed it manually outside of the environment with spack and gcc4.8.5</p>

    <pre><code>spack install cmake%gcc@4.8.5_rhel7

    </code></pre>

    <p>Then added the path to <code>packages.yaml</code>.</p>

    <h2><a id="user-content-resuming-work-in-an-environment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#resuming-work-in-an-environment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>resuming work in an environment</h2>

    <pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh

    spack env activate v0133

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633029356.0
SCOREC/drp-spack-config:
  data_format: 2
  description: CCI DRP Spack configuration
  filenames:
  - openFoam24/spack.yaml
  full_name: SCOREC/drp-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-drp-spack-config" class="anchor" aria-hidden="true"
    tabindex="-1" href="#drp-spack-config"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>drp-spack-config</h1>

    <p>CCI DRP Spack configuration</p>

    <h1><a id="user-content-contents" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>contents</h1>

    <p>openFoam24 - spack environment for an OpenFoam Organization 2.4.0 install</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1593654195.0
SCOREC/pcms:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: SCOREC/pcms
  latest_release: null
  readme: '<h1><a id="user-content-pcms-parallel-coupler-for-multimodel-simulations"
    class="anchor" aria-hidden="true" tabindex="-1" href="#pcms-parallel-coupler-for-multimodel-simulations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>PCMS: Parallel Coupler
    For Multimodel Simulations</h1>

    <p>Adios2-based xgc_coupler for XGC and GENE</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <ul>

    <li>CMake 3.19+</li>

    <li>MPI</li>

    <li>FFTW 3.3.8+</li>

    <li>redev 3.0.0+ (<a href="https://github.com/SCOREC/redev">https://github.com/SCOREC/redev</a>)</li>

    <li>Omega_h 10.2.0+ with MPI enabled (<a href="https://github.com/SCOREC/omega_h">https://github.com/SCOREC/omega_h</a>)</li>

    <li>Catch2 2.* (for unit tests) (<a href="https://github.com/catchorg/Catch2/tree/v2.13.8">https://github.com/catchorg/Catch2/tree/v2.13.8</a>)</li>

    </ul>

    <h2><a id="user-content-build-instructions" class="anchor" aria-hidden="true"
    tabindex="-1" href="#build-instructions"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Build Instructions</h2>

    <h2><a id="user-content-build-with-modules" class="anchor" aria-hidden="true"
    tabindex="-1" href="#build-with-modules"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Build with modules</h2>

    <p>SCOREC Rhel7 environment</p>

    <pre><code>module unuse /opt/scorec/spack/lmod/linux-rhel7-x86_64/Core

    module use /opt/scorec/spack/v0154_2/lmod/linux-rhel7-x86_64/Core

    module load \

    gcc/10.1.0 \

    mpich \

    cmake/3.20.0 \

    fftw \

    gdb

    </code></pre>

    <p>Build, install, and test</p>

    <pre><code>git clone git@github.com:SCOREC/wdmapp_testcases.git #test data

    git clone git@github.com:SCOREC/wdmapp_coupling.git


    cmake -S wdmapp_coupling -B buildWdmCpl \

    -Dredev_ROOT=/path/to/redev/install \

    -DOmega_h_ROOT=/path/to/omegah/install \

    -DCMAKE_INSTALL_PREFIX=$PWD/buildWdmCpl/install \

    -DPCMS_TEST_DATA_DIR=$PWD/wdmapp_testcases \

    -DCatch2_ROOT=/path/to/catch2/install


    cmake --build buildWdmCpl --target install


    ctest --test-dir buildWdmCpl --output-on-failure

    </code></pre>

    <h2><a id="user-content-spack-based-build" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-based-build"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    based build</h2>

    <ol>

    <li>

    <p>Install spack</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">mkdir
    /lore/<span class="pl-smi">$USER</span>/spack</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> /lore/<span class="pl-smi">$USER</span>/spack</span>

    $ <span class="pl-s1">git clone -c feature.manyFiles=true -b releases/v0.20 https://github.com/spack/spack.git</span>

    $ <span class="pl-s1"><span class="pl-c1">.</span> spack/share/spack/setup-env.sh</span></pre></div>

    <p>We can also add the spack setup line into the <code>~/.bashrc</code> with `echo
    ". spack/share/spack/setup-env.sh" &gt;&gt; ~/.bashrc". This will load the spack
    setup script every time we start our terminal session.</p>

    </li>

    <li>

    <p>Get PCMS spack repo

    The following commands will add the pcms recipe files to spack. They are not currently
    installed inthe upstream spack repository.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">git
    clone https://github.com/jacobmerson/pcms-spack.git</span>

    $ <span class="pl-s1">spack repo add pcms-spack/pcms</span></pre></div>

    </li>

    <li>

    <p>Add Spack binary mirror

    Addding the binary mirrors will avoid some compilation by downloading prebuilt
    binaries when available.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">spack
    mirror add v0.20.1 https://binaries.spack.io/v0.20.1</span>

    $ <span class="pl-s1">spack buildcache keys --install --trust</span></pre></div>

    </li>

    <li>

    <p>Install PCMS repo</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">mkdir
    /lore/<span class="pl-smi">$USER</span>/pcms-coupler</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> /lore/<span class="pl-smi">$USER</span>/pcms-coupler</span>

    $ <span class="pl-s1">git clone -b pcms-spack https://github.com/jacobmerson/pcms</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> pcms/spack</span>

    $ <span class="pl-s1">spack env create -d env spack.yaml</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> env</span>

    $ <span class="pl-s1">spack env activate <span class="pl-c1">.</span></span>

    $ <span class="pl-s1">spack install</span></pre></div>

    </li>

    </ol>

    <p>At this point hopefully, spack will now install all of the relavant dependencies
    and a baseline build of PCMS. The default environment has PCMS in develop mode.
    To modify and recompile PCMS you can modify the code and rerun <code>spack install</code>.</p>

    <h3><a id="user-content-build-todo" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build-todo"><span aria-hidden="true" class="octicon octicon-link"></span></a>BUILD
    TODO</h3>

    <ul>

    <li>create a spack environment that''s part of this project that can build the
    whole stack.

    most of the pieces are in place for this, but it will require createing a package
    for redev

    and of the SCOREC version of Omega_h

    <ul>

    <li>scorec version 10.1.0 of Omega_h is in spack@develop

    <a href="https://github.com/spack/spack/blob/8ddaa08ed2aacb4b5e587a33c625492cbdd4886e/var/spack/repos/builtin/packages/omega-h/package.py#L21">https://github.com/spack/spack/blob/8ddaa08ed2aacb4b5e587a33c625492cbdd4886e/var/spack/repos/builtin/packages/omega-h/package.py#L21</a>

    </li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 2
  subscribers_count: 18
  topics: []
  updated_at: 1681842553.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.20.1/v1/spack.yaml
  - v0.18.1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#rhel7-spack-config\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n\
    <p>rhel7 spack configuration and scripts</p>\n<p>The <code>install.sh</code> script\
    \ maintained in this repo is for documentation purposes (e.g., in case we had\
    \ to reinstall the entire stack from scratch) and should not be executed as it\
    \ will not use all of our existing package installs.  More discussion of package\
    \ installation is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#useful-commands\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>useful commands</h2>\n\
    <p>regenerate lmod module tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n\
    <h2><a id=\"user-content-installing-new-packages\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#installing-new-packages\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>installing new packages</h2>\n\
    <p>Our spack repo is tracking the master spack branch.  Spack package updates\
    \ could result in additional installation of packages with little or no package\
    \ source code changes.  These additional installs can be avoided when installing\
    \ new packages by first examining the output of the <code>spack spec -I</code>\
    \ command.  If a utility/infrastructure level package, such as cmake or mpich,\
    \ is marked with a <code>[+]</code> symbol in the leftmost column then it means\
    \ that the existing install will be used.  If spack does not default to using\
    \ the existing install you can append the hash of the package to the spec command.</p>\n\
    <p>For example, lets see what happens when we ask for a pumi install using gcc\
    \ 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global\
    \ config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical\
    \ layout for lua modules\npackages.yaml - system installed packages\nREADME.md\
    \ - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1683174256.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/archived/rhel7-runner-x86_64/spack.yaml
  - docker-recipes/runner/archived/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-amd64-clang-16/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/runner/archived/ubuntu18.04-ppc64le/spack.yaml
  - spack-sdk-environments/compilers_and_support/spack.yaml
  - docker-recipes/runner/ubuntu22.04-amd64-oneapi-2023.2.1/spack.yaml
  - docker-recipes/runner/archived/ubuntu20.04-x86_64-gcc-11.2/spack.yaml
  - docker-recipes/runner/archived/ubuntu20.04-x86_64-gcc-11.4-spack/spack.yaml
  - docker-recipes/archived/special/superlu-sc/spack.yaml
  - docker-recipes/runner/ubuntu22.04-amd64-gcc-11.4/spack.yaml
  - docker-recipes/runner/archived/ubuntu22.04-ppc64le/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 19
  subscribers_count: 7
  topics: []
  updated_at: 1696778511.0
WAAutoMaton/spack:
  data_format: 2
  description: null
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/e4s-power/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/e4s-cray-rhel/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/deprecated/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/aws-isc/spack.yaml
  full_name: WAAutoMaton/spack
  latest_release: null
  readme: "<h1><a id=\"user-content--spack\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\"\
    \ href=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/build-containers.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/build-containers.yml/badge.svg\"\
    \ alt=\"Containers\" style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/d91ed7ac7abbd5a6102cbe988dd8e9ac21bde0a73d97be7603b891ad08ce3479/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/code%20style-black-000000.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/4bbdc2b44561be6dfffe64e15730e1c5a2bed9c4efe6f9942638091a4ce3ede2/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a>\n<a href=\"https://matrix.to/#/#spack-space:matrix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/98f99ad5aaea488753f5330264e7dd87fcb54e3a40c83eba258a3ad7160686e1/68747470733a2f2f696d672e736869656c64732e696f2f6d61747269782f737061636b2d73706163652533416d61747269782e6f72673f6c6162656c3d4d6174726978\"\
    \ alt=\"Matrix\" data-canonical-src=\"https://img.shields.io/matrix/spack-space%3Amatrix.org?label=Matrix\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager\
    \ that builds and installs\nmultiple versions and configurations of software.\
    \ It works on Linux,\nmacOS, and many supercomputers. Spack is non-destructive:\
    \ installing a\nnew version of a package does not break existing installations,\
    \ so many\nconfigurations of the same package can coexist.</p>\n<p>Spack offers\
    \ a simple \"spec\" syntax that allows users to specify versions\nand configuration\
    \ options. Package files are written in pure Python, and\nspecs allow package\
    \ authors to write a single script for many different\nbuilds of the same package.\
    \  With Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p><a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <h2><a id=\"user-content-tutorial\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Tutorial</h2>\n<p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<h2><a id=\"user-content-community\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#community\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Community</h2>\n<p>Spack is an open source project.\
    \  Questions, discussion, and\ncontributions are welcome. Contributions can be\
    \ anything from new\npackages to bugfixes, documentation, or even new core features.</p>\n\
    <p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<strong>Matrix\
    \ space</strong>: <a href=\"https://matrix.to/#/#spack-space:matrix.org\" rel=\"\
    nofollow\">#spack-space:matrix.org</a>:\n<a href=\"https://github.com/matrix-org/matrix-appservice-slack#matrix-appservice-slack\"\
    >bridged</a> to Slack.</li>\n<li>\n<a href=\"https://github.com/spack/spack/discussions\"\
    ><strong>Github Discussions</strong></a>:\nnot just for discussions, also Q&amp;A.</li>\n\
    <li>\n<strong>Mailing list</strong>: <a href=\"https://groups.google.com/d/forum/spack\"\
    \ rel=\"nofollow\">groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>:\
    \ <a href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n\
    <p>Contributing to Spack is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2><a id=\"user-content-releases\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Releases</h2>\n<p>For multi-user site deployments or other use cases\
    \ that need very stable\nsoftware installations, we recommend using Spack's\n\
    <a href=\"https://github.com/spack/spack/releases\">stable releases</a>.</p>\n\
    <p>Each Spack release series also has a corresponding branch, e.g.\n<code>releases/v0.14</code>\
    \ has <code>0.14.x</code> versions of Spack, and <code>releases/v0.13</code> has\n\
    <code>0.13.x</code> versions. We backport important bug fixes to these branches\
    \ but\nwe do not advance the package versions or make other changes that would\n\
    change the way Spack concretizes dependencies within a release branch.\nSo, you\
    \ can base your Spack deployment on a release branch and <code>git pull</code>\n\
    to get fixes, without the package churn that comes with <code>develop</code>.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<p>See the <a href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\"\
    \ rel=\"nofollow\">docs on releases</a>\nfor more details.</p>\n<h2><a id=\"user-content-code-of-conduct\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#code-of-conduct\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Code of\
    \ Conduct</h2>\n<p>Please note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"\
    ><strong>Code of Conduct</strong></a>. By participating in\nthe Spack community,\
    \ you agree to abide by its rules.</p>\n<h2><a id=\"user-content-authors\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#authors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>Many thanks\
    \ go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\"\
    >tgamblin@llnl.gov</a>.</p>\n<h3><a id=\"user-content-citing-spack\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Citing Spack</h3>\n<p>If you\
    \ are referencing Spack in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee,\n\
    Adam Moody, Bronis R. de Supinski, and W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<p>On GitHub, you can copy\
    \ this citation in APA or BibTeX format via the \"Cite this repository\"\nbutton.\
    \ Or, see the comments in <code>CITATION.cff</code> for the raw BibTeX.</p>\n\
    <h2><a id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>License</h2>\n<p>Spack is distributed under the terms of both the\
    \ MIT license and the\nApache License (Version 2.0). Users may choose either license,\
    \ at their\noption.</p>\n<p>All new contributions must be made under both the\
    \ MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\"\
    >LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\"\
    >LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\"\
    >COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\"\
    >NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1700286887.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - compilers/envs/compilers/spack.yaml
  - cent7/library/spack.yaml
  - cent7/library/bak/spack.yaml
  - cent7/python_376/spack.yaml
  - cent7/bioinformatics_default/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1><a id="user-content-spack-environments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>SPACK Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2><a id="user-content-software-deployment-for-centos-8x" class="anchor" aria-hidden="true"
    tabindex="-1" href="#software-deployment-for-centos-8x"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Software deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3><a id="user-content-compilers" class="anchor" aria-hidden="true" tabindex="-1"
    href="#compilers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3><a id="user-content-lu-software" class="anchor" aria-hidden="true" tabindex="-1"
    href="#lu-software"><span aria-hidden="true" class="octicon octicon-link"></span></a>LU
    Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4><a id="user-content-available-environments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#available-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Available Environments</h4>

    <h5><a id="user-content-solhawk" class="anchor" aria-hidden="true" tabindex="-1"
    href="#solhawk"><span aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-avxavx2avx512" class="anchor" aria-hidden="true" tabindex="-1"
    href="#avxavx2avx512"><span aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-python-and-r-packages" class="anchor" aria-hidden="true"
    tabindex="-1" href="#python-and-r-packages"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Python and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-x86_64" class="anchor" aria-hidden="true" tabindex="-1"
    href="#x86_64"><span aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2><a id="user-content-centos-7x-software" class="anchor" aria-hidden="true"
    tabindex="-1" href="#centos-7x-software"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>CentOS 7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657632897.0
boutproject/BOUT-configs:
  data_format: 2
  description: Configuration scripts for BOUT++
  filenames:
  - lassen/spack_env/bout_petsc_with_hypre/spack.yaml
  - lassen/spack_env/bout/spack.yaml
  full_name: boutproject/BOUT-configs
  latest_release: null
  readme: '<h1><a id="user-content-configuration-scripts" class="anchor" aria-hidden="true"
    tabindex="-1" href="#configuration-scripts"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Configuration scripts</h1>

    <p>The CMake and autotools (configure/make) scripts supplied with BOUT++

    should be able to automatically find and configure BOUT++ in most

    cases. Where a complex configuration is desired, for example including

    many dependencies (esp. complex dependencies like PETSc), or compiling

    for GPUs, configuration can be quite complex.</p>

    <p>The files in this directory are intended to be convenient shortcuts for

    configuration on particular machines. Where there are many scripts, these

    are put into sub-directories (e.g. "cori" and "lassen").</p>

    <h2><a id="user-content-environment" class="anchor" aria-hidden="true" tabindex="-1"
    href="#environment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Environment</h2>

    <p>Scripts which set up the environment, for example loading and unloading

    modules, start with <code>setup</code> or <code>setup-env</code>. These are typically
    modifying

    shell environments and so should be invoked with <code>source</code>.</p>

    <h2><a id="user-content-bout-configuration" class="anchor" aria-hidden="true"
    tabindex="-1" href="#bout-configuration"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>BOUT++ configuration</h2>

    <p>The wrappers around CMake (or configure) start with <code>config</code> or
    <code>config-bout</code>.

    These are shell scripts which can be run without <code>source</code>.</p>

    '
  stargazers_count: 1
  subscribers_count: 17
  topics: []
  updated_at: 1686816130.0
camierjs/okina-jit:
  data_format: 2
  description: null
  filenames:
  - config/docker/spack.yaml
  full_name: camierjs/okina-jit
  latest_release: null
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed\
    \ under the terms of the BSD-3 license. All new contributions\nmust be made under\
    \ this license. See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>\
    \ for\ndetails.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release\
    \ Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1689268998.0
celeritas-project/celeritas:
  data_format: 2
  description: Celeritas is a new Monte Carlo transport code designed for high-performance
    simulation of high-energy physics detectors.
  filenames:
  - scripts/spack.yaml
  full_name: celeritas-project/celeritas
  latest_release: v0.4.0
  readme: "<h1><a id=\"user-content-celeritas\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#celeritas\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Celeritas</h1>\n<p>The Celeritas project implements\
    \ HEP detector physics on GPU accelerator\nhardware with the ultimate goal of\
    \ supporting the massive computational\nrequirements of the <a href=\"https://home.cern/science/accelerators/high-luminosity-lhc\"\
    \ rel=\"nofollow\">HL-LHC upgrade</a>.</p>\n<h1><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n\
    <p>Most of the Celeritas documentation is readable through the codebase through\
    \ a\ncombination of <a href=\"doc/index.rst\">static RST documentation</a> and\
    \ Doxygen-markup\ncomments in the source code itself. The full <a href=\"https://celeritas-project.github.io/celeritas/user/index.html\"\
    \ rel=\"nofollow\">Celeritas user\ndocumentation</a> (including selected code\
    \ documentation incorporated\nby Breathe) and the <a href=\"https://celeritas-project.github.io/celeritas/dev/index.html\"\
    \ rel=\"nofollow\">Celeritas code documentation</a> are mirrored on\nour GitHub\
    \ pages site. You can generate these yourself (if the necessary\nprerequisites\
    \ are installed) by\nsetting the <code>CELERITAS_BUILD_DOCS=ON</code> configuration\
    \ option and running <code>ninja doc</code> (user) or <code>ninja doxygen</code>\
    \ (developer). A continuously updated version of\nthe <a href=\"https://celeritas.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">static Celeritas user documentation</a> (without API documentation)\
    \ is\nhosted on <code>readthedocs.io</code>.</p>\n<h1><a id=\"user-content-installation-for-applications\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation-for-applications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ for applications</h1>\n<p>The easiest way to install Celeritas as a library/app\
    \ is with Spack:</p>\n<ul>\n<li>Follow the first two steps above to install <a\
    \ href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"\
    nofollow\">Spack</a> and set up its CUDA usage.</li>\n<li>Install Celeritas with\
    \ <code>spack install celeritas</code>\n</li>\n<li>Use <code>spack load celeritas</code>\
    \ to add the installation to your <code>PATH</code>.</li>\n</ul>\n<p>Then see\
    \ the \"Downstream usage as a library\" section of the <a href=\"doc/installation.rst\"\
    >installation\ndocumentation</a> for how to use Celeritas in your application\
    \ or framework.</p>\n<h1><a id=\"user-content-installation-for-developers\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation-for-developers\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ for developers</h1>\n<p>Since Celeritas is still under heavy development and\
    \ is not yet full-featured\nfor downstream integration, you are likely installing\
    \ it for development\npurposes. The <a href=\"doc/installation.rst\">installation\
    \ documentation</a> has a\ncomplete description of the code's dependencies and\
    \ installation process for\ndevelopment.</p>\n<p>As an example, if you have the\
    \ <a href=\"https://github.com/spack/spack\">Spack</a> package manager\ninstalled\
    \ and want to do development on a CUDA system with Volta-class graphics\ncards,\
    \ execute the following steps from within the cloned Celeritas source\ndirectory:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre># <span class=\"pl-s1\"\
    >Set up CUDA (optional)</span>\n$ <span class=\"pl-s1\">spack external find cuda</span>\n\
    $ <span class=\"pl-s1\">spack config add packages:all:variants:<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>+cuda cuda_arch=70<span class=\"pl-pds\"\
    >\"</span></span></span>\n# <span class=\"pl-s1\">Install celeritas dependencies</span>\n\
    $ <span class=\"pl-s1\">spack env create celeritas scripts/spack.yaml</span>\n\
    $ <span class=\"pl-s1\">spack env activate celeritas</span>\n$ <span class=\"\
    pl-s1\">spack install</span>\n# <span class=\"pl-s1\">Configure, build, and <span\
    \ class=\"pl-c1\">test</span></span>\n$ <span class=\"pl-s1\">./build.sh base</span></pre></div>\n\
    <p>If you don't use Spack but have all the dependencies you want (Geant4,\ngoogletest,\
    \ VecGeom, etc.) in your <code>CMAKE_PREFIX_PATH</code>, you can configure and\n\
    build Celeritas as you would any other project:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">mkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build</span>\n$ <span class=\"pl-s1\">cmake\
    \ ..</span>\n$ <span class=\"pl-s1\">make <span class=\"pl-k\">&amp;&amp;</span>\
    \ ctest</span></pre></div>\n<p>Celeritas guarantees full compatibility and correctness\
    \ only on the\ncombinations of compilers and dependencies tested under continuous\
    \ integration.\nCurrently supported compilers are GCC 11.2 + NVCC 11.8, and HIP-Clang\
    \ 15.0, but\nsince we compile with extra warning flags and avoid non-portable\
    \ code, most\nother compilers <em>should</em> work.\nCurrently Geant4 11.0 and\
    \ VecGeom 1.2 are the only versions that are guaranteed\nto work, but older versions\
    \ might be OK.\nThe full set of configurations is viewable on <a href=\"https://cloud.cees.ornl.gov/jenkins-ci/blue/organizations/jenkins/Celeritas/activity?branch=master\"\
    \ rel=\"nofollow\">the CI web site</a>.\nCompatibility fixes that do not cause\
    \ newer versions to fail are welcome.</p>\n<h1><a id=\"user-content-development\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#development\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development</h1>\n\
    <p>See the <a href=\"CONTRIBUTING.rst\">contribution guide</a> for the contribution\
    \ process,\n<a href=\"doc/appendices/development.rst\">the development guidelines</a>\
    \ for further\ndetails on coding in Celeritas, and <a href=\"doc/appendices/administration.rst\"\
    >the administration guidelines</a> for community standards and roles.</p>\n<h1><a\
    \ id=\"user-content-citing-celeritas\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#citing-celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing Celeritas</h1>\n<p>If using Celeritas in your work, we ask\
    \ that you cite the code using its\n<a href=\"https://www.osti.gov/doecode/biblio/94866\"\
    \ rel=\"nofollow\">DOECode</a> registration:</p>\n<blockquote>\n<p>Johnson, Seth\
    \ R., Amanda Lund, Soon Yung Jun, Stefano Tognini, Guilherme Lima, Paul Romano,\
    \ Philippe Canal, Ben Morgan, and Tom Evans. \u201CCeleritas,\u201D July 2022.\
    \ <a href=\"https://doi.org/10.11578/dc.20221011.1\" rel=\"nofollow\">https://doi.org/10.11578/dc.20221011.1</a>.</p>\n\
    </blockquote>\n<p>Additional references for code implementation details, benchmark\
    \ problem\nresults, etc., can be found in our continually evolving <a href=\"\
    doc/_static/celeritas.bib\">citation\nfile</a>. An <a href=\"https://github.com/celeritas-project/celeritas-docs/blob/main/presentations/presentations.bib\"\
    >exhaustive list of Celeritas presentations\n</a>\nauthored by (or with content\
    \ authored by) core team members is available in our\ndocuments repo.</p>\n"
  stargazers_count: 45
  subscribers_count: 11
  topics:
  - hep
  - cuda
  - computational-physics
  - monte-carlo
  updated_at: 1699860485.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<h1><a id=\"user-content-d-seams\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#d-seams\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>d-SEAMS</h1>\n<p><strong>Deferred Structural Elucidation\
    \ Analysis for Molecular Simulations</strong></p>\n<p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82b492dd4f94cd6fe1783f1065487d3dbc0602c2a65b1717a5613df3b6e8f65f/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <h1><a id=\"user-content-citation\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#citation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citation</h1>\n<ul>\n<li>\n<p>This has been published at the <a href=\"\
    https://doi.org/10.1021/acs.jcim.0c00031\" rel=\"nofollow\">Journal of Chemical\
    \ Information and Modeling\n(JCIM)</a></p>\n</li>\n<li>\n<p>You may also read\
    \ <a href=\"https://arxiv.org/abs/1909.09830\" rel=\"nofollow\">the preprint on\
    \ arXiv</a></p>\n</li>\n</ul>\n<p>If you use this software please cite the following:</p>\n\
    <pre><code>Goswami, R., Goswami, A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred\
    \ Structural Elucidation Analysis for Molecular Simulations. Journal of Chemical\
    \ Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n</code></pre>\n\
    <p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<h1><a id=\"\
    user-content-compilation\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\"\
    \ href=\"#compilation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Compilation</h1>\n<p>We use a deterministic build system to generate\
    \ both bug reports and uniform\nusage statistics. This also handles the <code>lua</code>\
    \ scripting engine.</p>\n<p>\\note The lua functions are documented on the <a\
    \ href=\"https://docs.dseams.info/md_markdown_luafunctions\" rel=\"nofollow\"\
    >on the API Docs</a></p>\n<p>We also provide a <code>conda</code> environment\
    \ as a fallback, which is also recommended for MacOS users.</p>\n<h2><a id=\"\
    user-content-build\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build</h2>\n\
    <h3><a id=\"user-content-conda-working-now\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#conda-working-now\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Conda (working now)</h3>\n<p>Although we strongly\
    \ suggest using <code>nix</code>, for MacOS systems, the following\ninstructions\
    \ may be more suitable. We will assume the presence of <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\"\
    \ rel=\"nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-k\">~</span>/seams-core\n\
    micromamba create -f environment.yml\nmicromamba activate dseams\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Now the installation can proceed.</p>\n<p>\\note\
    \ we do not install <code>lua-luafilesystem</code> within the <code>conda</code>\
    \ environment because it is outdated on <code>osx</code></p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>mkdir build\n<span class=\"pl-c1\">cd</span> build\n\
    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span\
    \ class=\"pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake\
    \ install\n<span class=\"pl-smi\">$CONDA_PREFIX</span>/bin/yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<h3><a\
    \ id=\"user-content-spack-not-working-at-the-moment\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#spack-not-working-at-the-moment\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack (not working at the moment)</h3>\n\
    <p>Manually this can be done in a painful way as follows:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack install eigen@3.3.9 lua@5.2\nspack install\
    \ catch2 fmt yaml-cpp openblas boost cmake ninja meson\nspack load catch2 fmt\
    \ yaml-cpp openblas boost cmake ninja meson eigen@3.3.9 lua@5.2\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span\
    \ class=\"pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> After loading the packages</span>\nluarocks install luafilesystem</pre></div>\n\
    <p>Now we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<h3><a id=\"user-content-nix-not-working-at-the-moment\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#nix-not-working-at-the-moment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Nix (not\
    \ working at the moment)</h3>\n<p>Since this project is built with <code>nix</code>,\
    \ we can simply do the following from the\nroot directory (longer method):</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Make sure there are no artifacts</span>\nrm -rf build\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This will take a long time\
    \ the first time as it builds the dependencies</span>\nnix-build <span class=\"\
    pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>A faster method of building the software is by using the <a href=\"https://dseams.cachix.org/\"\
    \ rel=\"nofollow\">cachix binary cache</a> as shown:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install cachix</span>\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Use the binary cache</span>\n\
    cachix use dseams\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with\
    \ the cache than building from scratch</span>\nnix-build <span class=\"pl-c1\"\
    >.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <h3><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Usage</h3>\n<p>Having installed the <code>yodaStruct</code> binary\
    \ and library, we can now use it.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>yodaStruct -c lua_inputs/config.yml</pre></div>\n<p>\\note The paths in\
    \ the <code>.yml</code> should be <strong>relative to the folder from which the\
    \ binary is called</strong>.</p>\n<p>If you're confused about how to handle the\
    \ relative paths, run the command <code>yodaStruct -c lua_inputs/config.yml</code>\
    \ in the top-level directory, and set the paths relative to the top-level directory.\
    \ This is the convention used in the examples as well.</p>\n<h3><a id=\"user-content-language-server-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#language-server-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Language\
    \ Server Support</h3>\n<p>To generate a <code>compile_commands.json</code> file\
    \ for working with a language server\nlike <a href=\"https://github.com/MaskRay/ccls\"\
    >ccls</a> use the following commands:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\n\
    nix-shell --pure\nmkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span\
    \ class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES\
    \ ../\ncp compile_commands.json ../</pre></div>\n<p>Note that there is no need\
    \ to actually compile the project if you simply need to\nget the compiler database\
    \ for the language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<h2><a id=\"user-content-development\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#development\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Development</h2>\n<p>We can simply use the <code>nix</code>\
    \ environment:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> From the project root</span>\n\
    nix-shell --pure</pre></div>\n<h1><a id=\"user-content-running\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#running\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n<p>This is built\
    \ completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install systemwide\n\
    nix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply install the\
    \ software, and ensure that <code>input/</code> is a child directory.</p>\n<pre\
    \ lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<h2><a id=\"user-content-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#tests\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tests</h2>\n\
    <p>Apart from the <a href=\"https://docs.dseams.info/pages.html\" rel=\"nofollow\"\
    >examples</a>, the test-suite\ncan be run with the <code>yodaStruct_test</code>\
    \ binary, which will drop into the\n<code>nix</code> environment before building\
    \ and executing <code>gdb</code>:</p>\n<pre lang=\"{bash}\"><code># Just run this\n\
    ./testBuild.sh\n# At this point the binary and library are copied into the root\n\
    # One might, in a foolhardy attempt, use gdb at this point\n# Here be dragons\
    \ :)\n# USE NIX\n# Anyway\ngdb --args ./yodaStruct -c lua_inputs/config.yml\n\
    # quit gdb with quit\n# Go run the test binary\ncd shellBuild\n./yodaStruct_test\n\
    </code></pre>\n<p>Do note that the regular installation via <code>nix-env</code>\
    \ runs the tests before the installation</p>\n<h1><a id=\"user-content-developer-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#developer-documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developer\
    \ Documentation</h1>\n\n<p>While developing, it is sometimes expedient to update\
    \ the packages used. It is\nthen useful to note that we use <a href=\"https://github.com/nmattia/niv/\"\
    >niv</a> to handle our pinned packages (apart from\nthe ones built from Github).\
    \ Thus, one might need, say:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>niv update nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with\
    \ nix:</p>\n<div class=\"highlight highlight-source-shell\"><pre>nix-build <span\
    \ class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Outputs are in ./result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ If you get a CMake error</span>\nrm -rf build\nnix-store --delete /nix/store/<span\
    \ class=\"pl-smi\">$whatever</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> $whatever is the derivation complaining</span>\nnix-collect-garbage\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> then try again [worst case\
    \ scenario]</span></pre></div>\n<h2><a id=\"user-content-leaks-and-performance\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#leaks-and-performance\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Leaks and\
    \ performance</h2>\n<p>While testing for leaks, use <code>clang</code> (for\n\
    <a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\">AddressSanitizer</a>\n\
    and\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<h1><a id=\"user-content-overview\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#overview\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h1>\n\
    <p>As of Mon Jan 20 15:57:18 2020, the lines of code calculated by\n<a href=\"\
    http://cloc.sourceforge.net/\" rel=\"nofollow\">cloc</a> are as follows:</p>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"\
    ><img src=\"images/cloc-2020-01-20_15-56.png\" alt=\"Cloc Lines\" style=\"max-width:\
    \ 100%;\"></a></p>\n<h1><a id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Contributing</h1>\n<p>Please ensure that all\
    \ contributions are formatted according to the\n<a href=\"./clang-format\">clang-format</a>\
    \ configuration file.</p>\n<p>Specifically, consider using the following:</p>\n\
    <ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\">Sublime\
    \ Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"https://github.com/lassik/emacs-format-all-the-code\"\
    >format-all</a> for Emacs</p>\n</li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\"\
    >vim-clang-format</a> for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <h2><a id=\"user-content-commit-hook\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#commit-hook\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Commit Hook</h2>\n<p>Note that we expect compliance with the <code>clang-format</code>\
    \ as mentioned above, and this may be enforced by using the provided scripts for\
    \ a pre-commit hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<h2><a id=\"user-content-development-builds\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#development-builds\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development\
    \ Builds</h2>\n<p>The general idea is to drop into an interactive shell with the\
    \ dependencies and then use <code>cmake</code> as usual.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>nix-shell --pure --run bash --show-trace --verbose\n\
    <span class=\"pl-c1\">cd</span> build\ncmake .. -DCMAKE_BUILD_TYPE=Debug -DNO_WARN=TRUE\
    \ \\\n -DFIND_EIGEN=TRUE \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n -G <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Ninja<span class=\"pl-pds\">\"\
    </span></span>\nninja\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Test</span>\n\
    <span class=\"pl-c1\">cd</span> ../\nyodaStruct -c lua_inputs/config.yml\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Debug</span>\ngdb --args yodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>To load debugging symbols from the\
    \ shared library, when you are inside <code>gdb</code> (from the top-level directory,\
    \ for instance), use the following command:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>add-symbol-file build/libyodaLib.so</pre></div>\n<p>Then you can set breakpoints\
    \ in the C++ code; for instance:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>b seams_input.cpp:408</pre></div>\n<h1><a id=\"user-content-acknowledgements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#acknowledgements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h1>\n\
    <p>The following tools are used in this project:</p>\n<ul>\n<li>\n<a href=\"https://cmake.org/\"\
    \ rel=\"nofollow\">CMake</a> for compilation (<a href=\"https://github.com/cginternals/cmake-init\"\
    >cmake-init</a> was used as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\"\
    \ rel=\"nofollow\">Clang</a> because it is more descriptive with better tools</li>\n\
    <li>\n<a href=\"https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the\
    \ developer API</li>\n<li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\"\
    \ rel=\"nofollow\">clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"\
    https://github.com/barisione/clang-format-hooks\">clang-format-hooks</a> for <code>git</code>\
    \ hooks to enforce formatting</li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\"\
    \ rel=\"nofollow\">lua</a> for the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\"\
    \ rel=\"nofollow\">yaml</a> for the configuration</li>\n</ul>\n<h2><a id=\"user-content-third-party-libraries\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#third-party-libraries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Third Party\
    \ Libraries</h2>\n<p>The libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n<li>\n<a href=\"https://github.com/renatoGarcia/icecream-cpp\"\
    >icecream-cpp</a> for pretty-printing and debugging</li>\n</ul>\n"
  stargazers_count: 32
  subscribers_count: 5
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1699251640.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - hmmer-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<h1><a id="user-content-benchmark-containers" class="anchor" aria-hidden="true"
    tabindex="-1" href="#benchmark-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Benchmark Containers</h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
eflows4hpc/workflow-registry:
  data_format: 2
  description: Registry to store workflow descriptions
  filenames:
  - minimal_workflow/wordcount/spack.yaml
  - Pillar_II/esm/spack.yaml
  - tutorial/lysozyme/spack.yaml
  - kaust/exageostat/spack.yaml
  full_name: eflows4hpc/workflow-registry
  latest_release: 2nd_stack_release
  readme: "<h1><a id=\"user-content-workflow-registry\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#workflow-registry\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Workflow Registry</h1>\n<p>This is\
    \ a repository to store the Workflow descriptions using the eFlows4HPC methodology.\
    \ This description consist of at least the TOSCA description of the worklfow,\
    \ the code of the their different steps and their required software per step.</p>\n\
    <h2><a id=\"user-content-repository-structure\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#repository-structure\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Repository structure</h2>\n<p>Workflow\
    \ descriptions have to be included inside this repository according to the following\
    \ structure.</p>\n<pre><code>workflow-registry\n  |- workflow_1\n  |    |- tosca\n\
    \  |    |    |- types.yml               TOSCA description of the different components\
    \ involved in the workflow\n  |    |       ... \n  |    |- step_1\n  |    |  \
    \  |- spack.yml               Sofware requirements for this workflow step as a\
    \ Spack environment specification \n  |    |    |- src                     PyCOMPSs\
    \ code of the workflow step\n  |    |       ...\n  |    |- step_2\n  |       \
    \  ....\n  |- workflow_2                                \n  |\t...\n\n</code></pre>\n\
    <h2><a id=\"user-content-including-new-workflows\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#including-new-workflows\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Including new Workflows</h2>\n\
    <p>To include new workflows in the repository, first create a new fork of the\
    \ repository and  include a new folder for the workflow with a subfolder for the\
    \ TOSCA description and the different workflow steps. Finally, create a pull request\
    \ with the new workflow description. This pull request will be reviewed and included\
    \ in the repository.</p>\n"
  stargazers_count: 2
  subscribers_count: 10
  topics: []
  updated_at: 1675113861.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - env-bipp-izar/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<h1><a id="user-content-ska-spack-env" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a>ska-spack-env</h1>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
epfl-scitas/spack-sdploy:
  data_format: 2
  description: Toolset to deploy software stacks
  filenames:
  - samples/spack.yaml
  full_name: epfl-scitas/spack-sdploy
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-sdploy\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#spack-sdploy\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>spack-sdploy</h1>\n<p>Spack extension for automatic\
    \ package configuration and deployment.</p>\n<h2><a id=\"user-content-how-to-install\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-to-install\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to install</h2>\n\
    <p>You can try out this Spack extension be executing 4 easy steps:</p>\n<ul>\n\
    <li>Set up and activate a local python environment</li>\n<li>Set up and activate\
    \ <code>spack</code>\n</li>\n<li>Install <code>spack-sdploy</code> dependencies</li>\n\
    <li>Clone and configure spack-sdploy</li>\n</ul>\n<p>This 4 steps are now detailed\
    \ in the next section.</p>\n<h3><a id=\"user-content-step-by-step-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-by-step-installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step-by-step\
    \ installation</h3>\n<p>Just for a matter of completeness, all the steps needed\
    \ get up and running with\nspack-sdploy extension will be covered, which can be\
    \ a bit pedantic.</p>\n<h4><a id=\"user-content-set-up-and-activate-a-local-python-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#set-up-and-activate-a-local-python-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Set up and\
    \ activate a local python environment</h4>\n<p>It is recommended that a Python\
    \ environment be used to support sdploy. This same\nPython can also be used to\
    \ run Spack.</p>\n<pre><code>python3 -m venv &lt;path-to-environment-directory&gt;\n\
    . &lt;path-to-environment-directory&gt;/bin/activate\n</code></pre>\n<p>For more\
    \ information on how to create a virtual environment in Python refer to\nthe PEP\
    \ 405 \u2013 Python Virtual Environments documentation.</p>\n<h4><a id=\"user-content-set-up-and-activate-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#set-up-and-activate-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Set up and\
    \ activate Spack</h4>\n<p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">Spack documentation</a>\non how to install Spack. For sake\
    \ of completeness, we copy paste the commands here:</p>\n<pre><code>git clone\
    \ -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n\
    </code></pre>\n<h4><a id=\"user-content-install-spack-sdploy-dependencies\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#install-spack-sdploy-dependencies\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Install\
    \ <code>spack-sdploy</code> dependencies</h4>\n<p>Up to now the only dependency\
    \ of spack-sdploy if jinja2. Once you have activated\nPython environment, you\
    \ can simply use pip to install the packages.</p>\n<pre><code>pip install jinja2\n\
    </code></pre>\n<h4><a id=\"user-content-clone-and-configure-spack-sdploy\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#clone-and-configure-spack-sdploy\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Clone and\
    \ configure spack-sdploy</h4>\n<pre><code>git clone git@github.com:epfl-scitas/spack-sdploy\n\
    </code></pre>\n<p>To activate the spack-sdploy extension you must add it to the\
    \ config.yaml. If\nyou already have another Spack installation and just want to\
    \ try out\nspack-sdploy may very well create a temporary directory to store the\n\
    configuration and then use the SPACK_USER_CONFIG_PATH variable to point this new\n\
    directory.</p>\n<pre><code>mkdir temporary_config\nexport SPACK_USER_CONFIG_PATH=/path/to/temporary_config\n\
    </code></pre>\n<p>and then, inside the temporary_config directory, write a config.yaml\
    \ file with\nthe following contents:</p>\n<pre><code>config:\n  extensions:\n\
    \  - /path/to/spack-sdploy\n</code></pre>\n<p>Be sure you do not change the spack-dploy\
    \ directory. Spack forces the extensions\nto follow strict rules. Please see the\n\
    <a href=\"https://spack.readthedocs.io/en/latest/extensions.html\" rel=\"nofollow\"\
    >Spack Extensions</a>\ndocumentation for more details about this subject. At this\
    \ point you should now\nbe able to call <code>spack -h</code> and see the new\
    \ Spack commands deployed by the\nspack-sdploy extension.</p>\n<h2><a id=\"user-content-how-to-use\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-to-use\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to use</h2>\n\
    <p>At the present time, spack-sdploy will add 2 commands to your already existing\n\
    Spack commands. These commandes are:</p>\n<pre><code>spack write-spack-yaml\n\
    spack write-packages-yaml\n</code></pre>\n<p>In the future we may change the names\
    \ of these commands, but for now lets just\nimagine these are short and easy to\
    \ type commands.</p>\n<p>As you may have guessed it (if you haven't that's ok),\
    \ write-spack-yaml will\nwrite the spack.yaml file and write-packages-yaml will\
    \ write the packages.yaml\nfile. Of course, Spack does not (yet!) guess what you\
    \ may want to install and\nfor that purpose, both these commands will read all\
    \ the specs you want in your\nspack.yaml file by reading another file you have\
    \ previously written and which\nwe call by stack.yaml.</p>\n<p>For the time being,\
    \ spack-sdploy already comes with a dummy stack.yaml so we can\nget started using\
    \ the new commands.</p>\n<h2><a id=\"user-content-write-spack-yaml\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#write-spack-yaml\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>write-spack-yaml</h2>\n\
    <pre><code>spack write-spack-yaml\n</code></pre>\n<h2><a id=\"user-content-write-packages-yaml\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#write-packages-yaml\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>write-packages-yaml</h2>\n\
    <pre><code>spack write-packages-yaml\n</code></pre>\n<h2><a id=\"user-content-write-activate-list\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#write-activate-list\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>write-activate-list</h2>\n\
    <pre><code>spack write-activate-list -p &lt;platform&gt; -s &lt;stack&gt;\n</code></pre>\n\
    <p>Write to file named <code>packages_to_activate</code> list of packages to activate,\
    \ using <code>spack activate &lt;package&gt;</code>. Packages are writen one per\
    \ line.</p>\n<p>Packages to activate can be marked in the stack file in two possible\
    \ ways: by adding the keyword <code>activate: true</code> in the metadata section\
    \ of a list of packages or by adding the keyword <code>activate: true</code> to\
    \ an individual package. Duplicates are removed.</p>\n"
  stargazers_count: 0
  subscribers_count: 9
  topics: []
  updated_at: 1669125412.0
esm-tools/esm_tools:
  data_format: 2
  description: Simple Infrastructure for Earth System Simulations
  filenames:
  - configs/spack_envs/albedo-spack.yaml
  full_name: esm-tools/esm_tools
  latest_release: v6.0.0
  stargazers_count: 22
  subscribers_count: 8
  topics: []
  updated_at: 1700171022.0
eth-cscs/spack-batteries-included:
  data_format: 2
  description: Installing spack without system dependencies
  filenames:
  - build/3_more_tools/spack.yaml
  full_name: eth-cscs/spack-batteries-included
  latest_release: develop
  readme: "<p><a href=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml\"\
    ><img src=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\"\
    \ alt=\"Update spack develop version\" style=\"max-width: 100%;\"></a></p>\n<h1><a\
    \ id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#-spack-with-batteries-included-linuxx86_64\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\U0001F50B\
    \ Spack with batteries included (linux/x86_64)</h1>\n<p><a href=\"https://github.com/spack/spack\"\
    >Spack</a> is a package manager, and package managers should be trivial to install.</p>\n\
    <p>This repo offers a single, static executable for Spack:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">wget -qO\
    \ spack.x https://github.com/eth-cscs/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n\
    $ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x\
    \ install curl tls=mbedtls</span></pre></div>\n<h2><a id=\"user-content-what-version-of-spack-is-shipped\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#what-version-of-spack-is-shipped\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What version\
    \ of Spack is shipped?</h2>\n<p>The URL above gives you a rolling release of Spack's\
    \ develop branch, which is updated\nhourly. The exact commit SHA is included as\
    \ a file and can be retrieved like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"\
    pl-k\">&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints\
    \ the Spack commit sha]</span></pre></div>\n<h2><a id=\"user-content-supported-platforms\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#supported-platforms\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ platforms</h2>\n<ul>\n<li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n\
    <li>Debian 8 and above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and\
    \ above</li>\n<li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for\
    \ Linux 2 with any of the above distro's.</li>\n</ul>\n<p>The system dependencies\
    \ are <code>glibc 2.17</code> and above and optionally the <code>fusermount</code>\n\
    executable. If your system supports rootless containers it likely has <code>fusermount</code>\n\
    installed already!</p>\n<h2><a id=\"user-content-how-does-it-work\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-does-it-work\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How does it work?</h2>\n<p><code>spack.x</code>\
    \ consists of a modified version of the AppImage runtime concatenated\nwith a\
    \ big squashfs file which includes <code>binutils</code>, <code>bzip2</code>,\
    \ <code>clingo</code>, <code>curl</code>,\n<code>file</code>, <code>git</code>,\
    \ <code>gmake</code>, <code>gpg</code>, <code>gzip</code>, <code>openssl</code>,\
    \ <code>patch</code>, <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>,\
    \ <code>tar</code>, <code>unzip</code>, <code>xz</code>, <code>zstd</code> and\
    \ their dependencies.</p>\n<p>When you run <code>spack.x [args]</code> it will\
    \ use <code>fusermount</code> to\nmount this squashfs file in a temporary directory,\
    \ and then execute the\nentrypoint executable <a href=\"build/6_spack/spack\"\
    >spack</a>.</p>\n<p>The <code>spack</code> executable sets some environment variables\
    \ like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code> to the bin and lib\
    \ folders of the squashfs file, and then it\nexecutes <code>python3 spack_src/bin/spack\
    \ [args]</code>.</p>\n<p>When the command is done running, the runtime unmounts\
    \ the squashfs file again.</p>\n<h2><a id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>My system\
    \ doesn't allow me to use <code>fusermount</code>, what now?</h2>\n<p><code>fusermount</code>\
    \ is used to mount a squashfs file included in the binary. If you\ndon't want\
    \ that, you can just extract it:</p>\n<pre><code>$ spack.x --squashfs-extract\n\
    $ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\
    </code></pre>\n<p>but working with the extracted <code>spack</code> folder can\
    \ come with a performance\npenalty on shared filesystems in HPC centers.</p>\n\
    <h2><a id=\"user-content-differences-and-improvements-over-appimage-runtime\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#differences-and-improvements-over-appimage-runtime\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Differences\
    \ and improvements over AppImage runtime</h2>\n<ul>\n<li>spack.x uses <code>zstd</code>\
    \ for faster decompression;</li>\n<li>spack.x itself is an entirely static binary;</li>\n\
    <li>spack.x does not need to dlopen libfuse.so.</li>\n</ul>\n<h2><a id=\"user-content-troubleshooting\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#troubleshooting\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Troubleshooting</h2>\n\
    <p><strong>immutability</strong> The squashfs mountpoint is a readonly folder,\
    \ meaning that\nspack can't write to spack/{var,opt} folders. spack.x is configured\
    \ to use some\nnon-standard directories, see <code>spack.x config blame config</code>\
    \ for details.</p>\n<p>Note, spack.x applies <a href=\"https://github.com/spack/spack/pull/20158/\"\
    >this patch</a>\nto ensure that log files are written to the <code>config:misc_cache</code>\
    \ folder.</p>\n<p><strong>openssl</strong>: By default spack.x uses <code>ca-certificates-mozilla</code>\
    \ for downloading\npackage sources over https. If you somehow need to use system\
    \ certificates,\nset <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAINFO</code>\
    \ or <code>SSL_CERT_FILE</code> and <code>GIT_SSL_CERT</code>.</p>\n<h2><a id=\"\
    user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#can-i-run-spackx-inside-a-container\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Can I run spack.x inside a container?</h2>\n\
    <p>Yes, but please don't! Since <code>fusermount</code> is a setuid binary, you\
    \ will need to\nrun a privileged container, which is never a good idea.</p>\n\
    <p>The recommended way to run spack.x inside a container is to just extract it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >spack.x --squashfs-extract</span>\n$ <span class=\"pl-s1\">./spack/spack --version</span></pre></div>\n\
    <p>If you insist on running spack.x in Docker, this is one way to do it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >sudo docker run --privileged --device /dev/fuse -it -v <span class=\"pl-smi\"\
    >$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n# <span class=\"pl-s1\"\
    >apt update <span class=\"pl-k\">&amp;&amp;</span> apt install fuse <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n# <span\
    \ class=\"pl-s1\">spack.x --version</span></pre></div>\n<h2><a id=\"user-content-running-an-executable-shipped-with-spackx-directly\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#running-an-executable-shipped-with-spackx-directly\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ an executable shipped with spack.x directly</h2>\n<p>If you want to run an executable\
    \ shipped with <code>spack.x</code> directly instead\nof invoking spack (the default\
    \ entrypoint), try this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x which python</span>\n<span\
    \ class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n\
    <hr>\n<h2><a id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-do-i-build-spackx-myself\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How do I\
    \ build spack.x myself?</h2>\n<p>Initially you may need docker to get a rootfs\
    \ filesystem for centos 7.</p>\n<p>Building goes like this:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">make rootfs-with-spack</span>\n\
    <span class=\"pl-c1\">make</span></pre></div>\n<p>You'll find the output in</p>\n\
    <pre><code>build/output\n</code></pre>\n"
  stargazers_count: 22
  subscribers_count: 3
  topics:
  - spack
  - squashfs
  - libfuse
  updated_at: 1683613383.0
eth-cscs/spack-stack:
  data_format: 2
  description: fast spack builds on slow filesystem
  filenames:
  - packages/nvhpc/spack.yaml
  - recipe/nvhpc.spack.yaml
  full_name: eth-cscs/spack-stack
  latest_release: null
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1684144105.0
eugeneswalker/exawind-containers:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/exawind-containers
  latest_release: null
  readme: '<h2><a id="user-content-working-with-the-docker-image-ecpe4sexawindlatest"
    class="anchor" aria-hidden="true" tabindex="-1" href="#working-with-the-docker-image-ecpe4sexawindlatest"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Working with the Docker
    image (ecpe4s/exawind:latest)</h2>

    <ol>

    <li>Build the Docker image</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Launch a container from the image</li>

    </ol>

    <pre><code>$&gt; docker run -it --rm ecpe4s/exawind


    root@8df184bdac63:/# which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    root@8df184bdac63:/# which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2><a id="user-content-working-with-the-singularity-image-exawindsif" class="anchor"
    aria-hidden="true" tabindex="-1" href="#working-with-the-singularity-image-exawindsif"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Working with the Singularity
    image (exawind.sif)</h2>

    <ol>

    <li>Build the Docker image:</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Save the Docker image as a docker-archive</li>

    </ol>

    <pre><code>$&gt; docker save -o exawind.tar ecpe4s/exawind:latest

    </code></pre>

    <ol start="3">

    <li>Build the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./build-singularity-image.sh

    </code></pre>

    <ol start="4">

    <li>Run the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./exawind.sif


    Exawind Singularity&gt; which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    Exawind Singularity&gt; which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2><a id="user-content-run-selected-exawind-regression-tests" class="anchor"
    aria-hidden="true" tabindex="-1" href="#run-selected-exawind-regression-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run Selected ExaWind
    Regression Tests</h2>

    <ol>

    <li>

    <p>Launch a container using either the Docker or Singularity image (see above)</p>

    </li>

    <li>

    <p>Clone this repository in the newly launched container and run the tests (here
    illustrated with Singularity)</p>

    </li>

    </ol>

    <pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers
    ~/exawind-containers

    Exawind Singularity&gt; cd ~/exawind-containers/demo



    Exawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh

    PASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15



    Exawind Singularity&gt; ./run-nalu-wind-tests.sh

    PASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11

    PASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13

    ...



    Exawind Singularity&gt; ./run-amr-wind-tests.sh

    finished abl_bndry_output

    finished abl_godunov

    ...

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1626420401.0
eugeneswalker/llvm-containers:
  data_format: 2
  description: null
  filenames:
  - x86_64/spack.yaml
  full_name: eugeneswalker/llvm-containers
  latest_release: null
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1615486265.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - oneapi/failures/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675202595.0
giordano/julia-on-fugaku:
  data_format: 2
  description: null
  filenames:
  - benchmarks/blas-axpy/spack-env/spack.yaml
  full_name: giordano/julia-on-fugaku
  latest_release: null
  readme: "<h1><a id=\"user-content-julia-on-fugaku-2022-07-23\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#julia-on-fugaku-2022-07-23\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Julia on Fugaku\
    \ (2022-07-23)</h1>\n<p><em>Note: many links refer to internal documentation which\
    \ is accessible only to Fugaku users.</em></p>\n<h2><a id=\"user-content-read-the-paper\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#read-the-paper\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Read the\
    \ paper</h2>\n<p>Benchmarks present in this repository have been published in\
    \ the paper <a href=\"https://doi.org/10.1109/CLUSTER51413.2022.00072\" rel=\"\
    nofollow\">Productivity meets\nPerformance: Julia on A64FX</a>, presented at\n\
    the 2022 IEEE International Conference on Cluster Computing (CLUSTER22), as part\
    \ of the\n<a href=\"https://arm-hpc-user-group.github.io/eahpc-2022/\" rel=\"\
    nofollow\">Embracing Arm for High Performance Computing\nWorkshop</a> (pre-print\
    \ available on arXiv:\n<a href=\"https://arxiv.org/abs/2207.12762\" rel=\"nofollow\"\
    ><code>2207.12762</code></a>).  See the <a href=\"./CITATION.bib\"><code>CITATION.bib</code></a>\n\
    file for a BibTeX entry to cite the paper.</p>\n<h2><a id=\"user-content-storage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#storage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Storage</h2>\n\
    <p>Before doing anything on Fugaku, be aware that there are <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20220408_01\"\
    \ rel=\"nofollow\">tight\nlimits</a> on the size of (20 GiB)\nand the number of\
    \ inodes in (200k) your home directory.  If you use many Julia Pkg\nartifacts,\
    \ it's very likely you'll hit these limits.  You'll notice that you hit the limit\n\
    because any disk I/O operation will result in a <code>Disk quota exceeded</code>\
    \ error like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-e\">[user@fn01sv03 ~]</span>$ <span class=\"pl-s1\">touch\
    \ foo</span>\n<span class=\"pl-c1\">touch: cannot touch 'foo': Disk quota exceeded</span></pre></div>\n\
    <p>You can check the quota of your home directory with <code>accountd</code> for\
    \ the size, and <code>accountd -i</code> for the number of inodes.</p>\n<h3><a\
    \ id=\"user-content-using-the-data-directory\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#using-the-data-directory\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using the data directory</h3>\n\
    <p>In order to avoid clogging up the home directory you may want to move the Julia\
    \ depot to the\ndata directory:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>DATADIR=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/data/&lt;YOUR\
    \ GROUP&gt;/<span class=\"pl-smi\">${USER}</span><span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-k\">export</span> JULIA_DEPOT_PATH=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span><span class=\"pl-smi\">${DATADIR}</span>/julia-depot<span\
    \ class=\"pl-pds\">\"</span></span></pre></div>\n<h2><a id=\"user-content-interactive-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#interactive-usage\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Interactive\
    \ usage</h2>\n<p>The login nodes you access via <code>login.fugaku.r-ccs.riken.jp</code>\
    \ (<a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/AccessToTheSystem/LoggingInToTheFugakuComputerWithLocalAccount.html\"\
    \ rel=\"nofollow\">connection\ninstructions</a>)\nhave Cascade Lake CPUs, so they\
    \ aren't much useful if you want to run an aarch64 Julia.</p>\n<p>You can <a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/Overview.html\"\
    \ rel=\"nofollow\">submit jobs to the\nqueue</a>\nto run Julia code on the A64FX\
    \ compute nodes, but this can be cumbersone if you need quick\nfeedback during\
    \ development or debugging.  You can also request an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/InteractiveJob.html\"\
    \ rel=\"nofollow\">interactive\nnode</a>,\nfor example with:</p>\n<pre><code>pjsub\
    \ --interact -L \"node=1\" -L \"rscgrp=int\" -L \"elapse=30:00\" --sparam \"wait-time=600\"\
    \ --mpi \"max-proc-per-node=4\"\n</code></pre>\n<h2><a id=\"user-content-available-software\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#available-software\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Available\
    \ software</h2>\n<p>Fugaku uses the <a href=\"https://spack.io/\" rel=\"nofollow\"\
    >Spack package manager</a>.  For more information about how\nto use it, see the\
    \ <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/FugakuSpackGuide/\"\
    \ rel=\"nofollow\">Fugaku Spack User\nGuide</a>.</p>\n<p>Note that Spack is installed\
    \ in <code>/vol0004</code>, this means that if your home directory isn't\nmounted\
    \ on this volume you will have to <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20211130_02\"\
    \ rel=\"nofollow\">explicitly request the\npartition</a> in your submission\n\
    job scripts or commands, for example by adding <code>-x PJM_LLIO_GFSCACHE=/vol0004</code>\
    \ to the\n<code>pjsub</code> command, or the line</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>PJM\
    \ -x PJM_LLIO_GFSCACHE=/vol0004</span></pre></div>\n<p>in a job script.</p>\n\
    <h2><a id=\"user-content-using-julia-on-the-compute-nodes\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#using-julia-on-the-compute-nodes\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using Julia on the compute nodes</h2>\n\
    <p>There is a Julia module built with Spack <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/UsingOSS/oss_e.html#packages-installed-on-the-compute-nodes\"\
    \ rel=\"nofollow\">available on the compute\nnodes</a>,\nbut as of this writing\
    \ (2022-07-23) the version of Julia provided is 1.6.3, so you may want\nto download\
    \ a more recent version from the <a href=\"https://julialang.org/downloads/\"\
    \ rel=\"nofollow\">official\nwebsite</a>.  Use the <code>aarch64</code> builds\
    \ for Glibc Linux,\npreferably <a href=\"https://julialang.org/downloads/#current_stable_release\"\
    \ rel=\"nofollow\">latest stable</a> or even\nthe <a href=\"https://julialang.org/downloads/nightlies/\"\
    \ rel=\"nofollow\">nightly build</a> if you feel confident.</p>\n<p>To enable\
    \ full vectorisation you may need to set the environment variable\n<code>JULIA_LLVM_ARGS=\"\
    -aarch64-sve-vector-bits-min=512\"</code>.  Example:\n<a href=\"https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\"\
    >https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623</a>. \
    \ However, note that\nare a couple of severe bugs when using 512-bit vectors:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/JuliaLang/julia/issues/44401\">https://github.com/JuliaLang/julia/issues/44401</a>\
    \ (may be an upstream LLVM bug:\n<a href=\"https://github.com/llvm/llvm-project/issues/53331\"\
    >https://github.com/llvm/llvm-project/issues/53331</a>)</li>\n<li>\n<a href=\"\
    https://github.com/JuliaLang/julia/issues/44263\">https://github.com/JuliaLang/julia/issues/44263</a>\
    \ (only in Julia v1.8+)</li>\n</ul>\n<p><em><strong>Note</strong></em>: Julia\
    \ v1.9, which is based on <a href=\"https://community.arm.com/arm-community-blogs/b/tools-software-ides-blog/posts/llvm-14\"\
    \ rel=\"nofollow\">LLVM\n14</a>,\nis able to natively autovectorise code for A64FX\
    \ <em>without</em> having to set\n<code>JULIA_LLVM_ARGS</code>, side stepping\
    \ the issues above altogether.</p>\n<h2><a id=\"user-content-mpijl\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#mpijl\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>MPI.jl</h2>\n<p><a href=\"https://github.com/JuliaParallel/MPI.jl\"\
    ><code>MPI.jl</code></a> with default JLL-provided MPICH works\nout of the box!\
    \  In order to\n<a href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\"\
    \ rel=\"nofollow\">configure</a> <code>MPI.jl</code> v0.19 to\nuse system-provided\
    \ Fujitsu MPI (based on OpenMPI) you have to specify the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/CompileCommands.html\"\
    \ rel=\"nofollow\">MPI C\ncompiler</a>\nfor A64FX with</p>\n<pre><code>julia --project\
    \ -e 'ENV[\"JULIA_MPI_BINARY\"]=\"system\"; ENV[\"JULIA_MPICC\"]=\"mpifcc\"; using\
    \ Pkg; Pkg.build(\"MPI\"; verbose=true)'\n</code></pre>\n<p><em><strong>Note #1</strong></em>:\
    \ <code>mpifcc</code> is available only on the compute nodes.  On the login nodes\
    \ that would be\n<code>mpifccpx</code>, but this is the cross compiler running\
    \ on Intel architecture, it's unlikely\nyou'll run an <code>aarch64</code> Julia\
    \ on there.  <a href=\"https://github.com/JuliaParallel/MPI.jl/issues/539\">Preliminary\n\
    tests</a> show that <code>MPI.jl</code> should work\nmostly fine with Fujitsu\
    \ MPI, but custom error handlers may not be available (read: trying\nto use them\
    \ causes segmentation faults).</p>\n<p><em><strong>Note #2</strong></em>: in <code>MPI.jl</code>\
    \ v0.20 Fujitsu MPI is a known ABI (it's the same as OpenMPI) and\nthere is nothing\
    \ special to do to configure it apart from <a href=\"https://juliaparallel.org/MPI.jl/dev/configuration/#Configuration-2\"\
    \ rel=\"nofollow\">choosing the system\nbinaries</a>.</p>\n<p><em><strong>Note\
    \ #3</strong></em>: we recommend using <code>MPI.jl</code>'s wrapper of <code>mpiexec</code>\
    \ to run MPI applications\nwith Julia:\n<a href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Julia-wrapper-for-mpiexec\"\
    \ rel=\"nofollow\"><code>mpiexecjl</code></a>.</p>\n<h3><a id=\"user-content-file-system-latency\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#file-system-latency\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>File system\
    \ latency</h3>\n<p>Fugaku has an advanced system to handle <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/index.html\"\
    \ rel=\"nofollow\">parallel file system\nlatency</a>.\nIn order.  In order to\
    \ speed up parallel applications run through MPI you may want to\ndistribute it\
    \ to the cache area of the second-layer storage on the first-layer storage using\n\
    <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/TheSecondLayerStrage.html#common-file-distribution-function-llio-transfer\"\
    \ rel=\"nofollow\"><code>llio_transfer</code></a>.\nIn particular, if you're using\
    \ Julia, you likely want to distribute the <code>julia</code> executable\nitself\
    \ together with its installation bundle.</p>\n<p>For example, assuming that you\
    \ are using the official binaries from the website, instead of\nthe Julia module\
    \ provided by Spack, you can do the following:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Directory for log of\
    \ `llio_transfer` and its wrapper `dir_transfer`</span>\nLOGDIR=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${TMPDIR}</span>/log<span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Create the log directory if necessary</span>\nmkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Get directory where Julia is placed</span>\nJL_BUNDLE=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>dirname <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>julia --startup-file=no\
    \ -O0 --compile=min -e <span class=\"pl-s\"><span class=\"pl-pds\">'</span>print(Sys.BINDIR)<span\
    \ class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span><span\
    \ class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Move Julia installation to\
    \ fast LLIO directory</span>\n/home/system/tool/dir_transfer -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Do not write\
    \ empty stdout/stderr files for MPI processes.</span>\n<span class=\"pl-k\">export</span>\
    \ PLE_MPI_STD_EMPTYFILE=off\n\nmpiexecjl --project=. -np ... julia ...\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Remove Julia installation directory\
    \ from the cache.</span>\n/home/system/tool/dir_transfer -p -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span></pre></div>\n<h2><a id=\"user-content-reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reverse\
    \ engineering Fujitsu compiler using LLVM output</h2>\n<p>The Fujitsu compiler\
    \ has <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/C/modeTradAndClangC.html\"\
    \ rel=\"nofollow\">two operation\nmodes</a>:\n\"trad\" (for \"traditional\") and\
    \ \"clang\" (enabled by the flag <code>-Nclang</code>).  In clang mode it's\n\
    based on LLVM (version 7 at the moment).  This means you can get it to emit LLVM\
    \ IR with\n<code>-emit-llvm</code>.  For example, with</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\"\
    >echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>int main(){}<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> fcc -Nclang -x\
    \ c - -S -emit-llvm -o -</span></pre></div>\n<p>you get</p>\n<div class=\"highlight\
    \ highlight-source-llvm\"><pre><span class=\"pl-c\">; ModuleID = '-'</span>\n\
    source_filename = <span class=\"pl-s\">\"-\"</span>\n<span class=\"pl-k\">target</span>\
    \ <span class=\"pl-k\">datalayout</span> = <span class=\"pl-s\">\"e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128\"\
    </span>\n<span class=\"pl-k\">target</span> <span class=\"pl-k\">triple</span>\
    \ = <span class=\"pl-s\">\"aarch64-unknown-linux-gnu\"</span>\n\n<span class=\"\
    pl-c\">; Function Attrs: norecurse nounwind readnone uwtable</span>\n<span class=\"\
    pl-k\">define</span> dso_local <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">@main</span>() <span class=\"pl-k\">local_unnamed_addr</span> #<span class=\"\
    pl-c1\">0</span> <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!8</span>\
    \ {\n  <span class=\"pl-k\">ret</span> <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!11</span>\n\
    }\n\n<span class=\"pl-k\">attributes</span> #<span class=\"pl-c1\">0</span> =\
    \ { <span class=\"pl-k\">norecurse</span> <span class=\"pl-k\">nounwind</span>\
    \ <span class=\"pl-k\">readnone</span> <span class=\"pl-k\">uwtable</span> <span\
    \ class=\"pl-s\">\"correctly-rounded-divide-sqrt-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"disable-tail-calls\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"less-precise-fpmad\"\
    </span>=<span class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim\"\
    </span>=<span class=\"pl-s\">\"true\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim-non-leaf\"\
    </span> <span class=\"pl-s\">\"no-infs-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"no-jump-tables\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> <span class=\"pl-s\">\"no-nans-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-signed-zeros-fp-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-trapping-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"stack-protector-buffer-size\"\
    </span>=<span class=\"pl-s\">\"8\"</span> <span class=\"pl-s\">\"target-cpu\"\
    </span>=<span class=\"pl-s\">\"a64fx\"</span> <span class=\"pl-s\">\"target-features\"\
    </span>=<span class=\"pl-s\">\"+crc,+crypto,+fp-armv8,+lse,+neon,+ras,+rdm,+sve,+v8.2a\"\
    </span> <span class=\"pl-s\">\"unsafe-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"use-soft-float\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> }\n\n<span class=\"pl-v\">!llvm.dbg.cu</span> = !{<span class=\"\
    pl-v\">!0</span>}\n<span class=\"pl-v\">!llvm.module.flags</span> = !{<span class=\"\
    pl-v\">!3</span>, <span class=\"pl-v\">!4</span>, <span class=\"pl-v\">!5</span>}\n\
    <span class=\"pl-v\">!llvm.ident</span> = !{<span class=\"pl-v\">!6</span>}\n\
    <span class=\"pl-v\">!llvm.compinfo</span> = !{<span class=\"pl-v\">!7</span>}\n\
    \n<span class=\"pl-v\">!0</span> = distinct <span class=\"pl-v\">!DICompileUnit</span>(language:\
    \ DW_LANG_C99, file: <span class=\"pl-v\">!1</span>, producer: <span class=\"\
    pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on\
    \ LLVM 7.1.0)\"</span>, isOptimized: <span class=\"pl-k\">true</span>, runtimeVersion:\
    \ <span class=\"pl-c1\">0</span>, emissionKind: LineTablesOnly, enums: <span class=\"\
    pl-v\">!2</span>)\n<span class=\"pl-v\">!1</span> = <span class=\"pl-v\">!DIFile</span>(filename:\
    \ <span class=\"pl-s\">\"-\"</span>, directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"\
    </span>)\n<span class=\"pl-v\">!2</span> = !{}\n<span class=\"pl-v\">!3</span>\
    \ = !{<span class=\"pl-k\">i32</span> <span class=\"pl-c1\">2</span>, !<span class=\"\
    pl-s\">\"Dwarf Version\"</span>, <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">4</span>}\n<span class=\"pl-v\">!4</span> = !{<span class=\"pl-k\">i32</span>\
    \ <span class=\"pl-c1\">2</span>, !<span class=\"pl-s\">\"Debug Info Version\"\
    </span>, <span class=\"pl-k\">i32</span> <span class=\"pl-c1\">3</span>}\n<span\
    \ class=\"pl-v\">!5</span> = !{<span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">1</span>, !<span class=\"pl-s\">\"wchar_size\"</span>, <span class=\"\
    pl-k\">i32</span> <span class=\"pl-c1\">4</span>}\n<span class=\"pl-v\">!6</span>\
    \ = !{!<span class=\"pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021\
    \ 10:55:52) (based on LLVM 7.1.0)\"</span>}\n<span class=\"pl-v\">!7</span> =\
    \ !{!<span class=\"pl-s\">\"C::clang\"</span>}\n<span class=\"pl-v\">!8</span>\
    \ = distinct <span class=\"pl-v\">!DISubprogram</span>(name: <span class=\"pl-s\"\
    >\"main\"</span>, scope: <span class=\"pl-v\">!9</span>, file: <span class=\"\
    pl-v\">!9</span>, line: <span class=\"pl-c1\">1</span>, type: <span class=\"pl-v\"\
    >!10</span>, isLocal: <span class=\"pl-k\">false</span>, isDefinition: <span class=\"\
    pl-k\">true</span>, scopeLine: <span class=\"pl-c1\">1</span>, isOptimized: <span\
    \ class=\"pl-k\">true</span>, unit: <span class=\"pl-v\">!0</span>, retainedNodes:\
    \ <span class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!9</span> = <span class=\"\
    pl-v\">!DIFile</span>(filename: <span class=\"pl-s\">\"&lt;stdin&gt;\"</span>,\
    \ directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"</span>)\n<span class=\"\
    pl-v\">!10</span> = <span class=\"pl-v\">!DISubroutineType</span>(types: <span\
    \ class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!11</span> = <span class=\"\
    pl-v\">!DILocation</span>(line: <span class=\"pl-c1\">1</span>, column: <span\
    \ class=\"pl-c1\">12</span>, scope: <span class=\"pl-v\">!8</span>)</pre></div>\n\
    <h2><a id=\"user-content-systembenchmarksjl\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#systembenchmarksjl\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>SystemBenchmarks.jl</h2>\n<p>I ran\
    \ <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl\"><code>SystemBenchmarks.jl</code></a>\
    \ on a\ncompute node.  Here are the results:\n<a href=\"https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\"\
    >https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968</a>.</p>\n\
    <h2><a id=\"user-content-blas\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#blas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>BLAS</h2>\n<p>OpenBLAS seems to have poor performance:</p>\n<div class=\"\
    highlight highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span>\
    \ <span class=\"pl-k\">using</span> LinearAlgebra\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.589865257047898e10</span></pre></div>\n\
    <p>Up to v1.7, Julia uses OpenBLAS v0.3.17, which actually doesn't support A64FX\
    \ at all, so\nit's probably using the generic kernels.\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.19\"\
    ><code>v0.3.19</code></a> and\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.20\"\
    ><code>v0.3.20</code></a> improved support for\nthis chip, you can find a build\
    \ of 0.3.20 at\n<a href=\"https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\"\
    >https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz</a>,\n\
    but sadly there isn't a great performance improvement:</p>\n<div class=\"highlight\
    \ highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">lbt_forward</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>lib/libopenblas64_.so<span class=\"pl-pds\"\
    >\"</span></span>)\n<span class=\"pl-c1\">4856</span>\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.6362952057793587e10</span></pre></div>\n\
    <p>There is an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/Library/BLASLAPACKScaLAPACKLibrary.html#how-to-dynamically-load-and-use-blas-lapack-and-scalapack\"\
    \ rel=\"nofollow\">optimised\nBLAS</a>\nprovided by Fujitsu, with support for\
    \ SVE (with both LP64 and ILP64).  In order to use it,\ninstall <a href=\"https://github.com/giordano/FujitsuBLAS.jl\"\
    ><code>FujitsuBLAS.jl</code></a></p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ FujitsuBLAS, LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">get_config</span>()\nLinearAlgebra<span\
    \ class=\"pl-k\">.</span>BLAS<span class=\"pl-k\">.</span>LBTConfig\nLibraries<span\
    \ class=\"pl-k\">:</span>\n\u2514 [ILP64] libfjlapackexsve_ilp64<span class=\"\
    pl-k\">.</span>so\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">4.801227630694119e10</span></pre></div>\n\
    <p>The package <a href=\"https://github.com/carstenbauer/BLISBLAS.jl\"><code>BLISBLAS.jl</code></a>\
    \ similarly forwards\nBLAS calls to the <a href=\"https://github.com/flame/blis\"\
    >blis</a> library, which has optimised kernels\nfor A64FX.</p>\n<h2><a id=\"user-content-building-julia-from-source\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-julia-from-source\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ Julia from source</h2>\n<h3><a id=\"user-content-with-gcc\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#with-gcc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>with GCC</h3>\n<p>Building Julia\
    \ from source with GCC (which is the default if you don't set <code>CC</code>\
    \ and <code>CXX</code>)\nworks fine, it's just <em>slow</em>:</p>\n<pre><code>[...]\n\
    \    JULIA usr/lib/julia/corecompiler.ji\nCore.Compiler \u2500\u2500\u2500\u2500\
    \ 903.661 seconds\n[...]\nBase  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500271.257337 seconds\nArgTools  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500 50.348227 seconds\nArtifacts  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  1.193792 seconds\nBase64  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.057241 seconds\nCRC32c  \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.097865 seconds\n\
    FileWatching  \u2500\u2500\u2500\u2500\u2500  1.169747 seconds\nLibdl  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.026215 seconds\n\
    Logging  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.411966\
    \ seconds\nMmap  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.972844 seconds\nNetworkOptions  \u2500\u2500\u2500  1.159094 seconds\n\
    SHA  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  2.067851 seconds\nSerialization  \u2500\u2500\u2500\u2500  2.942512 seconds\n\
    Sockets  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.568797\
    \ seconds\nUnicode  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \  0.814165 seconds\nDelimitedFiles  \u2500\u2500\u2500  1.121546 seconds\nLinearAlgebra\
    \  \u2500\u2500\u2500\u2500109.560774 seconds\nMarkdown  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500  7.977584 seconds\nPrintf  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.635409 seconds\nRandom  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 13.843395 seconds\nTar\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  3.146368 seconds\nDates  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500 16.694863 seconds\nDistributed  \u2500\u2500\u2500\u2500\
    \u2500\u2500  8.163152 seconds\nFuture  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500  0.060472 seconds\nInteractiveUtils  \u2500  5.245523\
    \ seconds\nLibGit2  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 15.469061 seconds\nProfile  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  5.399918 seconds\nSparseArrays  \u2500\u2500\u2500\u2500\u2500 42.660136\
    \ seconds\nUUIDs  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.165799 seconds\nREPL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500 40.149298 seconds\nSharedArrays  \u2500\u2500\
    \u2500\u2500\u2500  5.476926 seconds\nStatistics  \u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  2.130843 seconds\nSuiteSparse  \u2500\u2500\u2500\u2500\u2500\u2500\
    \ 16.849304 seconds\nTOML  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500  0.714203 seconds\nTest  \u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.538098 seconds\nLibCURL  \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.547585 seconds\nDownloads\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.657012 seconds\nPkg  \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 54.053634 seconds\nLazyArtifacts  \u2500\u2500\u2500\u2500  0.019103 seconds\n\
    Stdlibs total  \u2500\u2500\u2500\u2500427.178257 seconds\nSysimage built. Summary:\n\
    Total \u2500\u2500\u2500\u2500\u2500\u2500\u2500 698.447219 seconds\nBase: \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500 271.257337 seconds 38.8372%\nStdlibs: \u2500\
    \u2500\u2500\u2500 427.178257 seconds 61.1611%\n[...]\nPrecompilation complete.\
    \ Summary:\nTotal \u2500\u2500\u2500\u2500\u2500\u2500\u2500 1274.714700 seconds\n\
    Generation \u2500\u2500 886.445205 seconds 69.5407%\nExecution \u2500\u2500\u2500\
    \ 388.269495 seconds 30.4593%\n</code></pre>\n<h3><a id=\"user-content-with-fujitsu-compiler\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#with-fujitsu-compiler\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>With Fujitsu\
    \ compiler</h3>\n<p><em>For reference, the version used for the last build I attempted\
    \ was\n<a href=\"https://github.com/JuliaLang/julia/commit/1ad2396f05fa63a71e5842c814791cd7c7715100\"\
    ><code>1ad2396f</code></a></em></p>\n<p>Compiling Julia from source with the Fujitsu\
    \ compiler is complicated.  In particular, it's\nan absolute pain to use the Fujitsu\
    \ compiler in trad mode.  You can have some more luck with\nclang mode.</p>\n\
    <p>Preparation.  Create the <code>Make.user</code> file with this content (I'm\
    \ not sure this file is\nactually necessary when using Clang mode, but it definitely\
    \ is with trad mode):</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-k\">override</span> <span class=\"pl-smi\">ARCH</span>\
    \ := aarch64\n<span class=\"pl-k\">override</span> <span class=\"pl-smi\">BUILD_MACHINE</span>\
    \ := aarch64-unknown-linux-gnu</pre></div>\n<p>Then you can compile with (<code>-Nclang</code>\
    \ is to select clang mode)</p>\n<pre><code>make -j50 CC=\"fcc -Nclang\" CFLAGS=\"\
    -Kopenmp\" CXX=\"FCC -Nclang\" CXXFLAGS=\"-Kopenmp\"\n</code></pre>\n<p>The compiler\
    \ in trad mode doesn't define the macro <code>__SIZEOF_POINTER__</code>, so compilation\n\
    would fail in\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115</a>.\n\
    The solution is to set the macro <code>-D__SIZEOF_POINTER__=8</code> in the <code>CFLAGS</code>\
    \ (or just not use\ntrad mode).  Then, you may get errors like</p>\n<pre><code>/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2000:13:\
    \ error: initializer element is not a compile-time constant\n            jl_typename_type,\n\
    \            ^~~~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    /vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2025:43: error: initializer\
    \ element is not a compile-time constant\n    jl_typename_type-&gt;types = jl_svec(13,\
    \ jl_symbol_type, jl_any_type /*jl_module_type*/,\n                          \
    \                ^~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    </code></pre>\n<p>This is the compiler's fault, which is supposed to be able to\
    \ handle this, but you can just\ndelete the assertions at lines\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446</a>.</p>\n\
    <p>If you're lucky enough, with all these changes, you may be able to build <code>usr/bin/julia</code>.\n\
    Unfortunately, last time I tried, run this executable causes a segmentation fault\
    \ in\n<code>dl_init</code>:</p>\n<pre><code>(gdb) run\nStarting program: /vol0003/ra000019/a04463/repo/julia/julia\n\
    Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-151.el8.aarch64\n\
    [Thread debugging using libthread_db enabled]\nUsing host libthread_db library\
    \ \"/lib64/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation\
    \ fault.\n0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\n\
    Missing separate debuginfos, use: yum debuginfo-install FJSVxoslibmpg-2.0.0-25.14.1.el8.aarch64\
    \ elfutils-libelf-0.182-3.el8.aarch64\n(gdb) bt\n#0  0x000040000000def4 in _dl_init\
    \ () from /lib/ld-linux-aarch64.so.1\n#1  0x000040000020adb0 in _dl_catch_exception\
    \ () from /lib64/libc.so.6\n#2  0x00004000000125e4 in dl_open_worker () from /lib/ld-linux-aarch64.so.1\n\
    #3  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#4  0x0000400000011aa8\
    \ in _dl_open () from /lib/ld-linux-aarch64.so.1\n#5  0x0000400000091094 in dlopen_doit\
    \ () from /lib64/libdl.so.2\n#6  0x000040000020ad54 in _dl_catch_exception ()\
    \ from /lib64/libc.so.6\n#7  0x000040000020ae20 in _dl_catch_error () from /lib64/libc.so.6\n\
    #8  0x00004000000917f0 in _dlerror_run () from /lib64/libdl.so.2\n#9  0x0000400000091134\
    \ in dlopen@@GLIBC_2.17 () from /lib64/libdl.so.2\n#10 0x0000400000291f34 in load_library\
    \ (rel_path=0x400001e900c6 &lt;dep_libs+30&gt; \"libjulia-internal.so.1\", src_dir=&lt;optimized\
    \ out&gt;, err=1) at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:65\n\
    #11 0x0000400000291c78 in jl_load_libjulia_internal () at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:200\n\
    #12 0x000040000000de04 in call_init.part () from /lib/ld-linux-aarch64.so.1\n\
    #13 0x000040000000df08 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#14 0x0000400000001044\
    \ in _dl_start_user () from /lib/ld-linux-aarch64.so.1\nBacktrace stopped: previous\
    \ frame identical to this frame (corrupt stack?)\n</code></pre>\n"
  stargazers_count: 10
  subscribers_count: 2
  topics: []
  updated_at: 1690337110.0
haampie/sirius-appimage:
  data_format: 2
  description: SIRIUS AppImage (using just the bare minimum)
  filenames:
  - libtree/spack.yaml
  full_name: haampie/sirius-appimage
  latest_release: null
  readme: "<h1><a id=\"user-content-creating-an-appimage-from-a-spack-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#creating-an-appimage-from-a-spack-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ an AppImage from a spack environment</h1>\n<p>HPC container runtimes often use\
    \ squashfs as an archive to store an image, which is then mounted on compute nodes\
    \ and made writeable using overlayfs where the top layer is a ramfs. This trick\
    \ gives good performance particularly on shared filesystems, since the squashfs\
    \ file is a single blob on the disk and has good caching behavior.</p>\n<p>However,\
    \ perfect isolation from the host system is not always possible, in particular\
    \ when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into\
    \ the container, and the question is what the point of containers really is if\
    \ they still depend on the host system.</p>\n<p>Instead of using containers, one\
    \ can still deploy applications as a single self-contained blob on the filesystem\
    \ by using the AppImage runtime. The basic idea is to create an executable which\
    \ unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo\
    \ shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\"\
    >SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a>\
    \ and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\"\
    >AppImage runtime</a>.</p>\n<h2><a id=\"user-content-building\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#building\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./build.sh</span></pre></div>\n\
    <h2><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running</h2>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n<span class=\"pl-c1\"\
    >SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git\
    \ hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    <span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\"\
    >build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time\
    \     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI\
    \ ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                 \
    \     : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\
    \n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n\
    <span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"\
    pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n\
    <span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"\
    pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"\
    pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n\
    <span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in\
    \ Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=\
    \   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double}\
    \ default value for APW linearization energies</span>\n<span class=\"pl-c1\">\
    \  --auto_enu allow search of APW linearization energies</span>\n<span class=\"\
    pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\"\
    >  --rel      use scalar-relativistic solver</span></pre></div>\n<h2><a id=\"\
    user-content-running-on-piz-daint\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#running-on-piz-daint\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Running on piz daint</h2>\n<p>For Piz Daint I've modified\
    \ the <code>sirius/spack.yaml</code> a bit so that it links against system libmpi.so\
    \ (<code>^cray-mpich</code> that is):</p>\n<pre><code>daint103 $ ./build.sh\n\
    ...\n\ndaint103 $ du -sh sirius.app # binary size (includes compressed squashfs)\n\
    26M\tsirius.app\n\ndaint103 $ ./sirius.app --appimage-extract # runtime allows\
    \ you to extract\nsquashfs-root/AppRun\nsquashfs-root/usr\nsquashfs-root/usr/bin\n\
    squashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\nsquashfs-root/usr/lib\n\
    squashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\n\
    squashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n\
    ...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\
    \ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf\
    \ # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\n\
    srun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\n\
    input file does not exist\n===========================================================================================================\n\
    \                            #         Total          %   Parent %        Median\
    \           Min           Max\n-----------------------------------------------------------------------------------------------------------\n\
    sirius                      1       2.30 ms     100.00     100.00       2.30 ms\
    \       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms   \
    \   60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize\
    \        1     333.28 us      14.52      14.52     333.28 us     333.28 us   \
    \  333.28 us\n\n===========================================================================================================\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1616508538.0
hepnos/HEPnOS-PEP-Benchmark:
  data_format: 2
  description: Benchmark exercizing the ParallelEventProcessor feature of HEPnOS.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-PEP-Benchmark
  latest_release: v0.6
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1643644897.0
hepnos/HEPnOS-Wizard:
  data_format: 2
  description: Python utilities to generate HEPnOS configurations
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-Wizard
  latest_release: v0.0.2
  readme: '<h1><a id="user-content-hepnos-wizard" class="anchor" aria-hidden="true"
    tabindex="-1" href="#hepnos-wizard"><span aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS-Wizard</h1>

    <p>This package contains scripts to help setup valid configurations

    for the HEPnOS storage service.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641579766.0
hipdac-lab/SC23-AMRIC:
  data_format: 2
  description: 'Artifacts of SC''23 paper "AMRIC: A Novel In Situ Lossy Compression
    Framework for Efficient I/O in Adaptive Mesh Refinement Applications"'
  filenames:
  - warpx_directory/WarpX/Docs/spack.yaml
  full_name: hipdac-lab/SC23-AMRIC
  latest_release: v0.1.0
  readme: "<h1><a id=\"user-content-amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>AMRIC: A\
    \ Novel In Situ Lossy Compression Framework for Efficient I/O in Adaptive Mesh\
    \ Refinement Applications</h1>\n<p><a href=\"https://zenodo.org/badge/latestdoi/658166802\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d27197f9c57b31e8ebc942e043641820e994db2d17639562140d4e1c6eaf2442/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3635383136363830322e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/658166802.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>AMRIC is a novel in-situ lossy compression framework\
    \ that leverages the HDF5 filter to enhance both I/O efficiency and compression\
    \ quality for Adaptive Mesh Refinement (AMR) applications. AMRIC was integrated\
    \ into the <a href=\"https://amrex-codes.github.io/amrex/\" rel=\"nofollow\">AMReX</a>\
    \ framework and evaluated on two real-world AMR applications, Nyx and WarpX.</p>\n\
    <p>While preparing the artifacts, we executed them on a single node from the Chameleon\
    \ Cloud, equipped with two Intel Xeon Gold 6242 CPUs and 192 GB of memory (specifically,\
    \ <code>compute_skylake</code> configuration). We recommend that reviewers also\
    \ use the Chameleon Cloud for artifact evaluation.</p>\n<h2><a id=\"user-content-method-1-use-singularity-image-recommended\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#method-1-use-singularity-image-recommended\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Method 1:\
    \ Use Singularity Image (Recommended)</h2>\n<p>The entire workflow takes approximately\
    \ 10 minutes to execute, including downloading container image and preparing environment\
    \ (3 mins), running WarpX simulation (3 mins), running Nyx simulation (3 mins),\
    \ and evaluating compression performance (1 min).</p>\n<h3><a id=\"user-content-minimum-system-requirements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#minimum-system-requirements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimum\
    \ system requirements</h3>\n<p>OS: Ubuntu (20.04 is recommended)</p>\n<p>Memory:\
    \ &gt;= 16 GB RAM</p>\n<p>Processor: &gt;= 8 cores</p>\n<p>Storage: &gt;= 32 GBs</p>\n\
    <h3><a id=\"user-content-step-1-install-singularity\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-1-install-singularity\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 1: Install Singularity</h3>\n\
    <p>Install <a href=\"https://singularity-tutorial.github.io/01-installation/\"\
    \ rel=\"nofollow\">Singularity</a></p>\n<h3><a id=\"user-content-step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 2:\
    \ Download the pre-built Singularity image file via gdown</h3>\n<p>Press Enter\
    \ after finishing.</p>\n<pre><code>sudo pip3 install gdown\ngdown https://drive.google.com/uc?id=14v_xUmET-HvCFO3LqmD4sNJL65jBcd0L&amp;export=download\n\
    </code></pre>\n<p>or via GitHub</p>\n<pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC-Image.git\n\
    cat SC23-AMRIC-Image/img/amric.sif-* &gt; amric.sif\n</code></pre>\n<h3><a id=\"\
    user-content-step-3-build-and-run-the-image-file-need-root-privilege\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-3-build-and-run-the-image-file-need-root-privilege\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 3:\
    \ Build and run the image file (need root privilege)</h3>\n<pre><code>sudo singularity\
    \ build --sandbox artiAmr amric.sif\nsudo singularity shell --writable artiAmr\n\
    </code></pre>\n<h3><a id=\"user-content-step-4-set-up-environmental-variables\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-4-set-up-environmental-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 4:\
    \ Set up environmental variables</h3>\n<pre><code>export OMPI_DIR=/opt/ompi \n\
    export OMPI_VERSION=4.1.1\nexport PATH=$OMPI_DIR/bin:$PATH\nexport LD_LIBRARY_PATH=$OMPI_DIR/lib:$LD_LIBRARY_PATH\n\
    export MANPATH=$OMPI_DIR/share/man:$MANPATH\nexport C_INCLUDE_PATH=/opt/ompi/include:$C_INCLUDE_PATH\n\
    export CPLUS_INCLUDE_PATH=/opt/ompi/include:$CPLUS_INCLUDE_PATH\nexport OMPI_ALLOW_RUN_AS_ROOT=1\n\
    export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1\n</code></pre>\n<h3><a id=\"user-content-step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 5:\
    \ Run WarpX simulation with no compression, AMReX's original compression, and\
    \ AMRIC</h3>\n<pre><code>cd /home/wpx256/\n. bash.sh\n</code></pre>\n<h3><a id=\"\
    user-content-step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 6:\
    \ Run NYX simulation with no compression, AMReX's original compression, and AMRIC</h3>\n\
    <pre><code>cd /home/nyx128/\n. bash.sh\n</code></pre>\n<h3><a id=\"user-content-step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 7:\
    \ Evaluate WarpX's data quality and compression ratio for original AMReX compression\
    \ and our AMRIC</h3>\n<pre><code>cd /home/wpx256/diags/\n. decomp.sh &gt; temp.txt\n\
    . qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 8:\
    \ Evaluate NYX's data quality and compression ratio for original AMReX compression\
    \ and our AMRIC</h3>\n<pre><code>cd /home/nyx128/run/\n. decomp.sh &gt; temp.txt\n\
    . qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 9:\
    \ Compare I/O perf for baselines (i.e., no compression and ori AMReX compression)\
    \ and AMRIC in WarpX</h3>\n<pre><code>cd /home/wpx256/otfile/\n. io.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 10:\
    \ Compare I/O performance between baselines and AMRIC in NYX</h3>\n<pre><code>cd\
    \ /home/nyx128/otfile/\n. io.sh\n</code></pre>\n<h2><a id=\"user-content-method-2-build-from-source\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#method-2-build-from-source\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Method 2:\
    \ Build From Source</h2>\n<h3><a id=\"user-content-minimum-system--software-libraries-requirements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#minimum-system--software-libraries-requirements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimum\
    \ system &amp; software libraries requirements</h3>\n<p>OS: Linux (Ubuntu is recommended)</p>\n\
    <p>Memory: &gt;= 16 GB RAM</p>\n<p>Processor: &gt;= 8 cores</p>\n<p>gcc/9.4.0\
    \ (or 9.3.0)</p>\n<p>cmake (&gt;= 3.23)</p>\n<p>OpenMPI/4.1.1 (install scripts\
    \ provided, or spectrum-mpi)</p>\n<p>python/3.8</p>\n<p>hdf5/1.12.2 (install scripts\
    \ provided)</p>\n<h3><a id=\"user-content-step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 1:\
    \ Download AMRIC, checkpoint files, and set up environmental variables (2 mins)</h3>\n\
    <pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC.git\ncd SC23-AMRIC\n\
    export AMRIC_HOME=$(pwd)\necho \"# start of AMRIC env\" &gt;&gt; ~/.bashrc\necho\
    \ export AMRIC_HOME=$(pwd) &gt;&gt; ~/.bashrc\n</code></pre>\n<h3><a id=\"user-content-step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 2:\
    \ Load or install CMake and numpy. For example, in Ubuntu</h3>\n<pre><code>pip3\
    \ install numpy\nsudo snap install cmake --classic\n</code></pre>\n<h3><a id=\"\
    user-content-step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 3:\
    \ Load or install OpenMPI. For example, in Ubuntu (7 mins)</h3>\n<pre><code>sudo\
    \ bash openmpi.sh \n. mpi_env.sh\n</code></pre>\n<h3><a id=\"user-content-step-4-download-and-install-the-hdf5-library-4-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-4-download-and-install-the-hdf5-library-4-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 4:\
    \ Download and install the HDF5 library (4 mins)</h3>\n<pre><code>. hdf5.sh\n\
    </code></pre>\n<h3><a id=\"user-content-step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 5:\
    \ Install optimized SZ3 compressor and H5Z-SZ3 compression filter (5 mins)</h3>\n\
    <pre><code>. compressor.sh\n</code></pre>\n<h3><a id=\"user-content-step-6-install-amrex-and-nyx-with-amric-8-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-6-install-amrex-and-nyx-with-amric-8-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 6:\
    \ Install AMReX and Nyx with AMRIC (8 mins)</h3>\n<pre><code>. nyx.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-7-install-warpx-with-amric-9-mins\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-7-install-warpx-with-amric-9-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 7:\
    \ Install WarpX with AMRIC (9 mins)</h3>\n<pre><code>. warpx.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-8-download-qcat-compression-analysis-tool-1-min\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-8-download-qcat-compression-analysis-tool-1-min\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 8:\
    \ Download qcat (compression analysis tool, 1 min)</h3>\n<pre><code>. qcat.sh\n\
    </code></pre>\n<h3><a id=\"user-content-step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 9:\
    \ Run WarpX with no compression, AMReX\u2019s original compression, and AMRIC\
    \ (3 mins)</h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX\n. runwarpx.sh\n\
    </code></pre>\n<h3><a id=\"user-content-step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 10:\
    \ Run NYX with no compression, AMReX\u2019s original compression, and AMRIC (3\
    \ mins).</h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density\n. runnyx.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 11:\
    \ Evaluate WarpX\u2019s data quality and compression ratio for original AMReX\
    \ compression and our AMRIC.</h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/diags\n\
    cp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des-w .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss-w\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack-w .\ncp $AMRIC_HOME/qcat/install/bin/compareData\
    \ .\n. decomp.sh &gt; out.txt\n. qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 12:\
    \ Evaluate NYX\u2019s data quality and compression ratio for original AMReX compression\
    \ and our AMRIC.</h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/run\ncp\
    \ $AMRIC_HOME/qcat/install/bin/compareData .\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack\
    \ .\n. decomp.sh &gt; out.txt\n. qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 13:\
    \ Compare I/O performance between baselines (i.e., no compression and ori AMReX\
    \ compression) and AMRIC in WarpX.</h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/otfile\n\
    . io.sh\n</code></pre>\n<h3><a id=\"user-content-step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 14:\
    \ Compare I/O performance between baselines (i.e., no compression and ori AMReX\
    \ compression) and AMRIC in Nyx.</h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/otfile\n\
    . io.sh\n</code></pre>\n<h2><a id=\"user-content-expected-evaluation-results\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#expected-evaluation-results\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Expected\
    \ Evaluation Results</h2>\n<h3><a id=\"user-content-the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for WarpX\u2019s data quality and compression ratio (method 1 step 6)\
    \ are:</h3>\n<pre><code>----- Data Quality for original AMReX Compression -----\n\
    PSNR = 58.600102\n---------- Data Quality for AMRIC-SZ-L/R ----------\nPSNR =\
    \ 61.749515\n---------- Data Quality for AMRIC-SZInterp ----------\nPSNR = 59.146966\n\
    ---------- CR for original AMReX Compression ----------\nCR is: 14.62\n----------\
    \ CR for AMRIC-SZ-L/R ----------\nCR is: 108.94\n---------- CR for AMRIC-SZInterp\
    \ ----------\nCR is: 131.41\n</code></pre>\n<h3><a id=\"user-content-the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for Nyx\u2019s data quality and compression ratio (method 1 step 7)\
    \ are:</h3>\n<pre><code>----- Data Quality for original AMReX Compression -----\n\
    PSNR = 61.977332\n---------- Data Quality for AMRIC-SZ_L/R ----------\nPSNR =\
    \ 66.650492\n---------- Data Quality for AMRIC-SZInterp ----------\nPSNR = 66.566370\n\
    ---------- CR for original AMReX Compression ----------\nCR is: 6.53\n----------\
    \ CR for AMRIC-SZ_L/R ----------\nCR is: 13.08\n---------- CR for AMRIC-SZInterp\
    \ ----------\nCR is: 11.25\n</code></pre>\n<h3><a id=\"user-content-the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for WarpX\u2019s I/O performance  (method 1 step 8) are:</h3>\n<pre><code>----------\
    \ Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression\
    \ Total time = 1.514 seconds\nNo Compression Preprocess time = 0.216 seconds\n\
    No Compression writing time = 1.322 seconds\n...\n------------------------ END\
    \ ------------------------\n------ Writing Time for original AMReX Compression\
    \ ------\n***** run 0 *****\noriginal AMReX Total time = 4.734 seconds\noriginal\
    \ AMReX Preprocess time = 0.189 seconds\noriginal AMReX Writing+Compression time\
    \ = 4.493 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 1.115 seconds\nAMRIC-SZ_L/R Preprocess time = 0.223 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.906 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 1.878 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.950 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.937 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n<h3><a id=\"user-content-the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for Nyx\u2019s I/O performance  (method 1 step 9) are:</h3>\n<pre><code>----------\
    \ Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression\
    \ Total time = 0.195 seconds\nNo Compression Preprocess time = 0.016 seconds\n\
    No Compression writing time = 0.177 seconds\n...\n------------------------ END\
    \ ------------------------\n----- Writing Time for original AMReX Compression\
    \ -----\n***** run 0 *****\noriginal AMReX Total time = 0.674 seconds\noriginal\
    \ AMReX Preprocess time = 0.020 seconds\noriginal AMReX Writing+Compression time\
    \ = 0.649 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 0.182 seconds\nAMRIC-SZ_L/R Preprocess time = 0.018 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.155 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 0.230 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.102 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.122 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n"
  stargazers_count: 3
  subscribers_count: 2
  topics: []
  updated_at: 1699637463.0
iarspider/cms-spack-repo:
  data_format: 2
  description: null
  filenames:
  - environments/CMSSW_12_6_X/spack.yaml
  full_name: iarspider/cms-spack-repo
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1699779200.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/8257fa34c1c5b6c660b31bf16a6196859c354c9c503b7742e1cdee871fbb96c8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/b768fc44ae95216e4b53ff734978771466ba222596e760da27e9e60a0d47d6f7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <h2><a id="user-content-available-modules" class="anchor" aria-hidden="true" tabindex="-1"
    href="#available-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    modules</h2>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>ReconX</code> - provider of different reconstruction schemes</li>

    <li>

    <code>TOVSolverX</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    started</h2>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    <h2><a id="user-content-related-talks-and-tutorials" class="anchor" aria-hidden="true"
    tabindex="-1" href="#related-talks-and-tutorials"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Related talks and tutorials</h2>

    <ul>

    <li>"<a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html" rel="nofollow">Using
    CarpetX: A Guide for Early Adopters</a>".

    Recorded seminar talk by Erik Schnetter, providing an overview of the current
    capabilities of CarpetX.</li>

    <li>"<a href="https://einsteintoolkit.github.io/et2022uidaho/lectures/38-Tutorial8/index.html"
    rel="nofollow">Tutorial: GPUs and the Einstein Toolkit</a>".

    Recorded tutorial by Lorenzo Ennoggi, Jay Kalinani and Federico Lopez Armengol
    during the North American Einstein Toolkit workshop 2022, presenting a brief overview
    on AsterX, followed by a hands-on session.</li>

    <li>"<a href="https://drive.google.com/file/d/1Z4i--W56mxeNIu598LQTpEEowX56FOoD/view?usp=sharing"
    rel="nofollow">AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes</a>".

    Slides based on the talk by Jay Kalinani at the APS April Meeting 2023.</li>

    </ul>

    '
  stargazers_count: 17
  subscribers_count: 10
  topics: []
  updated_at: 1698593900.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - anl/polaris/polaris.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1658934301.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/eagle/compilers/spack.yaml
  - configs/eagle/utilities/spack.yaml
  - configs/ellis/compilers/spack.yaml
  - configs/rhodes/utilities/spack.yaml
  - configs/rhodes/compilers/spack.yaml
  - configs/eagle/software/spack.yaml
  - envs/exawind/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" aria-hidden="true" tabindex="-1" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666717629.0
js947/spack-docker-test:
  data_format: 2
  description: testing spack's containerize command
  filenames:
  - spack.yaml
  full_name: js947/spack-docker-test
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"><img
    src="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"
    alt="Build container" style="max-width: 100%;"></a></p>

    <h1><a id="user-content-spack-docker-test" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-docker-test"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-docker-test</h1>

    <p>testing spack''s containerize command</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1606954982.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-ci/spack.yaml
  - environments/key4hep-nightly/spack.yaml
  - environments/key4hep-nightly-debug/spack.yaml
  - environments/key4hep-release-clang/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" tabindex="-1" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software.</p>

    <p>Consult the the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep documentation
    website</a> and the

    <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack documentation</a>
    for more details.</p>

    <h2><a id="user-content-spack-versions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-versions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Versions</h2>

    <p>The spack recipes in this repository should work with any version of spack
    (0.19

    is known to work and it''s possible older versions work too, newer than 0.19

    works). Some of the environments require spack 0.20 or newer since they use (or

    they include a file that uses) the <code>require</code> keyword which was introduced
    in

    <a href="https://github.com/spack/spack/releases/tag/v0.20.0">spack 0.20</a>.</p>

    <h2><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    tabindex="-1" href="#repository-contents"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Repository Contents</h2>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the

    repository contains a collection of environments used to build the stack in

    <code>environments</code> and some scripts used for publishing on cvmfs and other
    utilities

    in <code>scripts</code>. The builds run in Gitlab CI runners and the workflows
    can be found

    in the file <code>.gitlab-ci.yml</code> in the <a href="https://gitlab.cern.ch/key4hep/k4-deploy"
    rel="nofollow">gitlab

    repository</a>.</p>

    <p>Additionally, the file <code>.latest-commit</code> contains the latest commit
    of Spack used

    for the recent builds, which is updated from time to time to keep up with the

    develop branch of Spack.</p>

    <h2><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    tabindex="-1" href="#central-installations"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Central Installations</h2>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org</code>
    (for

    CentOS 7) and <code>/cvmfs/sw-nightlies.hsf.org</code> (for CentOS 7, AlmaLinux
    9 and

    Ubuntu) see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    <h2><a id="user-content-requirements" class="anchor" aria-hidden="true" tabindex="-1"
    href="#requirements"><span aria-hidden="true" class="octicon octicon-link"></span></a>Requirements</h2>

    <p>To compile the key4hep stack some system packages are required; without these,

    the spack concretization or compilation can fail. The packages needed are an

    OpenGL implementation that can be installed:</p>

    <div class="highlight highlight-source-shell"><pre>yum install -y mesa-libGL mesa-libGL-devel
    mesa-libGLU mesa-libGLU-devel      <span class="pl-c"><span class="pl-c">#</span>
    Centos 7</span>

    apt install -y libgl1-mesa-glx libgl1-mesa-dev libglu1-mesa libglu1-mesa-dev  <span
    class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    dnf install -y mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel      <span
    class="pl-c"><span class="pl-c">#</span> AlmaLinux 9</span></pre></div>

    <p>The environments that make use of these libraries or headers expect them to
    be

    found under <code>/usr</code>, which is the typical location when they are installed

    system-wide (for example in <code>/usr/include</code> or <code>/usr/lib</code>).</p>

    <p>Alternatively, one can install

    <a href="https://gitlab.cern.ch/linuxsupport/rpms/HEP_OSlibs" rel="nofollow">HEP_OSlibs</a>,
    which will

    install the previous and more libraries.</p>

    <p>In addition, for Ubuntu and Alma 9 the compilers are picked up from the system,

    so, for example, building in an image without <code>gcc</code> or <code>glibc</code>
    won''t work. These

    commands should install most of the compilers and the development tools:</p>

    <div class="highlight highlight-source-shell"><pre>apt install -y build-essential
    gfortran                            <span class="pl-c"><span class="pl-c">#</span>
    Ubuntu</span>

    dnf groupinstall -y <span class="pl-s"><span class="pl-pds">"</span>Development
    Tools<span class="pl-pds">"</span></span> <span class="pl-k">&amp;&amp;</span>
    dnf install -y gfortran <span class="pl-c"><span class="pl-c">#</span> AlmaLinux
    9</span></pre></div>

    <p>Dockerfiles with the images that are used to build the key4hep stack can be

    found in <a href="https://github.com/key4hep/key4hep-images">https://github.com/key4hep/key4hep-images</a>.</p>

    '
  stargazers_count: 8
  subscribers_count: 10
  topics: []
  updated_at: 1682439760.0
lanl/CELLAR:
  data_format: 2
  description: The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based
    adaptive mesh refinement data structures and execution for parallel computing
    architectures.
  filenames:
  - spack/snow/spack.yaml
  - spack/ci/spack.yaml
  - spack/darwin-power9/spack.yaml
  full_name: lanl/CELLAR
  latest_release: null
  readme: '<h1><a id="user-content-cellar-----eap-core" class="anchor" aria-hidden="true"
    tabindex="-1" href="#cellar-----eap-core"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>CELLAR  -  EAP Core</h1>

    <p>CELLAR is a C++ project that forms the foundation of cell based AMR for applications</p>

    <p>It provides the following:</p>

    <ul>

    <li>AMR Mesh Datastructure</li>

    <li>AMR Mesh Reconstruction</li>

    <li>Communication Patterns</li>

    <li>C++ Error Handling and Tracing</li>

    <li>Performance Monitoring</li>

    <li>C++/Fortran Interop</li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" tabindex="-1"
    href="#building"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>The easiest way to install dependencies is using <a href="https://spack.io"
    rel="nofollow">Spack</a>.

    After

    <a href="https://spack.readthedocs.io/en/latest/getting_started.html" rel="nofollow">installing
    Spack</a>,

    you can start build dependencies.</p>

    <p>The following instructions assume that you have Spack 0.13 or newer. You can
    check your

    Spack version like so:</p>

    <pre><code>$ spack --version

    0.13.0

    </code></pre>

    <p>First, add <a href="https://github.com/lanl/cellar-spack">lanl/cellar-spack</a>

    to your list of spack repos.</p>

    <p>Once you have the <code>lanl/cellar-spack</code> installed, then you can install
    all

    dependencies using

    <a href="https://spack.readthedocs.io/en/latest/tutorial_environments.html#" rel="nofollow">Spack
    environments</a>.

    You''ll need to use a modern-ish C++ compiler that supports C++14:</p>

    <pre><code>$ module load gcc/9.3.0

    $ spack compiler find

    $ cd path/to/eap-core

    </code></pre>

    <p>Then issue the following commands. This will build all of eap-core''s dependencies.:</p>

    <pre><code>$ spack env create -d spack/default

    $ spack env activate -d $PWD/spack/default

    $ spack install

    </code></pre>

    <p>Any time you open a new shell, you''ll need to re-activate the Spack environment:</p>

    <pre><code>$ spack env activate -d $PWD/spack/default

    </code></pre>

    <p>Now you''re ready to build eap-core. First configure the project using CMake:</p>

    <pre><code>mkdir build &amp;&amp; cd build

    cmake ..

    </code></pre>

    <p>And then build:</p>

    <pre><code>make -j

    </code></pre>

    <p>For snow, substitute in spack/snow in the above instructions in place of spack/default.
    If you need

    to change the environment use "spack env deactivate".</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Code contributors should read the <a href="DEVELOPERS.md">Developers Guide</a>
    prior to

    sending a pull request.</p>

    '
  stargazers_count: 3
  subscribers_count: 7
  topics: []
  updated_at: 1694614627.0
lanl/SICM:
  data_format: 2
  description: Simplified Interface to Complex Memory
  filenames:
  - spack.yaml
  full_name: lanl/SICM
  latest_release: null
  readme: '<h1><a id="user-content-sicm" class="anchor" aria-hidden="true" tabindex="-1"
    href="#sicm"><span aria-hidden="true" class="octicon octicon-link"></span></a>SICM</h1>

    <p>Simplified Interface to Complex Memory</p>

    <p><a href="https://github.com/lanl/SICM/actions"><img src="https://github.com/lanl/SICM/actions/workflows/sicm.yml/badge.svg"
    alt="GitHub Actions" style="max-width: 100%;"></a></p>

    <h2><a id="user-content-introduction" class="anchor" aria-hidden="true" tabindex="-1"
    href="#introduction"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

    <p>This project is split into two interfaces: <code>low</code> and <code>high</code>.</p>

    <p>The <code>low</code> interface provides a minimal interface for application
    wanting to

    manage their own memory on heterogeneous memory tiers. It also provides an

    arena allocator that application developers can use to create <code>jemalloc</code>
    arenas

    on different memory tiers and allocate to those tiers.</p>

    <p>The <code>high</code> interface attempts to automatically manage the memory
    tiers for the

    application. It provides an LLVM compiler pass (and compiler wrappers) to

    automatically transform applications to make the appropriate <code>high</code>
    interface

    calls, as well as a runtime library which provides profiling for the

    application.  The profiling is currently meant to be used offline; that is,

    after enabling the profiling for an application run, the results are printed

    out at the end of the run, and that information must be fed into a second run

    to make use of it. An online approach is planned.</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>The only dependencies that you will need for the low-level interface

    are <code>libnuma</code> and <code>jemalloc</code>. We require that <code>jemalloc</code>
    be

    configured with the <code>je_</code> prefix (using the <code>--with-jemalloc-prefix</code>
    flag).

    <code>CMake</code> will use <code>pkg-config</code> to find <code>jemalloc</code>.</p>

    <p>For the high-level interface, you need an installation of LLVM. LLVM 4.0 and

    later have been tested, although 3.9 may possibly work. For the profiling, you

    will also need an installation of <code>libpfm</code>, which is a small helper
    library for

    <code>perf</code> that is available on most distributions.</p>

    <p>Additionally, several other packages are required, and can be installed through
    a package manager:</p>

    <h3><a id="user-content-binaries" class="anchor" aria-hidden="true" tabindex="-1"
    href="#binaries"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binaries</h3>

    <ul>

    <li>A modern C compiler</li>

    <li>A modern C++ compiler</li>

    <li>A modern Fortran compiler</li>

    <li>CMake 3.0+</li>

    <li>Make</li>

    <li>numactl</li>

    <li>automake + friends (if jemalloc needs to be built)</li>

    </ul>

    <h3><a id="user-content-development-libraries" class="anchor" aria-hidden="true"
    tabindex="-1" href="#development-libraries"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Development Libraries</h3>

    <p>These packages are usually named <code>lib*-dev</code> or <code>lib*-devel</code>:</p>

    <ul>

    <li>numa</li>

    </ul>

    <p>Additional packages are required for the high level interface:</p>

    <ul>

    <li>hwloc</li>

    <li>llvm</li>

    <li>omp (if OpenMP is not available by default on your compilers)</li>

    <li>pfm4</li>

    </ul>

    <h2><a id="user-content-compilation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#compilation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h2>

    <pre><code>export PKG_CONFIG_PATH=&lt;jemalloc prefix&gt;/lib/pkgconfig:$PKG_CONFIG_PATH

    mkdir build

    cd build

    cmake .. -DCMAKE_INSTALL_PREFIX=&lt;prefix&gt;

    make

    make install

    </code></pre>

    <h2><a id="user-content-low-level-api" class="anchor" aria-hidden="true" tabindex="-1"
    href="#low-level-api"><span aria-hidden="true" class="octicon octicon-link"></span></a>Low-Level
    API</h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_init</code></td>

    <td>Detects all memory devices on system, returns a list of them.</td>

    </tr>

    <tr>

    <td><code>sicm_fini</code></td>

    <td>Frees up a device list and associated SICM data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_find_device</code></td>

    <td>Return the first device that matches a given type and page size.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc</code></td>

    <td>Allocates to a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_free</code></td>

    <td>Frees memory on a device.</td>

    </tr>

    <tr>

    <td><code>sicm_can_place_exact</code></td>

    <td>Returns whether or not a device supports exact placement.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc_exact</code></td>

    <td>Allocate memory on a device with an exact base address.</td>

    </tr>

    <tr>

    <td><code>sicm_numa_id</code></td>

    <td>Returns the NUMA ID that a device is on.</td>

    </tr>

    <tr>

    <td><code>sicm_device_page_size</code></td>

    <td>Returns the page size of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_eq</code></td>

    <td>Returns if two devices are equal or not.</td>

    </tr>

    <tr>

    <td><code>sicm_move</code></td>

    <td>Moves memory from one device to another.</td>

    </tr>

    <tr>

    <td><code>sicm_pin</code></td>

    <td>Pin the current process to a device''s memory.</td>

    </tr>

    <tr>

    <td><code>sicm_capacity</code></td>

    <td>Returns the capacity of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_avail</code></td>

    <td>Returns the amount of memory available on a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_model_distance</code></td>

    <td>Returns the distance of a given memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_is_near</code></td>

    <td>Returns whether or not a given memory device is nearby the current NUMA node.</td>

    </tr>

    <tr>

    <td><code>sicm_latency</code></td>

    <td>Measures the latency of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear2</code></td>

    <td>Measures a memory device''s linear access bandwidth.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random2</code></td>

    <td>Measures random access bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear3</code></td>

    <td>Measures the linear bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random3</code></td>

    <td>Measures the random access bandwidth of a memory device.</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-arena-allocator-api" class="anchor" aria-hidden="true"
    tabindex="-1" href="#arena-allocator-api"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Arena Allocator API</h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_arenas_list</code></td>

    <td>List all arenas created in the arena allocator.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_create</code></td>

    <td>Create a new arena on the given device.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_destroy</code></td>

    <td>Frees up an arena, deleting all associated data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_default</code></td>

    <td>Sets an arena as the default for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_default</code></td>

    <td>Gets the default arena for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_device</code></td>

    <td>Gets the device for a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_device</code></td>

    <td>Sets the memory device for a given arena. Moves all allocated memory already
    allocated to the arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_size</code></td>

    <td>Gets the size of memory allocated to the given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc</code></td>

    <td>Allocate to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc_aligned</code></td>

    <td>Allocate aligned memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_realloc</code></td>

    <td>Resize allocated memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_lookup</code></td>

    <td>Returns which arena a given pointer belongs to.</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-high-level-interface" class="anchor" aria-hidden="true"
    tabindex="-1" href="#high-level-interface"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>High-Level Interface</h2>

    <p>The high-level interface is normally used with the compiler wrappers located
    in

    <code>bin/</code>. Users should use these wrappers to compile their applications,
    and a

    compiler pass will automatically transform the code so that it calls the

    high-level interface with the appropriate arguments, including initialization,

    destruction, and the proper allocation functions. Assuming the high-level

    interface is linked to the application as a shared library, it automatically

    initializes itself.  All heap allocation routines are replaced by calls to

    <code>void* sh_alloc(int id, size_t sz)</code>, which associates an ID with a
    given

    allocation and allocates the memory into an arena with other allocations of

    that ID.</p>

    <h2><a id="user-content-programming-practices" class="anchor" aria-hidden="true"
    tabindex="-1" href="#programming-practices"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Programming Practices</h2>

    <ol>

    <li>All blocks use curly braces

    <ul>

    <li>Even one-line blocks</li>

    </ul>

    </li>

    <li>Constants on the left side of <code>==</code>

    <ul>

    <li><code>if(NULL == foo) { ...</code></li>

    </ul>

    </li>

    <li>Functions with no arguments are <code>(void)</code>

    </li>

    <li>No C++-style comments in C code</li>

    <li>No GCC extensions except in GCC-only code</li>

    <li>No C++ code in libraries

    <ul>

    <li>Discouraged in components</li>

    </ul>

    </li>

    <li>Always define preprocessor macros

    <ul>

    <li>Define logicals to 0 or 1 (vs. define or not define)</li>

    <li>Use <code>#if FOO</code>, not <code>#ifdef FOO</code>

    </li>

    </ul>

    </li>

    </ol>

    '
  stargazers_count: 25
  subscribers_count: 23
  topics: []
  updated_at: 1695897425.0
laristra/ristra_spackages:
  data_format: 2
  description: 'A mirror of Ristra''s internal gitlab repository. '
  filenames:
  - .gitlab-ci/env/dry-run/spack.yaml
  full_name: laristra/ristra_spackages
  latest_release: null
  readme: '<h1><a id="user-content-ristra-spackages" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ristra-spackages"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Ristra Spackages</h1>

    <p>This repository contains the custom spackage files for the repos in laristra
    family.</p>

    <h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#basic-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Basic
    Usage</h2>

    <p>We assume the user wish to work in the home directory and already have a spack
    instance setup.  The minimum required version of spack is 0.15.2.</p>

    <p>To get the content of this repo</p>

    <pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git

    </code></pre>

    <p>To use the custom spackage files with your spack</p>

    <pre><code>$ spack repo add ristra_spackages/spack-repo

    ==&gt; Added repo with namespace ''lanl_ristra''.


    $ spack repo list

    ==&gt; 2 package repositories.

    lanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo

    builtin            /home/&lt;user&gt;/spack/var/spack/repos/builtin

    </code></pre>

    <p>[Optional]

    To ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code>
    into your spack config folder</p>

    <pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/

    </code></pre>

    <p>Please see the <a href="https://spack.readthedocs.io/en/latest/configuration.html"
    rel="nofollow">Spack documentation</a> for more detailed info.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1649449003.0
lezzidan/spack:
  data_format: 2
  description: Spack clone
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss-aws-aarch64/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/aws-isc/spack.yaml
  full_name: lezzidan/spack
  latest_release: null
  readme: "<h1><a id=\"user-content--spack\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\"\
    \ href=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/build-containers.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/build-containers.yml/badge.svg\"\
    \ alt=\"Containers\" style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/d91ed7ac7abbd5a6102cbe988dd8e9ac21bde0a73d97be7603b891ad08ce3479/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/code%20style-black-000000.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/4bbdc2b44561be6dfffe64e15730e1c5a2bed9c4efe6f9942638091a4ce3ede2/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p><a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <h2><a id=\"user-content-tutorial\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Tutorial</h2>\n<p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<h2><a id=\"user-content-community\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#community\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Community</h2>\n<p>Spack is an open source project.\
    \  Questions, discussion, and\ncontributions are welcome. Contributions can be\
    \ anything from new\npackages to bugfixes, documentation, or even new core features.</p>\n\
    <p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<a href=\"\
    https://github.com/spack/spack/discussions\"><strong>Github Discussions</strong></a>:\
    \ not just for discussions, also Q&amp;A.</li>\n<li>\n<strong>Mailing list</strong>:\
    \ <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\">groups.google.com/d/forum/spack</a>\n\
    </li>\n<li>\n<strong>Twitter</strong>: <a href=\"https://twitter.com/spackpm\"\
    \ rel=\"nofollow\">@spackpm</a>. Be sure to\n<code>@mention</code> us!</li>\n\
    </ul>\n<h2><a id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Contributing</h2>\n<p>Contributing to Spack\
    \ is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2><a id=\"user-content-releases\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Releases</h2>\n<p>For multi-user site deployments or other use cases\
    \ that need very stable\nsoftware installations, we recommend using Spack's\n\
    <a href=\"https://github.com/spack/spack/releases\">stable releases</a>.</p>\n\
    <p>Each Spack release series also has a corresponding branch, e.g.\n<code>releases/v0.14</code>\
    \ has <code>0.14.x</code> versions of Spack, and <code>releases/v0.13</code> has\n\
    <code>0.13.x</code> versions. We backport important bug fixes to these branches\
    \ but\nwe do not advance the package versions or make other changes that would\n\
    change the way Spack concretizes dependencies within a release branch.\nSo, you\
    \ can base your Spack deployment on a release branch and <code>git pull</code>\n\
    to get fixes, without the package churn that comes with <code>develop</code>.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<p>See the <a href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\"\
    \ rel=\"nofollow\">docs on releases</a>\nfor more details.</p>\n<h2><a id=\"user-content-code-of-conduct\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#code-of-conduct\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Code of\
    \ Conduct</h2>\n<p>Please note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"\
    ><strong>Code of Conduct</strong></a>. By participating in\nthe Spack community,\
    \ you agree to abide by its rules.</p>\n<h2><a id=\"user-content-authors\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#authors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>Many thanks\
    \ go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\"\
    >tgamblin@llnl.gov</a>.</p>\n<h3><a id=\"user-content-citing-spack\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Citing Spack</h3>\n<p>If you\
    \ are referencing Spack in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee,\n\
    Adam Moody, Bronis R. de Supinski, and W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<p>On GitHub, you can copy\
    \ this citation in APA or BibTeX format via the \"Cite this repository\"\nbutton.\
    \ Or, see the comments in <code>CITATION.cff</code> for the raw BibTeX.</p>\n\
    <h2><a id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>License</h2>\n<p>Spack is distributed under the terms of both the\
    \ MIT license and the\nApache License (Version 2.0). Users may choose either license,\
    \ at their\noption.</p>\n<p>All new contributions must be made under both the\
    \ MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\"\
    >LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\"\
    >LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\"\
    >COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\"\
    >NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1684418839.0
lfortran/lfortran:
  data_format: 2
  description: Official main repository for LFortran
  filenames:
  - spack.yaml
  full_name: lfortran/lfortran
  latest_release: v0.29.0
  readme: "<h1><a id=\"user-content-lfortran\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#lfortran\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>LFortran</h1>\n<p><a href=\"https://lfortran.zulipchat.com/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>LFortran is a modern open-source (BSD\
    \ licensed) interactive Fortran compiler\nbuilt on top of LLVM. It can execute\
    \ user's code interactively to allow\nexploratory work (much like Python, MATLAB\
    \ or Julia) as well as compile to\nbinaries with the goal to run user's code on\
    \ modern architectures such as\nmulti-core CPUs and GPUs.</p>\n<p>Website: <a\
    \ href=\"https://lfortran.org/\" rel=\"nofollow\">https://lfortran.org/</a></p>\n\
    <p>Try online: <a href=\"https://dev.lfortran.org/\" rel=\"nofollow\">https://dev.lfortran.org/</a></p>\n\
    <h1><a id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#documentation\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Documentation</h1>\n<p>All documentation, installation\
    \ instructions, motivation, design, ... is\navailable at:</p>\n<p><a href=\"https://docs.lfortran.org/\"\
    \ rel=\"nofollow\">https://docs.lfortran.org/</a></p>\n<p>Which is generated using\
    \ the files in the <code>doc</code> directory.</p>\n<h1><a id=\"user-content-development\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#development\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development</h1>\n\
    <p>We welcome all contributions.\nThe main development repository is at GitHub:</p>\n\
    <p><a href=\"https://github.com/lfortran/lfortran\">https://github.com/lfortran/lfortran</a></p>\n\
    <p>Please send Pull Requests (PRs) and open issues there.</p>\n<p>See the <a href=\"\
    CONTRIBUTING.md\">CONTRIBUTING</a> document for more information.</p>\n<p>Main\
    \ mailinglist:</p>\n<p><a href=\"https://groups.io/g/lfortran\" rel=\"nofollow\"\
    >https://groups.io/g/lfortran</a></p>\n<p>You can also chat with us on Zulip (<a\
    \ href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a>).</p>\n<p>Note: We moved to the above GitHub\
    \ repository from GitLab on July 18, 2022.</p>\n<h1><a id=\"user-content-donations\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#donations\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Donations</h1>\n\
    <p>You can support LFortran's development by donating to NumFOCUS or Open\nCollective\
    \ as well as GitHub Sponsors:</p>\n<ul>\n<li><a href=\"https://numfocus.org/donate-to-lfortran\"\
    \ rel=\"nofollow\">https://numfocus.org/donate-to-lfortran</a></li>\n<li><a href=\"\
    https://opencollective.com/lfortran\" rel=\"nofollow\">https://opencollective.com/lfortran</a></li>\n\
    <li><a href=\"https://github.com/sponsors/lfortran\">https://github.com/sponsors/lfortran</a></li>\n\
    </ul>\n<p>All donations will be used strictly to fund LFortran development, by\
    \ supporting\ntasks such as paying developers to implement features, sprints,\
    \ improved\ndocumentation, fixing bugs, etc.</p>\n<p>The donations to LFortran\
    \ are managed by the NumFOCUS foundation. NumFOCUS is a\n501(c)3 non-profit foundation,\
    \ so if you are subject to US Tax law, your\ncontributions will be tax-deductible.</p>\n\
    <p>If you want to discuss another way to fund or help with the development, feel\n\
    free to contact Ond\u0159ej \u010Cert\xEDk (<a href=\"mailto:ondrej@certik.us\"\
    >ondrej@certik.us</a>).</p>\n<h1><a id=\"user-content-star-history\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#star-history\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Star History</h1>\n<p><a href=\"\
    https://star-history.com/#lfortran/lfortran&amp;Date\" rel=\"nofollow\"><img src=\"\
    https://camo.githubusercontent.com/7e19634671b985a40376628d5d76d76ef6baf79368e0c4b6a409523464e705b7/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c666f727472616e2f6c666f727472616e26747970653d44617465\"\
    \ alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=lfortran/lfortran&amp;type=Date\"\
    \ style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 773
  subscribers_count: 20
  topics:
  - fortran
  - interactive
  - compiler
  - library
  - repl
  - jupyter
  - jupyter-notebook
  - jupyter-kernels
  updated_at: 1701285139.0
m-s-will/nyx:
  data_format: 2
  description: null
  filenames:
  - nyx/inputs/spack/spack.yaml
  full_name: m-s-will/nyx
  latest_release: null
  readme: '<h1><a id="user-content-nyx-with-ascent-in-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#nyx-with-ascent-in-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Nyx with Ascent in Container</h1>

    <p>This project contains a Dockerfile and all necessary components to create a
    Docker container for Nyx.

    The container is available on <a href="https://hub.docker.com/repository/docker/mswill/elwe_nyx"
    rel="nofollow">Dockerhub</a>, however these versions may not always be up to date.</p>

    <h2><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#building-the-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Building the container</h2>

    <p>The Ascent actions can be changed by editing <a href="https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml">ascent_actions.yaml</a>.

    When finished with the customization, the container can be rebuilt by navigating
    into the source directory and executing:</p>

    <pre><code>$ docker build -t &lt;mytag&gt; .

    </code></pre>

    <p>The Nyx simulation is being run during container creation and provides a Cinema
    database.</p>

    <h2><a id="user-content-running-the-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#running-the-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Running the container</h2>

    <p>After either pulling or building the container, it can be run by calling:</p>

    <pre><code>$ docker run -p 80:80 &lt;mytag&gt;.

    </code></pre>

    <p><code>-p 80:80</code> makes port 80 available on the outside which is needed
    for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code>
    in our browser.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1619455896.0
mfem/mfem:
  data_format: 2
  description: Lightweight, general, scalable C++ library for finite element methods
  filenames:
  - config/docker/spack.yaml
  full_name: mfem/mfem
  latest_release: v4.6
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed\
    \ under the terms of the BSD-3 license. All new contributions\nmust be made under\
    \ this license. See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>\
    \ for\ndetails.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release\
    \ Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 1415
  subscribers_count: 118
  topics:
  - finite-elements
  - high-order
  - high-performance-computing
  - parallel-computing
  - amr
  - computational-science
  - fem
  - scientific-computing
  - hpc
  - math-physics
  - radiuss
  updated_at: 1700853462.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ORNL/Crusher/spack.yaml
  - ORNL/Summit/spack.yaml
  - ANL/Cooley/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" tabindex="-1" href="#platform-configurations-for-mochi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Platform configurations
    for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    tabindex="-1" href="#using-spackyaml-files"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Using spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Then, execute the following commands

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    $ spack env activate myenv

    $ spack repo add /where/you/cloned/mochi-spack-packages

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    tabindex="-1" href="#contributing-to-this-repository"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 4
  subscribers_count: 3
  topics: []
  updated_at: 1682086466.0
mochi-hpc/flamestore:
  data_format: 2
  description: Storage system for Deep Learning models designed using the Mochi components.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/flamestore
  latest_release: null
  readme: '<h1><a id="user-content-what-is-flamestore" class="anchor" aria-hidden="true"
    tabindex="-1" href="#what-is-flamestore"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>What is FlameStore?</h1>

    <p>FlameStore is a Mochi component to access Keras deep learning models

    and store them in various backends (right now: in memory, on a local

    file system, or on a composition of SDSKV and BAKE providers).</p>

    <p>FlameStore is developped by Matthieu Dorier (<a href="mailto:mdorier@anl.gov">mdorier@anl.gov</a>).

    More information on how to install and use is available

    <a href="https://xgitlab.cels.anl.gov/sds/flamestore/wikis/home" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1700115196.0
mochi-hpc/mochi-bake:
  data_format: 2
  description: A microservice (i.e., Mochi provider) for high performance bulk storage
    of raw data regions
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bake
  latest_release: v0.6.4
  readme: "<h1><a id=\"user-content-bake\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#bake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Bake</h1>\n<p>Bake is a microservice (i.e., Mochi provider) for high\
    \ performance bulk\nstorage of raw data regions.  Bake uses modular backends to\
    \ store data\non persistent memory, conventional file systems, or other storage\
    \ media.</p>\n<p>See <a href=\"https://www.mcs.anl.gov/research/projects/mochi/\"\
    \ rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a> and\n\
    <a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a>\
    \ for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively\
    \ to data storage.  Capabilities such as\nindexing, name spaces, and sharding\
    \ must be provided by other microservice\ncomponents.</p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>The easiest way to install Bake is through spack:</p>\n<p><code>spack install\
    \ bake</code></p>\n<p>This will install BAKE and its dependencies.  Please refer\
    \ to the end of the\ndocument for manual compilation instructions.</p>\n<h2><a\
    \ id=\"user-content-architecture\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#architecture\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Architecture</h2>\n<p>Like most Mochi services, BAKE relies on a client/provider\
    \ architecture.\nA provider, identified by its <em>address</em> and <em>multiplex\
    \ id</em>, manages one or more\n<em>BAKE targets</em>, referenced externally by\
    \ their <em>target id</em>.</p>\n<p>A target can be thought of as a storage device.\
    \  This may be (for example) a\nPMDK volume or a local file system.</p>\n<h2><a\
    \ id=\"user-content-setting-up-a-bake-target\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#setting-up-a-bake-target\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up a BAKE target</h2>\n\
    <p>BAKE requires the backend storage file to be created beforehand using\n<code>bake-mkpool</code>.\
    \ For instance:</p>\n<p><code>bake-mkpool -s 500M /dev/shm/foo.dat</code></p>\n\
    <p>creates a 500 MB file at <em>/dev/shm/foo.dat</em> to be used by BAKE as a\
    \ target.\nBake will use the <code>pmem</code> (persistent memory) backend by\
    \ default, which means\nthat the underlying file will memory mapped for access\
    \ usign the PMDK\nlibrary.  You can also providie an explicit prefix (such as\
    \ <code>file:</code> for the\nconventional file backend or <code>pmem:</code>\
    \ for the persistent memory backend) to\ndictate a specific target type.</p>\n\
    <h2><a id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#starting-a-daemon\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>BAKE ships with a\
    \ default daemon program that can setup providers and attach\nto storage targets.\
    \ This daemon can be started as follows:</p>\n<p><code>bake-server-daemon [options]\
    \ &lt;listen_address&gt; &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n\
    <p>The program takes a set of options followed by an address at which to listen\
    \ for\nincoming RPCs, and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n\
    <p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234\
    \ /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n\
    <ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the\
    \ address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em>\
    \ or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates\
    \ that, if multiple BAKE targets are used (as above),\nthese targets should be\
    \ managed by multiple providers, accessible through\ndifferent multiplex ids 1,\
    \ 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage.\
    \ The <em>targets</em> mode indicates that a single provider should be used to\n\
    manage all the storage targets.</p>\n<h2><a id=\"user-content-integrating-bake-into-a-larger-service\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#integrating-bake-into-a-larger-service\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Integrating\
    \ Bake into a larger service</h2>\n<p>Bake is not intended to be a standalone\
    \ user-facing service.  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\"\
    \ rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for\
    \ guidance on how to\nintegrate it with other providers using Mochi's Bedrock\
    \ capability.</p>\n<h2><a id=\"user-content-client-api-example\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#client-api-example\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Client API example</h2>\n<p>Data\
    \ is stored in <code>regions</code> within a <code>target</code> using explicit\
    \ create,\nwrite, and persist operations.  The caller cannot dictate the region\
    \ id\nthat will be used to reference a region; this identifier is generated\n\
    by Bake at creation time.  The region size must be specified at creation\ntime\
    \ as well; there is no mechanism for extending the size of an existing\nregion.</p>\n\
    <div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">#include</span>\
    \ <span class=\"pl-s\">&lt;bake-client.h&gt;</span>\n\n<span class=\"pl-smi\"\
    >int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">int</span>\
    \ <span class=\"pl-s1\">argc</span>, <span class=\"pl-smi\">char</span> <span\
    \ class=\"pl-c1\">*</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >argv</span>)\n{\n    <span class=\"pl-smi\">char</span> <span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">svr_addr_str</span>; <span class=\"pl-c\">// string\
    \ address of the BAKE server</span>\n    <span class=\"pl-smi\">hg_addr_t</span>\
    \ <span class=\"pl-s1\">svr_addr</span>; <span class=\"pl-c\">// Mercury address\
    \ of the BAKE server</span>\n    <span class=\"pl-smi\">margo_instance_id</span>\
    \ <span class=\"pl-s1\">mid</span>; <span class=\"pl-c\">// Margo instance id</span>\n\
    \    <span class=\"pl-smi\">bake_client_t</span> <span class=\"pl-s1\">bcl</span>;\
    \ <span class=\"pl-c\">// BAKE client</span>\n    <span class=\"pl-smi\">bake_provider_handle_t</span>\
    \ <span class=\"pl-s1\">bph</span>; <span class=\"pl-c\">// BAKE handle to provider</span>\n\
    \    <span class=\"pl-smi\">uint8_t</span> <span class=\"pl-s1\">mplex_id</span>;\
    \ <span class=\"pl-c\">// multiplex id of the provider</span>\n    <span class=\"\
    pl-smi\">uint32_t</span> <span class=\"pl-s1\">target_number</span>; <span class=\"\
    pl-c\">// target to use</span>\n    <span class=\"pl-smi\">bake_region_id_t</span>\
    \ <span class=\"pl-s1\">rid</span>; <span class=\"pl-c\">// BAKE region id handle</span>\n\
    \t<span class=\"pl-smi\">bake_target_id_t</span><span class=\"pl-c1\">*</span>\
    \ <span class=\"pl-s1\">bti</span>; <span class=\"pl-c\">// array of target ids</span>\n\
    \n\t<span class=\"pl-c\">/* ... setup variables ... */</span>\n\n\t<span class=\"\
    pl-c\">/* Initialize Margo */</span>\n\t<span class=\"pl-s1\">mid</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">margo_init</span>(..., <span\
    \ class=\"pl-c1\">MARGO_CLIENT_MODE</span>, <span class=\"pl-c1\">0</span>, <span\
    \ class=\"pl-c1\">-1</span>);\n\t<span class=\"pl-c\">/* Lookup the server */</span>\n\
    \t<span class=\"pl-en\">margo_addr_lookup</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr_str</span>, <span class=\"pl-c1\">&amp;</span><span\
    \ class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-c\">/* Creates the BAKE\
    \ client */</span>\n\t<span class=\"pl-en\">bake_client_init</span>(<span class=\"\
    pl-s1\">mid</span>, <span class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bcl</span>);\n\
    \t<span class=\"pl-c\">/* Creates the provider handle */</span>\n\t<span class=\"\
    pl-en\">bake_provider_handle_create</span>(<span class=\"pl-s1\">bcl</span>, <span\
    \ class=\"pl-s1\">svr_addr</span>, <span class=\"pl-s1\">mplex_id</span>, <span\
    \ class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bph</span>);\n\t<span class=\"\
    pl-c\">/* Asks the provider for up to target_number target ids */</span>\n\t<span\
    \ class=\"pl-smi\">uint32_t</span> <span class=\"pl-s1\">num_targets</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-c1\">0</span>;\n\t<span class=\"pl-s1\"\
    >bti</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">calloc</span>(<span\
    \ class=\"pl-s1\">num_targets</span>, <span class=\"pl-k\">sizeof</span>(<span\
    \ class=\"pl-c1\">*</span><span class=\"pl-s1\">bti</span>));\n\t<span class=\"\
    pl-en\">bake_probe</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >target_number</span>, <span class=\"pl-s1\">bti</span>, <span class=\"pl-c1\"\
    >&amp;</span><span class=\"pl-s1\">num_targets</span>);\n\t<span class=\"pl-k\"\
    >if</span>(<span class=\"pl-s1\">num_targets</span> <span class=\"pl-c1\">&lt;</span>\
    \ <span class=\"pl-s1\">target_number</span>) {\n\t\t<span class=\"pl-en\">fprintf</span>(<span\
    \ class=\"pl-s1\">stderr</span>, <span class=\"pl-s\">\"Error: provider has only\
    \ %d storage targets\\n\"</span>, <span class=\"pl-s1\">num_targets</span>);\n\
    \t}\n\t<span class=\"pl-c\">/* Create a region */</span>\n\t<span class=\"pl-smi\"\
    >size_t</span> <span class=\"pl-s1\">size</span> <span class=\"pl-c1\">=</span>\
    \ ...; <span class=\"pl-c\">// size of the region to create</span>\n\t<span class=\"\
    pl-en\">bake_create</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >bti</span>[<span class=\"pl-s1\">target_number</span><span class=\"pl-c1\">-</span><span\
    \ class=\"pl-c1\">1</span>], <span class=\"pl-s1\">size</span>, <span class=\"\
    pl-c1\">&amp;</span><span class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\"\
    >/* Write data into the region at offset 0 */</span>\n\t<span class=\"pl-smi\"\
    >char</span><span class=\"pl-c1\">*</span> <span class=\"pl-s1\">buf</span> <span\
    \ class=\"pl-c1\">=</span> ...;\n\t<span class=\"pl-en\">bake_write</span>(<span\
    \ class=\"pl-s1\">bph</span>, <span class=\"pl-s1\">rid</span>, <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-s1\">buf</span>, <span class=\"pl-s1\">size</span>);\n\
    \t<span class=\"pl-c\">/* Make all modifications persistent */</span>\n\t<span\
    \ class=\"pl-en\">bake_persist</span>(<span class=\"pl-s1\">bph</span>, <span\
    \ class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\">/* Release provider handle\
    \ */</span>\n\t<span class=\"pl-en\">bake_provider_handle_release</span>(<span\
    \ class=\"pl-s1\">bph</span>);\n\t<span class=\"pl-c\">/* Release BAKE client\
    \ */</span>\n\t<span class=\"pl-en\">bake_client_finalize</span>(<span class=\"\
    pl-s1\">bcl</span>);\n\t<span class=\"pl-c\">/* Cleanup Margo resources */</span>\n\
    \t<span class=\"pl-en\">margo_addr_free</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-en\">margo_finalize</span>(<span\
    \ class=\"pl-s1\">mid</span>);\n\t<span class=\"pl-k\">return</span> <span class=\"\
    pl-c1\">0</span>;\n}</pre></div>\n<p>Note that a <code>bake_region_id_t</code>\
    \ object is persistent.  It can be written\n(into a file or a socket) and stored\
    \ or sent to another program. These\nregion ids are what uniquely reference a\
    \ region within a given target.</p>\n<p>The rest of the client-side API can be\
    \ found in <code>bake-client.h</code>.</p>\n<h2><a id=\"user-content-provider-api\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#provider-api\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider\
    \ API</h2>\n<p>The bake-server-daemon source is a good example of how to create\
    \ providers and\nattach storage targets to them. The provider-side API is located\
    \ in\n<em>bake-server.h</em>, and consists of mainly two functions:</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre><span class=\"pl-smi\">int</span>\
    \ <span class=\"pl-en\">bake_provider_register</span>(<span class=\"pl-smi\">margo_instance_id</span>\
    \                     <span class=\"pl-s1\">mid</span>,\n                    \
    \       <span class=\"pl-smi\">uint16_t</span>                              <span\
    \ class=\"pl-s1\">provider_id</span>,\n                           <span class=\"\
    pl-k\">const</span> <span class=\"pl-k\">struct</span> <span class=\"pl-smi\"\
    >bake_provider_init_info</span><span class=\"pl-c1\">*</span> <span class=\"pl-s1\"\
    >args</span>,\n                           <span class=\"pl-smi\">bake_provider_t</span><span\
    \ class=\"pl-c1\">*</span>                      <span class=\"pl-s1\">provider</span>);</pre></div>\n\
    <p>This creates a provider at the given provider id using the specified margo\n\
    instance.  The <code>args</code> parameter can be used to modify default settings,\n\
    including passing in a fully specified json configuration block.  See\n<code>bake-server.h</code>\
    \ for details.</p>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"\
    pl-smi\">int</span> <span class=\"pl-en\">bake_provider_attach_target</span>(<span\
    \ class=\"pl-smi\">bake_provider_t</span>   <span class=\"pl-s1\">provider</span>,\n\
    \                                <span class=\"pl-k\">const</span> <span class=\"\
    pl-smi\">char</span><span class=\"pl-c1\">*</span>       <span class=\"pl-s1\"\
    >target_name</span>,\n                                <span class=\"pl-smi\">bake_target_id_t</span><span\
    \ class=\"pl-c1\">*</span> <span class=\"pl-s1\">target_id</span>);</pre></div>\n\
    <p>This makes the provider manage the given storage target.</p>\n<p>Other functions\
    \ are available to create and detach targets from a provider.</p>\n<h2><a id=\"\
    user-content-generic-bake-benchmark\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#generic-bake-benchmark\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Generic Bake benchmark</h2>\n<p>By using <code>--enable-benchmark</code>\
    \ when compiling Bake (or <code>+benchmark</code> when using Spack),\nyou will\
    \ build a <code>bake-benchmark</code> program that can be used as a configurable\
    \ benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure\
    \ Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n<p>The benchmark\
    \ is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a\
    \ server, while non-zero ranks act as clients. The server will not create\na Bake\
    \ target. The Bake target needs to be created (with <code>bake-makepool</code>)\
    \ beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing\
    \ the sequence\nof benchmarks to execute. An example of such a file is located\
    \ in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code>\
    \ array corresponds to a benchmark. The <code>type</code> field indicates\nthe\
    \ type of benchmark to execute. The <code>repetitions</code> field indicates how\
    \ many times the\nbenchmark should be repeated.</p>\n<p>The following table describes\
    \ each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n\
    <th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n\
    </tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to\
    \ the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n\
    <td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for\
    \ each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n\
    <td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's\
    \ buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n\
    <td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n\
    <td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions,\
    \ or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether\
    \ to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n\
    </tbody>\n</table>\n<h2><a id=\"user-content-manual-installation\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#manual-installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manual installation</h2>\n<p>BAKE\
    \ depends on the following libraries:</p>\n<ul>\n<li>uuid (install uuid-dev package\
    \ on ubuntu)</li>\n<li>PMDK (see instructions below)</li>\n<li>json-c</li>\n<li>mochi-abt-io</li>\n\
    <li>mochi-margo</li>\n</ul>\n<p>Bake will automatically identify these dependencies\
    \ at configure time using\npkg-config. To compile BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n\
    <li><code>mkdir build</code></li>\n<li><code>cd build</code></li>\n<li><code>../configure\
    \ --prefix=/home/carns/working/install</code></li>\n<li><code>make</code></li>\n\
    </ul>\n<p>If any dependencies are installed in a nonstandard location, then\n\
    modify the configure step listed above to include the following argument:</p>\n\
    <ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1633975151.0
mochi-hpc/mochi-raft:
  data_format: 2
  description: Mochi-based implementation of RAFT using c-raft
  filenames:
  - polaris-spack.yaml
  full_name: mochi-hpc/mochi-raft
  latest_release: null
  readme: '<h1><a id="user-content-mochi-raft" class="anchor" aria-hidden="true" tabindex="-1"
    href="#mochi-raft"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi-RAFT</h1>

    <p>This repository provides an implementation of the RAFT protocol using

    Margo for communication and <a href="https://github.com/canonical/raft">C-Raft</a>

    for the protocol itself.</p>

    <p>Mochi-RAFT (Mraft) is modular and allows users to provide their own

    implementation of a persistent log.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1692622489.0
mochi-hpc/mochi-sdskv:
  data_format: 2
  description: simple margo-projected keyval service
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-sdskv
  latest_release: v0.1.14
  readme: "<h1><a id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sdskv-sds-keyval\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>SDSKV (SDS Key/Val)</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>SDSKV can easily be installed using Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n\
    <p>This will install SDSKV (and any required dependencies).\nAvailable backends\
    \ will be <em>Map</em> (in-memory C++ std::map, useful for testing)\nand BwTree\
    \ (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code>\
    \ and <code>+leveldb</code> respectively. For example:</p>\n<p><code>spack install\
    \ sdskeyval+bdb+leveldb</code></p>\n<p>Note that if you are using a system boost\
    \ path in spack (in your\npackages.yaml) rather than letting spack build boost,\
    \ then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages\
    \ on\nyour system.</p>\n<h2><a id=\"user-content-architecture\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#architecture\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>List most\
    \ mochi services, SDSKV relies on a client/provider architecture.\nA provider,\
    \ identified by its <em>address</em> and <em>multiplex id</em>, manages one or\
    \ more\ndatabases, referenced externally by their database id.</p>\n<h2><a id=\"\
    user-content-starting-a-daemon\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#starting-a-daemon\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Starting a daemon</h2>\n<p>SDSKV ships with a default daemon program\
    \ that can setup providers and\ndatabases. This daemon can be started as follows:</p>\n\
    <p><code>sdskv-server-daemon [OPTIONS] &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb]\
    \ &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb] ...</code></p>\n<p>For example:</p>\n\
    <p><code>sdskv-server-daemon tcp://localhost:1234 foo:bdb bar</code></p>\n<p>listen_addr\
    \ is the address at which to listen; database names should be provided in the\
    \ form\n<em>name:type</em> where <em>type</em> is <em>map</em> (std::map), <em>bwt</em>\
    \ (BwTree), <em>bdb</em> (Berkeley DB), or <em>ldb</em> (LevelDB).</p>\n<p>For\
    \ database that are persistent like BerkeleyDB or LevelDB, the name should be\
    \ a path to the\nfile where the database will be put (this file should not exist).</p>\n\
    <p>The following additional options are accepted:</p>\n<ul>\n<li>\n<code>-f</code>\
    \ provides the name of the file in which to write the address of the daemon.</li>\n\
    <li>\n<code>-m</code> provides the mode (providers or databases).</li>\n</ul>\n\
    <p>The providers mode indicates that, if multiple SDSKV databases are used (as\
    \ above),\nthese databases should be managed by multiple providers, accessible\
    \ through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\n\
    to manage. The targets mode indicates that a single provider should be used to\n\
    manage all the databases. This provider will be accessible at multiplex id 1.</p>\n\
    <h2><a id=\"user-content-client-api\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#client-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Client API</h2>\n<p>The client API is available in <em>sdskv-client.h</em>.\n\
    The codes in the <em>test</em> folder illustrate how to use it.</p>\n<h2><a id=\"\
    user-content-provider-api\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#provider-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Provider API</h2>\n<p>The server-side API is available in <em>sdskv-server.h</em>.\n\
    The code of the daemon (<em>src/sdskv-server-daemon.c</em>) can be used as an\
    \ example.</p>\n<h3><a id=\"user-content-custom-key-comparison-function\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#custom-key-comparison-function\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Custom key\
    \ comparison function</h3>\n<p>It is possible to specify a custom function for\
    \ comparing/sorting keys\nwhen creating a provider. A comparison function must\
    \ have the following prototype:</p>\n<p><code>int (*)(const void* key1, size_t\
    \ keysize1, const void* key2, size_t keysize2)</code></p>\n<p>Its return value\
    \ must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0 if key1 &gt; key2.\n\
    It must define a total order of the key space.</p>\n<h2><a id=\"user-content-c-api\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#c-api\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ API</h2>\n\
    <p>An object-oriented C++ API is available in <code>sdskv-client.hpp</code> and\
    \ <code>sdskv-server.hpp</code>.\nOn the client side this API provides the <code>client</code>,\
    \ <code>provider_handle</code>, and <code>database</code> objects.\nExamples of\
    \ usage of these objects can be found in the <code>test/sdskv-cxx-test.cc</code>.\n\
    On the server side, this API provides a <code>provider</code> object.</p>\n<h2><a\
    \ id=\"user-content-benchmark\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#benchmark\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Benchmark</h2>\n<p>SDSKV can be compiled with <code>--enable-benchmark</code>\
    \ (or <code>+benchmark</code> in Spack). In this case,\nSDSKV requires the JsonCPP\
    \ and MPI dependencies (when compiling manually, use <code>CXX=mpicxx</code> in\n\
    your configure step, for example), and it will build and install the <code>sdskv-benchmark</code>\
    \ program.</p>\n<p>This program is an MPI program that reads a JSON file describing\
    \ a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server.\
    \ Other ranks act as clients, all executing\nthis access pattern.</p>\n<p>The\
    \ following is an example of a JSON file.</p>\n<div class=\"highlight highlight-source-json\"\
    ><pre>{\n\t<span class=\"pl-ent\">\"protocol\"</span> : <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span\
    \ class=\"pl-ent\">\"seed\"</span> : <span class=\"pl-c1\">0</span>,\n\t<span\
    \ class=\"pl-ent\">\"server\"</span> : {\n\t\t<span class=\"pl-ent\">\"use-progress-thread\"\
    </span> : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-ent\">\"rpc-thread-count\"\
    </span> : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-ent\">\"database\"\
    </span> : {\n\t\t\t<span class=\"pl-ent\">\"type\"</span> : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\">\"</span></span>,\n\
    \t\t\t<span class=\"pl-ent\">\"name\"</span> : <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t\
    <span class=\"pl-ent\">\"path\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/dev/shm<span class=\"pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span\
    \ class=\"pl-ent\">\"benchmarks\"</span> : [\n\t{\n\t\t<span class=\"pl-ent\"\
    >\"type\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span\
    \ class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-ent\">\"repetitions\"\
    </span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-ent\">\"num-entries\"\
    </span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-ent\">\"key-sizes\"\
    </span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span> ],\n\
    \t\t<span class=\"pl-ent\">\"val-sizes\"</span> : [ <span class=\"pl-c1\">24</span>,\
    \ <span class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-ent\">\"erase-on-teardown\"\
    </span> : <span class=\"pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-ent\"\
    >\"type\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>get<span\
    \ class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-ent\">\"repetitions\"\
    </span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-ent\">\"num-entries\"\
    </span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-ent\">\"key-sizes\"\
    </span> : <span class=\"pl-c1\">64</span>,\n\t\t<span class=\"pl-ent\">\"val-sizes\"\
    </span> : <span class=\"pl-c1\">128</span>,\n\t\t<span class=\"pl-ent\">\"erase-on-teardown\"\
    </span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n<p>The JSON\
    \ file starts with the protocol to use, and a seed for the random-number generator\
    \ (RNG).\nThe actual seed used on each rank will actually be a function of this\
    \ global seed and the rank of\nthe client. The RNG will be reset with this seed\
    \ after each benchmark.</p>\n<p>The <code>server</code> field sets up the provider\
    \ and the database. Database types can be <code>map</code>, <code>ldb</code>,\
    \ or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which\
    \ is a list of benchmarks to execute. Each benchmark is composed\nof three steps.\
    \ A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em>\
    \ phase. The setup phase may for\nexample store a bunch of keys in the database\
    \ that the execution phase will read by (in the case of a\n<em>get</em> benchmark,\
    \ for example). The teardown phase will usually remove all the keys that were\
    \ written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n\
    <p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>,\
    \ <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n\
    <code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>),\
    \ and a number of repetitions. The benchmark will be\nexecuted as many times as\
    \ requested (without resetting the RNG in between repetitions). Taking the\nexample\
    \ of the <code>put</code> benchmark above, each repetition will put 30 key/value\
    \ pairs into the database.\nThe key size will be chosen randomly in a uniform\
    \ manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size\
    \ will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded).\
    \ Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI\
    \ barrier between clients is executed in between each benchmark and in between\
    \ the setup,\nexecution, and teardown phases, so that the execution phase is always\
    \ executed at the same time\non all the clients. Once all the repetitions are\
    \ done for a given benchmark entry, the program\nwill report statistics on the\
    \ timings: average time, variance, standard deviation, mininum, maximum,\nmedian,\
    \ first and third quartiles. Note that these times are for a repetition, not for\
    \ single operations\nwithin a repetition. To get the timing of each individual\
    \ operation, it is then necessary to divide\nthe times by the number of key/value\
    \ pairs involved in the benchmark.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1635867720.0
mochi-hpc/mochi-sonata:
  data_format: 2
  description: Sonata is a Mochi service for JSON document storage. It is based on
    UnQLite and Thallium.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-sonata
  latest_release: v0.6.3
  readme: '<h1><a id="user-content-what-is-sonata" class="anchor" aria-hidden="true"
    tabindex="-1" href="#what-is-sonata"><span aria-hidden="true" class="octicon octicon-link"></span></a>What
    is Sonata?</h1>

    <p>Sonata is a remotely-accessibl JSON document store based on UnQLite and on

    the Mochi suit of libraries. It enables managing collections of JSON records,

    searching through them, and running Jx9 scripts on them.</p>

    <h1><a id="user-content-got-some-examples" class="anchor" aria-hidden="true" tabindex="-1"
    href="#got-some-examples"><span aria-hidden="true" class="octicon octicon-link"></span></a>Got
    some examples?</h1>

    <p>A comprehensive set of examples is available in <a href="examples">this directory</a>.</p>

    <h1><a id="user-content-how-do-i-install-sonata" class="anchor" aria-hidden="true"
    tabindex="-1" href="#how-do-i-install-sonata"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>How do I install Sonata?</h1>

    <p>The easiest way to install Sonata is to use <a href="https://spack.readthedocs.io"
    rel="nofollow">spack</a>.

    Once you have spack installed and setup on your machine, you need to added the

    mochi namespace to it, as follows.</p>

    <pre><code>git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    spack repo add mochi-spack-packages

    </code></pre>

    <p>You can now install Sonata as follows.</p>

    <pre><code>spack install mochi-sonata

    </code></pre>

    <h1><a id="user-content-and-then" class="anchor" aria-hidden="true" tabindex="-1"
    href="#and-then"><span aria-hidden="true" class="octicon octicon-link"></span></a>And
    then?</h1>

    <p>Sonata comes in three libraries: sonata-server, sonata-client, and sonata-admin.

    The server library contains the <code>sonata::Provider</code> class, which allows
    to start

    a Sonata service on a server program. The admin library contains the

    <code>sonata::Admin</code> class, which enables creating and destroying database
    on a

    running provider. The <code>sonata::Client</code> class is contained in the client
    library.

    This class provides the main interface to open a database, and manipulat

    collections.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1684096567.0
mochi-hpc/mochi-thallium:
  data_format: 2
  description: Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and
    providing an object-oriented way to use these libraries.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-thallium
  latest_release: v0.12.0
  readme: '<h1><a id="user-content-thallium" class="anchor" aria-hidden="true" tabindex="-1"
    href="#thallium"><span aria-hidden="true" class="octicon octicon-link"></span></a>Thallium</h1>

    <p>Thallium is a C++ interface to <a href="https://github.com/mochi-hpc/mochi-margo/">Margo</a>.

    It offers a modern, object-oriented way of developing HPC data services. More

    information can be found on <a href="https://mochi.readthedocs.io/en/latest/"
    rel="nofollow">Mochi''s readthedocs</a>

    website.</p>

    '
  stargazers_count: 10
  subscribers_count: 4
  topics: []
  updated_at: 1685720588.0
mochi-hpc/mochi-warabi:
  data_format: 2
  description: Blob storage service for Mochi
  filenames:
  - tests/spack.yaml
  full_name: mochi-hpc/mochi-warabi
  latest_release: v0.1.0
  readme: '<p>Warabi is a Blob-storage component for Mochi HPC services.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1695909045.0
mochi-hpc/py-mochi-bake:
  data_format: 2
  description: Python wrapper for BAKE
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-bake
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633975348.0
mochi-hpc/py-mochi-s4m:
  data_format: 2
  description: Python library using Mochi to broadcast data
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-s4m
  latest_release: null
  readme: '<h1><a id="user-content-mochi-s4m-share-for-me" class="anchor" aria-hidden="true"
    tabindex="-1" href="#mochi-s4m-share-for-me"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Mochi S4M (Share for Me)</h1>

    <p>This service provides a simple non-blocking broadcast/receive

    mechanism based on Mochi.</p>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <p>Make sure you have <a href="https://spack.io/" rel="nofollow">spack</a> installed
    and setup.

    If needed, install it and set it up as follows:</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>You then need to clone the <code>mochi-spack-packages</code> repository

    and make it available to spack:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Finally, you can install S4M as follows:</p>

    <pre><code>$ spack install py-mochi-s4m

    </code></pre>

    <h2><a id="user-content-using" class="anchor" aria-hidden="true" tabindex="-1"
    href="#using"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using</h2>

    <p>S4M has a very simple API consisting of an <code>S4MService</code> class with

    two functions: <code>broadcast</code>, and <code>receive</code>. It requires mpi4py
    to

    bootstrap the set of processes. The <a href="test/test.py">test.py</a> file

    provides a comprehensive use case.</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1663070268.0
mochi-hpc/py-mochi-sonata:
  data_format: 2
  description: Python binding to the Mochi Sonata microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-sonata
  latest_release: null
  readme: '<p>Py-Sonata is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-sonata">Sonata
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975502.0
mochi-hpc/thallium-microservice-template:
  data_format: 2
  description: Template for a thallium-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/thallium-microservice-template
  latest_release: null
  readme: '<h1><a id="user-content-thallium-microservice-template" class="anchor"
    aria-hidden="true" tabindex="-1" href="#thallium-microservice-template"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Thallium Microservice
    Template</h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Thallium.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/02_thallium.html" rel="nofollow">here</a>.</p>

    <p>To use this template:</p>

    <ul>

    <li>Click on the green "Use this template" button at the top.</li>

    <li>Give a name to your project.</li>

    <li>Once your project repository is created, go to Settings &gt; Actions &gt;
    General and give "Read and write permissions" under <em>Workflow permissions</em>.</li>

    <li>Finally, edit the initial-setup.json file and push the changes to your repo.</li>

    </ul>

    <p>Editing the initial-setup.json file with trigger a github action that will

    cleanup your repository and rename files, namespaces, functions, etc. according

    to the name of your service and the resources it manages.</p>

    <p>Enjoy working with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1649080284.0
mpbelhorn/olcf-spack:
  data_format: 2
  description: Spack fork used on OLCF resources
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  full_name: mpbelhorn/olcf-spack
  latest_release: null
  readme: "<h1><a id=\"user-content--spack\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\"\
    \ href=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions?query=workflow%3A%22macOS+builds+nightly%22\"\
    ><img src=\"https://github.com/spack/spack/workflows/macOS%20builds%20nightly/badge.svg?branch=develop\"\
    \ alt=\"macOS Builds (nightly)\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/4bbdc2b44561be6dfffe64e15730e1c5a2bed9c4efe6f9942638091a4ce3ede2/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p><a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <h2><a id=\"user-content-tutorial\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Tutorial</h2>\n<p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<h2><a id=\"user-content-community\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#community\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Community</h2>\n<p>Spack is an open source project.\
    \  Questions, discussion, and\ncontributions are welcome. Contributions can be\
    \ anything from new\npackages to bugfixes, documentation, or even new core features.</p>\n\
    <p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<strong>Mailing\
    \ list</strong>: <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\"\
    >groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>: <a\
    \ href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n\
    <p>Contributing to Spack is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2><a id=\"user-content-releases\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Releases</h2>\n<p>For multi-user site deployments or other use cases\
    \ that need very stable\nsoftware installations, we recommend using Spack's\n\
    <a href=\"https://github.com/spack/spack/releases\">stable releases</a>.</p>\n\
    <p>Each Spack release series also has a corresponding branch, e.g.\n<code>releases/v0.14</code>\
    \ has <code>0.14.x</code> versions of Spack, and <code>releases/v0.13</code> has\n\
    <code>0.13.x</code> versions. We backport important bug fixes to these branches\
    \ but\nwe do not advance the package versions or make other changes that would\n\
    change the way Spack concretizes dependencies within a release branch.\nSo, you\
    \ can base your Spack deployment on a release branch and <code>git pull</code>\n\
    to get fixes, without the package churn that comes with <code>develop</code>.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<p>See the <a href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\"\
    \ rel=\"nofollow\">docs on releases</a>\nfor more details.</p>\n<h2><a id=\"user-content-code-of-conduct\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#code-of-conduct\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Code of\
    \ Conduct</h2>\n<p>Please note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"\
    ><strong>Code of Conduct</strong></a>. By participating in\nthe Spack community,\
    \ you agree to abide by its rules.</p>\n<h2><a id=\"user-content-authors\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#authors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>Many thanks\
    \ go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\"\
    >tgamblin@llnl.gov</a>.</p>\n<h3><a id=\"user-content-citing-spack\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Citing Spack</h3>\n<p>If you\
    \ are referencing Spack in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee,\n\
    Adam Moody, Bronis R. de Supinski, and W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>Spack is distributed under the terms of both the MIT license and the\nApache\
    \ License (Version 2.0). Users may choose either license, at their\noption.</p>\n\
    <p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n\
    <p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1580743748.0
mpbelhorn/olcf-spack-environments:
  data_format: 2
  description: Spack environments for OLCF resources.
  filenames:
  - hosts/borg/envs/base/spack.yaml
  - hosts/ascent/envs/base-rh7/spack.yaml
  - hosts/summit/envs/base/spack.yaml
  - hosts/ascent/envs/base/spack.yaml
  - hosts/peak/envs/base/spack.yaml
  - hosts/frontier/envs/base/spack.yaml
  full_name: mpbelhorn/olcf-spack-environments
  latest_release: null
  readme: '<h1><a id="user-content-olcf-spack-environments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#olcf-spack-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>OLCF Spack Environments</h1>

    <p>This repo contains the infrastructure and environment definitions to deploy

    site-provided software on OLCF resources via Spack environments.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started</h2>

    <p>Clone this repo and it''s facility-modified spack fork somewhere on an OLCF

    filesystem:</p>

    <pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git

    </code></pre>

    <p>or</p>

    <pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments

    </code></pre>

    <p>Next, initialize spack and the build environment. This is done by calling</p>

    <pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base
    . ./init-facility-spack.sh

    </code></pre>

    <p>This will configure the spack build- and run-time environment build and install

    the facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this
    repo for the

    current machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both
    of these

    variables are optional. If omitted, each variable will take on their default

    values:</p>

    <pre><code>FACSPACK_MY_ENVS="/sw/${_THIS_HOST}/spack-envs"

    FACSPACK_ENV_NAME="base"

    </code></pre>

    <p>such that sourcing this script by itself</p>

    <pre><code>. ./init-facility-spack.sh

    </code></pre>

    <p>will setup the runtime shell environment to manipulate the production spack

    environment on the current system.</p>

    <p>This repo will always track at least one spack environment per machine named

    <code>base</code> which is the complete standard software environment used in
    production

    for that machine. Furthermore, only the user account with owner permissions on

    the production environment may be used to manipulate it in the default

    <code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent
    multiple

    users from concurrently modifying the production environment. Users may set an

    alternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using
    any

    tracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file
    in this repo.</p>

    <p>From these variables, a unique path per each environment name will be

    constructed:</p>

    <pre><code>FACSPACK_ENV="${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}"

    </code></pre>

    <p>The value of <code>${_THIS_HOST}</code> is determined automatically from the
    hostname on

    which the init script is being run. For each system and environment tracked in

    this repo that you wish to work on, ensure that the final expanded value of

    <code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>

    <p>Configuration paths in our <code>spack.yaml</code> environments that are not
    fixed to

    universal values are expressed in terms of relative paths to either the spack

    instance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.

    These paths are referenced in the <code>spack.yaml</code> files via environment
    variables

    set by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code>
    environment files to

    define portable and relocatable spack environments which can be re-deployed in

    arbitrary private locations by any users without needing to modify the

    environment file.</p>

    <p>The following variables are exported in Spack''s runtime environment by

    <code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code>
    the enviornment

    files tracked in this repo.</p>

    <ul>

    <li>

    <code>${FACSPACK_ENV}</code>:

    Path to where spack environment will be installed. Contains subdirs <code>opt</code>

    and <code>modules</code>.</li>

    <li>

    <code>${FACSPACK_ENV_MODULEROOT}</code>:

    Shortcut to <code>${FACSPACK_ENV}/modules</code> under which static and

    spack-generated modules are generated. Contains subdirectories <code>spack</code>,

    <code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static
    modulefiles

    respectively.</li>

    <li>

    <code>${FACSPACK_CONF_COMMON}</code>:

    Path to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>

    <li>

    <code>${FACSPACK_CONF_HOST}</code>:

    Path to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>

    </li>

    </ul>

    <p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>

    files which cannot de-reference environment variables. These affect</p>

    <ul>

    <li>Mirrors</li>

    <li>Extensions</li>

    </ul>

    <p>Spack does not internally expand environment variables in the configuration
    of

    these items so they must be expressed as hard-coded full path strings. The

    default values in this repo should point to permanent world-readable paths on

    the OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>

    <h2><a id="user-content-spack-fork" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-fork"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Fork</h2>

    <p>The upstream development branch of spack is not used directly. Instead, the
    OLCF

    has implemented some customizations that are tracked in the "olcf-X.Y.Z"

    branches of a <a href="https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0">facility
    fork of spack</a>

    where <code>X.Y.Z</code> refers to the tagged release of upstream spack from which
    the

    OLCF-modified branch is forked.</p>

    '
  stargazers_count: 3
  subscribers_count: 2
  topics: []
  updated_at: 1698198568.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - linux-centos7-broadwell/or-slurm/spack.yaml
  - linux-sles15-zen2/spock/spack.yaml
  - linux-rhel8-ppc64le/summit/spack.yaml
  - cray-sles15-zen3/frontier/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_environments.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2><a id="user-content-purpose" class="anchor" aria-hidden="true" tabindex="-1"
    href="#purpose"><span aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 4
  subscribers_count: 20
  topics: []
  updated_at: 1670008521.0
onkarbpatil/IPDPS2020-benchmarks:
  data_format: 2
  description: null
  filenames:
  - SICM/spack.yaml
  full_name: onkarbpatil/IPDPS2020-benchmarks
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1591368300.0
openPMD/openPMD-api:
  data_format: 2
  description: ':floppy_disk: C++ & Python API for Scientific I/O'
  filenames:
  - spack.yaml
  full_name: openPMD/openPMD-api
  latest_release: 0.15.2
  readme: "<h1><a id=\"user-content-c--python-api-for-scientific-io-with-openpmd\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#c--python-api-for-scientific-io-with-openpmd\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ &amp;\
    \ Python API for Scientific I/O with openPMD</h1>\n<p><a href=\"https://github.com/openPMD/openPMD-standard/releases\"\
    ><img src=\"https://camo.githubusercontent.com/5957dc11cb68f6705ef9ef6683152c6c4fcc057a24dff340e1e8bada1bee0d01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\"\
    \ alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d54fa5adcf7ca50d2cdb45823be5064379b613d526fa06f6e193ba2ce616318/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/f551141eea2176c34aa163092549d6fdde9a220d605d6efe9128b024c6e5932b/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\"\
    \ alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"\
    https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"\
    max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4fc8091716dbd967fa2a82eef3d29227110e5081f3128aaa38663e547c24f812/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/104f6901ae04bff8385acc8273bb276ab84656a927a418108b940d09fd6e5d7c/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0d568047fbbd300af56b766d9a4235a20534485f5827194e859d4f5c20e58334/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\"\
    \ alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f0487a8fc14d269210ae8ce80b556d4afcd93684f02e61386d2d02daa4423cbd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f438ca4eaa308f982d0a28c48f05bf63ca1a86e52c3d2817f6d7559d1dee68e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8278d89e3634e25a818a2d673fe997c2aa5a09fd5995f716aeffa743388030ee/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\"\
    \ alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/30679331f3c6a5ae54970eda85f36a30347dee8a9111448d7aa48587fd524a1d/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\"\
    \ alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\
    ><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\"\
    \ alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fc9c860bb1fc8e7e145ea9dd6723b9ac6ac2743c195e5e899f6cfa3d38a5a69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\"\
    \ alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0b068d7b5718aafccb46e2ee35f8249938ef189a36ba353c15222ed5e6f65e49/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\"\
    \ alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD is an open meta-data schema\
    \ that provides meaning and self-description for data sets in science and engineering.\n\
    See <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a>\
    \ for details of this schema.</p>\n<p>This library provides a reference API for\
    \ openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable,\
    \ hierarchical file formats, this library implements various backends such as\
    \ HDF5, ADIOS2 and JSON.\nWriting &amp; reading through those backends and their\
    \ associated files are supported for serial and <a href=\"https://www.mpi-forum.org/docs/\"\
    \ rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#usage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <h3><a id=\"user-content-c\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#c\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++</h3>\n\
    <p><a href=\"https://isocpp.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d47ea5fd5ff323ff5c76593ea37f2340533c73de5e6e37a2b27d7dc28070cd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\"\
    \ alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span>\
    \ s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span\
    \ class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"\
    pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>\
    \ &amp; [step, it] : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span>\
    \ &lt;&lt; step &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span\
    \ class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\"\
    >const</span> &amp; [name, mesh] : it.<span class=\"pl-smi\">meshes</span> ) {\n\
    \        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\
    \  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; name &lt;&lt; <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\"\
    >\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\"\
    >for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp;\
    \ val : mesh.<span class=\"pl-c1\">attributes</span>() )\n            std::cout\
    \ &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"\
    pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\
    \    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span>\
    \ <span class=\"pl-k\">const</span> &amp; [name, species] : it.<span class=\"\
    pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"\
    </span></span> &lt;&lt; name &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\"\
    >auto</span> <span class=\"pl-k\">const</span>&amp; val : species.<span class=\"\
    pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt;\
    \ val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n\
    <h3><a id=\"user-content-python\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#python\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Python</h3>\n<p><a href=\"https://www.python.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\"\
    \ alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span>\
    \ <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"\
    pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span\
    \ class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\"\
    >io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\
    \n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"\
    pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span\
    \ class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n  \
    \  <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\
    \n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span\
    \ class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n\
    \        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}'\
    \ attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\"\
    >k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"\
    pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span\
    \ class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span\
    \ class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"\
    pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"\
    pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n  \
    \          <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n\
    <h3><a id=\"user-content-more\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#more\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>More!</h3>\n<p>Curious?\nOur manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\"\
    \ rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n\
    <h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Dependencies</h2>\n<p>Required:</p>\n<ul>\n<li>CMake\
    \ 3.15.0+</li>\n<li>C++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+,\
    \ icpc 19+, icpx</li>\n</ul>\n<p>Shipped internally in <code>share/openPMD/thirdParty/</code>:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> 2.13.10+\
    \ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\">BSL-1.0</a>)</li>\n\
    <li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> 2.11.1+ (<a\
    \ href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)</li>\n\
    <li>\n<a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a> 3.9.1+ (<a\
    \ href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\">MIT</a>)</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> 3.7.1+ (<a href=\"\
    https://github.com/ToruNiina/toml11/blob/master/LICENSE\">MIT</a>)</li>\n</ul>\n\
    <p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\"\
    \ rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\"\
    \ rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either\
    \ with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n\
    </ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python\
    \ 3.8 - 3.12</li>\n<li>pybind11 2.11.1+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py\
    \ 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n\
    <li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n<li>CUDA C++\
    \ (optional, currently used only in tests)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/580cdb6331254f66680bd967326d9630f5124291efd5ace18549fbb93cbae6db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3c3728308a9e416589fa8b3b8168967287c515037bfbd4b40f1b14f266de56fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/92b7b7bb69b2b17d1981ae5fdcdb32f971ee57f54a98ea4804e93fd0a2eb58ef/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4eeb2c48c0e554ea8dbe8e90f73a6f2d217e775e0bd5e5cb90ddf4619ef3a6a0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/2babf79954ea524c24f2f9b1cfa05728fdaccbe0a80c2da6a7a7595cc131894c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\"\
    \ alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our community loves to help each other.\n\
    Please <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\"\
    >report installation problems</a> in case you should get stuck.</p>\n<p>Choose\
    \ <em>one</em> of the install methods below to get started:</p>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://spack.io\" rel=\"nofollow\">Spack</a></h3>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/becffbecb6a50502286f02ec86c4e62f239f3671148d11341152e0dc695a2fc9/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\"\
    \ alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b29fc54abf92a2a6d1d2c70159eb276df53b67a1294ae3f82b1b0bf22a3c586b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\"\
    \ alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \    +python -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack load\
    \ openpmd-api</pre></div>\n<h3><a id=\"user-content-conda\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#conda\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a></h3>\n\
    <p><a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img\
    \ src=\"https://camo.githubusercontent.com/3ad2b345bb3589aa2d733ca20df72938ed54a48342b69f7cbe9eacab43d84549/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a51d3cd2bfa3c6b01bd0f2e36abc206fb9db5700105fac2acd2c2105fced2ec4/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \           OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\n\
    conda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n\
    <h3><a id=\"user-content-brew\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#brew\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"https://brew.sh\" rel=\"nofollow\">Brew</a></h3>\n<p><a\
    \ href=\"https://github.com/openPMD/homebrew-openPMD\"><img src=\"https://camo.githubusercontent.com/d873c8c473fece8abf1c34a8299a50b7ee0da9772eb50cce8649e7ca32468a6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\"\
    \ alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/7b767b67facc26db7d850ae5c3155fa949048991dde7a0f5471c1e6862f0a586/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\"\
    \ alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<h3><a id=\"\
    user-content-pypi\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #pypi\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a></h3>\n<p><a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fc28bd368523d0b8adab5f4b414aebb304743130eef42bca203f4e9eed428ae7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\"\
    \ alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7cef25e887c028f65d5d7e20f3e7abe394ab328ecb499e34e47460afd2c78558/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\"\
    \ alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82acdd95515851a5ba4a3006871151f76cfe4d6583f6c24e80bd0fd29d391845/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\"\
    \ alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9)\
    \ or on exotic processor architectures, this install method <em>compiles from\
    \ source</em> against the found installations of HDF5, ADIOS2, and/or MPI (in\
    \ system paths, from other package managers, or loaded via a module system, ...).</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> optional:                   --user</span>\npython3\
    \ -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n\
    <p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional:                                    --user</span>\npython3\
    \ -m pip install -U pip packaging setuptools wheel\npython3 -m pip install -U\
    \ cmake\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:      \
    \                                                             --user</span>\n\
    openPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n\
    <p>For some exotic architectures and compilers, you might need to disable a compiler\
    \ feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\"\
    \ rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter\
    \ linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                               \
    \                 --user</span>\npython3 -m pip install openpmd-api --no-binary\
    \ openpmd-api</pre></div>\n<p>Additional CMake options can be passed via individual\
    \ environment variables, which need to be prefixed with <code>openPMD_CMAKE_</code>.</p>\n\
    <h3><a id=\"user-content-from-source\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#from-source\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>From Source</h3>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/0a40953107090abff3b564ec3436668756b873cd4d9e021738a046781a5a0e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\"\
    \ alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD-api can also be built and installed\
    \ from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\
    \nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests,\
    \ with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which\
    \ python3)</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\"\
    >.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\n\
    ctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required\
    \ for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target\
    \ install</pre></div>\n<p>The following options can be added to the <code>cmake</code>\
    \ call to control features.\nCMake controls options with prefixed <code>-D</code>,\
    \ e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n\
    <td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n\
    <td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code\
    \ <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro\
    \ independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_INSTALL_RPATH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Add RPATHs to installed binaries</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n\
    <td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n\
    </table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n\
    <sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without\
    \ specific cause is highly discouraged</em></p>\n<p>Additionally, the following\
    \ libraries are shipped internally.\nThe following options allow to switch to\
    \ external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n\
    <th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.10+</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>pybind11</td>\n<td>2.11.1+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_TOML11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>toml11</td>\n<td>3.7.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this\
    \ will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and\
    \ installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code>\
    \ to the <code>cmake</code> command.\nYou can only build a static or a shared\
    \ library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\n\
    In order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code>\
    \ to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and\
    \ command line tools are built.\nIn order to skip building those, pass <code>OFF</code>\
    \ to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_CUDA_EXAMPLES</code></td>\n<td>ON/<strong>OFF</strong>\n\
    </td>\n<td>Use CUDA in examples</td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-linking-to-your-project\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#linking-to-your-project\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Linking to your project</h2>\n<p>The install will\
    \ contain header files and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n\
    <h3><a id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>CMake</h3>\n<p>If your project is using CMake for its build, one can\
    \ conveniently use our provided <code>openPMDConfig.cmake</code> package, which\
    \ is installed alongside the library.</p>\n<p>First set the following environment\
    \ hint if openPMD-api was <em>not</em> installed in a system path:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional: only needed if installed outside of system paths</span>\n\
    <span class=\"pl-k\">export</span> CMAKE_PREFIX_PATH=<span class=\"pl-smi\">$HOME</span>/somepath:<span\
    \ class=\"pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n<p>Use the following\
    \ lines in your project's <code>CMakeLists.txt</code>:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ supports:                       COMPONENTS MPI NOMPI HDF5 ADIOS2</span>\n<span\
    \ class=\"pl-c1\">find_package</span>(openPMD 0.15.0 <span class=\"pl-k\">CONFIG</span>)\n\
    \n<span class=\"pl-k\">if</span>(openPMD_FOUND)\n    <span class=\"pl-c1\">target_link_libraries</span>(YourTarget\
    \ <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)\n<span class=\"pl-k\"\
    >endif</span>()</pre></div>\n<p><em>Alternatively</em>, add the openPMD-api repository\
    \ source directly to your project and use it via:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">add_subdirectory</span>(<span\
    \ class=\"pl-s\">\"path/to/source/of/openPMD-api\"</span>)\n\n<span class=\"pl-c1\"\
    >target_link_libraries</span>(YourTarget <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n\
    <p>For development workflows, you can even automatically download and build openPMD-api\
    \ from within a depending CMake project.\nJust replace the <code>add_subdirectory</code>\
    \ call with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"\
    pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077\
    \ <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_SHARED_LIBS\
    \ <span class=\"pl-k\">OFF</span>)  <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> precedence over BUILD_SHARED_LIBS if needed</span>\n<span class=\"pl-c1\"\
    >set</span>(openPMD_INSTALL <span class=\"pl-k\">OFF</span>)            <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> or instead use:</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> set(openPMD_INSTALL ${BUILD_SHARED_LIBS})\
    \  # only install if used as a shared library</span>\n<span class=\"pl-c1\">set</span>(openPMD_USE_PYTHON\
    \ <span class=\"pl-k\">OFF</span>)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY\
    \ <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"</span>\n\
    \  GIT_TAG        <span class=\"pl-s\">\"0.15.0\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n\
    <h3><a id=\"user-content-manually\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#manually\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Manually</h3>\n<p>If your (Linux/OSX) project is build by calling\
    \ the compiler directly or uses a manually written <code>Makefile</code>, consider\
    \ using our <code>openPMD.pc</code> helper file for <code>pkg-config</code>, which\
    \ are installed alongside the library.</p>\n<p>First set the following environment\
    \ hint if openPMD-api was <em>not</em> installed in a system path:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional: only needed if installed outside of system paths</span>\n\
    <span class=\"pl-k\">export</span> PKG_CONFIG_PATH=<span class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span\
    \ class=\"pl-smi\">$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and\
    \ compiler flags for your project are available via:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ switch to check if openPMD-api was build as static library</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> (via BUILD_SHARED_LIBS=OFF) or as shared\
    \ library (default)</span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config\
    \ --variable=static openPMD<span class=\"pl-pds\">)</span></span><span class=\"\
    pl-pds\">\"</span></span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>true<span class=\"pl-pds\">\"</span></span> ]\n\
    <span class=\"pl-k\">then</span>\n    pkg-config --libs --static openPMD\n   \
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib\
    \ -lopenPMD -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so\
    \ /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config\
    \ --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib\
    \ -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n\
    <h2><a id=\"user-content-author-contributions\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#author-contributions\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Author Contributions</h2>\n<p>openPMD-api\
    \ is developed by many people.\nIt was initially started by the <a href=\"https://hzdr.de/crp\"\
    \ rel=\"nofollow\">Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\
    >libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\"\
    \ rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"\
    https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe\
    \ following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\
    >contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\"\
    >Axel Huebl (HZDR, now LBNL)</a>:\nproject lead, releases, documentation, automated\
    \ CI/CD, Python bindings, Dask, installation &amp; packaging, prior reference\
    \ implementations</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\">Franz\
    \ Poeschel (CASUS)</a>:\nJSON &amp; ADIOS2 backend, data staging/streaming, reworked\
    \ class design</li>\n<li>\n<a href=\"https://github.com/C0nsultant\">Fabian Koller\
    \ (HZDR)</a>:\ninitial library design and implementation with HDF5 &amp; ADIOS1\
    \ backend</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu (LBNL)</a>:\n\
    non-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n</ul>\n\
    <p>Further thanks go to improvements and contributions from:</p>\n<ul>\n<li>\n\
    <a href=\"https://github.com/CFGrote\">Carsten Fortmann-Grote (EU XFEL GmbH, now\
    \ MPI-EvolBio)</a>:\ndraft of our Python unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\"\
    >Dominik Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n\
    <li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\n\
    support on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\"\
    >James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"\
    https://github.com/psychocoderHPC\">Ren\xE9 Widera (HZDR)</a>:\ndesign improvements\
    \ for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\"\
    >Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n\
    <a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation\
    \ improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\xE9\
    mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n\
    <a href=\"https://github.com/LDAmorim\">L\xEDgia Diana Amorim (LBNL)</a>:\npackage\
    \ integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\"\
    >Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"\
    https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing,\
    \ documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\"\
    >Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"\
    https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask prototyping\
    \ &amp; ADIOS2 benchmarking</li>\n<li>\n<a href=\"https://github.com/jakirkham\"\
    >John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n<li>\n<a href=\"\
    https://github.com/eschnett\">Erik Schnetter (PITP)</a>:\nC++ API bug fixes</li>\n\
    <li>\n<a href=\"https://github.com/jeanbez\">Jean Luca Bez (LBNL)</a>:\nHDF5 performance\
    \ tuning</li>\n<li>\n<a href=\"https://github.com/bernhardmgruber\">Bernhard Manfred\
    \ Gruber (CERN)</a>:\nCMake fix for parallel HDF5</li>\n<li>\n<a href=\"https://github.com/DerNils-git\"\
    >Nils Schild (IPP)</a>:\nCMake improvements for subprojects</li>\n</ul>\n<h3><a\
    \ id=\"user-content-grants\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#grants\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Grants</h3>\n<p>The openPMD-api authors acknowledge support via the\
    \ following programs.\nSupported by the CAMPA collaboration, a project of the\
    \ U.S. Department of Energy, Office of Science, Office of Advanced Scientific\
    \ Computing Research and Office of High Energy Physics, Scientific Discovery through\
    \ Advanced Computing (SciDAC) program.\nPreviously supported by the Consortium\
    \ for Advanced Modeling of Particles Accelerators (CAMPA), funded by the U.S.\
    \ DOE Office of Science under Contract No. DE-AC02-05CH11231.\nSupported by the\
    \ Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S.\
    \ Department of Energy organizations (Office of Science and the National Nuclear\
    \ Security Administration).\nThis project has received funding from the European\
    \ Unions Horizon 2020 research and innovation programme under grant agreement\
    \ No 654220.\nThis work was partially funded by the Center of Advanced Systems\
    \ Understanding (CASUS), which is financed by Germany's Federal Ministry of Education\
    \ and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism\
    \ (SMWK) with tax funds on the basis of the budget approved by the Saxon State\
    \ Parliament.\nSupported by the HElmholtz Laser Plasma Metadata Initiative (HELPMI)\
    \ project (ZT-I-PF-3-066), funded by the \"Initiative and Networking Fund\" of\
    \ the Helmholtz Association in the framework of the \"Helmholtz Metadata Collaboration\"\
    \ project call 2022.</p>\n<h3><a id=\"user-content-transitive-contributions\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#transitive-contributions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Transitive\
    \ Contributions</h3>\n<p>openPMD-api stands on the shoulders of giants and we\
    \ are grateful for the following projects included as direct dependencies:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\">ADIOS2</a> by <a href=\"\
    https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky, N. Podhorszki, W.F.\
    \ Godoy (ORNL), team, collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"\
    https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\xFD</a> and <a href=\"\
    https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n\
    <li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a>\
    \ and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a>\
    \ by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"\
    https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> by <a href=\"\
    https://github.com/ToruNiina\">Toru Niina</a> and <a href=\"https://github.com/ToruNiina/toml11#Contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\"\
    >pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a>\
    \ and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n\
    </li>\n<li>all contributors to the evolution of modern C++ and early library preview\
    \ developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n\
    </li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a>\
    \ and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n\
    </li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"\
    nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\
    \ and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among\
    \ others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\"\
    >openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR,\
    \ now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\
    >contributors</a>\n</li>\n</ul>\n"
  stargazers_count: 122
  subscribers_count: 10
  topics:
  - openpmd
  - openscience
  - hdf5
  - adios
  - mpi
  - hpc
  - research
  - file-handling
  - python3
  - opendata
  - metadata
  - cpp17
  updated_at: 1700537578.0
player1537-playground/triple-r:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537-playground/triple-r
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1614701026.0
pnnl/ExaGO:
  data_format: 2
  description: High-performance power grid optimization for stochastic, security-constrained,
    and multi-period ACOPF problems.
  filenames:
  - buildsystem/spack/summit/spack.yaml
  - buildsystem/spack/deception/spack.yaml
  - buildsystem/spack/incline/spack.yaml
  - buildsystem/container/spack.yaml
  full_name: pnnl/ExaGO
  latest_release: v1.6.0
  readme: "<h1><a id=\"user-content-exascale-grid-optimization-toolkit-exagotm-----\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#exascale-grid-optimization-toolkit-exagotm-----\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n<b>Exa</b>scale\
    \ <b>G</b>rid <b>O</b>ptimization toolkit (ExaGO<sup>TM</sup>) <a href=\"https://github.com/pre-commit/pre-commit\"\
    ><img src=\"https://camo.githubusercontent.com/a58d28773559eecad3ca137f4f248ad5604c530a4db52aa3780d3e65b5a4e6f3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7072652d2d636f6d6d69742d656e61626c65642d627269676874677265656e3f6c6f676f3d7072652d636f6d6d6974\"\
    \ alt=\"pre-commit\" data-canonical-src=\"https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    \ alt=\"PNNL GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    \ alt=\"ORNL Ascent GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    \ alt=\"pre-commit GitHub Action\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    \ alt=\"Spack CPU Build\" style=\"max-width: 100%;\"></a>\n</h1>\n\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"viz/images/network_gen_load_us.png\"\
    ><img src=\"viz/images/network_gen_load_us.png\" style=\"max-width: 100%;\"></a></p>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/manual/figures/three_in_one.png\"\
    ><img src=\"docs/manual/figures/three_in_one.png\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>ExaGO<sup>TM</sup> is a package for solving large-scale  power grid\
    \ optimization problems on parallel and distributed architectures, particularly\
    \ targeted for exascale machines with heteregenous architectures (GPU). Combinations\
    \ of stochastic, contingency-constrained, multiperiod ACOPF problems can be solved\
    \ with ExaGO. The package is written in C/C++ with python bindings available for\
    \ python-based applications. An overview of the package is given on this page.\
    \ For extended information, including the modeling details and formulations, see\
    \ the <a href=\"docs/manual/manual.pdf\">ExaGO manual</a>.</p>\n<p>ExaGO<sup>TM</sup>\
    \ includes the following applications for solving different power grid optimization\
    \ problems:</p>\n<ul>\n<li>\n<a href=\"docs/web/opflow.md\">OPFLOW</a> solves\
    \ an AC optimal power flow either on CPU and GPU</li>\n<li>\n<a href=\"docs/web/tcopflow.md\"\
    >TCOPFLOW</a> solves a multi-period optimal power flow</li>\n<li>\n<a href=\"\
    docs/web/scopflow.md\">SCOPFLOW</a> solves a security-constrained (contingency-constrained)\
    \ optimal power. Both single-period and multi-period problems can be solved.</li>\n\
    <li>\n<a href=\"docs/web/sopflow.md\">SOPFLOW</a> solves a stochastic optimal\
    \ power flow with (optional) security constraints for single and multiple periods.</li>\n\
    </ul>\n<p>ExaGO<sup>TM</sup> applications are interfaced with the following optimization\
    \ solver packaages:</p>\n<ul>\n<li>\n<a href=\"https://github.com/coin-or/Ipopt\"\
    >Ipopt</a> is a popular optimization package for solving nonlinear optimization\
    \ problems that uses an interior-point algorithm.</li>\n<li>\n<a href=\"https://github.com/LLNL/hiop\"\
    >HiOp</a> is a HPC package for optimization. ExaGO interfaces with two of its\
    \ solvers -- a mixed sparse-dense interior-point solver (NewtonMDS) and a sparse\
    \ interior-point solver (HiOPSparse). NewtonMDS  allows execution of the optimization\
    \ either on CPU and GPU. The sparse HiOp solver is currently supported on CPU\
    \ only.</li>\n</ul>\n<p>Note that not all applications can utilize all solvers\
    \ yet. The following table lists the solver-application compatibility.</p>\n<table>\n\
    <thead>\n<tr>\n<th align=\"center\">Solver</th>\n<th align=\"center\">OPFLOW</th>\n\
    <th align=\"center\">TCOPFLOW</th>\n<th align=\"center\">SCOPLOW</th>\n<th align=\"\
    center\">SOPFLOW</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Ipopt</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\">Y</td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td align=\"center\">HiOp</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\"></td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<p>Additionally,\
    \ note that SCOPFLOW and SOPFLOW with HiOp solver use Ipopt to solve a portion\
    \ of the problem (base problem). So one must also configure with Ipopt when using\
    \ HiOp solver for these applications.</p>\n<h2><a id=\"user-content-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n\
    <p>Details installation instructions are given at <a href=\"./INSTALL.md\">INSTALL.md</a>\
    \ for information on acquiring, building and installing ExaGO.</p>\n<h2><a id=\"\
    user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <p>Instructions for executing the different ExaGO<sup>TM</sup> applications is\
    \ given below.</p>\n<ul>\n<li><a href=\"docs/web/opflow.md\">OPFLOW</a></li>\n\
    <li><a href=\"docs/web/tcopflow.md\">TCOPFLOW</a></li>\n<li><a href=\"docs/web/sopflow.md\"\
    >SOPFLOW</a></li>\n<li><a href=\"docs/web/scopflow.md\">SCOPFLOW</a></li>\n<li><a\
    \ href=\"docs/web/pflow.md\">PFLOW</a></li>\n</ul>\n<h3><a id=\"user-content-options\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#options\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Options</h3>\n\
    <p>Each application has a different set of options that are described in depth\
    \ in the usage notes. These options can be passed optionally through an options\
    \ file (<code>-optionsfile &lt;option_file&gt;</code>), or directly on the command\
    \ line.</p>\n<p>Since options may be specified in more than one location (on the\
    \ command line, and through an options file), it is worth noting that the option\
    \ specified on the command line supersede those in the options file. For example,\
    \ if <code>opflowoptions</code> options file set the network file via the option\
    \ <code>-netfile case9mod.m</code>, the following behavior occurs:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> This uses case9mod.m</span>\n./opflow -optionsfile opflowoptions\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This uses case118.m</span>\n\
    ./opflow -netfile case118.m -options_file opflowoptions</pre></div>\n<h2><a id=\"\
    user-content-visualization-experimental\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#visualization-experimental\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Visualization (experimental)</h2>\n\
    <p>ExaGO has an experimental visualization to display the results of <code>OPFLOW</code>\
    \ application on a map. See the <a href=\"viz/README.md\">visualization README</a>\
    \ for more information.</p>\n<h2><a id=\"user-content-contributing\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Please\
    \ see <a href=\"docs/developer_guidelines.md\">the developer guidelines</a> before\
    \ attempting to contribute.\nFeel free to raise an issue or contact the team if\
    \ the guidelines are ambiguous or you have a particular question.</p>\n<h2><a\
    \ id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#authors\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Authors</h2>\n<ul>\n<li>Shrirang Abhyankar</li>\n<li>Slaven Peles</li>\n\
    <li>Asher Mancinelli</li>\n<li>Cameron Rutherford</li>\n<li>Bruce Palmer</li>\n\
    <li>Jaelyn Litzinger</li>\n<li>William Perkins</li>\n<li>Sayef Azad Sakin</li>\n\
    <li>Joseph Macam</li>\n<li>Ryan Danehy</li>\n<li>Nicholson Koukpaizan</li>\n</ul>\n\
    <h2><a id=\"user-content-acknowledgement\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#acknowledgement\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Acknowledgement</h2>\n<p>This package is developed\
    \ as a part of <a href=\"https://www.exascaleproject.org/research-project/exasgd/\"\
    \ rel=\"nofollow\">ExaSGD</a> project under the <a href=\"https://www.exascaleproject.org/\"\
    \ rel=\"nofollow\">Exascale computing project</a>.</p>\n<h2><a id=\"user-content-copyright\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#copyright\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Copyright</h2>\n\
    <p>Copyright \xA9 2020, Battelle Memorial Institute.</p>\n<p>ExaGO<sup>TM</sup>\
    \ is a free software distributed under a BSD 2-clause license. You may reuse,\
    \ modify, and redistribute the software. See the <a href=\"LICENSE\">license</a>\
    \ file for details.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#disclaimer\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Disclaimer</h2>\n<p>This material\
    \ was prepared as an account of work sponsored by an agency of the United States\
    \ Government.  Neither the United States Government nor the United States Department\
    \ of Energy, nor Battelle, nor any of their employees, nor any jurisdiction or\
    \ organization that has cooperated in the development of these materials, makes\
    \ any warranty, express or implied, or assumes any legal liability or responsibility\
    \ for the accuracy, completeness, or usefulness or any information, apparatus,\
    \ product, software, or process disclosed, or represents that its use would not\
    \ infringe privately owned rights.\nReference herein to any specific commercial\
    \ product, process, or service by trade name, trademark, manufacturer, or otherwise\
    \ does not necessarily constitute or imply its endorsement, recommendation, or\
    \ favoring by the United States Government or any agency thereof, or Battelle\
    \ Memorial Institute. The views and opinions of authors expressed herein do not\
    \ necessarily state or reflect those of the United States Government or any agency\
    \ thereof.</p>\n"
  stargazers_count: 19
  subscribers_count: 10
  topics: []
  updated_at: 1701055987.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<h1><a id=\"user-content-libpressio\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#libpressio\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>LibPressio</h1>\n<p><em>the stable version of this\
    \ code is found at <a href=\"https://github.com/CODARcode/libpressio\">at the\
    \ CODARCode organization</a> it is updated about anually</em></p>\n<p>Pressio\
    \ is latin for compression.  LibPressio is a C++ library with C compatible bindings\
    \ to abstract between different lossless and lossy compressors and their configurations.\
    \  It solves the problem of having to having to write separate application level\
    \ code for each lossy compressor that is developed.  Instead, users write application\
    \ level code using LibPressio, and the library will make the correct underlying\
    \ calls to the compressors.  It provides interfaces to represent data, compressors\
    \ settings, and compressors.</p>\n<p>Documentation for the <code>master</code>\
    \ branch can be <a href=\"https://robertu94.github.io/libpressio/\" rel=\"nofollow\"\
    >found here</a></p>\n<h1><a id=\"user-content-using-libpressio\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#using-libpressio\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using LibPressio</h1>\n<p>Example\
    \ using the CLI from <a href=\"https://github.com/robertu94/pressio-tools\"><code>pressio-tools</code></a>\n\
    We also have C, C++, Rust, Julia, and Python bindings.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pressio -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<h2><a id=\"user-content-getting-started\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#getting-started\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n\
    <p>After skimming the example, LibPressio has 6 major headers that you will need\
    \ to use:</p>\n<table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td><code>pressio.h</code></td>\n<td>Error reporting and aquiring\
    \ handles to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<h2><a id=\"user-content-supported-compressors-and-metrics\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#supported-compressors-and-metrics\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ Compressors and Metrics</h2>\n<p>Libpressio provides a number of builtin compressor\
    \ and metrics modules.\nAll of these are <strong>disabled by default</strong>.\n\
    They can be enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code>\
    \ variable to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information\
    \ on writing a compressor plugin see [Writing a Compressor Plugin](@ref writingacompressor)\n\
    For information on writing a metrics plugin see [Writing a Metrics Plugin](@ref\
    \ writingametric)</p>\n<h3><a id=\"user-content-compressor-plugins\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#compressor-plugins\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compressor Plugins</h3>\n\
    <p>1st party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the [compressor settings page](@ref compressors)\
    \ for information on how to configure them.</p>\n<h3><a id=\"user-content-metrics-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#metrics-plugins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Metrics\
    \ Plugins</h3>\n<p>1st party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the [metrics results page](@ref metrics)\
    \ for information on what they produce</p>\n<h3><a id=\"user-content-io-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#io-plugins\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>IO Plugins</h3>\n\
    <p>1st party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the [io settings page](@ref io) for information\
    \ on how to configure them</p>\n<h1><a id=\"user-content-installation\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h1>\n<h2><a id=\"\
    user-content-installing-libpressio-using-spack\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#installing-libpressio-using-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing LibPressio using Spack</h2>\n\
    <p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\">spack</a>.\
    \  This example will install libpressio with only the SZ3 plugin.</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<h2><a id=\"user-content-doing-a-development-build-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#doing-a-development-build-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Doing a\
    \ development build with spack</h2>\n<p>The easiest way to do a development build\
    \ of libpressio is to use Spack envionments.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> one time setup: create\
    \ an envionment</span>\nspack env create -d mydevenviroment\nspack env activate\
    \ mydevenvionment\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one time\
    \ setup: tell spack to set LD_LIBRARY_PATH with the spack envionment's library\
    \ paths</span>\nspack config add modules:prefix_inspections:lib64:[LD_LIBRARY_PATH]\n\
    spack config add modules:prefix_inspections:lib:[LD_LIBRARY_PATH]\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> one time setup: install libpressio-tools\
    \ and checkout </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> libpressio\
    \ for development</span>\nspack add libpressio-tools\nspack develop libpressio@git.master\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compile and install (repeat\
    \ as needed)</span>\nspack install </pre></div>\n<h2><a id=\"user-content-manual-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#manual-installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manual Installation</h2>\n\
    <p>Libpressio unconditionally requires:</p>\n<ul>\n<li><code>cmake</code></li>\n\
    <li><code>pkg-config</code></li>\n<li><a href=\"https://github.com/robertu94/std_compat\"\
    ><code>std_compat</code></a></li>\n<li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code>\
    \ or later</li>\n<li>\n<code>clang-7.0.0</code> or later using either <code>libc++</code>\
    \ or <code>libstdc++</code>.  Beware that system libraries may need to be recompiled\
    \ with <code>libc++</code> if using <code>libc++</code>\n</li>\n</ul>\n</li>\n\
    </ul>\n<p>Dependency versions and optional dependencies are documented <a href=\"\
    https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<h2><a id=\"user-content-configuring-libpressio-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#configuring-libpressio-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ LibPressio Manually</h2>\n<p>LibPressio uses a fairly standard CMake buildsystem.\n\
    For more information on <a href=\"https://robertu94.github.io/learning/cmake\"\
    \ rel=\"nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration\
    \ options for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\n\
    For information on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<h1><a id=\"user-content-api-stability\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#api-stability\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>API Stability</h1>\n<p>Please\
    \ refer to <a href=\"docs/stability.md\">docs/stability.md</a>.</p>\n<h1><a id=\"\
    user-content-how-to-contribute\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#how-to-contribute\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>How to Contribute</h1>\n<p>Please refer to <a href=\"CONTRIBUTORS.md\"\
    >CONTRIBUTORS.md</a> for a list of contributors, sponsors, and contribution guidelines.</p>\n\
    <h1><a id=\"user-content-bug-reports\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#bug-reports\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Bug Reports</h1>\n<p>Please files bugs to the Github Issues page on\
    \ the CODARCode libpressio repository.</p>\n<p>Please read this post on <a href=\"\
    https://codingnest.com/how-to-file-a-good-bug-report/\" rel=\"nofollow\">how to\
    \ file a good bug report</a>.\_ After reading this post, please provide the following\
    \ information specific to libpressio:</p>\n<ul>\n<li>Your OS version and distribution\
    \ information, usually this can be found in <code>/etc/os-release</code>\n</li>\n\
    <li>the output of <code>cmake -L $BUILD_DIR</code>\n</li>\n<li>the version of\
    \ each of libpressio's dependencies listed in the README that you have installed.\
    \ Where possible, please provide the commit hashes.</li>\n</ul>\n<h1><a id=\"\
    user-content-citing-libpressio\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#citing-libpressio\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing LibPressio</h1>\n<p>If you find LibPressio useful, please cite\
    \ this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n  title={Productive\
    \ and Performant Generic Lossy Data Compression with LibPressio},\n  author={Underwood,\
    \ Robert and Malvoso, Victoriana and Calhoun, Jon C and Di, Sheng and Cappello,\
    \ Franck},\n  booktitle={2021 7th International Workshop on Data Analysis and\
    \ Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n  year={2021},\n\
    \  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 23
  subscribers_count: 5
  topics: []
  updated_at: 1701321189.0
roblatham00/cashersize:
  data_format: 2
  description: Exercise caching in the mochi context
  filenames:
  - spack.yaml
  full_name: roblatham00/cashersize
  latest_release: null
  readme: '<p>Your project "cachersize" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652377734.0
roblatham00/phonebook:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: roblatham00/phonebook
  latest_release: null
  readme: '<p>Your project "YP" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1682697472.0
rohankumardubey/libtree:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: rohankumardubey/libtree
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    ><img src=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    \ alt=\"Test\" style=\"max-width: 100%;\"></a>\n<a href=\"https://aur.archlinux.org/packages/libtree/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7e7cc860b359b4e8c852178856fed7ba2f3ceb557ab7e2c021ab84d695412362/68747470733a2f2f696d672e736869656c64732e696f2f6175722f76657273696f6e2f6c6962747265653f6c6f676f3d417263682d4c696e7578\"\
    \ alt=\"AUR version\" data-canonical-src=\"https://img.shields.io/aur/version/libtree?logo=Arch-Linux\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-libtree\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#libtree\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>libtree</h1>\n<p>A tool that:</p>\n\
    <ul>\n<li>\U0001F333 turns <code>ldd</code> into a tree</li>\n<li>\u261D\uFE0F\
    \ explains why shared libraries are found and why not</li>\n<li>\U0001F4E6 optionally\
    \ deploys executables and dependencies into a single directory</li>\n</ul>\n<p><a\
    \ target=\"_blank\" rel=\"noopener noreferrer\" href=\"doc/screenshot.png\"><img\
    \ src=\"doc/screenshot.png\" alt=\"example\" style=\"max-width: 100%;\"></a></p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Installation</h2>\n<p>Download the <a href=\"https://github.com/haampie/libtree/releases\"\
    ><strong>latest release</strong></a> from Github.</p>\n<p><strong>Static executable</strong></p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>wget -qO libtree https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64\n\
    chmod +x libtree\n./libtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<p><strong>Static executable\
    \ + optional dependencies</strong></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>wget -qO libtree.tar.gz https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64.tar.gz\n\
    mkdir libtree\ntar -xf libtree.tar.gz -C libtree\n<span class=\"pl-k\">export</span>\
    \ PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$PWD</span>/libtree:<span class=\"pl-smi\">$PATH</span><span class=\"pl-pds\"\
    >\"</span></span>\nlibtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<h2><a id=\"user-content-deploying-binaries--dependencies-into-a-folder\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#deploying-binaries--dependencies-into-a-folder\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Deploying\
    \ binaries + dependencies into a folder</h2>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ libtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which man<span\
    \ class=\"pl-pds\">)</span></span> -d man.bundle --chrpath --strip\nman\n\u251C\
    \u2500\u2500 libmandb-2.9.1.so [runpath]\n\u2502   \u251C\u2500\u2500 libman-2.9.1.so\
    \ [runpath]\n\u2502   \u2502   \u251C\u2500\u2500 libpipeline.so.1 [ld.so.conf]\n\
    \u2502   \u2502   \u2514\u2500\u2500 libseccomp.so.2 [ld.so.conf]\n\u2502   \u2514\
    \u2500\u2500 libgdbm.so.6 [ld.so.conf]\n\u251C\u2500\u2500 libman-2.9.1.so (collapsed)\
    \ [runpath]\n\u2514\u2500\u2500 libpipeline.so.1 (collapsed) [ld.so.conf]\n\n\
    Deploying to <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/bin/man<span class=\"pl-pds\">\"</span></span> =<span class=\"\
    pl-k\">&gt;</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/bin/man<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/lib/man-db/libmandb-2.9.1.so<span class=\"pl-pds\">\"</span></span>\
    \ =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>man.bundle/usr/lib/libmandb-2.9.1.so<span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/man-db/libman-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libman-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/lib/x86_64-linux-gnu/libpipeline.so.1.5.2<span class=\"pl-pds\"\
    >\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1.5.2<span class=\"\
    pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1<span class=\"pl-pds\">\"\
    </span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2<span class=\"pl-pds\"\
    >\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6<span class=\"pl-pds\"\
    >\"</span></span>\n\n$ tree man.bundle/\nman.bundle/\n\u2514\u2500\u2500 usr\n\
    \    \u251C\u2500\u2500 bin\n    \u2502\_\_ \u2514\u2500\u2500 man\n    \u2514\
    \u2500\u2500 lib\n        \u251C\u2500\u2500 libgdbm.so.6 -<span class=\"pl-k\"\
    >&gt;</span> libgdbm.so.6.0.0\n        \u251C\u2500\u2500 libgdbm.so.6.0.0\n \
    \       \u251C\u2500\u2500 libman-2.9.1.so\n        \u251C\u2500\u2500 libmandb-2.9.1.so\n\
    \        \u251C\u2500\u2500 libpipeline.so.1 -<span class=\"pl-k\">&gt;</span>\
    \ libpipeline.so.1.5.2\n        \u251C\u2500\u2500 libpipeline.so.1.5.2\n    \
    \    \u251C\u2500\u2500 libseccomp.so.2 -<span class=\"pl-k\">&gt;</span> libseccomp.so.2.5.1\n\
    \        \u2514\u2500\u2500 libseccomp.so.2.5.1\n\n3 directories, 9 files</pre></div>\n\
    <h2><a id=\"user-content-verbose-output\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#verbose-output\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Verbose output</h2>\n<p>By default certain standard\
    \ depenendencies are not shown. For more verbose output use</p>\n<ul>\n<li>\n\
    <code>libtree -v $(which man)</code> to show skipped libraries without their children</li>\n\
    <li>\n<code>libtree -a $(which apt-get)</code> to show the full recursive list\
    \ of libraries</li>\n</ul>\n<p>Use the <code>--path</code> or <code>-p</code>\
    \ flags to show paths rather than sonames:</p>\n<ul>\n<li><code>libtree -p $(which\
    \ tar)</code></li>\n</ul>\n<h2><a id=\"user-content-changing-search-paths\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#changing-search-paths\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Changing\
    \ search paths</h2>\n<p><code>libtree</code> follows the rules of <code>ld.so</code>\
    \ to locate libraries, but does not use <code>ldconfig</code>'s\ncache. Instead\
    \ it parses <code>/etc/ld.so.conf</code> at runtime. In fact you can change the\
    \ search\npath config by setting <code>--ldconf mylibs.conf</code>. Search paths\
    \ can be added as well via\n<code>LD_LIBRARY_PATH=\"path1:path2:$LD_LIBRARY_PATH\"\
    \ libtree ...</code>.</p>\n<h2><a id=\"user-content-building\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#building\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<ul>\n<li>\n<strong>From\
    \ source</strong>:\n<div class=\"highlight highlight-source-shell\"><pre>git clone\
    \ https://github.com/haampie/libtree.git\n<span class=\"pl-c1\">cd</span> libtree\n\
    mkdir build\n<span class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_PREFIX_PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/cxxopts;/path/to/elfio;/path/to/termcolor<span\
    \ class=\"pl-pds\">\"</span></span> ..\nmake -j\nmake install</pre></div>\n</li>\n\
    <li>\n<strong>Using <a href=\"https://github.com/spack/spack\">spack</a></strong>:\n\
    <pre><code>spack install libtree +chrpath +strip\nspack load libtree\n</code></pre>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-known-issues\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#known-issues\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Known issues</h2>\n<ul>\n<li>When deploying\
    \ libs with <code>libtree app -d folder.bundle --chrpath</code>, the runpaths\
    \ are only\nchanged when the binaries already have an an rpath or runpath. This\
    \ is a limitation of\n<code>chrpath</code>. Another option is to use <code>patchelf</code>\
    \ instead, but this tool is known to break\nbinaries sometimes.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664232270.0
salotz/snailpacks:
  data_format: 2
  description: Spack repo for multimedia development
  filenames:
  - examples/c-embed-chibi/spack.yaml
  - examples/c-embed-python/spack.yaml
  full_name: salotz/snailpacks
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics:
  - spack
  - spack-repo
  - scopes-lang
  - multimedia
  - game-development
  - package-manager
  - development-environment
  updated_at: 1648089720.0
simonpintarelli/acclapack-tests:
  data_format: 2
  description: null
  filenames:
  - spack-envs/rocm/spack.yaml
  full_name: simonpintarelli/acclapack-tests
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667393188.0
simonpintarelli/nlcglib:
  data_format: 2
  description: Nonlinear CG methods for wave-function optimization in DFT
  filenames:
  - spack-envs/q-e-sirius-cpu-only/spack.yaml
  full_name: simonpintarelli/nlcglib
  latest_release: v0.9.1
  stargazers_count: 7
  subscribers_count: 2
  topics: []
  updated_at: 1698920452.0
spack/gitlab-runners:
  data_format: 2
  description: Images used to run Gitlab pipelines in the cloud
  filenames:
  - spack.yaml
  full_name: spack/gitlab-runners
  latest_release: v2023-10-30
  readme: '<p>This repository contains images that are used to run Gitlab pipelines
    to validate PRs in Spack.</p>

    <p>The recipes have been modified from ones in: <a href="https://github.com/UO-OACISS/e4s">https://github.com/UO-OACISS/e4s</a></p>

    '
  stargazers_count: 2
  subscribers_count: 11
  topics: []
  updated_at: 1685684158.0
spack/localized-docs:
  data_format: 2
  description: Localized documentation for Spack
  filenames:
  - spack.yaml
  full_name: spack/localized-docs
  latest_release: null
  readme: "<h1><a id=\"user-content-localized-documentation-for-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#localized-documentation-for-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Localized\
    \ Documentation for Spack</h1>\n<p>This repository contains translations of <a\
    \ href=\"/spack/spack\">Spack</a>'s\ndocumentation.  It implements the workflow\
    \ described in the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">Sphinx docs</a>.</p>\n<p>The instructions here describe how\
    \ you can contribute by:</p>\n<ol>\n<li>Adding to an existing translation, and</li>\n\
    <li>Creating a translation in a new language.</li>\n</ol>\n<h2><a id=\"user-content-prerequisites\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#prerequisites\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h2>\n\
    <ol>\n<li>\n<p>First, init the <code>spack</code> submodule:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">git clone\
    \ https://github.com/spack/localized-docs</span>\n$ <span class=\"pl-s1\"><span\
    \ class=\"pl-c1\">cd</span> localized-docs</span>\n$ <span class=\"pl-s1\">git\
    \ submodule init</span>\n$ <span class=\"pl-s1\">git submodule update</span></pre></div>\n\
    </li>\n<li>\n<p>To use this repository you'll need Sphinx, some plugins for it,\
    \ and\n<code>gettext</code>.  To install these dependencies, using <code>pip</code>\
    \ and <code>brew</code>, you\ncan run:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">pip3 install -r requirements.txt</span>\n$ <span\
    \ class=\"pl-s1\">brew install gettext</span></pre></div>\n<p>Using Spack, you\
    \ can just take advantage of the <code>spack.yaml</code> file at\nthe root of\
    \ this repo:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span\
    \ class=\"pl-c1\">spack install</span>\n<span class=\"pl-c1\">spack env activate\
    \ .</span></pre></div>\n<p>This will install the tools you need and put them in\
    \ your <code>PATH</code>.</p>\n</li>\n</ol>\n<h2><a id=\"user-content-adding-to-an-existing-translation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#adding-to-an-existing-translation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding to\
    \ an existing translation</h2>\n<p>Translations in this repository are stored\
    \ in <code>.po</code> files under\n<code>translations</code>.  There is one translation\
    \ per languages, and each file is\nnamed according to its\n<a href=\"https://www.gnu.org/software/gettext/manual/html_node/Language-Codes.html#Language-Codes\"\
    \ rel=\"nofollow\">ISO-639 language code</a>.\nSo, the Japanese translation data\
    \ for Spack is stored in\n<code>translations/ja.po</code>.</p>\n<p>If you want\
    \ to add to an existing translation, all you need to do is edit\nthe appropriate\
    \ <code>.po</code> file and add translated strings to it.  <code>.po</code> files\n\
    are comprised of <code>msgid</code>/<code>msgstr</code> pairs.  The <code>msgid</code>\
    \ corresponds to an\nEnglish string in the original documentation, and the <code>msgstr</code>\
    \ is its\ntranslation in the target language.  For example, for Japanese, the\n\
    translation of \"Basic Usage\" is stored like this:</p>\n<pre><code>#: ../spack/lib/spack/docs/basic_usage.rst:10\n\
    msgid \"Basic Usage\"\nmsgstr \"\u57FA\u672C\u7684\u306A\u4F7F\u3044\u65B9\"\n\
    </code></pre>\n<p>To add a translation:</p>\n<ol>\n<li>Update <code>msgstr</code>\
    \ elements in the appropriate <code>.po</code> files;</li>\n<li>Run <code>make</code>;</li>\n\
    <li>Commit the results;</li>\n<li>Submit a pull request so that we can merge your\
    \ changes.</li>\n</ol>\n<p>That's all!  Merged pull requests will automatically\
    \ trigger a rebuild of\nthe translated docs, and you should see your changes at\n\
    <a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\">spack.readthedocs.io</a>.</p>\n\
    <p>If you want to look at the documentation while you're editing it, running\n\
    <code>make</code> also generates per-language builds of the docs in <code>html/&lt;lang&gt;</code>.\n\
    So, to see the Japanese documentation, you can run <code>make</code> and open\n\
    <code>html/ja/index.html</code> in a local web browser.</p>\n<h2><a id=\"user-content-creating-a-new-translation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#creating-a-new-translation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ a new translation</h2>\n<p>To create a new translation, add the language to\
    \ the <code>languages</code> list in\nthe <code>Makefile</code>.  For example,\
    \ if the only language is Japanese (<code>ja</code>) and\nyou want to add German\
    \ (<code>de</code>), just add <code>de</code>:</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-smi\">languages</span> = ja de</pre></div>\n<p>Running\
    \ <code>make</code>, will create files in <code>docs</code>, <code>locale</code>,\
    \ and\n<code>translations</code>, and <code>html</code>:</p>\n<pre><code>    translations/de.po\
    \          # German translation file\n    translations/de.mo          # generated\
    \ from de.po\n    locale/de/LC_MESSAGES/*.mo  # symlinks to translations/de.mo\n\
    \    docs/de/                    # a Sphinx build directory for German docs\n\
    \    html/de/                    # HTML built by Sphinx from docs/de\n</code></pre>\n\
    <p>Add everything <em>except</em> <code>html</code>, then commit. <code>html</code>\
    \ is ignored by default\n(see <code>.gitignore</code>), so you can just run this:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >git add <span class=\"pl-c1\">.</span></span>\n$ <span class=\"pl-s1\">git commit</span></pre></div>\n\
    <p>See instructions above for how to start translating.</p>\n<h2><a id=\"user-content-workflow\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#workflow\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Workflow</h2>\n\
    <p>This repository implements the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">workflow described here</a>.\nMost users will only need to\
    \ concern themselves with <code>translations/*.po</code>\nfiles, but we provide\
    \ a short summary here so that you can understand how\neverything works.</p>\n\
    <p>Translation is done as follows:</p>\n<ol>\n<li>\n<p>First, we use (or rather\
    \ Sphinx uses) the <code>gettext</code> tool to extract\nstrings to be translated\
    \ from each <code>.rst</code> document in the Spack\ndocumentation. This results\
    \ in a set of <code>.pot</code> files in\n<code>templates/*.pot</code>.  These\
    \ contain keys (<code>msgid</code>s) for unique strings,\nas well as their location\
    \ (file and line number) in the documentation.</p>\n</li>\n<li>\n<p>We merge the\
    \ <code>.pot</code> files into a single <code>merged.pot</code> file to eliminate\n\
    duplicate strings in multiple files.</p>\n</li>\n<li>\n<p><code>merged.pot</code>\
    \ is used to create an initial <code>translations/&lt;lang&gt;.po</code>\nfile.\
    \  Translations are added to <code>msgstr</code> fields in the <code>.po</code>\
    \ file.</p>\n</li>\n<li>\n<p>A single <code>translations/&lt;lang&gt;.mo</code>\
    \ file is generated from the <code>.po</code>\nfile. The <code>.mo</code> file\
    \ is in a special binary format.</p>\n</li>\n<li>\n<p>We generate symlinks in\
    \ <code>locale/&lt;lang&gt;/LC_MESSAGES/*.mo</code> that all\npoint back to the\
    \ single, unified <code>translations/&lt;lang&gt;.mo</code> file.  The\n<code>locale</code>\
    \ directory can then be used with Sphinx to build translated\ndocumentation.</p>\n\
    </li>\n</ol>\n<p>The top-level <code>Makefile</code> implements this workflow,\
    \ so you don't have to\nthink too much about it.</p>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>This repository is part of Spack, which distributed under the terms of\nboth\
    \ the MIT license and the Apache License (Version 2.0). Users may\nchoose either\
    \ license, at their option.</p>\n<p>All new contributions must be made under both\
    \ the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/localized-docs/blob/master/LICENSE-MIT\"\
    >LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/localized-docs//blob/master/LICENSE-APACHE\"\
    >LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/localized-docs/blob/master/COPYRIGHT\"\
    >COPYRIGHT</a>,\nand <a href=\"https://github.com/spack/localized-docs/blob/master/NOTICE\"\
    >NOTICE</a>\nfor details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-647188</p>\n"
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1621989548.0
spack/spack-ci-containers:
  data_format: 2
  description: Container recipes used by Spack for test purposes
  filenames:
  - clingo/spack.yaml
  full_name: spack/spack-ci-containers
  latest_release: null
  readme: '<h1><a id="user-content-spack-ci-containers" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-ci-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Spack CI containers</h1>

    <p>This repository contains recipes for containers that are

    used to test Spack under CI.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-ci-containers/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1621989328.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-22.05/prod/cce/spack.yaml
  - NERSC/perlmutter/e4s-23.08/nvhpc/spack.yaml
  - NERSC/perlmutter/e4s-23.08/gcc/spack.yaml
  - NERSC/perlmutter/e4s-23.08/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/nvhpc/spack.yaml
  - NERSC/perlmutter/e4s-23.05/data/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-22.11/cuda/spack.yaml
  - NERSC/perlmutter/e4s-23.05/gcc/spack.yaml
  - NREL/configs/rhodes/utilities/spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/Frank-Jupiter/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/prod/spack.yaml
  - NERSC/perlmutter/e4s-22.11/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cuda/spack.yaml
  - NREL/configs/rhodes/compilers/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - NERSC/perlmutter/e4s-22.11/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.05/spack.yaml
  - OLCF/andes/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/gcc/spack.yaml
  - BOISESTATE/borah/environments/b4s/_spack.yaml
  - BOISESTATE/borah/applications/gromacs/_spack.yaml
  - OLCF/frontier/spack.yaml
  - NERSC/perlmutter/e4s-23.05/nvhpc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.08/spack.yaml
  - OLCF/summit/spack.yaml
  - NREL/configs/eagle/base/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/tools/spack.yaml
  - NREL/configs/eagle/compilers/spack.yaml
  - OLCF/crusher/spack.yaml
  - NERSC/perlmutter/e4s-22.05/cuda/spack.yaml
  - NREL/configs/eagle/utilities/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.02/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cce/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/spack.yaml
  - BOISESTATE/borah/environments/compilers/_spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/NERSC-Cori/gcc-spack.yaml
  - NERSC/cori/e4s-21.02/prod/spack.yaml
  - NREL/configs/eagle/software/spack.yaml
  - OLCF/spock/spack.yaml
  - NERSC/cori/e4s-20.10/prod/spack.yaml
  - NERSC/perlmutter/e4s-22.05/nvhpc/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 55
  subscribers_count: 29
  topics: []
  updated_at: 1699468871.0
spack/spack-tutorial:
  data_format: 2
  description: Standalone Spack Tutorial Repository
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial
  latest_release: sc23
  readme: '<h1><a id="user-content--spack-tutorial" class="anchor" aria-hidden="true"
    tabindex="-1" href="#-spack-tutorial"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667"><img
    src="https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667"
    width="64" valign="middle" alt="Spack" data-canonical-src="https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg"
    style="max-width: 100%;"></a> Spack Tutorial</h1>

    <p><a href="https://spack-tutorial.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/f38d9ceff55c2a7fea5d61861aa91b64fe00c220b83af1fd8af46da42ede70f5/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2d7475746f7269616c2f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/spack-tutorial/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is a multi-platform package manager that builds and installs multiple
    versions and configurations of software. It works on Linux, macOS, and many supercomputers.
    Spack is non-destructive: installing a new version of a package does not break
    existing installations, so many configurations of the same package can coexist.</p>

    <p>This repository houses Spack''s <a href="https://spack-tutorial.readthedocs.io/en/latest/"
    rel="nofollow"><strong>hands-on tutorial</strong></a>, which is a subset of Spack''s
    <a href="https://spack.readthedocs.io/" rel="nofollow"><strong>full documentation</strong></a>
    (or you can run <code>spack help</code> or <code>spack help --all</code>).</p>

    <p>This tutorial covers basic to advanced usage, packaging, developer features,
    and large HPC deployments.  You can do all of the exercises on your own laptop
    using a Docker container. Feel free to use these materials to teach users at your
    organization about Spack.</p>

    <h2><a id="user-content-updating-the-tutorial" class="anchor" aria-hidden="true"
    tabindex="-1" href="#updating-the-tutorial"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Updating the tutorial</h2>

    <ol>

    <li>Create a new branch named for the event/milestone that corresponds to the
    new version you want to create.</li>

    <li>Upload screen shot of first slide (244px wide, .png) to <a href="https://github.com/spack/spack-tutorial/tree/master/tutorial/images">images
    directory</a> following existing file-naming convention.</li>

    <li>Upload PDF of slide deck to <a href="https://github.com/spack/spack-tutorial/tree/master/_static/slides">slides
    directory</a> following existing file-naming convention.</li>

    <li>Update <a href="https://github.com/spack/spack-tutorial/blob/master/index.rst">index.rst</a>
    with event name and date; full citation; and file paths for image and PDF.</li>

    <li>Update this README (lines 3 and 7) with link to new version''s URL.</li>

    <li>Build docs locally.</li>

    <li>Push changes to GitHub and active new tag/version on Read the Docs.</li>

    <li>Build new version on Read the Docs.</li>

    </ol>

    <h2><a id="user-content-updating-the-tutorial-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#updating-the-tutorial-container"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Updating the tutorial container</h2>

    <p>The Spack tutorial container is automatically built from <a href="docker/Dockerfile">repository</a>
    by <a href=".github/workflows/containers.yaml">this GitHub action</a>. The latest
    version is available at</p>

    <pre><code>ghcr.io/spack/tutorial:latest

    </code></pre>

    <p>and is rebuilt on a schedule. It can also be <a href="https://github.com/spack/spack-tutorial/actions">triggered
    manually</a>.</p>

    <p>The tutorial image builds on top of the container image that runs in Spack
    CI, which is built in a different repository at <a href="https://github.com/spack/gitlab-runners/">spack/gitlab-runners</a></p>

    <h2><a id="user-content-automatically-generating-command-ouputs" class="anchor"
    aria-hidden="true" tabindex="-1" href="#automatically-generating-command-ouputs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Automatically generating
    command ouputs</h2>

    <p>The tutorial <code>rst</code> files include output from Spack commands. This
    process is automated, and it is

    recommended not to run commands manually.</p>

    <p><strong>Note:</strong> as a preliminary step, check your terminal width. All
    current outputs

    are generated on a fixed terminal width <strong>94</strong>; deviating from that
    can cause

    unnecessarily large diffs:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">tput
    cols</span>

    <span class="pl-c1">94</span></pre></div>

    <p>To regenerate the outputs, run:</p>

    <div class="highlight highlight-source-shell"><pre>make -C outputs -j <span class="pl-k">&lt;</span>N<span
    class="pl-k">&gt;</span></pre></div>

    <p>This runs each <code>outputs/&lt;section&gt;.sh</code> script in parallel in
    a container, and collects outputs in

    <code>outputs/raw/*</code>. When all complete succesfully, the outputs are post-processed
    and put in

    <code>outputs/</code>.</p>

    <p>In case you want to restrict to particular sections, or if you need to modify
    the container

    executable and flags, specify those as variables in <code>outputs/Make.user</code>:</p>

    <div class="highlight highlight-source-makefile"><pre><span class="pl-smi">sections</span>
    := basics scripting

    <span class="pl-smi">DOCKER</span> := sudo docker</pre></div>

    <ul>

    <li>

    <p><code>make</code> will regenerate the relevant outputs when <code>outputs/&lt;section&gt;.sh</code>
    files are modified.</p>

    </li>

    <li>

    <p>To start from scratch, run <code>make clean</code></p>

    </li>

    <li>

    <p><code>make run-&lt;tab&gt;</code> can also be used to regenerate a particular
    section, but notice it will only

    create raw outputs.</p>

    </li>

    </ul>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the Apache
    License (Version 2.0). Users may choose either license, at their option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack/blob/develop/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack/blob/develop/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack/blob/develop/NOTICE">NOTICE</a> for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 36
  subscribers_count: 35
  topics:
  - tutorial
  updated_at: 1700985883.0
spack/spack-tutorial-container:
  data_format: 2
  description: Dockerfile and artifacts (minus build cache) to create Spack tutorial
    container.
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial-container
  latest_release: null
  readme: '<h1><a id="user-content-spack-tutorial-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-tutorial-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Spack Tutorial Container</h1>

    <p>This repository contains a container image you can use to do the

    <a href="https://spack.readthedocs.io/en/latest/tutorial.html" rel="nofollow">Spack
    Tutorial</a>.

    It''s exactly like the AWS images we use when we give the tutorial at

    conferences.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1657127710.0
supercontainers/ecp-tutorial:
  data_format: 2
  description: ECP Tutorial
  filenames:
  - examples/spack/spack.yaml
  full_name: supercontainers/ecp-tutorial
  latest_release: null
  readme: "<h1><a id=\"user-content-getting-started-with-containers-on-hpc\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#getting-started-with-containers-on-hpc\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting\
    \ Started with Containers on HPC</h1>\n<p>View this on <a href=\"https://supercontainers.github.io/ecp-tutorial/\"\
    \ rel=\"nofollow\">GitHub Pages</a>.</p>\n<h2><a id=\"user-content-ecp-supercontainers-tutorial-session\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#ecp-supercontainers-tutorial-session\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ECP Supercontainers\
    \ Tutorial Session</h2>\n<div><a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"images/ecp.jpg\"><img src=\"images/ecp.jpg\" width=\"250\" style=\"max-width:\
    \ 100%;\"></a></div>\n<h2><a id=\"user-content-details\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#details\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Details</h2>\n<p>Short Tutorial Session</p>\n<p>Venue:\
    \ ECP Annual Meeting 2022</p>\n<p>Date: Friday, May 6, 2022  2:30pm - 4:00pm EDT</p>\n\
    <p>Location: Remote</p>\n<p>Topic Area: Programming Models &amp; Systems Software</p>\n\
    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific\
    \ Software Development, DevOps</p>\n<h2><a id=\"user-content-tutorial-login-details\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#tutorial-login-details\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tutorial\
    \ Login details</h2>\n<p>Appropriate login details to our EC2 VM instances and\
    \ an (optional) training account to the Cori supercomputer will all be provided\
    \ to you at the start of the tutorial session. Please claim your own instance\
    \ in the table at the bottom of the <a href=\"https://docs.google.com/document/d/1rmi5tSuk_7Q5YVDS1SD7TcxjoEYFgXK-ofvUV2jmL4Y/edit?usp=sharing\"\
    \ rel=\"nofollow\">Google Doc</a></p>\n<h3><a id=\"user-content-ec2-login\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#ec2-login\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>EC2 Login</h3>\n<p>hostname:\
    \ tutXX.supercontainers.org</p>\n<p>user: tutorial</p>\n<p>password: Will be provided</p>\n\
    <h3><a id=\"user-content-nersc-login\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#nersc-login\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>NERSC Login</h3>\n<p>hostname: cori.nesrc.gov</p>\n<p>Sign Up; Go\
    \ to <a href=\"https://iris.nersc.gov/train\" rel=\"nofollow\">this page</a> to\
    \ sign up for the account.  Use training code <em>dJ2d</em>.  If you already have\
    \ a NERSC account, you can use that account.</p>\n<h2><a id=\"user-content-abstract\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#abstract\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Abstract</h2>\n\
    <p>Container computing has revolutionized the way applications are developed and\
    \ delivered. It offers opportunities that never existed before for significantly\
    \ improving efficiency of scientific workflows and easily moving these workflows\
    \ from the laptop to the supercomputer. Tools like Docker, Shifter, Singularity\
    \ and Charliecloud enable a new paradigm for scientific and technical computing.\
    \ However, to fully unlock its potential, users and administrators need to understand\
    \ how to utilize these new approaches. This tutorial will introduce attendees\
    \ to the basics of creating container images, explain best practices, and cover\
    \ more advanced topics such as creating images to be run on HPC platforms using\
    \ various container runtimes. The tutorial will also explain how research scientists\
    \ can utilize container-based computing to accelerate their research and how these\
    \ tools can boost the impact of their research by enabling better reproducibility\
    \ and sharing of their scientific process without compromising security.</p>\n\
    <p>This is an short version of the highly successful tutorial presented at multiple\
    \ SC conferences and multiple ECP Summit Meetings.</p>\n<h2><a id=\"user-content-prerequisites\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#prerequisites\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h2>\n\
    <p>This is a hands-on tutorial. Participants will need a laptop/workstation with\
    \ an ssh client to make best use of time during the tutorial.  We will be providing\
    \ training user accounts to both pre-configured EC2 instances as well as the Cori\
    \ Supercomputer at NERSC.</p>\n<div><a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"images/AWS_logo.png\"><img src=\"images/AWS_logo.png\" width=\"250\"\
    \ style=\"max-width: 100%;\"></a></div>\n<p>This tutorial is supported by the\
    \ Amazon AWS Machine Learning Research Awards. EC2 images and temporary login\
    \ credentials will be distributed onsite at the tutorial.</p>\n<p>After the tutorial,\
    \ you can boot our tutorial image yourself on Amazon EC2 to run through the tutorial\
    \ again. We recommend you use your own EC2 key and change the password.</p>\n\
    <p>US-West-Oregon: ami-09bd35c8089302e0d</p>\n<h3><a id=\"user-content-optional-prerequisites\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#optional-prerequisites\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Optional\
    \ Prerequisites</h3>\n<p>Users can also install Docker and Singularity prior to\
    \ attending the tutorial session. Here, it may be beneficial to create a docker\
    \ and sylabs (singularity) account in advance at <a href=\"https://cloud.docker.com/\"\
    \ rel=\"nofollow\">https://cloud.docker.com/</a> and <a href=\"https://cloud.sylabs.io/\"\
    \ rel=\"nofollow\">https://cloud.sylabs.io/</a> This accounts will be needed to\
    \ create images on docker cloud/dockerhub and sylabs cloud.</p>\n<p><a href=\"\
    https://sylabs.io/guides/3.3/user-guide/\" rel=\"nofollow\">Install Singularity\
    \ on Linux</a></p>\n<p><a href=\"https://www.docker.com/products/docker-desktop\"\
    \ rel=\"nofollow\">Install Docker for Desktop</a></p>\n<h2><a id=\"user-content-questions\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#questions\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Questions</h2>\n\
    <p>You can ask questions verbally or with this <a href=\"https://docs.google.com/document/d/1rmi5tSuk_7Q5YVDS1SD7TcxjoEYFgXK-ofvUV2jmL4Y/edit?usp=sharing\"\
    \ rel=\"nofollow\">Google Doc</a>.\nPlease append your question below the others\
    \ in the document.</p>\n<p>We have also created a Slack Team for any and all related\
    \ HPC container discussions.  The invitation link is <a href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h2><a id=\"user-content-schedule\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#schedule\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Schedule</h2>\n<p>Note: times\
    \ are listed in EDT</p>\n<p>2:30 \u2013 2:45 <a href=\"https://drive.google.com/file/d/1KNnrpJI24u2XeL9GTg2HXkV_RHeupD6r/view?usp=sharing\"\
    \ rel=\"nofollow\">Introduction to Containers in HPC</a> (Younge)</p>\n<p>2:45\
    \ \u2013 3:00 <a href=\"/01-hands-on.md\">How to build your first Docker container</a>\
    \ (Canon)</p>\n<p>3:00 \u2013 3:15 <a href=\"/02-hands-on.md\">How to deploy a\
    \ container on a supercomputer</a> (Canon)</p>\n<p>3:15 - 3:45 Containers and\
    \ E4S (Shende)</p>\n<p>3:45 - 4:00 <a href=\"https://drive.google.com/file/d/1Rj2PxSwUHsAC1YtgTo40mod3gFeuYxoN/view?usp=sharing\"\
    \ rel=\"nofollow\">Best Practices and Wrap Up</a> (Canon)</p>\n"
  stargazers_count: 1
  subscribers_count: 7
  topics: []
  updated_at: 1650325690.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2023.10.11
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2023.10.11\"\
    ><img src=\"https://camo.githubusercontent.com/3c7e98ea04bb65e8c1fe3d010054b4ae068cb06ee48c21472afd331cd5772141/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032332e31302e31312d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2023.10.11-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.8431874\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f9eeab14f9dc1b1fd7367bfa5ac1e09e61a20b63357dfb9dba342d13bf36b869/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e383433313837342e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.8431874.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#what-is-spectre\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What is\
    \ SpECTRE?</h2>\n<p>SpECTRE is an open-source code for multi-scale, multi-physics\
    \ problems\nin astrophysics and gravitational physics. In the future, we hope\
    \ that\nit can be applied to problems across discipline boundaries in fluid\n\
    dynamics, geoscience, plasma physics, nuclear physics, and\nengineering. It runs\
    \ at petascale and is designed for future exascale\ncomputers.</p>\n<p>SpECTRE\
    \ is being developed in support of our collaborative Simulating\neXtreme Spacetimes\
    \ (SXS) research program into the multi-messenger\nastrophysics of neutron star\
    \ mergers, core-collapse supernovae, and\ngamma-ray bursts.</p>\n<h2><a id=\"\
    user-content-citing-spectre\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#citing-spectre\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing SpECTRE</h2>\n<p>Please cite SpECTRE in any publications that\
    \ make use of its code or data. Cite\nthe latest version that you use in your\
    \ publication. The DOI for this version\nis:</p>\n<ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.8431874\"\
    \ rel=\"nofollow\">10.5281/zenodo.8431874</a>\n</li>\n</ul>\n<p>You can cite this\
    \ BibTeX entry in your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"\
    ><pre><span class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and Nelli, Kyle C. and Armaza, Crist\\\
    'obal and Bonilla, Marceline S. and</span>\n<span class=\"pl-s\">H\\'ebert, Fran\\\
    c{c}ois and Kim, Yoonsoo and Kumar, Prayush and Lovelace,</span>\n<span class=\"\
    pl-s\">Geoffrey and Macedo, Alexandra and Moxon, Jordan and O'Shea, Eamonn and</span>\n\
    <span class=\"pl-s\">Pfeiffer, Harald P. and Scheel, Mark A. and Teukolsky, Saul\
    \ A. and Wittek,</span>\n<span class=\"pl-s\">Nikolas A. and others<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> = <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2023.10.11}<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span> = <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>2023.10.11<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">publisher</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Zenodo<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"\
    pl-s\">doi</span> = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>10.5281/zenodo.8431874<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>https://spectre-code.org<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">howpublished</span>\
    \ =\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.8431874}{10.5281/zenodo.8431874}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2023<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>10<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2><a id=\"\
    user-content-viewing-documentation\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#viewing-documentation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Viewing Documentation</h2>\n<p>The documentation can\
    \ be viewed at <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 135
  subscribers_count: 16
  topics: []
  updated_at: 1700606434.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - thetagpu/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1><a id="user-content-spack-envs" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-envs"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-envs</h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2><a id="user-content-locally" class="anchor" aria-hidden="true" tabindex="-1"
    href="#locally"><span aria-hidden="true" class="octicon octicon-link"></span></a>Locally</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: $spack/opt/spack</span>

    <span class="pl-c1">build_stage: $spack/var/spack/stage</span>


    <span class="pl-c1">spack env activate ~/Dev/spack-envs/local</span>

    <span class="pl-c1">spack install</span></pre></div>

    <h2><a id="user-content-g5k" class="anchor" aria-hidden="true" tabindex="-1" href="#g5k"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>G5k</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: /my-spack/spack</span>

    <span class="pl-c1">build_stage: /tmp/spack-stage</span></pre></div>

    <h2><a id="user-content-anl" class="anchor" aria-hidden="true" tabindex="-1" href="#anl"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ANL</h2>

    <h3><a id="user-content-cooley" class="anchor" aria-hidden="true" tabindex="-1"
    href="#cooley"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cooley</h3>

    <p>Before using Spack to compile stuff on Cooley, we recommend to run <code>use_build_cooley</code>
    to get access to newer gcc, cmake, and mvapich versions.</p>

    <h3><a id="user-content-thetagpu" class="anchor" aria-hidden="true" tabindex="-1"
    href="#thetagpu"><span aria-hidden="true" class="octicon octicon-link"></span></a>ThetaGPU</h3>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1678891926.0
toxa81/se:
  data_format: 2
  description: Software environments
  filenames:
  - catalog-config/core/spack.yaml
  - catalog-config/libxc-5.2.3/spack.yaml
  full_name: toxa81/se
  latest_release: null
  readme: '<h1><a id="user-content-software-environments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#software-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Software environments</h1>

    <p>Deployment steps</p>

    <ul>

    <li>clone spack <code>git clone https://github.com/spack/spack.git</code>

    </li>

    <li>enable spack <code>source enable-spack</code>

    </li>

    <li>srun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16</li>

    <li>install gcc-11.3.0 view <code>spack -e  ./env-spec/gcc-11.3.0/ install</code>

    </li>

    <li>install nvhpc-22.9 <code>srun -N1 --partition=nvgpu spack -e . install -j64</code>

    </li>

    </ul>

    <p>spack compiler find $(spack find --format {prefix.bin} gcc@11)</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669195550.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-argo/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1635166163.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/hpccf/franklin/cluster-core/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<h1><a id="user-content-spack--uc-davis" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack--uc-davis"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Spack @ UC Davis</h1>

    <h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters" class="anchor"
    aria-hidden="true" tabindex="-1" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack repos and configs
    for UC Davis HPCCF Clusters</h2>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1676322811.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - benchmarks/spack/github-actions/default/spack.yaml
  - benchmarks/spack/isambard-macs/rome/spack.yaml
  - benchmarks/spack/isambard-phase3/ampere/spack.yaml
  - benchmarks/spack/csd3-cascadelake/compute-node/spack.yaml
  - benchmarks/spack/cosma7/rockport-openmpi-compute-node/spack.yaml
  - benchmarks/spack/myriad/v100/spack.yaml
  - benchmarks/spack/isambard-macs/volta/spack.yaml
  - benchmarks/spack/isambard-a64fx/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1><a id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#excalibur-tests\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks\
    \ and regression tests for the ExCALIBUR project.</p>\n<p>These benchmarks are\
    \ based on a similar project by\n<a href=\"https://github.com/stackhpc/hpc-tests\"\
    >StackHPC</a>.</p>\n<p><em><strong>Note</strong>: at the moment the ExCALIBUR\
    \ benchmarks are a work-in-progress.</em></p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>We require Python version 3.7 or later. Install the <strong>excalibur-tests</strong>\
    \ package with <code>pip</code> by</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pip install -e <span class=\"pl-c1\">.</span></pre></div>\n<p>The <code>-e/--editable</code>\
    \ flag is recommended for two reasons.</p>\n<ul>\n<li>Spack installs packages\
    \ in a <code>opt</code> directory under the spack environment. With <code>-e</code>\
    \ the spack\nenvironment remains in your local directory and <code>pip</code>\
    \ creates symlinks to it. Without <code>-e</code> spack\nwill install packages\
    \ inside your python environment.</li>\n<li>For <a href=\"https://setuptools.pypa.io/en/latest/userguide/development_mode.html\"\
    \ rel=\"nofollow\">development</a>,\nthe <code>-e</code> flag to <code>pip</code>\
    \ links the installed package to the files in the local\ndirectory, instead of\
    \ copying, to allow making changes to the installed package.</li>\n</ul>\n<p>Note\
    \ that to use <code>-e</code> with a project configured with a <code>pyproject.toml</code>\
    \ you need <code>pip</code> version 22 or later.</p>\n<p>On most systems, it is\
    \ recommended to install the package in a virtual environment.\nFor example, using\
    \ the python3 <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow\"\
    >built-in virtual environment tool <code>venv</code></a>,\ncreate an environment\
    \ called <code>my_environment</code> with</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python3 -m venv ./my_environment</pre></div>\n<p>and activate it with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">source</span>\
    \ ./my_environment/bin/activate</pre></div>\n<h3><a id=\"user-content-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>The <code>pip install</code> command will install a compatible version of <strong>ReFrame</strong>\
    \ from\n<a href=\"https://pypi.org/project/ReFrame-HPC/\" rel=\"nofollow\">PyPi</a>.\
    \ However, you will have to\nmanually provide an installation of <strong>Spack</strong>.</p>\n\
    <p><a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager\
    \ specifically designed for HPC\nfacilities. In some HPC facilities there may\
    \ be already a central Spack installation available.\nHowever, the version installed\
    \ is most likely too old to support all the features\nused by this package. Therefore\
    \ we recommend you install the latest version locally,\nfollowing the instructions\
    \ below.</p>\n<p><em><strong>Note</strong>: if you have already installed spack\
    \ locally and you want to upgrade to\na newer version, you might first have to\
    \ clear the cache to avoid conflicts:\n<code>spack clean -m</code></em></p>\n\
    <p>Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official instructions</a>\nto install the latest version of\
    \ Spack (summarised here for convenience, but not guaranteed to be\nup-to-date):</p>\n\
    <ul>\n<li>git clone spack:\n<code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code>\n\
    </li>\n<li>run spack setup script: <code>source ./spack/share/spack/setup-env.sh</code>\n\
    </li>\n<li>check spack is in <code>$PATH</code>, for example <code>spack --version</code>\n\
    </li>\n</ul>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable. This\
    \ is taken care of by the <code>setup-env.sh</code>\nscript as above, and you\
    \ can have your shell init script (e.g. <code>.bashrc</code>)\ndo that automatically\
    \ in every session, by adding the following lines to it:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame also requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRAC projects in\n\
    <a href=\"https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack\"\
    >https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack/</a>.\n\
    If you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system if known, otherwise it will automatically\ncreate a very basic environment\
    \ (see \"Usage on unsupported systems\" section below).</p>\n<h2><a id=\"user-content-configuration\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuration</h2>\n\
    <h3><a id=\"user-content-reframe\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#reframe\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ReFrame</h3>\n<p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\"\
    \ rel=\"nofollow\">ReFrame</a> is a high-level\nframework for writing regression\
    \ tests for HPC systems.  For our tests we\nrequire ReFrame v4.1.3.</p>\n<p>We\
    \ provide a ReFrame configuration file with the settings of some systems that\n\
    are part of the ExCALIBUR or DiRAC projects.  You can point ReFrame to this file\
    \ by\nsetting the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILES\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILES</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILES=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-smi\">${PWD}</span>/benchmarks/reframe_config.py<span class=\"pl-pds\"\
    >\"</span></span></pre></div>\n<p>If you want to use a different ReFrame configuration\
    \ file, for example because\nyou use a different system, you can set this environment\
    \ variable to the path of\nthat file.</p>\n<p><strong>Note</strong>: in order\
    \ to use the Spack build system in ReFrame, the <code>spack</code>\nexecutable\
    \ must be in the <code>PATH</code> also on the compute nodes of a cluster, if\n\
    you want to run your benchmarks on them. This is taken care of by adding it\n\
    to your init file (see spack section above).</p>\n<p>However, you will also need\
    \ to set the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ (<code>export RFM_USE_LOGIN_SHELL=\"true\"</code>) in order to make ReFrame\
    \ use</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash -l</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a> line, which would load\nthe user's init script.</p>\n<h2><a id=\"\
    user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <p>Once you have set up Spack and ReFrame, you can execute a benchmark with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/BENCH_NAME\
    \ -r --performance-report</pre></div>\n<p>where <code>benchmarks/apps/BENCH_NAME</code>\
    \ is the directory where the benchmark is.  The command\nabove assumes you have\
    \ the program <code>reframe</code> in your PATH.  If you have followed the instructions\n\
    to install using <code>pip</code> into the default directory, it should have been\
    \ automatically added.\nIf it is not the case, call <code>reframe</code> with\
    \ its relative or absolute path.</p>\n<p>For example, to run the Sombrero benchmark\
    \ in the <code>benchmarks/apps/sombrero</code> directory you can\nuse</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/sombrero\
    \ -r --performance-report</pre></div>\n<p>For benchmarks that use the Spack build\
    \ system, the tests define a default Spack specification\nto be installed in the\
    \ environment, but users can change it when invoking ReFrame on the\ncommand line\
    \ with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3><a id=\"user-content-setting-environment-variables\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#setting-environment-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting\
    \ environment variables</h3>\n<p>All the built-in fields of ReFrame regression\
    \ classes can be set on a per-job basis using the\n<code>-S</code> command-line\
    \ option. One useful such field is\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.env_vars\"\
    \ rel=\"nofollow\"><code>env_vars</code></a>,\nwhich controls the environment\
    \ variables used in a job.\nThe syntax to set dictionary items, like for <code>env_vars</code>,\
    \ is a comma-separated list of <code>key:value</code> pairs: <code>-S dict=key_1:value_1,key_2:value_2</code>.\n\
    For example</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S env_vars=OMP_PLACES:threads\n</code></pre>\n<p>runs the <code>benchmarks/apps/sombrero</code>\
    \ benchmark setting the environment variable <code>OMP_PLACES</code>\nto <code>threads</code>.</p>\n\
    <h3><a id=\"user-content-selecting-system-and-queue-access-options\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#selecting-system-and-queue-access-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  To avoid this, you can use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3><a id=\"user-content-usage-on-unsupported-systems\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#usage-on-unsupported-systems\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage on\
    \ unsupported systems</h3>\n<p>The configuration provided in <a href=\"./reframe_config.py\"\
    ><code>reframe_config.py</code></a> lets you run the\nbenchmarks on pre-configured\
    \ HPC systems.  However you\ncan use this framework on any system by choosing\
    \ the \"default\" system with <code>--system default</code>, or by using your\
    \ own ReFrame configuration.  You can use the \"default\" system to run\nbenchmarks\
    \ in ReFrame without using a queue manager or an MPI launcher (e.g. on a personal\
    \ workstation).</p>\n<p>If you choose the \"default\" system and a benchmark using\
    \ the Spack build system,\na new empty Spack environment will be automatically\
    \ created in\n<code>benchmarks/spack/default</code> when ReFrame is launched for\
    \ the first time.\nYou should populate the environment with the packages already\
    \ installed on your system\nbefore running Spack to avoid excessively rebuilding\
    \ system packages. See the\n<em>Spack configuration</em> section of <a href=\"\
    ./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on how\n\
    to set up a Spack environment.\nIn particular, make sure that at least a compiler\
    \ and an MPI library are added into the environment.\nAfter the Spack environment\
    \ is set up, tell ReFrame to use it by setting the environment\nvariable <code>EXCALIBUR_SPACK_ENV</code>,\
    \ as described above.</p>\n<h3><a id=\"user-content-system-specific-flags\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#system-specific-flags\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System-specific\
    \ flags</h3>\n<p>While the aim is to automate as much system-specific configuration\
    \ as possible, there are some options that have to be provided by the user, such\
    \ as accounting details, and unfortunately the syntax can vary.\nThe file <a href=\"\
    ./SYSTEMS.md\"><code>SYSTEMS.md</code></a> contains information about the use\
    \ of this framework on specific systems.</p>\n<h3><a id=\"user-content-selecting-multiple-benchmarks\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#selecting-multiple-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ multiple benchmarks</h3>\n<p>ReFrame tests may contain tags that allow the user\
    \ to select which tests to run. These can be leveraged to defined sets of benchmarks.\
    \ To run all tests in a directory, pass the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-R\"\
    \ rel=\"nofollow\"><code>-R</code> flag</a> to ReFrame. Then filter down to a\
    \ specific tag by passing the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-0\"\
    \ rel=\"nofollow\"><code>-t</code> flag</a>.</p>\n<p>For example, the <a href=\"\
    https://github.com/ukri-excalibur/excalibur-tests/blob/1a7377e885977833c150569c32eb1db478f63087/benchmarks/examples/sombrero/sombrero.py#L113\"\
    >tag \"example\" is defined</a> in the sombrero example. To select the sombrero\
    \ example out of all benchmarks, run</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>reframe -c benchmarks/ -R -r -t example</pre></div>\n<p>Tests can contain\
    \ multiple tags. To create a custom set of benchmarks, add a new tag to the tests\
    \ you want to include in the set.</p>\n<h2><a id=\"user-content-contributing-new-systems-or-benchmarks\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing-new-systems-or-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\
    \ <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 14
  subscribers_count: 8
  topics: []
  updated_at: 1700350877.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-38/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: v1.1.0
  stargazers_count: 21
  subscribers_count: 5
  topics:
  - jupyter
  - ipython
  - ipython-widget
  - ipywidget
  - jupyter-notebook
  - jupyterhub
  - notebook
  updated_at: 1686918926.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/summit/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  stargazers_count: 5
  subscribers_count: 8
  topics: []
  updated_at: 1700846395.0
