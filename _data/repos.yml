AMReX-Codes/pyamrex:
  data_format: 2
  description: '[Experimental] AMReX Python Bindings'
  filenames:
  - spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: null
  readme: '<h1>

    <a id="user-content-pyamrex" class="anchor" href="#pyamrex" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>pyAMReX</h1>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width:100%;"></a> <a href="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"
    alt="Python3 API: Pre-Alpha" title="Status: Pre-Alpha" data-canonical-src="https://img.shields.io/badge/phase-pre--alpha-yellowgreen"
    style="max-width:100%;"></a>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License AMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width:100%;"></a><br>

    <a href="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    target="_blank" rel="noopener noreferrer"><img src="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    alt="linux" style="max-width:100%;"></a>

    <a href="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    target="_blank" rel="noopener noreferrer"><img src="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    alt="macos" style="max-width:100%;"></a>

    <a href="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    target="_blank" rel="noopener noreferrer"><img src="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    alt="windows" style="max-width:100%;"></a></p>

    <p>pyAMReX is part of AMReX.</p>

    <p>Due to its <strong>highly experimental</strong> nature, we develop it currently
    in a separate respository.</p>

    <p>We will add further information here once first development versions are ready
    for testing.</p>

    <h2>

    <a id="user-content-users" class="anchor" href="#users" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Users</h2>

    <p><em>to do</em></p>

    <ul>

    <li>pip/pypa</li>

    <li>conda-forge</li>

    <li>spack</li>

    <li>brew</li>

    <li>...</li>

    </ul>

    <h3>

    <a id="user-content-usage" class="anchor" href="#usage" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h3>

    <p><em>to do</em></p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <h2>

    <a id="user-content-developers" class="anchor" href="#developers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Developers</h2>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <h3>

    <a id="user-content-dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B14" rel="nofollow">C++14</a>
    compiler: e.g. g++ 5.0+, clang 5.0+, VS 2017+</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.18.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.6.2+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.6+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://www.openmp.org" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (needs
    3.7.9+ for CUDA)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <h3>

    <a id="user-content-install-dependencies" class="anchor" href="#install-dependencies"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Install
    Dependencies</h3>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.18.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional:                                    --user</span>

    python3 -m pip install -U pip setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <h3>

    <a id="user-content-configure-your-compiler" class="anchor" href="#configure-your-compiler"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configure
    your compiler</h3>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <h3>

    <a id="user-content-build--test" class="anchor" href="#build--test" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build &amp; Test</h3>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    <span class="pl-c"><span class="pl-c">#</span> optional:                 --force-reinstall
    --user</span>

    python3 -m pip install -v <span class="pl-c1">.</span></pre></div>

    <p>On successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests </span>

    python -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python -m pytest tests/test_intvect.py::test_iv_conversions</pre></div>

    <p>If you are iterating on C++ builds, it might be faster to just call CMake:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build

    cmake --build build -j 8  <span class="pl-c"><span class="pl-c">#</span> repeat
    this step to fix compile errors</span></pre></div>

    <h3>

    <a id="user-content-build-options" class="anchor" href="#build-options" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Options</h3>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>1/2/<strong>3</strong>

    </td>

    <td>Dimension of AMReX</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_LIBDIR</code></td>

    <td>

    <em>None</em>         (note: not yet implemented)</td>

    <td>If set, search for pre-built AMReX C++ libraries (see below)</td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    </tbody>

    </table>

    <p>For example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>pyAMReX Copyright (c) 2021, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for pyamrex can be found at <a href="LICENSE">LICENSE</a>.</p>

    '
  stargazers_count: 8
  subscribers_count: 15
  topics:
  - amrex
  - python
  updated_at: 1618453857.0
Alpine-DAV/ascent:
  data_format: 2
  description: A flyweight in situ visualization and analysis runtime for multi-physics
    HPC simulations
  filenames:
  - scripts/uberenv/spack_envs/llnl/pascal-cuda/spack.yaml
  - scripts/uberenv/spack_envs/ci/ubuntu_18_cuda_10.1_devel/spack.yaml
  - scripts/uberenv/spack_envs/llnl/quartz/spack.yaml
  - scripts/uberenv/spack_envs/olcf/summit/spack.yaml
  - scripts/uberenv/spack_envs/ci/ubuntu_18_devel/spack.yaml
  full_name: Alpine-DAV/ascent
  latest_release: v0.7.1
  readme: '<h1>

    <a id="user-content-ascent" class="anchor" href="#ascent" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Ascent</h1>

    <p>Ascent is an open source many-core capable lightweight in situ visualization
    and analysis infrastructure for multi-physics HPC simulations.</p>

    <h1>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>To get started building and using Ascent, check out the full documentation:</p>

    <p><a href="https://alpine-dav.github.io/ascent/" rel="nofollow">https://alpine-dav.github.io/ascent/</a></p>

    <h1>

    <a id="user-content-source-repo" class="anchor" href="#source-repo" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Repo</h1>

    <p>Ascent''s source is hosted on GitHub:</p>

    <p><a href="https://github.com/Alpine-DAV/ascent">https://github.com/Alpine-DAV/ascent</a></p>

    <h1>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h1>

    <p>Ascent is released under a BSD-style license - for detailed license info, refer
    to:</p>

    <p><a href="http://ascent.readthedocs.io/en/latest/Licenses.html" rel="nofollow">http://ascent.readthedocs.io/en/latest/Licenses.html</a></p>

    <p>or the following files in the Ascent source tree:</p>

    <ul>

    <li><a href="/LICENSE">LICENSE</a></li>

    </ul>

    <h1>

    <a id="user-content-changelog" class="anchor" href="#changelog" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Changelog</h1>

    <ul>

    <li><a href="/CHANGELOG.md">Changelog</a></li>

    </ul>

    '
  stargazers_count: 79
  subscribers_count: 12
  topics:
  - hpc
  - parallel-computing
  - cuda
  - mpi
  - rendering
  - analysis
  - scientific-computing
  - data-viz
  - radiuss
  updated_at: 1621576283.0
ArangoGutierrez/spack-operator:
  data_format: 2
  description: The Spack-operator manages automated builds on a distributed and heterogeneus
    kubernetes cluster
  filenames: []
  full_name: ArangoGutierrez/spack-operator
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-operator" class="anchor" href="#spack-operator" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-operator</h1>

    <p>The Spack-operator manages automated builds on a distributed and heterogeneus
    kubernetes cluster</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1613727652.0
FTHPC/libpressio_tutorial:
  data_format: 2
  description: A Tutorial for LibPressio
  filenames:
  - spack.yaml
  full_name: FTHPC/libpressio_tutorial
  latest_release: null
  readme: '<h1>

    <a id="user-content-libpressio-tutorial" class="anchor" href="#libpressio-tutorial"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>LibPressio
    Tutorial</h1>

    <p>This repository contains a number of example applications to help you learn
    how

    to use LibPressio lossy compression.  The exercises are located in <code>exercises/</code>

    and have their own instructions in the README.md file.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1621648529.0
KoyamaSohei/raft:
  data_format: 2
  description: Raft implementation which depends on Mochi Project and Symas LMDB
  filenames:
  - spack.yaml
  full_name: KoyamaSohei/raft
  latest_release: null
  readme: "<h2>\n<a id=\"user-content-raft\" class=\"anchor\" href=\"#raft\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>raft</h2>\n\
    <p><a href=\"https://raft.github.io/\" rel=\"nofollow\">Raft</a> implementation\
    \ which depends on <a href=\"https://mochi.readthedocs.io/\" rel=\"nofollow\"\
    >Mochi Project</a> and <a href=\"https://symas.com/lmdb/\" rel=\"nofollow\">Symas\
    \ LMDB</a></p>\n<p>this is one of projects in <a href=\"http://www.hpcs.cs.tsukuba.ac.jp/~tatebe/lecture/r02/dpro/\"\
    \ rel=\"nofollow\">\u4E3B\u5C02\u653B\u5B9F\u9A13 K-16</a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1612651620.0
LLNL/conduit:
  data_format: 2
  description: Simplified Data Exchange for HPC Simulations
  filenames:
  - scripts/uberenv_configs/spack_envs/llnl/quartz/spack.yaml
  full_name: LLNL/conduit
  latest_release: v0.7.2
  readme: '<h1>

    <a id="user-content-conduit" class="anchor" href="#conduit" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Conduit</h1>

    <p><strong>Conduit: Simplified Data Exchange for HPC Simulations</strong></p>

    <p>Conduit is an open source project from Lawrence Livermore National Laboratory
    that provides an intuitive model for describing hierarchical scientific data in
    C++, C, Fortran, and Python. It is used for data coupling between packages in-core,
    serialization, and I/O tasks.</p>

    <p><a href="https://travis-ci.org/LLNL/conduit" rel="nofollow"><img src="https://camo.githubusercontent.com/478365930966f70f879ae04d59ea3f5c5888bee7d2a50e7e281dc1da3cf9aff1/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67"
    alt="Travis CI Build Status" data-canonical-src="https://travis-ci.org/LLNL/conduit.png"
    style="max-width:100%;"></a>

    <a href="https://ci.appveyor.com/project/cyrush/conduit" rel="nofollow"><img src="https://camo.githubusercontent.com/a0839e4a484ebb633a1c2ebcd90e345a176f5edc60e42f32636eefa9c3c79fad/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565"
    alt="Appveyor Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop&amp;svg=true"
    style="max-width:100%;"></a>

    <a href="https://coveralls.io/github/LLNL/conduit?branch=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/50b12c605f0f4bcc64b6db415dddf2de99c5e19a526d7bc53e45db45c95b2931/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop"
    style="max-width:100%;"></a>

    <a href="https://scan.coverity.com/projects/llnl-conduit" rel="nofollow"><img
    src="https://camo.githubusercontent.com/d4b204e42fe1ef30b166cdfd7cba043d5d74600b343aedd5e094a810b4c5c727/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31"
    alt="Static Analysis Status" data-canonical-src="https://scan.coverity.com/projects/8426/badge.svg?flat=1"
    style="max-width:100%;"></a></p>

    <h1>

    <a id="user-content-documentation" class="anchor" href="#documentation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>To get started building and using Conduit, check out the full documentation:</p>

    <p><a href="http://llnl-conduit.readthedocs.io/" rel="nofollow">http://llnl-conduit.readthedocs.io/</a></p>

    <h1>

    <a id="user-content-source-repo" class="anchor" href="#source-repo" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Repo</h1>

    <p>Conduit''s source is hosted on GitHub:</p>

    <p><a href="https://github.com/llnl/conduit">https://github.com/llnl/conduit</a></p>

    <h1>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h1>

    <p>Conduit is released under a BSD-style license - for detailed license info,
    refer to:</p>

    <p><a href="https://llnl-conduit.readthedocs.io/en/latest/licenses.html" rel="nofollow">https://llnl-conduit.readthedocs.io/en/latest/licenses.html</a></p>

    <p>or the following files in the Conduit source tree:</p>

    <ul>

    <li><a href="/LICENSE">LICENSE</a></li>

    <li><a href="/thirdparty_licenses.md">thirdparty_licenses.md</a></li>

    </ul>

    <h1>

    <a id="user-content-changelog" class="anchor" href="#changelog" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Changelog</h1>

    <ul>

    <li><a href="/CHANGELOG.md">Changelog</a></li>

    </ul>

    '
  stargazers_count: 88
  subscribers_count: 16
  topics:
  - hpc
  - scientific-computing
  - cpp
  - fortran
  - python
  - llnl
  - json
  - yaml
  - hdf5
  - radiuss
  - data-management
  updated_at: 1621476188.0
SeisSol/seissol-spack-aid:
  data_format: 2
  description: Spack support for SeisSol and related tools
  filenames:
  - deployment/default-env-utils-images/image-files/arm64/spack.yaml
  - deployment/default-env-utils-images/image-files/amd64/spack.yaml
  full_name: SeisSol/seissol-spack-aid
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack" class="anchor" href="#spack" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack</h1>

    <p>Spack support for SeisSol and related tools</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1619723394.0
TurbulentDynamics/tdLBCpp:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: TurbulentDynamics/tdLBCpp
  latest_release: null
  readme: '<h1>

    <a id="user-content-turbulent-dynamics-lattice-boltzmann-c" class="anchor" href="#turbulent-dynamics-lattice-boltzmann-c"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Turbulent
    Dynamics Lattice Boltzmann (C++)</h1>

    <p>This is a basic version of the multi-node heterogeneous HPC code to run billions
    of cell simulation.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1619466471.0
UCR-Research-Computing/using-nautilus-cluster:
  data_format: 2
  description: null
  filenames: []
  full_name: UCR-Research-Computing/using-nautilus-cluster
  latest_release: null
  readme: '<h1>

    <a id="user-content-using-nautilus-cluster" class="anchor" href="#using-nautilus-cluster"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>using-nautilus-cluster</h1>

    <h3>

    <a id="user-content-basic-commmands" class="anchor" href="#basic-commmands" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>basic commmands</h3>

    <div class="highlight highlight-source-shell"><pre>

    kubectl get pods

    kubectl create -f <span class="pl-k">&lt;</span>yaml-file<span class="pl-k">&gt;</span>

    kubectl delete pods <span class="pl-k">&lt;</span>pod-name<span class="pl-k">&gt;</span>


    kubectl <span class="pl-c1">exec</span> -it <span class="pl-k">&lt;</span>pod-name<span
    class="pl-k">&gt;</span> bash

    kubectl port-forward <span class="pl-k">&lt;</span>pod-name<span class="pl-k">&gt;</span>
    8888:8888

    </pre></div>

    <h3>

    <a id="user-content-starting-jupyter" class="anchor" href="#starting-jupyter"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Starting
    Jupyter</h3>

    <p>Use the tensorflow-cpu-pod.yaml or tensorflow-gpu-pod.yaml file to start the
    pod</p>

    <div class="highlight highlight-source-shell"><pre>

    kubectl create -f tensorflow-gpu-pod.yaml

    kubectl <span class="pl-c1">exec</span> -it gpu-pod-example bash


    jovyan@gpu-pod-example:<span class="pl-k">~</span>$ jupyter notebook --ip=<span
    class="pl-s"><span class="pl-pds">''</span>0.0.0.0<span class="pl-pds">''</span></span>


    kubectl port-forward gpu-pod-example 8888:8888

    </pre></div>

    <ul>

    <li>open browser to localhost:8888 and paste in the token from the jupyter notebook
    start command</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1607345085.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/rhel8-runner-ppc64le/spack.yaml
  - spack-sdk-environments/e4s_ecosystem/spack.yaml
  - spack-sdk-environments/xsdk/spack.yaml
  - docker-recipes/rhel7-runner-ppc64le/spack.yaml
  - spack-sdk-environments/compilers_and_support/spack.yaml
  - spack-sdk-environments/data-mgmt_io-services_checkpoint-restart/spack.yaml
  - spack-sdk-environments/visualization_analysis_reduction/spack.yaml
  - docker-recipes/rhel8-runner-x86_64/spack.yaml
  - spack-sdk-environments/pmr_core/spack.yaml
  - docker-recipes/superlu-sc/spack.yaml
  - docker-recipes/rhel7-runner-x86_64/spack.yaml
  - spack-sdk-environments/tools_and_technology/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a href="figures/SDKdefinition1.png" target="_blank" rel="noopener noreferrer"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width:100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 11
  subscribers_count: 4
  topics: []
  updated_at: 1621369941.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent8/envs/avx/lusoft/spack.yaml
  - cent7/library/spack.yaml
  - cent7/ece_hpc/spack.yaml
  - cent7/library/spack.yaml~
  - cent8/envs/x86_64/spack.yaml
  - cent8/envs/avx512/python/spack.yaml
  - cent7/py_376/spack.yaml
  - cent7/bioinformatics_default/spack.yaml.bak
  - cent7/libs_old/spack.yaml
  - cent7/bioinformatics/spack.yaml
  - cent7/python_376/spack.yaml
  - compilers/envs/compilers/spack.yaml
  - cent8/envs/avx2/lusoft/spack.yaml
  - cent8/envs/avx512/lusoft/spack.yaml
  - cent8/envs/avx512/rproject/spack.yaml
  - cent8/envs/avx/python/spack.yaml
  - cent7/library/bak/spack.yaml
  - cent7/mpis/spack.yaml
  - cent8/envs/avx/rproject/spack.yaml
  - cent7/bio_old/spack.yaml
  - cent8/envs/avx2/python/spack.yaml
  - cent7/apps/spack.yaml
  - cent8/envs/solhawk/spack.yaml
  - cent8/envs/avx2/rproject/spack.yaml
  - cent7/bioinformatics_default/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-environments" class="anchor" href="#spack-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPACK
    Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2>

    <a id="user-content-software-deployment-for-centos-8x" class="anchor" href="#software-deployment-for-centos-8x"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3>

    <a id="user-content-compilers" class="anchor" href="#compilers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3>

    <a id="user-content-lu-software" class="anchor" href="#lu-software" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LU Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4>

    <a id="user-content-available-environments" class="anchor" href="#available-environments"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    Environments</h4>

    <h5>

    <a id="user-content-solhawk" class="anchor" href="#solhawk" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-avxavx2avx512" class="anchor" href="#avxavx2avx512" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-python-and-r-packages" class="anchor" href="#python-and-r-packages"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Python
    and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4>

    <a id="user-content-x86_64" class="anchor" href="#x86_64" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2>

    <a id="user-content-centos-7x-software" class="anchor" href="#centos-7x-software"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CentOS
    7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1620234577.0
autamus/registry:
  data_format: 2
  description: The Core Registry of Container Blueprints for the Autamus Build System
  filenames:
  - containers/g/graphviz/spack.yaml
  - containers/i/igraph/spack.yaml
  - containers/m/mothur/spack.yaml
  - containers/p/pandaseq/spack.yaml
  - containers/c/corset/spack.yaml
  - containers/g/go/spack.yaml
  - containers/a/advancecomp/spack.yaml
  - containers/p/proj/spack.yaml
  - containers/v/valgrind/spack.yaml
  - containers/e/eagle/spack.yaml
  - containers/r/raxml/spack.yaml
  - containers/g/gmp/spack.yaml
  - containers/m/mummer/spack.yaml
  - containers/p/poppler/spack.yaml
  - containers/x/xrootd/spack.yaml
  - containers/s/singularity/spack.yaml
  - containers/v/viennarna/spack.yaml
  - containers/b/boost/spack.yaml
  - containers/m/meme/spack.yaml
  - containers/p/prodigal/spack.yaml
  - containers/j/jags/spack.yaml
  - containers/p/plink/spack.yaml
  - containers/c/circos/spack.yaml
  - containers/b/beast2/spack.yaml
  - containers/r/r-seqlogo/spack.yaml
  - containers/a/astral/spack.yaml
  - containers/i/iq-tree/spack.yaml
  - containers/s/scons/spack.yaml
  - containers/b/bedtools2/spack.yaml
  - containers/r/ruby/spack.yaml
  - containers/a/alps/spack.yaml
  - containers/p/protobuf/spack.yaml
  - containers/a/admixtools/spack.yaml
  - containers/g/git/spack.yaml
  - containers/g/gnuplot/spack.yaml
  - containers/g/geant4/spack.yaml
  - containers/g/geos/spack.yaml
  - containers/m/mono/spack.yaml
  - containers/b/binutils/spack.yaml
  - containers/n/nco/spack.yaml
  - containers/f/fastqc/spack.yaml
  - containers/q/qhull/spack.yaml
  - containers/p/papi/spack.yaml
  - containers/c/cloc/spack.yaml
  - containers/o/octave/spack.yaml
  - containers/p/perl/spack.yaml
  - containers/t/tcsh/spack.yaml
  - containers/h/hypre/spack.yaml
  - containers/c/cctools/spack.yaml
  - containers/r/rust/spack.yaml
  - containers/c/cdo/spack.yaml
  - containers/o/openbabel/spack.yaml
  - containers/s/sparsehash/spack.yaml
  - containers/i/ior/spack.yaml
  - containers/a/apr/spack.yaml
  - containers/l/lmod/spack.yaml
  - containers/s/sparse/spack.yaml
  - containers/g/gdal/spack.yaml
  - containers/l/libpng/spack.yaml
  - containers/p/pcre/spack.yaml
  - containers/b/bracken/spack.yaml
  - containers/d/dyninst/spack.yaml
  - containers/r/r/spack.yaml
  - containers/o/openjdk/spack.yaml
  - containers/c/clingo-bootstrap/spack.yaml
  - containers/a/accumulo/spack.yaml
  - containers/a/aria2/spack.yaml
  - containers/m/mpc/spack.yaml
  - containers/b/bbmap/spack.yaml
  - containers/l/lp-solve/spack.yaml
  - containers/c/cowsay/spack.yaml
  - containers/a/abyss/spack.yaml
  - containers/c/cufflinks/spack.yaml
  - containers/g/gsl/spack.yaml
  - containers/a/autodock-gpu/spack.yaml
  - containers/m/mercurial/spack.yaml
  - containers/b/bedops/spack.yaml
  - containers/m/mafft/spack.yaml
  - containers/i/intel-mkl/spack.yaml
  - containers/g/gromacs/spack.yaml
  - containers/c/cantera/spack.yaml
  - containers/g/glpk/spack.yaml
  - containers/m/mpfr/spack.yaml
  - containers/b/bowtie2/spack.yaml
  - containers/w/wget/spack.yaml
  - containers/r/rclone/spack.yaml
  - containers/a/apr-util/spack.yaml
  - containers/a/ascent/spack.yaml
  - containers/a/addrwatch/spack.yaml
  - containers/h/htslib/spack.yaml
  - containers/n/node-js/spack.yaml
  - containers/a/ant/spack.yaml
  - containers/h/hdf5/spack.yaml
  - containers/a/argobots/spack.yaml
  - containers/a/angsd/spack.yaml
  - containers/s/samtools/spack.yaml
  - containers/b/bwa/spack.yaml
  - containers/g/gatk/spack.yaml
  - containers/j/julia/spack.yaml
  - containers/s/salmon/spack.yaml
  - containers/s/spades/spack.yaml
  - containers/d/dakota/dakota/spack.yaml
  - containers/o/opencv/spack.yaml
  - containers/b/bart/spack.yaml
  - containers/l/lammps/spack.yaml
  - containers/m/muscle/spack.yaml
  - containers/a/alan/spack.yaml
  - containers/b/bismark/spack.yaml
  - containers/l/libtiff/spack.yaml
  - containers/c/cfitsio/spack.yaml
  - containers/s/siesta/spack.yaml
  - containers/a/autodock-vina/spack.yaml
  - containers/c/curl/spack.yaml
  - containers/d/diamond/spack.yaml
  - containers/u/unixodbc/spack.yaml
  - containers/s/stringtie/spack.yaml
  - containers/g/grass/spack.yaml
  - containers/m/migrate/spack.yaml
  - containers/f/fraggenescan/spack.yaml
  - containers/h/hisat2/spack.yaml
  - containers/s/snappy/spack.yaml
  - containers/c/clhep/spack.yaml
  - containers/l/libxpm/spack.yaml
  - containers/h/heaptrack/spack.yaml
  - containers/a/abi-dumper/spack.yaml
  - containers/c/clingo/spack.yaml
  - containers/z/zlib/spack.yaml
  - containers/f/ffmpeg/spack.yaml
  - containers/j/jasper/spack.yaml
  - containers/x/xz/spack.yaml
  - containers/u/udunits/spack.yaml
  - containers/h/hmmer/spack.yaml
  - containers/g/gcc/spack.yaml
  - containers/k/kallisto/spack.yaml
  - containers/s/sqlite/spack.yaml
  - containers/k/kraken2/spack.yaml
  - containers/b/bcftools/spack.yaml
  - containers/p/python/spack.yaml
  - containers/p/povray/spack.yaml
  - containers/p/picard/spack.yaml
  full_name: autamus/registry
  latest_release: null
  readme: '<h1>

    <a id="user-content-registry" class="anchor" href="#registry" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Registry</h1>

    <p><a href="https://avatars.githubusercontent.com/u/73002963" target="_blank"
    rel="nofollow"><img src="https://avatars.githubusercontent.com/u/73002963" width="300"
    height="300" style="max-width:100%;"></a></p>

    The Core Registry of Container Blueprints for the Autamus Build System

    <h2>

    <a id="user-content-table-of-contents" class="anchor" href="#table-of-contents"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Table
    of Contents</h2>

    <ul>

    <li><a href="#backstory">Backstory</a></li>

    <li><a href="#introduction">Introduction</a></li>

    <li>

    <a href="#usage">Usage</a>

    <ul>

    <li><a href="#downloading-a-container">Downloading A Container</a></li>

    <li><a href="#submitting-a-package">Submitting A Package</a></li>

    </ul>

    </li>

    <li><a href="#container-size-comparison">Container Size Comparison</a></li>

    </ul>

    <h2>

    <a id="user-content-backstory" class="anchor" href="#backstory" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Backstory</h2>

    <p>At the end of my undergraduate freshman year, as my internship with the University''s
    Research &amp; HPC Computing group was finishing up, a friend (@bjoyce3) and I
    (@alecbcs) were talking about the software installed on our University''s local
    HPC. In particular, how the age of many of the analysis packages (and their depedencies)
    were keeping us from updating the operating systems of the clusters. During that
    conversation, we started dreaming about "an autonoumous build system" for scientific
    containers. One that would update containers as new versions of their source code
    became available, rebuild containers as a package''s depedencies received updates,
    and thoroughly test the containers before publishing them. During that following
    summer, I was hired on by the HPC Team and this idea became a multi-year project.
    Although we''ve still got a ways to go handling depdencies and testing contaiers
    we''re ready to begin building analysis packages for researchers. If this interests
    you as a researcher, research software engineer, or system admin check below to
    see how you can submit packages and pull the built containers.</p>

    <h2>

    <a id="user-content-introduction" class="anchor" href="#introduction" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

    <p>Autamus is an semi-autonomous build system for scientific containers. What
    do I mean by "semi-autonomous"? Well given that the source code of a package is
    hosted on GitHub, GitLab, Sourceforge, etc... our bot Binoc can tell when new
    versions of a package have been released and will submit those updates as Pull
    Requests to this repository and attempt to build the updated packages. Don''t
    worry a human will always be in the loop to check over and approve an update for
    security. With Binoc''s help however, container maintainers no longer have to
    spend their time remembering to check every package for updates. From the perspective
    of a user this also means you can spend less time submitting update requests and
    more time using whichever version of a container that you''d like.</p>

    <h2>

    <a id="user-content-usage" class="anchor" href="#usage" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h2>

    <h3>

    <a id="user-content-downloading-a-container" class="anchor" href="#downloading-a-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Downloading
    A Container</h3>

    <p>Right now all of our packages are hosted on the GitHub Container Registry.</p>

    <p><a href="https://github.com/orgs/autamus/packages">Check Them Out Here!</a></p>

    <h3>

    <a id="user-content-submitting-a-package" class="anchor" href="#submitting-a-package"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Submitting
    a Package</h3>

    <p>*note: At the moment we are only building single package containers although
    multi-package containers are coming soon!</p>

    <ol>

    <li>Fork this repository (button at the top right of this page!)</li>

    <li>Check out the <a href="https://spack.readthedocs.io/en/latest/package_list.html"
    rel="nofollow">Spack Repository</a> to see if they have the package build instructions
    you are looking for. Or checkout the <a href="https://spack.readthedocs.io/en/latest/packaging_guide.html"
    rel="nofollow">Spack Docs</a> to learn how to build your very of instruction file
    (called a Speck).</li>

    <li>Add that package.py file (and any other nessiary files like patches) to a
    directory in your fork of this repository under <code>spack/FIRST-LETTER-OF-APPLICATION/NAME-OF-APPLICATION/package.py</code>.</li>

    <li>Commit that new directory to your fork and open a pull request on this repository
    from your fork.</li>

    </ol>

    <h2>

    <a id="user-content-container-size-comparison" class="anchor" href="#container-size-comparison"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Container
    Size Comparison</h2>

    <table>

    <thead>

    <tr>

    <th><strong>Package/Container Name</strong></th>

    <th><strong>Autamus Container Size</strong></th>

    <th><strong>Official Dockerhub Container Size</strong></th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Python</td>

    <td>417MB</td>

    <td>885MB</td>

    </tr>

    <tr>

    <td>R</td>

    <td>517.9MB</td>

    <td>761.2MB</td>

    </tr>

    <tr>

    <td>GCC</td>

    <td>1.731GB</td>

    <td>1.186GB</td>

    </tr>

    <tr>

    <td>Go</td>

    <td>751.2MB</td>

    <td>861.9MB</td>

    </tr>

    </tbody>

    </table>

    <h3>

    <a id="user-content-how-are-autamus-containers-smaller" class="anchor" href="#how-are-autamus-containers-smaller"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How
    are Autamus Containers Smaller?</h3>

    <p>Autamus uses Spack to build all packages from source before deleting no longer
    needed build dependencies. As a result Autamus containers only contain a minimal
    Linux environment and the software of the container.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1621656911.0
cinemascienceworkflows/2021-05_ExaWind-AMRWind:
  data_format: 2
  description: null
  filenames:
  - inputs/spack/spack.yaml
  full_name: cinemascienceworkflows/2021-05_ExaWind-AMRWind
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configs" class="anchor" href="#spack-configs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1621478944.0
eugeneswalker/exawind-containers:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/exawind-containers
  latest_release: null
  readme: '<h2>

    <a id="user-content-working-with-the-docker-image-ecpe4sexawindlatest" class="anchor"
    href="#working-with-the-docker-image-ecpe4sexawindlatest" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Working with the Docker
    image (ecpe4s/exawind:latest)</h2>

    <ol>

    <li>Build the Docker image</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Launch a container from the image</li>

    </ol>

    <pre><code>$&gt; docker run -it --rm ecpe4s/exawind


    root@8df184bdac63:/# which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    root@8df184bdac63:/# which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2>

    <a id="user-content-working-with-the-singularity-image-exawindsif" class="anchor"
    href="#working-with-the-singularity-image-exawindsif" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Working with the Singularity
    image (exawind.sif)</h2>

    <ol>

    <li>Build the Docker image:</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Build the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./build-singularity-image.sh

    </code></pre>

    <ol start="3">

    <li>Run the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./exawind.sif


    Exawind Singularity&gt; which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    Exawind Singularity&gt; which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2>

    <a id="user-content-run-selected-exawind-regression-tests" class="anchor" href="#run-selected-exawind-regression-tests"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Run
    Selected ExaWind Regression Tests</h2>

    <ol>

    <li>

    <p>Launch a container using either the Docker or Singularity image (see above)</p>

    </li>

    <li>

    <p>Clone this repository in the newly launched container and run the tests (here
    illustrated with Singularity)</p>

    </li>

    </ol>

    <pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers
    ~/exawind-containers

    Exawind Singularity&gt; cd ~/exawind-containers/demo



    Exawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh

    PASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15



    Exawind Singularity&gt; ./run-nalu-wind-tests.sh

    PASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11

    PASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13

    ...



    Exawind Singularity&gt; ./run-amr-wind-tests.sh

    finished abl_bndry_output

    finished abl_godunov

    ...

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1619816372.0
felixthieme/2020_ASPECT_IGG:
  data_format: 2
  description: null
  filenames:
  - contrib/spack/spack.yaml
  full_name: felixthieme/2020_ASPECT_IGG
  latest_release: null
  readme: "<p>(Cloned from ASPECT by Felix Thieme (Idaho Geodynamics Group) on 5/27/2020)</p>\n\
    <h1>\n<a id=\"user-content-aspect---advanced-solver-for-problems-in-earths-convection\"\
    \ class=\"anchor\" href=\"#aspect---advanced-solver-for-problems-in-earths-convection\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ASPECT - Advanced Solver for Problems in Earth's ConvecTion</h1>\n\
    <p><a href=\"https://github.com/geodynamics/aspect/blob/master/LICENSE\"><img\
    \ src=\"https://camo.githubusercontent.com/6bdbfedce993ff7baeecb8c93e87eeebe79d7ae3d19002c54f87e301ec0e7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6372616e2f6c2f646576746f6f6c732e737667\"\
    \ alt=\"License GPL2:\" data-canonical-src=\"https://img.shields.io/cran/l/devtools.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.2653531\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/91da28a81e083b7f3b47a26fd70f2dfcf0a87a9306f2b6f0d457a65ebe089752/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e323635333533312e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.2653531.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.6084/m9.figshare.4865333\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7f17ee0a3d31869d37f8d1b1f43540d6fb99d9a8c72bcf879977682693cbe1a7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6765742d5044462d677265656e2e737667\"\
    \ alt=\"pdf manual\" data-canonical-src=\"https://img.shields.io/badge/get-PDF-green.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-about\" class=\"\
    anchor\" href=\"#about\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>About</h2>\n<p>ASPECT is a code to simulate\
    \ convection in Earth's mantle and elsewhere.\nIt has grown from a pure mantle-convection\
    \ code into a tool for many\ngeodynamic applications including applications for\
    \ inner core convection,\nlithospheric scale deformation, two-phase flow, and\
    \ numerical methods development.\nThe project is supported by CIG (<a href=\"\
    http://geodynamics.org\" rel=\"nofollow\">http://geodynamics.org</a>).</p>\n<h2>\n\
    <a id=\"user-content-installation-instructions\" class=\"anchor\" href=\"#installation-instructions\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation instructions</h2>\n<p>The steps to install the necessary\
    \ dependencies and ASPECT itself are described\nin the Installation instructions\
    \ section of the ASPECT\n<a href=\"http://www.math.clemson.edu/~heister/manual.pdf\"\
    \ rel=\"nofollow\">manual</a>. If you encounter\nproblems during the installation,\
    \ please consult our\n<a href=\"https://github.com/geodynamics/aspect/wiki\">wiki</a>\
    \ for typical installation\nproblems or specific instructions for MacOS users,\
    \ before asking your question\non the mailing list.</p>\n<h2>\n<a id=\"user-content-running-and-extending-aspect\"\
    \ class=\"anchor\" href=\"#running-and-extending-aspect\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ and extending ASPECT</h2>\n<p>Instructions on how to run and extend, as well\
    \ as on how to interpret the\noutput of ASPECT can also be found in the ASPECT\n\
    <a href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\">manual</a>.\
    \ This manual also\ndiscusses the structure of the source code.</p>\n<p>For getting\
    \ started, you can also watch our online\n<a href=\"https://geodynamics.org/cig/events/calendar/2016-cig-all-hands-meeting/aspect-tutorial/tutorial/\"\
    \ rel=\"nofollow\">tutorial</a>.</p>\n<h2>\n<a id=\"user-content-contributing-to-aspect\"\
    \ class=\"anchor\" href=\"#contributing-to-aspect\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ to ASPECT</h2>\n<p>ASPECT is a community project that lives by the participation\
    \ of its\nmembers \u2014 i.e., including you! It is our goal to build an inclusive\n\
    and participatory community so we are happy that you are interested in\nparticipating!\
    \ We have collected a set of guidelines and advice on how\nto get involved in\
    \ the community and keep them in the\n<a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a>\n\
    file in ASPECT's repository.</p>\n<h2>\n<a id=\"user-content-more-information\"\
    \ class=\"anchor\" href=\"#more-information\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>More information</h2>\n<p>For\
    \ more information see:</p>\n<ul>\n<li>\n<p>The official website at <a href=\"\
    https://aspect.geodynamics.org\" rel=\"nofollow\">https://aspect.geodynamics.org</a></p>\n\
    </li>\n<li>\n<p>The current <a href=\"http://www.math.clemson.edu/~heister/manual.pdf\"\
    \ rel=\"nofollow\">manual</a></p>\n</li>\n<li>\n<p><a href=\"https://aspect.geodynamics.org/cite.html\"\
    \ rel=\"nofollow\">How to cite ASPECT</a></p>\n</li>\n<li>\n<p>For questions on\
    \ the source code of ASPECT, portability, installation, new or existing features,\
    \ etc., use the <a href=\"https://community.geodynamics.org/c/aspect\" rel=\"\
    nofollow\">ASPECT forum</a>. This forum is where the ASPECT users and developers\
    \ all hang out. Archived discussions from the inactive aspect-devel mailing list\
    \ can be downloaded at <a href=\"http://lists.geodynamics.org/pipermail/aspect-devel\"\
    \ rel=\"nofollow\">aspect-devel archives</a>.</p>\n</li>\n<li>\n<p>ASPECT is primarily\
    \ based on the deal.II library. If you have particular questions about deal.II,\
    \ contact the <a href=\"https://www.dealii.org/mail.html\" rel=\"nofollow\">deal.II\
    \ discussion groups</a>.</p>\n</li>\n<li>\n<p>In case of more general questions\
    \ about mantle convection, you can contact the <a href=\"http://lists.geodynamics.org/cgi-bin/mailman/listinfo/cig-MC\"\
    \ rel=\"nofollow\">CIG mantle convection mailing lists</a>.</p>\n</li>\n<li>\n\
    <p>ASPECT is being developed by a large, collaborative, and inclusive community.\
    \ It is currently maintained by the following people:</p>\n<ul>\n<li>Wolfgang\
    \ Bangerth: <a href=\"mailto:bangerth@math.colostate.edu\">bangerth@math.colostate.edu</a>\n\
    </li>\n<li>Juliane Dannberg: <a href=\"mailto:judannberg@gmail.com\">judannberg@gmail.com</a>\n\
    </li>\n<li>Rene Gassmoeller: <a href=\"mailto:rene.gassmoeller@mailbox.org\">rene.gassmoeller@mailbox.org</a>\n\
    </li>\n<li>Timo Heister: <a href=\"mailto:heister@clemson.edu\">heister@clemson.edu</a>\n\
    </li>\n</ul>\n</li>\n<li>\n<p>The following people have significantly contributed\
    \ and furthered ASPECT's goals and are therefore Principal Developers:</p>\n<ul>\n\
    <li>Jacky Austermann</li>\n<li>Wolfgang Bangerth</li>\n<li>Juliane Dannberg</li>\n\
    <li>Menno Fraters</li>\n<li>Rene Gassmoeller</li>\n<li>Anne Glerum</li>\n<li>Timo\
    \ Heister</li>\n<li>John Naliboff</li>\n</ul>\n</li>\n<li>\n<p>A complete and\
    \ growing list of the many authors that have contributed over the years can be\
    \ found at <a href=\"https://github.com/geodynamics/aspect/graphs/contributors\"\
    >github</a></p>\n</li>\n<li>\n<p>If you have specific questions about ASPECT that\
    \ are not suitable for public and archived mailing lists, feel free to contact\
    \ the maintainers or principal developers.</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-license\"\
    \ class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>ASPECT is published\
    \ under <a href=\"LICENSE\">GPL v2 or newer</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1590632076.0
haampie-spack/ci-example-2:
  data_format: 2
  description: trying to use spack in gh actions without docker images
  filenames:
  - tools/environments/ci/spack.yaml
  full_name: haampie-spack/ci-example-2
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    configuration files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1620232443.0
haampie/spack-batteries-included:
  data_format: 2
  description: Installing spack without system dependencies
  filenames:
  - build/5_runtime/spack.yaml
  - build/6_spack/spack.yaml
  - build/3_more_tools/spack.yaml
  - build/1_ccache/spack.yaml
  - build/2_compiler/spack.yaml
  full_name: haampie/spack-batteries-included
  latest_release: develop
  readme: "<p><a href=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml\"\
    ><img src=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\"\
    \ alt=\"Update spack develop version\" style=\"max-width:100%;\"></a></p>\n<h1>\n\
    <a id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\"\
    \ href=\"#-spack-with-batteries-included-linuxx86_64\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><g-emoji class=\"\
    g-emoji\" alias=\"battery\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png\"\
    >\U0001F50B</g-emoji> Spack with batteries included (linux/x86_64)</h1>\n<p><a\
    \ href=\"https://github.com/spack/spack\">Spack</a> is a package manager, and\
    \ package managers should be trivial to install.</p>\n<p>This repo offers a single,\
    \ static executable for Spack:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">wget -qO spack.x https://github.com/haampie/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n\
    $ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x\
    \ install zstd +programs <span class=\"pl-k\">~</span>shared build_type=Release</span></pre></div>\n\
    <h2>\n<a id=\"user-content-what-version-of-spack-is-shipped\" class=\"anchor\"\
    \ href=\"#what-version-of-spack-is-shipped\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>What version of Spack is shipped?</h2>\n\
    <p>The URL above gives you a rolling release of Spack's develop branch, which\
    \ is updated\nhourly. The exact commit SHA is included as a file and can be retrieved\
    \ like this:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$\
    \ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"pl-k\"\
    >&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints the\
    \ Spack commit sha]</span></pre></div>\n<h2>\n<a id=\"user-content-supported-platforms\"\
    \ class=\"anchor\" href=\"#supported-platforms\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Supported platforms</h2>\n<ul>\n\
    <li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n<li>Debian 8 and\
    \ above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and above</li>\n\
    <li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for Linux 2 with any\
    \ of the above distro's.</li>\n</ul>\n<p>The system dependencies are <code>glibc\
    \ 2.17</code> and above and optionally the <code>fusermount</code>\nexecutable.\
    \ If your system supports rootless containers it likely has <code>fusermount</code>\n\
    installed already!</p>\n<h2>\n<a id=\"user-content-how-does-it-work\" class=\"\
    anchor\" href=\"#how-does-it-work\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How does it work?</h2>\n<p><code>spack.x</code>\
    \ consists of a modified version of the AppImage runtime concatenated\nwith a\
    \ big squashfs file which includes <code>binutils</code>, <code>bzip2</code>,\
    \ <code>clingo</code>, <code>curl</code>,\n<code>file</code>, <code>git</code>,\
    \ <code>gmake</code>, <code>gpg</code>, <code>gzip</code>, <code>openssl</code>,\
    \ <code>patch</code>, <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>,\
    \ <code>tar</code>, <code>unzip</code>, <code>xz</code>, <code>zstd</code> and\
    \ their dependencies.</p>\n<p>When you run <code>spack.x [args]</code> it will\
    \ use <code>fusermount</code> to\nmount this squashfs file in a temporary directory,\
    \ and then execute the\nentrypoint executable <a href=\"build/6_spack/spack\"\
    >spack</a>.</p>\n<p>The <code>spack</code> executable sets some environment variables\
    \ like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code> to the bin and lib\
    \ folders of the squashfs file, and then it\nexecutes <code>python3 spack_src/bin/spack\
    \ [args]</code>.</p>\n<p>When the command is done running, the runtime unmounts\
    \ the squashfs file again.</p>\n<h2>\n<a id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    \ class=\"anchor\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>My system doesn't allow me to use <code>fusermount</code>, what now?</h2>\n\
    <p><code>fusermount</code> is used to mount a squashfs file included in the binary.\
    \ If you\ndon't want that, you can just extract it:</p>\n<pre><code>$ spack.x\
    \ --squashfs-extract\n$ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}]\
    \ COMMAND ...\n</code></pre>\n<p>but working with the extracted <code>spack</code>\
    \ folder can come with a performance\npenalty on shared filesystems in HPC centers.</p>\n\
    <h2>\n<a id=\"user-content-differences-and-improvements-over-appimage-runtime\"\
    \ class=\"anchor\" href=\"#differences-and-improvements-over-appimage-runtime\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Differences and improvements over AppImage runtime</h2>\n<ul>\n<li>spack.x\
    \ uses <code>zstd</code> for faster decompression;</li>\n<li>spack.x itself is\
    \ an entirely static binary;</li>\n<li>spack.x does not need to dlopen libfuse.so.</li>\n\
    </ul>\n<h2>\n<a id=\"user-content-troubleshooting\" class=\"anchor\" href=\"#troubleshooting\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Troubleshooting</h2>\n<p><strong>immutability</strong> The squashfs\
    \ mountpoint is a readonly folder, meaning that\nspack can't write to spack/{var,opt}\
    \ folders. spack.x is configured to use some\nnon-standard directories, see <code>spack.x\
    \ config blame config</code> for details.</p>\n<p>Note, spack.x applies <a href=\"\
    https://github.com/spack/spack/pull/20158/\">this patch</a>\nto ensure that log\
    \ files are written to the <code>config:misc_cache</code> folder.</p>\n<p><strong>openssl</strong>:\
    \ By default spack.x uses <code>ca-certificates-mozilla</code> for downloading\n\
    package sources over https. If you somehow need to use system certificates,\n\
    set <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAINFO</code> or <code>SSL_CERT_FILE</code>\
    \ and <code>GIT_SSL_CERT</code>.</p>\n<h2>\n<a id=\"user-content-can-i-run-spackx-inside-a-container\"\
    \ class=\"anchor\" href=\"#can-i-run-spackx-inside-a-container\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Can\
    \ I run spack.x inside a container?</h2>\n<p>Yes, but please don't! Since <code>fusermount</code>\
    \ is a setuid binary, you will need to\nrun a privileged container, which is never\
    \ a good idea.</p>\n<p>The recommended way to run spack.x inside a container is\
    \ to just extract it:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract</span>\n$ <span class=\"\
    pl-s1\">./spack/spack --version</span></pre></div>\n<p>If you insist on running\
    \ spack.x in Docker, this is one way to do it:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">sudo docker run --privileged --device /dev/fuse\
    \ -it -v <span class=\"pl-smi\">$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n\
    # <span class=\"pl-s1\">apt update <span class=\"pl-k\">&amp;&amp;</span> apt\
    \ install fuse <span class=\"pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n\
    # <span class=\"pl-s1\">spack.x --version</span></pre></div>\n<h2>\n<a id=\"user-content-running-an-executable-shipped-with-spackx-directly\"\
    \ class=\"anchor\" href=\"#running-an-executable-shipped-with-spackx-directly\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running an executable shipped with spack.x directly</h2>\n<p>If you\
    \ want to run an executable shipped with <code>spack.x</code> directly instead\n\
    of invoking spack (the default entrypoint), try this:</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x\
    \ which python</span>\n<span class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n\
    <hr>\n<h2>\n<a id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\"\
    \ href=\"#how-do-i-build-spackx-myself\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How do I build spack.x myself?</h2>\n\
    <p>Initially you may need docker to get a rootfs filesystem for centos 7.</p>\n\
    <p>Building goes like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">make rootfs-with-spack</span>\n<span class=\"pl-c1\"\
    >make</span></pre></div>\n<p>You'll find the output in</p>\n<pre><code>build/output\n\
    </code></pre>\n"
  stargazers_count: 8
  subscribers_count: 1
  topics:
  - spack
  - squashfs
  - libfuse
  updated_at: 1621575407.0
hariharan-devarajan/emacs:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: hariharan-devarajan/emacs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    configuration files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1620426207.0
hepnos/HEPnOS:
  data_format: 2
  description: HEPnOS is a distributed object store for high energy physics applications,
    developed at Argonne National Laboratory.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS
  latest_release: v0.4.2
  readme: '<h1>

    <a id="user-content-hepnos" class="anchor" href="#hepnos" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS</h1>

    <p>HEPnOS is the <em>High-Energy Physics''s new Object Store</em>, a distributed
    storage

    system specially designed for HEP experiments and workflows for the FermiLab.

    HEPnOS relies on libraries developed at Argonne National Laboratory within the

    context of the Mochi project (ANL, CMU, LANL, HDF Group).</p>

    <p>For information on copyright and licensing, see the COPYRIGHT file.

    For information on how to use, see the <a href="https://xgitlab.cels.anl.gov/sds/HEPnOS/wikis/home"
    rel="nofollow">wiki</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1617116230.0
hepnos/HEPnOS-PEP-Benchmark:
  data_format: 2
  description: Benchmark exercizing the ParallelEventProcessor feature of HEPnOS.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-PEP-Benchmark
  latest_release: null
  readme: '<h1>

    <a id="user-content-building" class="anchor" href="#building" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h1>

    <p>Setup spack and sds-repo, clone this repository and <code>cd</code> in it,
    then:</p>

    <pre><code>spack env create ssg-test spack.yaml

    spack env activate ssg-test

    spack install

    spack env deactivate

    </code></pre>

    <p>Then to build the code:</p>

    <pre><code>export CRAYPE_LINK_TYPE=dynamic

    module swap PrgEnv-intel PrgEnv-gnu

    module swap gcc/8.3.0 gcc/9.3.0

    spack env activate ssg-test

    mkdir build

    cd build

    cmake ..

    make

    </code></pre>

    <h1>

    <a id="user-content-running" class="anchor" href="#running" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running</h1>

    <p>From the <code>build</code> directory:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 128 ./test-server

    # one of the server will print "Credential: X", copy the X

    </code></pre>

    <p>In another terminal window, with current working directory set to <code>build</code>:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 1 ./test-client X # replace X with the copied value

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1613603490.0
icaoberg/singularity-octave:
  data_format: 2
  description: Singularity recipe for Octave
  filenames:
  - 6.2.0/spack.yaml
  full_name: icaoberg/singularity-octave
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-singularity-octave\" class=\"anchor\" href=\"\
    #singularity-octave\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>singularity-octave</h1>\n<p><a href=\"https://www.travis-ci.com/icaoberg/singularity-octave\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2ee2520b43fa597d24d8c42ccae9e2d15ea0e54a927d5b90207cde03bd895e9c/68747470733a2f2f7777772e7472617669732d63692e636f6d2f6963616f626572672f73696e67756c61726974792d6f63746176652e7376673f6272616e63683d6d61696e\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://www.travis-ci.com/icaoberg/singularity-octave.svg?branch=main\"\
    \ style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\"\
    \ alt=\"Octave\" data-canonical-src=\"https://www.gnu.org/software/octave/img/GNU_Octave_4-4-0_screenshot_1600x900.png\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>Singularity recipe for <a href=\"https://www.gnu.org/software/octave/\"\
    \ rel=\"nofollow\">octave</a>.</p>\n<h2>\n<a id=\"user-content-building-the-image-using-the-recipe\"\
    \ class=\"anchor\" href=\"#building-the-image-using-the-recipe\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ the image using the recipe</h2>\n<h3>\n<a id=\"user-content-to-build-the-image-locally\"\
    \ class=\"anchor\" href=\"#to-build-the-image-locally\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the\
    \ image locally</h3>\n<p>Run the script <code>build.sh</code> to build image locally.</p>\n\
    <pre><code>bash ./build.sh\n</code></pre>\n<h3>\n<a id=\"user-content-to-build-the-image-remotely\"\
    \ class=\"anchor\" href=\"#to-build-the-image-remotely\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build\
    \ the image remotely</h3>\n<p>Run the script <code>rbuild.sh</code> to build image\
    \ locally.</p>\n<pre><code>bash ./build.sh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-the-container-on-bridges-or-similar\"\
    \ class=\"anchor\" href=\"#installing-the-container-on-bridges-or-similar\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ the container on Bridges (or similar)</h2>\n<p>Copy the</p>\n<ul>\n<li>\n<code>SIF</code>\
    \ file</li>\n<li>and the <code>octave</code> and <code>octave-gui</code> scripts</li>\n\
    </ul>\n<p>to <code>/opt/packages/octave/6.2.0</code>.</p>\n<p>Copy the file <code>modulefile.lua</code>\
    \ to <code>/opt/modules/octave</code> as <code>6.2.0.lua</code>.</p>\n<hr>\n<p>Copyright\
    \ \xA9 2021 Pittsburgh Supercomputing Center. All Rights Reserved.</p>\n<p><a\
    \ href=\"http://www.andrew.cmu.edu/~icaoberg\" rel=\"nofollow\">icaoberg</a> at\
    \ the <a href=\"http://www.psc.edu\" rel=\"nofollow\">Pittsburgh Supercomputing\
    \ Center</a> in the <a href=\"https://www.cmu.edu/mcs/\" rel=\"nofollow\">Mellon\
    \ College of Science</a> at <a href=\"http://www.cmu.edu\" rel=\"nofollow\">Carnegie\
    \ Mellon University</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - singularity
  - octave
  - singularity-recipe
  updated_at: 1619522434.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/rhodes/base/spack.yaml
  - configs/eagle/compilers/spack.yaml
  - configs/rhodes/compilers/spack.yaml
  - configs/rhodes/software/spack.yaml
  - configs/eagle/base/spack.yaml
  - configs/eagle/utilities/spack.yaml
  - configs/eagle/software/spack.yaml
  - envs/exawind/spack.yaml
  - configs/rhodes/utilities/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    configuration files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1620946052.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack overlay repository of HEP software packaging.
  filenames:
  - environments/key4hep-nightlies/spack.yaml
  - environments/geant4-data-share/spack.yaml
  - environments/key4hep-release-broadwell/spack.yaml
  - environments/key4hep-release/spack.yaml
  - environments/key4hep-release-user/spack.yaml
  - environments/key4hep-nightlies-debug/spack.yaml
  - environments/key4hep-debug/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: 2021-02-25a-opt
  readme: '<h1>

    <a id="user-content-spack-package-repo-for-key4hep-software-packaging" class="anchor"
    href="#spack-package-repo-for-key4hep-software-packaging" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://github.com/spack/spack">Spack</a>
    package repo for Key4HEP software packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3>

    <a id="user-content-repository-contents" class="anchor" href="#repository-contents"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3>

    <a id="user-content-central-installations" class="anchor" href="#central-installations"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1621523159.0
le-raffael/AdaptiveTimeSteppingSEAS:
  data_format: 2
  description: null
  filenames:
  - tandem/submodules/yateto/tests/spack.yaml
  full_name: le-raffael/AdaptiveTimeSteppingSEAS
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-playground" class="anchor" href="#spack-playground"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-playground</h1>

    <h2>

    <a id="user-content-env" class="anchor" href="#env" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Env</h2>

    <div class="highlight highlight-source-shell"><pre>$ <span class="pl-c1">cd</span>
    /workspaces/spack-playground

    $ spack env create -d envs/dev

    $ spack env activate -p -d envs/dev

    $ spack external find</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1620773652.0
m-s-will/nyx:
  data_format: 2
  description: null
  filenames:
  - nyx/inputs/spack/spack.yaml
  full_name: m-s-will/nyx
  latest_release: null
  readme: '<h1>

    <a id="user-content-nyx-with-ascent-in-container" class="anchor" href="#nyx-with-ascent-in-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Nyx
    with Ascent in Container</h1>

    <p>This project contains a Dockerfile and all necessary components to create a
    Docker container for Nyx.

    The container is available on <a href="https://hub.docker.com/repository/docker/mswill/elwe_nyx"
    rel="nofollow">Dockerhub</a>, however these versions may not always be up to date.</p>

    <h2>

    <a id="user-content-building-the-container" class="anchor" href="#building-the-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h2>

    <p>The Ascent actions can be changed by editing <a href="https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml">ascent_actions.yaml</a>.

    When finished with the customization, the container can be rebuilt by navigating
    into the source directory and executing:</p>

    <pre><code>$ docker build -t &lt;mytag&gt; .

    </code></pre>

    <p>The Nyx simulation is being run during container creation and provides a Cinema
    database.</p>

    <h2>

    <a id="user-content-running-the-container" class="anchor" href="#running-the-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the container</h2>

    <p>After either pulling or building the container, it can be run by calling:</p>

    <pre><code>$ docker run -p 80:80 &lt;mytag&gt;.

    </code></pre>

    <p><code>-p 80:80</code> makes port 80 available on the outside which is needed
    for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code>
    in our browser.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1619477496.0
mdorier/test-ssg-cori:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: mdorier/test-ssg-cori
  latest_release: null
  readme: '<h1>

    <a id="user-content-building" class="anchor" href="#building" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h1>

    <p>Setup spack and sds-repo, clone this repository and <code>cd</code> in it,
    then:</p>

    <pre><code>spack env create ssg-test spack.yaml

    spack env activate ssg-test

    spack install

    spack env deactivate

    </code></pre>

    <p>Then to build the code:</p>

    <pre><code>export CRAYPE_LINK_TYPE=dynamic

    module swap PrgEnv-intel PrgEnv-gnu

    module swap gcc/8.3.0 gcc/9.3.0

    spack env activate ssg-test

    mkdir build

    cd build

    cmake ..

    make

    </code></pre>

    <h1>

    <a id="user-content-running" class="anchor" href="#running" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running</h1>

    <p>From the <code>build</code> directory:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 128 ./test-server

    # one of the server will print "Credential: X", copy the X

    </code></pre>

    <p>In another terminal window, with current working directory set to <code>build</code>:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 1 ./test-client X # replace X with the copied value

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1614204735.0
mochi-hpc/margo-microservice-template:
  data_format: 2
  description: Template for a margo-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/margo-microservice-template
  latest_release: null
  readme: '<h1>

    <a id="user-content-margo-microservice-template" class="anchor" href="#margo-microservice-template"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Margo
    Microservice Template</h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Margo.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/01_margo.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1614210543.0
mochi-hpc/mobject:
  data_format: 2
  description: Mobject is a prototype Mochi object storage system based on RADOS
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mobject
  latest_release: v0.5
  readme: ''
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1621277137.0
mochi-hpc/mochi-bake:
  data_format: 2
  description: A microservice (i.e., Mochi provider) for high performance bulk storage
    of raw data regions
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bake
  latest_release: v0.6.3
  readme: "<h1>\n<a id=\"user-content-bake\" class=\"anchor\" href=\"#bake\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bake</h1>\n\
    <p>Bake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage\
    \ of raw data regions.  Bake uses modular backends to store data\non persistent\
    \ memory, conventional file systems, or other storage media.</p>\n<p>See <a href=\"\
    https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a>\
    \ and\n<a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a>\
    \ for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively\
    \ to data storage.  Capabilities such as\nindexing, name spaces, and sharding\
    \ must be provided by other microservice\ncomponents.</p>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The easiest\
    \ way to install Bake is through spack:</p>\n<p><code>spack install bake</code></p>\n\
    <p>This will install BAKE and its dependencies.  Please refer to the end of the\n\
    document for manual compilation instructions.</p>\n<h2>\n<a id=\"user-content-architecture\"\
    \ class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>Like most\
    \ Mochi services, BAKE relies on a client/provider architecture.\nA provider,\
    \ identified by its <em>address</em> and <em>multiplex id</em>, manages one or\
    \ more\n<em>BAKE targets</em>, referenced externally by their <em>target id</em>.</p>\n\
    <p>A target can be thought of as a storage device.  This may be (for example)\
    \ a\nPMDK volume or a local file system.</p>\n<h2>\n<a id=\"user-content-setting-up-a-bake-target\"\
    \ class=\"anchor\" href=\"#setting-up-a-bake-target\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up a\
    \ BAKE target</h2>\n<p>BAKE requires the backend storage file to be created beforehand\
    \ using\n<code>bake-mkpool</code>. For instance:</p>\n<p><code>bake-mkpool -s\
    \ 500M /dev/shm/foo.dat</code></p>\n<p>creates a 500 MB file at <em>/dev/shm/foo.dat</em>\
    \ to be used by BAKE as a target.\nBake will use the <code>pmem</code> (persistent\
    \ memory) backend by default, which means\nthat the underlying file will memory\
    \ mapped for access usign the PMDK\nlibrary.  You can also providie an explicit\
    \ prefix (such as <code>file:</code> for the\nconventional file backend or <code>pmem:</code>\
    \ for the persistent memory backend) to\ndictate a specific target type.</p>\n\
    <h2>\n<a id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Starting a daemon</h2>\n<p>BAKE ships with a default daemon program\
    \ that can setup providers and attach\nto storage targets. This daemon can be\
    \ started as follows:</p>\n<p><code>bake-server-daemon [options] &lt;listen_address&gt;\
    \ &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n<p>The program takes\
    \ a set of options followed by an address at which to listen for\nincoming RPCs,\
    \ and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n\
    <p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234\
    \ /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n\
    <ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the\
    \ address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em>\
    \ or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates\
    \ that, if multiple BAKE targets are used (as above),\nthese targets should be\
    \ managed by multiple providers, accessible through\ndifferent multiplex ids 1,\
    \ 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage.\
    \ The <em>targets</em> mode indicates that a single provider should be used to\n\
    manage all the storage targets.</p>\n<h2>\n<a id=\"user-content-integrating-bake-into-a-larger-service\"\
    \ class=\"anchor\" href=\"#integrating-bake-into-a-larger-service\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Integrating\
    \ Bake into a larger service</h2>\n<p>Bake is not intended to be a standalone\
    \ user-facing service.  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\"\
    \ rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for\
    \ guidance on how to\nintegrate it with other providers using Mochi's Bedrock\
    \ capability.</p>\n<h2>\n<a id=\"user-content-client-api-example\" class=\"anchor\"\
    \ href=\"#client-api-example\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Client API example</h2>\n<p>Data is\
    \ stored in <code>regions</code> within a <code>target</code> using explicit create,\n\
    write, and persist operations.  The caller cannot dictate the region id\nthat\
    \ will be used to reference a region; this identifier is generated\nby Bake at\
    \ creation time.  The region size must be specified at creation\ntime as well;\
    \ there is no mechanism for extending the size of an existing\nregion.</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>bake-client.h<span class=\"\
    pl-pds\">&gt;</span></span>\n\n<span class=\"pl-k\">int</span> <span class=\"\
    pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\"\
    >char</span> **argv)\n{\n    <span class=\"pl-k\">char</span> *svr_addr_str; <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> string address of the BAKE server</span>\n\
    \    <span class=\"pl-c1\">hg_addr_t</span> svr_addr; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Mercury address of the BAKE server</span>\n    margo_instance_id\
    \ mid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> Margo instance id</span>\n\
    \    <span class=\"pl-c1\">bake_client_t</span> bcl; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> BAKE client</span>\n    <span class=\"pl-c1\">bake_provider_handle_t</span>\
    \ bph; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE handle to provider</span>\n\
    \    <span class=\"pl-c1\">uint8_t</span> mplex_id; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> multiplex id of the provider</span>\n    <span class=\"\
    pl-c1\">uint32_t</span> target_number; <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> target to use</span>\n    <span class=\"pl-c1\">bake_region_id_t</span>\
    \ rid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE region id handle</span>\n\
    \t<span class=\"pl-c1\">bake_target_id_t</span>* bti; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> array of target ids</span>\n\n\t<span class=\"pl-c\"\
    ><span class=\"pl-c\">/*</span> ... setup variables ... <span class=\"pl-c\">*/</span></span>\n\
    \n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Initialize Margo <span\
    \ class=\"pl-c\">*/</span></span>\n\tmid = <span class=\"pl-c1\">margo_init</span>(...,\
    \ MARGO_CLIENT_MODE, <span class=\"pl-c1\">0</span>, -<span class=\"pl-c1\">1</span>);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Lookup the server <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_lookup</span>(mid,\
    \ svr_addr_str, &amp;svr_addr);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span>\
    \ Creates the BAKE client <span class=\"pl-c\">*/</span></span>\n\t<span class=\"\
    pl-c1\">bake_client_init</span>(mid, &amp;bcl);\n\t<span class=\"pl-c\"><span\
    \ class=\"pl-c\">/*</span> Creates the provider handle <span class=\"pl-c\">*/</span></span>\n\
    \t<span class=\"pl-c1\">bake_provider_handle_create</span>(bcl, svr_addr, mplex_id,\
    \ &amp;bph);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Asks the provider\
    \ for up to target_number target ids <span class=\"pl-c\">*/</span></span>\n\t\
    <span class=\"pl-c1\">uint32_t</span> num_targets = <span class=\"pl-c1\">0</span>;\n\
    \tbti = <span class=\"pl-c1\">calloc</span>(num_targets, <span class=\"pl-k\"\
    >sizeof</span>(*bti));\n\t<span class=\"pl-c1\">bake_probe</span>(bph, target_number,\
    \ bti, &amp;num_targets);\n\t<span class=\"pl-k\">if</span>(num_targets &lt; target_number)\
    \ {\n\t\t<span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>Error: provider has only <span class=\"pl-c1\">%d</span>\
    \ storage targets<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>,\
    \ num_targets);\n\t}\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Create\
    \ a region <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">size_t</span>\
    \ size = ...; <span class=\"pl-c\"><span class=\"pl-c\">//</span> size of the\
    \ region to create</span>\n\t<span class=\"pl-c1\">bake_create</span>(bph, bti[target_number-<span\
    \ class=\"pl-c1\">1</span>], size, &amp;rid);\n\t<span class=\"pl-c\"><span class=\"\
    pl-c\">/*</span> Write data into the region at offset 0 <span class=\"pl-c\">*/</span></span>\n\
    \t<span class=\"pl-k\">char</span>* buf = ...;\n\t<span class=\"pl-c1\">bake_write</span>(bph,\
    \ rid, <span class=\"pl-c1\">0</span>, buf, size);\n\t<span class=\"pl-c\"><span\
    \ class=\"pl-c\">/*</span> Make all modifications persistent <span class=\"pl-c\"\
    >*/</span></span>\n\t<span class=\"pl-c1\">bake_persist</span>(bph, rid);\n\t\
    <span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release provider handle <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_provider_handle_release</span>(bph);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release BAKE client <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_client_finalize</span>(bcl);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Cleanup Margo resources\
    \ <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_free</span>(mid,\
    \ svr_addr);\n\t<span class=\"pl-c1\">margo_finalize</span>(mid);\n\t<span class=\"\
    pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n<p>Note that\
    \ a <code>bake_region_id_t</code> object is persistent.  It can be written\n(into\
    \ a file or a socket) and stored or sent to another program. These\nregion ids\
    \ are what uniquely reference a region within a given target.</p>\n<p>The rest\
    \ of the client-side API can be found in <code>bake-client.h</code>.</p>\n<h2>\n\
    <a id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider\
    \ API</h2>\n<p>The bake-server-daemon source is a good example of how to create\
    \ providers and\nattach storage targets to them. The provider-side API is located\
    \ in\n<em>bake-server.h</em>, and consists of mainly two functions:</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">bake_provider_register</span>(margo_instance_id      \
    \               mid,\n                           <span class=\"pl-c1\">uint16_t</span>\
    \                              provider_id,\n                           <span\
    \ class=\"pl-k\">const</span> <span class=\"pl-k\">struct</span> bake_provider_init_info*\
    \ args,\n                           <span class=\"pl-c1\">bake_provider_t</span>*\
    \                      provider);</pre></div>\n<p>This creates a provider at the\
    \ given provider id using the specified margo\ninstance.  The <code>args</code>\
    \ parameter can be used to modify default settings,\nincluding passing in a fully\
    \ specified json configuration block.  See\n<code>bake-server.h</code> for details.</p>\n\
    <div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">bake_provider_attach_target</span>(<span class=\"pl-c1\"\
    >bake_provider_t</span>   provider,\n                                <span class=\"\
    pl-k\">const</span> <span class=\"pl-k\">char</span>*       target_name,\n   \
    \                             <span class=\"pl-c1\">bake_target_id_t</span>* target_id);</pre></div>\n\
    <p>This makes the provider manage the given storage target.</p>\n<p>Other functions\
    \ are available to create and detach targets from a provider.</p>\n<h2>\n<a id=\"\
    user-content-generic-bake-benchmark\" class=\"anchor\" href=\"#generic-bake-benchmark\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Generic Bake benchmark</h2>\n<p>By using <code>--enable-benchmark</code>\
    \ when compiling Bake (or <code>+benchmark</code> when using Spack),\nyou will\
    \ build a <code>bake-benchmark</code> program that can be used as a configurable\
    \ benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure\
    \ Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n<p>The benchmark\
    \ is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a\
    \ server, while non-zero ranks act as clients. The server will not create\na Bake\
    \ target. The Bake target needs to be created (with <code>bake-makepool</code>)\
    \ beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing\
    \ the sequence\nof benchmarks to execute. An example of such a file is located\
    \ in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code>\
    \ array corresponds to a benchmark. The <code>type</code> field indicates\nthe\
    \ type of benchmark to execute. The <code>repetitions</code> field indicates how\
    \ many times the\nbenchmark should be repeated.</p>\n<p>The following table describes\
    \ each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n\
    <th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n\
    </tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to\
    \ the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n\
    <td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for\
    \ each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n\
    <td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's\
    \ buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n\
    <td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n\
    <td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions,\
    \ or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether\
    \ to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n\
    </tbody>\n</table>\n<h2>\n<a id=\"user-content-manual-installation\" class=\"\
    anchor\" href=\"#manual-installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manual installation</h2>\n<p>BAKE\
    \ depends on the following libraries:</p>\n<ul>\n<li>uuid (install uuid-dev package\
    \ on ubuntu)</li>\n<li>PMDK (see instructions below)</li>\n<li>json-c</li>\n<li>mochi-abt-io</li>\n\
    <li>mochi-margo</li>\n</ul>\n<p>Bake will automatically identify these dependencies\
    \ at configure time using\npkg-config. To compile BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n\
    <li><code>mkdir build</code></li>\n<li><code>cd build</code></li>\n<li><code>../configure\
    \ --prefix=/home/carns/working/install</code></li>\n<li><code>make</code></li>\n\
    </ul>\n<p>If any dependencies are installed in a nonstandard location, then\n\
    modify the configure step listed above to include the following argument:</p>\n\
    <ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1620945435.0
mochi-hpc/mochi-bedrock:
  data_format: 2
  description: Mochi bootstrapping service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bedrock
  latest_release: v0.3
  readme: '<h1>

    <a id="user-content-bedrock" class="anchor" href="#bedrock" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bedrock</h1>

    <p>Bedrock is Mochi''s service bootstrapping mechanism.

    For documentations and tutorials, please see

    <a href="https://mochi.readthedocs.io/en/latest/bedrock.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1620916986.0
mochi-hpc/mochi-colza:
  data_format: 2
  description: Mochi-based staging service for in situ analysis and visualization
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-colza
  latest_release: v0.1
  readme: ''
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1617665054.0
mochi-hpc/mochi-doc:
  data_format: 2
  description: Documentations and tutorials for Margo, Thallium, Argobots, Mercury,
    and other Mochi libraries.
  filenames:
  - code/spack.yaml
  full_name: mochi-hpc/mochi-doc
  latest_release: null
  readme: '<h1>

    <a id="user-content-mochi-documentation" class="anchor" href="#mochi-documentation"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    documentation</h1>

    <p>This repository contains a Sphinx-based documentation

    for the Mochi libraries: Margo, Thallium, Argobots, Mercury,

    ABT-IO, and SSG, as well as corresponding code examples.</p>

    <h2>

    <a id="user-content-building-the-documentation" class="anchor" href="#building-the-documentation"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the documentation</h2>

    <p>To build and/orcontribute to this documentation, make sure

    that you have Sphinx installed as well as the ReadTheDoc theme.

    These can be installed as follows using Python''s <code>pip</code>.</p>

    <pre><code>pip install sphinx

    pip install sphinx_rtd_theme

    </code></pre>

    <p>Once you have these dependencies installed, clone this

    repository and cd into it. You can change the documentation

    by editing the files in the source subdirectory (these files

    use the .rst format). You can build the documentation

    using the following command.</p>

    <pre><code>cd docs

    make html

    </code></pre>

    <p>And check the result by opening the <code>build/index.html</code> page

    that has been created in the docs directory.</p>

    <h2>

    <a id="user-content-building-the-code-examples" class="anchor" href="#building-the-code-examples"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the code examples</h2>

    <p>To build the code, you will need spack and the

    <a href="https://xgitlab.cels.anl.gov/sds/sds-repo" rel="nofollow">sds-repo</a>
    setup.</p>

    <pre><code>cd code

    spack env create mochi-doc-env spack.yaml

    spack env activate mochi-doc-env

    spack install

    mkdir build

    cd build

    cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc

    make

    </code></pre>

    '
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1621119976.0
mochi-hpc/mochi-margo:
  data_format: 2
  description: Argobots bindings for the Mercury RPC library
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-margo
  latest_release: v0.9.4
  readme: "<h1>\n<a id=\"user-content-margo\" class=\"anchor\" href=\"#margo\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n\
    <p><a href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ alt=\"\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings\
    \ to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\"\
    \ rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\n\
    library optimized for use in HPC environments.  Its native API presents a\ncallback-oriented\
    \ interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\"\
    \ rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n\
    <p>Margo combines Mercury and Argobots to simplify development of distributed\n\
    services.  Mercury operations are presented as conventional blocking\noperations,\
    \ and RPC handlers are presented as sequential threads.  This\nconfiguration enables\
    \ high degree of concurrency while hiding the\ncomplexity associated with asynchronous\
    \ communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends\
    \ callers after issuing a Mercury operation, and\nautomatically resumes them when\
    \ the operation completes.  This allows\nother concurrent user-level threads to\
    \ make progress while Mercury\noperations are in flight without consuming operating\
    \ system threads.\nThe goal of this design is to combine the performance advantages\
    \ of\nMercury's native event-driven execution model with the progamming\nsimplicity\
    \ of a multi-threaded execution model.</p>\n<p>A companion library called abt-io\
    \ provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\"\
    >https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should\
    \ be compatible with any Mercury network\ntransport (NA plugin).  The documentation\
    \ assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury\
    \ for\nsimplicity.  This plugin is only valid for communication between\nprocesses\
    \ on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\"\
    >Using Margo with other Mercury NA\nplugins</a> for information\non other configuration\
    \ options.</p>\n<h2>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing\
    \ the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"\
    nofollow\">https://spack.io/</a>).</p>\n<h2>\n<a id=\"user-content-dependencies\"\
    \ class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury\
    \  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\"\
    >https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone\
    \ <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n\
    </ul>\n<h3>\n<a id=\"user-content-recommended-mercury-build-options\" class=\"\
    anchor\" href=\"#recommended-mercury-build-options\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury\
    \ build options</h3>\n<ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON\
    \ to enable the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should\
    \ be compiled with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast\
    \ execution path for cases in which a Mercury service is linked into the same\n\
    executable as the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir\
    \ build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON\
    \ -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install\
    \ \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n\
    <h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n\
    <p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install\
    \ \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"\
    -g -Wall\"\n</code></pre>\n<h2>\n<a id=\"user-content-running-examples\" class=\"\
    anchor\" href=\"#running-examples\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The\
    \ examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example\
    \ client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]:\
    \ an example RPC definition</li>\n</ul>\n<p>The following example shows how to\
    \ execute them.  Note that when the server starts it will display the address\
    \ that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server\
    \ na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with\
    \ input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val:\
    \ 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client\
    \ na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3]\
    \ running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\n\
    Got response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n\
    <p>The client will issue 4 concurrent RPCs to the server and wait for them to\n\
    complete.</p>\n<h2>\n<a id=\"user-content-running-tests\" class=\"anchor\" href=\"\
    #running-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Running tests</h2>\n<p><code>make check</code></p>\n\
    <h2>\n<a id=\"user-content-using-margo-with-the-other-na-plugins\" class=\"anchor\"\
    \ href=\"#using-margo-with-the-other-na-plugins\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using Margo with the other NA\
    \ plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\"\
    \ rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible\
    \ with any Mercury transport and uses the same address\nformat.</p>\n<h2>\n<a\
    \ id=\"user-content-instrumentation\" class=\"anchor\" href=\"#instrumentation\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Instrumentation</h2>\n<p>See the <a href=\"doc/instrumentation.md\"\
    >Instrumentation documentation</a> for\ninformation on how to extract diagnostic\
    \ instrumentation from Margo.</p>\n<h2>\n<a id=\"user-content-debugging\" class=\"\
    anchor\" href=\"#debugging\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Debugging</h2>\n<p>See the <a href=\"doc/debugging.md\"\
    >Debugging documentation</a> for Margo debugging\nfeatures and strategies.</p>\n\
    <h2>\n<a id=\"user-content-design-details\" class=\"anchor\" href=\"#design-details\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Design details</h2>\n<p><a href=\"doc/fig/margo-diagram.png\" target=\"\
    _blank\" rel=\"noopener noreferrer\"><img src=\"doc/fig/margo-diagram.png\" alt=\"\
    Margo architecture\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware\
    \ wrappers to common Mercury library functions\nlike HG_Forward(), HG_Addr_lookup(),\
    \ and HG_Bulk_transfer().  The wrappers\nhave the same arguments as their native\
    \ Mercury counterparts except that no\ncallback function is specified.  Each function\
    \ blocks until the operation\nis complete.  The above diagram illustrates a typical\
    \ control flow.</p>\n<p>Margo launches a long-running user-level thread internally\
    \ to drive\nprogress on Mercury and execute Mercury callback functions (labeled\n\
    <code>__margo_progress()</code> above).  This thread can be assigned to a\ndedicated\
    \ Argobots execution stream (i.e., an operating system thread)\nto drive network\
    \ progress with a dedicated core.  Otherwise it will be\nautomatically scheduled\
    \ when the caller's execution stream is blocked\nwaiting for network events as\
    \ shown in the above diagram.</p>\n<p>Argobots eventual constructs are used to\
    \ suspend and resume user-level\nthreads while Mercury operations are in flight.</p>\n\
    <p>Margo allows several different threading/multicore configurations:</p>\n<ul>\n\
    <li>The progress loop can run on a dedicated operating system thread or not</li>\n\
    <li>Multiple Margo instances (and thus progress loops) can be\nexecuted on different\
    \ operating system threads</li>\n<li>(for servers) a single Margo instance can\
    \ launch RPC handlers\non different operating system threads</li>\n</ul>\n"
  stargazers_count: 7
  subscribers_count: 7
  topics: []
  updated_at: 1621616859.0
mochi-hpc/mochi-remi:
  data_format: 2
  description: Mochi's REsource Migration Interface
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-remi
  latest_release: null
  readme: '<h1>

    <a id="user-content-resource-migration-interface" class="anchor" href="#resource-migration-interface"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>REsource
    Migration Interface</h1>

    <p>REMI is a Mochi microservice designed to handle the migration of sets of files

    from a node to another. It uses RDMA and memory mapping to efficiently transfer

    potentially large groups of files at once.</p>

    <h3>

    <a id="user-content-installing" class="anchor" href="#installing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>Just like all Mochi services, REMI can be installed using Spack. Once you have

    clone the <a href="https://xgitlab.cels.anl.gov/sds/sds-repo" rel="nofollow">sds-repo</a>
    package repository

    and added it to your spack installation, you can install REMI using the following

    command:</p>

    <pre><code>spack install mochi-remi

    </code></pre>

    <p>REMI depends on <a href="https://xgitlab.cels.anl.gov/sds/thallium/" rel="nofollow">Thallium</a>,
    which

    Spack will install (if needed) along with Thallium''s own dependencies. It also

    depends on Bedrock, unless the <code>bedrock</code> variant is disable when installing

    with Spack (i.e. passing <code>~bedrock</code> to the above command).</p>

    <h3>

    <a id="user-content-overview" class="anchor" href="#overview" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h3>

    <p>REMI works with <em>filesets</em>. A fileset consists of a root directory and

    a set of file paths relative to this root directory. A fileset is also characterized

    by the name of its <em>migration class</em>.</p>

    <p>REMI clients create filesets to group files corresponding to a particular resource

    (e.g. a database''s files). They can then request the migration of fileset to

    a target provider.</p>

    <p>Uppon receiving a request for migration, a provider will recreate the tree
    of

    directories required to receive the files of the fileset, create the files,

    mmap them into memory, and issue an RDMA pull operation from the client''s files

    (themselves mmap-ed into the client''s memory).</p>

    <p>Following successful migration, the provider will call a user-supplied callback

    corresponding to the particular fileset''s migration class.</p>

    <p>For an example of code, please see the <a href="examples">examples</a>

    folder in the source tree.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1614271878.0
mochi-hpc/mochi-sdskv:
  data_format: 2
  description: simple margo-projected keyval service
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-sdskv
  latest_release: v0.1.13
  readme: "<h1>\n<a id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" href=\"\
    #sdskv-sds-keyval\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>SDSKV (SDS Key/Val)</h1>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>SDSKV can\
    \ easily be installed using Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n\
    <p>This will install SDSKV (and any required dependencies).\nAvailable backends\
    \ will be <em>Map</em> (in-memory C++ std::map, useful for testing)\nand BwTree\
    \ (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code>\
    \ and <code>+leveldb</code> respectively. For example:</p>\n<p><code>spack install\
    \ sdskeyval+bdb+leveldb</code></p>\n<p>Note that if you are using a system boost\
    \ path in spack (in your\npackages.yaml) rather than letting spack build boost,\
    \ then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages\
    \ on\nyour system.</p>\n<h2>\n<a id=\"user-content-architecture\" class=\"anchor\"\
    \ href=\"#architecture\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Architecture</h2>\n<p>List most mochi services,\
    \ SDSKV relies on a client/provider architecture.\nA provider, identified by its\
    \ <em>address</em> and <em>multiplex id</em>, manages one or more\ndatabases,\
    \ referenced externally by their database id.</p>\n<h2>\n<a id=\"user-content-starting-a-daemon\"\
    \ class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>SDSKV\
    \ ships with a default daemon program that can setup providers and\ndatabases.\
    \ This daemon can be started as follows:</p>\n<p><code>sdskv-server-daemon [OPTIONS]\
    \ &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb] &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb]\
    \ ...</code></p>\n<p>For example:</p>\n<p><code>sdskv-server-daemon tcp://localhost:1234\
    \ foo:bdb bar</code></p>\n<p>listen_addr is the address at which to listen; database\
    \ names should be provided in the form\n<em>name:type</em> where <em>type</em>\
    \ is <em>map</em> (std::map), <em>bwt</em> (BwTree), <em>bdb</em> (Berkeley DB),\
    \ or <em>ldb</em> (LevelDB).</p>\n<p>For database that are persistent like BerkeleyDB\
    \ or LevelDB, the name should be a path to the\nfile where the database will be\
    \ put (this file should not exist).</p>\n<p>The following additional options are\
    \ accepted:</p>\n<ul>\n<li>\n<code>-f</code> provides the name of the file in\
    \ which to write the address of the daemon.</li>\n<li>\n<code>-m</code> provides\
    \ the mode (providers or databases).</li>\n</ul>\n<p>The providers mode indicates\
    \ that, if multiple SDSKV databases are used (as above),\nthese databases should\
    \ be managed by multiple providers, accessible through\ndifferent multiplex ids\
    \ 1, 2, ... N where N is the number of databases\nto manage. The targets mode\
    \ indicates that a single provider should be used to\nmanage all the databases.\
    \ This provider will be accessible at multiplex id 1.</p>\n<h2>\n<a id=\"user-content-client-api\"\
    \ class=\"anchor\" href=\"#client-api\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Client API</h2>\n<p>The client\
    \ API is available in <em>sdskv-client.h</em>.\nThe codes in the <em>test</em>\
    \ folder illustrate how to use it.</p>\n<h2>\n<a id=\"user-content-provider-api\"\
    \ class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Provider API</h2>\n<p>The server-side\
    \ API is available in <em>sdskv-server.h</em>.\nThe code of the daemon (<em>src/sdskv-server-daemon.c</em>)\
    \ can be used as an example.</p>\n<h3>\n<a id=\"user-content-custom-key-comparison-function\"\
    \ class=\"anchor\" href=\"#custom-key-comparison-function\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Custom key\
    \ comparison function</h3>\n<p>It is possible to specify a custom function for\
    \ comparing/sorting keys\nwhen creating a provider. A comparison function must\
    \ have the following prototype:</p>\n<p><code>int (*)(const void* key1, size_t\
    \ keysize1, const void* key2, size_t keysize2)</code></p>\n<p>Its return value\
    \ must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0 if key1 &gt; key2.\n\
    It must define a total order of the key space.</p>\n<h2>\n<a id=\"user-content-c-api\"\
    \ class=\"anchor\" href=\"#c-api\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>C++ API</h2>\n<p>An object-oriented\
    \ C++ API is available in <code>sdskv-client.hpp</code> and <code>sdskv-server.hpp</code>.\n\
    On the client side this API provides the <code>client</code>, <code>provider_handle</code>,\
    \ and <code>database</code> objects.\nExamples of usage of these objects can be\
    \ found in the <code>test/sdskv-cxx-test.cc</code>.\nOn the server side, this\
    \ API provides a <code>provider</code> object.</p>\n<h2>\n<a id=\"user-content-benchmark\"\
    \ class=\"anchor\" href=\"#benchmark\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Benchmark</h2>\n<p>SDSKV can\
    \ be compiled with <code>--enable-benchmark</code> (or <code>+benchmark</code>\
    \ in Spack). In this case,\nSDSKV requires the JsonCPP and MPI dependencies (when\
    \ compiling manually, use <code>CXX=mpicxx</code> in\nyour configure step, for\
    \ example), and it will build and install the <code>sdskv-benchmark</code> program.</p>\n\
    <p>This program is an MPI program that reads a JSON file describing a series of\
    \ access patterns.\nRank 0 of this MPI program acts as an SDSKV server. Other\
    \ ranks act as clients, all executing\nthis access pattern.</p>\n<p>The following\
    \ is an example of a JSON file.</p>\n<div class=\"highlight highlight-source-json\"\
    ><pre>{\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>protocol<span\
    \ class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>seed<span class=\"pl-pds\">\"</span></span> :\
    \ <span class=\"pl-c1\">0</span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>server<span class=\"pl-pds\">\"</span></span> : {\n\t\t<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>use-progress-thread<span class=\"pl-pds\"\
    >\"</span></span> : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>rpc-thread-count<span class=\"pl-pds\">\"</span></span>\
    \ : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>database<span class=\"pl-pds\">\"</span></span> : {\n\t\t\t<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span>\
    \ : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\"\
    >\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span\
    \ class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>path<span class=\"pl-pds\">\"</span></span>\
    \ : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/dev/shm<span class=\"\
    pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>benchmarks<span class=\"pl-pds\">\"</span></span> : [\n\t{\n\
    \t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\"\
    >\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span\
    \ class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"\
    pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span\
    \ class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\"\
    >\"</span></span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span>\
    \ ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span\
    \ class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">24</span>, <span\
    \ class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"\
    pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>get<span class=\"pl-pds\">\"</span></span>,\n\t\t\
    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"\
    pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span>\
    \ : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"\
    pl-c1\">64</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span\
    \ class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">128</span>,\n\t\t\
    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"\
    pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n\
    <p>The JSON file starts with the protocol to use, and a seed for the random-number\
    \ generator (RNG).\nThe actual seed used on each rank will actually be a function\
    \ of this global seed and the rank of\nthe client. The RNG will be reset with\
    \ this seed after each benchmark.</p>\n<p>The <code>server</code> field sets up\
    \ the provider and the database. Database types can be <code>map</code>, <code>ldb</code>,\
    \ or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which\
    \ is a list of benchmarks to execute. Each benchmark is composed\nof three steps.\
    \ A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em>\
    \ phase. The setup phase may for\nexample store a bunch of keys in the database\
    \ that the execution phase will read by (in the case of a\n<em>get</em> benchmark,\
    \ for example). The teardown phase will usually remove all the keys that were\
    \ written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n\
    <p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>,\
    \ <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n\
    <code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>),\
    \ and a number of repetitions. The benchmark will be\nexecuted as many times as\
    \ requested (without resetting the RNG in between repetitions). Taking the\nexample\
    \ of the <code>put</code> benchmark above, each repetition will put 30 key/value\
    \ pairs into the database.\nThe key size will be chosen randomly in a uniform\
    \ manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size\
    \ will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded).\
    \ Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI\
    \ barrier between clients is executed in between each benchmark and in between\
    \ the setup,\nexecution, and teardown phases, so that the execution phase is always\
    \ executed at the same time\non all the clients. Once all the repetitions are\
    \ done for a given benchmark entry, the program\nwill report statistics on the\
    \ timings: average time, variance, standard deviation, mininum, maximum,\nmedian,\
    \ first and third quartiles. Note that these times are for a repetition, not for\
    \ single operations\nwithin a repetition. To get the timing of each individual\
    \ operation, it is then necessary to divide\nthe times by the number of key/value\
    \ pairs involved in the benchmark.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1620851629.0
mochi-hpc/mochi-sonata:
  data_format: 2
  description: Sonata is a Mochi service for JSON document storage. It is based on
    UnQLite and Thallium.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-sonata
  latest_release: v0.6.2
  readme: '<h1>

    <a id="user-content-what-is-sonata" class="anchor" href="#what-is-sonata" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>What is Sonata?</h1>

    <p>Sonata is a remotely-accessibl JSON document store based on UnQLite and on

    the Mochi suit of libraries. It enables managing collections of JSON records,

    searching through them, and running Jx9 scripts on them.</p>

    <h1>

    <a id="user-content-got-some-examples" class="anchor" href="#got-some-examples"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Got
    some examples?</h1>

    <p>A comprehensive set of examples is available in <a href="examples">this directory</a>.</p>

    <h1>

    <a id="user-content-how-do-i-install-sonata" class="anchor" href="#how-do-i-install-sonata"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How
    do I install Sonata?</h1>

    <p>The easiest way to install Sonata is to use <a href="https://spack.readthedocs.io"
    rel="nofollow">spack</a>.

    Once you have spack installed and setup on your machine, you need to added the

    mochi namespace to it, as follows.</p>

    <pre><code>git clone https://xgitlab.cels.anl.gov/sds/sds-repo.git

    spack repo add sds-repo

    </code></pre>

    <p>You can now install Sonata as follows.</p>

    <pre><code>spack install mochi-sonata

    </code></pre>

    <h1>

    <a id="user-content-and-then" class="anchor" href="#and-then" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>And then?</h1>

    <p>Sonata comes in three libraries: sonata-server, sonata-client, and sonata-admin.

    The server library contains the <code>sonata::Provider</code> class, which allows
    to start

    a Sonata service on a server program. The admin library contains the

    <code>sonata::Admin</code> class, which enables creating and destroying database
    on a

    running provider. The <code>sonata::Client</code> class is contained in the client
    library.

    This class provides the main interface to open a database, and manipulat

    collections.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1619728396.0
mochi-hpc/py-mochi-bedrock:
  data_format: 2
  description: Python interface for Mochi's Bedrock service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-bedrock
  latest_release: v0.1
  readme: '<h1>

    <a id="user-content-py-bedrock" class="anchor" href="#py-bedrock" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Py-Bedrock</h1>

    <p>Py-Bedrock providers Python utilities to configure and deploy Mochi-based

    services using Python.</p>

    <h2>

    <a id="user-content-running-the-jupyter-demo" class="anchor" href="#running-the-jupyter-demo"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Jupyter demo</h2>

    <p>Create a spack environment and add the required packages in it.</p>

    <pre><code>spack env create py-bedrock-demo

    spack env activate py-bedrock-demo

    spack add py-mochi-bedrock

    spack add py-jupyterlab-server

    spack install

    </code></pre>

    <p>Deactivate and re-activate the environment for the PYTHONPATH variable to

    be updated.</p>

    <pre><code>spack env deactivate

    spack env activate py-bedrock-demo

    </code></pre>

    <p>Run the Jupyter server.</p>

    <pre><code>jupyter notebook --ip 0.0.0.0 --port 8888

    </code></pre>

    <p>Then from your browser, open the <code>notebooks/Demo.ipynb</code> notebook,

    and start playing!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1620857361.0
mochi-hpc/py-mochi-sonata:
  data_format: 2
  description: Python binding to the Mochi Sonata microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-sonata
  latest_release: null
  readme: '<p>Py-Sonata is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-sonata">Sonata
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1614213349.0
mochi-hpc/thallium-microservice-template:
  data_format: 2
  description: Template for a thallium-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/thallium-microservice-template
  latest_release: null
  readme: '<h1>

    <a id="user-content-thallium-microservice-template" class="anchor" href="#thallium-microservice-template"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Thallium
    Microservice Template</h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Thallium.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/02_thallium.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1614210486.0
player1537/dhmem:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537/dhmem
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-dhmem-simplified-cross-workflow-communication\"\
    \ class=\"anchor\" href=\"#dhmem-simplified-cross-workflow-communication\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dhmem:\
    \ Simplified Cross-Workflow Communication</h1>\n<h2>\n<a id=\"user-content-buildinginstalling\"\
    \ class=\"anchor\" href=\"#buildinginstalling\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building/Installing</h2>\n<p>To\
    \ build, either vendor the source code and include with CMake's <code>add_subdirectory</code>\
    \ or add via <code>ExternalProject_Add</code>.</p>\n<h2>\n<a id=\"user-content-example\"\
    \ class=\"anchor\" href=\"#example\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Example</h2>\n<div class=\"highlight\
    \ highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>dhmem/dhmem.h<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>cstdio<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">int</span>\
    \ argc, <span class=\"pl-k\">char</span> **argv) {\n    dhmem::Dhmem <span class=\"\
    pl-smi\">dhmem</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>shared_memory_namespace<span\
    \ class=\"pl-pds\">\"</span></span>);\n\n    <span class=\"pl-k\">auto</span>\
    \ &amp;n = dhmem.<span class=\"pl-smi\">shared</span>&lt;<span class=\"pl-k\"\
    >int</span>&gt;();\n    <span class=\"pl-k\">auto</span> &amp;mutex = dhmem.<span\
    \ class=\"pl-smi\">shared</span>&lt;dhmem::mutex&gt;();\n    \n    {\n       \
    \ dhmem::scoped_lock <span class=\"pl-smi\">lock</span>(mutex);\n        ++n;\n\
    \        <span class=\"pl-c1\">std::printf</span>(<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>n = %d<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>, n);\n    }\n\n    <span class=\"pl-c1\">std::printf</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Press Enter to quit...<span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">std::getchar</span>();\n\n    <span class=\"pl-k\">return</span> <span\
    \ class=\"pl-c1\">0</span>;\n}</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1614216540.0
range3/spack-playground:
  data_format: 2
  description: null
  filenames:
  - envs/chris8x/spack.yaml
  - envs/broken-verbs-chris8x/spack.yaml
  - envs/dev/spack.yaml
  full_name: range3/spack-playground
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-playground" class="anchor" href="#spack-playground"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-playground</h1>

    <h2>

    <a id="user-content-env" class="anchor" href="#env" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Env</h2>

    <div class="highlight highlight-source-shell"><pre>$ <span class="pl-c1">cd</span>
    /workspaces/spack-playground

    $ spack env create -d envs/dev

    $ spack env activate -p -d envs/dev

    $ spack external find</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1620808001.0
smutch/playbooks:
  data_format: 2
  description: A random and evolving collection of ansible playbooks.
  filenames:
  - roles/ronin_cluster/files/ronin_cluster-spack.yaml
  full_name: smutch/playbooks
  latest_release: null
  readme: '<h2>

    <a id="user-content-playbooks" class="anchor" href="#playbooks" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Playbooks</h2>

    <p>This is a random collection of playbooks and roles as I begin my journey using

    ansible to automate the tedious set up devel machines.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1612705252.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - UOREGON/E4S-Develop/spack-ubuntu18.04-ppc64le.yaml
  - NERSC/cori/e4s-20.10/spack.yaml
  - NERSC/cori/e4s-stacks/hsw/spack.yaml
  - NREL/configs/rhodes/software/spack.yaml
  - UOREGON/E4S-Develop/spack-ubuntu20.04-ppc64le.yaml
  - UOREGON/E4S-Develop/spack-rhel8-x86_64.yaml
  - UOREGON/E4S-Develop/spack-ubuntu18.04-x86_64.yaml
  - NERSC/cori/e4s-20.10/prod/spack.yaml
  - NERSC/cori/e4s-stacks/knl/spack.yaml
  - NREL/configs/eagle/base/spack.yaml
  - NREL/configs/rhodes/compilers/spack.yaml
  - UOREGON/E4S-Develop/spack-rhel7-ppc64le.yaml
  - NREL/configs/rhodes/utilities/spack.yaml
  - UOREGON/E4S-Develop/spack-rhel8-ppc64le.yaml
  - NREL/configs/eagle/software/spack.yaml
  - OLCF/e4s-stacks/etc/spack.yaml
  - UOREGON/E4S-Develop/spack-ubuntu20.04-x86_64.yaml
  - UOREGON/E4S-Develop/spack-rhel7-x86_64.yaml
  - NREL/configs/eagle/compilers/spack.yaml
  - NERSC/cori/e4s-stacks/x86/spack.yaml
  - OLCF/e4s-stacks/spack/var/spack/environments/test/spack.yaml
  - NREL/configs/rhodes/base/spack.yaml
  - NREL/configs/eagle/utilities/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1>

    <a id="user-content-spack-configs" class="anchor" href="#spack-configs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 28
  subscribers_count: 22
  topics: []
  updated_at: 1621550978.0
supercontainers/isc-tutorial:
  data_format: 2
  description: 2021 IN PROGRESS -- Getting Started with Containers on HPC
  filenames:
  - files/spack_contenerize/spack.yaml
  - exercises/spack_contenerize/spack.yaml
  full_name: supercontainers/isc-tutorial
  latest_release: null
  readme: '<h1>

    <a id="user-content-getting-started-with-containers-on-hpc" class="anchor" href="#getting-started-with-containers-on-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started with Containers on HPC</h1>

    <p>View this on <a href="https://supercontainers.github.io/isc-tutorial/" rel="nofollow">GitHub
    Pages</a>.</p>

    <h2>

    <a id="user-content-ecp-supercontainers-tutorial-session" class="anchor" href="#ecp-supercontainers-tutorial-session"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ECP
    Supercontainers Tutorial Session</h2>

    <p><a href="fig/ecp.jpg" target="_blank" rel="noopener noreferrer"><img src="fig/ecp.jpg"
    width="250" style="max-width:100%;"></a><a href="fig/pawsey.jpeg" target="_blank"
    rel="noopener noreferrer"><img src="fig/pawsey.jpeg" width="250" style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-details" class="anchor" href="#details" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Half-day Tutorial Session</p>

    <p>Venue: International Supercomputing Conference (ISC21)</p>

    <p>Date: TBD, 24 or 25 June 2021 2:00pm - 6:00pm (European Central Time)</p>

    <p>Location: Virtual</p>

    <p>Link: <a href="https://www.isc-hpc.com/" rel="nofollow">Getting Started with
    Containers in HPC @ ISC21</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2>

    <a id="user-content-ec2-login" class="anchor" href="#ec2-login" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EC2 Login</h2>

    <p>These will be provided the day of the tutorial.</p>

    <h2>

    <a id="user-content-abstract" class="anchor" href="#abstract" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Container computing has revolutionized the way applications are developed and
    delivered. It offers opportunities that never existed before for significantly
    improving efficiency of scientific workflows and easily moving these workflows
    from the laptop to the supercomputer. Tools like Docker, Shifter, Singularity,
    Charliecloud and Podman enable a new paradigm for scientific and technical computing.
    However, to fully unlock its potential, users and administrators need to understand
    how to utilize these new approaches. This tutorial will introduce attendees to
    the basics of creating container images, explain best practices, and cover more
    advanced topics such as creating images to be run on HPC platforms using various
    container runtimes. The tutorial will also explain how research scientists can
    utilize container-based computing to accelerate their research and how these tools
    can boost the impact of their research by enabling better reproducibility and
    sharing of their scientific process without compromising security.</p>

    <p>This is an updated version of the highly successful tutorial presented at SC16-20
    and ISC19.</p>

    <h2>

    <a id="user-content-prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This is a hands-on tutorial. Participants should bring a laptop and load or
    pre-install a terminal and/or ssh client in advance to make best use of time during
    the tutorial.  We will be providing training user accounts to both pre-configured
    EC2 instances.</p>

    <div><a href="fig/AWS_logo.png" target="_blank" rel="noopener noreferrer"><img
    src="fig/AWS_logo.png" width="250" style="max-width:100%;"></a></div>

    <p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards.
    EC2 images and temporary login credentials will be distributed onsite at the tutorial.</p>

    <p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2
    to run through the tutorial again. We recommend you use your own EC2 key and change
    the password.</p>

    <p>US-West-Oregon: ami-0fe12765123c6a840</p>

    <h3>

    <a id="user-content-optional-prerequisites" class="anchor" href="#optional-prerequisites"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optional
    Prerequisites</h3>

    <p>Users can also install Docker and Singularity prior to attending the tutorial
    session. Here, it may be beneficial to create a docker and sylabs (singularity)
    account in advance at <a href="https://cloud.docker.com/" rel="nofollow">https://cloud.docker.com/</a>
    and <a href="https://cloud.sylabs.io/" rel="nofollow">https://cloud.sylabs.io/</a>
    This accounts will be needed to create images on docker cloud/dockerhub and sylabs
    cloud.</p>

    <p><a href="https://sylabs.io/guides/3.7/user-guide/" rel="nofollow">Install Singularity
    on Linux</a></p>

    <p><a href="https://repo.sylabs.io/desktop/" rel="nofollow">Install Singualrity
    on Mac</a> (Alpha)</p>

    <p><a href="https://www.docker.com/products/docker-desktop" rel="nofollow">Install
    Docker for Desktop</a></p>

    <h2>

    <a id="user-content-questions" class="anchor" href="#questions" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2>

    <a id="user-content-schedule-tbd" class="anchor" href="#schedule-tbd" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Schedule (TBD)</h2>

    <p>14:00 - 14:15 Introduction to containers in HPC (Shane)<br>

    Including defining jargon (containers, images, registries/repos,..)</p>

    <p>14:15 - 14:55 Build and run your first container with Podman (Shane)<br>

    Including also minimal pull and run examples, to define these concepts</p>

    <p>14:55 - 15:30 Deploy containers on a supercomputer (Marco)</p>

    <p>15:30 - 16:00 High-performance containers (Marco)</p>

    <p>16:00 - 16:30 BREAK</p>

    <p>16:30 - 17:05 Best practices (Shane)</p>

    <p>17:05 - 17:35 E4S containers initiative (Sameer)</p>

    <p>17:35 - 17:55 Advanced container builds (Eduardo)</p>

    <p>17:55 - 18:00 Wrap-up and final Q&amp;A</p>

    '
  stargazers_count: 3
  subscribers_count: 8
  topics:
  - hpc
  - containers
  - singularity-container
  - singularity
  - shifter
  - docker
  - tutorial
  - supercomputer
  updated_at: 1621589992.0
wangzhezhe/mona-vtk:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: wangzhezhe/mona-vtk
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-mona-vtk-examples\" class=\"anchor\" href=\"\
    #mona-vtk-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>MoNA-VTK examples</h1>\n<p>This repo shows how\
    \ to implement the MonaController and use it for Paraview Catalyst to do the in-situ\
    \ data analytics. The <code>src</code> folder contains the implementation details\
    \ of the MonaController based on the MonaCommunicator which is implemented based\
    \ on <a href=\"https://github.com/mochi-hpc/mochi-mona\">mochi-mona</a>.</p>\n\
    <p>There are several examples in the <code>example</code> folder:</p>\n<ul>\n\
    <li>\n<p>basic: This example shows that how the MonaController can be used to\
    \ execute the basic vtk parallel operations such as send and recv vtk object.</p>\n\
    </li>\n<li>\n<p>icetExample: This exmaple shows that how the mochi-mona can be\
    \ used to execute the iceT test cases based on the iceT wrapper for the mochi-mona.</p>\n\
    </li>\n<li>\n<p>MandelbulbCatalystExample: This example shows how the MonaController\
    \ can be used to execute the tightly coupled in-situ analytics in distributed\
    \ way.</p>\n</li>\n<li>\n<p>MandelbulbColza: This example shows how the MonaController\
    \ can be used to execute the loosely coupled in-situ analytics in distributed\
    \ way, the <a href=\"https://github.com/mochi-hpc/mochi-colza\">mochi-colza</a>\
    \ is used as the data staging service for this example.</p>\n</li>\n<li>\n<p>GrayScottColza:\
    \ This example is similar with the MandelbulbColza case but the simulation data\
    \ is generated by Gray-Scott simulation.</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-installing\"\
    \ class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n<p>We assume\
    \ there is a new account on cori system, and we need following operations to install\
    \ necessary depedencies</p>\n<p><strong>Spack configuration</strong></p>\n<p>There\
    \ are two ways to use the Spack to install the software packages, the first one\
    \ is to init the package.yaml file and the second one is to use the spack env.</p>\n\
    <p>For example, we use <code>spack arch -p</code> to check the current architecture.\
    \ If the architecture is the cray, the <code>package.yaml</code> file should locate\
    \ at the <code>~/.spack/cray/</code>. And we update the <code>package.yaml</code>\
    \ file as needed for installing the mochi-software stacks. One sample <code>package.yaml</code>\
    \ for cori system is located in <code>./config/cori/packages.yaml</code>.</p>\n\
    <p>The repo of the spack used by the mochi project: <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo.git\"\
    \ rel=\"nofollow\">https://xgitlab.cels.anl.gov/sds/sds-repo.git</a>, we need\
    \ to add this repo into the spack system by executing <code>spack repo add sds-repo</code>\
    \ at the current direactly.</p>\n<p><strong>Building ParaView patch version</strong></p>\n\
    <p>The source code of ParaView patch is located at this repo: <a href=\"https://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration\"\
    \ rel=\"nofollow\">https://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration</a>.</p>\n\
    <pre><code>git clone https://gitlab.kitware.com/mdorier/paraview.git\ncd paraview\n\
    git checkout ecb0a075f459c9db78bdd57bf83d715a99f0fe55\ngit submodule update --init\
    \ --recursive\n</code></pre>\n<p>The ParaView needs the osmesa to support the\
    \ capability of in-situ rendering. We use the osmesa installed by the spack on\
    \ the cori system:</p>\n<pre><code>module load spack\nspack load -r mesa/qozjngg\n\
    PATH=\"/global/common/cori/software/altd/2.0/bin:$PATH\"\n</code></pre>\n<p>We\
    \ also need to set the compiler on the cori before building the ParaView</p>\n\
    <pre><code># for compiling vtk on cori\nexport CRAYPE_LINK_TYPE=dynamic\n\n# let\
    \ cc and CC to be the gnu compier\nmodule swap PrgEnv-intel PrgEnv-gnu\n\nmodule\
    \ swap gcc/8.3.0 gcc/9.3.0\n</code></pre>\n<p>At the build direactory of the ParaView,\
    \ we use cmake commands as follows (if we assume the source direactory is <code>~/cworkspace/src/ParaView_patch/paraview</code>):</p>\n\
    <pre><code>cmake ~/cworkspace/src/ParaView_patch/paraview -DPARAVIEW_USE_QT=OFF\
    \ -DPARAVIEW_USE_PYTHON=ON -DPARAVIEW_USE_MPI=ON -DVTK_OPENGL_HAS_OSMESA:BOOL=TRUE\
    \ -DVTK_USE_X:BOOL=FALSE -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_PYTHON_OPTIONAL_LINK=OFF\
    \ -DCMAKE_BUILD_TYPE=Release\n</code></pre>\n<p><strong>Building and installing\
    \ Colza</strong></p>\n<p>This command will install the mochi-colza and other related\
    \ mochi softwares</p>\n<pre><code>spack install mochi-colza@main+drc+examples%gcc@9.3.0\n\
    </code></pre>\n<p><strong>Building all examples</strong></p>\n<p>We can load these\
    \ depedencies if all packages are installed successfully. The sample commands\
    \ are located in <code>config/cori/monavtkEnv.sh</code>. We execute these commands\
    \ before building the mona-vtk examples.</p>\n<p>Then we can build the mona-vtk\
    \ the cmake command like this:</p>\n<pre><code>cmake ~/cworkspace/src/mona-vtk/\
    \ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=$SCRATCH/build_paraview_patch_release/\
    \ -DENABLE_EXAMPLE=ON -DParaView_DIR=$SCRATCH/build_paraview_patch_release/ -DBUILD_SHARED_LIBS=ON\
    \ \n</code></pre>\n<h2>\n<a id=\"user-content-running\" class=\"anchor\" href=\"\
    #running\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running</h2>\n<p>The scripts for scale evaluation are located at the\
    \ <code>example/MandelbulbColza/testScripts</code> and <code>./example/GrayScottColza/testScripts</code>\
    \ separately.</p>\n<p>For example, we can set the build and src dir properly at\
    \ the beginning of the scripts, such as</p>\n<pre><code>BUILDDIR=/global/cscratch1/sd/zw241/build_monavtk\n\
    SRCDIR=/global/homes/z/zw241/cworkspace/src/mona-vtk\n</code></pre>\n<p>and then\
    \ use sbatch to submit jobs with specific node configurations as needed:</p>\n\
    <pre><code>sbatch ~/cworkspace/src/mona-vtk/example/MandelbulbColza/testScripts/strongscale/cori_strongscale_mona_4.scripts\n\
    </code></pre>\n<p>or</p>\n<pre><code>sbatch ~/cworkspace/src/mona-vtk/example/GrayScottColza/testScripts/strongscale/cori_gsstrongscale_mona_128_512.scripts\n\
    </code></pre>\n<p>We can check the corresponding server and log file to get the\
    \ particular data put and analysing time.</p>\n<p>For example, the <code>mbclient_mona_4_512.log</code>\
    \ records the client information when there are 4 staging processes and 512 client\
    \ pracesses.</p>\n<p>For the <code>MandelbulbColza</code> example, we can set\
    \ the size of the data block by updating the <code>BLOCKLENW</code>, <code>BLOCKLENH</code>\
    \ and <code>BLOCKLEND</code> in the associated script.</p>\n<p>For the <code>GrayScottColza</code>\
    \ example, we can set the size of the data block by updating the <code>L</code>\
    \ value at the client configuration file. For example, at the <code>client_settings_monaback_408.json</code>,\
    \ we set the <code>L</code> as 408, which means there are <code>408*408*408</code>\
    \ cells for each data block.</p>\n<h2>\n<a id=\"user-content-other-potential-issues\"\
    \ class=\"anchor\" href=\"#other-potential-issues\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other potential\
    \ issues</h2>\n<p>We could also try to install osmesa by spack manaully:</p>\n\
    <pre><code>spack install mesa+osmesa~llvm swr=none\n</code></pre>\n<p><a href=\"\
    https://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5\" rel=\"\
    nofollow\">https://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5</a></p>\n\
    <pre><code>/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so:\
    \ undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023'\n</code></pre>\n\
    <p>try this:</p>\n<p>SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")</p>\n\
    <p>refer to</p>\n<p><a href=\"https://github.com/halide/Halide/issues/1112\">https://github.com/halide/Halide/issues/1112</a></p>\n\
    <p>if the MPICH_GNI_NDREG_ENTRIES is not set properly\n<a href=\"https://github.com/mercury-hpc/mercury/issues/426\"\
    >https://github.com/mercury-hpc/mercury/issues/426</a></p>\n<p>some osmesa warning\
    \ from paraview if it is built in the Debug mode for building paraview (it is\
    \ ok when we use the Release mode to build the paraview)</p>\n<p>(  44.958s) [pvbatch.3\
    \       ]vtkOpenGLFramebufferObj:356    ERR| vtkOpenGLFramebufferObject (0x10005dc58e0):\
    \ failed at glGenFramebuffers 1 OpenGL errors detected\n1:   0 : (1280) Invalid\
    \ enum</p>\n<p>vtkOpenGLState.cxx:505   WARN| Error glBindFramebuffer1 OpenGL\
    \ errors detected\n2:   0 : (1280) Invalid enum</p>\n<p>Try to build the paraview\
    \ with the Release mode, otherwise, there are mosa related warnings</p>\n<p>For\
    \ the python on cori, refer to this (<a href=\"https://docs.nersc.gov/development/languages/python/nersc-python/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/development/languages/python/nersc-python/</a>)\n\
    If you only use the module option, but the python is not the default one, there\
    \ are some issues</p>\n<p>One issue is \"unnamed python module encoding\", or\
    \ other issues that have different gcc version which may cause the byte code issue\n\
    It is prefered to use the conda activate then the python virtual env if you not\
    \ use the default python3 system on cori</p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1617912788.0
