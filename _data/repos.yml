AMReX-Codes/ExaEpi:
  data_format: 2
  description: An agent-based epidemiological simulation code using AMReX
  filenames:
  - docs/spack.yaml
  full_name: AMReX-Codes/ExaEpi
  latest_release: null
  readme: '<p>This is a demo for an Agent-based epidemiology code built using the
    AMReX framework.</p>

    <p>For more information about AMReX:

    website: <a href="https://amrex-codes.github.io/" rel="nofollow">https://amrex-codes.github.io/</a>

    documentation: <a href="https://amrex-codes.github.io/amrex/docs_html/" rel="nofollow">https://amrex-codes.github.io/amrex/docs_html/</a>

    source code: <a href="https://github.com/AMReX-Codes/amrex">https://github.com/AMReX-Codes/amrex</a></p>

    <h2 id="user-content-building-the-code"><a class="heading-link" href="#building-the-code">Building
    the code<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This demo uses CMake version 3.14 or higher. To build it:

    mkdir build

    cd build

    cmake ..

    make -j8</p>

    <p>To build with GPU support, use the <code>-DAMReX_GPU_BACKEND=CUDA</code> CMake
    option.</p>

    <p>For convenience, a script for setting up the module environment for Perlmutter
    is

    provided in etc/perlmutter_environment.sh. To use it, do:</p>

    <pre><code>source etc/perlmutter_environment.sh

    </code></pre>

    <h2 id="user-content-running-the-code"><a class="heading-link" href="#running-the-code">Running
    the code<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Navigate to build/bin and run the executable using one of the "inputs" files
    in "examples".</p>

    <p>For example:

    cd build/bin

    ./agent ../../examples/inputs</p>

    <h2 id="user-content-looking-at-the-output"><a class="heading-link" href="#looking-at-the-output">Looking
    at the output<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Running the code succesfully will create a number of "plt?????" files. You
    can visualize

    these using the script at etc/plot.py. This will require the "yt" package to be
    installed:</p>

    <pre><code>https://yt-project.org/

    </code></pre>

    <h2 id="user-content-copyright-notice"><a class="heading-link" href="#copyright-notice">Copyright
    Notice<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>ExaEpi Copyright (c) 2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of

    any required approvals from the U.S. Dept. of Energy). All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Intellectual Property Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights.  As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit others to do so.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1689181940.0
AMReX-Codes/pyamrex:
  data_format: 2
  description: GPU-Enabled, Zero-Copy AMReX Python Bindings including AI/ML
  filenames:
  - spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: '23.10'
  readme: '<h1 id="user-content-pyamrex"><a class="heading-link" href="#pyamrex">pyAMReX<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e"><img
    src="https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e"
    alt="Python3 API: Beta" title="Status: Beta" data-canonical-src="https://img.shields.io/badge/phase-beta-yellowgreen"
    style="max-width: 100%;"></a>

    <a href="https://pyamrex.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b4a85ae8b93dc3f1dfd3392e135136aac8c828cf2c2dcc99135db2463af3edc2/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7079616d7265782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/pyamrex/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://github.com/AMReX-Codes/pyamrex/discussions"><img src="https://camo.githubusercontent.com/dcbb262bbe27c41e6885c404f5cac70d3a21a42b6499e931fed8c874879b7ef6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667"
    alt="Discussions" data-canonical-src="https://img.shields.io/badge/chat-discussions-turquoise.svg"
    style="max-width: 100%;"></a><br>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    alt="linux" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    alt="macos" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    alt="windows" style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License pyAMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.8408733" rel="nofollow"><img src="https://camo.githubusercontent.com/bbb0ce8fe427bcc088d5401290073f3ed203b507354ba27b1fcf5f31250c94c5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e383430383733332d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.8408733-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>The Python binding pyAMReX bridges the worlds of block-structured codes and
    data science: it provides zero-copy application GPU data access for AI/ML, in
    situ analysis, application coupling and enables rapid, massively parallel prototyping.

    pyAMReX enhances the <a href="https://amrex-codes.github.io" rel="nofollow">Block-Structured
    AMR Software Framework AMReX</a> and its applications.</p>

    <h2 id="user-content-users"><a class="heading-link" href="#users">Users<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <p>pyAMReX can be installed <a href="https://pyamrex.readthedocs.io/en/latest/install/users.html"
    rel="nofollow">from source</a>.</p>

    <p><em>Coming soon:</em></p>

    <ul>

    <li>pip/pypa</li>

    <li>conda-forge</li>

    <li>spack</li>

    <li>brew</li>

    <li>...</li>

    </ul>

    <h3 id="user-content-usage"><a class="heading-link" href="#usage">Usage<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h3>

    <p>Please see the <a href="https://pyamrex.readthedocs.io/en/latest/usage/how_to_run.html"
    rel="nofollow">manual</a> and our <a href="https://github.com/AMReX-Codes/pyamrex/tree/development/tests">test
    cases</a> for detailed examples.</p>

    <p>Use AMReX objects and APIs from Python:</p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>.<span class="pl-s1">space3d</span> <span class="pl-k">as</span>
    <span class="pl-s1">amr</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">IntVect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">IntVect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <h2 id="user-content-developers"><a class="heading-link" href="#developers">Developers<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <h3 id="user-content-dependencies"><a class="heading-link" href="#dependencies">Dependencies<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B17" rel="nofollow">C++17</a>
    compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.20.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.10.1+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.8+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://mpi4py.readthedocs.io" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (for
    CUDA support, needs 3.7.9+ and 4.2+ is recommended)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <p>Optional CUDA-capable dependencies for tests include:</p>

    <ul>

    <li>

    <a href="https://github.com/cupy/cupy#installation">cupy</a> 11.2+</li>

    <li>

    <a href="https://numba.readthedocs.io/en/stable/user/installing.html" rel="nofollow">numba</a>
    0.56+</li>

    <li>

    <a href="https://pytorch.org/get-started/locally/" rel="nofollow">torch</a> 1.12+</li>

    </ul>

    <h3 id="user-content-install-dependencies"><a class="heading-link" href="#install-dependencies">Install
    Dependencies<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.20.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional:                                    --user</span>

    python3 -m pip install -U pip setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <h3 id="user-content-configure-your-compiler"><a class="heading-link" href="#configure-your-compiler">Configure
    your compiler<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <h3 id="user-content-build"><a class="heading-link" href="#build">Build<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h3>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    python3 -m pip install -U -r requirements.txt

    python3 -m pip install -v --force-reinstall --no-deps <span class="pl-c1">.</span></pre></div>

    <p>If you are iterating on builds, it will faster to rely on <code>ccache</code>
    and to let CMake call the <code>pip</code> install logic:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build -DAMReX_SPACEDIM=<span class="pl-s"><span class="pl-pds">"</span>1;2;3<span
    class="pl-pds">"</span></span>

    cmake --build build --target pip_install -j 8</pre></div>

    <h3 id="user-content-test"><a class="heading-link" href="#test">Test<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h3>

    <p>After successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests</span>

    python3 -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python3 -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python3 -m pytest tests/test_intvect.py::test_iv_conversions


    <span class="pl-c"><span class="pl-c">#</span> Run all tests, do not capture "print"
    output and be verbose</span>

    python3 -m pytest -s -vvvv tests/</pre></div>

    <h3 id="user-content-build-options"><a class="heading-link" href="#build-options">Build
    Options<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>"1;2;3"</td>

    <td>Dimension(s) of AMReX as a <code>;</code>-separated list</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>PYBIND11_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    <tr>

    <td><code>PYAMREX_LIBDIR</code></td>

    <td><em>None</em></td>

    <td>If set, search for pre-built a pyAMReX library</td>

    </tr>

    <tr>

    <td><code>PYAMREX_IPO</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Compile with interprocedural/link optimization (IPO/LTO)</td>

    </tr>

    <tr>

    <td><code>PYINSTALLOPTIONS</code></td>

    <td><em>None</em></td>

    <td>Additional options for <code>pip install</code>, e.g., <code>-v --user</code>

    </td>

    </tr>

    </tbody>

    </table>

    <p>Furthermore, pyAMReX adds a few selected CMake build options:</p>

    <table>

    <thead>

    <tr>

    <th>CMake Option</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMReX_SPACEDIM</code></td>

    <td>

    <strong>3</strong>, use <code>"1;2;3"</code> for all</td>

    <td>Dimension(s) of AMReX as a <code>;</code>-separated list</td>

    </tr>

    <tr>

    <td><code>pyAMReX_IPO</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Compile with interprocedural/link optimization (IPO/LTO)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_src</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_internal</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_repo</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_branch</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>pyAMReX_amrex_repo</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_src</code></td>

    <td><em>None</em></td>

    <td>Absolute path to pybind11 source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_internal</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_repo</code></td>

    <td><code>https://github.com/pybind/pybind11.git</code></td>

    <td>Repository URI to pull and build pybind11 from</td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_branch</code></td>

    <td><code>v2.10.1</code></td>

    <td>Repository branch for <code>pyAMReX_pybind11_repo</code>

    </td>

    </tr>

    <tr>

    <td><code>Python_EXECUTABLE</code></td>

    <td>(newest found)</td>

    <td>Path to Python executable</td>

    </tr>

    </tbody>

    </table>

    <p>As one example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <h2 id="user-content-acknowledgements"><a class="heading-link" href="#acknowledgements">Acknowledgements<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This work was supported by the Laboratory Directed Research and Development
    Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy
    Contract No. DE-AC02-05CH11231.</p>

    <h2 id="user-content-copyright-notice"><a class="heading-link" href="#copyright-notice">Copyright
    Notice<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>pyAMReX Copyright (c) 2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory, National Renewable Energy

    Laboratory Alliance for Sustainable Energy, LLC and Lawrence Livermore

    National Security, LLC (subject to receipt of any required approvals from the
    U.S.

    Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Intellectual Property Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights.  As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit others to do so.</p>

    <p>License for pyamrex can be found at <a href="LICENSE">LICENSE</a>.</p>

    '
  stargazers_count: 21
  subscribers_count: 16
  topics:
  - amrex
  - python
  updated_at: 1696528031.0
AMReX-Microelectronics/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  - Docs/spack.yaml
  full_name: AMReX-Microelectronics/artemis
  latest_release: null
  readme: '<h1 id="user-content-artemis"><a class="heading-link" href="#artemis">ARTEMIS<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    '
  stargazers_count: 10
  subscribers_count: 5
  topics: []
  updated_at: 1696392722.0
AMReX-Microelectronics/artemis_bakup:
  data_format: 2
  description: null
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis_bakup
  latest_release: null
  readme: '<h1 id="user-content-artemis"><a class="heading-link" href="#artemis">ARTEMIS<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <h2 id="user-content-overview"><a class="heading-link" href="#overview">Overview<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a code
    for modeling micromagnetics and electrodynamic waves in next-generation microelectornics.</p>

    <h2 id="user-content-documentation"><a class="heading-link" href="#documentation">Documentation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2 id="user-content-contributing"><a class="heading-link" href="#contributing">Contributing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>WarpX Copyright (c) 2018-2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1688585950.0
Alpine-DAV/spack_configs:
  data_format: 2
  description: spack envs
  filenames:
  - _experimental/envs/alpinedav/ubuntu_18_cuda_10.1_devel/spack.yaml
  - _experimental/envs/alpinedav/ubuntu_18_devel/spack.yaml
  full_name: Alpine-DAV/spack_configs
  latest_release: null
  readme: '<h1 id="user-content-spack_configs"><a class="heading-link" href="#spack_configs">spack_configs<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>shared spack configs repo</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1639176281.0
C2SM/spack-c2sm:
  data_format: 2
  description: Repository for c2sm spack config and repo files
  filenames:
  - upstreams/daint/icon-dsl/spack.yaml
  full_name: C2SM/spack-c2sm
  latest_release: v0.20.1.0
  readme: '<h1 id="user-content-the-spack-extension-of-c2sm-and-mch"><a class="heading-link"
    href="#the-spack-extension-of-c2sm-and-mch">The spack extension of C2SM and MCH<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/67d98f3f50b1ad629290b2fc5a38331fc19df5a656363fb14bdd892b371dcf0e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616e7369636f6c6f72746167732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/ansicolortags/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is the package manager used by C2SM and MeteoSwiss to install and deploy
    software on supercomputers, local machines and the cloud.</p>

    <h2 id="user-content-documentations"><a class="heading-link" href="#documentations">Documentations<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><strong>Infos about c2sm-supported software and machines</strong></p>

    <ul>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow">spack-c2sm
    latest</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.0" rel="nofollow">spack-c2sm
    v0.20.1.0</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.12" rel="nofollow">spack-c2sm
    v0.18.1.12</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.10" rel="nofollow">spack-c2sm
    v0.18.1.10</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.9" rel="nofollow">spack-c2sm
    v0.18.1.9</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.8" rel="nofollow">spack-c2sm
    v0.18.1.8</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.7" rel="nofollow">spack-c2sm
    v0.18.1.7</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.6" rel="nofollow">spack-c2sm
    v0.18.1.6</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.5" rel="nofollow">spack-c2sm
    v0.18.1.5</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.4" rel="nofollow">spack-c2sm
    v0.18.1.4</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.3" rel="nofollow">spack-c2sm
    v0.18.1.3</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.2" rel="nofollow">spack-c2sm
    v0.18.1.2</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.1" rel="nofollow">spack-c2sm
    v0.18.1.1</a> [deprecated]</p>

    </li>

    </ul>

    <p><strong>General infos about spack</strong></p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/v0.20.1/" rel="nofollow">Official
    spack v0.20.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/v0.18.1/" rel="nofollow">Official
    spack v0.18.1</a></li>

    </ul>

    <h2 id="user-content-workflow"><a class="heading-link" href="#workflow">Workflow<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>With spack v0.18 we suggest local/individual spack instances and the use of
    spack environments.</p>

    <p>A user clones the spack repo</p>

    <div class="highlight highlight-source-shell"><pre>git clone --depth 1 --recurse-submodules
    --shallow-submodules -b v0.20.1.0 https://github.com/C2SM/spack-c2sm.git</pre></div>

    <p>gets spack in the command line</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">.</span>
    spack-c2sm/setup-env.sh</pre></div>

    <p>activates an environment</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate <span class="pl-k">&lt;</span>path_to_env<span
    class="pl-k">&gt;</span></pre></div>

    <p>and starts exploring</p>

    <div class="highlight highlight-source-shell"><pre>spack info <span class="pl-k">&lt;</span>package<span
    class="pl-k">&gt;</span>

    spack spec <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>and building</p>

    <div class="highlight highlight-source-shell"><pre>spack install <span class="pl-k">&lt;</span>spec<span
    class="pl-k">&gt;</span>

    spack dev-build <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>a package.</p>

    <p>Updating spack-c2sm is in the hands of the user.</p>

    <div class="highlight highlight-source-shell"><pre>git pull

    git submodule update --recursive</pre></div>

    <p>After an update we advice to clean</p>

    <div class="highlight highlight-source-shell"><pre>spack uninstall -a

    spack clean -a

    rm -rf <span class="pl-k">~</span>/.spack</pre></div>

    <p>and rebuild.</p>

    <h2 id="user-content-command-cheat-sheet"><a class="heading-link" href="#command-cheat-sheet">Command
    cheat sheet<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Clone</td>

    <td><code>git clone --depth 1 --recurse-submodules --shallow-submodules -b &lt;branch/tag&gt;
    https://github.com/C2SM/spack-c2sm.git</code></td>

    </tr>

    <tr>

    <td>Load</td>

    <td>

    <code>. spack-c2sm/setup-env.sh</code> autodetects machine <br>or<br><code>. spack-c2sm/setup-env.sh
    &lt;machine&gt;</code> forces machine<br>or<br><code>. spack-c2sm/setup-env.sh
    unknown</code> uses blank config<br><code>spack compiler find</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-compiler-find"
    rel="nofollow">autodetects compilers</a><br><code>spack external find --all</code>
    <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-external-find"
    rel="nofollow">autodetects externally installed packages</a>

    </td>

    </tr>

    <tr>

    <td>Update</td>

    <td>

    <code>git pull</code><br><code>git submodule update --recursive</code>

    </td>

    </tr>

    <tr>

    <td>Clean</td>

    <td>

    <code>spack uninstall -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-uninstall"
    rel="nofollow">uninstalls all packages</a><br><code>spack clean -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-clean"
    rel="nofollow">cleans all misc caches</a><br><code>rm -rf ~/.spack</code> removes
    user scope data</td>

    </tr>

    </tbody>

    </table>

    <p><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><strong>Spec syntax</strong></a>: <code>&lt;package&gt;</code><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#version-specifier"
    rel="nofollow"><code>@&lt;version&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-specifier"
    rel="nofollow"><code>%&lt;compiler&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#variants"
    rel="nofollow"><code>+&lt;variant&gt; ~&lt;variant&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><code>^&lt;sub-package&gt; +&lt;sub-package-variant&gt;</code></a><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-flags"
    rel="nofollow"><code>&lt;compiler flags&gt;</code></a></p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Find</td>

    <td>

    <code>spack find</code> lists all installed packages. <br><code>spack find &lt;spec&gt;</code>
    lists all installed packages that match the spec.</td>

    </tr>

    <tr>

    <td>Info</td>

    <td><code>spack info &lt;package&gt;</code></td>

    </tr>

    <tr>

    <td>Spec</td>

    <td>

    <code>spack spec &lt;spec&gt;</code> concretizes abstract spec (unspecfied variant
    = <strong>any</strong>)<br><em>Spack is not required to use the default of an
    unspecified variant. The default value is only a tiebreaker for the concretizer.</em>

    </td>

    </tr>

    <tr>

    <td>Install</td>

    <td><code>spack install &lt;spec&gt;</code></td>

    </tr>

    <tr>

    <td>Locate</td>

    <td>

    <code>spack location --install-dir &lt;spec&gt;</code> prints location of <strong>all</strong>
    installs that satisfy the spec</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-load"
    rel="nofollow">Load env</a></td>

    <td>

    <code>spack load &lt;spec&gt;</code> loads run environment</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Activate
    env</a></td>

    <td><code>spack env activate &lt;env_name&gt;</code></td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Deactivate
    env</a></td>

    <td><code>spack deactivate</code></td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 5
  subscribers_count: 18
  topics: []
  updated_at: 1694432475.0
CHIP-SPV/chipStar-Spack:
  data_format: 2
  description: Support for building chipStar and related libraries via Spack
  filenames:
  - Environments/ROCm/spack.yaml
  - Environments/LevelZero/spack.yaml
  full_name: CHIP-SPV/chipStar-Spack
  latest_release: null
  readme: '

    <h1 id="user-content-overview"><a class="heading-link" href="#overview">Overview<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="https://github.com/CHIP-SPV/chipStar">chipStar</a> (formerly CHIP-SPV)

    is software that allows software written to use the

    <a href="https://https://github.com/ROCm-Developer-Tools/HIP" rel="nofollow">Heterogeneous-compute
    Interface for Portability

    (HIP)</a>

    interface and kernel language to target GPUs via the

    <a href="https://registry.khronos.org/spir" rel="nofollow">SPIR-V</a> intermediate
    language.

    chipStar can use either the Intel Level Zero runtime or an OpenCL

    runtime as a backend.</p>

    <p>This repository contains support for building chipStar and its

    dependencies via the <a href="https://github.com/spack/spack">Spack</a> package

    manager.</p>

    <p>Note: most development to date has been done with the Level Zero

    environment, and it is expected that substantial work is needed for

    the environment targeting the OpenCL backend to work.</p>

    <h1 id="user-content-prerequisites"><a class="heading-link" href="#prerequisites">Prerequisites<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <ul>

    <li>An x86_64 system running a common Linux distribution.  OpenSLES 15 is

    the best tested to date.</li>

    <li>A working Spack installation.</li>

    <li>A recent Clang installation that is registered with Spack as a compiler.

    Versions 15 and 16 are best tested, but 14 might work.  We suggest

    installing the compiler via Spack (i.e., by installing something like

    <code>llvm@16.0.2</code> and then using <code>spack compiler add</code> with the
    llvm

    package''s install location), because the <code>chipstar</code> package defined

    in this repository depends on the <code>llvm</code> package anyway.</li>

    <li>A recent (at least version 2023.1) Intel OneAPI compiler installation

    that is registered with Spack as a compiler.  The recommended way

    of doing this is by installing the Spack <code>intel-oneapi-compilers</code>

    package, then registering the location of its compilers with Spack.

    E.g.,</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>$ spack install intel-oneapi-compilers@2023

    $ spack compiler add <span class="pl-s"><span class="pl-pds">$(</span>spack location
    -i intel-oneapi-compilers@2023<span class="pl-pds">)</span></span>/compiler/latest/linux</pre></div>

    <h1 id="user-content-usage"><a class="heading-link" href="#usage">Usage<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <ol start="0">

    <li>Clone this repository to the target system.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ git clone https://github.com/CHIP-SPV/CHIP-SPV-Spack</pre></div>

    <ol start="2">

    <li>Activate the environment you want to build.  E.g., for the

    environment that just builds chipStar with Level Zero backend:</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ <span class="pl-c1">cd</span>
    CHIP-SPV-Spack/Environments/LevelZero

    $ spack env activate <span class="pl-c1">.</span></pre></div>

    <ol start="3">

    <li>Concretize the active environment.  (In Spack terminology,

    "to concretize" means to let Spack examine the package specifications

    it has been asked to build, plus the available package repositories,

    resolve dependencies and check constraints, and decide exactly which

    packages it will build, in which order, and with which configuration.)</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack concretize -f -U</pre></div>

    <p>We suggest examining the output from running the <code>spack concretize</code>

    command to make sure that Spack''s concretizer has truly decided to

    use the configuration options and especially the compilers that you

    want it to use.  Note that the environment and related configuration

    are purposefully not overly constrained to use the given compiler

    for every dependency package, so even though there are some packages

    that must be built with <code>%clang</code>, there are others that may be

    built (or re-used from already-installed packages) using <code>%gcc</code> such

    as the system''s GCC installation.</p>

    <p>If Spack''s concretizer  didn''t do what you want, you can re-concretize

    the environment and be more explicit about what you want using command-line

    configuration options (recommended) or by editing the environment''s

    <code>spack.yaml</code> file or other configuration options that your Spack installation

    is using.  (Use <code>spack config blame</code> to see which configuration files
    Spack is

    using.)  For instance, if you have both <code>clang@16.0.2</code> and <code>clang@15.0.7</code>

    installed and registered as Spack compilers, and you want to build

    using <code>clang@15.0.7</code>, you may have to use a concretize command like
    the

    following:</p>

    <div class="highlight highlight-source-shell"><pre>$ spack -c <span class="pl-s"><span
    class="pl-pds">"</span>packages:chipstar:require:''%clang@15.0.7''<span class="pl-pds">"</span></span>
    concretize -f -U</pre></div>

    <p>As before, verify from the output of the <code>spack concretize</code> command
    that it

    is using the compiler version you want, <code>clang@15.0.7</code> in this example.</p>

    <ol start="4">

    <li>Build the environment.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack install</pre></div>

    <p>Spack supports some options for controlling the build and installation,

    such as <code>-j</code> to limit the number of processes used for parallel builds,

    useful for being a good citizen on shared systems by not allowing Spack

    to use all available cores (its default).  See the Spack documentation for

    more information.</p>

    <p>Assuming all goes well with the build and install, a <code>spack find</code>

    should show the packages that you just built.</p>

    <ol start="5">

    <li>Use the installed software.  There are several ways you might

    update your environment to use the software, including:</li>

    </ol>

    <ul>

    <li><code>spack load chipstar</code></li>

    <li>Activating the environment that you used to build the software</li>

    <li>If your Spack configuration is such that it can generate module files

    and module files have been generated for the software you built

    via this environment, <code>module load chipstar</code>

    </li>

    </ul>

    <p>Note that you may need to modify your environment to be able to run

    programs produced using chipStar and the H4I libraries built

    using this Spack repository.  For instance, on some systems,

    one must load the <code>intel_compute_runtime</code> module before being

    able to run programs that use the Intel Level Zero runtime.</p>

    <h1 id="user-content-todo"><a class="heading-link" href="#todo">TODO<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <ul>

    <li>Clean up and verify the OpenCL-based environment.</li>

    <li>Ensure the OpenCL-based environment can use any OpenCL implementation.</li>

    <li>Incorporate H4I HIP libraries like H4I-HipBLAS into an environments.</li>

    <li>Support using the software installed by the environment via

    <code>module</code> command.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1687550793.0
COSIMA/spack-config:
  data_format: 2
  description: Spack configuration installed at /g/data/ik11/spack/ to provide ACCESS-OM3
    dependencies
  filenames:
  - environments/common_tools_and_libraries/spack.yaml
  - environments/cesm-0_x_0/spack.yaml
  full_name: COSIMA/spack-config
  latest_release: access-om3-v0.2.0
  readme: "<h1 id=\"user-content-cosima-spack-configuration\"><a class=\"heading-link\"\
    \ href=\"#cosima-spack-configuration\">COSIMA Spack Configuration<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>This repository contains\
    \ the spack configuration and the spack environments used\nby COSIMA to deploy\
    \ software on gadi.</p>\n<h2 id=\"user-content-installation-instructions\"><a\
    \ class=\"heading-link\" href=\"#installation-instructions\">Installation instructions<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Clone\
    \ this repository and its submodules to some appropriate location (e.g.,\n<code>/g/data/ik11/spack/0.20.1</code>):</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ git clone --recursive https://github.com/COSIMA/spack-config.git\
    \ /g/data/ik11/spack/0.20.1</pre></div>\n<p>Next, create the python virtual environment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ <span class=\"pl-c1\">cd</span>\
    \ /g/data/ik11/spack/0.20.1\n$ ./bootstrap_venv.sh</pre></div>\n<p>Finally, to\
    \ use this spack installation one just needs to activate the python\nenvironment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$  <span class=\"pl-c1\"\
    >.</span> /g/data/ik11/spack/0.20.1/venv/bin/activate\n$ which spack\n<span class=\"\
    pl-en\">spack</span> ()\n{ \n    <span class=\"pl-c1\">:</span> this is a shell\
    \ <span class=\"pl-k\">function</span> <span class=\"pl-en\">from:</span> /g/data/ik11/spack/0.20.1/spack/share/spack/setup-env.sh;\n\
    \    <span class=\"pl-c1\">:</span> the real spack script is here: /g/data/ik11/spack/0.20.1/spack/bin/spack<span\
    \ class=\"pl-k\">;</span>\n    _spack_shell_wrapper <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span><span class=\"pl-smi\">$@</span><span class=\"pl-pds\"\
    >\"</span></span><span class=\"pl-k\">;</span>\n    <span class=\"pl-k\">return</span>\
    \ <span class=\"pl-smi\">$?</span>\n}</pre></div>\n<h2 id=\"user-content-installing-software\"\
    ><a class=\"heading-link\" href=\"#installing-software\">Installing software<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>It\
    \ is recommended that all software be installed using spack\nenvironments. Currently\
    \ the following environments are provided (the names\nshould be self-explanatory):</p>\n\
    <ol>\n<li><code>access-om3-0_1_0</code></li>\n<li><code>access-om3-devel</code></li>\n\
    <li><code>cesm-0_1_0</code></li>\n<li><code>common_tools_and_libraries</code></li>\n\
    </ol>\n<p>Installation of a spack environment is usually quite straightforward,\
    \ but\nbecause this can be a CPU intensive operation and take quite some time,\
    \ it is\nbest to do this in parallel and to use an interactive job.</p>\n<h3 id=\"\
    user-content-step-by-step-instructions\"><a class=\"heading-link\" href=\"#step-by-step-instructions\"\
    >Step-by-step instructions:<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<ol>\n<li>Activate spack environment</li>\n</ol>\n<p>First\
    \ activate the spack environment</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ spack env activate <span class=\"pl-k\">&lt;</span>env<span class=\"pl-k\"\
    >&gt;</span></pre></div>\n<p>where <code>&lt;env&gt;</code> by the actual name\
    \ of the environment.</p>\n<ol start=\"2\">\n<li>Download the sources</li>\n</ol>\n\
    <p>As the compute nodes do not have internet access, one needs to download all\
    \ the\nnecessary sources from the login node. This is done using a spack mirror.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ spack mirror create -d\
    \ sources -a</pre></div>\n<p>Here <code>sources</code> is the name of a mirror\
    \ that has already been configured.</p>\n<ol start=\"3\">\n<li>Submit interactive\
    \ job</li>\n</ol>\n<p>This should not use more than a single node. Also, make\
    \ sure to add <code>gdata/ik11</code>\nand <code>scratch/ik11</code> to the storage\
    \ options.</p>\n<ol start=\"4\">\n<li>Install software</li>\n</ol>\n<p>Once the\
    \ job has started, because it starts a completely new shell session, one\nneeds\
    \ to activate again both the python and the spack environments:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$  <span class=\"pl-c1\">.</span> /g/data/ik11/spack/0.20.1/venv/bin/activate\n\
    $ spack env activate <span class=\"pl-k\">&lt;</span>env<span class=\"pl-k\">&gt;</span></pre></div>\n\
    <p>Then one can simply do</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ spack install </pre></div>\n<p>In this case, although each individual\
    \ build will use some level of parallelism,\nspack will proceed through the installation\
    \ of the packages sequentially. To\nfully use parallelism one needs to tell spack\
    \ to create a Makefile and use this\nto install the software:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$ spack env depfile -o Makefile\n$ make\
    \ -j</pre></div>\n<p>In the end, all the packages should be available in some\
    \ subdirectory of\n<code>/g/data/ik11/spack/0.20.1/opt/</code> and the corresponding\
    \ environment modules are\ninstalled under a subdirectory of <code>/g/data/ik11/spack/0.20.1/modules</code>.\
    \ The\nactual subdirectories depend on the selected environement.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1692145219.0
CUP-ECS/beatnik:
  data_format: 2
  description: Initial Cabana/Cajita Low/High-order Z-model Interface Solver. Benchmark
    for evaluating the performance of algorithms requiring global communication. Beatnik
    is also a precursor to potential later a High Performance Parallel Interface solver.
  filenames:
  - configs/unm-hopper/spack.yaml
  full_name: CUP-ECS/beatnik
  latest_release: null
  readme: '<h1 id="user-content-beatnik---a--prototype-high-performance-parallel-interface-benchmark"><a
    class="heading-link" href="#beatnik---a--prototype-high-performance-parallel-interface-benchmark">Beatnik
    - A  prototype High Performance Parallel Interface Benchmark<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <h2 id="user-content-description"><a class="heading-link" href="#description">Description<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Beatnik is a benchmark for global communication based on Pandya and Shkoller''s
    3D fluid interace "Z-Model" in the Cabana/Cajita mesh framework [1]. The goals

    of Beatnik are to:</p>

    <ol>

    <li>Provide an interesting and meaningful benchmark for numerical methods that
    require global communication, particularly fast fourier transforms and fast multipole
    methods.</li>

    <li>Understand the performance characteristics of different parallel decompositions
    of the Z-Model based on both a 2D decomposition based on logical mesh location
    location and a space-filling curve mesh decomposition.</li>

    <li>Provide a working prototype parallel implementation of the fluid interface
    model that other implementations can use to understand the implementation.</li>

    </ol>

    <p>The initial Beatnik implementation of the Z-Model uses a simple mesh-based
    representation of the surface manifold with a regular decomposition as a Cajita
    2D mesh in I/J space and the physical position of each element in the mesh stored
    as a separate vector in the nodes of the mesh. This is efficient for the low-order
    z-model, as the computation of surface normals, artificial viscosity, and Fourier
    transforms for estimating interface velocities are straightforward in this representation.</p>

    <p>Because Beatnik does not yet include a spatial mesh decomposition, its support
    for scalable far-field solvers in the higher-order interface solution models (e.g.
    the fast multipole method, P3M, or distance-sorting cutoff-based methods) is limited.
    In particular, Beatnik 1.0 currently only supports either O(N^2) brute-force calculation
    of far-field forces or the use of an external far-field force solver that re-sorts
    the mesh at each derivative calculation.</p>

    <p>In the future, we plan to add the ability to decompose the Beatnik mesh spatially
    by adding a ParticleMesh abstraction that the implements the portions of Cajita
    meshes Beatnik requires using Cabana particle abstractions. This will in turn
    enable the direct implementation of scalable far-field force methods. This work
    is planned for Beatnik 2.0.</p>

    <h2 id="user-content-building-beatnik"><a class="heading-link" href="#building-beatnik">Building
    Beatnik<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Beatnik relies on multiple external packages to build, including:</p>

    <ul>

    <li>LLNL''s build, link, test (BLT) library [2]</li>

    <li>ECP CoPA''s Cabana/Cajita particle and mesh framework [3]</li>

    <li>UT-Knoxville''s HeFFTe fast fourier transform library [4]</li>

    <li>The FFTW fast fourier transform library [5]</li>

    <li>A high-performance MPI implementation such as OpenMPI, MPICH, or MVAPICH</li>

    <li>[Optional] UT-Austin''s PVFMM fast multipole solver [6]</li>

    </ul>

    <p>To ease building Beatnik, the configs/ directory includes Spack configuration
    files for building in spack environments on multiple systems and test case run
    scripts for those systems, as well as a spack package description for directly
    building Beatnik. This spack package will be contributed back to the mainline
    Spack repository following the first public Beatnik release.</p>

    <h3 id="user-content-building-beatnik-in-a-spack-environment"><a class="heading-link"
    href="#building-beatnik-in-a-spack-environment">Building Beatnik in a Spack Environment<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>Assuming that you have Spack already installed on your HPC systems (as described
    in <a href="https://spack.readthedocs.io" rel="nofollow">https://spack.readthedocs.io</a>),
    you can use spack to create an environment for building and developing spack as
    follows:</p>

    <ol>

    <li>If not checked out from git recursively, checkout all needed Beatnik submodules,
    e.g. <code>git submodule init &amp;&amp; git submodule update --recursive</code>

    </li>

    <li>Create a build directory for housing the Spack environment and housing the
    out-of-source build, e.g. <code>mkdir build-hopper</code> on the UNM hopper compute
    cluster.</li>

    <li>Copy the appropriate spack.yaml file from configs/[systemname]/ to spack.yaml
    in the newly-created build directory, e.g. <code>cp configs/unm-hopper/spack.yaml
    build-hopper/</code>

    </li>

    <li>Perform any compiler setup needed using the system module system, as spack
    environments do not necessarily configure the compiler, e.g. <code>module load
    gcc/11.2.0</code>. This compiler should be compatible with one used in the spack.yaml
    file chosen, and ideally described in a README.md file in the associated configs/
    directory</li>

    <li>Change directory to the created build directory and create a spack environment
    in which to build Beatnik in that directory, e.g. <code>cd build-hopper; spack
    env create -d . spack.yaml</code>

    </li>

    <li>Activate, concretize, and install the resulting environment, e.g. <code>spack
    env activate -d . &amp;&amp; spack concretize &amp;&amp; spack install</code>

    </li>

    <li>Run cmake and make to create the appropriate Makefiles and build using them,
    e.g. <code>cmake .. &amp;&amp; make</code>.</li>

    </ol>

    <h3 id="user-content-building-beatnik-directly-using-a-spack-package-description"><a
    class="heading-link" href="#building-beatnik-directly-using-a-spack-package-description">Building
    Beatnik directly using a Spack package description<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h3>

    <p>XXX</p>

    <h3 id="user-content-developing-beatnik-using-a-spack-package-description"><a
    class="heading-link" href="#developing-beatnik-using-a-spack-package-description">Developing
    Beatnik using a Spack package description<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h3>

    <p>XXX</p>

    <h3 id="user-content-beatnik-build-time-configuration-options"><a class="heading-link"
    href="#beatnik-build-time-configuration-options">Beatnik Build-Time Configuration
    Options<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>

    <code>ENABLE_PVFMM=ON</code> - Enables the PVFMM fast multipole solver for direct
    calculation of the Birchoff-Rott integral far-field forces. Activated at runtime
    through the option ''-b pvfmm''. Note that PVFMM support is both highly experimental
    and is not

    necessarily faster than brute force solutions for many problem sizes due to its
    lack of GPU support for particle fast multipole problems.</li>

    </ul>

    <h2 id="user-content-running-beatnik"><a class="heading-link" href="#running-beatnik">Running
    Beatnik<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>By default, Beatnik solves a simple multi-mode rocket rig problem sized for
    a

    single serial CPU core with approximately 4GB of memory. It also includes

    command line options to change initial problem state, I/O frequency, and to

    weak-scale scale up the initial problem to larger number of processes.</p>

    <h3 id="user-content-general-command-line-parameters"><a class="heading-link"
    href="#general-command-line-parameters">General command line parameters<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>

    <code>-x [cuda|threads|serial]</code> - The node-level parallelism/accelerator
    backend to use</li>

    <li>

    <code>-F [write-frequency]</code> - Interval between timesteps when I/O is written</li>

    <li>

    <code>-O [solution order]</code> - Order of solver to use (''high'', ''medium'',
    or ''low''). ''low'' is the default.</li>

    <li>`-w [weak scaling factor] - Scale up the problem specification, including
    the x/y bounding box, to be N times larger</li>

    </ul>

    <h3 id="user-content-problem-specific-command-line-parameters"><a class="heading-link"
    href="#problem-specific-command-line-parameters">Problem-specific command line
    parameters<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>

    <code>-n [i/j mesh dimension ]</code> - Number of points on the interface manifold
    in the I and J dimensions</li>

    <li>`-t [timesteps] - number of timesteps to simulate</li>

    <li>

    <code>-I [interface initialization]</code> - Function to use for interface initial
    condition. Currently only ''cos'' and ''sech2'' are supported.</li>

    <li>

    <code>-m [magnitude]</code> - The maximum magnitude of the initialization function.</li>

    <li>

    <code>-p [period]</code> - The number of periods of the interface in the initial
    bounding box</li>

    <li>

    <code>-a [atwood]</code> - Atwood''s constant for the difference in pressure between
    the two fluids</li>

    <li>

    <code>-g [gravity]</code> - Gravitational acceleration in the -Z direction</li>

    <li>

    <code>-a [atwood]</code> -  Atwood''s constant for the difference in pressure
    between the two fluids</li>

    <li>

    <code>-M [mu]</code> - Mu, the artificial viscosity constant used in the Z-Model</li>

    <li>

    <code>-e [epsilon]</code> - Epsilon, the desingularization constant used in the
    Z-Model expressed as a fraction of the distance between interface mesh points</li>

    </ul>

    <h3 id="user-content-example-1-periodic-multi-mode-rocket-rig"><a class="heading-link"
    href="#example-1-periodic-multi-mode-rocket-rig">Example 1: Periodic Multi-mode
    Rocket Rig<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>The simplest test case and the one to which the rocketrig example program defaults
    is an initial interface distributed according to a cosine function. Simple usage
    examples:</p>

    <ol>

    <li>Serial execution: <code>bin/rocketrig -x serial</code>

    </li>

    <li>Cuda execution (on systems with GPUs) with a 512x512 mesh: <code>bin/rocketrig
    -x cuda -n 512</code>

    </li>

    <li>Cuda execution with a 1024x1024 problem scaled up to be sixteen times as large
    in terms of bounding box and number of total points with no I/O: bin/rocketrig
    -x cuda -n 1024 -F 0 -w 16`</li>

    </ol>

    <h3 id="user-content-example-2-non-periodic-single-mode-gaussian-rollup"><a class="heading-link"
    href="#example-2-non-periodic-single-mode-gaussian-rollup">Example 2: Non-periodic
    Single-mode Gaussian Rollup<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>Another test case is a single-mode rollup test where the intitial interface
    is set according to a hyperbolic secant function. This testcase recreates the
    the gaussian perturbation results in Panda and Shkoller''s paper from sections
    2.3 and 2.4.  To run this testcase with a high-order model, use the following
    command line parameters. Note that this works best with a GPU accelerator, as
    the exact high-order far field force solver is very compute intensive and is generally
    impractical for non-trivial mesh sizes without GPU acceleration:

    <code>bin/rocketrig -x cuda -O high -n 64 -I sech2 -m 0.1 -p 9.0 -b free -a 0.15
    -M 2 -e 2</code></p>

    <h2 id="user-content-planned-development-steps"><a class="heading-link" href="#planned-development-steps">Planned
    Development Steps<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Beatnik is being implemented in multiple distinct steps, with associated planned
    releases:</p>

    <ul>

    <li>

    <p>Version 1.0 Features</p>

    <ol>

    <li>A low-order model implementation that relies on Cajita/HeFFTe Fourier transforms
    for estimating velocity interface at mesh points.</li>

    <li>A high-order model implementation based on either exact or PVFMM for computing
    long-range forces</li>

    <li>A medium-order model that uses the Fourier transform for estimating interface
    velocity and the fast multipole method for estimating how the vorticity changes
    at each interface point.</li>

    <li>Support for periodic boundary conditions and free boundary conditions</li>

    <li>A few simple benchmark examples, including a single-mode gaussian roll-up
    test and the multi-mode rocket rig experiment.</li>

    <li>Direct support for weak scaling of benchmarks through command line arguments</li>

    </ol>

    </li>

    <li>

    <p>Version 1.X Planned Features</p>

    <ol>

    <li>A cutoff-based approach for calculating far-field forces using the Cabana
    particle framework that accelerates far-field force calculations by avoiding the
    complex hierarchical communications and calculations in the fast multipole solver.</li>

    <li>Improved timestep, desingularization, and artificial viscosity handling to
    provide good defaults for the input parameters given</li>

    <li>Additional interface initialization options, including gaussian random and
    file-based interface initialization (also useful for checkpointing)</li>

    <li>Support for coupling with other applications through either I/O (e.g. ADIOS)
    or Communication (e.g. Portage) approaches</li>

    <li>Additional test cases definitions</li>

    </ol>

    </li>

    <li>

    <p>Version 2.0 Planned Features</p>

    <ol>

    <li>Spatial partitioning of the mesh using a space-filling curve to better optimize
    the high-order model</li>

    <li>Direct fast multipole or P3M solver for scalable, high precision high-order
    model solves.</li>

    </ol>

    </li>

    </ul>

    <h2 id="user-content-acknowledgement-contributors-and-copyright-information"><a
    class="heading-link" href="#acknowledgement-contributors-and-copyright-information">Acknowledgement,
    Contributors, and Copyright Information<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h2>

    <p>Beatnik is primarily availble as open source under a 3-Clause BSD License.
    It is being developed at the University of New Mexico, University of Tennessee
    at Chatanooga, and the University of Alabama under funding the U.S. Department
    of Energy''s Predictive Science Academic Alliance Partnership III (PSAAP-III)
    program. Contributors to Beatnik development include the following:</p>

    <ul>

    <li>Patrick G. Bridges (<a href="mailto:patrickb@unm.edu">patrickb@unm.edu</a>)</li>

    <li>Thomas Hines (<a href="mailto:thomas-hines-01@utc.edu">thomas-hines-01@utc.edu</a>)</li>

    <li>Jered Dominguez-Trujillo (<a href="mailto:jereddt@unm.edu">jereddt@unm.edu</a>)</li>

    <li>Jacob McCullough (<a href="mailto:jmccullough12@unm.edu">jmccullough12@unm.edu</a>)</li>

    </ul>

    <p>The general structure of Beatnik and the rocketrig examples were taken from
    the ExaMPM proxy application (<a href="https://github.com/ECP-copa/ExaMPM">https://github.com/ECP-copa/ExaMPM</a>)
    developed by the ECP Center for Particle Applications (CoPA), which was also available
    under a 3-Clause BSD License when used for creating application structure.</p>

    <h2 id="user-content-references"><a class="heading-link" href="#references">References<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ol>

    <li>

    <p>Gavin Pandya and Steve Shkoller. "3d Interface Models for Raleigh-Taylor Instability."
    Published as arxiv.org preprint <a href="https://arxiv.org/abs/2201.04538" rel="nofollow">https://arxiv.org/abs/2201.04538</a>,
    2022.</p>

    </li>

    <li>

    <p><a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a></p>

    </li>

    <li>

    <p><a href="https://github.com/ECP-copa/Cabana/">https://github.com/ECP-copa/Cabana/</a></p>

    </li>

    <li>

    <p>Innovative Computing Laboratory. "heFFTe." URL: <a href="https://icl.utk.edu/fft/"
    rel="nofollow">https://icl.utk.edu/fft/</a></p>

    </li>

    <li>

    <p>Matteo Frigo. "A Fast Fourier Transform Compiler," In the Proceedings of the
    1999 ACM SIGPLAN Conference on Programming Language Design and Implementation
    (PLDI ''99), Atlanta, Georgia, May 1999</p>

    </li>

    <li>

    <p><a href="https://pvfmm.org" rel="nofollow">https://pvfmm.org</a></p>

    </li>

    </ol>

    '
  stargazers_count: 4
  subscribers_count: 4
  topics: []
  updated_at: 1696885371.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/23.08/oneapi-x86_64/spack.yaml
  - environments/22.05/cuda-x86_64.spack.yaml
  - environments/22.05/rocm.spack.yaml
  - environments/23.02/cuda-ppc64le/spack.yaml
  - environments/23.08/cuda-aarch64/spack.yaml
  - environments/23.05/rocm-x86_64/spack.yaml
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/22.08/cuda-ppc64le.spack.yaml
  - environments/23.05/cuda-x86_64/spack.yaml
  - environments/21.08/spack.yaml
  - environments/21.05/spack.yaml
  - environments/23.02/cuda-x86_64/spack.yaml
  - environments/23.08/cuda-x86_64/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: v23.08
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1 id=\"user-content-e4s\"><a class=\"\
    heading-link\" href=\"#e4s\">E4S<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p>The <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >Extreme-scale Scientific Software Stack (E4S)</a> is a community effort to provide\
    \ open source\nsoftware packages for developing, deploying and running scientific\
    \ applications on high-performance\ncomputing (HPC) platforms. E4S provides from-source\
    \ builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2 id=\"user-content-useful-links\"\
    ><a class=\"heading-link\" href=\"#useful-links\">Useful Links<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<ul>\n<li>User Documentation:\
    \ <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\">https://e4s.readthedocs.io</a>\n\
    </li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub: <a href=\"https://github.com/E4S-Project/\"\
    >https://github.com/E4S-Project/</a>\n</li>\n<li>E4S Slack Channel: <a href=\"\
    https://e4s-project.slack.com\" rel=\"nofollow\">https://e4s-project.slack.com</a>\n\
    </li>\n<li>Slack Channel Invitation: <a href=\"https://communityinviter.com/apps/e4s-project/e4s\"\
    \ rel=\"nofollow\">https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n\
    <li>E4S Dashboard: <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2 id=\"user-content-related-projects\"><a class=\"heading-link\"\
    \ href=\"#related-projects\">Related Projects<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<ul>\n<li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\
    >E4S-Project/E4S-Project.github.io</a> - E4S Documentation repo that is hosted\
    \ on <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2 id=\"user-content-license\"\
    ><a class=\"heading-link\" href=\"#license\">License<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>E4S is released as MIT license\
    \ for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2 id=\"user-content-contact\"><a class=\"heading-link\"\
    \ href=\"#contact\">Contact<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 18
  subscribers_count: 10
  topics: []
  updated_at: 1690987779.0
ECP-CANDLE/Supervisor:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: ECP-CANDLE/Supervisor
  latest_release: null
  stargazers_count: 7
  subscribers_count: 11
  topics:
  - nci-doe-collaboration-capability
  updated_at: 1690319274.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, time-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '23.10'
  readme: '<h1 id="user-content-warpx"><a class="heading-link" href="#warpx">WarpX<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/discussions"><img src="https://camo.githubusercontent.com/dcbb262bbe27c41e6885c404f5cac70d3a21a42b6499e931fed8c874879b7ef6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667"
    alt="Discussions" data-canonical-src="https://img.shields.io/badge/chat-discussions-turquoise.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1109/SC41404.2022.00008" rel="nofollow"><img src="https://camo.githubusercontent.com/2be0ab9ceaff22581aac9ee5d5eac9cc73cae7e4bad2c69bcf0ffd6713337293/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2 id="user-content-overview"><a class="heading-link" href="#overview">Overview<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2 id="user-content-documentation"><a class="heading-link" href="#documentation">Documentation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our discussions page at <a href="https://github.com/ECP-WarpX/WarpX/discussions">https://github.com/ECP-WarpX/WarpX/discussions</a></p>

    <h2 id="user-content-contributing"><a class="heading-link" href="#contributing">Contributing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2 id="user-content-copyright-notice"><a class="heading-link" href="#copyright-notice">Copyright
    Notice<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>WarpX Copyright (c) 2018, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>Please see the full license agreement in <a href="LICENSE.txt">LICENSE.txt</a>.

    The SPDX license identifier is <code>BSD-3-Clause-LBNL</code>.</p>

    '
  stargazers_count: 215
  subscribers_count: 14
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1697430885.0
EnzymeAD/CMake-Template:
  data_format: 2
  description: "\U0001F528 A template for using Enzyme with CMake"
  filenames:
  - spack.yaml
  full_name: EnzymeAD/CMake-Template
  latest_release: null
  readme: "<h1 id=\"user-content-cmake-template\"><a class=\"heading-link\" href=\"\
    #cmake-template\">CMake-Template<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<h2 id=\"user-content-usage\"><a class=\"heading-link\" href=\"\
    #usage\">Usage<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <h3 id=\"user-content-install-dependencies\"><a class=\"heading-link\" href=\"\
    #install-dependencies\">Install dependencies<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<ul>\n<li>cmake</li>\n<li>make</li>\n\
    <li>llvm</li>\n<li>enzyme</li>\n</ul>\n<p>Using spack:</p>\n<pre><code>spack env\
    \ activate .\nspack install\n</code></pre>\n<p>Using homebrew:</p>\n<pre><code>brew\
    \ bundle install\n</code></pre>\n<h3 id=\"user-content-configure-and-build\"><a\
    \ class=\"heading-link\" href=\"#configure-and-build\">Configure and build<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Configure\
    \ the CMake project using the version of Enzyme installed on the system:</p>\n\
    <pre><code>mkdir build &amp;&amp; cd build\ncmake ..\nmake\n</code></pre>\n<p>Configure\
    \ the CMake project using a custom Enzyme version:</p>\n<pre><code>mkdir build\
    \ &amp;&amp; cd build\ncmake -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics:
  - cmake
  - enzyme-ad
  - template
  updated_at: 1687815556.0
Exawind/exawind-builder:
  data_format: 2
  description: Scripts to help building Exawind codes on various systems
  filenames:
  - etc/spack/nrel-eagle/spack.yaml
  - etc/spack/spack/spack.yaml
  full_name: Exawind/exawind-builder
  latest_release: v0.1.0
  readme: '<h1 id="user-content-exawind-code-builder"><a class="heading-link" href="#exawind-code-builder">ExaWind
    Code Builder<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="https://exawind.github.io/exawind-builder" rel="nofollow">Documentation</a></p>

    <p>ExaWind Builder is a collection of bash scripts to configure and compile the

    codes used within the <a href="https://github.com/exawind">ExaWind</a> project
    on various

    high-performance computing (HPC) systems. The builder provides the following</p>

    <ul>

    <li>

    <p><strong>Platform configuration</strong>: Provides the minimal set of modules
    that must be

    loaded when compiling with different compilers and MPI libraries on different

    HPC systems.</p>

    </li>

    <li>

    <p><strong>Software configuration</strong>: Provides baseline CMake configuration
    that can be

    used to configure the various options when building a <em>project</em>, e.g.,

    enable/disable optional modules, automate specification of paths to various

    libraries, configure release vs. debug builds.</p>

    </li>

    <li>

    <p><strong>Build script generation</strong>: Generates an executable end-user
    script for a

    combination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>

    </li>

    <li>

    <p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific

    script that allows the user to recreate the exact environment used to build

    the codes during runtime.</p>

    </li>

    </ul>

    <p>The build scripts are intended for developers who might want to compile the

    codes with different configuration options, build different branches during

    their development cycle, or link to a different development version of a library

    that is currently not available in the standard installation on the system. Please
    see the

    <a href="https://exawind.github.io/exawind-builder" rel="nofollow">documentation</a>
    for

    details on how to use this to build ExaWind software.</p>

    <h2 id="user-content-installation-and-usage"><a class="heading-link" href="#installation-and-usage">Installation
    and usage<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <h3 id="user-content-using-exawind-builder-with-pre-installed-exawind-environment"><a
    class="heading-link" href="#using-exawind-builder-with-pre-installed-exawind-environment">Using
    exawind-builder with pre-installed ExaWind environment<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h3>

    <p>ExaWind Builder is already installed and setup on OLCF Summit, NREL

    Eagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly

    to using build scripts from the central installation. Please consult <a href="https://exawind.github.io/exawind-builder/basic.html#basic-usage"
    rel="nofollow">user

    manual</a> to

    learn how to use the scripts.</p>

    <h3 id="user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions"><a
    class="heading-link" href="#bootstrapping-exawind-builder-with-pre-configured-system-definitions">Bootstrapping
    exawind-builder with pre-configured system definitions<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h3>

    <p>ExaWind builder has <a href="https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems"
    rel="nofollow">pre-built

    configurations</a>

    for several systems. On these systems you can use the <code>bootstrap</code> script
    to

    quickly get up and running. Please consult <a href="https://exawind.github.io/exawind-builder/installation.html"
    rel="nofollow">installation

    manual</a>. The

    relevant steps are shown below.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Download bootstrap script</span>

    curl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Make it executable</span>

    chmod a+x bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Execute bootstrap and provide system/compiler
    combination</span>

    ./bootstrap.sh -s [SYSTEM] -c [COMPILER]


    <span class="pl-c"><span class="pl-c">#</span> Examples</span>

    ./bootstrap.sh -s spack -c clang       <span class="pl-c"><span class="pl-c">#</span>
    On MacOS with homebrew</span>

    ./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system

    ./bootstrap.sh -s eagle -c gcc         <span class="pl-c"><span class="pl-c">#</span>
    NREL Eagle</span>

    ./bootstrap.sh -s cori -c intel        <span class="pl-c"><span class="pl-c">#</span>
    NERSC Cori</span>

    ./bootstrap.sh -s snl-ascicgpu -c gcc  <span class="pl-c"><span class="pl-c">#</span>
    SNL GPU development machine</span></pre></div>

    <h3 id="user-content-creating-new-system-configuration"><a class="heading-link"
    href="#creating-new-system-configuration">Creating new system configuration<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>You can add new system definitions to exawind-builder for use on new systems

    that are not used by ExaWind team. Please see <a href="https://exawind.github.io/exawind-builder/advanced.html"
    rel="nofollow">manual

    installation</a> and

    <a href="https://exawind.github.io/exawind-builder/newsys.html" rel="nofollow">adding
    a new system</a>

    sections in the user manual.</p>

    <h2 id="user-content-links"><a class="heading-link" href="#links">Links<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <ul>

    <li><a href="https://www.exawind.org" rel="nofollow">ExaWind</a></li>

    <li><a href="https://github.com/exawind">ExaWind GitHub Organization</a></li>

    <li><a href="https://a2e.energy.gov/about/hfm" rel="nofollow">A2e HFM</a></li>

    </ul>

    '
  stargazers_count: 3
  subscribers_count: 5
  topics:
  - cmake
  - build
  - exawind
  - hpc
  - exawind-builder
  updated_at: 1643028069.0
FZJ-INM1-BDA/siibra-python:
  data_format: 2
  description: Software interfaces for interacting with brain atlases - Python client
  filenames:
  - .ebrains/spack/siibra-spack.yaml
  full_name: FZJ-INM1-BDA/siibra-python
  latest_release: null
  stargazers_count: 41
  subscribers_count: 7
  topics:
  - brain
  - atlas
  - neuroscience
  - bigbrain
  - bigbrainproject
  - humanbrainproject
  updated_at: 1697202732.0
FairRootGroup/FairMQ:
  data_format: 2
  description: C++ Message Queuing Library and Framework
  filenames:
  - spack.yaml
  full_name: FairRootGroup/FairMQ
  latest_release: v1.8.0
  readme: '

    <h1 id="user-content-fairmq"><a class="heading-link" href="#fairmq">FairMQ<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="COPYRIGHT"><img src="https://camo.githubusercontent.com/c137674b017e381c618ebcabdecb42821c3cd3671e32cee8d1ed60ccc192a1dd/68747470733a2f2f616c66612d63692e6773692e64652f736869656c64732f62616467652f6c6963656e73652d4c47504c2d2d332e302d6f72616e67652e737667"
    alt="license" data-canonical-src="https://alfa-ci.gsi.de/shields/badge/license-LGPL--3.0-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.1689985" rel="nofollow"><img src="https://camo.githubusercontent.com/ae672eef12e67029da460aa41e43e31ddfca7b5256fe67b40b40650a68a24b2e/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e313638393938352e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.1689985.svg"
    style="max-width: 100%;"></a>

    <a href="https://bestpractices.coreinfrastructure.org/projects/6915" rel="nofollow"><img
    src="https://camo.githubusercontent.com/ebabb62e89af2e9bcd77f32d83b953d214f7205c40c56a27e7380ec178b9470d/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f363931352f6261646765"
    alt="OpenSSF Best Practices" data-canonical-src="https://bestpractices.coreinfrastructure.org/projects/6915/badge"
    style="max-width: 100%;"></a>

    <a href="https://github.com/FairRootGroup/FairMQ/actions/workflows/fair-software.yml"><img
    src="https://camo.githubusercontent.com/1993428095da072cadfe3cade519c683f681bc22e2ef72ffd4fe215e2ce083d0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666169722d2d736f6674776172652e65752d2545322539372538462532302532302545322539372538462532302532302545322539372538422532302532302545322539372538462532302532302545322539372538462d79656c6c6f77"
    alt="fair-software.eu" data-canonical-src="https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B%20%20%E2%97%8F%20%20%E2%97%8F-yellow"
    style="max-width: 100%;"></a>

    <a href="https://repology.org/project/fairmq/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/f8657b44c2c7ad0eaf3d60e9c29f3c79b98340e31ebc957e0a2371cbe7a7a2a6/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f76657273696f6e2d666f722d7265706f2f737061636b2f666169726d712e737667"
    alt="Spack package" data-canonical-src="https://repology.org/badge/version-for-repo/spack/fairmq.svg"
    style="max-width: 100%;"></a></p>

    <p>C++ Message Queuing Library and Framework</p>

    <p>Docs: <a href="https://github.com/FairRootGroup/FairMQ/blob/dev/README.md#documentation">Book</a></p>

    <p>Find all FairMQ releases <a href="https://github.com/FairRootGroup/FairMQ/releases">here</a>.</p>

    <h2 id="user-content-introduction"><a class="heading-link" href="#introduction">Introduction<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>FairMQ is designed to help implementing large-scale data processing workflows
    needed in next-generation Particle Physics experiments. FairMQ is written in C++
    and aims to</p>

    <ul>

    <li>provide <strong>an asynchronous message passing abstraction</strong> of different
    data transport technologies,</li>

    <li>provide a reasonably <strong>efficient data transport</strong> service (zero-copy,
    high throughput),</li>

    <li>be <strong>data format agnostic</strong>, and</li>

    <li>provide <strong>basic building blocks</strong> that can be used to implement
    higher level data processing workflows.</li>

    </ul>

    <p>The core of FairMQ provides an abstract asynchronous message passing API with
    scalability protocols

    inspired by <a href="https://github.com/zeromq/libzmq">ZeroMQ</a> (e.g. PUSH/PULL,
    PUB/SUB).

    FairMQ provides multiple implementations for its API (so-called "transports",

    e.g. <code>zeromq</code> and <code>shmem</code> (latest release of the <code>ofi</code>
    transport in v1.4.56, removed since v1.5+)) to cover

    a variety of use cases

    (e.g. inter-thread, inter-process, inter-node communication) and machines (e.g.
    Ethernet, Infiniband).

    In addition to this core functionality FairMQ provides a framework for creating
    "devices" - actors which

    are communicating through message passing. FairMQ does not only allow the user
    to use different transport

    but also to mix them; i.e: A Device can communicate using different transport
    on different channels at the

    same time. Device execution is modelled as a simple state machine that shapes
    the integration points for

    the user task. Devices also incorporate a plugin system for runtime configuration
    and control.

    Next to the provided <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/devices">devices</a>
    and

    <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/plugins">plugins</a>
    the user can extend FairMQ

    by developing his own plugins to integrate his devices with external configuration
    and control services.</p>

    <p>FairMQ has been developed in the context of its mother project <a href="https://github.com/FairRootGroup/FairRoot">FairRoot</a>
    -

    a simulation, reconstruction and analysis framework.</p>

    <h2 id="user-content-installation-from-source"><a class="heading-link" href="#installation-from-source">Installation
    from Source<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Recommended:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/FairRootGroup/FairMQ
    fairmq_source

    cmake -S fairmq_source -B fairmq_build -GNinja -DCMAKE_BUILD_TYPE=Release

    cmake --build fairmq_build

    ctest --test-dir fairmq_build --output-on-failure --schedule-random -j<span class="pl-k">&lt;</span>ncpus<span
    class="pl-k">&gt;</span>

    cmake --install fairmq_build --prefix <span class="pl-s"><span class="pl-pds">$(</span>pwd<span
    class="pl-pds">)</span></span>/fairmq_install</pre></div>

    <p>Please consult the <a href="https://cmake.org/cmake/help/latest/manual/cmake.1.html"
    rel="nofollow">manpages of your CMake version</a> for more options.</p>

    <p>If dependencies are not installed in standard system directories, you can hint
    the installation location via

    <code>-DCMAKE_PREFIX_PATH=...</code> or per dependency via <code>-D{DEPENDENCY}_ROOT=...</code>
    (<code>*_ROOT</code> variables can also be environment variables).</p>

    <h2 id="user-content-usage"><a class="heading-link" href="#usage">Usage<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <p>FairMQ ships as a CMake package, so in your <code>CMakeLists.txt</code> you
    can discover it like this:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">find_package</span>(FairCMakeModules
    1.0 <span class="pl-k">REQUIRED</span>)

    <span class="pl-c1">include</span>(FairFindPackage2)

    find_package2(FairMQ)

    find_package2_implicit_dependencies()</pre></div>

    <p>The <a href="https://fairrootgroup.github.io/FairCMakeModules/latest/module/FairFindPackage2.html"
    rel="nofollow"><code>FairFindPackage2</code> module</a> is part of the <a href="https://fairrootgroup.github.io/FairCMakeModules"
    rel="nofollow"><code>FairCMakeModules</code> package</a>.</p>

    <p>If FairMQ is not installed in system directories, you can hint the installation:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">list</span>(PREPEND
    CMAKE_PREFIX_PATH /path/to/fairmq_install)</pre></div>

    <h2 id="user-content-dependencies"><a class="heading-link" href="#dependencies">Dependencies<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li><a href="https://www.boost.org/" rel="nofollow">Boost</a></li>

    <li><a href="https://cmake.org/" rel="nofollow">CMake</a></li>

    <li><a href="http://www.doxygen.org/" rel="nofollow">Doxygen</a></li>

    <li>

    <a href="https://github.com/FairRootGroup/FairCMakeModules">FairCMakeModules</a>
    (optionally bundled)</li>

    <li><a href="https://github.com/FairRootGroup/FairLogger">FairLogger</a></li>

    <li>

    <a href="https://github.com/google/googletest">GTest</a> (optionally bundled)</li>

    <li><a href="http://zeromq.org/" rel="nofollow">ZeroMQ</a></li>

    </ul>

    <p>Which dependencies are required depends on which components are built.</p>

    <p>Supported platform is Linux. macOS is supported on a best-effort basis.</p>

    <h2 id="user-content-cmake-options"><a class="heading-link" href="#cmake-options">CMake
    options<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>On command line:</p>

    <ul>

    <li>

    <code>-DDISABLE_COLOR=ON</code> disables coloured console output.</li>

    <li>

    <code>-DBUILD_TESTING=OFF</code> disables building of tests.</li>

    <li>

    <code>-DBUILD_EXAMPLES=OFF</code> disables building of examples.</li>

    <li>

    <code>-DBUILD_DOCS=ON</code> enables building of API docs.</li>

    <li>

    <code>-DFAIRMQ_CHANNEL_DEFAULT_AUTOBIND=OFF</code> disable channel <code>autoBind</code>
    by default</li>

    <li>You can hint non-system installations for dependent packages, see the #installation-from-source
    section above</li>

    </ul>

    <p>After the <code>find_package(FairMQ)</code> call the following CMake variables
    are defined:</p>

    <table>

    <thead>

    <tr>

    <th>Variable</th>

    <th>Info</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>${FairMQ_PACKAGE_DEPENDENCIES}</code></td>

    <td>the list of public package dependencies</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_VERSION}</code></td>

    <td>the minimum <code>&lt;dep&gt;</code> version FairMQ requires</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_COMPONENTS}</code></td>

    <td>the list of <code>&lt;dep&gt;</code> components FairMQ depends on</td>

    </tr>

    <tr>

    <td><code>${FairMQ_PACKAGE_COMPONENTS}</code></td>

    <td>the list of components FairMQ consists of</td>

    </tr>

    <tr>

    <td><code>${FairMQ_#COMPONENT#_FOUND}</code></td>

    <td>

    <code>TRUE</code> if this component was built</td>

    </tr>

    <tr>

    <td><code>${FairMQ_VERSION}</code></td>

    <td>the version in format <code>MAJOR.MINOR.PATCH</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_GIT_VERSION}</code></td>

    <td>the version in the format returned by <code>git describe --tags --dirty --match
    "v*"</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_PREFIX}</code></td>

    <td>the actual installation prefix</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BINDIR}</code></td>

    <td>the installation bin directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_INCDIR}</code></td>

    <td>the installation include directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_LIBDIR}</code></td>

    <td>the installation lib directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_DATADIR}</code></td>

    <td>the installation data directory (<code>../share/fairmq</code>)</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CMAKEMODDIR}</code></td>

    <td>the installation directory of shipped CMake find modules</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BUILD_TYPE}</code></td>

    <td>the value of <code>CMAKE_BUILD_TYPE</code> at build-time</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CXX_FLAGS}</code></td>

    <td>the values of <code>CMAKE_CXX_FLAGS</code> and <code>CMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE}</code>
    at build-time</td>

    </tr>

    </tbody>

    </table>

    <h2 id="user-content-documentation"><a class="heading-link" href="#documentation">Documentation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ol>

    <li>

    <a href="docs/Device.md#1-device">Device</a>

    <ol>

    <li><a href="docs/Device.md#11-topology">Topology</a></li>

    <li><a href="docs/Device.md#12-communication-patterns">Communication Patterns</a></li>

    <li><a href="docs/Device.md#13-state-machine">State Machine</a></li>

    <li><a href="docs/Device.md#15-multiple-devices-in-the-same-process">Multiple
    devices in the same process</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Transport.md#2-transport-interface">Transport Interface</a>

    <ol>

    <li>

    <a href="docs/Transport.md#21-message">Message</a>

    <ol>

    <li><a href="docs/Transport.md#211-ownership">Ownership</a></li>

    </ol>

    </li>

    <li><a href="docs/Transport.md#22-channel">Channel</a></li>

    <li><a href="docs/Transport.md#23-poller">Poller</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Configuration.md#3-configuration">Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#31-device-configuration">Device Configuration</a></li>

    <li>

    <a href="docs/Configuration.md#32-communication-channels-configuration">Communication
    Channels Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#321-json-parser">JSON Parser</a></li>

    <li><a href="docs/Configuration.md#322-suboptparser">SuboptParser</a></li>

    </ol>

    </li>

    <li><a href="docs/Configuration.md#33-introspection">Introspection</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Development.md#4-development">Development</a>

    <ol>

    <li><a href="docs/Development.md#41-testing">Testing</a></li>

    <li>

    <a href="docs/Development.md#42-static-analysis">Static Analysis</a>

    <ol>

    <li><a href="docs/Development.md#421-cmake-integration">CMake Integration</a></li>

    <li><a href="docs/Development.md#422-extra-compiler-arguments">Extra Compiler
    Arguments</a></li>

    </ol>

    </li>

    </ol>

    </li>

    <li>

    <a href="docs/Logging.md#5-logging">Logging</a>

    <ol>

    <li><a href="docs/Logging.md#51-log-severity">Log severity</a></li>

    <li><a href="docs/Logging.md#52-log-verbosity">Log verbosity</a></li>

    <li><a href="docs/Logging.md#53-color">Color for console output</a></li>

    <li><a href="docs/Logging.md#54-file-output">File output</a></li>

    <li><a href="docs/Logging.md#55-custom-sinks">Custom sinks</a></li>

    </ol>

    </li>

    <li><a href="docs/Examples.md#6-examples">Examples</a></li>

    <li>

    <a href="docs/Plugins.md#7-plugins">Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#71-usage">Usage</a></li>

    <li><a href="docs/Plugins.md#72-development">Development</a></li>

    <li>

    <a href="docs/Plugins.md#73-provided-plugins">Provided Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#731-pmix">PMIx</a></li>

    </ol>

    </li>

    </ol>

    </li>

    </ol>

    '
  stargazers_count: 74
  subscribers_count: 10
  topics:
  - fairroot
  - fairmq
  - zeromq
  - shmem
  - c-plus-plus
  updated_at: 1695842853.0
FairRootGroup/FairSoft:
  data_format: 2
  description: Repository for installation routines of the external software required
    by FairRoot
  filenames:
  - test/env/jun19_fairroot_18_4/spack.yaml
  full_name: FairRootGroup/FairSoft
  latest_release: nov22p1
  readme: "<h1 id=\"user-content-fairsoft\"><a class=\"heading-link\" href=\"#fairsoft\"\
    >FairSoft<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>The FairSoft distribution provides the software packages needed to compile\
    \ and run the <a href=\"https://github.com/FairRootGroup/FairRoot\">FairRoot framework</a>\
    \ and experiment packages based on FairRoot. FairSoft is a source distribution\
    \ with recurring releases for macOS and Linux.</p>\n<h2 id=\"user-content-installation-from-source\"\
    ><a class=\"heading-link\" href=\"#installation-from-source\">Installation from\
    \ Source<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>Choose between the classic (called \"Legacy\") installation method or the new\
    \ Spack-based one:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Legacy (Recommended)</strong></th>\n\
    <th><strong>Spack (EXPERIMENTAL)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>This is the classic bash/cmake based setup system.</td>\n<td>This is an ongoing\
    \ standardization and modernization effort based on Spack (which itself is still\
    \ under heavy development). Most things are already working. For early adopters.</td>\n\
    </tr>\n<tr>\n<td>Releases are reflected in the git history via tags and branches,\
    \ e.g.: <code>nov22</code>, <code>apr21p2</code>, <code>apr21_patches</code>\n\
    </td>\n<td>Always use the latest <code>dev</code> branch. Multiple releases are\
    \ described within the metadata contained in the repo (read on in the Installation\
    \ instructions on how to select a release).</td>\n</tr>\n<tr>\n<td>\u25BA <a href=\"\
    legacy/README.md\">continue</a>\n</td>\n<td>\u25BA <a href=\"docs/README.md\"\
    >continue</a>\n</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"user-content-installation-of-pre-compiled-binaries\"\
    ><a class=\"heading-link\" href=\"#installation-of-pre-compiled-binaries\">Installation\
    \ of pre-compiled Binaries<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p><em>Note</em>: FairSoft is primarily a source distribution.\
    \ Availability of latest releases as pre-compiled binaries may be delayed.</p>\n\
    <h3 id=\"user-content-gsi-virgo-cluster\"><a class=\"heading-link\" href=\"#gsi-virgo-cluster\"\
    >GSI Virgo Cluster<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>For all <a href=\"https://hpc.gsi.de/virgo/platform/software.html#application-environment\"\
    \ rel=\"nofollow\">VAEs</a> at <code>/cvmfs/fairsoft.gsi.de/&lt;vae-os&gt;/fairsoft/&lt;release&gt;</code>.\
    \ Use by exporting the <code>SIMPATH</code> environment variable pointing to one\
    \ of the directories.</p>\n<h3 id=\"user-content-macos-beta\"><a class=\"heading-link\"\
    \ href=\"#macos-beta\">macOS (beta)<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h3>\n<p>Tested: <code>macOS 11 (x86_64)</code>,\
    \ <code>macOS 12 (x86_64)</code>, <code>macOS 12 (arm64)</code> with <em>Command\
    \ Line Tools for Xcode</em> <code>13</code></p>\n<p>FairSoft config: <a href=\"\
    FairSoftConfig.cmake\">default</a>, no other configs planned</p>\n<ol>\n<li>Install\
    \ <em>Command Line Tools for Xcode</em> from <a href=\"https://developer.apple.com/downloads\"\
    \ rel=\"nofollow\">https://developer.apple.com/downloads</a> (requires Apple account)</li>\n\
    <li>Install <a href=\"https://brew.sh/\" rel=\"nofollow\">Homebrew</a>\n</li>\n\
    <li>Run <code>brew update &amp;&amp; brew doctor</code> and fix potential issues\
    \ reported by these commands until <code>Your system is ready to brew.</code>\n\
    </li>\n<li>Run</li>\n</ol>\n<pre><code>brew tap fairrootgroup/fairsoft\nbrew install\
    \ fairsoft@22.11\n</code></pre>\n<ol start=\"5\">\n<li>Use via <code>export SIMPATH=$(brew\
    \ --prefix fairsoft@22.11)</code>\n</li>\n</ol>\n<p><em>Note</em>: macOS is a\
    \ fast moving target and it is possible the packages will stop working from one\
    \ day to another after some system component was updated. We try our best to keep\
    \ up, one great way to help is to provide detailed problem reports <a href=\"\
    https://github.com/FairRootGroup/FairSoft/issues/new\">here on github</a>.</p>\n\
    <h3 id=\"user-content-other-platforms\"><a class=\"heading-link\" href=\"#other-platforms\"\
    >Other platforms<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>Binary packages for non-GSI Linux as well as Spack binary caches and/or pre-populated\
    \ install trees are planned for the future.</p>\n<h2 id=\"user-content-contributing\"\
    ><a class=\"heading-link\" href=\"#contributing\">Contributing<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Please ask your questions,\
    \ request features, and report issues by <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\
    >creating a github issue</a>.</p>\n"
  stargazers_count: 14
  subscribers_count: 13
  topics: []
  updated_at: 1683613174.0
FemusPlatform/NumericPlatform:
  data_format: 2
  description: Official repository of open-source code based Numerical Platform
  filenames:
  - spack_env/spack.yaml
  full_name: FemusPlatform/NumericPlatform
  latest_release: null
  readme: '<h1 id="user-content-numericplatform"><a class="heading-link" href="#numericplatform">NumericPlatform<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Official repository of open-source code based Numerical Platform</p>

    <p>The Numerical Platform has been developed as an environment where several numerical

    codes can be run together, allowing to model complex physical phenomena on different

    physical scales.</p>

    <p>The platform is organized into a hierarchical set of levels, namely</p>

    <ul>

    <li>

    <p>Level 0: main level of the Numerical Platform where the different components
    are gathered</p>

    </li>

    <li>

    <p>Level 1: differentiation of Numerical Platform main components into:</p>

    <ul>

    <li>

    <p>PLAT_BUILD: level where installing scripts are gathered and components are
    built</p>

    </li>

    <li>

    <p>PLAT_THIRD_PARTY: components needed to run the numerical codes</p>

    </li>

    <li>

    <p>PLAT_CODES: the numerical codes</p>

    </li>

    <li>

    <p>PLAT_VISU: software for post processing and data visualization</p>

    </li>

    <li>

    <p>PLAT_USERS: level where applications are run</p>

    </li>

    </ul>

    </li>

    <li>

    <p>Level 2: differentiation of the main components. Up to now the following packages
    can be installed</p>

    <ul>

    <li>

    <p>PLAT_THIRD_PARTY:

    <a href="http://www.salome-platform.org/" rel="nofollow">Salome platform</a>,

    <a href="https://www.open-mpi.org/" rel="nofollow">OpenMPI library</a>,

    <a href="https://www.mcs.anl.gov/petsc/" rel="nofollow">Petsc library</a>,

    <a href="http://libmesh.github.io/" rel="nofollow">Libmesh code</a>,

    <a href="http://www.salome-platform.org/user-section/about/med" rel="nofollow">med
    data format library</a>,

    <a href="http://docs.salome-platform.org/latest/dev/MEDCoupling/index.html" rel="nofollow">MedCoupling
    library</a></p>

    </li>

    <li>

    <p>PLAT_CODES:

    FEMuS code,

    <a href="https://openfoamwiki.net/index.php/Main_Page" rel="nofollow">OpenFOAM
    extend</a>,

    <a href="http://www.oecd-nea.org/tools/abstract/detail/uscd1234/" rel="nofollow">Dragon
    code</a>,

    Donjon code</p>

    </li>

    <li>

    <p>PLAT_VISU:

    Paraview, as Salome package</p>

    </li>

    </ul>

    </li>

    </ul>

    <p>This repository represents Level 0 and it can be used to perform a complete
    Numerical Platform installation from scratch.

    For a complete platform installation gcc7 and cmake (vesion &gt; 3.10) are required.</p>

    '
  stargazers_count: 5
  subscribers_count: 3
  topics: []
  updated_at: 1693291617.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1658856345.0
HenryWinterbottom-NOAA/ufs_containers:
  data_format: 2
  description: This repository contains Docker and spack recipes for building Docker
    containers supporting UFS related applications.
  filenames:
  - configs/ufs_utils.spack.yaml
  full_name: HenryWinterbottom-NOAA/ufs_containers
  latest_release: null
  readme: "<p><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_pyutils/blob/develop/LICENSE\"\
    ><img src=\"https://camo.githubusercontent.com/f1c8066ffa900d7f28fbf9dac53ecae9536d5f2d712acf5d28169053f7126d7a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76322e312d626c61636b\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/License-LGPL_v2.1-black\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/11283100b6bb6ad86286bbc513074be499d32590d1ac0683bb1fd225ba941e3c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e75782d7562756e747525374363656e746f732d6c6967687467726579\"\
    ><img src=\"https://camo.githubusercontent.com/11283100b6bb6ad86286bbc513074be499d32590d1ac0683bb1fd225ba941e3c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e75782d7562756e747525374363656e746f732d6c6967687467726579\"\
    \ alt=\"Linux\" data-canonical-src=\"https://img.shields.io/badge/Linux-ubuntu%7Ccentos-lightgrey\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/3178d3cf7f933dd9f799626e2a38c7b48b9e7ea19a8da1503c06b684d7aaf5d3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e35253743332e36253743332e372d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/3178d3cf7f933dd9f799626e2a38c7b48b9e7ea19a8da1503c06b684d7aaf5d3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e35253743332e36253743332e372d626c7565\"\
    \ alt=\"Python Version\" data-canonical-src=\"https://img.shields.io/badge/Python-3.5%7C3.6%7C3.7-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/84aeb27d17875b4119b3e6e584034bdfe7c2458434c8fbc41bda46f975d27451/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f64652532305374796c652d626c61636b2d707572706c652e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/Code%20Style-black-purple.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_containers/actions/workflows/pycodestyle.yaml\"\
    ><img src=\"https://github.com/HenryWinterbottom-NOAA/ufs_containers/actions/workflows/pycodestyle.yaml/badge.svg\"\
    \ alt=\"Python Coding Standards\" style=\"max-width: 100%;\"></a></p>\n<h1 id=\"\
    user-content-overview\"><a class=\"heading-link\" href=\"#overview\">Overview<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>This\
    \ repository contains Docker and spack recipes for building Docker\ncontainers\
    \ supporting Unified Forecast System (UFS) related\napplications.</p>\n<ul>\n\
    <li>\n<strong>Authors:</strong> <a href=\"mailto:henry.winterbottom@noaa.gov\"\
    >Henry R. Winterbottom</a>\n</li>\n<li>\n<strong>Maintainers:</strong> Henry R.\
    \ Winterbottom</li>\n<li>\n<strong>Version:</strong> 0.0.1</li>\n<li>\n<strong>License:</strong>\
    \ LGPL v2.1</li>\n<li>\n<strong>Copyright</strong>: Henry R. Winterbottom</li>\n\
    </ul>\n<h1 id=\"user-content-cloning\"><a class=\"heading-link\" href=\"#cloning\"\
    >Cloning<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>This repository utilizes several sub-modules from various sources. To\nobtain\
    \ the entire system, do as follows.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>user@host:$ git clone --recursive https://github.com/HenryWinterbottom-NOAA/ufs_containers\
    \ /path/to/ufs_containers</pre></div>\n<h1 id=\"user-content-dependencies\"><a\
    \ class=\"heading-link\" href=\"#dependencies\">Dependencies<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>The package dependencies\
    \ and the respective repository and manual\ninstallation attributes are provided\
    \ in the table below.</p>\n<div align=\"left\">\n<table>\n<thead>\n<tr>\n<th align=\"\
    center\">Dependency Package</th>\n<th align=\"center\"><div align=\"left\">Installation\
    \ Instructions</div></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"\
    ><div align=\"left\"><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_pyutils\"\
    ><code>ufs_pyutils</code></a></div></td>\n<td align=\"center\"><div align=\"left\"\
    ><code>git+https://www.github.com/HenryWinterbottom-NOAA/ufs_pyutils.git</code></div></td>\n\
    </tr>\n</tbody>\n</table>\n<h1 id=\"user-content-installing-package-dependencies\"\
    ><a class=\"heading-link\" href=\"#installing-package-dependencies\">Installing\
    \ Package Dependencies<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p>In order to install the respective Python packages upon\
    \ which\n<code>ufs_diags</code> is dependent, do as follows.</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>user@host:$ <span class=\"pl-c1\">cd</span>\
    \ /path/to/ufs_containers\nuser@host:$ /path/to/pip install update\nuser@host:$\
    \ /path/to/pip install -r /path/to/ufs_containers/requirements.txt</pre></div>\n\
    <p>For additional information using <code>pip</code> and <code>requirements.txt</code>\
    \ type files, see <a href=\"https://pip.pypa.io/en/stable/reference/requirements-file-format/\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h1 id=\"user-content-building-spack-configuration-files\"\
    ><a class=\"heading-link\" href=\"#building-spack-configuration-files\">Building\
    \ Spack Configuration Files<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p>To build the configuration files that <code>spack</code>\
    \ requires, an application\nhas been provided and can be executed as described\
    \ below.</p>\n<div class=\"highlight highlight-source-shell\"><pre>user@host:$\
    \ <span class=\"pl-c1\">cd</span> /path/to/ufs_containers/scripts\nuser@host:$\
    \ ./build_specs.py -h\n\nUsage: build_specs.py [-h] [--spack_yaml SPACK_YAML]\
    \ yaml\n\nSpack stack package specification(s) application interface.\n\nPositional\
    \ Arguments:\n  yaml                  YAML-formatted file containing the Spack\
    \ containerized stack package specification.\n\nOptional Arguments:\n  -h, --help\
    \            show this <span class=\"pl-c1\">help</span> message and <span class=\"\
    pl-c1\">exit</span>\n  --spack_yaml, -out SPACK_YAML\n                       \
    \ A YAML-formatted file containing the spack specification attributes.\n\nuser@host:$\
    \ ./build_specs.py /path/to/ufs_containers/parm/spack_demo.yaml --spack_yaml /path/to/ufs_containers/scripts/spack.yaml</pre></div>\n\
    <p>The resulting YAML-formatted file containing the <code>spack</code> instructions\n\
    described within the <code>/path/to/ufs_containers/parm/spack_demo.yaml</code>\
    \ in\nthe previous step will appear as follows.</p>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre><span class=\"pl-ent\">spack</span>:\n  <span class=\"pl-ent\">container</span>:\n\
    \    <span class=\"pl-ent\">format</span>: <span class=\"pl-s\">docker</span>\n\
    \  <span class=\"pl-ent\">specs</span>:\n  - <span class=\"pl-s\">package_1</span>\n\
    \  - <span class=\"pl-s\">package_2</span>\n  - <span class=\"pl-s\">package_3</span></pre></div>\n\
    <p>Additional, supported applications, can be found beneath\n<code>/path/to/ufs_containers/parm</code>.</p>\n\
    <h1 id=\"user-content-building-using-docker-services\"><a class=\"heading-link\"\
    \ href=\"#building-using-docker-services\">Building Using Docker Services<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>To\
    \ <code>build</code>, <code>push</code>, and <code>cleanup</code> all Docker services\
    \ images, do as follows.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>user@host:$ <span class=\"pl-c1\">cd</span> /path/to/ufs_containers/scripts\n\
    user@host:$ ./docker_services.py --help\n\nUsage: docker_services.py [-h] [-build]\
    \ [-cleanup] [-push] compose env\n\nDocker services interface.\n\nPositional Arguments:\n\
    \  compose     Docker compose YAML-formatted services file.\n  env         Docker\
    \ compose YAML-formatted environment configuration file.\n\nOptional Arguments:\n\
    \  -h, --help  show this <span class=\"pl-c1\">help</span> message and <span class=\"\
    pl-c1\">exit</span>\n  -build      Build the specified Docker service images.\n\
    \  -cleanup    Cleanup <span class=\"pl-k\">local</span> services images.\n  -push\
    \       Push existing images to their respective repositories.\n\nuser@host:$\
    \ ./docker_services.py /path/to/ufs_containers/Docker/docker_services.yaml /path/to/ufs_containers/Docker/docker_services_env.yaml\
    \ --build --push --cleanup</pre></div>\n<h1 id=\"user-content-forking\"><a class=\"\
    heading-link\" href=\"#forking\">Forking<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h1>\n<p>If a user wishes to contribute modifications\
    \ done within their\nrespective fork(s) to the authoritative repository, we request\
    \ that\nthe user first submit an issue and that the fork naming conventions\n\
    follow those listed below.</p>\n<ul>\n<li>\n<p><code>docs/user_fork_name</code>:\
    \ Documentation additions and/or corrections for the application(s).</p>\n</li>\n\
    <li>\n<p><code>feature/user_fork_name</code>: Additions, enhancements, and/or\
    \ upgrades for the application(s).</p>\n</li>\n<li>\n<p><code>fix/user_fork_name</code>:\
    \ Bug-type fixes for the application(s) that do not require immediate attention.</p>\n\
    </li>\n<li>\n<p><code>hotfix/user_fork_name</code>: Bug-type fixes which require\
    \ immediate attention to fix issues that compromise the integrity of the respective\
    \ application(s).</p>\n</li>\n</ul>\n</div>"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - docker
  - spack
  - docker-services
  updated_at: 1696729175.0
JCSDA/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/skylab-dev/spack.yaml
  - configs/templates/ufs-weather-model/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/unified-dev/spack.yaml
  - configs/templates/ufs-weather-model-static/spack.yaml
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/gfs-v16.2/spack.yaml
  full_name: JCSDA/spack-stack
  latest_release: 1.5.0
  readme: '<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"><img
    src="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"
    width="425" style="max-width: 100%;"></a></p>

    <p>Spack-stack is a framework for installing software libraries to support

    NOAA''s Unified Forecast System (UFS) applications and the

    Joint Effort for Data assimilation Integration (JEDI) coupled to

    several Earth system prediction models (MPAS, NEPTUNE, UM, FV3, GEOS, UFS).</p>

    <p>Spack-stack supports installations on a range of R&amp;D and operational platforms.

    It provides a set of installation templates (package lists), default package settings,

    system configurations for a range of <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">macOS and Linux workstation, HPC, and cloud

    platforms</a>, and Spack extensions, and uses a fork of the

    <a href="https://github.com/spack/spack">Spack repository</a>. <a href="https://spack.io/"
    rel="nofollow">Spack</a> is a

    community-supported, multi-platform package manager

    developed by Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about Spack, see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for Spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">Spack
    documentation</a>.</p>

    <p><strong>To get started with spack-stack</strong>, either by using an existing

    installation on a <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">supported platform</a>

    or by <a href="https://spack-stack.readthedocs.io/en/latest/CreatingEnvironments.html"
    rel="nofollow">creating a new installation</a>, see the

    <a href="https://spack-stack.readthedocs.io/en/latest/Overview.html#getting-started"
    rel="nofollow">Getting Started</a> documentation page.

    Full documentation with table of contents can be found at <a href="https://spack-stack.readthedocs.io/en/latest/"
    rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a>.</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li>

    <a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a>: <a href="https://www.github.com/AlexanderRichert-NOAA">Alex
    Richert</a>, <a href="https://www.github.com/Hang-Lei-NOAA">Hang Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed
    Hartnett</a>

    </li>

    <li>

    <a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a>: <a href="https://www.github.com/climbfuji">Dom
    Heinzeller</a>, <a href="https://github.com/srherbener">Steve Herbener</a>

    </li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>: <a href="https://github.com/ulmononian">Cam Book</a>, <a href="https://github.com/natalie-perlin">Natalie
    Perlin</a>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    '
  stargazers_count: 17
  subscribers_count: 9
  topics: []
  updated_at: 1695997145.0
JuliaParallel/MPI.jl:
  data_format: 2
  description: MPI wrappers for Julia
  filenames:
  - .ci/mvapich/spack.yaml
  full_name: JuliaParallel/MPI.jl
  latest_release: v0.20.16
  readme: '<h1 id="user-content-mpi-interface-for-the-julia-language"><a class="heading-link"
    href="#mpi-interface-for-the-julia-language">MPI interface for the Julia language<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="https://juliaparallel.github.io/MPI.jl/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667"
    alt="Docs latest" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667"
    alt="Docs stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml"><img
    src="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml/badge.svg"
    alt="Unit Tests" style="max-width: 100%;"></a>

    <a href="https://buildkite.com/julialang/mpi-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/87debbd756a8b45df7ac1f25dc034436051f7ccfe155df49f1ec1f6209e51caf/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65643831336263346437396635353761646264623832316231633863386465393839393936383665363937646634613337332e7376673f6272616e63683d6d6173746572"
    alt="GPU tests" data-canonical-src="https://badge.buildkite.com/ed813bc4d79f557adbdb821b1c8c8de98999686e697df4a373.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00ad86424fd334dccd9dde2876e4f3e82b84ad4219e5c1661d6a06b63f46f516/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f4d50492e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572"
    alt="codecov.io" data-canonical-src="https://codecov.io/github/JuliaParallel/MPI.jl/coverage.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://coveralls.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/4d989c928ad758732dcf79e5d1a0b592a1765763c2237af784955ed806e37ef1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f4d50492e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaParallel/MPI.jl/badge.svg?branch=master&amp;service=github"
    style="max-width: 100%;"></a></p>

    <p>This provides <a href="http://julialang.org/" rel="nofollow">Julia</a> interface
    to the Message Passing Interface (<a href="http://www.mpi-forum.org/" rel="nofollow">MPI</a>),
    roughly inspired by <a href="https://github.com/mpi4py/mpi4py/">mpi4py</a>.</p>

    <p>Please see the <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow">documentation</a>
    for instructions on <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/"
    rel="nofollow">configuration</a> and <a href="https://juliaparallel.github.io/MPI.jl/stable/usage/"
    rel="nofollow">usage</a>.</p>

    <p><strong>Breaking changes with v0.20:</strong> The way how MPI.jl is configured
    to use

    different MPI implementations has changed from v0.19 to v0.20 in a

    <em>non-backward-compatible</em> manner.

    Specifically, most <code>JULIA_MPI_XXX</code> variables do not have an effect
    anymore.

    Please refer to the

    <a href="https://juliaparallel.org/MPI.jl/stable/configuration/#Migration-from-MPI.jl-v0.19-or-earlier"
    rel="nofollow">docs</a>

    for information on how to migrate your existing configuration.</p>

    <h1 id="user-content-help-and-discussion"><a class="heading-link" href="#help-and-discussion">Help
    and discussion<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>For help and discussion, we suggest asking on the following venues:</p>

    <ul>

    <li><a href="https://discourse.julialang.org/c/domain/parallel/34" rel="nofollow">"Julia
    at Scale" topic on the Julia Discourse</a></li>

    <li>#distributed channel on the <a href="https://julialang.slack.com/" rel="nofollow">Julia
    Slack</a> (visit <a href="https://julialang.org/slack/" rel="nofollow">https://julialang.org/slack/</a>
    to join).</li>

    </ul>

    <h1 id="user-content-contributing"><a class="heading-link" href="#contributing">Contributing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Contributions are encouraged. In particular, MPI provides several hundred functions,
    only a small number of which are currently exposed. If there are additional functions
    you would like to use, please open an <a href="https://github.com/JuliaParallel/MPI.jl/issues">issue</a>
    or <a href="https://github.com/JuliaParallel/MPI.jl/pulls">pull request</a>.</p>

    <p>Additional examples and documentation improvements are also very welcome.</p>

    <h1 id="user-content-citation"><a class="heading-link" href="#citation">Citation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>If you use MPI.jl in your work, please cite the following paper:</p>

    <blockquote>

    <p>Simon Byrne, Lucas C. Wilcox, and Valentin Churavy (2021) "MPI.jl: Julia bindings
    for the Message Passing Interface". <em>JuliaCon Proceedings</em>, 1(1), 68, doi:
    <a href="https://doi.org/10.21105/jcon.00068" rel="nofollow">10.21105/jcon.00068</a></p>

    </blockquote>

    '
  stargazers_count: 336
  subscribers_count: 19
  topics:
  - mpi
  - julia
  - hpc
  - julia-language
  - mpich
  - openmpi
  - microsoft-mpi
  updated_at: 1695403279.0
JuliaPelzer/Phd_simulation_groundtruth:
  data_format: 2
  description: pflotran .in-files for testcases
  filenames:
  - installs/spack.yaml
  full_name: JuliaPelzer/Phd_simulation_groundtruth
  latest_release: null
  readme: '<h1 id="user-content-prerequisite-installs"><a class="heading-link" href="#prerequisite-installs">Prerequisite
    (installs)<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <ul>

    <li>pflotran (explanation below)</li>

    <li>python 3.8.10 or newer (tested with this version)</li>

    <li>python packages (installation via pip possible): numpy, noise</li>

    <li>bash 5.0.17 or newer (tested with this version)</li>

    </ul>

    <h2 id="user-content-how-to-install-pflotran-using-spack"><a class="heading-link"
    href="#how-to-install-pflotran-using-spack">How to install Pflotran using spack:<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code></p>

    <p><code>. spack/share/spack/setup-env.sh</code></p>

    <p>copy <code>spack.yaml</code> (pflotran specific) to folder and go there (e.g.
    "cd test_nn/installs/")</p>

    <p><code>spack env activate .</code></p>

    <p><code>spack install</code> / <code>spack install pflotran</code></p>

    <blockquote>

    <p><strong>Note</strong>

    need internet access for it</p>

    </blockquote>

    <h3 id="user-content-next-login"><a class="heading-link" href="#next-login">next
    login:<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p><code>cd ../</code>

    <code>. spack/share/spack/setup-env.sh</code></p>

    <p>go to folder with <code>spack.yaml</code> (e.g. test_nn/installs)</p>

    <p><code>spack env activate .</code></p>

    <p><code>spack install pflotran</code></p>

    <h1 id="user-content-phd_simulation_groundtruth"><a class="heading-link" href="#phd_simulation_groundtruth">Phd_simulation_groundtruth<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>builds datasets with definable number of data points; based on one pflotran.in
    file, varying pressure gradients in external <code>.txt</code> file (and varying
    permeability fields based on <code>perlin_noise</code> in external <code>.h5</code>
    files)</p>

    <h2 id="user-content-if-you-use-this-script-on-a-new-computer"><a class="heading-link"
    href="#if-you-use-this-script-on-a-new-computer">If you use this script on a new
    computer<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>remember to copy all (!) required files (see <code>/dummy_dataset</code> +
    <code>*.sh</code> bash-script + <code>/scripts</code> and <code>test_*.py</code>)</li>

    <li>if you run the script for a varying permeability field, check that you have
    all required files in dummy_dataset:

    <ul>

    <li><code>pflotran_vary_perm.in</code></li>

    <li><code>settings.yaml</code></li>

    </ul>

    </li>

    <li>set the <code>$PFLOTRAN_DIR</code> (in <code>~/.zshrc</code> or <code>~/.bashrc</code>
    or similar)</li>

    </ul>

    <h2 id="user-content-how-to-run-the-script"><a class="heading-link" href="#how-to-run-the-script">How
    to run the script<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>always start from the dataset-directory where dummy_dataset, bash-script and
    scripts are located</li>

    <li>the datasets you want to simulate will be created in a subfolder</li>

    <li>run script via <code>bash &lt;name_of_script&gt;</code> (here <code>&lt;name_of_script&gt;</code>
    is <code>make_dataset_vary_perm.sh</code>) <code>&lt;CLA_NUMBER_VARIATIONS_PRESSURE&gt;
    &lt;CLA_PRESSURE_CASE&gt; &lt;CLA_NUMBER_VARIATIONS_PERMEABILITY&gt; &lt;CLA_PERM_CASE&gt;
    &lt;CLA_DIMENSIONS&gt; &lt;CLA_NAME&gt; &lt;CLA_VISUALISATION&gt;</code> with
    the respective commandline arguments

    -CLA_NUMBER_VARIATIONS_PRESSURE and CLA_NUMBER_VARIATIONS_PERMEABILITY: number
    of variations of pressure and permeability field (e.g. 10 10)

    <ul>

    <li>CLA_PRESSURE_CASE currently has two options: "1D" creates a dataset with a
    constant pressure field that only varies in the y-component (MOST LIKELY WHAT
    YOU WANT); "2D" creates a dataset with a constant pressure field that varies in
    the x- and y-component</li>

    <li>CLA_PERM_CASE currently has two options: "vary" creates a dataset with a varying
    permeability field (through perlin noise); "iso" creates a dataset with a constant
    permeability field</li>

    <li>CLA_DIMENSIONS: whether the dataset should be 2D or 3D</li>

    <li>CLA_NAME is the name of the dataset to create, i.e. of the subfolder to create
    in the current directory</li>

    <li>CLA_VISULISATION is an <strong>optional</strong> commandline argument defining
    whether to produce some automated pictures (selfmade in python) : if you want
    it, write "vis" as CLA_VISUALISATION, else leave it empty</li>

    </ul>

    </li>

    </ul>

    <h2 id="user-content-if-you-encounter-an-unexpected-error"><a class="heading-link"
    href="#if-you-encounter-an-unexpected-error">If you encounter an unexpected error<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>you can see that e.g. if a file fort.86 is produced</li>

    <li>comment <code>-screen_output off</code> out in the bash-script to get a log
    output from pflotran</li>

    </ul>

    <h2 id="user-content-how-to-change-the-size-of-the-domain"><a class="heading-link"
    href="#how-to-change-the-size-of-the-domain">How to change the size of the domain<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>

    <code>pflotran.in</code> :

    <ul>

    <li>adapt <code>REGION all</code> if domain should be larger than 200x2000x100m</li>

    </ul>

    </li>

    <li>change the <code>size</code> and <code>ncells</code> in <code>settings.yaml</code>

    </li>

    <li>check whether the heat pump is still located reasonably and if you change
    that position, remember to adapt the visualization and slicing as well</li>

    <li>you probably also want to change the frequency (for the permeability field)
    in <code>settings.yaml</code> <code>settings.frequency = (4,4,2)</code>

    </li>

    </ul>

    <h2 id="user-content-how-to-get-vtk-output-to-view-in-paraview"><a class="heading-link"
    href="#how-to-get-vtk-output-to-view-in-paraview">How to get vtk output to view
    in paraview<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>in <code>pflotran.in</code> change the following line:

    <ul>

    <li>

    <code>FORMAT VTK</code> (approx. line 213)</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1692464013.0
LLNL/DiHydrogen:
  data_format: 2
  description: null
  filenames:
  - .gitlab/spack/environments/corona/spack.yaml
  - .gitlab/spack/environments/quartz/spack.yaml
  - .gitlab/spack/environments/pascal/spack.yaml
  full_name: LLNL/DiHydrogen
  latest_release: v0.2.1
  readme: '<h1 id="user-content-dihydrogen"><a class="heading-link" href="#dihydrogen">DiHydrogen<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>DiHydrogen is the second version of the

    <a href="https://github.com/llnl/elemental">Hydrogen</a> fork of the well-known

    distributed linear algebra library,

    <a href="https://github.com/elemental/elemental">Elemental</a>.  DiHydrogen aims

    to be a basic distributed multilinear algebra interface with a

    particular emphasis on the needs of the distributed machine learning

    effort, <a href="https://github.com/llnl/lbann">LBANN</a>.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>DiHydrogen is distributed under the terms of the Apache License (Version 2.0).</p>

    <p>All new contributions must be made under the Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/LLNL/DiHydrogen/blob/develop/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/NOTICE">NOTICE</a> for
    details.</p>

    <p>SPDX-License-Identifier: Apache-2.0</p>

    <p>LLNL-CODE-800100</p>

    '
  stargazers_count: 4
  subscribers_count: 11
  topics:
  - cpp
  - math-physics
  updated_at: 1680394625.0
LLNL/Umpire:
  data_format: 2
  description: An application-focused API for memory management on NUMA & GPU architectures
  filenames:
  - .spack_env/llnl/spack.yaml
  - .spack_env/darwin/spack.yaml
  full_name: LLNL/Umpire
  latest_release: v2023.06.0
  readme: '<h1 id="user-content---umpire-v2023060"><a class="heading-link" href="#--umpire-v2023060">

    <img src="https://camo.githubusercontent.com/81bd6212d0dd884f5a1d99f54f5b792596f42ad2d6643791a885b7ff42aad41e/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"
    width="128" valign="middle" alt="Umpire" data-canonical-src="https://cdn.rawgit.com/LLNL/Umpire/develop/share/umpire/logo/umpire-logo.png"
    style="max-width: 100%;">  Umpire v2023.06.0<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h1>

    <p><a href="https://travis-ci.com/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/36f0f474aacbade149e980682a28b1b97aa3ea7737006edce896fa4ebbc9ffa7/68747470733a2f2f7472617669732d63692e636f6d2f4c4c4e4c2f556d706972652e7376673f6272616e63683d646576656c6f70"
    alt="Travis Build Status" data-canonical-src="https://travis-ci.com/LLNL/Umpire.svg?branch=develop"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/davidbeckingsale/Umpire/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/615ebc663bd8e7bce0a236693071d360c1f3d4b04bfabb454ba50068b0bac3c0/68747470733a2f2f6465762e617a7572652e636f6d2f64617669646265636b696e6773616c652f556d706972652f5f617069732f6275696c642f7374617475732f4c4c4e4c2e556d706972653f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/davidbeckingsale/Umpire/_apis/build/status/LLNL.Umpire?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://umpire.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/7fd7eef5a102528cae391ff45e9ae1026690d979c1413498b1604b23febeffaf/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756d706972652f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/umpire/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/d567cb288d0416a63a2faa83e8b2d5265860c1a3e9af604f4b6730340fa830c7/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f556d706972652f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/Umpire/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a> <a href="https://gitter.im/LLNL/Umpire?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/d812b594e8c008b20bc4b4e508035cb3ffd814a168debe18107da92e6c7e5f88/68747470733a2f2f6261646765732e6769747465722e696d2f4c4c4e4c2f556d706972652e737667"
    alt="Join the chat at https://gitter.im/LLNL/Umpire" data-canonical-src="https://badges.gitter.im/LLNL/Umpire.svg"
    style="max-width: 100%;"></a></p>

    <p>Umpire is a resource management library that allows the discovery, provision,

    and management of memory on machines with multiple memory devices like NUMA and
    GPUs.</p>

    <p>Umpire uses CMake and BLT to handle builds. Since BLT is included as a

    submodule, first make sure you run:</p>

    <pre><code>$ git submodule init &amp;&amp; git submodule update

    </code></pre>

    <p>Then, make sure that you have a modern compiler loaded, and the configuration
    is as

    simple as:</p>

    <pre><code>$ mkdir build &amp;&amp; cd build

    $ cmake ..

    </code></pre>

    <p>CMake will provide output about which compiler is being used. Once CMake has

    completed, Umpire can be built with Make:</p>

    <pre><code>$ make

    </code></pre>

    <p>For more advanced configuration you can use standard CMake variables.</p>

    <h1 id="user-content-documentation"><a class="heading-link" href="#documentation">Documentation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Both user and code documentation is available <a href="http://umpire.readthedocs.io/"
    rel="nofollow">here</a>.</p>

    <p>The Umpire <a href="https://umpire.readthedocs.io/en/develop/sphinx/tutorial.html"
    rel="nofollow">tutorial</a> provides a step by step introduction to Umpire features.</p>

    <p>If you have build problems, we have comprehensive <a href="https://umpire.readthedocs.io/en/develop/sphinx/advanced_configuration.html"
    rel="nofollow">build system documentation</a> too!</p>

    <h1 id="user-content-getting-involved"><a class="heading-link" href="#getting-involved">Getting
    Involved<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Umpire is an open-source project, and we welcome contributions from the community.</p>

    <h2 id="user-content-mailing-list"><a class="heading-link" href="#mailing-list">Mailing
    List<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The Umpire mailing list is hosted on Google Groups, and is a great place to
    ask questions:</p>

    <ul>

    <li><a href="https://groups.google.com/forum/#!forum/umpire-users" rel="nofollow">Umpire
    Users Google Group</a></li>

    </ul>

    <h2 id="user-content-contributions"><a class="heading-link" href="#contributions">Contributions<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits; it''s all great!</p>

    <p>To contribute, make a <a href="https://github.com/LLNL/Umpire/compare">pull
    request</a>, with <code>develop</code> as the destination branch.

    We use Travis to run CI tests, and your branch must pass these tests before being
    merged.</p>

    <p>For more information, see the <a href="https://github.com/LLNL/Umpire/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h1 id="user-content-authors"><a class="heading-link" href="#authors">Authors<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Thanks to all of Umpire''s

    <a href="https://github.com/LLNL/Umpire/graphs/contributors">contributors</a>.</p>

    <p>Umpire was created by David Beckingsale (<a href="mailto:david@llnl.gov">david@llnl.gov</a>).</p>

    <h2 id="user-content-citing-umpire"><a class="heading-link" href="#citing-umpire">Citing
    Umpire<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>If you are referencing Umpire in a publication, please use the following citation:</p>

    <ul>

    <li>D. Beckingsale, M. Mcfadden, J. Dahm, R. Pankajakshan and R. Hornung, <a href="https://ieeexplore.ieee.org/document/8907404"
    rel="nofollow">"Umpire: Application-Focused Management and Coordination of Complex
    Hierarchical Memory,"</a> in IBM Journal of Research and Development. 2019. doi:
    10.1147/JRD.2019.2954403</li>

    </ul>

    <h1 id="user-content-release"><a class="heading-link" href="#release">Release<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Umpire is released under an MIT license. For more details, please see the

    <a href="./LICENSE">LICENSE</a> and <a href="./RELEASE">RELEASE</a> files.</p>

    <p><code>LLNL-CODE-747640</code>

    <code>OCEC-18-031</code></p>

    '
  stargazers_count: 272
  subscribers_count: 15
  topics:
  - hpc
  - memory-management
  - gpu
  - blt
  - portability
  - radiuss
  - cpp
  updated_at: 1697212244.0
LLNL/UnifyFS:
  data_format: 2
  description: 'UnifyFS: A file system for burst buffers'
  filenames:
  - .spack-env/unifyfs-slurm-gcc4_9_3/spack.yaml
  - .spack-env/unifyfs-slurm-gcc10_2_1/spack.yaml
  - .spack-env/unifyfs-lsf-gcc4_9_3/spack.yaml
  full_name: LLNL/UnifyFS
  latest_release: v1.1
  readme: "<h1 id=\"user-content-unifyfs-a-distributed-burst-buffer-file-system\"\
    ><a class=\"heading-link\" href=\"#unifyfs-a-distributed-burst-buffer-file-system\"\
    >UnifyFS: A Distributed Burst Buffer File System<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h1>\n<p>Node-local burst buffers are becoming\
    \ an indispensable hardware resource on\nlarge-scale supercomputers to buffer\
    \ the bursty I/O from scientific\napplications. However, there is a lack of software\
    \ support for burst buffers to\nbe efficiently shared by applications within a\
    \ batch-submitted job and recycled\nacross different batch jobs. In addition,\
    \ burst buffers need to cope with a\nvariety of challenging I/O patterns from\
    \ data-intensive scientific\napplications.</p>\n<p>UnifyFS is a user-level burst\
    \ buffer file system under active development.\nUnifyFS supports scalable and\
    \ efficient aggregation of I/O bandwidth from burst\nbuffers while having the\
    \ same life cycle as a batch-submitted job. While UnifyFS\nis designed for N-N\
    \ write/read, UnifyFS compliments its functionality with the\nsupport for N-1\
    \ write/read. It efficiently accelerates scientific I/O based on\nscalable metadata\
    \ indexing, co-located I/O delegation, and server-side read\nclustering and pipelining.</p>\n\
    <h2 id=\"user-content-documentation\"><a class=\"heading-link\" href=\"#documentation\"\
    >Documentation<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>UnifyFS documentation is at <a href=\"https://unifyfs.readthedocs.io\" rel=\"\
    nofollow\">https://unifyfs.readthedocs.io</a>.</p>\n<p>For instructions on how\
    \ to build and install UnifyFS,\nsee <a href=\"http://unifyfs.readthedocs.io/en/dev/build.html\"\
    \ rel=\"nofollow\">Build UnifyFS</a>.</p>\n<h2 id=\"user-content-build-status\"\
    ><a class=\"heading-link\" href=\"#build-status\">Build Status<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Status of UnifyFS development\
    \ branch (dev):</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"\
    https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    ><img src=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://unifyfs.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e83e6f0dfc2d353a5c6d482643646205f8fcc8e0b3327cb32dc9b27292e16823/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756e69667966732f62616467652f3f76657273696f6e3d646576\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/unifyfs/badge/?version=dev\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2 id=\"user-content-unifyfs-citation\"\
    ><a class=\"heading-link\" href=\"#unifyfs-citation\">UnifyFS Citation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>We recommend that you\
    \ use this citation for UnifyFS:</p>\n<ul>\n<li>Michael Brim, Adam Moody, Seung-Hwan\
    \ Lim, Ross Miller, Swen Boehm, Cameron Stanavige, Kathryn Mohror, Sarp Oral,\
    \ \u201CUnifyFS: A User-level Shared File System for Unified Access to Distributed\
    \ Local Storage,\u201D 37th IEEE International Parallel &amp; Distributed Processing\
    \ Symposium (IPDPS 2023), St. Petersburg, FL, May 2023.</li>\n</ul>\n<h2 id=\"\
    user-content-contribute-and-develop\"><a class=\"heading-link\" href=\"#contribute-and-develop\"\
    >Contribute and Develop<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>If you would like to help, please see our <a href=\"https://unifyfs.readthedocs.io/en/dev/contribute-ways.html\"\
    \ rel=\"nofollow\">contributing guidelines</a>.</p>\n"
  stargazers_count: 92
  subscribers_count: 20
  topics:
  - system-software
  - burst-buffers
  - file-system
  updated_at: 1696778378.0
LLNL/axom:
  data_format: 2
  description: CS infrastructure components for HPC applications
  filenames:
  - scripts/spack/configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/toss_3_x86_64_ib/spack.yaml
  - scripts/spack/configs/blueos_3_ppc64le_ib_p9/spack.yaml
  - scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/linux_ubuntu_20/spack.yaml
  - scripts/spack/devtools_configs/toss_3_x86_64_ib/spack.yaml
  full_name: LLNL/axom
  latest_release: v0.8.1
  readme: '<h1 id=""><a class="heading-link" href="#"><img src="/share/axom/logo/axom_logo_transparent.png?raw=true"
    width="250" valign="middle" alt="Axom" style="max-width: 100%;"><span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <p><a href="https://dev.azure.com/axom/axom/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/1e537c454d83150c4b7bfb804bc21f0072b06abd9dfb3b512cda35bbd87cfa74/68747470733a2f2f6465762e617a7572652e636f6d2f61786f6d2f61786f6d2f5f617069732f6275696c642f7374617475732f4c4c4e4c2e61786f6d3f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/axom/axom/_apis/build/status/LLNL.axom?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://axom.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/0d1ad2943bef54d4b2dd8e5e6161872f93eb95a7b28498913b3b7c71c977b686/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f61786f6d2f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/axom/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/blob/develop/LICENSE"><img src="https://camo.githubusercontent.com/8ccf186e7288af6d88a1f6a930c0fcc4e7a8a9936b34e07629d815d1eab4d977/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/License-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/releases/latest"><img src="https://camo.githubusercontent.com/7e96e2e62e0ae13e391856d4c9a26779fb83684be5dd6274d812ce8c4c75e800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4c4c4e4c2f61786f6d2e737667"
    alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/LLNL/axom.svg"
    style="max-width: 100%;"></a></p>

    <p>Axom provides robust, flexible software infrastructure for the development
    of multi-physics applications and computational tools.</p>

    <h2 id="user-content-documentation"><a class="heading-link" href="#documentation">Documentation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Latest docs on Develop branch: <a href="https://axom.readthedocs.io" rel="nofollow">https://axom.readthedocs.io</a></p>

    <p>To access docs for other versions: <a href="https://readthedocs.org/projects/axom/"
    rel="nofollow">https://readthedocs.org/projects/axom/</a></p>

    <h2 id="user-content-getting-involved"><a class="heading-link" href="#getting-involved">Getting
    Involved<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Axom is an open-source project and we welcome contributions from the community.</p>

    <h2 id="user-content-mailing-list"><a class="heading-link" href="#mailing-list">Mailing
    List<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The project maintains two email lists:</p>

    <ul>

    <li>''<a href="mailto:axom-users@llnl.gov">axom-users@llnl.gov</a>'' is how Axom
    users can contact developers for questions, report issues, etc.</li>

    <li>''<a href="mailto:axom-dev@llnl.gov">axom-dev@llnl.gov</a>'' is for communication
    among team members.</li>

    </ul>

    <h2 id="user-content-contributions"><a class="heading-link" href="#contributions">Contributions<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits.</p>

    <p>To contribute, make a <a href="https://github.com/llnl/axom/compare">pull request</a>,
    with <code>develop</code>

    as the destination branch. We use CI testing and your branch must pass these tests
    before

    being merged.</p>

    <p>For more information, see the <a href="https://github.com/llnl/axom/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h2 id="user-content-authors"><a class="heading-link" href="#authors">Authors<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Thanks to all of Axom''s

    <a href="https://github.com/llnl/axom/graphs/contributors">contributors</a>.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Copyright (c) 2017-2023, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Axom project are retained by contributors.

    No copyright assignment is required to contribute to Axom.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution

    <code>LLNL-CODE-741217</code> <code>OCEC-17-187</code></p>

    <h2 id="user-content-spdx-usage"><a class="heading-link" href="#spdx-usage">SPDX
    usage<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2 id="user-content-external-packages"><a class="heading-link" href="#external-packages">External
    Packages<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Axom bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: CLI11<br>

    PackageHomePage: <a href="https://github.com/CLIUtils/CLI11">https://github.com/CLIUtils/CLI11</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: fmt<br>

    PackageHomePage: <a href="https://github.com/fmtlib/fmt">https://github.com/fmtlib/fmt</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sol<br>

    PackageHomePage: <a href="https://github.com/ThePhD/sol2">https://github.com/ThePhD/sol2</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sparsehash<br>

    PackageHomePage: <a href="https://github.com/sparsehash/sparsehash">https://github.com/sparsehash/sparsehash</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 115
  subscribers_count: 22
  topics:
  - hpc
  - parallel-computing
  - llnl
  - cpp
  - c-plus-plus
  - app-infrastructure
  - radiuss
  - fortran
  updated_at: 1695976046.0
LLNL/hiop:
  data_format: 2
  description: HPC solver for nonlinear optimization problems
  filenames:
  - scripts/platforms/summit/spack.yaml
  - scripts/platforms/marianas/spack.yaml
  - scripts/platforms/newell/spack.yaml
  full_name: LLNL/hiop
  latest_release: v1.0.1
  readme: "<h1 id=\"user-content-hiop---hpc-solver-for-optimization\"><a class=\"\
    heading-link\" href=\"#hiop---hpc-solver-for-optimization\">HiOp - HPC solver\
    \ for optimization<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\"\
    ><img src=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\" alt=\"tests\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>HiOp is an optimization solver for solving\
    \ certain mathematical optimization problems expressed as nonlinear programming\
    \ problems. HiOp is a lightweight HPC solver that leverages application's existing\
    \ data parallelism to parallelize the optimization iterations by using specialized\
    \ parallel linear algebra kernels.</p>\n<p>Please cite the user manual whenever\
    \ HiOp is used:</p>\n<pre><code>@TECHREPORT{hiop_techrep,\n  title={{HiOp} --\
    \ {U}ser {G}uide},\n  author={Petra, Cosmin G. and Chiang, NaiYuan and Jingyi\
    \ Wang},\n  year={2018},\n  institution = {Center for Applied Scientific Computing,\
    \ Lawrence Livermore National Laboratory},\n  number = {LLNL-SM-743591}\n}\n</code></pre>\n\
    <p>In addition, when using the quasi-Newton solver please cite:</p>\n<pre><code>@ARTICLE{Petra_18_hiopdecomp,\n\
    title = {A memory-distributed quasi-Newton solver for nonlinear programming problems\
    \ with a small number of general constraints},\njournal = {Journal of Parallel\
    \ and Distributed Computing},\nvolume = {133},\npages = {337-348},\nyear = {2019},\n\
    issn = {0743-7315},\ndoi = {https://doi.org/10.1016/j.jpdc.2018.10.009},\nurl\
    \ = {https://www.sciencedirect.com/science/article/pii/S0743731518307731},\nauthor\
    \ = {Cosmin G. Petra},\n}\n</code></pre>\n<p>and when using the the PriDec solver\
    \ please cite:</p>\n<pre><code>@article{wang2023,\n  archivePrefix = {arXiv},\n\
    \  author = {J. Wang and C. G. Petra},\n  title = {A Sequential Quadratic Programming\
    \ Algorithm for Nonsmooth Problems with Upper-$\\mathcal{C}^2$ Objective},\n \
    \ journal = {SIAM Journal on Optimization},\n  volume = {33},\n  number = {3},\n\
    \  pages = {2379-2405},\n  year = {2023},\n  doi = {10.1137/22M1490995}\n}\n@INPROCEEDINGS{wang2021,\n\
    \  author={J. Wang and N. Chiang and C. G. Petra},\n  booktitle={2021 20th International\
    \ Symposium on Parallel and Distributed Computing (ISPDC)}, \n  title={An asynchronous\
    \ distributed-memory optimization solver for two-stage stochastic programming\
    \ problems}, \n  year={2021},\n  volume={},\n  number={},\n  pages={33-40},\n\
    \  doi={10.1109/ISPDC52870.2021.9521613}}\n }\n</code></pre>\n<h2 id=\"user-content-buildinstall-instructions\"\
    ><a class=\"heading-link\" href=\"#buildinstall-instructions\">Build/install instructions<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>HiOp\
    \ uses a CMake-based build system. A standard build can be done by invoking in\
    \ the 'build' directory the following</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake ..\n$<span class=\"pl-k\">&gt;</span>\
    \ make \n$<span class=\"pl-k\">&gt;</span> make <span class=\"pl-c1\">test</span>\n\
    $<span class=\"pl-k\">&gt;</span> make install</pre></div>\n<p>This sequence will\
    \ build HiOp, run integrity and correctness tests, and install the headers and\
    \ the library in the directory '_dist-default-build' in HiOp's root directory.</p>\n\
    <p>Command <code>make test</code> runs extensive tests of the various modules\
    \ of HiOp to check integrity and correctness. The tests suite range from unit\
    \ testing to solving concrete optimization problems and checking the performance\
    \ of HiOp solvers on these problems against known solutions. By default <code>make\
    \ test</code> runs <code>mpirun</code> locally, which may not work on some HPC\
    \ machines. For these HiOp allows using <code>bsub</code> to schedule <code>make\
    \ test</code> on the compute nodes; to enable this, the use should use <em>-DHIOP_TEST_WITH_BSUB=ON</em>\
    \ with cmake when building and run <code>make test</code> in a bsub shell session,\
    \ for example,</p>\n<pre><code>bsub -P your_proj_name -nnodes 1 -W 30\nmake test\n\
    CTRL+D\n</code></pre>\n<p>The installation can be customized using the standard\
    \ CMake options. For example, one can provide an alternative installation directory\
    \ for HiOp by using</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span\
    \ class=\"pl-k\">&gt;</span> cmake -DCMAKE_INSTALL_PREFIX=/usr/lib/hiop ..<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span></span></pre></div>\n<h3 id=\"\
    user-content-selected-hiop-specific-build-options\"><a class=\"heading-link\"\
    \ href=\"#selected-hiop-specific-build-options\">Selected HiOp-specific build\
    \ options<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <ul>\n<li>Enable/disable MPI: <em>-DHIOP_USE_MPI=[ON/OFF]</em> (by default ON)</li>\n\
    <li>GPU support: <em>-DHIOP_USE_GPU=ON</em>. MPI can be either off or on. For\
    \ more build system options related to GPUs, see \"Dependencies\" section below.</li>\n\
    <li>Enable/disable \"developer mode\" build that enforces more restrictive compiler\
    \ rules and guidelines: <em>-DHIOP_DEVELOPER_MODE=ON</em>. This option is by default\
    \ off.</li>\n<li>Additional checks and self-diagnostics inside HiOp meant to detect\
    \ abnormalities and help to detect bugs and/or troubleshoot problematic instances:\
    \ <em>-DHIOP_DEEPCHECKS=[ON/OFF]</em> (by default ON). Disabling HIOP_DEEPCHECKS\
    \ usually provides 30-40% execution speedup in HiOp. For full strength, it is\
    \ recommended to use HIOP_DEEPCHECKS with debug builds. With non-debug builds,\
    \ in particular the ones that disable the assert macro, HIOP_DEEPCHECKS does not\
    \ perform all checks and, thus, may overlook potential issues.</li>\n</ul>\n<p>For\
    \ example:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span class=\"\
    pl-k\">&gt;</span> cmake -DHIOP_USE_MPI=ON -DHIOP_DEEPCHECKS=ON ..\n$<span class=\"\
    pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span> make <span class=\"\
    pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make install</pre></div>\n\
    <h3 id=\"user-content-other-useful-options-to-use-with-cmake\"><a class=\"heading-link\"\
    \ href=\"#other-useful-options-to-use-with-cmake\">Other useful options to use\
    \ with CMake<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <ul>\n<li>\n<em>-DCMAKE_BUILD_TYPE=Release</em> will build the code with the optimization\
    \ flags on</li>\n<li>\n<em>-DCMAKE_CXX_FLAGS=\"-O3\"</em> will enable a high level\
    \ of compiler code optimization</li>\n</ul>\n<h3 id=\"user-content-dependencies\"\
    ><a class=\"heading-link\" href=\"#dependencies\">Dependencies<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>A complete list of\
    \ dependencies is maintained <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/hiop/package.py\"\
    >here</a>.</p>\n<p>For a minimal build, HiOp requires LAPACK and BLAS. These dependencies\
    \ are automatically detected by the build system. MPI is optional and by default\
    \ enabled. To disable use cmake option '-DHIOP_USE_MPI=OFF'.</p>\n<p>HiOp has\
    \ support for NVIDIA <strong>GPU-based computations</strong> via CUDA and Magma.\
    \ To enable the use of GPUs, use cmake with '-DHIOP_USE_GPU=ON'. The build system\
    \ will automatically search for CUDA Toolkit. For non-standard CUDA Toolkit installations,\
    \ use '-DHIOP_CUDA_LIB_DIR=/path' and '-DHIOP_CUDA_INCLUDE_DIR=/path'. For \"\
    very\" non-standard CUDA Toolkit installations, one can specify the directory\
    \ of cuBlas libraries as well with '-DHIOP_CUBLAS_LIB_DIR=/path'.</p>\n<h3 id=\"\
    user-content-using-raja-and-umpire-portability-libraries\"><a class=\"heading-link\"\
    \ href=\"#using-raja-and-umpire-portability-libraries\">Using RAJA and Umpire\
    \ portability libraries<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<p>Portability libraries allow running HiOp's linear algebra\
    \ either on host (CPU) or a device (GPU). RAJA and Umpire are disabled by default.\
    \ You can turn them on together by passing <code>-DHIOP_USE_RAJA=ON</code> to\
    \ CMake. If the two libraries are not automatically found, specify their installation\
    \ directories like this:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_RAJA=ON -DRAJA_DIR=/path/to/raja/dir\
    \ -Dumpire_DIR=/path/to/umpire/dir</pre></div>\n<p>If the GPU support is enabled,\
    \ RAJA will run all HiOp linear algebra kernels on GPU, otherwise RAJA will run\
    \ the kernels on CPU using an OpenMP execution policy.</p>\n<h3 id=\"user-content-support-for-gpu-computations\"\
    ><a class=\"heading-link\" href=\"#support-for-gpu-computations\">Support for\
    \ GPU computations<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>When GPU support is on, HiOp requires Magma linear solver library and CUDA\
    \ Toolkit. Both are detected automatically in most cases. The typical cmake command\
    \ to enable GPU support in HiOp is</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_GPU=ON ..</pre></div>\n\
    <p>When Magma is not detected, one can specify its location by passing <code>-DHIOP_MAGMA_DIR=/path/to/magma/dir</code>\
    \ to cmake.</p>\n<p>For custom CUDA Toolkit installations, the locations to the\
    \ (missing/not found) CUDA libraries can be specified to cmake via <code>-DNAME=/path/cuda/directory/lib</code>,\
    \ where <code>NAME</code> can be any of</p>\n<pre><code>CUDA_cublas_LIBRARY\n\
    CUDA_CUDART_LIBRARY\nCUDA_cudadevrt_LIBRARY\nCUDA_cusparse_LIBRARY\nCUDA_cublasLt_LIBRARY\n\
    CUDA_nvblas_LIBRARY\nCUDA_culibos_LIBRARY\n</code></pre>\n<p>Below is an example\
    \ for specifiying <code>cuBlas</code>, <code>cuBlasLt</code>, and <code>nvblas</code>\
    \ libraries, which were <code>NOT_FOUND</code> because of a non-standard CUDA\
    \ Toolkit instalation:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span\
    \ class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_GPU=ON -DCUDA_cublas_LIBRARY=/usr/local/cuda-10.2/targets/x86_64-linux/lib/lib64\
    \ -DCUDA_cublasLt_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ -DCUDA_nvblas_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>A detailed example on how to compile HiOp straight\
    \ of the box on <code>summit.olcf.ornl.gov</code> is available <a href=\"README_summit.md\"\
    >here</a>.</p>\n<p>RAJA and UMPIRE dependencies are usually detected by HiOp's\
    \ cmake build system.</p>\n<h3 id=\"user-content-kron-reduction\"><a class=\"\
    heading-link\" href=\"#kron-reduction\">Kron reduction<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h3>\n<p>Kron reduction functionality\
    \ of HiOp is disabled by default. One can enable it by using</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> rm -rf\
    \ <span class=\"pl-k\">*</span><span class=\"pl-k\">;</span> cmake -DHIOP_WITH_KRON_REDUCTION=ON\
    \ -DUMFPACK_DIR=/Users/petra1/work/installs/SuiteSparse-5.7.1 -DMETIS_DIR=/Users/petra1/work/installs/metis-4.0.3\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>Metis is usually detected automatically and needs\
    \ not be specified under normal circumstances.</p>\n<p>UMFPACK (part of SuiteSparse)\
    \ and METIS need to be provided as shown above.</p>\n<h1 id=\"user-content-interfacing-with-hiop\"\
    ><a class=\"heading-link\" href=\"#interfacing-with-hiop\">Interfacing with HiOp<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>HiOp\
    \ supports three types of optimization problems, each with a separate input formats\
    \ in the form of the C++ interfaces <code>hiopInterfaceDenseConstraints</code>,<code>hiopInterfaceSparse</code>\
    \ and <code>hiopInterfaceMDS</code>. These interfaces are specified in <a href=\"\
    src/Interface/hiopInterface.hpp\">hiopInterface.hpp</a> and documented and discussed\
    \ as well in the <a href=\"doc/hiop_usermanual.pdf\">user manual</a>.</p>\n<p><em><code>hiopInterfaceDenseConstraints</code>\
    \ interface</em> supports NLPs with <strong>billions</strong> of variables with\
    \ and without bounds but only limited number (&lt;100) of general, equality and\
    \ inequality constraints. The underlying algorithm is a limited-memory quasi-Newton\
    \ interior-point method and generally scales well computationally (but it may\
    \ not algorithmically) on thousands of cores. This interface uses MPI for parallelization</p>\n\
    <p><em><code>hiopInterfaceSparse</code> interface</em> supports general sparse\
    \ and large-scale NLPs. This functionality is similar to that of the state-of-the-art\
    \ <a href=\"https://github.com/coin-or/Ipopt\">Ipopt</a> (without being as robust\
    \ and flexible as Ipopt is). Acceleration for this class of problems can be achieved\
    \ via OpenMP or CUDA, however, this is work in progress and you are encouraged\
    \ to contact HiOp's developers for up-to-date information.</p>\n<p><em><code>hiopInterfaceMDS</code>\
    \ interface</em> supports mixed dense-sparse NLPs and achives parallelization\
    \ using GPUs and RAJA portability abstraction layer.</p>\n<p>More information\
    \ on the HiOp interfaces are <a href=\"src/Interface/README.md\">here</a>.</p>\n\
    <h2 id=\"user-content-running-hiop-tests-and-applications\"><a class=\"heading-link\"\
    \ href=\"#running-hiop-tests-and-applications\">Running HiOp tests and applications<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>HiOp\
    \ is using NVBlas library when built with CUDA support. If you don't specify\n\
    location of the <code>nvblas.conf</code> configuration file, you may get an annoying\n\
    warnings. HiOp provides default <code>nvblas.conf</code> file and installs it\
    \ at the same\nlocation as HiOp libraries. To use it, set environment variable\
    \ as</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ <span class=\"\
    pl-k\">export</span> NVBLAS_CONFIG_FILE=<span class=\"pl-k\">&lt;</span>hiop install\
    \ dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n<p>or, if you\
    \ are using C-shell, as</p>\n<div class=\"highlight highlight-source-shell\"><pre>$\
    \ setenv NVBLAS_CONFIG_FILE <span class=\"pl-k\">&lt;</span>hiop install dir<span\
    \ class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n<h2 id=\"user-content-existing-issues\"\
    ><a class=\"heading-link\" href=\"#existing-issues\">Existing issues<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Users are highly encouraged\
    \ to report any issues they found from using HiOp.\nOne known issue is that there\
    \ is some minor inconsistence between HiOp and linear package STRUMPACK.\nWhen\
    \ STRUMPACK is compiled with MPI (and Scalapack), user must set flag <code>HIOP_USE_MPI</code>\
    \ to <code>ON</code> when compiling HiOp.\nOtherwise HiOp won't load MPI module\
    \ and will return an error when links to STRUMPACK, since the later one requires\
    \ a valid MPI module.\nSimilarly, if both Magma and STRUMPACK are linked to HiOp,\
    \ user must guarantee the all the packages are compiled by the same CUDA compiler.\n\
    User can check other issues and their existing status from <a href=\"https://github.com/LLNL/hiop\"\
    >https://github.com/LLNL/hiop</a></p>\n<h2 id=\"user-content-acknowledgments\"\
    ><a class=\"heading-link\" href=\"#acknowledgments\">Acknowledgments<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>HiOp has been developed\
    \ under the financial support of:</p>\n<ul>\n<li>Department of Energy, Office\
    \ of Advanced Scientific Computing Research (ASCR): Exascale Computing Program\
    \ (ECP) and Applied Math Program.</li>\n<li>Department of Energy, Advanced Research\
    \ Projects Agency-Energy (ARPA\u2011E)</li>\n<li>Lawrence Livermore National Laboratory\
    \ Institutional Scientific Capability Portfolio (ISCP)</li>\n<li>Lawrence Livermore\
    \ National Laboratory, through the LDRD program</li>\n</ul>\n<h1 id=\"user-content-contributors\"\
    ><a class=\"heading-link\" href=\"#contributors\">Contributors<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>HiOp is written by\
    \ Cosmin G. Petra (<a href=\"mailto:petra1@llnl.gov\">petra1@llnl.gov</a>), Nai-Yuan\
    \ Chiang (<a href=\"mailto:chiang7@llnl.gov\">chiang7@llnl.gov</a>), and Jingyi\
    \ \"Frank\" Wang (<a href=\"mailto:wang125@llnl.gov\">wang125@llnl.gov</a>) from\
    \ LLNL and has received important contributions from Asher Mancinelli (PNNL),\
    \ Slaven Peles (ORNL), Cameron Rutherford (PNNL), Jake K. Ryan (PNNL), and Michel\
    \ Schanen (ANL).</p>\n<h1 id=\"user-content-copyright\"><a class=\"heading-link\"\
    \ href=\"#copyright\">Copyright<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p>Copyright (c) 2017-2021, Lawrence Livermore National Security,\
    \ LLC. All rights reserved. Produced at the Lawrence Livermore National Laboratory.\
    \ LLNL-CODE-742473. HiOp is free software; you can modify it and/or redistribute\
    \ it under the terms of the BSD 3-clause license. See <a href=\"/COPYRIGHT\">COPYRIGHT</a>\
    \ and <a href=\"/LICENSE\">LICENSE</a> for complete copyright and license information.</p>\n"
  stargazers_count: 196
  subscribers_count: 17
  topics:
  - hpc
  - nonlinear-optimization
  - nonlinear-programming
  - nonlinear-programming-algorithms
  - interior-point-method
  - parallel-programming
  - mpi
  - bfgs
  - quasi-newton
  - constrained-optimization
  - solver
  - optimization
  - acopf
  - gpu-support
  - cuda
  - math-physics
  - radiuss
  - interior-point-optimizer
  - nonsmooth-optimization
  - rocm
  updated_at: 1697232230.0
LLNL/radiuss-spack-testing:
  data_format: 2
  description: Gitlab CI automation of Spack testing with RADIUSS projects builds.
  filenames:
  - spack-environments/raja-suite/spack.yaml
  full_name: LLNL/radiuss-spack-testing
  latest_release: null
  readme: '<h1 id="user-content-radiuss-spack-testing"><a class="heading-link" href="#radiuss-spack-testing">RADIUSS
    Spack Testing<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>The RADIUSS project promotes and supports key High Performance Computing (HPC)
    open-source software developed at the LLNL. These tools and libraries cover a
    wide range of features a team would need to develop a modern simulation code targeting
    HPC plaftorms.</p>

    <p>RADIUSS Spack Testing is a sub-project from the RADIUSS initiative providing
    a

    testing infrastructure to test Spack Packages automatically in GitLab while

    tracking changes in Spack.</p>

    <p>Access the <a href="https://radiuss-spack-testing.readthedocs.io/" rel="nofollow">documentation</a>.</p>

    <h2 id="user-content-getting-started"><a class="heading-link" href="#getting-started">Getting
    Started<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The primary goal of this repo is to be used in Gitlab. The Gitlab CI configuration
    is such that it will use Spack pipeline feature to generate and run a pipeline
    that builds one of the environments in the <code>spack-environments</code> directory.</p>

    <p>The specific environment to be built is controlled by the CI variable <code>ENV_NAME</code>.</p>

    <h3 id="user-content-installing"><a class="heading-link" href="#installing">Installing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>This project requires no installation.</p>

    <h2 id="user-content-contributing"><a class="heading-link" href="#contributing">Contributing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Please read <a href="https://github.com/LLNL/radiuss-spack-testing/CONTRIBUTING.md">CONTRIBUTING.md</a>
    for details on our code of conduct, and the process for submitting pull requests
    to us.</p>

    <h2 id="user-content-versioning"><a class="heading-link" href="#versioning">Versioning<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>version: 1.0.0</p>

    <p>TODO: Not even sure how to handle versioning here.</p>

    <h2 id="user-content-authors"><a class="heading-link" href="#authors">Authors<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Adrien M Bernede</p>

    <p>See also the list of <a href="https://github.com/LLNL/radiuss-spack-testing/contributors">contributors</a>
    who participated in this project.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a>
    file for details</p>

    <p>All new contributions must be made under the MIT License.</p>

    <p>See <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (MIT)</p>

    <p>LLNL-CODE-793462</p>

    <h2 id="user-content-acknowledgments"><a class="heading-link" href="#acknowledgments">Acknowledgments<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics:
  - radiuss
  updated_at: 1679009672.0
LLNL/serac:
  data_format: 2
  description: Serac is a high order nonlinear thermomechanical simulation code
  filenames:
  - scripts/spack/configs/darwin/spack.yaml
  - scripts/spack/configs/linux_ubuntu_22/spack.yaml
  - scripts/spack/configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/toss_3_x86_64_ib/spack.yaml
  - scripts/spack/configs/docker/ubuntu20/spack.yaml
  - scripts/spack/devtools_configs/blueos_3_ppc64le_ib_p9/spack.yaml
  full_name: LLNL/serac
  latest_release: null
  readme: '<h1 id=""><a class="heading-link" href="#"><img src="/share/serac/logo/serac-logo-blue.png?raw=true"
    width="150" alt="Serac" style="max-width: 100%;"><span aria-hidden="true" class="octicon
    octicon-link"></span></a></h1>

    <p><a href="https://dev.azure.com/llnl-serac/serac/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/32116a71164a7fb6a2fcfe0a7c886af91fec3370119490e45e69481936df0830/68747470733a2f2f6465762e617a7572652e636f6d2f6c6c6e6c2d73657261632f73657261632f5f617069732f6275696c642f7374617475732f4c4c4e4c2e73657261633f6272616e63684e616d653d646576656c6f70"
    alt="Build Status" data-canonical-src="https://dev.azure.com/llnl-serac/serac/_apis/build/status/LLNL.serac?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://serac.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/b98a52491f8df53cc2e655f7f1ad48d32a2e3ccca2c3eee393b16cd34e237c5e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73657261632f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/serac/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/serac" rel="nofollow"><img src="https://camo.githubusercontent.com/e6930e8581d65cfcd5b1d2a091d1260ffd65fbd0a61235d5eac8bc8914abbb09/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f73657261632f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d444f344b464d504e4d30"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/serac/branch/develop/graph/badge.svg?token=DO4KFMPNM0"
    style="max-width: 100%;"></a>

    <a href="./LICENSE"><img src="https://camo.githubusercontent.com/3d6a8874ec039bb1f4d9ab5f71e22b2cbd98b9005f413da1066664ef444ec780/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/license-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>Serac is a 3D implicit nonlinear thermal-structural simulation code. Its primary
    purpose is to investigate multiphysics

    abstraction strategies and implicit finite element-based algorithm development
    for emerging computing architectures.

    It also serves as a proxy-app for LLNL''s Smith code and heavily leverages the
    <a href="https://mfem.org/" rel="nofollow">MFEM finite element library</a>.</p>

    <blockquote>

    <p>This project is under heavy development and is currently a pre-alpha release.
    Functionality and interfaces may change rapidly

    as development progresses.</p>

    </blockquote>

    <h2 id="user-content-documentation"><a class="heading-link" href="#documentation">Documentation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Build, run, and design documentation can be found at <a href="https://serac.readthedocs.io"
    rel="nofollow">readthedocs</a>.</p>

    <p>Source documentation can be found <a href="https://serac.readthedocs.io/en/latest/doxygen/html/index.html"
    rel="nofollow">here</a>.</p>

    <h2 id="user-content-contributions"><a class="heading-link" href="#contributions">Contributions<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, and documentation
    edits.</p>

    <p>For more information, see the <a href="./CONTRIBUTING.md">contributing guide</a>.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Copyright (c) 2019-2023, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Serac project are retained by contributors.

    No copyright assignment is required to contribute to Serac.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution<br>

    <code>LLNL-CODE-805541</code></p>

    <h2 id="user-content-spdx-usage"><a class="heading-link" href="#spdx-usage">SPDX
    usage<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2 id="user-content-external-packages"><a class="heading-link" href="#external-packages">External
    Packages<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Serac bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: Axom<br>

    PackageHomePage: <a href="https://github.com/LLNL/axom">https://github.com/LLNL/axom</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: MFEM<br>

    PackageHomePage: <a href="https://github.com/mfem/mfem">https://github.com/mfem/mfem</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 133
  subscribers_count: 12
  topics:
  - math-physics
  - finite-elements
  - proxy-application
  - simulation
  - cpp
  updated_at: 1697157320.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/spack-nightly/int32-double/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int64-single/spack.yaml
  - docker/sundials-ci/spack-nightly/int64-double/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.6.1
  readme: '<h1 id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><a
    class="heading-link" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers">SUNDIALS:
    SUite of Nonlinear and DIfferential/ALgebraic equation Solvers<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <h3 id="user-content-version-661-sep-2023"><a class="heading-link" href="#version-661-sep-2023">Version
    6.6.1 (Sep 2023)<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form

    $$M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form

    $$y'' = f(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form

    $$y'' = f(t,y,p), \quad y(t_0) = y_0(p)$$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form

    $$F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0''$$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form

    $$F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p)$$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form

    $$F(u) = 0 \quad \text{or} \quad G(u) = u$$</p>

    </li>

    </ul>

    <h2 id="user-content-installation"><a class="heading-link" href="#installation">Installation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2 id="user-content-support"><a class="heading-link" href="#support">Support<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2 id="user-content-contributing"><a class="heading-link" href="#contributing">Contributing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2 id="user-content-citing"><a class="heading-link" href="#citing">Citing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2 id="user-content-authors"><a class="heading-link" href="#authors">Authors<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Yu Pan, Slaven Peles, Cosmin Petra, Steven B. Roberts, H. Hunter Schwartz,

    Jean M. Sexton, Dan Shumaker, Steve G. Smith, Shahbaj Sohal, Allan G. Taylor,

    Hilari C. Tiedeman, Chris White, Ting Yan, and Ulrike M. Yang.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 399
  subscribers_count: 35
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1696462654.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 22.08/0.19.0/spack.yaml
  - 22.08/0.18.1/spack.yaml
  - 23.03/0.20.0/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<h1 id="user-content-spack-configuration-files-for-lumi"><a class="heading-link"
    href="#spack-configuration-files-for-lumi">Spack configuration files for LUMI<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 12
  topics: []
  updated_at: 1675956191.0
NCAR/spack-derecho:
  data_format: 2
  description: Spack production user software stack on the Derecho system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-derecho
  latest_release: null
  readme: '<h1 id="user-content-ncar-spack-deployment"><a class="heading-link" href="#ncar-spack-deployment">NCAR
    Spack Deployment<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>derecho</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Wed May 31 08:38:35 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>efdf06a3cf590b751676e9ebdf3114f9f1e86d47</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.06</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/derecho/23.06</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/derecho/23.06/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 3
  subscribers_count: 9
  topics: []
  updated_at: 1695826459.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1 id="user-content-ncar-spack-deployment"><a class="heading-link" href="#ncar-spack-deployment">NCAR
    Spack Deployment<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Thu Mar 30 18:51:24 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fd3fc5c8cd67abe692e5e38bae52f29fb32700a3</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.04</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/23.04</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/23.04/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 5
  subscribers_count: 13
  topics: []
  updated_at: 1684182805.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/math-libs/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/tools/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/data/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/nvhpc/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/data/spack.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - docs/spack.yaml
  - spack-configs/cori-e4s-21.02/prod/spack.yaml
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/tools/spack.yaml
  - spack-configs/perlmutter-spack-develop/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1 id=\"user-content-spack-infrastructure\"><a class=\"heading-link\"\
    \ href=\"#spack-infrastructure\">Spack Infrastructure<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h1>\n<p>The Spack Infrastructure\
    \ Project makes use of <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"\
    nofollow\">spack package manager</a> to install spack software stack on NERSC\
    \ systems. This project contains spack configuration (<code>spack.yaml</code>)\
    \ required to build the spack stacks. The spack stack is based on <a href=\"https://e4s.io/\"\
    \ rel=\"nofollow\">Extreme-Scale Scientific Software Stack</a> (E4S) where we\
    \ install spack packages provided by E4S and use the recommended spack branch.\
    \ We leverage <a href=\"https://docs.gitlab.com/ee/ci/\" rel=\"nofollow\">Gitlab\
    \ CI</a> to automate deployment to ensure reproducible and automated builds. For\
    \ more details about this project you can see the documentation at <a href=\"\
    https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <h2 id=\"user-content-software-deployment-overview\"><a class=\"heading-link\"\
    \ href=\"#software-deployment-overview\">Software Deployment Overview<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The software deployment\
    \ consist of the following steps</p>\n<ol>\n<li>Acquire Spack Configuration from\
    \ E4S project <a href=\"https://github.com/E4S-Project/e4s\">https://github.com/E4S-Project/e4s</a>\n\
    </li>\n<li>Create one or more spack configuration files (spack.yaml) with list\
    \ of E4S packages and integrate spack configuration for NERSC system</li>\n<li>Create\
    \ a Gitlab Job to trigger the pipeline for TDS and Deployment system</li>\n<li>Create\
    \ a Modulefile as entry point to stack</li>\n<li>Write User Documentation</li>\n\
    <li>Share spack configuration with open-source community</li>\n<li>Send announcement\
    \ to all NERSC users</li>\n</ol>\n<h3 id=\"user-content-step-1-acquire-spack-configuration\"\
    ><a class=\"heading-link\" href=\"#step-1-acquire-spack-configuration\">Step 1:\
    \ Acquire Spack Configuration<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<p>At NERSC, we plan our software deployment with E4S releases\
    \ which is typically every 3 months however we perform deployment every 6 months.\
    \ Once E4S has released the spack configuration we acquire the spack configuration\
    \ which is typically found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >https://github.com/E4S-Project/e4s/tree/master/environments</a>. We also acquire\
    \ the spack <a href=\"https://github.com/spack/spack/branches\">branch</a> used\
    \ by E4S team as our baseline, this would be documented in the release notes.\
    \ The name of branch map to the E4S version so version 23.05 will have a branch\
    \ <a href=\"https://github.com/spack/spack/tree/e4s-23.05\">e4s-23.05</a>.</p>\n\
    <p>Next, we copy the packages into our project and create the spack configuration</p>\n\
    <h3 id=\"user-content-step-2-create-spack-configuration\"><a class=\"heading-link\"\
    \ href=\"#step-2-create-spack-configuration\">Step 2: Create Spack Configuration<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>In\
    \ this step we create the spack configuration. First we create a sub-directory\
    \ in <em>spack-configs</em> with the naming convention to distinguish E4S version.\
    \ This typically includes the\nname of the system such as <code>cori</code> or\
    \ <code>perlmutter</code> followed by name of e4s version such as <code>e4s-23.05</code>.</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >tree -L 1 spack-configs</span>\n<span class=\"pl-c1\">spack-configs</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-20.10</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 cori-e4s-21.02</span>\n<span class=\"pl-c1\">\u251C\
    \u2500\u2500 cori-e4s-21.05</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-22.02</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-21.11</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.05</span>\n<span class=\"pl-c1\"\
    >\u251C\u2500\u2500 perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\">\u251C\u2500\
    \u2500 perlmutter-e4s-23.05</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-spack-develop</span>\n\
    <span class=\"pl-c1\">\u2514\u2500\u2500 perlmutter-user-spack</span>\n\n<span\
    \ class=\"pl-c1\">10 directories, 0 files</span></pre></div>\n<p>Inside one of\
    \ the stacks, you will see several sub-directories that are used for defining\
    \ a sub-stack. These sub-stacks correspond to <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">spack environments</a>. The <code>prod</code> directory is\
    \ used for production deployment to install from the buildcache.</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">tree -L\
    \ 3 spack-configs/perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\">spack-configs/perlmutter-e4s-22.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cce</span>\n<span class=\"pl-c1\">\u2502\
    \_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500\
    \ cuda</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 definitions.yaml</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"\
    pl-c1\">\u2514\u2500\u2500 prod</span>\n<span class=\"pl-c1\">    \u251C\u2500\
    \u2500 cce</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">    \u251C\u2500\u2500 cuda</span>\n<span class=\"pl-c1\"\
    >    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\"> \
    \   \u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">    \u2514\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">        \u2514\u2500\u2500 spack.yaml</span>\n\n<span class=\"\
    pl-c1\">9 directories, 9 files</span></pre></div>\n<p>We create a special file\
    \ named <code>definitions.yaml</code> that is used for declaring definitions that\
    \ is referenced in <code>spack.yaml</code>. This file is appended to all spack\
    \ configuration. We do this\nto ensure all specs are defined in one place.</p>\n\
    <p>During this step, we will create the spack configuration and specify our preferred\
    \ compilers and package preference. We install software in buildcache so it can\
    \ be relocated to production path. In order to accomplish this task, we use <a\
    \ href=\"https://spack.readthedocs.io/en/latest/pipelines.html\" rel=\"nofollow\"\
    >spack pipelines</a> that uses <code>spack ci generate</code> and <code>spack\
    \ ci rebuild</code> to perform parallel pipeline execution. During this step,\
    \ we determine which packages to install from E4S and add our own packages to\
    \ comply with our site preference.</p>\n<h3 id=\"user-content-step-3-create-gitlab-job-for-automation\"\
    ><a class=\"heading-link\" href=\"#step-3-create-gitlab-job-for-automation\">Step\
    \ 3: Create Gitlab Job for Automation<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h3>\n<p>Once spack configuration is written, we\
    \ create a gitlab job to trigger the pipeline. This can be done by specifying\
    \ a job in <a href=\"https://github.com/NERSC/spack-infrastructure/blob/main/.gitlab-ci.yml\"\
    >.gitlab-ci.yml</a>.</p>\n<p>The gitlab job can be triggered through <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\" rel=\"\
    nofollow\">scheduled pipelines</a>, <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web-interface</a>, or merge request to the project. A typical\
    \ gitlab job will look something like this. Shown below is for E4S 23.05 generate\
    \ job. We make use of gitlab feature named <a href=\"https://docs.gitlab.com/ee/ci/yaml/index.html#extends\"\
    \ rel=\"nofollow\">extends</a> which allows us to reuse configuration. The <code>spack\
    \ ci generate</code> command will be the same for each substack. There is two\
    \ jobs, first is the generate step performed by <code>spack ci generate</code>\
    \ and this triggers the downstream job created by spack.</p>\n<div class=\"highlight\
    \ highlight-source-yaml\"><pre><span class=\"pl-ent\">.perlmutter-e4s-23.05-generate</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">generate</span>\n\
    \  <span class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    ]</span>\n  <span class=\"pl-ent\">tags</span>: <span class=\"pl-s\">[perlmutter-e4s]</span>\n\
    \  <span class=\"pl-ent\">interruptible</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">allow_failure</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">rules</span>:\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"schedule\" || $CI_PIPELINE_SOURCE\
    \ == \"web\") &amp;&amp; ($PIPELINE_NAME == \"PERLMUTTER_E4S_23.05\")</span>\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"merge_request_event\")</span>\n      <span class=\"pl-ent\">changes</span>:\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/$STACK_NAME/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">before_script</span>:\n    <span class=\"pl-s\">- *copy_perlmutter_settings</span>\n\
    \    <span class=\"pl-s\">- *startup_modules</span>\n  <span class=\"pl-ent\"\
    >script</span>:\n    <span class=\"pl-s\">- *e4s_23_05_setup </span>\n    - <span\
    \ class=\"pl-s\">cd $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/$STACK_NAME</span>\n\
    \    - <span class=\"pl-s\">cat $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/definitions.yaml\
    \ &gt;&gt; spack.yaml</span>\n    - <span class=\"pl-s\">spack env activate --without-view\
    \  .</span>\n    - <span class=\"pl-s\">spack env st</span>\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>- spack -d concretize -f | tee $CI_PROJECT_DIR/concretize.log\
    \    </span>\n    - <span class=\"pl-s\">spack -d ci generate --check-index-only\
    \ --artifacts-root \"$CI_PROJECT_DIR/jobs_scratch_dir\" --output-file \"${CI_PROJECT_DIR}/jobs_scratch_dir/pipeline.yml\"\
    </span>\n  <span class=\"pl-ent\">artifacts</span>: \n    <span class=\"pl-ent\"\
    >paths</span>:\n    - <span class=\"pl-s\">${CI_PROJECT_DIR}/jobs_scratch_dir</span>\n\
    \n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-generate</span>:\n  <span\
    \ class=\"pl-ent\">extends</span>: <span class=\"pl-s\">.perlmutter-e4s-23.05-generate</span>\n\
    \  <span class=\"pl-ent\">variables</span>:\n    <span class=\"pl-ent\">STACK_NAME</span>:\
    \ <span class=\"pl-s\">cce</span>\n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-build</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">build</span>\n  <span\
    \ class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    , \"perlmutter-e4s-23.05-cce-generate\"]</span>\n  <span class=\"pl-ent\">allow_failure</span>:\
    \ <span class=\"pl-c1\">true</span>\n  <span class=\"pl-ent\">rules</span>:\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"schedule\" || $CI_PIPELINE_SOURCE == \"web\") &amp;&amp; ($PIPELINE_NAME\
    \ == \"PERLMUTTER_E4S_23.05\")</span>\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"merge_request_event\")</span>\n\
    \      <span class=\"pl-ent\">changes</span>:\n      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/cce/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">trigger</span>:\n    <span class=\"pl-ent\">include</span>:\n\
    \      - <span class=\"pl-ent\">artifact</span>: <span class=\"pl-s\">jobs_scratch_dir/pipeline.yml</span>\n\
    \        <span class=\"pl-ent\">job</span>: <span class=\"pl-s\">perlmutter-e4s-23.05-cce-generate</span>\n\
    \    <span class=\"pl-ent\">strategy</span>: <span class=\"pl-s\">depend</span></pre></div>\n\
    <h3 id=\"user-content-step-4-create-modulefile\"><a class=\"heading-link\" href=\"\
    #step-4-create-modulefile\">Step 4: Create Modulefile<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h3>\n<p>In this step, we create\
    \ a modulefile as entry point to software stack and setup <code>spack</code>.\
    \ We do not create spack generated modules for spack packages, instead one is\
    \ expected to use <code>spack load</code>.  Shown below are the modulefiles available\
    \ on NERSC system, they are typically called <code>e4s/&lt;version&gt;</code>\
    \ with a symbolic link to module <code>spack/e4s-&lt;version&gt;</code></p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml -t av e4s</span>\n<span\
    \ class=\"pl-c1\">/global/common/software/nersc/pm-2022.12.0/extra_modulefiles:</span>\n\
    <span class=\"pl-c1\">e4s/22.05</span>\n<span class=\"pl-c1\">e4s/22.11</span>\n\
    <span class=\"pl-c1\">spack/e4s-22.05</span>\n<span class=\"pl-c1\">spack/e4s-22.11</span></pre></div>\n\
    <p>Shown below is the content of our modulefile, the setup is subject to change</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml --raw show e4s</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">   /global/common/software/nersc/pm-2022.12.0/extra_modulefiles/e4s/22.11.lua:</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">whatis([[</span>\n<span class=\"pl-c1\">        The Extreme-scale\
    \ Scientific Software Stack (E4S) is a collection of open source software packages\
    \ for running scientific applications on high-performance computing (HPC) platforms.</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n<span class=\"pl-c1\">help([[ The Extreme-scale\
    \ Scientific Software Stack (E4S) is a community effort to provide open source\
    \ software packages for developing, deploying and running scientific applications\
    \ on high-performance computing (HPC) platforms. E4S provides from-source builds\
    \ and containers of a broad collection of HPC software packages.</span>\n\n<span\
    \ class=\"pl-c1\">References:</span>\n<span class=\"pl-c1\">  - E4S User Docs:\
    \ https://e4s.readthedocs.io/en/latest/index.html</span>\n<span class=\"pl-c1\"\
    >  - E4S 22.11 Docs: https://docs.nersc.gov/applications/e4s/perlmutter/22.11/</span>\n\
    <span class=\"pl-c1\">  - E4S Homepage: https://e4s-project.github.io/</span>\n\
    <span class=\"pl-c1\">  - E4S GitHub: https://github.com/E4S-Project/e4s</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n\n<span class=\"pl-c1\">local root =\
    \ \"/global/common/software/spackecp/perlmutter/e4s-22.11/default/spack\"</span>\n\
    \n<span class=\"pl-c1\">setenv(\"SPACK_GNUPGHOME\", pathJoin(os.getenv(\"HOME\"\
    ), \".gnupg\"))</span>\n<span class=\"pl-c1\">setenv(\"SPACK_SYSTEM_CONFIG_PATH\"\
    , \"/global/common/software/spackecp/perlmutter/spack_settings\")</span>\n<span\
    \ class=\"pl-c1\">-- setup spack shell functionality</span>\n<span class=\"pl-c1\"\
    >local shell = myShellType()</span>\n<span class=\"pl-c1\">if (mode() == \"load\"\
    ) then</span>\n<span class=\"pl-c1\">    local spack_setup = ''</span>\n<span\
    \ class=\"pl-c1\">    if (shell == \"sh\" or shell == \"bash\" or shell == \"\
    zsh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.sh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"csh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.csh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"fish\")  then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.fish\")</span>\n<span class=\"pl-c1\">    end</span>\n\
    \n<span class=\"pl-c1\">    -- If we are unable to find spack setup script let's\
    \ terminate now.</span>\n<span class=\"pl-c1\">    if not isFile(spack_setup)\
    \ then</span>\n<span class=\"pl-c1\">        LmodError(\"Unable to find spack\
    \ setup script \" .. spack_setup .. \"\\n\")</span>\n<span class=\"pl-c1\">  \
    \  end</span>\n\n<span class=\"pl-c1\">    execute{cmd=\"source \" .. spack_setup,\
    \ modeA={\"load\"}}</span>\n\n<span class=\"pl-c1\">    LmodMessage([[</span>\n\
    <span class=\"pl-c1\">    _______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">     The Extreme-Scale Scientific Software Stack (E4S) is\
    \ accessible via the Spack package manager.</span>\n\n<span class=\"pl-c1\"> \
    \    In order to access the production stack, you will need to load a spack environment.\
    \ Here are some tips to get started:</span>\n\n\n<span class=\"pl-c1\">     'spack\
    \ env list' - List all Spack environments</span>\n<span class=\"pl-c1\">     'spack\
    \ env activate gcc' - Activate the \"gcc\" Spack environment</span>\n<span class=\"\
    pl-c1\">     'spack env status' - Display the active Spack environment</span>\n\
    <span class=\"pl-c1\">     'spack load amrex' - Load the \"amrex\" Spack package\
    \ into your user environment</span>\n\n<span class=\"pl-c1\">     For additional\
    \ support, please refer to the following references:</span>\n\n<span class=\"\
    pl-c1\">       NERSC E4S Documentation: https://docs.nersc.gov/applications/e4s/</span>\n\
    <span class=\"pl-c1\">       E4S Documentation: https://e4s.readthedocs.io</span>\n\
    <span class=\"pl-c1\">       Spack Documentation: https://spack.readthedocs.io/en/latest/</span>\n\
    <span class=\"pl-c1\">       Spack Slack: https://spackpm.slack.com</span>\n\n\
    <span class=\"pl-c1\">    ______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">    ]])</span>\n<span class=\"pl-c1\">-- To remove spack\
    \ from shell we need to remove a few environment variables, alias and remove $SPACK_ROOT/bin\
    \ from $PATH</span>\n<span class=\"pl-c1\">elseif (mode() == \"unload\" or mode()\
    \ == \"purge\") then</span>\n<span class=\"pl-c1\">    if (shell == \"sh\" or\
    \ shell == \"bash\" or shell == \"zsh\") then</span>\n<span class=\"pl-c1\"> \
    \     execute{cmd=\"unset SPACK_ENV\",modeA={\"unload\"}}</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unset SPACK_ROOT\",modeA={\"unload\"}}</span>\n<span\
    \ class=\"pl-c1\">      execute{cmd=\"unset -f spack\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">    elseif (shell == \"csh\") then</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unsetenv SPACK_ENV\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">      execute{cmd=\"unsetenv SPACK_ROOT\",modeA={\"unload\"\
    }}</span>\n<span class=\"pl-c1\">      execute{cmd=\"unalias spack\",modeA={\"\
    unload\"}}</span>\n<span class=\"pl-c1\">    end</span>\n\n<span class=\"pl-c1\"\
    >    -- Need to remove $SPACK_ROOT/bin from $PATH which removes the 'spack' command</span>\n\
    <span class=\"pl-c1\">    remove_path(\"PATH\", pathJoin(root, \"bin\"))</span>\n\
    \n<span class=\"pl-c1\">    -- Remove alias spacktivate. Need to pipe to /dev/null\
    \ as invalid alias can report error to stderr</span>\n<span class=\"pl-c1\"> \
    \   execute{cmd=\"unalias spacktivate &gt; /dev/null\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">end</span></pre></div>\n<h3 id=\"user-content-step-5-user-documentation\"\
    ><a class=\"heading-link\" href=\"#step-5-user-documentation\">Step 5: User Documentation<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>User\
    \ documentation is fundamental to help assist users with using E4S at NERSC. We\
    \ document every E4S release with its <em>Release Date</em> and <em>End of Support</em>\
    \ date along with a documentation page outlining the software stack. Our E4S documentation\
    \ is available at <a href=\"https://docs.nersc.gov/applications/e4s/\" rel=\"\
    nofollow\">https://docs.nersc.gov/applications/e4s/</a>. The release date is when\
    \ documentation is live. We perform this action in conjunction with release of\
    \ modulefile so that user gain access to software stack.</p>\n<p>Upon completion\
    \ of this task, we are ready to make announcement to our NERSC users</p>\n<h3\
    \ id=\"user-content-step-6-sharing-spack-configuration-with-open-source-community\"\
    ><a class=\"heading-link\" href=\"#step-6-sharing-spack-configuration-with-open-source-community\"\
    >Step 6: Sharing spack configuration with open-source community<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>In this step, we share\
    \ our spack configuration with open-source community that may benefit the wider\
    \ community. We share our spack configuration at <a href=\"https://github.com/spack/spack-configs\"\
    >https://github.com/spack/spack-configs</a>. In addition, we update the <a href=\"\
    https://e4s.readthedocs.io/en/latest/facility_e4s.html\" rel=\"nofollow\">E4S\
    \ Facility Dashboard</a> that shows all the E4S deployments across all the facilities.</p>\n\
    <h3 id=\"user-content-step-7-public-announcement\"><a class=\"heading-link\" href=\"\
    #step-7-public-announcement\">Step 7: Public Announcement<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>This is the final step\
    \ of the deployment process, where we make a public announcement in NERSC weekly\
    \ email, along with various slack channels such as Nersc User Group (NUG), Spack,\
    \ ECP and E4S slack.</p>\n<h2 id=\"user-content-current-challenges\"><a class=\"\
    heading-link\" href=\"#current-challenges\">Current Challenges<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>There are several challenges\
    \ with building spack stack at NERSC which can be summarized as follows</p>\n\
    <ul>\n<li>\n<p><strong>System OS + Cray Programming Environment (CPE) changes</strong>:\
    \ A system upgrade such as change to <code>glibc</code> or upgrades in CPE can\
    \ lead to full software stack rebuild, especially if you have external packages\
    \ set for packages like <code>cray-mpich</code>, <code>cray-libsci</code> which\
    \ generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2 id=\"user-content-contact\"><a class=\"heading-link\" href=\"#contact\">Contact<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>If\
    \ you need elevated privledge or assistance with this project please contact one\
    \ of the maintainers:</p>\n<ul>\n<li>Shahzeb Siddiqui - <a href=\"mailto:shahzebsiddiqui@lbl.gov\"\
    >shahzebsiddiqui@lbl.gov</a>\n</li>\n<li>Erik Palmer - <a href=\"mailto:epalmer@lbl.gov\"\
    >epalmer@lbl.gov</a>\n</li>\n<li>Justin Cook - <a href=\"mailto:JSCook@lbl.gov\"\
    >JSCook@lbl.gov</a>\n</li>\n<li>E4S Team: Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>), Christopher Peyralans (<a href=\"mailto:lpeyrala@uoregon.edu\"\
    >lpeyrala@uoregon.edu</a>), Wyatt Spear (<a href=\"mailto:wspear@cs.uoregon.edu\"\
    >wspear@cs.uoregon.edu</a>), Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\"\
    >nchaimov@paratools.com</a>)</li>\n</ul>\n"
  stargazers_count: 8
  subscribers_count: 14
  topics: []
  updated_at: 1673545287.0
NERSC/timemory:
  data_format: 2
  description: 'Modular C++ Toolkit for Performance Analysis and Logging. Profiling
    API and Tools for C, C++, CUDA, Fortran, and Python. The C++ template API is essentially
    a framework to creating tools: it is designed to provide a unifying interface
    for recording various performance measurements alongside data logging and interfaces
    to other tools.'
  filenames:
  - docker/gpu/spack.yaml
  full_name: NERSC/timemory
  latest_release: v3.2.3
  readme: "<h1 id=\"user-content-timemory\"><a class=\"heading-link\" href=\"#timemory\"\
    >timemory<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <h2 id=\"user-content-timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    ><a class=\"heading-link\" href=\"#timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    >Timing + Memory + Hardware Counter Utilities for C / C++ / CUDA / Python<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p><a\
    \ href=\"https://travis-ci.org/NERSC/timemory\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9505e1c9d1da422846396830ac218c61bb3343ebe5402ffb3b05b52558266d67/68747470733a2f2f7472617669732d63692e6f72672f4e455253432f74696d656d6f72792e7376673f6272616e63683d6d6173746572\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/NERSC/timemory.svg?branch=master\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/jrmadsen/timemory/branch/master\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4a833ca1c608ec560c59f2db36c4ea6c9c466102cba6505d53e6fcd6deaa3d7c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38786b37326f6f7477736566693863312f6272616e63682f6d61737465723f7376673d74727565\"\
    \ alt=\"Build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/8xk72ootwsefi8c1/branch/master?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/NERSC/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/87983d45b3e2381d7edd4ba6c892d41b4aeddd939663bcf2fb8cc60d29d4496f/68747470733a2f2f636f6465636f762e696f2f67682f4e455253432f74696d656d6f72792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/NERSC/timemory/branch/master/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/NERSC/timemory\"\
    >timemory on GitHub (Source code)</a></p>\n<p><a href=\"https://timemory.readthedocs.io\"\
    \ rel=\"nofollow\">timemory General Documentation (ReadTheDocs)</a></p>\n<p><a\
    \ href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\
    >timemory Source Code Documentation (Doxygen)</a></p>\n<p><a href=\"https://cdash.nersc.gov/index.php?project=TiMemory\"\
    \ rel=\"nofollow\">timemory Testing Dashboard (CDash)</a></p>\n<p><a href=\"https://github.com/NERSC/timemory-tutorials\"\
    >timemory Tutorials</a></p>\n<ul>\n<li>\n<p><a href=\"https://www.youtube.com/watch?v=K1Pazcw7zVo\"\
    \ rel=\"nofollow\">ECP 2021 Tutorial Day 1 (YouTube)</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://www.youtube.com/watch?v=-zIpZDiwrmI\" rel=\"nofollow\">ECP 2021\
    \ Tutorial Day 2 (YouTube)</a></p>\n</li>\n</ul>\n<p><a href=\"https://github.com/NERSC/timemory/wiki\"\
    >timemory Wiki</a></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>GitHub</td>\n<td><code>git clone https://github.com/NERSC/timemory.git</code></td>\n\
    </tr>\n<tr>\n<td>PyPi</td>\n<td><code>pip install timemory</code></td>\n</tr>\n\
    <tr>\n<td>Spack</td>\n<td><code>spack install timemory</code></td>\n</tr>\n<tr>\n\
    <td>conda-forge</td>\n<td><code>conda install -c conda-forge timemory</code></td>\n\
    </tr>\n<tr>\n<td></td>\n<td><a href=\"https://anaconda.org/conda-forge/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/33319eee64e9e77e6164e27e48c8d3e752580de537246f0108c2613a392c44d2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265636970652d74696d656d6f72792d677265656e2e737667\"\
    \ alt=\"Conda Recipe\" data-canonical-src=\"https://img.shields.io/badge/recipe-timemory-green.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/a9c6e0aeed14f60203f554ea93bf6b34a4c8f041c16d2e88bc3e2ab2c0e786bd/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/336c5f6fee8494649e0e14802c2fa61d049a0fc4d3c424a9b8f0626aa4b27f78/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/4db6b05734f08002f400c6aaefe6579f74282758c11efbe421981e8200bd2c6d/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f706e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/conda/pn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"></a></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"user-content-purpose\"\
    ><a class=\"heading-link\" href=\"#purpose\">Purpose<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>The goal of timemory is\
    \ to create an open-source performance measurement and analyis package\nwith modular\
    \ and reusable components which can be used to adapt to any existing C/C++\nperformance\
    \ measurement and analysis API and is arbitrarily extendable by users within their\n\
    application.\nTimemory is not just another profiling tool, it is a profling <em>toolkit</em>\
    \ which streamlines building custom\nprofiling tools through modularity and then\
    \ utilizes the toolkit to provides several pre-built tools.</p>\n<p>In other words,\
    \ timemory provides many pre-built tools, libraries, and interfaces but, due to\
    \ it's modularity,\ncodes can re-use only individual pieces -- such as the classes\
    \ for measuring different timing intervals, memory usage,\nand hardware counters\
    \ -- without the timemory \"runtime management\".</p>\n<h2 id=\"user-content-building-and-installing\"\
    ><a class=\"heading-link\" href=\"#building-and-installing\">Building and Installing<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Timemory\
    \ uses a standard CMake installation.\nSeveral installation examples can be found\
    \ in the <a href=\"https://github.com/NERSC/timemory/wiki/Installation-Examples\"\
    >Wiki</a>. See the <a href=\"https://timemory.readthedocs.io/en/develop/installation.html\"\
    \ rel=\"nofollow\">installation documentation</a> for detailed information on\
    \ the CMake options.</p>\n<h2 id=\"user-content-documentation\"><a class=\"heading-link\"\
    \ href=\"#documentation\">Documentation<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h2>\n<p>The full documentation is available at <a\
    \ href=\"https://timemory.readthedocs.io\" rel=\"nofollow\">timemory.readthedocs.io</a>.\n\
    Detailed source documentation is provided in the <a href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\"\
    \ rel=\"nofollow\">doygen</a>\nsection of the full documentation.\nTutorials are\
    \ available in the <a href=\"https://github.com/NERSC/timemory-tutorials\">github.com/NERSC/timemory-tutorials</a>.</p>\n\
    <h2 id=\"user-content-overview\"><a class=\"heading-link\" href=\"#overview\"\
    >Overview<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p><strong><em>The primary objective of the timemory is the development of a common\
    \ framework for binding together software\nmonitoring code (i.e. performance analysis,\
    \ debugging, logging) into a compact and highly-efficient interface.</em></strong></p>\n\
    <p>Timemory arose out of the need for a universal adapator kit for the various\
    \ APIs provided several existing tools\nand a straight-forward and intuitive method\
    \ for creating new tools. Timemory makes it possible to bundle\ntogether deterministic\
    \ performance measurements, statistical performance\nmeasurements (i.e. sampling),\
    \ debug messages, data logging, and data validation into the same interface for\n\
    custom application-specific software monitoring interfaces, easily building tools\
    \ like <code>time</code>,\n<code>netstat</code>, instrumentation profilers, sampling\
    \ profilers, and writing implementations for MPI-P, MPI-T, OMPT,\nKokkosP, etc.\
    \ Furthermore, timemory can forward its markers to several third-party profilers\
    \ such as\n<a href=\"https://github.com/RRZE-HPC/likwid\">LIKWID</a>, <a href=\"\
    https://github.com/LLNL/Caliper\">Caliper</a>,\n<a href=\"https://www.cs.uoregon.edu/research/tau/home.php\"\
    \ rel=\"nofollow\">TAU</a>, <a href=\"https://github.com/gperftools/gperftools\"\
    >gperftools</a>,\n<a href=\"https://perfetto.dev/docs/\" rel=\"nofollow\">Perfetto</a>,\
    \ VTune, Allinea-MAP, CrayPAT, Nsight-Systems, Nsight-Compute, and NVProf.</p>\n\
    <p>Timemory provides a front-end <a href=\"https://timemory.readthedocs.io/en/develop/api/library.html\"\
    \ rel=\"nofollow\">C/C++/Fortran API</a>\nand <a href=\"https://timemory.readthedocs.io/en/develop/api/python.html\"\
    \ rel=\"nofollow\">Python API</a> which allows arbitrary selection\nof 50+ different\
    \ components from timers to hardware counters to interfaces with third-party tools.\
    \ This is all\nbuilt generically from the toolkit API with type-safe bundles of\
    \ tools such as:\n<code>component_tuple&lt;wall_clock, papi_vector, nvtx_marker,\
    \ user_bundle&gt;</code>\nwhere <code>wall_clock</code> is a wall-clock timer,\n\
    <code>papi_vector</code> is a handle for hardware counters,\n<code>nvxt_marker</code>\
    \ creates notations in the NVIDIA CUDA profilers, and\n<code>user_bundle</code>\
    \ is a generic component which downstream users can insert more components into\
    \ at runtime.</p>\n<p>Performance measurement components written with timemory\
    \ are arbitrarily scalable up to any number of threads and\nprocesses and fully\
    \ support intermixing different measurements at different locations within the\
    \ program -- this\nuniquely enables timemory to be deployed to collect performance\
    \ data at scale in HPC because highly detailed collection can\noccur at specific\
    \ locations within the program where ubiquitous collection would simulatenously\
    \ degrade performance\nsignificantly and require a prohibitive amount of memory.</p>\n\
    <p>Timemory can be used as a backend to bundle instrumentation and sampling tools\
    \ together, support serialization to JSON/XML,\nand provide statistics among other\
    \ uses. It can also be utilized as a front-end to invoke\ncustom instrumentation\
    \ and sampling tools. Timemory uses the abstract term \"component\" for a structure\n\
    which encapsulates some performance analysis operation. The structure might encapsulate\
    \ function\ncalls to another tool, record timestamps for timing, log values provided\
    \ by the application,\nprovide a operator for replacing a function in the code\
    \ dynamically, audit the incoming arguments\nand/or outgoing return value from\
    \ function, or just provide stubs which can be overloaded by the linker.</p>\n\
    <h3 id=\"user-content-visualization-and-analysis\"><a class=\"heading-link\" href=\"\
    #visualization-and-analysis\">Visualization and Analysis<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h3>\n<p>The native output format\
    \ of timemory is JSON and text; other output formats such as XML are also supported.\n\
    The text format is intended to be human readable. The JSON data\nis intended for\
    \ analysis and comes in two flavors: hierarchical and flat. Basic plotting capabilities\
    \ are\navailable via <code>timemory-plotting</code> but users are highly encouraged\
    \ to use <a href=\"https://github.com/hatchet/hatchet\">hatchet</a>\nfor analyzing\
    \ the heirarchical JSON data in pandas dataframes. <a href=\"https://github.com/hatchet/hatchet\"\
    >Hatchet</a> supports\nfiltering, unions, addition, subtractions, output to <code>dot</code>\
    \ and flamegraph formats, and an interactive Jupyter notebook.\nAt present, timemory\
    \ supports 45+ metric types for analysis in Hatchet.</p>\n<h3 id=\"user-content-categories\"\
    ><a class=\"heading-link\" href=\"#categories\">Categories<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>There are 4 primary\
    \ categories in timemory: components, operations, bundlers, and storage. Components\
    \ provide\nthe specifics of how to perform a particular behavior, operations provide\
    \ the scaffold for requesting that\na component perform an operation in complex\
    \ scenarios, bundlers group components into a single generic handle,\nand storage\
    \ manages data collection over the lifetime of the application. When all four\
    \ categories are combined,\ntimemory effectively resembles a standard performance\
    \ analysis tool which passively collects data and provides\nreports and analysis\
    \ at the termination of the application. Timemory, however, makes it <em>very\
    \ easy</em> to subtract\nstorage from the equation and, in doing so, transforms\
    \ timemory into a toolkit for customized data collection.</p>\n<ol>\n<li>\n<strong><em>Components</em></strong>\n\
    <ul>\n<li>Individual classes which encapsulate one or more measurement, analysis,\
    \ logging, or third-party library action(s)</li>\n<li>Any data specific to one\
    \ instance of performing the action is stored within the instance of the class</li>\n\
    <li>Any configuration data specific to that type is typically stored within static\
    \ member functions which return a reference to the configuration data</li>\n<li>These\
    \ classes are designed to support direct usage within other tools, libraries,\
    \ etc.</li>\n<li>Examples include:\n<ul>\n<li>\n<code>tim::component::wall_clock</code>\
    \ : a simple wall-clock timer</li>\n<li>\n<code>tim::component::vtune_profiler</code>\
    \ : a simple component which turns the VTune Profiler on and off (when VTune is\
    \ actively profiling application)</li>\n<li>\n<code>tim::component::data_tracker_integer</code>\
    \ : associates an integer values with a label as the application executes (e.g.\
    \ number of loop iterations used somewhere)</li>\n<li>\n<code>tim::component::papi_vector</code>\
    \ : uses the PAPI library to collect hardware-counters values</li>\n<li>\n<code>tim::component::user_bundle</code>\
    \ : encapsulates an array of components which the user can dynamically manipulate\
    \ during runtime</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Operations</em></strong>\n\
    <ul>\n<li>Templated classes whose primary purpose is to provide the implementation\
    \ for performing some action on a component, e.g. <code>tim::operation::start&lt;wall_clock&gt;</code>\
    \ will attempt to call the <code>start()</code> member function on a <code>wall_clock</code>\
    \ component instance</li>\n<li>Default implementations generally have one or two\
    \ public functions: a constructor and/or a function call operator\n<ul>\n<li>These\
    \ generally accept any/all arguments and use SFINAE to determine whether the operation\
    \ can be performed with or without the given arguments (i.e. does <code>wall_clock</code>\
    \ have a <code>store(int)</code> function? <code>store()</code>?)</li>\n</ul>\n\
    </li>\n<li>Operations are (generally) not directly utilized by the user and are\
    \ typically optimized out of the binary</li>\n<li>Examples include:\n<ul>\n<li>\n\
    <code>tim::operation::start</code> : instruct a component to start collection</li>\n\
    <li>\n<code>tim::operation::sample</code> : instruct a component to take individual\
    \ measurement</li>\n<li>\n<code>tim::operation::derive</code> : extra data from\
    \ other components if it is available</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n\
    <strong><em>Bundlers</em></strong>\n<ul>\n<li>Provide a generic handle for multiple\
    \ components</li>\n<li>Member functions generally accept any/all arguments and\
    \ use operations classes to correctly to handle differences between different\
    \ capabilities of the components it is bundling</li>\n<li>Examples include:\n\
    <ul>\n<li><code>tim::auto_tuple</code></li>\n<li><code>tim::component_tuple</code></li>\n\
    <li><code>tim::component_list</code></li>\n<li><code>tim::lightweight_tuple</code></li>\n\
    </ul>\n</li>\n<li>Various flavors provide different implicit behaviors and allocate\
    \ memory differently\n<ul>\n<li>\n<code>auto_tuple</code> starts all components\
    \ when constructed and stops all components when destructed whereas <code>component_tuple</code>\
    \ requires an explicit start</li>\n<li>\n<code>component_tuple</code> allocates\
    \ all components on the stack and components are \"always on\" whereas <code>component_list</code>\
    \ allocates components on the heap and thus components can be activated/deactivated\
    \ at runtime</li>\n<li>\n<code>lightweight_tuple</code> does not implicitly perform\
    \ any expensive actions, such as call-stack tracking in \"Storage\"</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>\n<strong><em>Storage</em></strong>\n<ul>\n<li>Provides\
    \ persistent storage for multiple instances of components over the lifetime of\
    \ a thread in the application</li>\n<li>Responsible for maintaining the hierarchy\
    \ and order of component measurements, i.e. call-stack tracking</li>\n<li>Responsible\
    \ for combining component data from multiple threads and/or processes and outputting\
    \ the results</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: <code>tim::lightweight_tuple</code>\
    \ is the recommended bundle for those seeking to use timemory as a toolkit for\
    \ implementing custom tools and interfaces</p>\n</blockquote>\n<h2 id=\"user-content-features\"\
    ><a class=\"heading-link\" href=\"#features\">Features<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<ul>\n<li>C++ Template API\n\
    <ul>\n<li>Modular and fully-customizable</li>\n<li>Adheres to C++ standard template\
    \ library paradigm of \"you don't pay for what you don't use\"</li>\n<li>Simplifies\
    \ and facilitates creation and implementation of performance measurement tools\n\
    <ul>\n<li>Create your own instrumentation profiler</li>\n<li>Create your own instrumentation\
    \ library</li>\n<li>Create your own sampling profiler</li>\n<li>Create your own\
    \ sampling library</li>\n<li>Create your own execution wrappers</li>\n<li>Supplement\
    \ timemory-provided tools with your own custom component(s)</li>\n<li>Thread-safe\
    \ data aggregation</li>\n<li>Aggregate collection over multiple processes (MPI\
    \ and UPC++ support)</li>\n<li>Serialization to text, JSON, XML</li>\n</ul>\n\
    </li>\n<li>Components are composable with other components</li>\n<li>Variadic\
    \ component bundlers which maintain complete type-safety\n<ul>\n<li>Components\
    \ can be bundled together into a single handle without abstractions</li>\n</ul>\n\
    </li>\n<li>Components can store data in any valid C++ data type</li>\n<li>Components\
    \ can return data in any valid C++ data type</li>\n</ul>\n</li>\n<li>C / C++ /\
    \ CUDA / Fortran Library API\n<ul>\n<li>Straight-forward collection of functions\
    \ and macros for creating built-in performance analysis to your code</li>\n<li>Component\
    \ collection can be arbitrarily inter-mixed\n<ul>\n<li>E.g. collect \"A\" and\
    \ \"B\" in one region, \"A\" and \"C\" in another region</li>\n</ul>\n</li>\n\
    <li>Component collection can be dynamically manipulated at runtime\n<ul>\n<li>E.g.\
    \ add/remove \"A\" at any point, on any thread, on any process</li>\n</ul>\n</li>\n\
    </ul>\n</li>\n<li>Python API\n<ul>\n<li>Decorators and context-managers for functions\
    \ or regions in code</li>\n<li>Python function profiling</li>\n<li>Python line-by-line\
    \ profiling</li>\n<li>Every component in <code>timemory-avail</code> is provided\
    \ as a stand-alone Python class\n<ul>\n<li>Provide low-overhead measurements for\
    \ building your own Python profiling tools</li>\n</ul>\n</li>\n</ul>\n</li>\n\
    <li>Python Analysis via <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\"\
    >pandas</a>\n</li>\n<li>Command-line Tools\n<ul>\n<li>\n<a href=\"source/tools/timemory-avail/README.md\"\
    >timemory-avail</a>\n<ul>\n<li>Provides available components, settings, and hardware\
    \ counters</li>\n<li>Quick API reference tool</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timem/README.md\">timem</a> (UNIX)\n<ul>\n<li>Extended version of\
    \ UNIX <code>time</code> command-line tool that includes additional information\
    \ on memory usage, context switches, and hardware counters</li>\n<li>Support collecting\
    \ hardware counters (Linux-only, requires PAPI)</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timemory-run/README.md\">timemory-run</a> (Linux)\n<ul>\n<li>Dynamic\
    \ instrumentation profiling tool</li>\n<li>Supports runtime instrumentation and\
    \ binary re-writing</li>\n</ul>\n</li>\n<li>\n<a href=\"source/tools/timemory-nvml/README.md\"\
    >timemory-nvml</a>\n<ul>\n<li>Data collection similar to <code>nvidia-smi</code>\n\
    </li>\n</ul>\n</li>\n<li>\n<code>timemory-python-profiler</code>\n<ul>\n<li>Python\
    \ function profiler supporting all timemory components</li>\n<li><code>from timemory.profiler\
    \ import Profile</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-trace</code>\n\
    <ul>\n<li>Python line-by-line profiler supporting all timemory components</li>\n\
    <li><code>from timemory.trace import Trace</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-line-profiler</code>\n\
    <ul>\n<li>Python line-by-line profiler based on <a href=\"https://pypi.org/project/line-profiler/\"\
    \ rel=\"nofollow\">line-profiler</a> package</li>\n<li>Extended to use components:\
    \ cpu-clock, memory-usage, context-switches, etc. (all components which collect\
    \ scalar values)</li>\n<li><code>from timemory.line_profiler import LineProfiler</code></li>\n\
    </ul>\n</li>\n</ul>\n</li>\n<li>Instrumentation Libraries\n<ul>\n<li>\n<a href=\"\
    source/tools/timemory-mpip/README.md\">timemory-mpip</a>: MPI Profiling Library\
    \ (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ncclp/README.md\">timemory-ncclp</a>:\
    \ NCCL Profiling Library (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ompt/README.md\"\
    >timemory-ompt</a>: OpenMP Profiling Library</li>\n<li>\n<a href=\"source/tools/timemory-compiler-instrument/README.md\"\
    >timemory-compiler-instrument</a>: Compiler instrumentation Library</li>\n<li>\n\
    <a href=\"source/tools/kokkos-connector/README.md\">kokkos-connector</a>: Kokkos\
    \ Profiling Libraries</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"user-content-samples\"\
    ><a class=\"heading-link\" href=\"#samples\">Samples<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>Various macros are defined\
    \ for C in <a href=\"source/timemory/timemory.h\">source/timemory/compat/timemory_c.h</a>\n\
    and <a href=\"source/timemory/variadic/macros.hpp\">source/timemory/variadic/macros.hpp</a>.\
    \ Numerous samples of\ntheir usage can be found in the examples.</p>\n<h3 id=\"\
    user-content-sample-c-template-api\"><a class=\"heading-link\" href=\"#sample-c-template-api\"\
    >Sample C++ Template API<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"\
    pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/timemory.hpp<span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">namespace</span> <span\
    \ class=\"pl-en\">comp</span> <span class=\"pl-k\">=</span> tim::component;\n\
    <span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span\
    \ class=\"pl-en\">tim</span><span class=\"pl-k\">;</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">//</span> specific set of components</span>\n<span class=\"\
    pl-k\">using</span> <span class=\"pl-c1\">specific_t</span> = component_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;;\n<span class=\"pl-k\">using</span> <span class=\"pl-c1\"\
    >generic_t</span>  = component_tuple&lt;comp::user_global_bundle&gt;;\n\n<span\
    \ class=\"pl-k\">int</span>\n<span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span>** argv)\n{\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> configure default settings</span>\n\
    \    <span class=\"pl-c1\">settings::flat_profile</span>() = <span class=\"pl-c1\"\
    >true</span>;\n    <span class=\"pl-c1\">settings::timing_units</span>() = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span class=\"pl-pds\">\"\
    </span></span>;\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> initialize\
    \ with cmd-line</span>\n    <span class=\"pl-c1\">timemory_init</span>(argc, argv);\n\
    \    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> add argparse support</span>\n\
    \    <span class=\"pl-c1\">timemory_argparse</span>(&amp;argc, &amp;argv);\n\n\
    \    <span class=\"pl-c\"><span class=\"pl-c\">//</span> create a region \"main\"\
    </span>\n    <span class=\"pl-c1\">specific_t</span> m{ <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span> };\n \
    \   m.<span class=\"pl-c1\">start</span>();\n    m.<span class=\"pl-c1\">stop</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">settings::enabled</span>() = <span\
    \ class=\"pl-c1\">false</span>;\n    <span class=\"pl-c1\">specific_t</span> h{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden<span class=\"pl-pds\"\
    >\"</span></span> };\n    h.<span class=\"pl-c1\">start</span>().<span class=\"\
    pl-c1\">stop</span>();\n    <span class=\"pl-c1\">settings::enabled</span>() =\
    \ <span class=\"pl-c1\">true</span>;\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Add peak_rss component to specific_t</span>\n    mpl::<span class=\"\
    pl-c1\">push_back_t</span>&lt;<span class=\"pl-c1\">specific_t</span>, comp::peak_rss&gt;\
    \ wprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>with peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n    \n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> create region collecting only peak_rss</span>\n    component_tuple&lt;comp::peak_rss&gt;\
    \ oprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>only peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> convert component_tuple to a type that starts/stops upon construction/destruction</span>\n\
    \    {\n        scope::config _scope{};\n        <span class=\"pl-k\">if</span>(<span\
    \ class=\"pl-c1\">true</span>)  _scope += scope::flat{};\n        <span class=\"\
    pl-k\">if</span>(<span class=\"pl-c1\">false</span>) _scope += scope::timeline{};\n\
    \        <span class=\"pl-c1\">convert_t</span>&lt;<span class=\"pl-c1\">specific_t</span>,\
    \ auto_tuple&lt;&gt;&gt; scoped{ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>scoped start/stop + flat<span class=\"pl-pds\">\"</span></span>, _scope\
    \ };\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> will yield auto_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;</span>\n    }\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of strings</span>\n    runtime::configure&lt;comp::user_global_bundle&gt;({\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> });\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of enumeration ids</span>\n\
    \    runtime::configure&lt;comp::user_global_bundle&gt;({ TIMEMORY_WALL_CLOCK,\
    \ TIMEMORY_CPU_CLOCK });\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ configure the generic bundle via component instances</span>\n    comp::user_global_bundle::configure&lt;comp::page_rss,\
    \ comp::papi_vector&gt;();\n    \n    <span class=\"pl-c1\">generic_t</span> g{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>generic<span class=\"pl-pds\"\
    >\"</span></span>, quirk::config&lt;quirk::auto_start&gt;{} };\n    g.<span class=\"\
    pl-c1\">stop</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3 id=\"user-content-sample-c--c-library-api\"><a class=\"heading-link\" href=\"\
    #sample-c--c-library-api\">Sample C / C++ Library API<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h3>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>timemory/library.h<span class=\"pl-pds\">\"</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>timemory/timemory.h<span class=\"pl-pds\">\"</span></span>\n\n<span\
    \ class=\"pl-k\">int</span>\n<span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span>** argv)\n{\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> configure settings</span>\n  \
    \  <span class=\"pl-k\">int</span> overwrite       = <span class=\"pl-c1\">0</span>;\n\
    \    <span class=\"pl-k\">int</span> update_settings = <span class=\"pl-c1\">1</span>;\n\
    \    <span class=\"pl-c\"><span class=\"pl-c\">//</span> default to flat-profile</span>\n\
    \    <span class=\"pl-c1\">timemory_set_environ</span>(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>TIMEMORY_FLAT_PROFILE<span class=\"pl-pds\">\"</span></span>,\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span class=\"pl-pds\"\
    >\"</span></span>, overwrite, update_settings);\n    <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> force timing units</span>\n    overwrite = <span class=\"\
    pl-c1\">1</span>;\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_TIMING_UNITS<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> initialize with cmd-line</span>\n\
    \    <span class=\"pl-c1\">timemory_init_library</span>(argc, argv);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> check if inited, init with name</span>\n\
    \    <span class=\"pl-k\">if</span>(!<span class=\"pl-c1\">timemory_library_is_initialized</span>())\n\
    \        <span class=\"pl-c1\">timemory_named_init_library</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>ex-c<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> define the default set\
    \ of components</span>\n    <span class=\"pl-c1\">timemory_set_default</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock, cpu_clock<span class=\"\
    pl-pds\">\"</span></span>);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ create a region \"main\"</span>\n    <span class=\"pl-c1\">timemory_push_region</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>);\n    <span class=\"pl-c1\">timemory_pop_region</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">timemory_pause</span>();\n    <span\
    \ class=\"pl-c1\">timemory_push_region</span>(<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_pop_region</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_resume</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> Add/remove component(s) to the current set of components</span>\n \
    \   <span class=\"pl-c1\">timemory_add_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_remove_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> get an identifier for\
    \ a region and end it</span>\n    <span class=\"pl-c1\">uint64_t</span> idx =\
    \ <span class=\"pl-c1\">timemory_get_begin_record</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> assign an existing identifier for a region</span>\n\
    \    <span class=\"pl-c1\">timemory_begin_record</span>(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>indexed/2<span class=\"pl-pds\">\"</span></span>,\
    \ &amp;idx);\n    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n \
    \   <span class=\"pl-c\"><span class=\"pl-c\">//</span> create region collecting\
    \ a specific set of data</span>\n    <span class=\"pl-c1\">timemory_begin_record_enum</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>enum<span class=\"pl-pds\">\"\
    </span></span>, &amp;idx, TIMEMORY_PEAK_RSS, TIMEMORY_COMPONENTS_END);\n    <span\
    \ class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"pl-c1\"\
    >timemory_begin_record_types</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>types<span class=\"pl-pds\">\"</span></span>, &amp;idx, <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> replace current set of components and then\
    \ restore previous set</span>\n    <span class=\"pl-c1\">timemory_push_components</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\"\
    >\"</span></span>);\n    <span class=\"pl-c1\">timemory_pop_components</span>();\n\
    \n    <span class=\"pl-c1\">timemory_push_components_enum</span>(<span class=\"\
    pl-c1\">2</span>, TIMEMORY_WALL_CLOCK, TIMEMORY_CPU_CLOCK);\n    <span class=\"\
    pl-c1\">timemory_pop_components</span>();\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize_library</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3 id=\"user-content-sample-fortran-api\"><a class=\"heading-link\" href=\"#sample-fortran-api\"\
    >Sample Fortran API<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <div class=\"highlight highlight-source-fortran\"><pre><span class=\"pl-k\">program</span>\
    \ fortran_example\n    use timemory\n    use iso_c_binding, only : C_INT64_T\n\
    \    <span class=\"pl-k\">implicit none</span>\n    <span class=\"pl-k\">integer</span>(C_INT64_T)\
    \ <span class=\"pl-k\">::</span> idx\n\n    ! initialize with explicit name\n\
    \    <span class=\"pl-k\">call</span> timemory_init_library(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>ex-fortran<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! initialize with name extracted from get_command_argument(<span class=\"\
    pl-c1\">0</span>, ...)\n    ! <span class=\"pl-k\">call</span> timemory_init_library(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! define the default set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_set_default(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock,\
    \ cpu_clock<span class=\"pl-pds\">\"</span></span>)\n\n    ! Start region <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! Add peak_rss <span class=\"pl-k\">to</span> the current\
    \ set of components\n    <span class=\"pl-k\">call</span> timemory_add_components(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\"\
    >\"</span></span>)\n\n    ! Nested region <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span> nested under <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! End the <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>inner<span class=\"pl-pds\">\"</span></span> region\n    <span class=\"\
    pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner<span class=\"pl-pds\">\"</span></span>)\n\n    ! remove peak_rss\n\
    \    <span class=\"pl-k\">call</span> timemory_remove_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! begin a region and get an identifier\n    idx <span class=\"pl-k\">=</span>\
    \ timemory_get_begin_record(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>indexed<span\
    \ class=\"pl-pds\">\"</span></span>)\n\n    ! replace current set of components\n\
    \    <span class=\"pl-k\">call</span> timemory_push_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Nested region <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> with only page_rss components\n    <span class=\"\
    pl-k\">call</span> timemory_push_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\n    ! <span\
    \ class=\"pl-k\">Stop</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> region with only page_rss components\n   \
    \ <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! restore previous set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_pop_components()\n\n    ! end the <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span> region\n    <span\
    \ class=\"pl-k\">call</span> timemory_end_record(idx)\n\n    ! End <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>\n\
    \    <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Output the results\n    <span class=\"pl-k\">call</span> timemory_finalize_library()\n\
    \n<span class=\"pl-k\">end program</span> fortran_example</pre></div>\n<h3 id=\"\
    user-content-sample-python-api\"><a class=\"heading-link\" href=\"#sample-python-api\"\
    >Sample Python API<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <h4 id=\"user-content-decorator\"><a class=\"heading-link\" href=\"#decorator\"\
    >Decorator<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h4>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">bundle</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">marker</span>\n\n<span class=\"\
    pl-en\">@<span class=\"pl-en\">marker</span>([<span class=\"pl-s\">\"cpu_clock\"\
    </span>, <span class=\"pl-s\">\"peak_rss\"</span>])</span>\n<span class=\"pl-k\"\
    >def</span> <span class=\"pl-en\">foo</span>():\n    <span class=\"pl-k\">pass</span></pre></div>\n\
    <h4 id=\"user-content-context-manager\"><a class=\"heading-link\" href=\"#context-manager\"\
    >Context Manager<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h4>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">profiler</span>\
    \ <span class=\"pl-k\">import</span> <span class=\"pl-s1\">profile</span>\n\n\
    <span class=\"pl-k\">def</span> <span class=\"pl-en\">bar</span>():\n    <span\
    \ class=\"pl-k\">with</span> <span class=\"pl-en\">profile</span>([<span class=\"\
    pl-s\">\"wall_clock\"</span>, <span class=\"pl-s\">\"cpu_util\"</span>]):\n  \
    \      <span class=\"pl-en\">foo</span>()</pre></div>\n<h4 id=\"user-content-individual-components\"\
    ><a class=\"heading-link\" href=\"#individual-components\">Individual Components<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h4>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span\
    \ class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">component</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-v\">WallClock</span>\n\n<span\
    \ class=\"pl-k\">def</span> <span class=\"pl-en\">spam</span>():\n\n    <span\
    \ class=\"pl-s1\">wc</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >WallClock</span>(<span class=\"pl-s\">\"spam\"</span>)\n    <span class=\"pl-s1\"\
    >wc</span>.<span class=\"pl-en\">start</span>()\n\n    <span class=\"pl-en\">bar</span>()\n\
    \n    <span class=\"pl-s1\">wc</span>.<span class=\"pl-en\">stop</span>()\n  \
    \  <span class=\"pl-s1\">data</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">wc</span>.<span class=\"pl-en\">get</span>()\n    <span class=\"pl-en\"\
    >print</span>(<span class=\"pl-s1\">data</span>)</pre></div>\n<h4 id=\"user-content-argparse-support\"\
    ><a class=\"heading-link\" href=\"#argparse-support\">Argparse Support<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h4>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">import</span> <span class=\"\
    pl-s1\">argparse</span>\n\n<span class=\"pl-s1\">parser</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">argparse</span>.<span class=\"pl-v\">ArgumentParser</span>(<span\
    \ class=\"pl-s\">\"example\"</span>)\n<span class=\"pl-c\"># ...</span>\n<span\
    \ class=\"pl-s1\">timemory</span>.<span class=\"pl-en\">add_arguments</span>(<span\
    \ class=\"pl-s1\">parser</span>)\n\n<span class=\"pl-s1\">args</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">parser</span>.<span class=\"pl-en\">parse_args</span>()</pre></div>\n\
    <h4 id=\"user-content-component-storage\"><a class=\"heading-link\" href=\"#component-storage\"\
    >Component Storage<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h4>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">storage</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-v\">WallClockStorage</span>\n\n\
    <span class=\"pl-c\"># data for current rank</span>\n<span class=\"pl-s1\">data</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">get</span>()\n<span class=\"pl-c\"># combined data on rank zero\
    \ but all ranks must call it</span>\n<span class=\"pl-s1\">dmp_data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">dmp_get</span>()</pre></div>\n<h2 id=\"user-content-versioning\"\
    ><a class=\"heading-link\" href=\"#versioning\">Versioning<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Timemory originated\
    \ as a very simple tool for recording timing and memory measurements (hence the\
    \ name) in C, C++, and Python and only supported\nthree modes prior to the 3.0.0\
    \ release: a fixed set of timers, a pair of memory measurements, and the combination\
    \ of the two.\n<strong>Prior to the 3.0.0 release, timemory was almost completely\
    \ rewritten from scratch</strong> with the sole exceptions of some C/C++ macro,\
    \ e.g.\n<code>TIMEMORY_AUTO_TIMER</code>, and some Python decorators and context-manager,\
    \ e.g. <code>timemory.util.auto_timer</code>, whose behavior were\nable to be\
    \ fully replicated in the new release. Thus, while it may appear that timemory\
    \ is a mature project at v3.0+, it\nis essentially still in it's first major release.</p>\n\
    <h2 id=\"user-content-citing-timemory\"><a class=\"heading-link\" href=\"#citing-timemory\"\
    >Citing timemory<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>To reference timemory in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Madsen, J.R. et al. (2020) Timemory: Modular Performance Analysis for\
    \ HPC. In: Sadayappan P., Chamberlain B., Juckeland G., Ltaief H. (eds) High Performance\
    \ Computing. ISC High Performance 2020. Lecture Notes in Computer Science, vol\
    \ 12151. Springer, Cham</li>\n</ul>\n<h2 id=\"user-content-additional-information\"\
    ><a class=\"heading-link\" href=\"#additional-information\">Additional Information<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>For\
    \ more information, refer to the <a href=\"https://timemory.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n"
  stargazers_count: 327
  subscribers_count: 17
  topics:
  - python
  - cpp
  - cplusplus
  - performance
  - c
  - cross-platform
  - cross-language
  - memory-measurements
  - mpi
  - cuda
  - papi
  - hardware-counters
  - analysis
  - roofline
  - performance-measurement
  - instrumentation-api
  - gotcha
  - cupti
  - modular-design
  updated_at: 1696011563.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 47
  subscribers_count: 21
  topics: []
  updated_at: 1697167843.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<h1 id="user-content-gsi-utils"><a class="heading-link" href="#gsi-utils">GSI-Utils<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 2
  subscribers_count: 8
  topics: []
  updated_at: 1690297134.0
PawseySC/hpc-container-training:
  data_format: 2
  description: 'Training material on using containers in an HPC setting. '
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/hpc-container-training
  latest_release: null
  readme: '<h1 id="user-content-readme"><a class="heading-link" href="#readme">Readme<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    '
  stargazers_count: 4
  subscribers_count: 5
  topics:
  - docker
  - singularity
  - hpc
  - pawsey
  - training-materials
  updated_at: 1682469853.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Automated deployment system for the scientific software stack in use
    at Pawsey
  filenames:
  - systems/setonix/environments/bench/spack.yaml
  - systems/setonix/environments/wrf/spack.yaml
  - systems/setonix/environments/utils/spack.yaml
  - systems/setonix/environments/astro/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1 id="user-content-pawsey-spack-configuration"><a class="heading-link"
    href="#pawsey-spack-configuration">Pawsey Spack Configuration<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <h2 id="user-content-installation"><a class="heading-link" href="#installation">Installation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_TAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <h3 id="user-content-singularity"><a class="heading-link" href="#singularity">Singularity<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <h3 id="user-content-software-stack-modulefile"><a class="heading-link" href="#software-stack-modulefile">Software
    stack modulefile<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <h2 id="user-content-repository-structure"><a class="heading-link" href="#repository-structure">Repository
    structure<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <h2 id="user-content-the-scripts-directory"><a class="heading-link" href="#the-scripts-directory">The
    <code>scripts</code> directory<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <h2 id="user-content-the-systemssystem-directory"><a class="heading-link" href="#the-systemssystem-directory">The
    <code>systems/&lt;system&gt;</code> directory<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h2>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <h2 id="user-content-notes"><a class="heading-link" href="#notes">Notes<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <h3 id="user-content-module-categories-in-use"><a class="heading-link" href="#module-categories-in-use">Module
    categories in use<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <h3 id="user-content-testing-modules"><a class="heading-link" href="#testing-modules">Testing
    Modules<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1687655533.0
PawseySC/singularity-containers:
  data_format: 2
  description: Webinars&Tutorial on Containers on HPC and Cloud with Singularity
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/singularity-containers
  latest_release: null
  readme: '<h1 id="user-content-readme"><a class="heading-link" href="#readme">Readme<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    '
  stargazers_count: 22
  subscribers_count: 11
  topics: []
  updated_at: 1687465164.0
RMeli/my-spack:
  data_format: 2
  description: Spack environments
  filenames:
  - envs/alps/dlaf/oneapi-mt/spack.yaml
  - envs/local/dlaf/mkl-mt-mpich-cuda-scalapack/spack.yaml
  - envs/alps/cp2k-dlaf/mkl-cuda/spack.yaml
  - envs/alps/sirius/cpu/spack.yaml
  full_name: RMeli/my-spack
  latest_release: null
  readme: '<h1 id="user-content-my-spack"><a class="heading-link" href="#my-spack">My
    Spack<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Spack-related stuff for @RMeli.</p>

    <h2 id="user-content-package-repository"><a class="heading-link" href="#package-repository">Package
    Repository<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><a href="https://spack.readthedocs.io/en/latest/repositories.html" rel="nofollow">Spack
    Package Repositories</a></p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679671251.0
ResearchComputing/core-software:
  data_format: 2
  description: Documentation and automation for provisioning the core software environment
    at University of Colorado Boulder Research Computing
  filenames:
  - spack/environments/develop/spack.yaml
  full_name: ResearchComputing/core-software
  latest_release: null
  readme: '<p>The Research Computing core software environment provides compilers,

    mpi, libraries, language environments, and applications that are of

    general use to the CU Boulder Research Computing user community.</p>

    <h2 id="user-content-manual-installation-procedures"><a class="heading-link" href="#manual-installation-procedures">Manual
    installation procedures<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Manual software installation procedures are available in the <code>Summit</code>

    and <code>Blanca</code> directories, organized by

    <code>Cluster/SoftwareName/VersionNumber</code>. The <code>VersionNumber</code>
    file

    contains build notes (bash commands, notes, instructions etc.) to

    install that software package for each compiler and MPI.</p>

    <h2 id="user-content-spack"><a class="heading-link" href="#spack">Spack<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <p>Spack, when deployed as intended, will be a central part of the

    provisioning of our Core Software service. Included here is the

    configuration and installation script for Spack as installed and

    presented at CU Boulder Research Computing.</p>

    '
  stargazers_count: 1
  subscribers_count: 8
  topics: []
  updated_at: 1649960895.0
SC-SGS/CPPuddle:
  data_format: 2
  description: Utility library to handle small, reusable pools of both device memory
    buffers (via allocators) and device executors (with multiple scheduling policies).
  filenames:
  - spack.yaml
  full_name: SC-SGS/CPPuddle
  latest_release: v0.3.1
  readme: "<h3 id=\"user-content-cppuddle\"><a class=\"heading-link\" href=\"#cppuddle\"\
    >CPPuddle<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p><a href=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml\"\
    ><img src=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml/badge.svg\"\
    \ alt=\"ctest\" style=\"max-width: 100%;\"></a>\n<a href=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/view/Octo-Tiger%20and%20Dependencies/job/CPPuddle/job/master/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f85055028a87ff41032206704d36fede5e5cc779d3369a6650f02d9d46676a45/68747470733a2f2f73696d7367732e696e666f726d6174696b2e756e692d7374757474676172742e64652f6a656e6b696e732f6275696c645374617475732f69636f6e3f6a6f623d4350507564646c652532466d617374657226636f6e6669673d616c6c6275696c6473\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=CPPuddle%2Fmaster&amp;config=allbuilds\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h4 id=\"user-content-purpose\"><a class=\"\
    heading-link\" href=\"#purpose\">Purpose<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h4>\n<p>This repository was initially created to\
    \ explore how to best use HPX and Kokkos together!\nFor fine-grained GPU tasks,\
    \ we needed a way to avoid excessive allocations of one-usage GPU buffers (as\
    \ allocations block the device for all streams) and creation/deletion of GPU executors\
    \ (as those are usually tied to a stream which is expensive to create as well).</p>\n\
    <p>We currently test/use CPPuddle in <a href=\"https://github.com/STEllAR-GROUP/octotiger\"\
    >Octo-Tiger</a>, together with <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\
    >HPX-Kokkos</a>.\nIn this use-case, allocating GPU buffers for all sub-grids in\
    \ advance would have wasted a lot of memory. On the other hand, unified memory\
    \ would have caused unnecessary GPU to CPU page migrations (as the old input data\
    \ gets overwritten anyway). Allocating buffers on-the-fly would have blocked the\
    \ device. Hence, we currently test this buffer management solution!</p>\n<h4 id=\"\
    user-content-tools-provided-by-this-repository\"><a class=\"heading-link\" href=\"\
    #tools-provided-by-this-repository\">Tools provided by this repository<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h4>\n<ul>\n<li>Allocators that\
    \ reuse previousely allocated buffers if available (works with normal heap memory,\
    \ pinned memory, aligned memory, CUDA/HIP device memory, and Kokkos Views). Note\
    \ that separate buffers do not coexist on a single chunk of continuous memory,\
    \ but use different allocations.</li>\n<li>Executor pools and various scheduling\
    \ policies (round robin, priority queue, multi-gpu), which rely on reference counting\
    \ to gauge the current load of a executor instead of querying the device itself.\
    \ Tested with CUDA, HIP and Kokkos executors provided by HPX / HPX-Kokkos.</li>\n\
    <li>Special Executors/Allocators for on-the-fly work GPU aggregation (using HPX).</li>\n\
    </ul>\n<h4 id=\"user-content-requirements\"><a class=\"heading-link\" href=\"\
    #requirements\">Requirements<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h4>\n<ul>\n<li>C++17</li>\n<li>CMake (&gt;= 3.16)</li>\n<li>Optional\
    \ (for the header-only utilities / test): CUDA, Boost, <a href=\"https://github.com/STEllAR-GROUP/hpx\"\
    >HPX</a>, <a href=\"https://github.com/kokkos/kokkos\">Kokkos</a>, <a href=\"\
    https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>\n</li>\n</ul>\n<p>The\
    \ submodules can be used to obtain the optional dependencies which are required\
    \ for testing the header-only utilities. If these tests are not required, the\
    \ submodule (and the respective buildscripts in /scripts) can be ignored safely.</p>\n\
    <h4 id=\"user-content-build--install\"><a class=\"heading-link\" href=\"#build--install\"\
    >Build / Install<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h4>\n\
    <ul>\n<li>\n<p>A spack package for CPPuddle is available in the <a href=\"https://github.com/G-071/octotiger-spack\"\
    >octotiger-spack repository</a></p>\n</li>\n<li>\n<p>Basic CMake build</p>\n</li>\n\
    </ul>\n<pre><code>  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF\
    \                                                             \n  cmake --build\
    \ /path/to/build --target install  \n</code></pre>\n<p>If installed correctly,\
    \ CPPuddle can be used in other CMake-based projects via</p>\n<pre><code>find_package(CPPuddle\
    \ REQUIRED)\n</code></pre>\n<ul>\n<li>Recommended CMake build:</li>\n</ul>\n<pre><code>\
    \  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle\
    \ -DCPPUDDLE_WITH_HPX=ON -DCPPUDDLE_WITH_HPX_AWARE_ALLOCATORS=ON -DCPPUDDLE_WITH_TESTS=OFF\
    \ -DCPPUDDLE_WITH_COUNTERS=OFF                                               \
    \              \n</code></pre>\n"
  stargazers_count: 6
  subscribers_count: 4
  topics: []
  updated_at: 1696743120.0
SCOREC/centos7-spack-config:
  data_format: 2
  description: spack config for erp cluster
  filenames:
  - v0190_gcc910/spack.yaml
  - openFoam24/spack.yaml
  full_name: SCOREC/centos7-spack-config
  latest_release: null
  readme: '<h1 id="user-content-centos7-spack-config"><a class="heading-link" href="#centos7-spack-config">centos7-spack-config<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>centos7 spack configuration and scripts</p>

    <h2 id="user-content-contents"><a class="heading-link" href="#contents">contents<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>compilers.yaml - compiler list

    config.yaml - global config

    install.sh - package installation commands

    modules.yaml - hierarchical layout for lua modules

    packages.yaml - system installed packages

    README.md - this file

    setupSpack.sh - env needed for executing spack commands</p>

    '
  stargazers_count: 1
  subscribers_count: 5
  topics: []
  updated_at: 1696768501.0
SCOREC/dcs-spack-config:
  data_format: 2
  description: Spack config for CCI DCS (AiMOS) system
  filenames:
  - rhel8NvhpcWdmapp/spack.yaml
  - spack.yaml
  full_name: SCOREC/dcs-spack-config
  latest_release: null
  readme: '<h1 id="user-content-dcs-spack-config"><a class="heading-link" href="#dcs-spack-config">dcs-spack-config<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies

    with the IBM XL compilers and Spectrum-MPI.</p>

    <h2 id="user-content-contents"><a class="heading-link" href="#contents">contents<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>compilers.yaml - compiler list</p>

    <p>config.yaml - global config</p>

    <p>install.sh - package installation commands</p>

    <p>modules.yaml - hierarchical layout for lua modules</p>

    <p>packages.yaml - system installed packages</p>

    <p>README.md - this file</p>

    <p>setupSpack.sh - env needed for executing spack commands</p>

    <p>spack.yaml - list of packages to install</p>

    <h2 id="user-content-setup"><a class="heading-link" href="#setup">setup<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <pre><code>git clone git@github.com:spack/spack.git spack

    cd !$

    git checkout v0.13.3

    # add the simmetrix-simmodsuite package from the develop branch

    git cherry-pick 5ddf5e2

    # create the environment

    spack env create v0133

    spack env activate v0133

    # copy the yaml files into the v0133

    cp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.

    # copy the compiler yaml file into the spack etc dir

    cp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.

    </code></pre>

    <h2 id="user-content-install-cmake"><a class="heading-link" href="#install-cmake">install
    cmake<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The bootstrap step of the cmake install fails with the XL compilers.  I

    installed it manually outside of the environment with spack and gcc4.8.5</p>

    <pre><code>spack install cmake%gcc@4.8.5_rhel7

    </code></pre>

    <p>Then added the path to <code>packages.yaml</code>.</p>

    <h2 id="user-content-resuming-work-in-an-environment"><a class="heading-link"
    href="#resuming-work-in-an-environment">resuming work in an environment<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh

    spack env activate v0133

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633029356.0
SCOREC/drp-spack-config:
  data_format: 2
  description: CCI DRP Spack configuration
  filenames:
  - openFoam24/spack.yaml
  full_name: SCOREC/drp-spack-config
  latest_release: null
  readme: '<h1 id="user-content-drp-spack-config"><a class="heading-link" href="#drp-spack-config">drp-spack-config<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>CCI DRP Spack configuration</p>

    <h1 id="user-content-contents"><a class="heading-link" href="#contents">contents<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>openFoam24 - spack environment for an OpenFoam Organization 2.4.0 install</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1593654195.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.20.1/v1/spack.yaml
  - v0.18.1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1 id=\"user-content-setup-on-scorec\"><a class=\"heading-link\" href=\"\
    #setup-on-scorec\">setup on SCOREC<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\nsource\
    \ setupSpack.sh\n</code></pre>\n<h1 id=\"user-content-rhel7-spack-config\"><a\
    \ class=\"heading-link\" href=\"#rhel7-spack-config\">rhel7-spack-config<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2 id=\"user-content-useful-commands\"><a class=\"heading-link\"\
    \ href=\"#useful-commands\">useful commands<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>regenerate lmod module tree:</p>\n\
    <pre><code>spack module lmod refresh\n</code></pre>\n<h2 id=\"user-content-installing-new-packages\"\
    ><a class=\"heading-link\" href=\"#installing-new-packages\">installing new packages<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Our\
    \ spack repo is tracking the master spack branch.  Spack package updates could\
    \ result in additional installation of packages with little or no package source\
    \ code changes.  These additional installs can be avoided when installing new\
    \ packages by first examining the output of the <code>spack spec -I</code> command.\
    \  If a utility/infrastructure level package, such as cmake or mpich, is marked\
    \ with a <code>[+]</code> symbol in the leftmost column then it means that the\
    \ existing install will be used.  If spack does not default to using the existing\
    \ install you can append the hash of the package to the spec command.</p>\n<p>For\
    \ example, lets see what happens when we ask for a pumi install using gcc 7.3.0</p>\n\
    <pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2 id=\"user-content-contents\"><a class=\"heading-link\" href=\"#contents\"\
    >contents<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1683174256.0
ScottWales/spack-environments:
  data_format: 2
  description: null
  filenames:
  - envs/base/spack.yaml
  full_name: ScottWales/spack-environments
  latest_release: null
  readme: "<h1 id=\"user-content-ngm-spack-environments--containers\"><a class=\"\
    heading-link\" href=\"#ngm-spack-environments--containers\">NGM Spack Environments\
    \ &amp; Containers<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <h2 id=\"user-content-repository-layout\"><a class=\"heading-link\" href=\"#repository-layout\"\
    >Repository Layout<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <ul>\n<li>\n<code>bin/</code>: User scripts</li>\n<li>\n<code>ci/</code>: CI scripts</li>\n\
    <li>\n<code>config/</code>: Spack config files</li>\n<li>\n<code>containers/</code>:\
    \ Dockerfiles</li>\n<li>\n<code>envs/</code>: Environments</li>\n<li>\n<code>etc/</code>:\
    \ Config files and build scripts</li>\n<li>\n<code>repos/</code>: Spack Packages</li>\n\
    </ul>\n<h2 id=\"user-content-using-containers\"><a class=\"heading-link\" href=\"\
    #using-containers\">Using containers<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h2>\n<h3 id=\"user-content-run-container-on-gadi\"\
    ><a class=\"heading-link\" href=\"#run-container-on-gadi\">Run container on Gadi<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Load\
    \ the container module</p>\n<pre><code>module use /scratch/hc46/hc46_gitlab/ngm/modules\n\
    module load lfric-v0/gcc-openmpi\n</code></pre>\n<p>The <code>imagerun</code>\
    \ helper script will run a command in the container</p>\n<pre><code>imagerun unifiedmodel_hofx.x\n\
    </code></pre>\n<p><code>imagerun</code> will also set up bind mode MPI automatically,\
    \ use it inside of <code>mpirun</code></p>\n<pre><code>mpirun -n 4 imagerun unifiedmodel_hofx.x\n\
    </code></pre>\n<h3 id=\"user-content-run-container-on-a-generic-system\"><a class=\"\
    heading-link\" href=\"#run-container-on-a-generic-system\">Run container on a\
    \ generic system<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>Run from a container using Apptainer</p>\n<pre><code>apptainer run jopa-intel-openmpi.sif\
    \ unifiedmodel_hofx.x\n</code></pre>\n<p>Configure Bind-mode MPI by mounting your\
    \ system MPI to /bind/openmpi@4</p>\n<pre><code>mpirun -n 4 apptainer run --bind\
    \ /apps/openmpi/4.1.4:/bind/openmpi@4 \\\n    jopa-intel-openmpi.sif unifiedmodel_hofx.x\n\
    </code></pre>\n<h2 id=\"user-content-installing-on-a-bare-system\"><a class=\"\
    heading-link\" href=\"#installing-on-a-bare-system\">Installing on a bare system<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<h3 id=\"\
    user-content-installing-environments-on-nci-gadi\"><a class=\"heading-link\" href=\"\
    #installing-environments-on-nci-gadi\">Installing environments on NCI Gadi<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>To\
    \ install an environment on Gadi run</p>\n<pre><code>./bin/install_gadi.sh ENV\n\
    </code></pre>\n<p>with ENV the name of a directory under <code>envs/</code>.</p>\n\
    <h3 id=\"user-content-installing-environments-on-aws-ec2\"><a class=\"heading-link\"\
    \ href=\"#installing-environments-on-aws-ec2\">Installing environments on AWS\
    \ EC2<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>To install an environment on EC2 run</p>\n<pre><code>./bin/install_aws.sh ENV\n\
    </code></pre>\n<p>The instance should be running Amazon Linux. Spack, Mamba and\
    \ their\ndependencies will be installed if not present.</p>\n<h3 id=\"user-content-installing-environments-on-a-generic-system\"\
    ><a class=\"heading-link\" href=\"#installing-environments-on-a-generic-system\"\
    >Installing environments on a generic system<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>Installing an environment locally\
    \ requires <code>spack</code> and <code>mamba</code> to be installed\nand active.</p>\n\
    <p>To install an environment run</p>\n<pre><code>./bin/install.sh ENV\n</code></pre>\n\
    <h3 id=\"user-content-setting-compiler-and-mpi-version\"><a class=\"heading-link\"\
    \ href=\"#setting-compiler-and-mpi-version\">Setting Compiler and MPI version<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>By\
    \ default the environment will be built with Spack's defaults for compiler and\
    \ MPI.</p>\n<p>To use a different version set the <code>SPACK_COMPILER</code>\
    \ and <code>SPACK_MPI</code> environment\nvariables, e.g.</p>\n<pre><code>export\
    \ SPACK_COMPILER=intel@2021.8.0\nexport SPACK_MPI=openmpi@4.1.4\n\n./bin/install.sh\
    \ lfric-v0\n</code></pre>\n<p>will install the <code>lfric-v0</code> environment\
    \ with that compiler and MPI.</p>\n"
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1688057708.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/archived/special/superlu-sc/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/archived/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/archived/ubuntu20.04-x86_64-gcc-11.4-spack/spack.yaml
  - docker-recipes/runner/ubuntu20.04-amd64-clang-16/spack.yaml
  - docker-recipes/runner/archived/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/archived/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/archived/rhel7-runner-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu22.04-amd64-gcc-11.4/spack.yaml
  - docker-recipes/runner/archived/ubuntu20.04-x86_64-gcc-11.2/spack.yaml
  - docker-recipes/runner/ubuntu22.04-amd64-oneapi-2023.2.1/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 19
  subscribers_count: 7
  topics: []
  updated_at: 1696778511.0
alecbcs/dotfiles:
  data_format: 2
  description: Mirror only. Primary repository is at https://gitlab.com/alecbcs/dotfiles
  filenames:
  - home/.spack/environments/default/spack.yaml
  full_name: alecbcs/dotfiles
  latest_release: null
  readme: "<h1 id=\"user-content-dotfiles\"><a class=\"heading-link\" href=\"#dotfiles\"\
    >dotfiles<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>by Alec Scott and <a href=\"https://github.com/tgamblin/dotfiles\">Todd Gamblin</a></p>\n\
    <h2 id=\"user-content-table-of-contents\"><a class=\"heading-link\" href=\"#table-of-contents\"\
    >Table of Contents<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <ul>\n<li><a href=\"/home/.bashrc\">Bash Config</a></li>\n<li>\n<a href=\"/home/.emacs.d\"\
    >Emacs Config</a>\n<ul>\n<li><a href=\"/home/.emacs.d/init/init-prog-langs.el\"\
    >Programming Languages</a></li>\n<li><a href=\"/home/.emacs.d/init/init-markdown.el\"\
    >Markdown</a></li>\n<li><a href=\"/home/.emacs.d/init/init-org.el\">Org</a></li>\n\
    <li><a href=\"/home/.emacs.d/init/init-podman.el\">Podman</a></li>\n<li><a href=\"\
    /home/.emacs.d/init/init-lsp.el\">LSP</a></li>\n</ul>\n</li>\n<li><a href=\"/home/.gitconfig\"\
    >Git Config</a></li>\n<li><a href=\"/home/.zshrc\">ZSH Config</a></li>\n<li><a\
    \ href=\"/home/.zshenv\">ZSH Env</a></li>\n</ul>\n<h2 id=\"user-content-getting-started\"\
    ><a class=\"heading-link\" href=\"#getting-started\">Getting Started<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>To get started there\
    \ are three easy steps:</p>\n<ol>\n<li>Fork this repo, then clone your fork to\
    \ your computer.</li>\n<li>Put your dotfiles in <code>home/</code> and check them\
    \ in.</li>\n<li>Run the <code>link</code> script to create symbolic links in your\
    \ home directory.</li>\n</ol>\n<p>Now your dotfiles are in a git repo and you\
    \ can clone them anywhere and keep\nthem synchronized.</p>\n<h4 id=\"user-content-linking-in-your-dotfiles-on-a-new-computer\"\
    ><a class=\"heading-link\" href=\"#linking-in-your-dotfiles-on-a-new-computer\"\
    >Linking in Your Dotfiles on a New Computer<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h4>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>alec@laptop dotfiles % ./link\nlinking dotfiles\n  from: /Users/alecbcs/src/dotfiles/home\n\
    \  into: /Users/alecbcs\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ exclude a file/directory</span>\nalec@laptop dotfiles % ./link -e .emacs.d</pre></div>\n\
    <p>If something goes wrong, not to worry.  <code>link</code> keeps backups in\
    \ <code>~/.dotfiles-backup</code>.  You can run <code>unlink</code> to delete\
    \ all the symbolic links and put your old config files back where they were:</p>\n\
    <h4 id=\"user-content-unlinking-your-dotfiles-from-a-computer\"><a class=\"heading-link\"\
    \ href=\"#unlinking-your-dotfiles-from-a-computer\">Unlinking Your Dotfiles from\
    \ a Computer<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h4>\n\
    <div class=\"highlight highlight-source-shell\"><pre>alec@laptop dotfiles % ./unlink\n\
    unlinking dotfiles\n  from: /Users/alecbcs/src/dotfiles/home\n  into: /Users/alecbcs</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1662179736.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent7/library/bak/spack.yaml
  - cent7/python_376/spack.yaml
  - cent8/envs/avx512/rproject/spack.yaml
  - cent8/envs/avx/rproject/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1 id="user-content-spack-environments"><a class="heading-link" href="#spack-environments">SPACK
    Environments<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2 id="user-content-software-deployment-for-centos-8x"><a class="heading-link"
    href="#software-deployment-for-centos-8x">Software deployment for CentOS 8.x<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3 id="user-content-compilers"><a class="heading-link" href="#compilers">Compilers<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3 id="user-content-lu-software"><a class="heading-link" href="#lu-software">LU
    Software<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4 id="user-content-available-environments"><a class="heading-link" href="#available-environments">Available
    Environments<span aria-hidden="true" class="octicon octicon-link"></span></a></h4>

    <h5 id="user-content-solhawk"><a class="heading-link" href="#solhawk">solhawk<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4 id="user-content-avxavx2avx512"><a class="heading-link" href="#avxavx2avx512">avx/avx2/avx512<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4 id="user-content-python-and-r-packages"><a class="heading-link" href="#python-and-r-packages">Python
    and R packages<span aria-hidden="true" class="octicon octicon-link"></span></a></h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4 id="user-content-x86_64"><a class="heading-link" href="#x86_64">x86_64<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2 id="user-content-centos-7x-software"><a class="heading-link" href="#centos-7x-software">CentOS
    7.x software<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657632897.0
boutproject/BOUT-configs:
  data_format: 2
  description: Configuration scripts for BOUT++
  filenames:
  - lassen/spack_env/bout_petsc_with_hypre/spack.yaml
  - lassen/spack_env/bout/spack.yaml
  full_name: boutproject/BOUT-configs
  latest_release: null
  readme: '<h1 id="user-content-configuration-scripts"><a class="heading-link" href="#configuration-scripts">Configuration
    scripts<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>The CMake and autotools (configure/make) scripts supplied with BOUT++

    should be able to automatically find and configure BOUT++ in most

    cases. Where a complex configuration is desired, for example including

    many dependencies (esp. complex dependencies like PETSc), or compiling

    for GPUs, configuration can be quite complex.</p>

    <p>The files in this directory are intended to be convenient shortcuts for

    configuration on particular machines. Where there are many scripts, these

    are put into sub-directories (e.g. "cori" and "lassen").</p>

    <h2 id="user-content-environment"><a class="heading-link" href="#environment">Environment<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Scripts which set up the environment, for example loading and unloading

    modules, start with <code>setup</code> or <code>setup-env</code>. These are typically
    modifying

    shell environments and so should be invoked with <code>source</code>.</p>

    <h2 id="user-content-bout-configuration"><a class="heading-link" href="#bout-configuration">BOUT++
    configuration<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The wrappers around CMake (or configure) start with <code>config</code> or
    <code>config-bout</code>.

    These are shell scripts which can be run without <code>source</code>.</p>

    '
  stargazers_count: 1
  subscribers_count: 17
  topics: []
  updated_at: 1686816130.0
camierjs/okina-jit:
  data_format: 2
  description: null
  filenames:
  - config/docker/spack.yaml
  full_name: camierjs/okina-jit
  latest_release: null
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2 id=\"user-content-license\"><a class=\"heading-link\"\
    \ href=\"#license\">License<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>MFEM is distributed under the terms of the BSD-3 license.\
    \ All new contributions\nmust be made under this license. See <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> for\ndetails.</p>\n<p>SPDX-License-Identifier:\
    \ BSD-3-Clause <br>\nLLNL Release Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1689268998.0
celeritas-project/celeritas:
  data_format: 2
  description: Celeritas is a new Monte Carlo transport code designed for high-performance
    simulation of high-energy physics detectors.
  filenames:
  - scripts/spack.yaml
  full_name: celeritas-project/celeritas
  latest_release: v0.3.2
  readme: "<h1 id=\"user-content-celeritas\"><a class=\"heading-link\" href=\"#celeritas\"\
    >Celeritas<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>The Celeritas project implements HEP detector physics on GPU accelerator\n\
    hardware with the ultimate goal of supporting the massive computational\nrequirements\
    \ of the <a href=\"https://home.cern/science/accelerators/high-luminosity-lhc\"\
    \ rel=\"nofollow\">HL-LHC upgrade</a>.</p>\n<h1 id=\"user-content-documentation\"\
    ><a class=\"heading-link\" href=\"#documentation\">Documentation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>Most of the Celeritas\
    \ documentation is readable through the codebase through a\ncombination of <a\
    \ href=\"doc/index.rst\">static RST documentation</a> and Doxygen-markup\ncomments\
    \ in the source code itself. The full <a href=\"https://celeritas-project.github.io/celeritas/user/index.html\"\
    \ rel=\"nofollow\">Celeritas user\ndocumentation</a> (including selected code\
    \ documentation incorporated\nby Breathe) and the <a href=\"https://celeritas-project.github.io/celeritas/dev/index.html\"\
    \ rel=\"nofollow\">Celeritas code documentation</a> are mirrored on\nour GitHub\
    \ pages site. You can generate these yourself (if the necessary\nprerequisites\
    \ are installed) by\nsetting the <code>CELERITAS_BUILD_DOCS=ON</code> configuration\
    \ option and running <code>ninja doc</code> (user) or <code>ninja doxygen</code>\
    \ (developer). A continuously updated version of\nthe <a href=\"https://celeritas.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">static Celeritas user documentation</a> (without API documentation)\
    \ is\nhosted on <code>readthedocs.io</code>.</p>\n<h1 id=\"user-content-installation-for-applications\"\
    ><a class=\"heading-link\" href=\"#installation-for-applications\">Installation\
    \ for applications<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>The easiest way to install Celeritas as a library/app is with Spack:</p>\n\
    <ul>\n<li>Follow the first two steps above to install <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">Spack</a> and set up its CUDA usage.</li>\n<li>Install Celeritas\
    \ with <code>spack install celeritas</code>\n</li>\n<li>Use <code>spack load celeritas</code>\
    \ to add the installation to your <code>PATH</code>.</li>\n</ul>\n<p>Then see\
    \ the \"Downstream usage as a library\" section of the <a href=\"doc/installation.rst\"\
    >installation\ndocumentation</a> for how to use Celeritas in your application\
    \ or framework.</p>\n<h1 id=\"user-content-installation-for-developers\"><a class=\"\
    heading-link\" href=\"#installation-for-developers\">Installation for developers<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>Since\
    \ Celeritas is still under heavy development and is not yet full-featured\nfor\
    \ downstream integration, you are likely installing it for development\npurposes.\
    \ The <a href=\"doc/installation.rst\">installation documentation</a> has a\n\
    complete description of the code's dependencies and installation process for\n\
    development.</p>\n<p>As an example, if you have the <a href=\"https://github.com/spack/spack\"\
    >Spack</a> package manager\ninstalled and want to do development on a CUDA system\
    \ with Volta-class graphics\ncards, execute the following steps from within the\
    \ cloned Celeritas source\ndirectory:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre># <span class=\"pl-s1\">Set up CUDA (optional)</span>\n$ <span class=\"\
    pl-s1\">spack external find cuda</span>\n$ <span class=\"pl-s1\">spack config\
    \ add packages:all:variants:<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>+cuda\
    \ cuda_arch=70<span class=\"pl-pds\">\"</span></span></span>\n# <span class=\"\
    pl-s1\">Install celeritas dependencies</span>\n$ <span class=\"pl-s1\">spack env\
    \ create celeritas scripts/spack.yaml</span>\n$ <span class=\"pl-s1\">spack env\
    \ activate celeritas</span>\n$ <span class=\"pl-s1\">spack install</span>\n# <span\
    \ class=\"pl-s1\">Configure, build, and <span class=\"pl-c1\">test</span></span>\n\
    $ <span class=\"pl-s1\">./build.sh base</span></pre></div>\n<p>If you don't use\
    \ Spack but have all the dependencies you want (Geant4,\ngoogletest, VecGeom,\
    \ etc.) in your <code>CMAKE_PREFIX_PATH</code>, you can configure and\nbuild Celeritas\
    \ as you would any other project:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">mkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build</span>\n$ <span class=\"pl-s1\">cmake\
    \ ..</span>\n$ <span class=\"pl-s1\">make <span class=\"pl-k\">&amp;&amp;</span>\
    \ ctest</span></pre></div>\n<p>Celeritas guarantees full compatibility and correctness\
    \ only on the\ncombinations of compilers and dependencies tested under continuous\
    \ integration.\nCurrently supported compilers are GCC 11.2 + NVCC 11.8, and HIP-Clang\
    \ 15.0, but\nsince we compile with extra warning flags and avoid non-portable\
    \ code, most\nother compilers <em>should</em> work.\nCurrently Geant4 11.0 and\
    \ VecGeom 1.2 are the only versions that are guaranteed\nto work, but older versions\
    \ might be OK.\nThe full set of configurations is viewable on <a href=\"https://cloud.cees.ornl.gov/jenkins-ci/blue/organizations/jenkins/Celeritas/activity?branch=master\"\
    \ rel=\"nofollow\">the CI web site</a>.\nCompatibility fixes that do not cause\
    \ newer versions to fail are welcome.</p>\n<h1 id=\"user-content-development\"\
    ><a class=\"heading-link\" href=\"#development\">Development<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>See the <a href=\"\
    CONTRIBUTING.rst\">contribution guide</a> for the contribution process,\n<a href=\"\
    doc/appendices/development.rst\">the development guidelines</a> for further\n\
    details on coding in Celeritas, and <a href=\"doc/appendices/administration.rst\"\
    >the administration guidelines</a> for community standards and roles.</p>\n<h1\
    \ id=\"user-content-citing-celeritas\"><a class=\"heading-link\" href=\"#citing-celeritas\"\
    >Citing Celeritas<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>If using Celeritas in your work, we ask that you cite the code using its\n\
    <a href=\"https://www.osti.gov/doecode/biblio/94866\" rel=\"nofollow\">DOECode</a>\
    \ registration:</p>\n<blockquote>\n<p>Johnson, Seth R., Amanda Lund, Soon Yung\
    \ Jun, Stefano Tognini, Guilherme Lima, Paul Romano, Philippe Canal, Ben Morgan,\
    \ and Tom Evans. \u201CCeleritas,\u201D July 2022. <a href=\"https://doi.org/10.11578/dc.20221011.1\"\
    \ rel=\"nofollow\">https://doi.org/10.11578/dc.20221011.1</a>.</p>\n</blockquote>\n\
    <p>Additional references for code implementation details, benchmark problem\n\
    results, etc., can be found in our continually evolving <a href=\"doc/_static/celeritas.bib\"\
    >citation\nfile</a>. An <a href=\"https://github.com/celeritas-project/celeritas-docs/blob/main/presentations/presentations.bib\"\
    >exhaustive list of Celeritas presentations\n</a>\nauthored by (or with content\
    \ authored by) core team members is available in our\ndocuments repo.</p>\n"
  stargazers_count: 40
  subscribers_count: 13
  topics:
  - hep
  - cuda
  - computational-physics
  - monte-carlo
  updated_at: 1694315157.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<h1 id=\"user-content-d-seams\"><a class=\"heading-link\" href=\"#d-seams\"\
    >d-SEAMS<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p><strong>Deferred Structural Elucidation Analysis for Molecular Simulations</strong></p>\n\
    <p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82b492dd4f94cd6fe1783f1065487d3dbc0602c2a65b1717a5613df3b6e8f65f/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <h1 id=\"user-content-citation\"><a class=\"heading-link\" href=\"#citation\"\
    >Citation<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <ul>\n<li>\n<p>This has been published at the <a href=\"https://doi.org/10.1021/acs.jcim.0c00031\"\
    \ rel=\"nofollow\">Journal of Chemical Information and Modeling\n(JCIM)</a></p>\n\
    </li>\n<li>\n<p>You may also read <a href=\"https://arxiv.org/abs/1909.09830\"\
    \ rel=\"nofollow\">the preprint on arXiv</a></p>\n</li>\n</ul>\n<p>If you use\
    \ this software please cite the following:</p>\n<pre><code>Goswami, R., Goswami,\
    \ A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations. Journal of Chemical Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n\
    </code></pre>\n<p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<h1 id=\"user-content-compilation\"\
    ><a class=\"heading-link\" href=\"#compilation\">Compilation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>We use a deterministic\
    \ build system to generate both bug reports and uniform\nusage statistics. This\
    \ also handles the <code>lua</code> scripting engine.</p>\n<p>\\note The lua functions\
    \ are documented on the <a href=\"https://docs.dseams.info/md_markdown_luafunctions\"\
    \ rel=\"nofollow\">on the API Docs</a></p>\n<p>We also provide a <code>conda</code>\
    \ environment as a fallback, which is also recommended for MacOS users.</p>\n\
    <h2 id=\"user-content-build\"><a class=\"heading-link\" href=\"#build\">Build<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<h3 id=\"\
    user-content-conda-working-now\"><a class=\"heading-link\" href=\"#conda-working-now\"\
    >Conda (working now)<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<p>Although we strongly suggest using <code>nix</code>, for\
    \ MacOS systems, the following\ninstructions may be more suitable. We will assume\
    \ the presence of <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\"\
    \ rel=\"nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-k\">~</span>/seams-core\n\
    micromamba create -f environment.yml\nmicromamba activate dseams\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Now the installation can proceed.</p>\n<p>\\note\
    \ we do not install <code>lua-luafilesystem</code> within the <code>conda</code>\
    \ environment because it is outdated on <code>osx</code></p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>mkdir build\n<span class=\"pl-c1\">cd</span> build\n\
    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span\
    \ class=\"pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake\
    \ install\n<span class=\"pl-smi\">$CONDA_PREFIX</span>/bin/yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<h3 id=\"\
    user-content-spack-not-working-at-the-moment\"><a class=\"heading-link\" href=\"\
    #spack-not-working-at-the-moment\">Spack (not working at the moment)<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Manually this can be\
    \ done in a painful way as follows:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack install eigen@3.3.9 lua@5.2\nspack install catch2 fmt yaml-cpp openblas\
    \ boost cmake ninja meson\nspack load catch2 fmt yaml-cpp openblas boost cmake\
    \ ninja meson eigen@3.3.9 lua@5.2\nluarocks install luafilesystem</pre></div>\n\
    <p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack\
    \ env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span class=\"\
    pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> After\
    \ loading the packages</span>\nluarocks install luafilesystem</pre></div>\n<p>Now\
    \ we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<h3 id=\"user-content-nix-not-working-at-the-moment\"\
    ><a class=\"heading-link\" href=\"#nix-not-working-at-the-moment\">Nix (not working\
    \ at the moment)<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>Since this project is built with <code>nix</code>, we can simply do the following\
    \ from the\nroot directory (longer method):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Make sure there are no\
    \ artifacts</span>\nrm -rf build\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ This will take a long time the first time as it builds the dependencies</span>\n\
    nix-build <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Optional</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install into your path</span>\nnix-env -if <span class=\"pl-c1\">.</span> <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Required</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Run the command anywhere</span>\nyodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>A faster method of building the software\
    \ is by using the <a href=\"https://dseams.cachix.org/\" rel=\"nofollow\">cachix\
    \ binary cache</a> as shown:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Install cachix</span>\n\
    nix-env -iA cachix -f https://cachix.org/api/v1/install\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> Use the binary cache</span>\ncachix use dseams\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with the cache than\
    \ building from scratch</span>\nnix-build <span class=\"pl-c1\">.</span> <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\nnix-env -if\
    \ <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run the\
    \ command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n<h3\
    \ id=\"user-content-usage\"><a class=\"heading-link\" href=\"#usage\">Usage<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Having\
    \ installed the <code>yodaStruct</code> binary and library, we can now use it.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>\\note The paths in the <code>.yml</code> should be <strong>relative to the\
    \ folder from which the binary is called</strong>.</p>\n<p>If you're confused\
    \ about how to handle the relative paths, run the command <code>yodaStruct -c\
    \ lua_inputs/config.yml</code> in the top-level directory, and set the paths relative\
    \ to the top-level directory. This is the convention used in the examples as well.</p>\n\
    <h3 id=\"user-content-language-server-support\"><a class=\"heading-link\" href=\"\
    #language-server-support\">Language Server Support<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>To generate a <code>compile_commands.json</code>\
    \ file for working with a language server\nlike <a href=\"https://github.com/MaskRay/ccls\"\
    >ccls</a> use the following commands:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\n\
    nix-shell --pure\nmkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span\
    \ class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES\
    \ ../\ncp compile_commands.json ../</pre></div>\n<p>Note that there is no need\
    \ to actually compile the project if you simply need to\nget the compiler database\
    \ for the language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<h2 id=\"user-content-development\"><a class=\"heading-link\" href=\"\
    #development\">Development<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>We can simply use the <code>nix</code> environment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> From the project root</span>\nnix-shell --pure</pre></div>\n\
    <h1 id=\"user-content-running\"><a class=\"heading-link\" href=\"#running\">Running<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>This\
    \ is built completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install systemwide\n\
    nix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply install the\
    \ software, and ensure that <code>input/</code> is a child directory.</p>\n<pre\
    \ lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<h2 id=\"user-content-tests\"\
    ><a class=\"heading-link\" href=\"#tests\">Tests<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>Apart from the <a href=\"https://docs.dseams.info/pages.html\"\
    \ rel=\"nofollow\">examples</a>, the test-suite\ncan be run with the <code>yodaStruct_test</code>\
    \ binary, which will drop into the\n<code>nix</code> environment before building\
    \ and executing <code>gdb</code>:</p>\n<pre lang=\"{bash}\"><code># Just run this\n\
    ./testBuild.sh\n# At this point the binary and library are copied into the root\n\
    # One might, in a foolhardy attempt, use gdb at this point\n# Here be dragons\
    \ :)\n# USE NIX\n# Anyway\ngdb --args ./yodaStruct -c lua_inputs/config.yml\n\
    # quit gdb with quit\n# Go run the test binary\ncd shellBuild\n./yodaStruct_test\n\
    </code></pre>\n<p>Do note that the regular installation via <code>nix-env</code>\
    \ runs the tests before the installation</p>\n<h1 id=\"user-content-developer-documentation\"\
    ><a class=\"heading-link\" href=\"#developer-documentation\">Developer Documentation<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\n<p>While\
    \ developing, it is sometimes expedient to update the packages used. It is\nthen\
    \ useful to note that we use <a href=\"https://github.com/nmattia/niv/\">niv</a>\
    \ to handle our pinned packages (apart from\nthe ones built from Github). Thus,\
    \ one might need, say:</p>\n<div class=\"highlight highlight-source-shell\"><pre>niv\
    \ update nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with nix:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>nix-build <span class=\"\
    pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Outputs are\
    \ in ./result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> If you\
    \ get a CMake error</span>\nrm -rf build\nnix-store --delete /nix/store/<span\
    \ class=\"pl-smi\">$whatever</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> $whatever is the derivation complaining</span>\nnix-collect-garbage\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> then try again [worst case\
    \ scenario]</span></pre></div>\n<h2 id=\"user-content-leaks-and-performance\"\
    ><a class=\"heading-link\" href=\"#leaks-and-performance\">Leaks and performance<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>While\
    \ testing for leaks, use <code>clang</code> (for\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\"\
    >AddressSanitizer</a>\nand\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<h1 id=\"user-content-overview\"\
    ><a class=\"heading-link\" href=\"#overview\">Overview<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h1>\n<p>As of Mon Jan 20 15:57:18\
    \ 2020, the lines of code calculated by\n<a href=\"http://cloc.sourceforge.net/\"\
    \ rel=\"nofollow\">cloc</a> are as follows:</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"><img src=\"images/cloc-2020-01-20_15-56.png\"\
    \ alt=\"Cloc Lines\" style=\"max-width: 100%;\"></a></p>\n<h1 id=\"user-content-contributing\"\
    ><a class=\"heading-link\" href=\"#contributing\">Contributing<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>Please ensure that\
    \ all contributions are formatted according to the\n<a href=\"./clang-format\"\
    >clang-format</a> configuration file.</p>\n<p>Specifically, consider using the\
    \ following:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\"\
    >Sublime Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"\
    https://github.com/lassik/emacs-format-all-the-code\">format-all</a> for Emacs</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\">vim-clang-format</a>\
    \ for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <h2 id=\"user-content-commit-hook\"><a class=\"heading-link\" href=\"#commit-hook\"\
    >Commit Hook<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>Note that we expect compliance with the <code>clang-format</code> as mentioned\
    \ above, and this may be enforced by using the provided scripts for a pre-commit\
    \ hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<h2 id=\"user-content-development-builds\"\
    ><a class=\"heading-link\" href=\"#development-builds\">Development Builds<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The\
    \ general idea is to drop into an interactive shell with the dependencies and\
    \ then use <code>cmake</code> as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>nix-shell --pure --run bash --show-trace --verbose\n<span class=\"pl-c1\"\
    >cd</span> build\ncmake .. -DCMAKE_BUILD_TYPE=Debug -DNO_WARN=TRUE \\\n -DFIND_EIGEN=TRUE\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n -G <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Ninja<span class=\"pl-pds\">\"</span></span>\nninja\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Test</span>\n<span class=\"pl-c1\">cd</span>\
    \ ../\nyodaStruct -c lua_inputs/config.yml\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Debug</span>\ngdb --args yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>To load debugging symbols from the shared library, when you are inside <code>gdb</code>\
    \ (from the top-level directory, for instance), use the following command:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>add-symbol-file build/libyodaLib.so</pre></div>\n\
    <p>Then you can set breakpoints in the C++ code; for instance:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>b seams_input.cpp:408</pre></div>\n<h1\
    \ id=\"user-content-acknowledgements\"><a class=\"heading-link\" href=\"#acknowledgements\"\
    >Acknowledgements<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>The following tools are used in this project:</p>\n<ul>\n<li>\n<a href=\"https://cmake.org/\"\
    \ rel=\"nofollow\">CMake</a> for compilation (<a href=\"https://github.com/cginternals/cmake-init\"\
    >cmake-init</a> was used as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\"\
    \ rel=\"nofollow\">Clang</a> because it is more descriptive with better tools</li>\n\
    <li>\n<a href=\"https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the\
    \ developer API</li>\n<li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\"\
    \ rel=\"nofollow\">clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"\
    https://github.com/barisione/clang-format-hooks\">clang-format-hooks</a> for <code>git</code>\
    \ hooks to enforce formatting</li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\"\
    \ rel=\"nofollow\">lua</a> for the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\"\
    \ rel=\"nofollow\">yaml</a> for the configuration</li>\n</ul>\n<h2 id=\"user-content-third-party-libraries\"\
    ><a class=\"heading-link\" href=\"#third-party-libraries\">Third Party Libraries<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The\
    \ libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n<li>\n<a href=\"https://github.com/renatoGarcia/icecream-cpp\"\
    >icecream-cpp</a> for pretty-printing and debugging</li>\n</ul>\n"
  stargazers_count: 31
  subscribers_count: 5
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1695765607.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - hmmer-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<h1 id="user-content-benchmark-containers"><a class="heading-link" href="#benchmark-containers">Benchmark
    Containers<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
eflows4hpc/workflow-registry:
  data_format: 2
  description: Registry to store workflow descriptions
  filenames:
  - tutorial/lysozyme/spack.yaml
  - minimal_workflow/wordcount/spack.yaml
  - kaust/exageostat/spack.yaml
  full_name: eflows4hpc/workflow-registry
  latest_release: 2nd_stack_release
  readme: "<h1 id=\"user-content-workflow-registry\"><a class=\"heading-link\" href=\"\
    #workflow-registry\">Workflow Registry<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h1>\n<p>This is a repository to store the Workflow\
    \ descriptions using the eFlows4HPC methodology. This description consist of at\
    \ least the TOSCA description of the worklfow, the code of the their different\
    \ steps and their required software per step.</p>\n<h2 id=\"user-content-repository-structure\"\
    ><a class=\"heading-link\" href=\"#repository-structure\">Repository structure<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Workflow\
    \ descriptions have to be included inside this repository according to the following\
    \ structure.</p>\n<pre><code>workflow-registry\n  |- workflow_1\n  |    |- tosca\n\
    \  |    |    |- types.yml               TOSCA description of the different components\
    \ involved in the workflow\n  |    |       ... \n  |    |- step_1\n  |    |  \
    \  |- spack.yml               Sofware requirements for this workflow step as a\
    \ Spack environment specification \n  |    |    |- src                     PyCOMPSs\
    \ code of the workflow step\n  |    |       ...\n  |    |- step_2\n  |       \
    \  ....\n  |- workflow_2                                \n  |\t...\n\n</code></pre>\n\
    <h2 id=\"user-content-including-new-workflows\"><a class=\"heading-link\" href=\"\
    #including-new-workflows\">Including new Workflows<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>To include new workflows in the repository,\
    \ first create a new fork of the repository and  include a new folder for the\
    \ workflow with a subfolder for the TOSCA description and the different workflow\
    \ steps. Finally, create a pull request with the new workflow description. This\
    \ pull request will be reviewed and included in the repository.</p>\n"
  stargazers_count: 2
  subscribers_count: 10
  topics: []
  updated_at: 1675113861.0
eic/containers:
  data_format: 2
  description: Container building infrastructure (mirror of https://eicweb.phy.anl.gov/containers/eic_container)
  filenames:
  - spack-environment/dev/spack.yaml
  full_name: eic/containers
  latest_release: null
  readme: '<h1 id="user-content-eic-software-environment-container"><a class="heading-link"
    href="#eic-software-environment-container">EIC software environment container<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>For installation instructions of <code>eic-shell</code>, see <a href="https://github.com/eic/eic-shell">https://github.com/eic/eic-shell</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1693159888.0
epfl-scitas/spack-sdploy:
  data_format: 2
  description: Toolset to deploy software stacks
  filenames:
  - samples/spack.yaml
  full_name: epfl-scitas/spack-sdploy
  latest_release: null
  readme: "<h1 id=\"user-content-spack-sdploy\"><a class=\"heading-link\" href=\"\
    #spack-sdploy\">spack-sdploy<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p>Spack extension for automatic package configuration and\
    \ deployment.</p>\n<h2 id=\"user-content-how-to-install\"><a class=\"heading-link\"\
    \ href=\"#how-to-install\">How to install<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h2>\n<p>You can try out this Spack extension be\
    \ executing 4 easy steps:</p>\n<ul>\n<li>Set up and activate a local python environment</li>\n\
    <li>Set up and activate <code>spack</code>\n</li>\n<li>Install <code>spack-sdploy</code>\
    \ dependencies</li>\n<li>Clone and configure spack-sdploy</li>\n</ul>\n<p>This\
    \ 4 steps are now detailed in the next section.</p>\n<h3 id=\"user-content-step-by-step-installation\"\
    ><a class=\"heading-link\" href=\"#step-by-step-installation\">Step-by-step installation<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Just\
    \ for a matter of completeness, all the steps needed get up and running with\n\
    spack-sdploy extension will be covered, which can be a bit pedantic.</p>\n<h4\
    \ id=\"user-content-set-up-and-activate-a-local-python-environment\"><a class=\"\
    heading-link\" href=\"#set-up-and-activate-a-local-python-environment\">Set up\
    \ and activate a local python environment<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h4>\n<p>It is recommended that a Python environment\
    \ be used to support sdploy. This same\nPython can also be used to run Spack.</p>\n\
    <pre><code>python3 -m venv &lt;path-to-environment-directory&gt;\n. &lt;path-to-environment-directory&gt;/bin/activate\n\
    </code></pre>\n<p>For more information on how to create a virtual environment\
    \ in Python refer to\nthe PEP 405 \u2013 Python Virtual Environments documentation.</p>\n\
    <h4 id=\"user-content-set-up-and-activate-spack\"><a class=\"heading-link\" href=\"\
    #set-up-and-activate-spack\">Set up and activate Spack<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h4>\n<p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">Spack documentation</a>\non how to install Spack. For sake\
    \ of completeness, we copy paste the commands here:</p>\n<pre><code>git clone\
    \ -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n\
    </code></pre>\n<h4 id=\"user-content-install-spack-sdploy-dependencies\"><a class=\"\
    heading-link\" href=\"#install-spack-sdploy-dependencies\">Install <code>spack-sdploy</code>\
    \ dependencies<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h4>\n\
    <p>Up to now the only dependency of spack-sdploy if jinja2. Once you have activated\n\
    Python environment, you can simply use pip to install the packages.</p>\n<pre><code>pip\
    \ install jinja2\n</code></pre>\n<h4 id=\"user-content-clone-and-configure-spack-sdploy\"\
    ><a class=\"heading-link\" href=\"#clone-and-configure-spack-sdploy\">Clone and\
    \ configure spack-sdploy<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h4>\n<pre><code>git clone git@github.com:epfl-scitas/spack-sdploy\n\
    </code></pre>\n<p>To activate the spack-sdploy extension you must add it to the\
    \ config.yaml. If\nyou already have another Spack installation and just want to\
    \ try out\nspack-sdploy may very well create a temporary directory to store the\n\
    configuration and then use the SPACK_USER_CONFIG_PATH variable to point this new\n\
    directory.</p>\n<pre><code>mkdir temporary_config\nexport SPACK_USER_CONFIG_PATH=/path/to/temporary_config\n\
    </code></pre>\n<p>and then, inside the temporary_config directory, write a config.yaml\
    \ file with\nthe following contents:</p>\n<pre><code>config:\n  extensions:\n\
    \  - /path/to/spack-sdploy\n</code></pre>\n<p>Be sure you do not change the spack-dploy\
    \ directory. Spack forces the extensions\nto follow strict rules. Please see the\n\
    <a href=\"https://spack.readthedocs.io/en/latest/extensions.html\" rel=\"nofollow\"\
    >Spack Extensions</a>\ndocumentation for more details about this subject. At this\
    \ point you should now\nbe able to call <code>spack -h</code> and see the new\
    \ Spack commands deployed by the\nspack-sdploy extension.</p>\n<h2 id=\"user-content-how-to-use\"\
    ><a class=\"heading-link\" href=\"#how-to-use\">How to use<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>At the present time,\
    \ spack-sdploy will add 2 commands to your already existing\nSpack commands. These\
    \ commandes are:</p>\n<pre><code>spack write-spack-yaml\nspack write-packages-yaml\n\
    </code></pre>\n<p>In the future we may change the names of these commands, but\
    \ for now lets just\nimagine these are short and easy to type commands.</p>\n\
    <p>As you may have guessed it (if you haven't that's ok), write-spack-yaml will\n\
    write the spack.yaml file and write-packages-yaml will write the packages.yaml\n\
    file. Of course, Spack does not (yet!) guess what you may want to install and\n\
    for that purpose, both these commands will read all the specs you want in your\n\
    spack.yaml file by reading another file you have previously written and which\n\
    we call by stack.yaml.</p>\n<p>For the time being, spack-sdploy already comes\
    \ with a dummy stack.yaml so we can\nget started using the new commands.</p>\n\
    <h2 id=\"user-content-write-spack-yaml\"><a class=\"heading-link\" href=\"#write-spack-yaml\"\
    >write-spack-yaml<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <pre><code>spack write-spack-yaml\n</code></pre>\n<h2 id=\"user-content-write-packages-yaml\"\
    ><a class=\"heading-link\" href=\"#write-packages-yaml\">write-packages-yaml<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<pre><code>spack\
    \ write-packages-yaml\n</code></pre>\n<h2 id=\"user-content-write-activate-list\"\
    ><a class=\"heading-link\" href=\"#write-activate-list\">write-activate-list<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<pre><code>spack\
    \ write-activate-list -p &lt;platform&gt; -s &lt;stack&gt;\n</code></pre>\n<p>Write\
    \ to file named <code>packages_to_activate</code> list of packages to activate,\
    \ using <code>spack activate &lt;package&gt;</code>. Packages are writen one per\
    \ line.</p>\n<p>Packages to activate can be marked in the stack file in two possible\
    \ ways: by adding the keyword <code>activate: true</code> in the metadata section\
    \ of a list of packages or by adding the keyword <code>activate: true</code> to\
    \ an individual package. Duplicates are removed.</p>\n"
  stargazers_count: 0
  subscribers_count: 9
  topics: []
  updated_at: 1669125412.0
esm-tools/esm_tools:
  data_format: 2
  description: Simple Infrastructure for Earth System Simulations
  filenames:
  - configs/spack_envs/albedo-spack.yaml
  full_name: esm-tools/esm_tools
  latest_release: v6.0.0
  stargazers_count: 21
  subscribers_count: 8
  topics: []
  updated_at: 1690976930.0
eth-cscs/spack-batteries-included:
  data_format: 2
  description: Installing spack without system dependencies
  filenames:
  - build/3_more_tools/spack.yaml
  full_name: eth-cscs/spack-batteries-included
  latest_release: develop
  readme: "<p><a href=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml\"\
    ><img src=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\"\
    \ alt=\"Update spack develop version\" style=\"max-width: 100%;\"></a></p>\n<h1\
    \ id=\"user-content--spack-with-batteries-included-linuxx86_64\"><a class=\"heading-link\"\
    \ href=\"#-spack-with-batteries-included-linuxx86_64\">\U0001F50B Spack with batteries\
    \ included (linux/x86_64)<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p><a href=\"https://github.com/spack/spack\">Spack</a> is\
    \ a package manager, and package managers should be trivial to install.</p>\n\
    <p>This repo offers a single, static executable for Spack:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">wget -qO\
    \ spack.x https://github.com/eth-cscs/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n\
    $ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x\
    \ install curl tls=mbedtls</span></pre></div>\n<h2 id=\"user-content-what-version-of-spack-is-shipped\"\
    ><a class=\"heading-link\" href=\"#what-version-of-spack-is-shipped\">What version\
    \ of Spack is shipped?<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>The URL above gives you a rolling release of Spack's develop\
    \ branch, which is updated\nhourly. The exact commit SHA is included as a file\
    \ and can be retrieved like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"\
    pl-k\">&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints\
    \ the Spack commit sha]</span></pre></div>\n<h2 id=\"user-content-supported-platforms\"\
    ><a class=\"heading-link\" href=\"#supported-platforms\">Supported platforms<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<ul>\n\
    <li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n<li>Debian 8 and\
    \ above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and above</li>\n\
    <li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for Linux 2 with any\
    \ of the above distro's.</li>\n</ul>\n<p>The system dependencies are <code>glibc\
    \ 2.17</code> and above and optionally the <code>fusermount</code>\nexecutable.\
    \ If your system supports rootless containers it likely has <code>fusermount</code>\n\
    installed already!</p>\n<h2 id=\"user-content-how-does-it-work\"><a class=\"heading-link\"\
    \ href=\"#how-does-it-work\">How does it work?<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p><code>spack.x</code> consists of a\
    \ modified version of the AppImage runtime concatenated\nwith a big squashfs file\
    \ which includes <code>binutils</code>, <code>bzip2</code>, <code>clingo</code>,\
    \ <code>curl</code>,\n<code>file</code>, <code>git</code>, <code>gmake</code>,\
    \ <code>gpg</code>, <code>gzip</code>, <code>openssl</code>, <code>patch</code>,\
    \ <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>, <code>tar</code>,\
    \ <code>unzip</code>, <code>xz</code>, <code>zstd</code> and their dependencies.</p>\n\
    <p>When you run <code>spack.x [args]</code> it will use <code>fusermount</code>\
    \ to\nmount this squashfs file in a temporary directory, and then execute the\n\
    entrypoint executable <a href=\"build/6_spack/spack\">spack</a>.</p>\n<p>The <code>spack</code>\
    \ executable sets some environment variables like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code>\
    \ to the bin and lib folders of the squashfs file, and then it\nexecutes <code>python3\
    \ spack_src/bin/spack [args]</code>.</p>\n<p>When the command is done running,\
    \ the runtime unmounts the squashfs file again.</p>\n<h2 id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    ><a class=\"heading-link\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    >My system doesn't allow me to use <code>fusermount</code>, what now?<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p><code>fusermount</code>\
    \ is used to mount a squashfs file included in the binary. If you\ndon't want\
    \ that, you can just extract it:</p>\n<pre><code>$ spack.x --squashfs-extract\n\
    $ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\
    </code></pre>\n<p>but working with the extracted <code>spack</code> folder can\
    \ come with a performance\npenalty on shared filesystems in HPC centers.</p>\n\
    <h2 id=\"user-content-differences-and-improvements-over-appimage-runtime\"><a\
    \ class=\"heading-link\" href=\"#differences-and-improvements-over-appimage-runtime\"\
    >Differences and improvements over AppImage runtime<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<ul>\n<li>spack.x uses <code>zstd</code>\
    \ for faster decompression;</li>\n<li>spack.x itself is an entirely static binary;</li>\n\
    <li>spack.x does not need to dlopen libfuse.so.</li>\n</ul>\n<h2 id=\"user-content-troubleshooting\"\
    ><a class=\"heading-link\" href=\"#troubleshooting\">Troubleshooting<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p><strong>immutability</strong>\
    \ The squashfs mountpoint is a readonly folder, meaning that\nspack can't write\
    \ to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard\
    \ directories, see <code>spack.x config blame config</code> for details.</p>\n\
    <p>Note, spack.x applies <a href=\"https://github.com/spack/spack/pull/20158/\"\
    >this patch</a>\nto ensure that log files are written to the <code>config:misc_cache</code>\
    \ folder.</p>\n<p><strong>openssl</strong>: By default spack.x uses <code>ca-certificates-mozilla</code>\
    \ for downloading\npackage sources over https. If you somehow need to use system\
    \ certificates,\nset <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAINFO</code>\
    \ or <code>SSL_CERT_FILE</code> and <code>GIT_SSL_CERT</code>.</p>\n<h2 id=\"\
    user-content-can-i-run-spackx-inside-a-container\"><a class=\"heading-link\" href=\"\
    #can-i-run-spackx-inside-a-container\">Can I run spack.x inside a container?<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Yes,\
    \ but please don't! Since <code>fusermount</code> is a setuid binary, you will\
    \ need to\nrun a privileged container, which is never a good idea.</p>\n<p>The\
    \ recommended way to run spack.x inside a container is to just extract it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >spack.x --squashfs-extract</span>\n$ <span class=\"pl-s1\">./spack/spack --version</span></pre></div>\n\
    <p>If you insist on running spack.x in Docker, this is one way to do it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >sudo docker run --privileged --device /dev/fuse -it -v <span class=\"pl-smi\"\
    >$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n# <span class=\"pl-s1\"\
    >apt update <span class=\"pl-k\">&amp;&amp;</span> apt install fuse <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n# <span\
    \ class=\"pl-s1\">spack.x --version</span></pre></div>\n<h2 id=\"user-content-running-an-executable-shipped-with-spackx-directly\"\
    ><a class=\"heading-link\" href=\"#running-an-executable-shipped-with-spackx-directly\"\
    >Running an executable shipped with spack.x directly<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>If you want to run an executable\
    \ shipped with <code>spack.x</code> directly instead\nof invoking spack (the default\
    \ entrypoint), try this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x which python</span>\n<span\
    \ class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n\
    <hr>\n<h2 id=\"user-content-how-do-i-build-spackx-myself\"><a class=\"heading-link\"\
    \ href=\"#how-do-i-build-spackx-myself\">How do I build spack.x myself?<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Initially you may need\
    \ docker to get a rootfs filesystem for centos 7.</p>\n<p>Building goes like this:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\"\
    >make rootfs-with-spack</span>\n<span class=\"pl-c1\">make</span></pre></div>\n\
    <p>You'll find the output in</p>\n<pre><code>build/output\n</code></pre>\n"
  stargazers_count: 22
  subscribers_count: 3
  topics:
  - spack
  - squashfs
  - libfuse
  updated_at: 1683613383.0
eugeneswalker/exawind-containers:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/exawind-containers
  latest_release: null
  readme: '<h2 id="user-content-working-with-the-docker-image-ecpe4sexawindlatest"><a
    class="heading-link" href="#working-with-the-docker-image-ecpe4sexawindlatest">Working
    with the Docker image (ecpe4s/exawind:latest)<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h2>

    <ol>

    <li>Build the Docker image</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Launch a container from the image</li>

    </ol>

    <pre><code>$&gt; docker run -it --rm ecpe4s/exawind


    root@8df184bdac63:/# which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    root@8df184bdac63:/# which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2 id="user-content-working-with-the-singularity-image-exawindsif"><a class="heading-link"
    href="#working-with-the-singularity-image-exawindsif">Working with the Singularity
    image (exawind.sif)<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ol>

    <li>Build the Docker image:</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Save the Docker image as a docker-archive</li>

    </ol>

    <pre><code>$&gt; docker save -o exawind.tar ecpe4s/exawind:latest

    </code></pre>

    <ol start="3">

    <li>Build the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./build-singularity-image.sh

    </code></pre>

    <ol start="4">

    <li>Run the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./exawind.sif


    Exawind Singularity&gt; which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    Exawind Singularity&gt; which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2 id="user-content-run-selected-exawind-regression-tests"><a class="heading-link"
    href="#run-selected-exawind-regression-tests">Run Selected ExaWind Regression
    Tests<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ol>

    <li>

    <p>Launch a container using either the Docker or Singularity image (see above)</p>

    </li>

    <li>

    <p>Clone this repository in the newly launched container and run the tests (here
    illustrated with Singularity)</p>

    </li>

    </ol>

    <pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers
    ~/exawind-containers

    Exawind Singularity&gt; cd ~/exawind-containers/demo



    Exawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh

    PASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15



    Exawind Singularity&gt; ./run-nalu-wind-tests.sh

    PASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11

    PASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13

    ...



    Exawind Singularity&gt; ./run-amr-wind-tests.sh

    finished abl_bndry_output

    finished abl_godunov

    ...

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1626420401.0
eugeneswalker/llvm-containers:
  data_format: 2
  description: null
  filenames:
  - x86_64/spack.yaml
  full_name: eugeneswalker/llvm-containers
  latest_release: null
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1615486265.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - gnu/spack.yaml
  - oneapi/failures/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675202595.0
giordano/julia-on-fugaku:
  data_format: 2
  description: null
  filenames:
  - benchmarks/blas-axpy/spack-env/spack.yaml
  full_name: giordano/julia-on-fugaku
  latest_release: null
  readme: "<h1 id=\"user-content-julia-on-fugaku-2022-07-23\"><a class=\"heading-link\"\
    \ href=\"#julia-on-fugaku-2022-07-23\">Julia on Fugaku (2022-07-23)<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p><em>Note: many links\
    \ refer to internal documentation which is accessible only to Fugaku users.</em></p>\n\
    <h2 id=\"user-content-read-the-paper\"><a class=\"heading-link\" href=\"#read-the-paper\"\
    >Read the paper<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>Benchmarks present in this repository have been published in the paper <a href=\"\
    https://doi.org/10.1109/CLUSTER51413.2022.00072\" rel=\"nofollow\">Productivity\
    \ meets\nPerformance: Julia on A64FX</a>, presented at\nthe 2022 IEEE International\
    \ Conference on Cluster Computing (CLUSTER22), as part of the\n<a href=\"https://arm-hpc-user-group.github.io/eahpc-2022/\"\
    \ rel=\"nofollow\">Embracing Arm for High Performance Computing\nWorkshop</a>\
    \ (pre-print available on arXiv:\n<a href=\"https://arxiv.org/abs/2207.12762\"\
    \ rel=\"nofollow\"><code>2207.12762</code></a>).  See the <a href=\"./CITATION.bib\"\
    ><code>CITATION.bib</code></a>\nfile for a BibTeX entry to cite the paper.</p>\n\
    <h2 id=\"user-content-storage\"><a class=\"heading-link\" href=\"#storage\">Storage<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Before\
    \ doing anything on Fugaku, be aware that there are <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20220408_01\"\
    \ rel=\"nofollow\">tight\nlimits</a> on the size of (20 GiB)\nand the number of\
    \ inodes in (200k) your home directory.  If you use many Julia Pkg\nartifacts,\
    \ it's very likely you'll hit these limits.  You'll notice that you hit the limit\n\
    because any disk I/O operation will result in a <code>Disk quota exceeded</code>\
    \ error like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-e\">[user@fn01sv03 ~]</span>$ <span class=\"pl-s1\">touch\
    \ foo</span>\n<span class=\"pl-c1\">touch: cannot touch 'foo': Disk quota exceeded</span></pre></div>\n\
    <p>You can check the quota of your home directory with <code>accountd</code> for\
    \ the size, and <code>accountd -i</code> for the number of inodes.</p>\n<h3 id=\"\
    user-content-using-the-data-directory\"><a class=\"heading-link\" href=\"#using-the-data-directory\"\
    >Using the data directory<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<p>In order to avoid clogging up the home directory you may\
    \ want to move the Julia depot to the\ndata directory:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>DATADIR=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/data/&lt;YOUR GROUP&gt;/<span class=\"pl-smi\">${USER}</span><span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">export</span> JULIA_DEPOT_PATH=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${DATADIR}</span>/julia-depot<span\
    \ class=\"pl-pds\">\"</span></span></pre></div>\n<h2 id=\"user-content-interactive-usage\"\
    ><a class=\"heading-link\" href=\"#interactive-usage\">Interactive usage<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The\
    \ login nodes you access via <code>login.fugaku.r-ccs.riken.jp</code> (<a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/AccessToTheSystem/LoggingInToTheFugakuComputerWithLocalAccount.html\"\
    \ rel=\"nofollow\">connection\ninstructions</a>)\nhave Cascade Lake CPUs, so they\
    \ aren't much useful if you want to run an aarch64 Julia.</p>\n<p>You can <a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/Overview.html\"\
    \ rel=\"nofollow\">submit jobs to the\nqueue</a>\nto run Julia code on the A64FX\
    \ compute nodes, but this can be cumbersone if you need quick\nfeedback during\
    \ development or debugging.  You can also request an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/InteractiveJob.html\"\
    \ rel=\"nofollow\">interactive\nnode</a>,\nfor example with:</p>\n<pre><code>pjsub\
    \ --interact -L \"node=1\" -L \"rscgrp=int\" -L \"elapse=30:00\" --sparam \"wait-time=600\"\
    \ --mpi \"max-proc-per-node=4\"\n</code></pre>\n<h2 id=\"user-content-available-software\"\
    ><a class=\"heading-link\" href=\"#available-software\">Available software<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Fugaku\
    \ uses the <a href=\"https://spack.io/\" rel=\"nofollow\">Spack package manager</a>.\
    \  For more information about how\nto use it, see the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/FugakuSpackGuide/\"\
    \ rel=\"nofollow\">Fugaku Spack User\nGuide</a>.</p>\n<p>Note that Spack is installed\
    \ in <code>/vol0004</code>, this means that if your home directory isn't\nmounted\
    \ on this volume you will have to <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20211130_02\"\
    \ rel=\"nofollow\">explicitly request the\npartition</a> in your submission\n\
    job scripts or commands, for example by adding <code>-x PJM_LLIO_GFSCACHE=/vol0004</code>\
    \ to the\n<code>pjsub</code> command, or the line</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>PJM\
    \ -x PJM_LLIO_GFSCACHE=/vol0004</span></pre></div>\n<p>in a job script.</p>\n\
    <h2 id=\"user-content-using-julia-on-the-compute-nodes\"><a class=\"heading-link\"\
    \ href=\"#using-julia-on-the-compute-nodes\">Using Julia on the compute nodes<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>There\
    \ is a Julia module built with Spack <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/UsingOSS/oss_e.html#packages-installed-on-the-compute-nodes\"\
    \ rel=\"nofollow\">available on the compute\nnodes</a>,\nbut as of this writing\
    \ (2022-07-23) the version of Julia provided is 1.6.3, so you may want\nto download\
    \ a more recent version from the <a href=\"https://julialang.org/downloads/\"\
    \ rel=\"nofollow\">official\nwebsite</a>.  Use the <code>aarch64</code> builds\
    \ for Glibc Linux,\npreferably <a href=\"https://julialang.org/downloads/#current_stable_release\"\
    \ rel=\"nofollow\">latest stable</a> or even\nthe <a href=\"https://julialang.org/downloads/nightlies/\"\
    \ rel=\"nofollow\">nightly build</a> if you feel confident.</p>\n<p>To enable\
    \ full vectorisation you may need to set the environment variable\n<code>JULIA_LLVM_ARGS=\"\
    -aarch64-sve-vector-bits-min=512\"</code>.  Example:\n<a href=\"https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\"\
    >https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623</a>. \
    \ However, note that\nare a couple of severe bugs when using 512-bit vectors:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/JuliaLang/julia/issues/44401\">https://github.com/JuliaLang/julia/issues/44401</a>\
    \ (may be an upstream LLVM bug:\n<a href=\"https://github.com/llvm/llvm-project/issues/53331\"\
    >https://github.com/llvm/llvm-project/issues/53331</a>)</li>\n<li>\n<a href=\"\
    https://github.com/JuliaLang/julia/issues/44263\">https://github.com/JuliaLang/julia/issues/44263</a>\
    \ (only in Julia v1.8+)</li>\n</ul>\n<p><em><strong>Note</strong></em>: Julia\
    \ v1.9, which is based on <a href=\"https://community.arm.com/arm-community-blogs/b/tools-software-ides-blog/posts/llvm-14\"\
    \ rel=\"nofollow\">LLVM\n14</a>,\nis able to natively autovectorise code for A64FX\
    \ <em>without</em> having to set\n<code>JULIA_LLVM_ARGS</code>, side stepping\
    \ the issues above altogether.</p>\n<h2 id=\"user-content-mpijl\"><a class=\"\
    heading-link\" href=\"#mpijl\">MPI.jl<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h2>\n<p><a href=\"https://github.com/JuliaParallel/MPI.jl\"\
    ><code>MPI.jl</code></a> with default JLL-provided MPICH works\nout of the box!\
    \  In order to\n<a href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\"\
    \ rel=\"nofollow\">configure</a> <code>MPI.jl</code> v0.19 to\nuse system-provided\
    \ Fujitsu MPI (based on OpenMPI) you have to specify the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/CompileCommands.html\"\
    \ rel=\"nofollow\">MPI C\ncompiler</a>\nfor A64FX with</p>\n<pre><code>julia --project\
    \ -e 'ENV[\"JULIA_MPI_BINARY\"]=\"system\"; ENV[\"JULIA_MPICC\"]=\"mpifcc\"; using\
    \ Pkg; Pkg.build(\"MPI\"; verbose=true)'\n</code></pre>\n<p><em><strong>Note #1</strong></em>:\
    \ <code>mpifcc</code> is available only on the compute nodes.  On the login nodes\
    \ that would be\n<code>mpifccpx</code>, but this is the cross compiler running\
    \ on Intel architecture, it's unlikely\nyou'll run an <code>aarch64</code> Julia\
    \ on there.  <a href=\"https://github.com/JuliaParallel/MPI.jl/issues/539\">Preliminary\n\
    tests</a> show that <code>MPI.jl</code> should work\nmostly fine with Fujitsu\
    \ MPI, but custom error handlers may not be available (read: trying\nto use them\
    \ causes segmentation faults).</p>\n<p><em><strong>Note #2</strong></em>: in <code>MPI.jl</code>\
    \ v0.20 Fujitsu MPI is a known ABI (it's the same as OpenMPI) and\nthere is nothing\
    \ special to do to configure it apart from <a href=\"https://juliaparallel.org/MPI.jl/dev/configuration/#Configuration-2\"\
    \ rel=\"nofollow\">choosing the system\nbinaries</a>.</p>\n<p><em><strong>Note\
    \ #3</strong></em>: we recommend using <code>MPI.jl</code>'s wrapper of <code>mpiexec</code>\
    \ to run MPI applications\nwith Julia:\n<a href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Julia-wrapper-for-mpiexec\"\
    \ rel=\"nofollow\"><code>mpiexecjl</code></a>.</p>\n<h3 id=\"user-content-file-system-latency\"\
    ><a class=\"heading-link\" href=\"#file-system-latency\">File system latency<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Fugaku\
    \ has an advanced system to handle <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/index.html\"\
    \ rel=\"nofollow\">parallel file system\nlatency</a>.\nIn order.  In order to\
    \ speed up parallel applications run through MPI you may want to\ndistribute it\
    \ to the cache area of the second-layer storage on the first-layer storage using\n\
    <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/TheSecondLayerStrage.html#common-file-distribution-function-llio-transfer\"\
    \ rel=\"nofollow\"><code>llio_transfer</code></a>.\nIn particular, if you're using\
    \ Julia, you likely want to distribute the <code>julia</code> executable\nitself\
    \ together with its installation bundle.</p>\n<p>For example, assuming that you\
    \ are using the official binaries from the website, instead of\nthe Julia module\
    \ provided by Spack, you can do the following:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Directory for log of\
    \ `llio_transfer` and its wrapper `dir_transfer`</span>\nLOGDIR=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${TMPDIR}</span>/log<span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Create the log directory if necessary</span>\nmkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Get directory where Julia is placed</span>\nJL_BUNDLE=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>dirname <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>julia --startup-file=no\
    \ -O0 --compile=min -e <span class=\"pl-s\"><span class=\"pl-pds\">'</span>print(Sys.BINDIR)<span\
    \ class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span><span\
    \ class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Move Julia installation to\
    \ fast LLIO directory</span>\n/home/system/tool/dir_transfer -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Do not write\
    \ empty stdout/stderr files for MPI processes.</span>\n<span class=\"pl-k\">export</span>\
    \ PLE_MPI_STD_EMPTYFILE=off\n\nmpiexecjl --project=. -np ... julia ...\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Remove Julia installation directory\
    \ from the cache.</span>\n/home/system/tool/dir_transfer -p -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span></pre></div>\n<h2 id=\"user-content-reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    ><a class=\"heading-link\" href=\"#reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    >Reverse engineering Fujitsu compiler using LLVM output<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>The Fujitsu compiler has\
    \ <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/C/modeTradAndClangC.html\"\
    \ rel=\"nofollow\">two operation\nmodes</a>:\n\"trad\" (for \"traditional\") and\
    \ \"clang\" (enabled by the flag <code>-Nclang</code>).  In clang mode it's\n\
    based on LLVM (version 7 at the moment).  This means you can get it to emit LLVM\
    \ IR with\n<code>-emit-llvm</code>.  For example, with</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\"\
    >echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>int main(){}<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> fcc -Nclang -x\
    \ c - -S -emit-llvm -o -</span></pre></div>\n<p>you get</p>\n<div class=\"highlight\
    \ highlight-source-llvm\"><pre><span class=\"pl-c\">; ModuleID = '-'</span>\n\
    source_filename = <span class=\"pl-s\">\"-\"</span>\n<span class=\"pl-k\">target</span>\
    \ <span class=\"pl-k\">datalayout</span> = <span class=\"pl-s\">\"e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128\"\
    </span>\n<span class=\"pl-k\">target</span> <span class=\"pl-k\">triple</span>\
    \ = <span class=\"pl-s\">\"aarch64-unknown-linux-gnu\"</span>\n\n<span class=\"\
    pl-c\">; Function Attrs: norecurse nounwind readnone uwtable</span>\n<span class=\"\
    pl-k\">define</span> dso_local <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">@main</span>() <span class=\"pl-k\">local_unnamed_addr</span> #<span class=\"\
    pl-c1\">0</span> <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!8</span>\
    \ {\n  <span class=\"pl-k\">ret</span> <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!11</span>\n\
    }\n\n<span class=\"pl-k\">attributes</span> #<span class=\"pl-c1\">0</span> =\
    \ { <span class=\"pl-k\">norecurse</span> <span class=\"pl-k\">nounwind</span>\
    \ <span class=\"pl-k\">readnone</span> <span class=\"pl-k\">uwtable</span> <span\
    \ class=\"pl-s\">\"correctly-rounded-divide-sqrt-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"disable-tail-calls\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"less-precise-fpmad\"\
    </span>=<span class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim\"\
    </span>=<span class=\"pl-s\">\"true\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim-non-leaf\"\
    </span> <span class=\"pl-s\">\"no-infs-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"no-jump-tables\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> <span class=\"pl-s\">\"no-nans-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-signed-zeros-fp-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-trapping-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"stack-protector-buffer-size\"\
    </span>=<span class=\"pl-s\">\"8\"</span> <span class=\"pl-s\">\"target-cpu\"\
    </span>=<span class=\"pl-s\">\"a64fx\"</span> <span class=\"pl-s\">\"target-features\"\
    </span>=<span class=\"pl-s\">\"+crc,+crypto,+fp-armv8,+lse,+neon,+ras,+rdm,+sve,+v8.2a\"\
    </span> <span class=\"pl-s\">\"unsafe-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"use-soft-float\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> }\n\n<span class=\"pl-v\">!llvm.dbg.cu</span> = !{<span class=\"\
    pl-v\">!0</span>}\n<span class=\"pl-v\">!llvm.module.flags</span> = !{<span class=\"\
    pl-v\">!3</span>, <span class=\"pl-v\">!4</span>, <span class=\"pl-v\">!5</span>}\n\
    <span class=\"pl-v\">!llvm.ident</span> = !{<span class=\"pl-v\">!6</span>}\n\
    <span class=\"pl-v\">!llvm.compinfo</span> = !{<span class=\"pl-v\">!7</span>}\n\
    \n<span class=\"pl-v\">!0</span> = distinct <span class=\"pl-v\">!DICompileUnit</span>(language:\
    \ DW_LANG_C99, file: <span class=\"pl-v\">!1</span>, producer: <span class=\"\
    pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on\
    \ LLVM 7.1.0)\"</span>, isOptimized: <span class=\"pl-k\">true</span>, runtimeVersion:\
    \ <span class=\"pl-c1\">0</span>, emissionKind: LineTablesOnly, enums: <span class=\"\
    pl-v\">!2</span>)\n<span class=\"pl-v\">!1</span> = <span class=\"pl-v\">!DIFile</span>(filename:\
    \ <span class=\"pl-s\">\"-\"</span>, directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"\
    </span>)\n<span class=\"pl-v\">!2</span> = !{}\n<span class=\"pl-v\">!3</span>\
    \ = !{<span class=\"pl-k\">i32</span> <span class=\"pl-c1\">2</span>, !<span class=\"\
    pl-s\">\"Dwarf Version\"</span>, <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">4</span>}\n<span class=\"pl-v\">!4</span> = !{<span class=\"pl-k\">i32</span>\
    \ <span class=\"pl-c1\">2</span>, !<span class=\"pl-s\">\"Debug Info Version\"\
    </span>, <span class=\"pl-k\">i32</span> <span class=\"pl-c1\">3</span>}\n<span\
    \ class=\"pl-v\">!5</span> = !{<span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">1</span>, !<span class=\"pl-s\">\"wchar_size\"</span>, <span class=\"\
    pl-k\">i32</span> <span class=\"pl-c1\">4</span>}\n<span class=\"pl-v\">!6</span>\
    \ = !{!<span class=\"pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021\
    \ 10:55:52) (based on LLVM 7.1.0)\"</span>}\n<span class=\"pl-v\">!7</span> =\
    \ !{!<span class=\"pl-s\">\"C::clang\"</span>}\n<span class=\"pl-v\">!8</span>\
    \ = distinct <span class=\"pl-v\">!DISubprogram</span>(name: <span class=\"pl-s\"\
    >\"main\"</span>, scope: <span class=\"pl-v\">!9</span>, file: <span class=\"\
    pl-v\">!9</span>, line: <span class=\"pl-c1\">1</span>, type: <span class=\"pl-v\"\
    >!10</span>, isLocal: <span class=\"pl-k\">false</span>, isDefinition: <span class=\"\
    pl-k\">true</span>, scopeLine: <span class=\"pl-c1\">1</span>, isOptimized: <span\
    \ class=\"pl-k\">true</span>, unit: <span class=\"pl-v\">!0</span>, retainedNodes:\
    \ <span class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!9</span> = <span class=\"\
    pl-v\">!DIFile</span>(filename: <span class=\"pl-s\">\"&lt;stdin&gt;\"</span>,\
    \ directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"</span>)\n<span class=\"\
    pl-v\">!10</span> = <span class=\"pl-v\">!DISubroutineType</span>(types: <span\
    \ class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!11</span> = <span class=\"\
    pl-v\">!DILocation</span>(line: <span class=\"pl-c1\">1</span>, column: <span\
    \ class=\"pl-c1\">12</span>, scope: <span class=\"pl-v\">!8</span>)</pre></div>\n\
    <h2 id=\"user-content-systembenchmarksjl\"><a class=\"heading-link\" href=\"#systembenchmarksjl\"\
    >SystemBenchmarks.jl<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>I ran <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl\"\
    ><code>SystemBenchmarks.jl</code></a> on a\ncompute node.  Here are the results:\n\
    <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\"\
    >https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968</a>.</p>\n\
    <h2 id=\"user-content-blas\"><a class=\"heading-link\" href=\"#blas\">BLAS<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>OpenBLAS\
    \ seems to have poor performance:</p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">2.589865257047898e10</span></pre></div>\n\
    <p>Up to v1.7, Julia uses OpenBLAS v0.3.17, which actually doesn't support A64FX\
    \ at all, so\nit's probably using the generic kernels.\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.19\"\
    ><code>v0.3.19</code></a> and\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.20\"\
    ><code>v0.3.20</code></a> improved support for\nthis chip, you can find a build\
    \ of 0.3.20 at\n<a href=\"https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\"\
    >https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz</a>,\n\
    but sadly there isn't a great performance improvement:</p>\n<div class=\"highlight\
    \ highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">lbt_forward</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>lib/libopenblas64_.so<span class=\"pl-pds\"\
    >\"</span></span>)\n<span class=\"pl-c1\">4856</span>\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.6362952057793587e10</span></pre></div>\n\
    <p>There is an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/Library/BLASLAPACKScaLAPACKLibrary.html#how-to-dynamically-load-and-use-blas-lapack-and-scalapack\"\
    \ rel=\"nofollow\">optimised\nBLAS</a>\nprovided by Fujitsu, with support for\
    \ SVE (with both LP64 and ILP64).  In order to use it,\ninstall <a href=\"https://github.com/giordano/FujitsuBLAS.jl\"\
    ><code>FujitsuBLAS.jl</code></a></p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ FujitsuBLAS, LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">get_config</span>()\nLinearAlgebra<span\
    \ class=\"pl-k\">.</span>BLAS<span class=\"pl-k\">.</span>LBTConfig\nLibraries<span\
    \ class=\"pl-k\">:</span>\n\u2514 [ILP64] libfjlapackexsve_ilp64<span class=\"\
    pl-k\">.</span>so\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">4.801227630694119e10</span></pre></div>\n\
    <p>The package <a href=\"https://github.com/carstenbauer/BLISBLAS.jl\"><code>BLISBLAS.jl</code></a>\
    \ similarly forwards\nBLAS calls to the <a href=\"https://github.com/flame/blis\"\
    >blis</a> library, which has optimised kernels\nfor A64FX.</p>\n<h2 id=\"user-content-building-julia-from-source\"\
    ><a class=\"heading-link\" href=\"#building-julia-from-source\">Building Julia\
    \ from source<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <h3 id=\"user-content-with-gcc\"><a class=\"heading-link\" href=\"#with-gcc\"\
    >with GCC<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>Building Julia from source with GCC (which is the default if you don't set\
    \ <code>CC</code> and <code>CXX</code>)\nworks fine, it's just <em>slow</em>:</p>\n\
    <pre><code>[...]\n    JULIA usr/lib/julia/corecompiler.ji\nCore.Compiler \u2500\
    \u2500\u2500\u2500 903.661 seconds\n[...]\nBase  \u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500271.257337 seconds\nArgTools \
    \ \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 50.348227 seconds\nArtifacts\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.193792 seconds\nBase64\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.057241\
    \ seconds\nCRC32c  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.097865 seconds\nFileWatching  \u2500\u2500\u2500\u2500\u2500  1.169747\
    \ seconds\nLibdl  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.026215 seconds\nLogging  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  0.411966 seconds\nMmap  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.972844 seconds\nNetworkOptions \
    \ \u2500\u2500\u2500  1.159094 seconds\nSHA  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.067851 seconds\nSerialization\
    \  \u2500\u2500\u2500\u2500  2.942512 seconds\nSockets  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.568797 seconds\nUnicode  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.814165 seconds\nDelimitedFiles \
    \ \u2500\u2500\u2500  1.121546 seconds\nLinearAlgebra  \u2500\u2500\u2500\u2500\
    109.560774 seconds\nMarkdown  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  7.977584 seconds\nPrintf  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  1.635409 seconds\nRandom  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 13.843395 seconds\nTar  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.146368 seconds\n\
    Dates  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 16.694863 seconds\nDistributed  \u2500\u2500\u2500\u2500\u2500\u2500  8.163152\
    \ seconds\nFuture  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.060472 seconds\nInteractiveUtils  \u2500  5.245523 seconds\nLibGit2\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 15.469061 seconds\n\
    Profile  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  5.399918\
    \ seconds\nSparseArrays  \u2500\u2500\u2500\u2500\u2500 42.660136 seconds\nUUIDs\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.165799\
    \ seconds\nREPL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500 40.149298 seconds\nSharedArrays  \u2500\u2500\u2500\u2500\u2500 \
    \ 5.476926 seconds\nStatistics  \u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.130843\
    \ seconds\nSuiteSparse  \u2500\u2500\u2500\u2500\u2500\u2500 16.849304 seconds\n\
    TOML  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.714203 seconds\nTest  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500  3.538098 seconds\nLibCURL  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.547585 seconds\nDownloads  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.657012 seconds\nPkg  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 54.053634 seconds\n\
    LazyArtifacts  \u2500\u2500\u2500\u2500  0.019103 seconds\nStdlibs total  \u2500\
    \u2500\u2500\u2500427.178257 seconds\nSysimage built. Summary:\nTotal \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 698.447219 seconds\nBase: \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500 271.257337 seconds 38.8372%\nStdlibs: \u2500\u2500\u2500\u2500\
    \ 427.178257 seconds 61.1611%\n[...]\nPrecompilation complete. Summary:\nTotal\
    \ \u2500\u2500\u2500\u2500\u2500\u2500\u2500 1274.714700 seconds\nGeneration \u2500\
    \u2500 886.445205 seconds 69.5407%\nExecution \u2500\u2500\u2500 388.269495 seconds\
    \ 30.4593%\n</code></pre>\n<h3 id=\"user-content-with-fujitsu-compiler\"><a class=\"\
    heading-link\" href=\"#with-fujitsu-compiler\">With Fujitsu compiler<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p><em>For reference,\
    \ the version used for the last build I attempted was\n<a href=\"https://github.com/JuliaLang/julia/commit/1ad2396f05fa63a71e5842c814791cd7c7715100\"\
    ><code>1ad2396f</code></a></em></p>\n<p>Compiling Julia from source with the Fujitsu\
    \ compiler is complicated.  In particular, it's\nan absolute pain to use the Fujitsu\
    \ compiler in trad mode.  You can have some more luck with\nclang mode.</p>\n\
    <p>Preparation.  Create the <code>Make.user</code> file with this content (I'm\
    \ not sure this file is\nactually necessary when using Clang mode, but it definitely\
    \ is with trad mode):</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-k\">override</span> <span class=\"pl-smi\">ARCH</span>\
    \ := aarch64\n<span class=\"pl-k\">override</span> <span class=\"pl-smi\">BUILD_MACHINE</span>\
    \ := aarch64-unknown-linux-gnu</pre></div>\n<p>Then you can compile with (<code>-Nclang</code>\
    \ is to select clang mode)</p>\n<pre><code>make -j50 CC=\"fcc -Nclang\" CFLAGS=\"\
    -Kopenmp\" CXX=\"FCC -Nclang\" CXXFLAGS=\"-Kopenmp\"\n</code></pre>\n<p>The compiler\
    \ in trad mode doesn't define the macro <code>__SIZEOF_POINTER__</code>, so compilation\n\
    would fail in\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115</a>.\n\
    The solution is to set the macro <code>-D__SIZEOF_POINTER__=8</code> in the <code>CFLAGS</code>\
    \ (or just not use\ntrad mode).  Then, you may get errors like</p>\n<pre><code>/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2000:13:\
    \ error: initializer element is not a compile-time constant\n            jl_typename_type,\n\
    \            ^~~~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    /vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2025:43: error: initializer\
    \ element is not a compile-time constant\n    jl_typename_type-&gt;types = jl_svec(13,\
    \ jl_symbol_type, jl_any_type /*jl_module_type*/,\n                          \
    \                ^~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    </code></pre>\n<p>This is the compiler's fault, which is supposed to be able to\
    \ handle this, but you can just\ndelete the assertions at lines\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446</a>.</p>\n\
    <p>If you're lucky enough, with all these changes, you may be able to build <code>usr/bin/julia</code>.\n\
    Unfortunately, last time I tried, run this executable causes a segmentation fault\
    \ in\n<code>dl_init</code>:</p>\n<pre><code>(gdb) run\nStarting program: /vol0003/ra000019/a04463/repo/julia/julia\n\
    Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-151.el8.aarch64\n\
    [Thread debugging using libthread_db enabled]\nUsing host libthread_db library\
    \ \"/lib64/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation\
    \ fault.\n0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\n\
    Missing separate debuginfos, use: yum debuginfo-install FJSVxoslibmpg-2.0.0-25.14.1.el8.aarch64\
    \ elfutils-libelf-0.182-3.el8.aarch64\n(gdb) bt\n#0  0x000040000000def4 in _dl_init\
    \ () from /lib/ld-linux-aarch64.so.1\n#1  0x000040000020adb0 in _dl_catch_exception\
    \ () from /lib64/libc.so.6\n#2  0x00004000000125e4 in dl_open_worker () from /lib/ld-linux-aarch64.so.1\n\
    #3  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#4  0x0000400000011aa8\
    \ in _dl_open () from /lib/ld-linux-aarch64.so.1\n#5  0x0000400000091094 in dlopen_doit\
    \ () from /lib64/libdl.so.2\n#6  0x000040000020ad54 in _dl_catch_exception ()\
    \ from /lib64/libc.so.6\n#7  0x000040000020ae20 in _dl_catch_error () from /lib64/libc.so.6\n\
    #8  0x00004000000917f0 in _dlerror_run () from /lib64/libdl.so.2\n#9  0x0000400000091134\
    \ in dlopen@@GLIBC_2.17 () from /lib64/libdl.so.2\n#10 0x0000400000291f34 in load_library\
    \ (rel_path=0x400001e900c6 &lt;dep_libs+30&gt; \"libjulia-internal.so.1\", src_dir=&lt;optimized\
    \ out&gt;, err=1) at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:65\n\
    #11 0x0000400000291c78 in jl_load_libjulia_internal () at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:200\n\
    #12 0x000040000000de04 in call_init.part () from /lib/ld-linux-aarch64.so.1\n\
    #13 0x000040000000df08 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#14 0x0000400000001044\
    \ in _dl_start_user () from /lib/ld-linux-aarch64.so.1\nBacktrace stopped: previous\
    \ frame identical to this frame (corrupt stack?)\n</code></pre>\n"
  stargazers_count: 10
  subscribers_count: 3
  topics: []
  updated_at: 1690337110.0
haampie/sirius-appimage:
  data_format: 2
  description: SIRIUS AppImage (using just the bare minimum)
  filenames:
  - libtree/spack.yaml
  full_name: haampie/sirius-appimage
  latest_release: null
  readme: "<h1 id=\"user-content-creating-an-appimage-from-a-spack-environment\"><a\
    \ class=\"heading-link\" href=\"#creating-an-appimage-from-a-spack-environment\"\
    >Creating an AppImage from a spack environment<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h1>\n<p>HPC container runtimes often use squashfs\
    \ as an archive to store an image, which is then mounted on compute nodes and\
    \ made writeable using overlayfs where the top layer is a ramfs. This trick gives\
    \ good performance particularly on shared filesystems, since the squashfs file\
    \ is a single blob on the disk and has good caching behavior.</p>\n<p>However,\
    \ perfect isolation from the host system is not always possible, in particular\
    \ when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into\
    \ the container, and the question is what the point of containers really is if\
    \ they still depend on the host system.</p>\n<p>Instead of using containers, one\
    \ can still deploy applications as a single self-contained blob on the filesystem\
    \ by using the AppImage runtime. The basic idea is to create an executable which\
    \ unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo\
    \ shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\"\
    >SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a>\
    \ and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\"\
    >AppImage runtime</a>.</p>\n<h2 id=\"user-content-building\"><a class=\"heading-link\"\
    \ href=\"#building\">Building<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<div class=\"highlight highlight-text-shell-session\"><pre>$\
    \ <span class=\"pl-s1\">./build.sh</span></pre></div>\n<h2 id=\"user-content-running\"\
    ><a class=\"heading-link\" href=\"#running\">Running<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n<span class=\"pl-c1\"\
    >SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git\
    \ hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    <span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\"\
    >build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time\
    \     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI\
    \ ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                 \
    \     : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\
    \n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n\
    <span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"\
    pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n\
    <span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"\
    pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"\
    pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n\
    <span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in\
    \ Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=\
    \   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double}\
    \ default value for APW linearization energies</span>\n<span class=\"pl-c1\">\
    \  --auto_enu allow search of APW linearization energies</span>\n<span class=\"\
    pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\"\
    >  --rel      use scalar-relativistic solver</span></pre></div>\n<h2 id=\"user-content-running-on-piz-daint\"\
    ><a class=\"heading-link\" href=\"#running-on-piz-daint\">Running on piz daint<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>For\
    \ Piz Daint I've modified the <code>sirius/spack.yaml</code> a bit so that it\
    \ links against system libmpi.so (<code>^cray-mpich</code> that is):</p>\n<pre><code>daint103\
    \ $ ./build.sh\n...\n\ndaint103 $ du -sh sirius.app # binary size (includes compressed\
    \ squashfs)\n26M\tsirius.app\n\ndaint103 $ ./sirius.app --appimage-extract # runtime\
    \ allows you to extract\nsquashfs-root/AppRun\nsquashfs-root/usr\nsquashfs-root/usr/bin\n\
    squashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\nsquashfs-root/usr/lib\n\
    squashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\n\
    squashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n\
    ...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\
    \ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf\
    \ # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\n\
    srun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\n\
    input file does not exist\n===========================================================================================================\n\
    \                            #         Total          %   Parent %        Median\
    \           Min           Max\n-----------------------------------------------------------------------------------------------------------\n\
    sirius                      1       2.30 ms     100.00     100.00       2.30 ms\
    \       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms   \
    \   60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize\
    \        1     333.28 us      14.52      14.52     333.28 us     333.28 us   \
    \  333.28 us\n\n===========================================================================================================\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1616508538.0
hepnos/HEPnOS-Wizard:
  data_format: 2
  description: Python utilities to generate HEPnOS configurations
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-Wizard
  latest_release: v0.0.2
  readme: '<h1 id="user-content-hepnos-wizard"><a class="heading-link" href="#hepnos-wizard">HEPnOS-Wizard<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This package contains scripts to help setup valid configurations

    for the HEPnOS storage service.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641579766.0
hipdac-lab/SC23-AMRIC:
  data_format: 2
  description: 'Artifacts of SC''23 paper "AMRIC: A Novel In Situ Lossy Compression
    Framework for Efficient I/O in Adaptive Mesh Refinement Applications"'
  filenames:
  - warpx_directory/WarpX/Docs/spack.yaml
  full_name: hipdac-lab/SC23-AMRIC
  latest_release: v0.1.0
  readme: "<h1 id=\"user-content-amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    ><a class=\"heading-link\" href=\"#amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    >AMRIC: A Novel In Situ Lossy Compression Framework for Efficient I/O in Adaptive\
    \ Mesh Refinement Applications<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p><a href=\"https://zenodo.org/badge/latestdoi/658166802\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d27197f9c57b31e8ebc942e043641820e994db2d17639562140d4e1c6eaf2442/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3635383136363830322e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/658166802.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>AMRIC is a novel in-situ lossy compression framework\
    \ that leverages the HDF5 filter to enhance both I/O efficiency and compression\
    \ quality for Adaptive Mesh Refinement (AMR) applications. AMRIC was integrated\
    \ into the <a href=\"https://amrex-codes.github.io/amrex/\" rel=\"nofollow\">AMReX</a>\
    \ framework and evaluated on two real-world AMR applications, Nyx and WarpX.</p>\n\
    <p>While preparing the artifacts, we executed them on a single node from the Chameleon\
    \ Cloud, equipped with two Intel Xeon Gold 6242 CPUs and 192 GB of memory (specifically,\
    \ <code>compute_skylake</code> configuration). We recommend that reviewers also\
    \ use the Chameleon Cloud for artifact evaluation.</p>\n<h2 id=\"user-content-method-1-use-singularity-image-recommended\"\
    ><a class=\"heading-link\" href=\"#method-1-use-singularity-image-recommended\"\
    >Method 1: Use Singularity Image (Recommended)<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>The entire workflow takes approximately\
    \ 10 minutes to execute, including downloading container image and preparing environment\
    \ (3 mins), running WarpX simulation (3 mins), running Nyx simulation (3 mins),\
    \ and evaluating compression performance (1 min).</p>\n<h3 id=\"user-content-minimum-system-requirements\"\
    ><a class=\"heading-link\" href=\"#minimum-system-requirements\">Minimum system\
    \ requirements<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>OS: Ubuntu (20.04 is recommended)</p>\n<p>Memory: &gt;= 16 GB RAM</p>\n<p>Processor:\
    \ &gt;= 8 cores</p>\n<p>Storage: &gt;= 32 GBs</p>\n<h3 id=\"user-content-step-1-install-singularity\"\
    ><a class=\"heading-link\" href=\"#step-1-install-singularity\">Step 1: Install\
    \ Singularity<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>Install <a href=\"https://singularity-tutorial.github.io/01-installation/\"\
    \ rel=\"nofollow\">Singularity</a></p>\n<h3 id=\"user-content-step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    ><a class=\"heading-link\" href=\"#step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    >Step 2: Download the pre-built Singularity image file via gdown<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Press Enter after finishing.</p>\n\
    <pre><code>sudo pip3 install gdown\ngdown https://drive.google.com/uc?id=14v_xUmET-HvCFO3LqmD4sNJL65jBcd0L&amp;export=download\n\
    </code></pre>\n<p>or via GitHub</p>\n<pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC-Image.git\n\
    cat SC23-AMRIC-Image/img/amric.sif-* &gt; amric.sif\n</code></pre>\n<h3 id=\"\
    user-content-step-3-build-and-run-the-image-file-need-root-privilege\"><a class=\"\
    heading-link\" href=\"#step-3-build-and-run-the-image-file-need-root-privilege\"\
    >Step 3: Build and run the image file (need root privilege)<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>sudo singularity\
    \ build --sandbox artiAmr amric.sif\nsudo singularity shell --writable artiAmr\n\
    </code></pre>\n<h3 id=\"user-content-step-4-set-up-environmental-variables\"><a\
    \ class=\"heading-link\" href=\"#step-4-set-up-environmental-variables\">Step\
    \ 4: Set up environmental variables<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h3>\n<pre><code>export OMPI_DIR=/opt/ompi \nexport\
    \ OMPI_VERSION=4.1.1\nexport PATH=$OMPI_DIR/bin:$PATH\nexport LD_LIBRARY_PATH=$OMPI_DIR/lib:$LD_LIBRARY_PATH\n\
    export MANPATH=$OMPI_DIR/share/man:$MANPATH\nexport C_INCLUDE_PATH=/opt/ompi/include:$C_INCLUDE_PATH\n\
    export CPLUS_INCLUDE_PATH=/opt/ompi/include:$CPLUS_INCLUDE_PATH\nexport OMPI_ALLOW_RUN_AS_ROOT=1\n\
    export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1\n</code></pre>\n<h3 id=\"user-content-step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><a class=\"heading-link\" href=\"#step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    >Step 5: Run WarpX simulation with no compression, AMReX's original compression,\
    \ and AMRIC<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>cd /home/wpx256/\n. bash.sh\n</code></pre>\n<h3 id=\"user-content-step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><a class=\"heading-link\" href=\"#step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    >Step 6: Run NYX simulation with no compression, AMReX's original compression,\
    \ and AMRIC<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>cd /home/nyx128/\n. bash.sh\n</code></pre>\n<h3 id=\"user-content-step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><a class=\"heading-link\" href=\"#step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    >Step 7: Evaluate WarpX's data quality and compression ratio for original AMReX\
    \ compression and our AMRIC<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<pre><code>cd /home/wpx256/diags/\n. decomp.sh &gt; temp.txt\n\
    . qualityCR.sh\n</code></pre>\n<h3 id=\"user-content-step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><a class=\"heading-link\" href=\"#step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    >Step 8: Evaluate NYX's data quality and compression ratio for original AMReX\
    \ compression and our AMRIC<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<pre><code>cd /home/nyx128/run/\n. decomp.sh &gt; temp.txt\n\
    . qualityCR.sh\n</code></pre>\n<h3 id=\"user-content-step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><a class=\"heading-link\" href=\"#step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    >Step 9: Compare I/O perf for baselines (i.e., no compression and ori AMReX compression)\
    \ and AMRIC in WarpX<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<pre><code>cd /home/wpx256/otfile/\n. io.sh\n</code></pre>\n\
    <h3 id=\"user-content-step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    ><a class=\"heading-link\" href=\"#step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    >Step 10: Compare I/O performance between baselines and AMRIC in NYX<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>cd /home/nyx128/otfile/\n\
    . io.sh\n</code></pre>\n<h2 id=\"user-content-method-2-build-from-source\"><a\
    \ class=\"heading-link\" href=\"#method-2-build-from-source\">Method 2: Build\
    \ From Source<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <h3 id=\"user-content-minimum-system--software-libraries-requirements\"><a class=\"\
    heading-link\" href=\"#minimum-system--software-libraries-requirements\">Minimum\
    \ system &amp; software libraries requirements<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>OS: Linux (Ubuntu is recommended)</p>\n\
    <p>Memory: &gt;= 16 GB RAM</p>\n<p>Processor: &gt;= 8 cores</p>\n<p>gcc/9.4.0\
    \ (or 9.3.0)</p>\n<p>cmake (&gt;= 3.23)</p>\n<p>OpenMPI/4.1.1 (install scripts\
    \ provided, or spectrum-mpi)</p>\n<p>python/3.8</p>\n<p>hdf5/1.12.2 (install scripts\
    \ provided)</p>\n<h3 id=\"user-content-step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    ><a class=\"heading-link\" href=\"#step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    >Step 1: Download AMRIC, checkpoint files, and set up environmental variables\
    \ (2 mins)<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC.git\ncd SC23-AMRIC\n\
    export AMRIC_HOME=$(pwd)\necho \"# start of AMRIC env\" &gt;&gt; ~/.bashrc\necho\
    \ export AMRIC_HOME=$(pwd) &gt;&gt; ~/.bashrc\n</code></pre>\n<h3 id=\"user-content-step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    ><a class=\"heading-link\" href=\"#step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    >Step 2: Load or install CMake and numpy. For example, in Ubuntu<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>pip3 install\
    \ numpy\nsudo snap install cmake --classic\n</code></pre>\n<h3 id=\"user-content-step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\"\
    ><a class=\"heading-link\" href=\"#step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\"\
    >Step 3: Load or install OpenMPI. For example, in Ubuntu (7 mins)<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>sudo bash openmpi.sh\
    \ \n. mpi_env.sh\n</code></pre>\n<h3 id=\"user-content-step-4-download-and-install-the-hdf5-library-4-mins\"\
    ><a class=\"heading-link\" href=\"#step-4-download-and-install-the-hdf5-library-4-mins\"\
    >Step 4: Download and install the HDF5 library (4 mins)<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>. hdf5.sh\n</code></pre>\n\
    <h3 id=\"user-content-step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    ><a class=\"heading-link\" href=\"#step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    >Step 5: Install optimized SZ3 compressor and H5Z-SZ3 compression filter (5 mins)<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>.\
    \ compressor.sh\n</code></pre>\n<h3 id=\"user-content-step-6-install-amrex-and-nyx-with-amric-8-mins\"\
    ><a class=\"heading-link\" href=\"#step-6-install-amrex-and-nyx-with-amric-8-mins\"\
    >Step 6: Install AMReX and Nyx with AMRIC (8 mins)<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<pre><code>. nyx.sh\n</code></pre>\n\
    <h3 id=\"user-content-step-7-install-warpx-with-amric-9-mins\"><a class=\"heading-link\"\
    \ href=\"#step-7-install-warpx-with-amric-9-mins\">Step 7: Install WarpX with\
    \ AMRIC (9 mins)<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>. warpx.sh\n</code></pre>\n<h3 id=\"user-content-step-8-download-qcat-compression-analysis-tool-1-min\"\
    ><a class=\"heading-link\" href=\"#step-8-download-qcat-compression-analysis-tool-1-min\"\
    >Step 8: Download qcat (compression analysis tool, 1 min)<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>. qcat.sh\n\
    </code></pre>\n<h3 id=\"user-content-step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><a class=\"heading-link\" href=\"#step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    >Step 9: Run WarpX with no compression, AMReX\u2019s original compression, and\
    \ AMRIC (3 mins)<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>cd $AMRIC_HOME/warpx_directory/WarpX\n. runwarpx.sh\n</code></pre>\n\
    <h3 id=\"user-content-step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><a class=\"heading-link\" href=\"#step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    >Step 10: Run NYX with no compression, AMReX\u2019s original compression, and\
    \ AMRIC (3 mins).<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density\n. runnyx.sh\n</code></pre>\n<h3\
    \ id=\"user-content-step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><a class=\"heading-link\" href=\"#step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    >Step 11: Evaluate WarpX\u2019s data quality and compression ratio for original\
    \ AMReX compression and our AMRIC.<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/diags\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des-w\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss-w .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack-w\
    \ .\ncp $AMRIC_HOME/qcat/install/bin/compareData .\n. decomp.sh &gt; out.txt\n\
    . qualityCR.sh\n</code></pre>\n<h3 id=\"user-content-step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><a class=\"heading-link\" href=\"#step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    >Step 12: Evaluate NYX\u2019s data quality and compression ratio for original\
    \ AMReX compression and our AMRIC.<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/run\ncp $AMRIC_HOME/qcat/install/bin/compareData\
    \ .\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack .\n. decomp.sh &gt;\
    \ out.txt\n. qualityCR.sh\n</code></pre>\n<h3 id=\"user-content-step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><a class=\"heading-link\" href=\"#step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    >Step 13: Compare I/O performance between baselines (i.e., no compression and\
    \ ori AMReX compression) and AMRIC in WarpX.<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/otfile\n\
    . io.sh\n</code></pre>\n<h3 id=\"user-content-step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    ><a class=\"heading-link\" href=\"#step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    >Step 14: Compare I/O performance between baselines (i.e., no compression and\
    \ ori AMReX compression) and AMRIC in Nyx.<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/otfile\n\
    . io.sh\n</code></pre>\n<h2 id=\"user-content-expected-evaluation-results\"><a\
    \ class=\"heading-link\" href=\"#expected-evaluation-results\">Expected Evaluation\
    \ Results<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <h3 id=\"user-content-the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    ><a class=\"heading-link\" href=\"#the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    >The expected results for WarpX\u2019s data quality and compression ratio (method\
    \ 1 step 6) are:<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>----- Data Quality for original AMReX Compression -----\nPSNR = 58.600102\n\
    ---------- Data Quality for AMRIC-SZ-L/R ----------\nPSNR = 61.749515\n----------\
    \ Data Quality for AMRIC-SZInterp ----------\nPSNR = 59.146966\n---------- CR\
    \ for original AMReX Compression ----------\nCR is: 14.62\n---------- CR for AMRIC-SZ-L/R\
    \ ----------\nCR is: 108.94\n---------- CR for AMRIC-SZInterp ----------\nCR is:\
    \ 131.41\n</code></pre>\n<h3 id=\"user-content-the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    ><a class=\"heading-link\" href=\"#the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    >The expected results for Nyx\u2019s data quality and compression ratio (method\
    \ 1 step 7) are:<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <pre><code>----- Data Quality for original AMReX Compression -----\nPSNR = 61.977332\n\
    ---------- Data Quality for AMRIC-SZ_L/R ----------\nPSNR = 66.650492\n----------\
    \ Data Quality for AMRIC-SZInterp ----------\nPSNR = 66.566370\n---------- CR\
    \ for original AMReX Compression ----------\nCR is: 6.53\n---------- CR for AMRIC-SZ_L/R\
    \ ----------\nCR is: 13.08\n---------- CR for AMRIC-SZInterp ----------\nCR is:\
    \ 11.25\n</code></pre>\n<h3 id=\"user-content-the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    ><a class=\"heading-link\" href=\"#the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    >The expected results for WarpX\u2019s I/O performance  (method 1 step 8) are:<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>----------\
    \ Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression\
    \ Total time = 1.514 seconds\nNo Compression Preprocess time = 0.216 seconds\n\
    No Compression writing time = 1.322 seconds\n...\n------------------------ END\
    \ ------------------------\n------ Writing Time for original AMReX Compression\
    \ ------\n***** run 0 *****\noriginal AMReX Total time = 4.734 seconds\noriginal\
    \ AMReX Preprocess time = 0.189 seconds\noriginal AMReX Writing+Compression time\
    \ = 4.493 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 1.115 seconds\nAMRIC-SZ_L/R Preprocess time = 0.223 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.906 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 1.878 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.950 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.937 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n<h3 id=\"user-content-the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    ><a class=\"heading-link\" href=\"#the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    >The expected results for Nyx\u2019s I/O performance  (method 1 step 9) are:<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<pre><code>----------\
    \ Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression\
    \ Total time = 0.195 seconds\nNo Compression Preprocess time = 0.016 seconds\n\
    No Compression writing time = 0.177 seconds\n...\n------------------------ END\
    \ ------------------------\n----- Writing Time for original AMReX Compression\
    \ -----\n***** run 0 *****\noriginal AMReX Total time = 0.674 seconds\noriginal\
    \ AMReX Preprocess time = 0.020 seconds\noriginal AMReX Writing+Compression time\
    \ = 0.649 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 0.182 seconds\nAMRIC-SZ_L/R Preprocess time = 0.018 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.155 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 0.230 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.102 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.122 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1687748549.0
iarspider/cms-spack-repo:
  data_format: 2
  description: null
  filenames:
  - environments/CMSSW_12_6_X/spack.yaml
  full_name: iarspider/cms-spack-repo
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1638894331.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  - Docs/compile-notes/frontera-bitbucket/CPU/spack.yaml
  - Docs/compile-notes/frontera-github/GPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/8257fa34c1c5b6c660b31bf16a6196859c354c9c503b7742e1cdee871fbb96c8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/b768fc44ae95216e4b53ff734978771466ba222596e760da27e9e60a0d47d6f7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2 id="user-content-overview"><a class="heading-link" href="#overview">Overview<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <h2 id="user-content-available-modules"><a class="heading-link" href="#available-modules">Available
    modules<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>ReconX</code> - provider of different reconstruction schemes</li>

    <li>

    <code>TOVSolver</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <h2 id="user-content-getting-started"><a class="heading-link" href="#getting-started">Getting
    started<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    <h2 id="user-content-related-talks-and-tutorials"><a class="heading-link" href="#related-talks-and-tutorials">Related
    talks and tutorials<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>"<a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html" rel="nofollow">Using
    CarpetX: A Guide for Early Adopters</a>".

    Recorded seminar talk by Erik Schnetter, providing an overview of the current
    capabilities of CarpetX.</li>

    <li>"<a href="https://einsteintoolkit.github.io/et2022uidaho/lectures/38-Tutorial8/index.html"
    rel="nofollow">Tutorial: GPUs and the Einstein Toolkit</a>".

    Recorded tutorial by Lorenzo Ennoggi, Jay Kalinani and Federico Lopez Armengol
    during the North American Einstein Toolkit workshop 2022, presenting a brief overview
    on AsterX, followed by a hands-on session.</li>

    <li>"<a href="https://drive.google.com/file/d/1Z4i--W56mxeNIu598LQTpEEowX56FOoD/view?usp=sharing"
    rel="nofollow">AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes</a>".

    Slides based on the talk by Jay Kalinani at the APS April Meeting 2023.</li>

    </ul>

    '
  stargazers_count: 16
  subscribers_count: 10
  topics: []
  updated_at: 1694096488.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - anl/polaris/polaris.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
js947/spack-docker-test:
  data_format: 2
  description: testing spack's containerize command
  filenames:
  - spack.yaml
  full_name: js947/spack-docker-test
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"><img
    src="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"
    alt="Build container" style="max-width: 100%;"></a></p>

    <h1 id="user-content-spack-docker-test"><a class="heading-link" href="#spack-docker-test">spack-docker-test<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>testing spack''s containerize command</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1606954982.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-nightly/spack.yaml
  - environments/key4hep-release-user/spack.yaml
  - environments/key4hep-ci/spack.yaml
  - environments/key4hep-release/spack.yaml
  - environments/key4hep-nightly-debug/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1 id="user-content-spack-package-repo-for-key4hep-software-packaging"><a
    class="heading-link" href="#spack-package-repo-for-key4hep-software-packaging">

    </a><a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP
    software packaging<span aria-hidden="true" class="octicon octicon-link"></span></h1>

    <p>This repository holds a set of Spack recipes for key4hep software.</p>

    <p>Consult the the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep documentation
    website</a> and the

    <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack documentation</a>
    for more details.</p>

    <h2 id="user-content-spack-versions"><a class="heading-link" href="#spack-versions">Spack
    Versions<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The spack recipes in this repository should work with any version of spack
    (0.19

    is known to work and it''s possible older versions work too, newer than 0.19

    works). Some of the environments require spack 0.20 or newer since they use (or

    they include a file that uses) the <code>require</code> keyword which was introduced
    in

    <a href="https://github.com/spack/spack/releases/tag/v0.20.0">spack 0.20</a>.</p>

    <h2 id="user-content-repository-contents"><a class="heading-link" href="#repository-contents">Repository
    Contents<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the

    repository contains a collection of environments used to build the stack in

    <code>environments</code> and some scripts used for publishing on cvmfs and other
    utilities

    in <code>scripts</code>. The builds run in Gitlab CI runners and the workflows
    can be found

    in the file <code>.gitlab-ci.yml</code> in the <a href="https://gitlab.cern.ch/key4hep/k4-deploy"
    rel="nofollow">gitlab

    repository</a>.</p>

    <p>Additionally, the file <code>.latest-commit</code> contains the latest commit
    of Spack used

    for the recent builds, which is updated from time to time to keep up with the

    develop branch of Spack.</p>

    <h2 id="user-content-central-installations"><a class="heading-link" href="#central-installations">Central
    Installations<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org</code>
    (for

    CentOS 7) and <code>/cvmfs/sw-nightlies.hsf.org</code> (for CentOS 7, AlmaLinux
    9 and

    Ubuntu) see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    <h2 id="user-content-requirements"><a class="heading-link" href="#requirements">Requirements<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>To compile the key4hep stack some package systems are required; without these,

    the spack concretization or compilation can fail. The packages needed are an

    OpenGL implementation that can be installed:</p>

    <div class="highlight highlight-source-shell"><pre>yum install -y mesa-libGL mesa-libGL-devel
    mesa-libGLU mesa-libGLU-devel      <span class="pl-c"><span class="pl-c">#</span>
    Centos 7</span>

    apt install -y libgl1-mesa-glx libgl1-mesa-dev libglu1-mesa libglu1-mesa-dev  <span
    class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    dnf install -y mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel      <span
    class="pl-c"><span class="pl-c">#</span> AlmaLinux 9</span></pre></div>

    <p>The environments that make use of these libraries or headers expect them to
    be

    found under <code>/usr</code>, which is the typical location when they are installed

    system-wide (for example in <code>/usr/include</code> or <code>/usr/lib</code>).</p>

    <p>Alternatively, one can install

    <a href="https://gitlab.cern.ch/linuxsupport/rpms/HEP_OSlibs" rel="nofollow">HEP_OSlibs</a>,
    which will

    install the previous and more libraries.</p>

    '
  stargazers_count: 8
  subscribers_count: 10
  topics: []
  updated_at: 1682439760.0
kokkos/kokkos-resilience:
  data_format: 2
  description: Resilience Extensions for Kokkos
  filenames:
  - ci/spack.yaml
  full_name: kokkos/kokkos-resilience
  latest_release: null
  readme: '<h1 id="user-content-kokkos-resilience"><a class="heading-link" href="#kokkos-resilience">Kokkos
    Resilience<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><em>Kokkos Resilience</em> is an experimental extension to <a href="https://github.com/kokkos/kokkos/"><em>Kokkos</em></a>
    for providing convenient resilience

    and checkpointing to scientific applications.</p>

    <h2 id="user-content-building"><a class="heading-link" href="#building">Building<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p><em>Kokkos Resilience</em> is built using <a href="https://cmake.org" rel="nofollow">CMake</a>
    version 3.17 or later. It has been tested on

    compilers such as GCC 11.2.0 and LLVM/Clang 11.0.0. It should work on any C++14
    supporting compiler, but your mileage

    may vary.</p>

    <h3 id="user-content-dependencies"><a class="heading-link" href="#dependencies">Dependencies<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <h4 id="user-content-kokkos"><a class="heading-link" href="#kokkos">Kokkos<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h4>

    <p>First and foremost, <em>Kokkos Resilience</em> requires an install of <em>Kokkos</em>.
    This can be compiled or a version bundled with

    other software (such as Trilinos) or as a package on a machine.</p>

    <p><strong>Note:</strong> <em>Kokkos Resilience</em> currently requires the <em>develop</em>
    branch of Kokkos for compile-time view hooking capabilities.</p>

    <h4 id="user-content-boost"><a class="heading-link" href="#boost">Boost<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h4>

    <p>Kokkos-resilience uses Boost for a replacement for some C++17 features such
    as the filesystem library, <code>std::optional</code>, and <code>std::variant</code>.

    This dependency will likely be removed in the future when Kokkos requires C++17.</p>

    <h4 id="user-content-veloc"><a class="heading-link" href="#veloc">VeloC<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h4>

    <p>Additionally, <em>Kokkos Resilience</em> uses the <a href="https://github.com/ECP-VeloC/VELOC">Veloc</a>
    library for efficient asynchronous

    checkpointing. If you desire automatic checkpointing to be available this library
    (and additionally MPI) must be installed.</p>

    <p>We are maintaining a special spack package for VeloC since the main one is
    not up-to-date. It can be found

    <a href="https://gitlab-ex.sandia.gov/kokkos-resilience/kr-spack" rel="nofollow">here</a>
    and can be installed via:</p>

    <div class="highlight highlight-source-shell"><pre>git clone git@gitlab-ex.sandia.gov:kokkos-resilience/kr-spack.git

    spack repo add kr-spack

    spack install veloc@barebone</pre></div>

    <p>It is recommended to install the "barebone" variant/branch of VeloC since it
    has reduced dependencies.</p>

    <h3 id="user-content-cmake-invocation"><a class="heading-link" href="#cmake-invocation">CMake
    Invocation<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>It is recommended to use the CMake presets to configure the project. More information
    on presets can be found <a href="https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html"
    rel="nofollow">here</a>. Note that CMake 3.19 or higher is required to use presets,
    and to inherit from presets bundled with <em>Kokkos Resilience</em>, you

    need at least CMake 3.21.</p>

    <p><em>Kokkos Resilience</em> includes a set of presets in <code>CMakePresets.json</code>.
    These can be inherited from and represent common aaplication configurations.</p>

    <h4 id="user-content-cmake-paths"><a class="heading-link" href="#cmake-paths">CMake
    paths<span aria-hidden="true" class="octicon octicon-link"></span></a></h4>

    <table>

    <thead>

    <tr>

    <th>Path</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Kokkos_ROOT</td>

    <td>Path to the root of the Kokkos install</td>

    </tr>

    <tr>

    <td>VeloC_ROOT</td>

    <td>Path to the root of VeloC if it is enabled (see below)</td>

    </tr>

    <tr>

    <td>HDF5_ROOT</td>

    <td>Path to the root of HDF5 if HDF5 is enabled (see below)</td>

    </tr>

    </tbody>

    </table>

    <h4 id="user-content-supported-cmake-options"><a class="heading-link" href="#supported-cmake-options">Supported
    CMake Options<span aria-hidden="true" class="octicon octicon-link"></span></a></h4>

    <table>

    <thead>

    <tr>

    <th>Variable</th>

    <th>Default</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>KR_ENABLE_VELOC</td>

    <td>ON</td>

    <td>Enables the VeloC backend</td>

    </tr>

    <tr>

    <td>KR_VELOC_BAREBONE</td>

    <td>OFF</td>

    <td>Enable VeloC barebone mode</td>

    </tr>

    <tr>

    <td>KR_ENABLE_TRACING</td>

    <td>OFF</td>

    <td>Enable performance tracing of resilience functions</td>

    </tr>

    <tr>

    <td>KR_ENABLE_STDIO</td>

    <td>OFF</td>

    <td>Use stdio for manual checkpoint</td>

    </tr>

    <tr>

    <td>KR_ENABLE_HDF5</td>

    <td>OFF</td>

    <td>Add HDF5 support for manual checkpoint</td>

    </tr>

    <tr>

    <td>KR_ENABLE_HDF5_PARALLEL</td>

    <td>OFF</td>

    <td>Use parallel version of HDF5 for manual checkpoint</td>

    </tr>

    <tr>

    <td>KR_ENABLE_TESTS</td>

    <td>ON</td>

    <td>Enable tests in the build</td>

    </tr>

    <tr>

    <td>KR_ENABLE_EXAMPLES</td>

    <td>ON</td>

    <td>Enable examples in the build</td>

    </tr>

    </tbody>

    </table>

    <h2 id="user-content-usage"><a class="heading-link" href="#usage">Usage<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <p><em>Kokkos Resilience</em> is designed to work with CMake projects, so using
    CMake is typically much easier. In your own

    project, call:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">find_package</span>(resilience)

    <span class="pl-c1">target_link_libraries</span>(target <span class="pl-k">PRIVATE</span>
    Kokkos::resilience) </pre></div>

    <p>Ensure that the build or install directory of <em>Kokkos Resilience</em> is
    in <code>CMAKE_PREFIX_PATH</code>, or the variable

    <code>resilience_ROOT</code> points to the build/install directory, or the variable
    <code>resilience_DIR</code> points to the location of

    the <em>Kokkos Resilience</em> <code>resilienceConfig.cmake</code> file. This
    file is located in the root build directory of <em>Kokkos

    Resilience</em> or the path <code>&lt;install directory&gt;/share/resilience/cmake</code>.
    See the

    <a href="https://cmake.org/cmake/help/latest/command/find_package.html" rel="nofollow">CMake
    documentation</a> for more details on how packages

    are found.</p>

    '
  stargazers_count: 1
  subscribers_count: 11
  topics: []
  updated_at: 1662994066.0
lanl/CELLAR:
  data_format: 2
  description: The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based
    adaptive mesh refinement data structures and execution for parallel computing
    architectures.
  filenames:
  - spack/darwin-power9/spack.yaml
  - spack/agaspar/spack.yaml
  - spack/ci/spack.yaml
  - spack/snow/spack.yaml
  full_name: lanl/CELLAR
  latest_release: null
  readme: '<h1 id="user-content-cellar-----eap-core"><a class="heading-link" href="#cellar-----eap-core">CELLAR  -  EAP
    Core<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>CELLAR is a C++ project that forms the foundation of cell based AMR for applications</p>

    <p>It provides the following:</p>

    <ul>

    <li>AMR Mesh Datastructure</li>

    <li>AMR Mesh Reconstruction</li>

    <li>Communication Patterns</li>

    <li>C++ Error Handling and Tracing</li>

    <li>Performance Monitoring</li>

    <li>C++/Fortran Interop</li>

    </ul>

    <h2 id="user-content-building"><a class="heading-link" href="#building">Building<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The easiest way to install dependencies is using <a href="https://spack.io"
    rel="nofollow">Spack</a>.

    After

    <a href="https://spack.readthedocs.io/en/latest/getting_started.html" rel="nofollow">installing
    Spack</a>,

    you can start build dependencies.</p>

    <p>The following instructions assume that you have Spack 0.13 or newer. You can
    check your

    Spack version like so:</p>

    <pre><code>$ spack --version

    0.13.0

    </code></pre>

    <p>First, add <a href="https://github.com/lanl/cellar-spack">lanl/cellar-spack</a>

    to your list of spack repos.</p>

    <p>Once you have the <code>lanl/cellar-spack</code> installed, then you can install
    all

    dependencies using

    <a href="https://spack.readthedocs.io/en/latest/tutorial_environments.html#" rel="nofollow">Spack
    environments</a>.

    You''ll need to use a modern-ish C++ compiler that supports C++14:</p>

    <pre><code>$ module load gcc/9.3.0

    $ spack compiler find

    $ cd path/to/eap-core

    </code></pre>

    <p>Then issue the following commands. This will build all of eap-core''s dependencies.:</p>

    <pre><code>$ spack env create -d spack/default

    $ spack env activate -d $PWD/spack/default

    $ spack install

    </code></pre>

    <p>Any time you open a new shell, you''ll need to re-activate the Spack environment:</p>

    <pre><code>$ spack env activate -d $PWD/spack/default

    </code></pre>

    <p>Now you''re ready to build eap-core. First configure the project using CMake:</p>

    <pre><code>mkdir build &amp;&amp; cd build

    cmake ..

    </code></pre>

    <p>And then build:</p>

    <pre><code>make -j

    </code></pre>

    <p>For snow, substitute in spack/snow in the above instructions in place of spack/default.
    If you need

    to change the environment use "spack env deactivate".</p>

    <h2 id="user-content-contributing"><a class="heading-link" href="#contributing">Contributing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Code contributors should read the <a href="DEVELOPERS.md">Developers Guide</a>
    prior to

    sending a pull request.</p>

    '
  stargazers_count: 3
  subscribers_count: 6
  topics: []
  updated_at: 1694614627.0
lanl/SICM:
  data_format: 2
  description: Simplified Interface to Complex Memory
  filenames:
  - spack.yaml
  full_name: lanl/SICM
  latest_release: null
  readme: '<h1 id="user-content-sicm"><a class="heading-link" href="#sicm">SICM<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Simplified Interface to Complex Memory</p>

    <p><a href="https://github.com/lanl/SICM/actions"><img src="https://github.com/lanl/SICM/actions/workflows/sicm.yml/badge.svg"
    alt="GitHub Actions" style="max-width: 100%;"></a></p>

    <h2 id="user-content-introduction"><a class="heading-link" href="#introduction">Introduction<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This project is split into two interfaces: <code>low</code> and <code>high</code>.</p>

    <p>The <code>low</code> interface provides a minimal interface for application
    wanting to

    manage their own memory on heterogeneous memory tiers. It also provides an

    arena allocator that application developers can use to create <code>jemalloc</code>
    arenas

    on different memory tiers and allocate to those tiers.</p>

    <p>The <code>high</code> interface attempts to automatically manage the memory
    tiers for the

    application. It provides an LLVM compiler pass (and compiler wrappers) to

    automatically transform applications to make the appropriate <code>high</code>
    interface

    calls, as well as a runtime library which provides profiling for the

    application.  The profiling is currently meant to be used offline; that is,

    after enabling the profiling for an application run, the results are printed

    out at the end of the run, and that information must be fed into a second run

    to make use of it. An online approach is planned.</p>

    <h2 id="user-content-dependencies"><a class="heading-link" href="#dependencies">Dependencies<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The only dependencies that you will need for the low-level interface

    are <code>libnuma</code> and <code>jemalloc</code>. We require that <code>jemalloc</code>
    be

    configured with the <code>je_</code> prefix (using the <code>--with-jemalloc-prefix</code>
    flag).

    <code>CMake</code> will use <code>pkg-config</code> to find <code>jemalloc</code>.</p>

    <p>For the high-level interface, you need an installation of LLVM. LLVM 4.0 and

    later have been tested, although 3.9 may possibly work. For the profiling, you

    will also need an installation of <code>libpfm</code>, which is a small helper
    library for

    <code>perf</code> that is available on most distributions.</p>

    <p>Additionally, several other packages are required, and can be installed through
    a package manager:</p>

    <h3 id="user-content-binaries"><a class="heading-link" href="#binaries">Binaries<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>A modern C compiler</li>

    <li>A modern C++ compiler</li>

    <li>A modern Fortran compiler</li>

    <li>CMake 3.0+</li>

    <li>Make</li>

    <li>numactl</li>

    <li>automake + friends (if jemalloc needs to be built)</li>

    </ul>

    <h3 id="user-content-development-libraries"><a class="heading-link" href="#development-libraries">Development
    Libraries<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>These packages are usually named <code>lib*-dev</code> or <code>lib*-devel</code>:</p>

    <ul>

    <li>numa</li>

    </ul>

    <p>Additional packages are required for the high level interface:</p>

    <ul>

    <li>hwloc</li>

    <li>llvm</li>

    <li>omp (if OpenMP is not available by default on your compilers)</li>

    <li>pfm4</li>

    </ul>

    <h2 id="user-content-compilation"><a class="heading-link" href="#compilation">Compilation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <pre><code>export PKG_CONFIG_PATH=&lt;jemalloc prefix&gt;/lib/pkgconfig:$PKG_CONFIG_PATH

    mkdir build

    cd build

    cmake .. -DCMAKE_INSTALL_PREFIX=&lt;prefix&gt;

    make

    make install

    </code></pre>

    <h2 id="user-content-low-level-api"><a class="heading-link" href="#low-level-api">Low-Level
    API<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_init</code></td>

    <td>Detects all memory devices on system, returns a list of them.</td>

    </tr>

    <tr>

    <td><code>sicm_fini</code></td>

    <td>Frees up a device list and associated SICM data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_find_device</code></td>

    <td>Return the first device that matches a given type and page size.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc</code></td>

    <td>Allocates to a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_free</code></td>

    <td>Frees memory on a device.</td>

    </tr>

    <tr>

    <td><code>sicm_can_place_exact</code></td>

    <td>Returns whether or not a device supports exact placement.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc_exact</code></td>

    <td>Allocate memory on a device with an exact base address.</td>

    </tr>

    <tr>

    <td><code>sicm_numa_id</code></td>

    <td>Returns the NUMA ID that a device is on.</td>

    </tr>

    <tr>

    <td><code>sicm_device_page_size</code></td>

    <td>Returns the page size of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_eq</code></td>

    <td>Returns if two devices are equal or not.</td>

    </tr>

    <tr>

    <td><code>sicm_move</code></td>

    <td>Moves memory from one device to another.</td>

    </tr>

    <tr>

    <td><code>sicm_pin</code></td>

    <td>Pin the current process to a device''s memory.</td>

    </tr>

    <tr>

    <td><code>sicm_capacity</code></td>

    <td>Returns the capacity of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_avail</code></td>

    <td>Returns the amount of memory available on a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_model_distance</code></td>

    <td>Returns the distance of a given memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_is_near</code></td>

    <td>Returns whether or not a given memory device is nearby the current NUMA node.</td>

    </tr>

    <tr>

    <td><code>sicm_latency</code></td>

    <td>Measures the latency of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear2</code></td>

    <td>Measures a memory device''s linear access bandwidth.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random2</code></td>

    <td>Measures random access bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear3</code></td>

    <td>Measures the linear bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random3</code></td>

    <td>Measures the random access bandwidth of a memory device.</td>

    </tr>

    </tbody>

    </table>

    <h2 id="user-content-arena-allocator-api"><a class="heading-link" href="#arena-allocator-api">Arena
    Allocator API<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_arenas_list</code></td>

    <td>List all arenas created in the arena allocator.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_create</code></td>

    <td>Create a new arena on the given device.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_destroy</code></td>

    <td>Frees up an arena, deleting all associated data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_default</code></td>

    <td>Sets an arena as the default for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_default</code></td>

    <td>Gets the default arena for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_device</code></td>

    <td>Gets the device for a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_device</code></td>

    <td>Sets the memory device for a given arena. Moves all allocated memory already
    allocated to the arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_size</code></td>

    <td>Gets the size of memory allocated to the given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc</code></td>

    <td>Allocate to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc_aligned</code></td>

    <td>Allocate aligned memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_realloc</code></td>

    <td>Resize allocated memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_lookup</code></td>

    <td>Returns which arena a given pointer belongs to.</td>

    </tr>

    </tbody>

    </table>

    <h2 id="user-content-high-level-interface"><a class="heading-link" href="#high-level-interface">High-Level
    Interface<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The high-level interface is normally used with the compiler wrappers located
    in

    <code>bin/</code>. Users should use these wrappers to compile their applications,
    and a

    compiler pass will automatically transform the code so that it calls the

    high-level interface with the appropriate arguments, including initialization,

    destruction, and the proper allocation functions. Assuming the high-level

    interface is linked to the application as a shared library, it automatically

    initializes itself.  All heap allocation routines are replaced by calls to

    <code>void* sh_alloc(int id, size_t sz)</code>, which associates an ID with a
    given

    allocation and allocates the memory into an arena with other allocations of

    that ID.</p>

    <h2 id="user-content-programming-practices"><a class="heading-link" href="#programming-practices">Programming
    Practices<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ol>

    <li>All blocks use curly braces

    <ul>

    <li>Even one-line blocks</li>

    </ul>

    </li>

    <li>Constants on the left side of <code>==</code>

    <ul>

    <li><code>if(NULL == foo) { ...</code></li>

    </ul>

    </li>

    <li>Functions with no arguments are <code>(void)</code>

    </li>

    <li>No C++-style comments in C code</li>

    <li>No GCC extensions except in GCC-only code</li>

    <li>No C++ code in libraries

    <ul>

    <li>Discouraged in components</li>

    </ul>

    </li>

    <li>Always define preprocessor macros

    <ul>

    <li>Define logicals to 0 or 1 (vs. define or not define)</li>

    <li>Use <code>#if FOO</code>, not <code>#ifdef FOO</code>

    </li>

    </ul>

    </li>

    </ol>

    '
  stargazers_count: 25
  subscribers_count: 23
  topics: []
  updated_at: 1695897425.0
laristra/ristra_spackages:
  data_format: 2
  description: 'A mirror of Ristra''s internal gitlab repository. '
  filenames:
  - .gitlab-ci/env/dry-run/spack.yaml
  full_name: laristra/ristra_spackages
  latest_release: null
  readme: '<h1 id="user-content-ristra-spackages"><a class="heading-link" href="#ristra-spackages">Ristra
    Spackages<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This repository contains the custom spackage files for the repos in laristra
    family.</p>

    <h2 id="user-content-basic-usage"><a class="heading-link" href="#basic-usage">Basic
    Usage<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>We assume the user wish to work in the home directory and already have a spack
    instance setup.  The minimum required version of spack is 0.15.2.</p>

    <p>To get the content of this repo</p>

    <pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git

    </code></pre>

    <p>To use the custom spackage files with your spack</p>

    <pre><code>$ spack repo add ristra_spackages/spack-repo

    ==&gt; Added repo with namespace ''lanl_ristra''.


    $ spack repo list

    ==&gt; 2 package repositories.

    lanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo

    builtin            /home/&lt;user&gt;/spack/var/spack/repos/builtin

    </code></pre>

    <p>[Optional]

    To ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code>
    into your spack config folder</p>

    <pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/

    </code></pre>

    <p>Please see the <a href="https://spack.readthedocs.io/en/latest/configuration.html"
    rel="nofollow">Spack documentation</a> for more detailed info.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1649449003.0
lcompilers/lpython:
  data_format: 2
  description: Python compiler
  filenames:
  - spack.yaml
  full_name: lcompilers/lpython
  latest_release: v0.20.0
  readme: '<h1 id="user-content-lpython"><a class="heading-link" href="#lpython">LPython<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>LPython is a Python compiler. It is in heavy development, currently in alpha

    stage. LPython works on Windows, macOS and Linux. Some of the goals of LPython

    include:</p>

    <ul>

    <li>The best possible performance for numerical, array-oriented code</li>

    <li>Run on all platforms</li>

    <li>Compile a subset of Python yet be fully compatible with Python</li>

    <li>Explore designs so that LPython eventually can compile all Python code</li>

    <li>Fast compilation</li>

    <li>Excellent user-friendly diagnostic messages: error, warnings, hints, notes,

    etc.</li>

    <li>Ahead-of-Time compilation to binaries, plus interactive usage (Jupyter notebook)</li>

    <li>Transforming Python code to C++, Fortran and other languages</li>

    </ul>

    <p>And more.</p>

    <h1 id="user-content-sponsors"><a class="heading-link" href="#sponsors">Sponsors<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>LPython has been sponsored by <a href="https://www.gsitechnology.com/" rel="nofollow">GSI
    Technology</a>.

    Our summer students were sponsored by Google Summer of Code via Python Software

    Foundation. The intermediate representation and backends are shared with

    LFortran, see that project for a list of sponsors.</p>

    <h1 id="user-content-installation"><a class="heading-link" href="#installation">Installation<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <h2 id="user-content-step-0-prerequisites"><a class="heading-link" href="#step-0-prerequisites">Step
    0: Prerequisites<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Here is the list of requirements needed to build LPython:</p>

    <ul>

    <li>Python (3.10+)</li>

    <li>Conda</li>

    </ul>

    <p>For Windows, these are additionally required:</p>

    <ul>

    <li>Miniforge Prompt</li>

    <li>Visual Studio (with "Desktop Development with C++" workload)</li>

    </ul>

    <p>Please follow the steps for your desired platform.</p>

    <h2 id="user-content-step-1-install-conda"><a class="heading-link" href="#step-1-install-conda">Step
    1: Install Conda<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This step involves installing Conda using a conda-forge distribution called
    Miniforge.</p>

    <p>Please follow the instructions here to install Conda on your platform:</p>

    <p>Miniforge download link (for Linux, MacOS and Windows): <a href="https://github.com/conda-forge/miniforge/#download">https://github.com/conda-forge/miniforge/#download</a></p>

    <h2 id="user-content-step-2-setting-up"><a class="heading-link" href="#step-2-setting-up">Step
    2: Setting up<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This step involves setting up the required configuration to run the programs
    in LPython.</p>

    <h3 id="user-content-linux"><a class="heading-link" href="#linux">Linux<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h3>

    <p>Run the below command to install <code>binutils-dev</code> package on Linux.</p>

    <div class="highlight highlight-source-shell"><pre>sudo apt install binutils-dev</pre></div>

    <h3 id="user-content-windows"><a class="heading-link" href="#windows">Windows<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>Please follow the below steps for Windows:</p>

    <ul>

    <li>

    <p>Install Visual Studio, for example the version 2022.</p>

    <ul>

    <li>You can download the

    Community version for free from: <a href="https://visualstudio.microsoft.com/downloads/"
    rel="nofollow">https://visualstudio.microsoft.com/downloads/</a>.</li>

    <li>After installing Visual Studio and running the Visual Studio Installer, you
    must install the "Desktop Development with C++" workload which will install Visual
    C++ Compiler (MSVC).</li>

    </ul>

    </li>

    <li>

    <p>Launch the Miniforge prompt from the Desktop.</p>

    <ul>

    <li>It is recommended to use MiniForge instead of Powershell as the main terminal
    to build and write code for LPython.</li>

    </ul>

    </li>

    <li>

    <p>In the MiniForge Prompt, initialize the MSVC compiler using the below command:</p>

    <div class="highlight highlight-source-shell"><pre>call <span class="pl-s"><span
    class="pl-pds">"</span>C:\Program Files\Microsoft Visual Studio\2022\Community\Common7\Tools\VsDevCmd<span
    class="pl-pds">"</span></span> -arch=x64</pre></div>

    </li>

    <li>

    <p>You can optionally test MSVC via:</p>

    <div class="highlight highlight-source-shell"><pre>cl /<span class="pl-k">?</span>

    link /<span class="pl-k">?</span></pre></div>

    <p>Both commands must print several pages of help text.</p>

    </li>

    </ul>

    <h2 id="user-content-step-3-build-lpython"><a class="heading-link" href="#step-3-build-lpython">Step
    3: Build LPython<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ul>

    <li>

    <p>Clone LPython using the following commands</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/lcompilers/lpython.git

    <span class="pl-c1">cd</span> lpython</pre></div>

    <p>You may also use GitHub Desktop to do the same.</p>

    </li>

    </ul>

    <h3 id="user-content-linux-and-macos"><a class="heading-link" href="#linux-and-macos">Linux
    and MacOS<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>

    <p>Create a Conda environment using the pre-existing file:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_unix.yml

    conda activate lp</pre></div>

    </li>

    <li>

    <p>Generate prerequisite files; build in Debug Mode:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    if you are developing on top of a forked repository; please run following command
    first</span>

    <span class="pl-c"><span class="pl-c">#</span> ./generate_default_tag.sh</span>



    ./build0.sh

    ./build1.sh</pre></div>

    </li>

    </ul>

    <h3 id="user-content-windows-1"><a class="heading-link" href="#windows-1">Windows<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>

    <p>Create a Conda environment using the pre-existing file:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_win.yml

    conda activate lp</pre></div>

    </li>

    <li>

    <p>Generate prerequisite files; build in Release Mode:</p>

    <div class="highlight highlight-source-shell"><pre>call build0.bat

    call build1.bat</pre></div>

    </li>

    <li>

    <p>Tests and examples</p>

    <div class="highlight highlight-source-shell"><pre>ctest

    inst<span class="pl-cce">\b</span>in<span class="pl-cce">\l</span>python examples<span
    class="pl-cce">\e</span>xpr2.py

    inst<span class="pl-cce">\b</span>in<span class="pl-cce">\l</span>python examples<span
    class="pl-cce">\e</span>xpr2.py -o a.out

    a.out</pre></div>

    </li>

    <li>

    <p>Whenever you are updating a test case file, you also need to update all the
    reference results associated with that test case:</p>

    <pre><code>python run_tests.py -u --skip-run-with-dbg

    </code></pre>

    </li>

    <li>

    <p>To see all the options associated with LPython test suite, use:</p>

    <pre><code>python run_tests.py --help

    </code></pre>

    </li>

    </ul>

    <h2 id="user-content-tests"><a class="heading-link" href="#tests">Tests:<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <h3 id="user-content-linux-or-macos"><a class="heading-link" href="#linux-or-macos">Linux
    or MacOS<span aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>

    <p>Run tests:</p>

    <div class="highlight highlight-source-shell"><pre>ctest

    ./run_tests.py</pre></div>

    </li>

    <li>

    <p>Run integration tests:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    integration_tests

    ./run_tests.py</pre></div>

    </li>

    <li>

    <p>Troubleshooting on MacOS latest version:</p>

    <ul>

    <li>

    <p>In case of recently updated MacOS, you may get a warning like below in some
    test cases:</p>

    <div class="highlight highlight-source-shell"><pre>ld: warning: object file (test_list_index2.out.tmp.o)
    was built <span class="pl-k">for</span> newer macOS version (14.0) than being
    linked (13.3)</pre></div>

    <p>This leads to mismatch of hashes with expected output in some test cases, this
    can be resolved by updating command line tools. Below is a snippet for the same.</p>

    <div class="highlight highlight-source-shell"><pre>git clean -dfx

    sudo rm -rf /Library/Developer/CommandLineTools <span class="pl-c"><span class="pl-c">#</span>
    make sure you know what you''re doing here</span>

    sudo xcode-select --install

    ./build.sh

    ./run_tests.py</pre></div>

    </li>

    </ul>

    </li>

    </ul>

    <h3 id="user-content-windows-2"><a class="heading-link" href="#windows-2">Windows<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <ul>

    <li>

    <p>Run integration tests</p>

    <div class="highlight highlight-source-shell"><pre>python run_tests.py --skip-run-with-dbg</pre></div>

    </li>

    <li>

    <p>Update reference tests</p>

    <div class="highlight highlight-source-shell"><pre>python run_tests.py -u --skip-run-with-dbg</pre></div>

    </li>

    </ul>

    <h2 id="user-content-speed-up-integration-tests-on-macos"><a class="heading-link"
    href="#speed-up-integration-tests-on-macos">Speed up Integration Tests on MacOS<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Integration tests run slowly because Apple checks the hash of each

    executable online before running.</p>

    <p>You can turn off that feature in the Privacy tab of the Security and Privacy
    item of System Preferences &gt; Developer Tools &gt; Terminal.app &gt; "allow
    the apps below

    to run software locally that does not meet the system''s security

    policy."</p>

    <h2 id="user-content-examples-linux-or-macos"><a class="heading-link" href="#examples-linux-or-macos">Examples
    (Linux or MacOS)<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>You can run the following examples manually in a terminal:</p>

    <div class="highlight highlight-source-shell"><pre>./src/bin/lpython examples/expr2.py

    ./src/bin/lpython examples/expr2.py -o expr

    ./expr

    ./src/bin/lpython --show-ast examples/expr2.py

    ./src/bin/lpython --show-asr examples/expr2.py

    ./src/bin/lpython --show-cpp examples/expr2.py

    ./src/bin/lpython --show-llvm examples/expr2.py

    ./src/bin/lpython --show-c examples/expr2.py</pre></div>

    <h2 id="user-content-contributing"><a class="heading-link" href="#contributing">Contributing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>We welcome contributions from anyone, even if you are new to compilers or to

    open source. It might sound daunting to contribute to a compiler at first, but

    please do, it is not complicated. We will help you with technical issues and

    help improve your contribution so that it can be merged.</p>

    <p>To contribute, submit a Pull Request (PR) against our repository at:</p>

    <p><a href="https://github.com/lcompilers/lpython">https://github.com/lcompilers/lpython</a></p>

    <p>and don''t forget to clean your history, see <a href="./doc/src/rebasing.md">example</a>.</p>

    <p>Please report any bugs you may find at our issue tracker:

    <a href="https://github.com/lcompilers/lpython/issues">https://github.com/lcompilers/lpython/issues</a>.
    Or, even better, fork the

    repository on GitHub and create a PR. We welcome all changes, big or small, and

    we will help you make a PR if you are new to git.</p>

    <p>If you have any questions or need help, please ask us at Zulip (<a href="https://lfortran.zulipchat.com/"
    rel="nofollow"><img src="https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667"
    alt="project chat" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg"
    style="max-width: 100%;"></a>)

    or our <a href="https://groups.io/g/lfortran" rel="nofollow">mailinglist</a>.</p>

    <p>See the <a href="CONTRIBUTING.md">CONTRIBUTING</a> document for more information.</p>

    <h1 id="user-content-star-history"><a class="heading-link" href="#star-history">Star
    History<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p><a href="https://star-history.com/#lcompilers/lpython&amp;Date" rel="nofollow"><img
    src="https://camo.githubusercontent.com/74354cd1e035c9b74d4f31a92341a1a6601b47c452fbfb82ec89e990e2b2b660/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c636f6d70696c6572732f6c707974686f6e26747970653d44617465"
    alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=lcompilers/lpython&amp;type=Date"
    style="max-width: 100%;"></a></p>

    '
  stargazers_count: 1118
  subscribers_count: 26
  topics:
  - compiler
  - high-performance
  - python
  updated_at: 1697417977.0
lezzidan/spack:
  data_format: 2
  description: Spack clone
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/aws-isc/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  full_name: lezzidan/spack
  latest_release: null
  readme: "<h1 id=\"user-content--spack\"><a class=\"heading-link\" href=\"#-spack\"\
    >\n<img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"> Spack<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/build-containers.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/build-containers.yml/badge.svg\"\
    \ alt=\"Containers\" style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/d91ed7ac7abbd5a6102cbe988dd8e9ac21bde0a73d97be7603b891ad08ce3479/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/code%20style-black-000000.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/4bbdc2b44561be6dfffe64e15730e1c5a2bed9c4efe6f9942638091a4ce3ede2/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2 id=\"user-content-documentation\"\
    ><a class=\"heading-link\" href=\"#documentation\">Documentation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p><a href=\"https://spack.readthedocs.io/\"\
    \ rel=\"nofollow\"><strong>Full documentation</strong></a> is available, or\n\
    run <code>spack help</code> or <code>spack help --all</code>.</p>\n<p>For a cheat\
    \ sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n<h2 id=\"user-content-tutorial\"\
    ><a class=\"heading-link\" href=\"#tutorial\">Tutorial<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>We maintain a\n<a href=\"\
    https://spack.readthedocs.io/en/latest/tutorial.html\" rel=\"nofollow\"><strong>hands-on\
    \ tutorial</strong></a>.\nIt covers basic to advanced usage, packaging, developer\
    \ features, and large HPC\ndeployments.  You can do all of the exercises on your\
    \ own laptop using a\nDocker container.</p>\n<p>Feel free to use these materials\
    \ to teach users at your organization\nabout Spack.</p>\n<h2 id=\"user-content-community\"\
    ><a class=\"heading-link\" href=\"#community\">Community<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>Spack is an open source\
    \ project.  Questions, discussion, and\ncontributions are welcome. Contributions\
    \ can be anything from new\npackages to bugfixes, documentation, or even new core\
    \ features.</p>\n<p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>:\
    \ <a href=\"https://spackpm.slack.com\" rel=\"nofollow\">spackpm.slack.com</a>.\n\
    To get an invitation, visit <a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    >slack.spack.io</a>.</li>\n<li>\n<a href=\"https://github.com/spack/spack/discussions\"\
    ><strong>Github Discussions</strong></a>: not just for discussions, also Q&amp;A.</li>\n\
    <li>\n<strong>Mailing list</strong>: <a href=\"https://groups.google.com/d/forum/spack\"\
    \ rel=\"nofollow\">groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>:\
    \ <a href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<h2 id=\"user-content-contributing\"\
    ><a class=\"heading-link\" href=\"#contributing\">Contributing<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Contributing to Spack\
    \ is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2 id=\"user-content-releases\"><a class=\"heading-link\" href=\"#releases\"\
    >Releases<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>For multi-user site deployments or other use cases that need very stable\n\
    software installations, we recommend using Spack's\n<a href=\"https://github.com/spack/spack/releases\"\
    >stable releases</a>.</p>\n<p>Each Spack release series also has a corresponding\
    \ branch, e.g.\n<code>releases/v0.14</code> has <code>0.14.x</code> versions of\
    \ Spack, and <code>releases/v0.13</code> has\n<code>0.13.x</code> versions. We\
    \ backport important bug fixes to these branches but\nwe do not advance the package\
    \ versions or make other changes that would\nchange the way Spack concretizes\
    \ dependencies within a release branch.\nSo, you can base your Spack deployment\
    \ on a release branch and <code>git pull</code>\nto get fixes, without the package\
    \ churn that comes with <code>develop</code>.</p>\n<p>The latest release is always\
    \ available with the <code>releases/latest</code> tag.</p>\n<p>See the <a href=\"\
    https://spack.readthedocs.io/en/latest/developer_guide.html#releases\" rel=\"\
    nofollow\">docs on releases</a>\nfor more details.</p>\n<h2 id=\"user-content-code-of-conduct\"\
    ><a class=\"heading-link\" href=\"#code-of-conduct\">Code of Conduct<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Please note that Spack\
    \ has a\n<a href=\".github/CODE_OF_CONDUCT.md\"><strong>Code of Conduct</strong></a>.\
    \ By participating in\nthe Spack community, you agree to abide by its rules.</p>\n\
    <h2 id=\"user-content-authors\"><a class=\"heading-link\" href=\"#authors\">Authors<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Many\
    \ thanks go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\"\
    >tgamblin@llnl.gov</a>.</p>\n<h3 id=\"user-content-citing-spack\"><a class=\"\
    heading-link\" href=\"#citing-spack\">Citing Spack<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>If you are referencing Spack in a\
    \ publication, please cite the following paper:</p>\n<ul>\n<li>Todd Gamblin, Matthew\
    \ P. LeGendre, Michael R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de\
    \ Supinski, and W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<p>On GitHub, you can copy\
    \ this citation in APA or BibTeX format via the \"Cite this repository\"\nbutton.\
    \ Or, see the comments in <code>CITATION.cff</code> for the raw BibTeX.</p>\n\
    <h2 id=\"user-content-license\"><a class=\"heading-link\" href=\"#license\">License<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Spack\
    \ is distributed under the terms of both the MIT license and the\nApache License\
    \ (Version 2.0). Users may choose either license, at their\noption.</p>\n<p>All\
    \ new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n\
    <p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1684418839.0
lfortran/lfortran:
  data_format: 2
  description: Official main repository for LFortran
  filenames:
  - spack.yaml
  full_name: lfortran/lfortran
  latest_release: v0.22.0
  readme: "<h1 id=\"user-content-lfortran\"><a class=\"heading-link\" href=\"#lfortran\"\
    >LFortran<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p><a href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>LFortran is a modern open-source (BSD\
    \ licensed) interactive Fortran compiler\nbuilt on top of LLVM. It can execute\
    \ user's code interactively to allow\nexploratory work (much like Python, MATLAB\
    \ or Julia) as well as compile to\nbinaries with the goal to run user's code on\
    \ modern architectures such as\nmulti-core CPUs and GPUs.</p>\n<p>Website: <a\
    \ href=\"https://lfortran.org/\" rel=\"nofollow\">https://lfortran.org/</a></p>\n\
    <p>Try online: <a href=\"https://dev.lfortran.org/\" rel=\"nofollow\">https://dev.lfortran.org/</a></p>\n\
    <h1 id=\"user-content-documentation\"><a class=\"heading-link\" href=\"#documentation\"\
    >Documentation<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p>All documentation, installation instructions, motivation, design, ... is\n\
    available at:</p>\n<p><a href=\"https://docs.lfortran.org/\" rel=\"nofollow\"\
    >https://docs.lfortran.org/</a></p>\n<p>Which is generated using the files in\
    \ the <code>doc</code> directory.</p>\n<h1 id=\"user-content-development\"><a\
    \ class=\"heading-link\" href=\"#development\">Development<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>We welcome all contributions.\n\
    The main development repository is at GitHub:</p>\n<p><a href=\"https://github.com/lfortran/lfortran\"\
    >https://github.com/lfortran/lfortran</a></p>\n<p>Please send Pull Requests (PRs)\
    \ and open issues there.</p>\n<p>See the <a href=\"CONTRIBUTING.md\">CONTRIBUTING</a>\
    \ document for more information.</p>\n<p>Main mailinglist:</p>\n<p><a href=\"\
    https://groups.io/g/lfortran\" rel=\"nofollow\">https://groups.io/g/lfortran</a></p>\n\
    <p>You can also chat with us on Zulip (<a href=\"https://lfortran.zulipchat.com/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a>).</p>\n<p>Note: We moved to the above GitHub\
    \ repository from GitLab on July 18, 2022.</p>\n<h1 id=\"user-content-donations\"\
    ><a class=\"heading-link\" href=\"#donations\">Donations<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h1>\n<p>You can support LFortran's\
    \ development by donating to NumFOCUS or Open\nCollective as well as GitHub Sponsors:</p>\n\
    <ul>\n<li><a href=\"https://numfocus.org/donate-to-lfortran\" rel=\"nofollow\"\
    >https://numfocus.org/donate-to-lfortran</a></li>\n<li><a href=\"https://opencollective.com/lfortran\"\
    \ rel=\"nofollow\">https://opencollective.com/lfortran</a></li>\n<li><a href=\"\
    https://github.com/sponsors/lfortran\">https://github.com/sponsors/lfortran</a></li>\n\
    </ul>\n<p>All donations will be used strictly to fund LFortran development, by\
    \ supporting\ntasks such as paying developers to implement features, sprints,\
    \ improved\ndocumentation, fixing bugs, etc.</p>\n<p>The donations to LFortran\
    \ are managed by the NumFOCUS foundation. NumFOCUS is a\n501(c)3 non-profit foundation,\
    \ so if you are subject to US Tax law, your\ncontributions will be tax-deductible.</p>\n\
    <p>If you want to discuss another way to fund or help with the development, feel\n\
    free to contact Ond\u0159ej \u010Cert\xEDk (<a href=\"mailto:ondrej@certik.us\"\
    >ondrej@certik.us</a>).</p>\n<h1 id=\"user-content-star-history\"><a class=\"\
    heading-link\" href=\"#star-history\">Star History<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h1>\n<p><a href=\"https://star-history.com/#lfortran/lfortran&amp;Date\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7e19634671b985a40376628d5d76d76ef6baf79368e0c4b6a409523464e705b7/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c666f727472616e2f6c666f727472616e26747970653d44617465\"\
    \ alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=lfortran/lfortran&amp;type=Date\"\
    \ style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 738
  subscribers_count: 20
  topics:
  - fortran
  - interactive
  - compiler
  - library
  - repl
  - jupyter
  - jupyter-notebook
  - jupyter-kernels
  updated_at: 1697355107.0
m-s-will/nyx:
  data_format: 2
  description: null
  filenames:
  - nyx/inputs/spack/spack.yaml
  full_name: m-s-will/nyx
  latest_release: null
  readme: '<h1 id="user-content-nyx-with-ascent-in-container"><a class="heading-link"
    href="#nyx-with-ascent-in-container">Nyx with Ascent in Container<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <p>This project contains a Dockerfile and all necessary components to create a
    Docker container for Nyx.

    The container is available on <a href="https://hub.docker.com/repository/docker/mswill/elwe_nyx"
    rel="nofollow">Dockerhub</a>, however these versions may not always be up to date.</p>

    <h2 id="user-content-building-the-container"><a class="heading-link" href="#building-the-container">Building
    the container<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The Ascent actions can be changed by editing <a href="https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml">ascent_actions.yaml</a>.

    When finished with the customization, the container can be rebuilt by navigating
    into the source directory and executing:</p>

    <pre><code>$ docker build -t &lt;mytag&gt; .

    </code></pre>

    <p>The Nyx simulation is being run during container creation and provides a Cinema
    database.</p>

    <h2 id="user-content-running-the-container"><a class="heading-link" href="#running-the-container">Running
    the container<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>After either pulling or building the container, it can be run by calling:</p>

    <pre><code>$ docker run -p 80:80 &lt;mytag&gt;.

    </code></pre>

    <p><code>-p 80:80</code> makes port 80 available on the outside which is needed
    for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code>
    in our browser.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1619455896.0
mfem/mfem:
  data_format: 2
  description: Lightweight, general, scalable C++ library for finite element methods
  filenames:
  - config/docker/spack.yaml
  full_name: mfem/mfem
  latest_release: v4.6
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2 id=\"user-content-license\"><a class=\"heading-link\"\
    \ href=\"#license\">License<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>MFEM is distributed under the terms of the BSD-3 license.\
    \ All new contributions\nmust be made under this license. See <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> for\ndetails.</p>\n<p>SPDX-License-Identifier:\
    \ BSD-3-Clause <br>\nLLNL Release Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 1382
  subscribers_count: 119
  topics:
  - finite-elements
  - high-order
  - high-performance-computing
  - parallel-computing
  - amr
  - computational-science
  - fem
  - scientific-computing
  - hpc
  - math-physics
  - radiuss
  updated_at: 1697277952.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ORNL/Frontier/spack.yaml
  - ANL/Theta/spack.yaml
  - ANL/Polaris/spack.yaml
  - NERSC/Perlmutter/ss11/spack.yaml
  - ANL/Sunspot/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1 id="user-content-platform-configurations-for-mochi"><a class="heading-link"
    href="#platform-configurations-for-mochi">Platform configurations for Mochi<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2 id="user-content-using-spackyaml-files"><a class="heading-link" href="#using-spackyaml-files">Using
    spack.yaml files<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2 id="user-content-contributing-to-this-repository"><a class="heading-link"
    href="#contributing-to-this-repository">Contributing to this repository<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 4
  subscribers_count: 3
  topics: []
  updated_at: 1682086466.0
mochi-hpc/margo-microservice-template:
  data_format: 2
  description: Template for a margo-based Mochi microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/margo-microservice-template
  latest_release: null
  readme: '<h1 id="user-content-margo-microservice-template"><a class="heading-link"
    href="#margo-microservice-template">Margo Microservice Template<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <p>This project is a template to start developing a Mochi microservice based on
    Margo.

    The complete documentation to get started using this template is available

    <a href="https://mochi.readthedocs.io/en/latest/templates/01_margo.html" rel="nofollow">here</a>.</p>

    <p>To use this template:</p>

    <ul>

    <li>Click on the green "Use this template" button at the top.</li>

    <li>Give a name to your project.</li>

    <li>Once your project repository is created, go to Settings &gt; Actions &gt;
    General and give "Read and write permissions" under <em>Workflow permissions</em>.</li>

    <li>Finally, edit the initial-setup.json file and push the changes to your repo.</li>

    </ul>

    <p>Editing the initial-setup.json file with trigger a github action that will

    cleanup your repository and rename files, namespaces, functions, etc. according

    to the name of your service and the resources it manages.</p>

    <p>Enjoy working with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1649078785.0
mochi-hpc/mochi-bake:
  data_format: 2
  description: A microservice (i.e., Mochi provider) for high performance bulk storage
    of raw data regions
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bake
  latest_release: v0.6.4
  readme: "<h1 id=\"user-content-bake\"><a class=\"heading-link\" href=\"#bake\">Bake<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>Bake\
    \ is a microservice (i.e., Mochi provider) for high performance bulk\nstorage\
    \ of raw data regions.  Bake uses modular backends to store data\non persistent\
    \ memory, conventional file systems, or other storage media.</p>\n<p>See <a href=\"\
    https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a>\
    \ and\n<a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a>\
    \ for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively\
    \ to data storage.  Capabilities such as\nindexing, name spaces, and sharding\
    \ must be provided by other microservice\ncomponents.</p>\n<h2 id=\"user-content-installation\"\
    ><a class=\"heading-link\" href=\"#installation\">Installation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The easiest way to\
    \ install Bake is through spack:</p>\n<p><code>spack install bake</code></p>\n\
    <p>This will install BAKE and its dependencies.  Please refer to the end of the\n\
    document for manual compilation instructions.</p>\n<h2 id=\"user-content-architecture\"\
    ><a class=\"heading-link\" href=\"#architecture\">Architecture<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Like most Mochi services,\
    \ BAKE relies on a client/provider architecture.\nA provider, identified by its\
    \ <em>address</em> and <em>multiplex id</em>, manages one or more\n<em>BAKE targets</em>,\
    \ referenced externally by their <em>target id</em>.</p>\n<p>A target can be thought\
    \ of as a storage device.  This may be (for example) a\nPMDK volume or a local\
    \ file system.</p>\n<h2 id=\"user-content-setting-up-a-bake-target\"><a class=\"\
    heading-link\" href=\"#setting-up-a-bake-target\">Setting up a BAKE target<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>BAKE\
    \ requires the backend storage file to be created beforehand using\n<code>bake-mkpool</code>.\
    \ For instance:</p>\n<p><code>bake-mkpool -s 500M /dev/shm/foo.dat</code></p>\n\
    <p>creates a 500 MB file at <em>/dev/shm/foo.dat</em> to be used by BAKE as a\
    \ target.\nBake will use the <code>pmem</code> (persistent memory) backend by\
    \ default, which means\nthat the underlying file will memory mapped for access\
    \ usign the PMDK\nlibrary.  You can also providie an explicit prefix (such as\
    \ <code>file:</code> for the\nconventional file backend or <code>pmem:</code>\
    \ for the persistent memory backend) to\ndictate a specific target type.</p>\n\
    <h2 id=\"user-content-starting-a-daemon\"><a class=\"heading-link\" href=\"#starting-a-daemon\"\
    >Starting a daemon<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>BAKE ships with a default daemon program that can setup providers and attach\n\
    to storage targets. This daemon can be started as follows:</p>\n<p><code>bake-server-daemon\
    \ [options] &lt;listen_address&gt; &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n\
    <p>The program takes a set of options followed by an address at which to listen\
    \ for\nincoming RPCs, and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n\
    <p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234\
    \ /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n\
    <ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the\
    \ address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em>\
    \ or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates\
    \ that, if multiple BAKE targets are used (as above),\nthese targets should be\
    \ managed by multiple providers, accessible through\ndifferent multiplex ids 1,\
    \ 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage.\
    \ The <em>targets</em> mode indicates that a single provider should be used to\n\
    manage all the storage targets.</p>\n<h2 id=\"user-content-integrating-bake-into-a-larger-service\"\
    ><a class=\"heading-link\" href=\"#integrating-bake-into-a-larger-service\">Integrating\
    \ Bake into a larger service<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>Bake is not intended to be a standalone user-facing service.\
    \  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\" rel=\"\
    nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for guidance\
    \ on how to\nintegrate it with other providers using Mochi's Bedrock capability.</p>\n\
    <h2 id=\"user-content-client-api-example\"><a class=\"heading-link\" href=\"#client-api-example\"\
    >Client API example<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>Data is stored in <code>regions</code> within a <code>target</code> using explicit\
    \ create,\nwrite, and persist operations.  The caller cannot dictate the region\
    \ id\nthat will be used to reference a region; this identifier is generated\n\
    by Bake at creation time.  The region size must be specified at creation\ntime\
    \ as well; there is no mechanism for extending the size of an existing\nregion.</p>\n\
    <div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">#include</span>\
    \ <span class=\"pl-s\">&lt;bake-client.h&gt;</span>\n\n<span class=\"pl-smi\"\
    >int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">int</span>\
    \ <span class=\"pl-s1\">argc</span>, <span class=\"pl-smi\">char</span> <span\
    \ class=\"pl-c1\">*</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >argv</span>)\n{\n    <span class=\"pl-smi\">char</span> <span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">svr_addr_str</span>; <span class=\"pl-c\">// string\
    \ address of the BAKE server</span>\n    <span class=\"pl-smi\">hg_addr_t</span>\
    \ <span class=\"pl-s1\">svr_addr</span>; <span class=\"pl-c\">// Mercury address\
    \ of the BAKE server</span>\n    <span class=\"pl-smi\">margo_instance_id</span>\
    \ <span class=\"pl-s1\">mid</span>; <span class=\"pl-c\">// Margo instance id</span>\n\
    \    <span class=\"pl-smi\">bake_client_t</span> <span class=\"pl-s1\">bcl</span>;\
    \ <span class=\"pl-c\">// BAKE client</span>\n    <span class=\"pl-smi\">bake_provider_handle_t</span>\
    \ <span class=\"pl-s1\">bph</span>; <span class=\"pl-c\">// BAKE handle to provider</span>\n\
    \    <span class=\"pl-smi\">uint8_t</span> <span class=\"pl-s1\">mplex_id</span>;\
    \ <span class=\"pl-c\">// multiplex id of the provider</span>\n    <span class=\"\
    pl-smi\">uint32_t</span> <span class=\"pl-s1\">target_number</span>; <span class=\"\
    pl-c\">// target to use</span>\n    <span class=\"pl-smi\">bake_region_id_t</span>\
    \ <span class=\"pl-s1\">rid</span>; <span class=\"pl-c\">// BAKE region id handle</span>\n\
    \t<span class=\"pl-smi\">bake_target_id_t</span><span class=\"pl-c1\">*</span>\
    \ <span class=\"pl-s1\">bti</span>; <span class=\"pl-c\">// array of target ids</span>\n\
    \n\t<span class=\"pl-c\">/* ... setup variables ... */</span>\n\n\t<span class=\"\
    pl-c\">/* Initialize Margo */</span>\n\t<span class=\"pl-s1\">mid</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">margo_init</span>(..., <span\
    \ class=\"pl-c1\">MARGO_CLIENT_MODE</span>, <span class=\"pl-c1\">0</span>, <span\
    \ class=\"pl-c1\">-1</span>);\n\t<span class=\"pl-c\">/* Lookup the server */</span>\n\
    \t<span class=\"pl-en\">margo_addr_lookup</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr_str</span>, <span class=\"pl-c1\">&amp;</span><span\
    \ class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-c\">/* Creates the BAKE\
    \ client */</span>\n\t<span class=\"pl-en\">bake_client_init</span>(<span class=\"\
    pl-s1\">mid</span>, <span class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bcl</span>);\n\
    \t<span class=\"pl-c\">/* Creates the provider handle */</span>\n\t<span class=\"\
    pl-en\">bake_provider_handle_create</span>(<span class=\"pl-s1\">bcl</span>, <span\
    \ class=\"pl-s1\">svr_addr</span>, <span class=\"pl-s1\">mplex_id</span>, <span\
    \ class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bph</span>);\n\t<span class=\"\
    pl-c\">/* Asks the provider for up to target_number target ids */</span>\n\t<span\
    \ class=\"pl-smi\">uint32_t</span> <span class=\"pl-s1\">num_targets</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-c1\">0</span>;\n\t<span class=\"pl-s1\"\
    >bti</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">calloc</span>(<span\
    \ class=\"pl-s1\">num_targets</span>, <span class=\"pl-k\">sizeof</span>(<span\
    \ class=\"pl-c1\">*</span><span class=\"pl-s1\">bti</span>));\n\t<span class=\"\
    pl-en\">bake_probe</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >target_number</span>, <span class=\"pl-s1\">bti</span>, <span class=\"pl-c1\"\
    >&amp;</span><span class=\"pl-s1\">num_targets</span>);\n\t<span class=\"pl-k\"\
    >if</span>(<span class=\"pl-s1\">num_targets</span> <span class=\"pl-c1\">&lt;</span>\
    \ <span class=\"pl-s1\">target_number</span>) {\n\t\t<span class=\"pl-en\">fprintf</span>(<span\
    \ class=\"pl-s1\">stderr</span>, <span class=\"pl-s\">\"Error: provider has only\
    \ %d storage targets\\n\"</span>, <span class=\"pl-s1\">num_targets</span>);\n\
    \t}\n\t<span class=\"pl-c\">/* Create a region */</span>\n\t<span class=\"pl-smi\"\
    >size_t</span> <span class=\"pl-s1\">size</span> <span class=\"pl-c1\">=</span>\
    \ ...; <span class=\"pl-c\">// size of the region to create</span>\n\t<span class=\"\
    pl-en\">bake_create</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >bti</span>[<span class=\"pl-s1\">target_number</span><span class=\"pl-c1\">-</span><span\
    \ class=\"pl-c1\">1</span>], <span class=\"pl-s1\">size</span>, <span class=\"\
    pl-c1\">&amp;</span><span class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\"\
    >/* Write data into the region at offset 0 */</span>\n\t<span class=\"pl-smi\"\
    >char</span><span class=\"pl-c1\">*</span> <span class=\"pl-s1\">buf</span> <span\
    \ class=\"pl-c1\">=</span> ...;\n\t<span class=\"pl-en\">bake_write</span>(<span\
    \ class=\"pl-s1\">bph</span>, <span class=\"pl-s1\">rid</span>, <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-s1\">buf</span>, <span class=\"pl-s1\">size</span>);\n\
    \t<span class=\"pl-c\">/* Make all modifications persistent */</span>\n\t<span\
    \ class=\"pl-en\">bake_persist</span>(<span class=\"pl-s1\">bph</span>, <span\
    \ class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\">/* Release provider handle\
    \ */</span>\n\t<span class=\"pl-en\">bake_provider_handle_release</span>(<span\
    \ class=\"pl-s1\">bph</span>);\n\t<span class=\"pl-c\">/* Release BAKE client\
    \ */</span>\n\t<span class=\"pl-en\">bake_client_finalize</span>(<span class=\"\
    pl-s1\">bcl</span>);\n\t<span class=\"pl-c\">/* Cleanup Margo resources */</span>\n\
    \t<span class=\"pl-en\">margo_addr_free</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-en\">margo_finalize</span>(<span\
    \ class=\"pl-s1\">mid</span>);\n\t<span class=\"pl-k\">return</span> <span class=\"\
    pl-c1\">0</span>;\n}</pre></div>\n<p>Note that a <code>bake_region_id_t</code>\
    \ object is persistent.  It can be written\n(into a file or a socket) and stored\
    \ or sent to another program. These\nregion ids are what uniquely reference a\
    \ region within a given target.</p>\n<p>The rest of the client-side API can be\
    \ found in <code>bake-client.h</code>.</p>\n<h2 id=\"user-content-provider-api\"\
    ><a class=\"heading-link\" href=\"#provider-api\">Provider API<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The bake-server-daemon\
    \ source is a good example of how to create providers and\nattach storage targets\
    \ to them. The provider-side API is located in\n<em>bake-server.h</em>, and consists\
    \ of mainly two functions:</p>\n<div class=\"highlight highlight-source-c\"><pre><span\
    \ class=\"pl-smi\">int</span> <span class=\"pl-en\">bake_provider_register</span>(<span\
    \ class=\"pl-smi\">margo_instance_id</span>                     <span class=\"\
    pl-s1\">mid</span>,\n                           <span class=\"pl-smi\">uint16_t</span>\
    \                              <span class=\"pl-s1\">provider_id</span>,\n   \
    \                        <span class=\"pl-k\">const</span> <span class=\"pl-k\"\
    >struct</span> <span class=\"pl-smi\">bake_provider_init_info</span><span class=\"\
    pl-c1\">*</span> <span class=\"pl-s1\">args</span>,\n                        \
    \   <span class=\"pl-smi\">bake_provider_t</span><span class=\"pl-c1\">*</span>\
    \                      <span class=\"pl-s1\">provider</span>);</pre></div>\n<p>This\
    \ creates a provider at the given provider id using the specified margo\ninstance.\
    \  The <code>args</code> parameter can be used to modify default settings,\nincluding\
    \ passing in a fully specified json configuration block.  See\n<code>bake-server.h</code>\
    \ for details.</p>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"\
    pl-smi\">int</span> <span class=\"pl-en\">bake_provider_attach_target</span>(<span\
    \ class=\"pl-smi\">bake_provider_t</span>   <span class=\"pl-s1\">provider</span>,\n\
    \                                <span class=\"pl-k\">const</span> <span class=\"\
    pl-smi\">char</span><span class=\"pl-c1\">*</span>       <span class=\"pl-s1\"\
    >target_name</span>,\n                                <span class=\"pl-smi\">bake_target_id_t</span><span\
    \ class=\"pl-c1\">*</span> <span class=\"pl-s1\">target_id</span>);</pre></div>\n\
    <p>This makes the provider manage the given storage target.</p>\n<p>Other functions\
    \ are available to create and detach targets from a provider.</p>\n<h2 id=\"user-content-generic-bake-benchmark\"\
    ><a class=\"heading-link\" href=\"#generic-bake-benchmark\">Generic Bake benchmark<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>By\
    \ using <code>--enable-benchmark</code> when compiling Bake (or <code>+benchmark</code>\
    \ when using Spack),\nyou will build a <code>bake-benchmark</code> program that\
    \ can be used as a configurable benchmark.\nThis benchmark requires an MPI compiler,\
    \ hence you may need to configure Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n\
    <p>The benchmark is an MPI program that can be run on 2 or more ranks. Rank 0\
    \ will act\nas a server, while non-zero ranks act as clients. The server will\
    \ not create\na Bake target. The Bake target needs to be created (with <code>bake-makepool</code>)\
    \ beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing\
    \ the sequence\nof benchmarks to execute. An example of such a file is located\
    \ in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code>\
    \ array corresponds to a benchmark. The <code>type</code> field indicates\nthe\
    \ type of benchmark to execute. The <code>repetitions</code> field indicates how\
    \ many times the\nbenchmark should be repeated.</p>\n<p>The following table describes\
    \ each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n\
    <th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n\
    </tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to\
    \ the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n\
    <td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for\
    \ each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n\
    <td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's\
    \ buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n\
    <td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n\
    <td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions,\
    \ or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether\
    \ to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n\
    </tbody>\n</table>\n<h2 id=\"user-content-manual-installation\"><a class=\"heading-link\"\
    \ href=\"#manual-installation\">Manual installation<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>BAKE depends on the following\
    \ libraries:</p>\n<ul>\n<li>uuid (install uuid-dev package on ubuntu)</li>\n<li>PMDK\
    \ (see instructions below)</li>\n<li>json-c</li>\n<li>mochi-abt-io</li>\n<li>mochi-margo</li>\n\
    </ul>\n<p>Bake will automatically identify these dependencies at configure time\
    \ using\npkg-config. To compile BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n\
    <li><code>mkdir build</code></li>\n<li><code>cd build</code></li>\n<li><code>../configure\
    \ --prefix=/home/carns/working/install</code></li>\n<li><code>make</code></li>\n\
    </ul>\n<p>If any dependencies are installed in a nonstandard location, then\n\
    modify the configure step listed above to include the following argument:</p>\n\
    <ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1633975151.0
mochi-hpc/mochi-raft:
  data_format: 2
  description: Mochi-based implementation of RAFT using c-raft
  filenames:
  - polaris-spack.yaml
  full_name: mochi-hpc/mochi-raft
  latest_release: null
  readme: '<h1 id="user-content-mochi-raft"><a class="heading-link" href="#mochi-raft">Mochi-RAFT<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This repository provides an implementation of the RAFT protocol using

    Margo for communication and <a href="https://github.com/canonical/raft">C-Raft</a>

    for the protocol itself.</p>

    <p>Mochi-RAFT (Mraft) is modular and allows users to provide their own

    implementation of a persistent log.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1692622489.0
mochi-hpc/mochi-sdskv:
  data_format: 2
  description: simple margo-projected keyval service
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-sdskv
  latest_release: v0.1.14
  readme: "<h1 id=\"user-content-sdskv-sds-keyval\"><a class=\"heading-link\" href=\"\
    #sdskv-sds-keyval\">SDSKV (SDS Key/Val)<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h1>\n<h2 id=\"user-content-installation\"><a class=\"\
    heading-link\" href=\"#installation\">Installation<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>SDSKV can easily be installed using\
    \ Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n<p>This will install\
    \ SDSKV (and any required dependencies).\nAvailable backends will be <em>Map</em>\
    \ (in-memory C++ std::map, useful for testing)\nand BwTree (deprecated). To enable\
    \ the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code> and <code>+leveldb</code>\
    \ respectively. For example:</p>\n<p><code>spack install sdskeyval+bdb+leveldb</code></p>\n\
    <p>Note that if you are using a system boost path in spack (in your\npackages.yaml)\
    \ rather than letting spack build boost, then you must\ninstall libboost-system-dev\
    \ and libboost-filesystem-dev packages on\nyour system.</p>\n<h2 id=\"user-content-architecture\"\
    ><a class=\"heading-link\" href=\"#architecture\">Architecture<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>List most mochi services,\
    \ SDSKV relies on a client/provider architecture.\nA provider, identified by its\
    \ <em>address</em> and <em>multiplex id</em>, manages one or more\ndatabases,\
    \ referenced externally by their database id.</p>\n<h2 id=\"user-content-starting-a-daemon\"\
    ><a class=\"heading-link\" href=\"#starting-a-daemon\">Starting a daemon<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>SDSKV\
    \ ships with a default daemon program that can setup providers and\ndatabases.\
    \ This daemon can be started as follows:</p>\n<p><code>sdskv-server-daemon [OPTIONS]\
    \ &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb] &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb]\
    \ ...</code></p>\n<p>For example:</p>\n<p><code>sdskv-server-daemon tcp://localhost:1234\
    \ foo:bdb bar</code></p>\n<p>listen_addr is the address at which to listen; database\
    \ names should be provided in the form\n<em>name:type</em> where <em>type</em>\
    \ is <em>map</em> (std::map), <em>bwt</em> (BwTree), <em>bdb</em> (Berkeley DB),\
    \ or <em>ldb</em> (LevelDB).</p>\n<p>For database that are persistent like BerkeleyDB\
    \ or LevelDB, the name should be a path to the\nfile where the database will be\
    \ put (this file should not exist).</p>\n<p>The following additional options are\
    \ accepted:</p>\n<ul>\n<li>\n<code>-f</code> provides the name of the file in\
    \ which to write the address of the daemon.</li>\n<li>\n<code>-m</code> provides\
    \ the mode (providers or databases).</li>\n</ul>\n<p>The providers mode indicates\
    \ that, if multiple SDSKV databases are used (as above),\nthese databases should\
    \ be managed by multiple providers, accessible through\ndifferent multiplex ids\
    \ 1, 2, ... N where N is the number of databases\nto manage. The targets mode\
    \ indicates that a single provider should be used to\nmanage all the databases.\
    \ This provider will be accessible at multiplex id 1.</p>\n<h2 id=\"user-content-client-api\"\
    ><a class=\"heading-link\" href=\"#client-api\">Client API<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The client API is available\
    \ in <em>sdskv-client.h</em>.\nThe codes in the <em>test</em> folder illustrate\
    \ how to use it.</p>\n<h2 id=\"user-content-provider-api\"><a class=\"heading-link\"\
    \ href=\"#provider-api\">Provider API<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h2>\n<p>The server-side API is available in <em>sdskv-server.h</em>.\n\
    The code of the daemon (<em>src/sdskv-server-daemon.c</em>) can be used as an\
    \ example.</p>\n<h3 id=\"user-content-custom-key-comparison-function\"><a class=\"\
    heading-link\" href=\"#custom-key-comparison-function\">Custom key comparison\
    \ function<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>It is possible to specify a custom function for comparing/sorting keys\nwhen\
    \ creating a provider. A comparison function must have the following prototype:</p>\n\
    <p><code>int (*)(const void* key1, size_t keysize1, const void* key2, size_t keysize2)</code></p>\n\
    <p>Its return value must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0\
    \ if key1 &gt; key2.\nIt must define a total order of the key space.</p>\n<h2\
    \ id=\"user-content-c-api\"><a class=\"heading-link\" href=\"#c-api\">C++ API<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>An\
    \ object-oriented C++ API is available in <code>sdskv-client.hpp</code> and <code>sdskv-server.hpp</code>.\n\
    On the client side this API provides the <code>client</code>, <code>provider_handle</code>,\
    \ and <code>database</code> objects.\nExamples of usage of these objects can be\
    \ found in the <code>test/sdskv-cxx-test.cc</code>.\nOn the server side, this\
    \ API provides a <code>provider</code> object.</p>\n<h2 id=\"user-content-benchmark\"\
    ><a class=\"heading-link\" href=\"#benchmark\">Benchmark<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>SDSKV can be compiled with\
    \ <code>--enable-benchmark</code> (or <code>+benchmark</code> in Spack). In this\
    \ case,\nSDSKV requires the JsonCPP and MPI dependencies (when compiling manually,\
    \ use <code>CXX=mpicxx</code> in\nyour configure step, for example), and it will\
    \ build and install the <code>sdskv-benchmark</code> program.</p>\n<p>This program\
    \ is an MPI program that reads a JSON file describing a series of access patterns.\n\
    Rank 0 of this MPI program acts as an SDSKV server. Other ranks act as clients,\
    \ all executing\nthis access pattern.</p>\n<p>The following is an example of a\
    \ JSON file.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\t<span\
    \ class=\"pl-ent\">\"protocol\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span class=\"pl-ent\"\
    >\"seed\"</span> : <span class=\"pl-c1\">0</span>,\n\t<span class=\"pl-ent\">\"\
    server\"</span> : {\n\t\t<span class=\"pl-ent\">\"use-progress-thread\"</span>\
    \ : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-ent\">\"rpc-thread-count\"\
    </span> : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-ent\">\"database\"\
    </span> : {\n\t\t\t<span class=\"pl-ent\">\"type\"</span> : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\">\"</span></span>,\n\
    \t\t\t<span class=\"pl-ent\">\"name\"</span> : <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t\
    <span class=\"pl-ent\">\"path\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/dev/shm<span class=\"pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span\
    \ class=\"pl-ent\">\"benchmarks\"</span> : [\n\t{\n\t\t<span class=\"pl-ent\"\
    >\"type\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span\
    \ class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-ent\">\"repetitions\"\
    </span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-ent\">\"num-entries\"\
    </span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-ent\">\"key-sizes\"\
    </span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span> ],\n\
    \t\t<span class=\"pl-ent\">\"val-sizes\"</span> : [ <span class=\"pl-c1\">24</span>,\
    \ <span class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-ent\">\"erase-on-teardown\"\
    </span> : <span class=\"pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-ent\"\
    >\"type\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>get<span\
    \ class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-ent\">\"repetitions\"\
    </span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-ent\">\"num-entries\"\
    </span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-ent\">\"key-sizes\"\
    </span> : <span class=\"pl-c1\">64</span>,\n\t\t<span class=\"pl-ent\">\"val-sizes\"\
    </span> : <span class=\"pl-c1\">128</span>,\n\t\t<span class=\"pl-ent\">\"erase-on-teardown\"\
    </span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n<p>The JSON\
    \ file starts with the protocol to use, and a seed for the random-number generator\
    \ (RNG).\nThe actual seed used on each rank will actually be a function of this\
    \ global seed and the rank of\nthe client. The RNG will be reset with this seed\
    \ after each benchmark.</p>\n<p>The <code>server</code> field sets up the provider\
    \ and the database. Database types can be <code>map</code>, <code>ldb</code>,\
    \ or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which\
    \ is a list of benchmarks to execute. Each benchmark is composed\nof three steps.\
    \ A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em>\
    \ phase. The setup phase may for\nexample store a bunch of keys in the database\
    \ that the execution phase will read by (in the case of a\n<em>get</em> benchmark,\
    \ for example). The teardown phase will usually remove all the keys that were\
    \ written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n\
    <p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>,\
    \ <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n\
    <code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>),\
    \ and a number of repetitions. The benchmark will be\nexecuted as many times as\
    \ requested (without resetting the RNG in between repetitions). Taking the\nexample\
    \ of the <code>put</code> benchmark above, each repetition will put 30 key/value\
    \ pairs into the database.\nThe key size will be chosen randomly in a uniform\
    \ manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size\
    \ will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded).\
    \ Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI\
    \ barrier between clients is executed in between each benchmark and in between\
    \ the setup,\nexecution, and teardown phases, so that the execution phase is always\
    \ executed at the same time\non all the clients. Once all the repetitions are\
    \ done for a given benchmark entry, the program\nwill report statistics on the\
    \ timings: average time, variance, standard deviation, mininum, maximum,\nmedian,\
    \ first and third quartiles. Note that these times are for a repetition, not for\
    \ single operations\nwithin a repetition. To get the timing of each individual\
    \ operation, it is then necessary to divide\nthe times by the number of key/value\
    \ pairs involved in the benchmark.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1635867720.0
mochi-hpc/mochi-thallium:
  data_format: 2
  description: Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and
    providing an object-oriented way to use these libraries.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-thallium
  latest_release: v0.11.3
  readme: '<h1 id="user-content-thallium"><a class="heading-link" href="#thallium">Thallium<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Thallium is a C++ interface to <a href="https://github.com/mochi-hpc/mochi-margo/">Margo</a>.

    It offers a modern, object-oriented way of developing HPC data services. More

    information can be found on <a href="https://mochi.readthedocs.io/en/latest/"
    rel="nofollow">Mochi''s readthedocs</a>

    website.</p>

    '
  stargazers_count: 10
  subscribers_count: 4
  topics: []
  updated_at: 1685720588.0
mochi-hpc/py-mochi-colza:
  data_format: 2
  description: Python binding for Mochi's Colza microservice
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-colza
  latest_release: null
  readme: '<p>Py-Colza is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-colza">Colza
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1633974570.0
mochi-hpc/py-mochi-s4m:
  data_format: 2
  description: Python library using Mochi to broadcast data
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-s4m
  latest_release: null
  readme: '<h1 id="user-content-mochi-s4m-share-for-me"><a class="heading-link" href="#mochi-s4m-share-for-me">Mochi
    S4M (Share for Me)<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This service provides a simple non-blocking broadcast/receive

    mechanism based on Mochi.</p>

    <h2 id="user-content-installing"><a class="heading-link" href="#installing">Installing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Make sure you have <a href="https://spack.io/" rel="nofollow">spack</a> installed
    and setup.

    If needed, install it and set it up as follows:</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>You then need to clone the <code>mochi-spack-packages</code> repository

    and make it available to spack:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Finally, you can install S4M as follows:</p>

    <pre><code>$ spack install py-mochi-s4m

    </code></pre>

    <h2 id="user-content-using"><a class="heading-link" href="#using">Using<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <p>S4M has a very simple API consisting of an <code>S4MService</code> class with

    two functions: <code>broadcast</code>, and <code>receive</code>. It requires mpi4py
    to

    bootstrap the set of processes. The <a href="test/test.py">test.py</a> file

    provides a comprehensive use case.</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1663070268.0
mochi-hpc/py-mochi-sonata:
  data_format: 2
  description: Python binding to the Mochi Sonata microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-sonata
  latest_release: null
  readme: '<p>Py-Sonata is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-sonata">Sonata
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975502.0
mpbelhorn/olcf-spack:
  data_format: 2
  description: Spack fork used on OLCF resources
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  full_name: mpbelhorn/olcf-spack
  latest_release: null
  readme: "<h1 id=\"user-content--spack\"><a class=\"heading-link\" href=\"#-spack\"\
    >\n<img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"> Spack<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions?query=workflow%3A%22macOS+builds+nightly%22\"\
    ><img src=\"https://github.com/spack/spack/workflows/macOS%20builds%20nightly/badge.svg?branch=develop\"\
    \ alt=\"macOS Builds (nightly)\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/4bbdc2b44561be6dfffe64e15730e1c5a2bed9c4efe6f9942638091a4ce3ede2/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2 id=\"user-content-documentation\"\
    ><a class=\"heading-link\" href=\"#documentation\">Documentation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p><a href=\"https://spack.readthedocs.io/\"\
    \ rel=\"nofollow\"><strong>Full documentation</strong></a> is available, or\n\
    run <code>spack help</code> or <code>spack help --all</code>.</p>\n<p>For a cheat\
    \ sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n<h2 id=\"user-content-tutorial\"\
    ><a class=\"heading-link\" href=\"#tutorial\">Tutorial<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>We maintain a\n<a href=\"\
    https://spack.readthedocs.io/en/latest/tutorial.html\" rel=\"nofollow\"><strong>hands-on\
    \ tutorial</strong></a>.\nIt covers basic to advanced usage, packaging, developer\
    \ features, and large HPC\ndeployments.  You can do all of the exercises on your\
    \ own laptop using a\nDocker container.</p>\n<p>Feel free to use these materials\
    \ to teach users at your organization\nabout Spack.</p>\n<h2 id=\"user-content-community\"\
    ><a class=\"heading-link\" href=\"#community\">Community<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>Spack is an open source\
    \ project.  Questions, discussion, and\ncontributions are welcome. Contributions\
    \ can be anything from new\npackages to bugfixes, documentation, or even new core\
    \ features.</p>\n<p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>:\
    \ <a href=\"https://spackpm.slack.com\" rel=\"nofollow\">spackpm.slack.com</a>.\n\
    To get an invitation, visit <a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    >slack.spack.io</a>.</li>\n<li>\n<strong>Mailing list</strong>: <a href=\"https://groups.google.com/d/forum/spack\"\
    \ rel=\"nofollow\">groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>:\
    \ <a href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<h2 id=\"user-content-contributing\"\
    ><a class=\"heading-link\" href=\"#contributing\">Contributing<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Contributing to Spack\
    \ is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2 id=\"user-content-releases\"><a class=\"heading-link\" href=\"#releases\"\
    >Releases<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>For multi-user site deployments or other use cases that need very stable\n\
    software installations, we recommend using Spack's\n<a href=\"https://github.com/spack/spack/releases\"\
    >stable releases</a>.</p>\n<p>Each Spack release series also has a corresponding\
    \ branch, e.g.\n<code>releases/v0.14</code> has <code>0.14.x</code> versions of\
    \ Spack, and <code>releases/v0.13</code> has\n<code>0.13.x</code> versions. We\
    \ backport important bug fixes to these branches but\nwe do not advance the package\
    \ versions or make other changes that would\nchange the way Spack concretizes\
    \ dependencies within a release branch.\nSo, you can base your Spack deployment\
    \ on a release branch and <code>git pull</code>\nto get fixes, without the package\
    \ churn that comes with <code>develop</code>.</p>\n<p>The latest release is always\
    \ available with the <code>releases/latest</code> tag.</p>\n<p>See the <a href=\"\
    https://spack.readthedocs.io/en/latest/developer_guide.html#releases\" rel=\"\
    nofollow\">docs on releases</a>\nfor more details.</p>\n<h2 id=\"user-content-code-of-conduct\"\
    ><a class=\"heading-link\" href=\"#code-of-conduct\">Code of Conduct<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Please note that Spack\
    \ has a\n<a href=\".github/CODE_OF_CONDUCT.md\"><strong>Code of Conduct</strong></a>.\
    \ By participating in\nthe Spack community, you agree to abide by its rules.</p>\n\
    <h2 id=\"user-content-authors\"><a class=\"heading-link\" href=\"#authors\">Authors<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Many\
    \ thanks go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\"\
    >tgamblin@llnl.gov</a>.</p>\n<h3 id=\"user-content-citing-spack\"><a class=\"\
    heading-link\" href=\"#citing-spack\">Citing Spack<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>If you are referencing Spack in a\
    \ publication, please cite the following paper:</p>\n<ul>\n<li>Todd Gamblin, Matthew\
    \ P. LeGendre, Michael R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de\
    \ Supinski, and W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<h2 id=\"user-content-license\"\
    ><a class=\"heading-link\" href=\"#license\">License<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>Spack is distributed under\
    \ the terms of both the MIT license and the\nApache License (Version 2.0). Users\
    \ may choose either license, at their\noption.</p>\n<p>All new contributions must\
    \ be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"\
    https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n<a\
    \ href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1580743748.0
mpbelhorn/olcf-spack-environments:
  data_format: 2
  description: Spack environments for OLCF resources.
  filenames:
  - hosts/peak/envs/base/spack.yaml
  - hosts/ascent/envs/base-rh7/spack.yaml
  - hosts/borg/envs/base/spack.yaml
  - hosts/frontier/envs/base/spack.yaml
  - hosts/ascent/envs/base/spack.yaml
  - hosts/summit/envs/base/spack.yaml
  full_name: mpbelhorn/olcf-spack-environments
  latest_release: null
  readme: '<h1 id="user-content-olcf-spack-environments"><a class="heading-link" href="#olcf-spack-environments">OLCF
    Spack Environments<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This repo contains the infrastructure and environment definitions to deploy

    site-provided software on OLCF resources via Spack environments.</p>

    <h2 id="user-content-getting-started"><a class="heading-link" href="#getting-started">Getting
    Started<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Clone this repo and it''s facility-modified spack fork somewhere on an OLCF

    filesystem:</p>

    <pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git

    </code></pre>

    <p>or</p>

    <pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments

    </code></pre>

    <p>Next, initialize spack and the build environment. This is done by calling</p>

    <pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base
    . ./init-facility-spack.sh

    </code></pre>

    <p>This will configure the spack build- and run-time environment build and install

    the facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this
    repo for the

    current machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both
    of these

    variables are optional. If omitted, each variable will take on their default

    values:</p>

    <pre><code>FACSPACK_MY_ENVS="/sw/${_THIS_HOST}/spack-envs"

    FACSPACK_ENV_NAME="base"

    </code></pre>

    <p>such that sourcing this script by itself</p>

    <pre><code>. ./init-facility-spack.sh

    </code></pre>

    <p>will setup the runtime shell environment to manipulate the production spack

    environment on the current system.</p>

    <p>This repo will always track at least one spack environment per machine named

    <code>base</code> which is the complete standard software environment used in
    production

    for that machine. Furthermore, only the user account with owner permissions on

    the production environment may be used to manipulate it in the default

    <code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent
    multiple

    users from concurrently modifying the production environment. Users may set an

    alternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using
    any

    tracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file
    in this repo.</p>

    <p>From these variables, a unique path per each environment name will be

    constructed:</p>

    <pre><code>FACSPACK_ENV="${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}"

    </code></pre>

    <p>The value of <code>${_THIS_HOST}</code> is determined automatically from the
    hostname on

    which the init script is being run. For each system and environment tracked in

    this repo that you wish to work on, ensure that the final expanded value of

    <code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>

    <p>Configuration paths in our <code>spack.yaml</code> environments that are not
    fixed to

    universal values are expressed in terms of relative paths to either the spack

    instance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.

    These paths are referenced in the <code>spack.yaml</code> files via environment
    variables

    set by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code>
    environment files to

    define portable and relocatable spack environments which can be re-deployed in

    arbitrary private locations by any users without needing to modify the

    environment file.</p>

    <p>The following variables are exported in Spack''s runtime environment by

    <code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code>
    the enviornment

    files tracked in this repo.</p>

    <ul>

    <li>

    <code>${FACSPACK_ENV}</code>:

    Path to where spack environment will be installed. Contains subdirs <code>opt</code>

    and <code>modules</code>.</li>

    <li>

    <code>${FACSPACK_ENV_MODULEROOT}</code>:

    Shortcut to <code>${FACSPACK_ENV}/modules</code> under which static and

    spack-generated modules are generated. Contains subdirectories <code>spack</code>,

    <code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static
    modulefiles

    respectively.</li>

    <li>

    <code>${FACSPACK_CONF_COMMON}</code>:

    Path to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>

    <li>

    <code>${FACSPACK_CONF_HOST}</code>:

    Path to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>

    </li>

    </ul>

    <p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>

    files which cannot de-reference environment variables. These affect</p>

    <ul>

    <li>Mirrors</li>

    <li>Extensions</li>

    </ul>

    <p>Spack does not internally expand environment variables in the configuration
    of

    these items so they must be expressed as hard-coded full path strings. The

    default values in this repo should point to permanent world-readable paths on

    the OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>

    <h2 id="user-content-spack-fork"><a class="heading-link" href="#spack-fork">Spack
    Fork<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The upstream development branch of spack is not used directly. Instead, the
    OLCF

    has implemented some customizations that are tracked in the "olcf-X.Y.Z"

    branches of a <a href="https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0">facility
    fork of spack</a>

    where <code>X.Y.Z</code> refers to the tagged release of upstream spack from which
    the

    OLCF-modified branch is forked.</p>

    '
  stargazers_count: 4
  subscribers_count: 2
  topics: []
  updated_at: 1662572646.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - linux-rhel8-ppc64le/summit/spack.yaml
  - linux-sles15-zen2/spock/spack.yaml
  - linux-centos7-broadwell/or-slurm/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_env/index.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2 id="user-content-purpose"><a class="heading-link" href="#purpose">Purpose<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 4
  subscribers_count: 20
  topics: []
  updated_at: 1670008521.0
onkarbpatil/IPDPS2020-benchmarks:
  data_format: 2
  description: null
  filenames:
  - SICM/spack.yaml
  full_name: onkarbpatil/IPDPS2020-benchmarks
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1591368300.0
openPMD/openPMD-api:
  data_format: 2
  description: ':floppy_disk: C++ & Python API for Scientific I/O'
  filenames:
  - spack.yaml
  full_name: openPMD/openPMD-api
  latest_release: 0.15.2
  readme: "<h1 id=\"user-content-c--python-api-for-scientific-io-with-openpmd\"><a\
    \ class=\"heading-link\" href=\"#c--python-api-for-scientific-io-with-openpmd\"\
    >C++ &amp; Python API for Scientific I/O with openPMD<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h1>\n<p><a href=\"https://github.com/openPMD/openPMD-standard/releases\"\
    ><img src=\"https://camo.githubusercontent.com/5957dc11cb68f6705ef9ef6683152c6c4fcc057a24dff340e1e8bada1bee0d01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\"\
    \ alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d54fa5adcf7ca50d2cdb45823be5064379b613d526fa06f6e193ba2ce616318/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/f551141eea2176c34aa163092549d6fdde9a220d605d6efe9128b024c6e5932b/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\"\
    \ alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"\
    https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"\
    max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4fc8091716dbd967fa2a82eef3d29227110e5081f3128aaa38663e547c24f812/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/104f6901ae04bff8385acc8273bb276ab84656a927a418108b940d09fd6e5d7c/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0d568047fbbd300af56b766d9a4235a20534485f5827194e859d4f5c20e58334/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\"\
    \ alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f0487a8fc14d269210ae8ce80b556d4afcd93684f02e61386d2d02daa4423cbd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f438ca4eaa308f982d0a28c48f05bf63ca1a86e52c3d2817f6d7559d1dee68e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8278d89e3634e25a818a2d673fe997c2aa5a09fd5995f716aeffa743388030ee/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\"\
    \ alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/30679331f3c6a5ae54970eda85f36a30347dee8a9111448d7aa48587fd524a1d/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\"\
    \ alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\
    ><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\"\
    \ alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fc9c860bb1fc8e7e145ea9dd6723b9ac6ac2743c195e5e899f6cfa3d38a5a69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\"\
    \ alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0b068d7b5718aafccb46e2ee35f8249938ef189a36ba353c15222ed5e6f65e49/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\"\
    \ alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD is an open meta-data schema\
    \ that provides meaning and self-description for data sets in science and engineering.\n\
    See <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a>\
    \ for details of this schema.</p>\n<p>This library provides a reference API for\
    \ openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable,\
    \ hierarchical file formats, this library implements various backends such as\
    \ HDF5, ADIOS2 and JSON.\nWriting &amp; reading through those backends and their\
    \ associated files are supported for serial and <a href=\"https://www.mpi-forum.org/docs/\"\
    \ rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<h2 id=\"user-content-usage\"\
    ><a class=\"heading-link\" href=\"#usage\">Usage<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<h3 id=\"user-content-c\"><a class=\"\
    heading-link\" href=\"#c\">C++<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<p><a href=\"https://isocpp.org/\" rel=\"nofollow\"><img src=\"\
    https://camo.githubusercontent.com/8d47ea5fd5ff323ff5c76593ea37f2340533c73de5e6e37a2b27d7dc28070cd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\"\
    \ alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span>\
    \ s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span\
    \ class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"\
    pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>\
    \ &amp; [step, it] : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span>\
    \ &lt;&lt; step &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span\
    \ class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\"\
    >const</span> &amp; [name, mesh] : it.<span class=\"pl-smi\">meshes</span> ) {\n\
    \        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\
    \  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; name &lt;&lt; <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\"\
    >\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\"\
    >for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp;\
    \ val : mesh.<span class=\"pl-c1\">attributes</span>() )\n            std::cout\
    \ &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"\
    pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\
    \    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span>\
    \ <span class=\"pl-k\">const</span> &amp; [name, species] : it.<span class=\"\
    pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"\
    </span></span> &lt;&lt; name &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\"\
    >auto</span> <span class=\"pl-k\">const</span>&amp; val : species.<span class=\"\
    pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt;\
    \ val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n\
    <h3 id=\"user-content-python\"><a class=\"heading-link\" href=\"#python\">Python<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p><a\
    \ href=\"https://www.python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\"\
    \ alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span>\
    \ <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"\
    pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span\
    \ class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\"\
    >io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\
    \n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"\
    pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span\
    \ class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n  \
    \  <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\
    \n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span\
    \ class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n\
    \        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}'\
    \ attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\"\
    >k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"\
    pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span\
    \ class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span\
    \ class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"\
    pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"\
    pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n  \
    \          <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n\
    <h3 id=\"user-content-more\"><a class=\"heading-link\" href=\"#more\">More!<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Curious?\n\
    Our manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\"\
    \ rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n\
    <h2 id=\"user-content-dependencies\"><a class=\"heading-link\" href=\"#dependencies\"\
    >Dependencies<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>Required:</p>\n<ul>\n<li>CMake 3.15.0+</li>\n<li>C++17 capable compiler, e.g.,\
    \ g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx</li>\n</ul>\n<p>Shipped internally\
    \ in <code>share/openPMD/thirdParty/</code>:</p>\n<ul>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> 2.13.10+ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\"\
    >BSL-1.0</a>)</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a>\
    \ 2.11.1+ (<a href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\"\
    >new BSD</a>)</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a>\
    \ 3.9.1+ (<a href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\"\
    >MIT</a>)</li>\n<li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a>\
    \ 3.7.1+ (<a href=\"https://github.com/ToruNiina/toml11/blob/master/LICENSE\"\
    >MIT</a>)</li>\n</ul>\n<p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\"\
    \ rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\"\
    \ rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either\
    \ with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n\
    </ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python\
    \ 3.8 - 3.11</li>\n<li>pybind11 2.11.1+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py\
    \ 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n\
    <li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n<li>CUDA C++\
    \ (optional, currently used only in tests)</li>\n</ul>\n<h2 id=\"user-content-installation\"\
    ><a class=\"heading-link\" href=\"#installation\">Installation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/580cdb6331254f66680bd967326d9630f5124291efd5ace18549fbb93cbae6db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3c3728308a9e416589fa8b3b8168967287c515037bfbd4b40f1b14f266de56fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/92b7b7bb69b2b17d1981ae5fdcdb32f971ee57f54a98ea4804e93fd0a2eb58ef/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4eeb2c48c0e554ea8dbe8e90f73a6f2d217e775e0bd5e5cb90ddf4619ef3a6a0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/2babf79954ea524c24f2f9b1cfa05728fdaccbe0a80c2da6a7a7595cc131894c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\"\
    \ alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our community loves to help each other.\n\
    Please <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\"\
    >report installation problems</a> in case you should get stuck.</p>\n<p>Choose\
    \ <em>one</em> of the install methods below to get started:</p>\n<h3 id=\"user-content-spack\"\
    ><a class=\"heading-link\" href=\"#spack\"></a><a href=\"https://spack.io\" rel=\"\
    nofollow\">Spack</a><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></h3>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/becffbecb6a50502286f02ec86c4e62f239f3671148d11341152e0dc695a2fc9/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\"\
    \ alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b29fc54abf92a2a6d1d2c70159eb276df53b67a1294ae3f82b1b0bf22a3c586b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\"\
    \ alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \    +python -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack load\
    \ openpmd-api</pre></div>\n<h3 id=\"user-content-conda\"><a class=\"heading-link\"\
    \ href=\"#conda\"></a><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></h3>\n<p><a href=\"\
    https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3ad2b345bb3589aa2d733ca20df72938ed54a48342b69f7cbe9eacab43d84549/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a51d3cd2bfa3c6b01bd0f2e36abc206fb9db5700105fac2acd2c2105fced2ec4/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \           OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\n\
    conda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n\
    <h3 id=\"user-content-brew\"><a class=\"heading-link\" href=\"#brew\"></a><a href=\"\
    https://brew.sh\" rel=\"nofollow\">Brew</a><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></h3>\n<p><a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/d873c8c473fece8abf1c34a8299a50b7ee0da9772eb50cce8649e7ca32468a6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\"\
    \ alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/7b767b67facc26db7d850ae5c3155fa949048991dde7a0f5471c1e6862f0a586/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\"\
    \ alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<h3 id=\"\
    user-content-pypi\"><a class=\"heading-link\" href=\"#pypi\"></a><a href=\"https://pypi.org\"\
    \ rel=\"nofollow\">PyPI</a><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></h3>\n<p><a href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/fc28bd368523d0b8adab5f4b414aebb304743130eef42bca203f4e9eed428ae7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\"\
    \ alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7cef25e887c028f65d5d7e20f3e7abe394ab328ecb499e34e47460afd2c78558/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\"\
    \ alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82acdd95515851a5ba4a3006871151f76cfe4d6583f6c24e80bd0fd29d391845/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\"\
    \ alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9)\
    \ or on exotic processor architectures, this install method <em>compiles from\
    \ source</em> against the found installations of HDF5, ADIOS2, and/or MPI (in\
    \ system paths, from other package managers, or loaded via a module system, ...).</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> optional:                   --user</span>\npython3\
    \ -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n\
    <p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional:                                    --user</span>\npython3\
    \ -m pip install -U pip packaging setuptools wheel\npython3 -m pip install -U\
    \ cmake\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:      \
    \                                                             --user</span>\n\
    openPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n\
    <p>For some exotic architectures and compilers, you might need to disable a compiler\
    \ feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\"\
    \ rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter\
    \ linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                               \
    \                 --user</span>\npython3 -m pip install openpmd-api --no-binary\
    \ openpmd-api</pre></div>\n<p>Additional CMake options can be passed via individual\
    \ environment variables, which need to be prefixed with <code>openPMD_CMAKE_</code>.</p>\n\
    <h3 id=\"user-content-from-source\"><a class=\"heading-link\" href=\"#from-source\"\
    >From Source<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p><a href=\"https://cmake.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0a40953107090abff3b564ec3436668756b873cd4d9e021738a046781a5a0e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\"\
    \ alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD-api can also be built and installed\
    \ from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\
    \nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests,\
    \ with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which\
    \ python3)</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\"\
    >.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\n\
    ctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required\
    \ for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target\
    \ install</pre></div>\n<p>The following options can be added to the <code>cmake</code>\
    \ call to control features.\nCMake controls options with prefixed <code>-D</code>,\
    \ e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n\
    <td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n\
    <td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code\
    \ <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro\
    \ independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_INSTALL_RPATH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Add RPATHs to installed binaries</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n\
    <td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n\
    </table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n\
    <sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without\
    \ specific cause is highly discouraged</em></p>\n<p>Additionally, the following\
    \ libraries are shipped internally.\nThe following options allow to switch to\
    \ external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n\
    <th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.10+</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>pybind11</td>\n<td>2.11.1+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_TOML11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>toml11</td>\n<td>3.7.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this\
    \ will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and\
    \ installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code>\
    \ to the <code>cmake</code> command.\nYou can only build a static or a shared\
    \ library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\n\
    In order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code>\
    \ to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and\
    \ command line tools are built.\nIn order to skip building those, pass <code>OFF</code>\
    \ to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_CUDA_EXAMPLES</code></td>\n<td>ON/<strong>OFF</strong>\n\
    </td>\n<td>Use CUDA in examples</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"user-content-linking-to-your-project\"\
    ><a class=\"heading-link\" href=\"#linking-to-your-project\">Linking to your project<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>The\
    \ install will contain header files and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n\
    <h3 id=\"user-content-cmake\"><a class=\"heading-link\" href=\"#cmake\">CMake<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>If\
    \ your project is using CMake for its build, one can conveniently use our provided\
    \ <code>openPMDConfig.cmake</code> package, which is installed alongside the library.</p>\n\
    <p>First set the following environment hint if openPMD-api was <em>not</em> installed\
    \ in a system path:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed if installed\
    \ outside of system paths</span>\n<span class=\"pl-k\">export</span> CMAKE_PREFIX_PATH=<span\
    \ class=\"pl-smi\">$HOME</span>/somepath:<span class=\"pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n\
    <p>Use the following lines in your project's <code>CMakeLists.txt</code>:</p>\n\
    <div class=\"highlight highlight-source-cmake\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> supports:                       COMPONENTS MPI NOMPI\
    \ HDF5 ADIOS2</span>\n<span class=\"pl-c1\">find_package</span>(openPMD 0.15.0\
    \ <span class=\"pl-k\">CONFIG</span>)\n\n<span class=\"pl-k\">if</span>(openPMD_FOUND)\n\
    \    <span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span class=\"\
    pl-k\">PRIVATE</span> openPMD::openPMD)\n<span class=\"pl-k\">endif</span>()</pre></div>\n\
    <p><em>Alternatively</em>, add the openPMD-api repository source directly to your\
    \ project and use it via:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">add_subdirectory</span>(<span class=\"pl-s\">\"path/to/source/of/openPMD-api\"\
    </span>)\n\n<span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span\
    \ class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n<p>For development\
    \ workflows, you can even automatically download and build openPMD-api from within\
    \ a depending CMake project.\nJust replace the <code>add_subdirectory</code> call\
    \ with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"\
    pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077\
    \ <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_SHARED_LIBS\
    \ <span class=\"pl-k\">OFF</span>)  <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> precedence over BUILD_SHARED_LIBS if needed</span>\n<span class=\"pl-c1\"\
    >set</span>(openPMD_INSTALL <span class=\"pl-k\">OFF</span>)            <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> or instead use:</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> set(openPMD_INSTALL ${BUILD_SHARED_LIBS})\
    \  # only install if used as a shared library</span>\n<span class=\"pl-c1\">set</span>(openPMD_USE_PYTHON\
    \ <span class=\"pl-k\">OFF</span>)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY\
    \ <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"</span>\n\
    \  GIT_TAG        <span class=\"pl-s\">\"0.15.0\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n\
    <h3 id=\"user-content-manually\"><a class=\"heading-link\" href=\"#manually\"\
    >Manually<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>If your (Linux/OSX) project is build by calling the compiler directly or uses\
    \ a manually written <code>Makefile</code>, consider using our <code>openPMD.pc</code>\
    \ helper file for <code>pkg-config</code>, which are installed alongside the library.</p>\n\
    <p>First set the following environment hint if openPMD-api was <em>not</em> installed\
    \ in a system path:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed if installed\
    \ outside of system paths</span>\n<span class=\"pl-k\">export</span> PKG_CONFIG_PATH=<span\
    \ class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span class=\"pl-smi\"\
    >$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and compiler flags\
    \ for your project are available via:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> switch to check if openPMD-api\
    \ was build as static library</span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> (via BUILD_SHARED_LIBS=OFF) or as shared library (default)</span>\n\
    <span class=\"pl-k\">if</span> [ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config --variable=static\
    \ openPMD<span class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\
    \ <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>true<span class=\"pl-pds\">\"</span></span> ]\n<span class=\"pl-k\">then</span>\n\
    \    pkg-config --libs --static openPMD\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so\
    \ /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config\
    \ --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib\
    \ -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n\
    <h2 id=\"user-content-author-contributions\"><a class=\"heading-link\" href=\"\
    #author-contributions\">Author Contributions<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>openPMD-api is developed by many people.\n\
    It was initially started by the <a href=\"https://hzdr.de/crp\" rel=\"nofollow\"\
    >Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\
    >libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\"\
    \ rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"\
    https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe\
    \ following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\
    >contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\"\
    >Axel Huebl (HZDR, now LBNL)</a>:\nproject lead, releases, documentation, automated\
    \ CI/CD, Python bindings, Dask, installation &amp; packaging, prior reference\
    \ implementations</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\">Franz\
    \ Poeschel (CASUS)</a>:\nJSON &amp; ADIOS2 backend, data staging/streaming, reworked\
    \ class design</li>\n<li>\n<a href=\"https://github.com/C0nsultant\">Fabian Koller\
    \ (HZDR)</a>:\ninitial library design and implementation with HDF5 &amp; ADIOS1\
    \ backend</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu (LBNL)</a>:\n\
    non-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n</ul>\n\
    <p>Further thanks go to improvements and contributions from:</p>\n<ul>\n<li>\n\
    <a href=\"https://github.com/CFGrote\">Carsten Fortmann-Grote (EU XFEL GmbH, now\
    \ MPI-EvolBio)</a>:\ndraft of our Python unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\"\
    >Dominik Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n\
    <li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\n\
    support on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\"\
    >James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"\
    https://github.com/psychocoderHPC\">Ren\xE9 Widera (HZDR)</a>:\ndesign improvements\
    \ for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\"\
    >Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n\
    <a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation\
    \ improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\xE9\
    mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n\
    <a href=\"https://github.com/LDAmorim\">L\xEDgia Diana Amorim (LBNL)</a>:\npackage\
    \ integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\"\
    >Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"\
    https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing,\
    \ documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\"\
    >Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"\
    https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask prototyping\
    \ &amp; ADIOS2 benchmarking</li>\n<li>\n<a href=\"https://github.com/jakirkham\"\
    >John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n<li>\n<a href=\"\
    https://github.com/eschnett\">Erik Schnetter (PITP)</a>:\nC++ API bug fixes</li>\n\
    <li>\n<a href=\"https://github.com/jeanbez\">Jean Luca Bez (LBNL)</a>:\nHDF5 performance\
    \ tuning</li>\n<li>\n<a href=\"https://github.com/bernhardmgruber\">Bernhard Manfred\
    \ Gruber (CERN)</a>:\nCMake fix for parallel HDF5</li>\n<li>\n<a href=\"https://github.com/DerNils-git\"\
    >Nils Schild (IPP)</a>:\nCMake improvements for subprojects</li>\n</ul>\n<h3 id=\"\
    user-content-grants\"><a class=\"heading-link\" href=\"#grants\">Grants<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>The openPMD-api authors\
    \ acknowledge support via the following programs.\nSupported by the CAMPA collaboration,\
    \ a project of the U.S. Department of Energy, Office of Science, Office of Advanced\
    \ Scientific Computing Research and Office of High Energy Physics, Scientific\
    \ Discovery through Advanced Computing (SciDAC) program.\nPreviously supported\
    \ by the Consortium for Advanced Modeling of Particles Accelerators (CAMPA), funded\
    \ by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\nSupported\
    \ by the Exascale Computing Project (17-SC-20-SC), a collaborative effort of two\
    \ U.S. Department of Energy organizations (Office of Science and the National\
    \ Nuclear Security Administration).\nThis project has received funding from the\
    \ European Unions Horizon 2020 research and innovation programme under grant agreement\
    \ No 654220.\nThis work was partially funded by the Center of Advanced Systems\
    \ Understanding (CASUS), which is financed by Germany's Federal Ministry of Education\
    \ and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism\
    \ (SMWK) with tax funds on the basis of the budget approved by the Saxon State\
    \ Parliament.</p>\n<h3 id=\"user-content-transitive-contributions\"><a class=\"\
    heading-link\" href=\"#transitive-contributions\">Transitive Contributions<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>openPMD-api\
    \ stands on the shoulders of giants and we are grateful for the following projects\
    \ included as direct dependencies:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> by <a href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky,\
    \ N. Podhorszki, W.F. Godoy (ORNL), team, collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"\
    https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\xFD</a> and <a href=\"\
    https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n\
    <li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a>\
    \ and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a>\
    \ by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"\
    https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> by <a href=\"\
    https://github.com/ToruNiina\">Toru Niina</a> and <a href=\"https://github.com/ToruNiina/toml11#Contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\"\
    >pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a>\
    \ and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n\
    </li>\n<li>all contributors to the evolution of modern C++ and early library preview\
    \ developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n\
    </li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a>\
    \ and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n\
    </li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"\
    nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\
    \ and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among\
    \ others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\"\
    >openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR,\
    \ now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\
    >contributors</a>\n</li>\n</ul>\n"
  stargazers_count: 118
  subscribers_count: 10
  topics:
  - openpmd
  - openscience
  - hdf5
  - adios
  - mpi
  - hpc
  - research
  - file-handling
  - python3
  - opendata
  - cpp14
  - metadata
  updated_at: 1697232683.0
player1537-playground/triple-r:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537-playground/triple-r
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1614701026.0
pnnl/ExaGO:
  data_format: 2
  description: High-performance power grid optimization for stochastic, security-constrained,
    and multi-period ACOPF problems.
  filenames:
  - buildsystem/spack/incline/spack.yaml
  - buildsystem/container/spack.yaml
  - buildsystem/spack/deception/spack.yaml
  full_name: pnnl/ExaGO
  latest_release: null
  readme: "<h1 id=\"user-content-exascale-grid-optimization-toolkit-exagotm-----\"\
    ><a class=\"heading-link\" href=\"#exascale-grid-optimization-toolkit-exagotm-----\"\
    >\n<b>Exa</b>scale <b>G</b>rid <b>O</b>ptimization toolkit (ExaGO<sup>TM</sup>)\
    \ </a><a href=\"https://github.com/pre-commit/pre-commit\"><img src=\"https://camo.githubusercontent.com/a58d28773559eecad3ca137f4f248ad5604c530a4db52aa3780d3e65b5a4e6f3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7072652d2d636f6d6d69742d656e61626c65642d627269676874677265656e3f6c6f676f3d7072652d636f6d6d6974\"\
    \ alt=\"pre-commit\" data-canonical-src=\"https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    \ alt=\"PNNL GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    \ alt=\"ORNL Ascent GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    \ alt=\"pre-commit GitHub Action\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    \ alt=\"Spack CPU Build\" style=\"max-width: 100%;\"></a>\n<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></h1>\n\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer\" href=\"viz/images/network_gen_load_us.png\"><img\
    \ src=\"viz/images/network_gen_load_us.png\" style=\"max-width: 100%;\"></a></p>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/manual/figures/three_in_one.png\"\
    ><img src=\"docs/manual/figures/three_in_one.png\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>ExaGO<sup>TM</sup> is a package for solving large-scale  power grid\
    \ optimization problems on parallel and distributed architectures, particularly\
    \ targeted for exascale machines with heteregenous architectures (GPU). Combinations\
    \ of stochastic, contingency-constrained, multiperiod ACOPF problems can be solved\
    \ with ExaGO. The package is written in C/C++ with python bindings available for\
    \ python-based applications. An overview of the package is given on this page.\
    \ For extended information, including the modeling details and formulations, see\
    \ the <a href=\"docs/manual/manual.pdf\">ExaGO manual</a>.</p>\n<p>ExaGO<sup>TM</sup>\
    \ includes the following applications for solving different power grid optimization\
    \ problems:</p>\n<ul>\n<li>\n<a href=\"docs/web/opflow.md\">OPFLOW</a> solves\
    \ an AC optimal power flow either on CPU and GPU</li>\n<li>\n<a href=\"docs/web/tcopflow.md\"\
    >TCOPFLOW</a> solves a multi-period optimal power flow</li>\n<li>\n<a href=\"\
    docs/web/scopflow.md\">SCOPFLOW</a> solves a security-constrained (contingency-constrained)\
    \ optimal power. Both single-period and multi-period problems can be solved.</li>\n\
    <li>\n<a href=\"docs/web/sopflow.md\">SOPFLOW</a> solves a stochastic optimal\
    \ power flow with (optional) security constraints for single and multiple periods.</li>\n\
    </ul>\n<p>ExaGO<sup>TM</sup> applications are interfaced with the following optimization\
    \ solver packaages:</p>\n<ul>\n<li>\n<a href=\"https://github.com/coin-or/Ipopt\"\
    >Ipopt</a> is a popular optimization package for solving nonlinear optimization\
    \ problems that uses an interior-point algorithm.</li>\n<li>\n<a href=\"https://github.com/LLNL/hiop\"\
    >HiOp</a> is a HPC package for optimization. ExaGO interfaces with two of its\
    \ solvers -- a mixed sparse-dense interior-point solver (NewtonMDS) and a sparse\
    \ interior-point solver (HiOPSparse). NewtonMDS  allows execution of the optimization\
    \ either on CPU and GPU. The sparse HiOp solver is currently supported on CPU\
    \ only.</li>\n</ul>\n<p>Note that not all applications can utilize all solvers\
    \ yet. The following table lists the solver-application compatibility.</p>\n<table>\n\
    <thead>\n<tr>\n<th align=\"center\">Solver</th>\n<th align=\"center\">OPFLOW</th>\n\
    <th align=\"center\">TCOPFLOW</th>\n<th align=\"center\">SCOPLOW</th>\n<th align=\"\
    center\">SOPFLOW</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Ipopt</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\">Y</td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td align=\"center\">HiOp</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\"></td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<p>Additionally,\
    \ note that SCOPFLOW and SOPFLOW with HiOp solver use Ipopt to solve a portion\
    \ of the problem (base problem). So one must also configure with Ipopt when using\
    \ HiOp solver for these applications.</p>\n<h2 id=\"user-content-installing\"\
    ><a class=\"heading-link\" href=\"#installing\">Installing<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Details installation\
    \ instructions are given at <a href=\"./INSTALL.md\">INSTALL.md</a> for information\
    \ on acquiring, building and installing ExaGO.</p>\n<h2 id=\"user-content-usage\"\
    ><a class=\"heading-link\" href=\"#usage\">Usage<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>Instructions for executing the different\
    \ ExaGO<sup>TM</sup> applications is given below.</p>\n<ul>\n<li><a href=\"docs/web/opflow.md\"\
    >OPFLOW</a></li>\n<li><a href=\"docs/web/tcopflow.md\">TCOPFLOW</a></li>\n<li><a\
    \ href=\"docs/web/sopflow.md\">SOPFLOW</a></li>\n<li><a href=\"docs/web/scopflow.md\"\
    >SCOPFLOW</a></li>\n<li><a href=\"docs/web/pflow.md\">PFLOW</a></li>\n</ul>\n\
    <h3 id=\"user-content-options\"><a class=\"heading-link\" href=\"#options\">Options<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>Each\
    \ application has a different set of options that are described in depth in the\
    \ usage notes. These options can be passed optionally through an options file\
    \ (<code>-optionsfile &lt;option_file&gt;</code>), or directly on the command\
    \ line.</p>\n<p>Since options may be specified in more than one location (on the\
    \ command line, and through an options file), it is worth noting that the option\
    \ specified on the command line supersede those in the options file. For example,\
    \ if <code>opflowoptions</code> options file set the network file via the option\
    \ <code>-netfile case9mod.m</code>, the following behavior occurs:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> This uses case9mod.m</span>\n./opflow -optionsfile opflowoptions\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This uses case118.m</span>\n\
    ./opflow -netfile case118.m -options_file opflowoptions</pre></div>\n<h2 id=\"\
    user-content-visualization-experimental\"><a class=\"heading-link\" href=\"#visualization-experimental\"\
    >Visualization (experimental)<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>ExaGO has an experimental visualization to display the results\
    \ of <code>OPFLOW</code> application on a map. See the <a href=\"viz/README.md\"\
    >visualization README</a> for more information.</p>\n<h2 id=\"user-content-contributing\"\
    ><a class=\"heading-link\" href=\"#contributing\">Contributing<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Please see <a href=\"\
    docs/developer_guidelines.md\">the developer guidelines</a> before attempting\
    \ to contribute.\nFeel free to raise an issue or contact the team if the guidelines\
    \ are ambiguous or you have a particular question.</p>\n<h2 id=\"user-content-authors\"\
    ><a class=\"heading-link\" href=\"#authors\">Authors<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<ul>\n<li>Shrirang Abhyankar</li>\n\
    <li>Slaven Peles</li>\n<li>Asher Mancinelli</li>\n<li>Cameron Rutherford</li>\n\
    <li>Bruce Palmer</li>\n<li>Jaelyn Litzinger</li>\n<li>William Perkins</li>\n<li>Sayef\
    \ Azad Sakin</li>\n<li>Joseph Macam</li>\n<li>Ryan Danehy</li>\n<li>Nicholson\
    \ Koukpaizan</li>\n</ul>\n<h2 id=\"user-content-acknowledgement\"><a class=\"\
    heading-link\" href=\"#acknowledgement\">Acknowledgement<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>This package is developed\
    \ as a part of <a href=\"https://www.exascaleproject.org/research-project/exasgd/\"\
    \ rel=\"nofollow\">ExaSGD</a> project under the <a href=\"https://www.exascaleproject.org/\"\
    \ rel=\"nofollow\">Exascale computing project</a>.</p>\n<h2 id=\"user-content-copyright\"\
    ><a class=\"heading-link\" href=\"#copyright\">Copyright<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>Copyright \xA9 2020, Battelle\
    \ Memorial Institute.</p>\n<p>ExaGO<sup>TM</sup> is a free software distributed\
    \ under a BSD 2-clause license. You may reuse, modify, and redistribute the software.\
    \ See the <a href=\"LICENSE\">license</a> file for details.</p>\n<h2 id=\"user-content-disclaimer\"\
    ><a class=\"heading-link\" href=\"#disclaimer\">Disclaimer<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>This material was prepared\
    \ as an account of work sponsored by an agency of the United States Government.\
    \  Neither the United States Government nor the United States Department of Energy,\
    \ nor Battelle, nor any of their employees, nor any jurisdiction or organization\
    \ that has cooperated in the development of these materials, makes any warranty,\
    \ express or implied, or assumes any legal liability or responsibility for the\
    \ accuracy, completeness, or usefulness or any information, apparatus, product,\
    \ software, or process disclosed, or represents that its use would not infringe\
    \ privately owned rights.\nReference herein to any specific commercial product,\
    \ process, or service by trade name, trademark, manufacturer, or otherwise does\
    \ not necessarily constitute or imply its endorsement, recommendation, or favoring\
    \ by the United States Government or any agency thereof, or Battelle Memorial\
    \ Institute. The views and opinions of authors expressed herein do not necessarily\
    \ state or reflect those of the United States Government or any agency thereof.</p>\n"
  stargazers_count: 12
  subscribers_count: 10
  topics: []
  updated_at: 1697215725.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<h1 id=\"user-content-libpressio\"><a class=\"heading-link\" href=\"#libpressio\"\
    >LibPressio<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n\
    <p><em>the stable version of this code is found at <a href=\"https://github.com/CODARcode/libpressio\"\
    >at the CODARCode organization</a> it is updated about anually</em></p>\n<p>Pressio\
    \ is latin for compression.  LibPressio is a C++ library with C compatible bindings\
    \ to abstract between different lossless and lossy compressors and their configurations.\
    \  It solves the problem of having to having to write separate application level\
    \ code for each lossy compressor that is developed.  Instead, users write application\
    \ level code using LibPressio, and the library will make the correct underlying\
    \ calls to the compressors.  It provides interfaces to represent data, compressors\
    \ settings, and compressors.</p>\n<p>Documentation for the <code>master</code>\
    \ branch can be <a href=\"https://robertu94.github.io/libpressio/\" rel=\"nofollow\"\
    >found here</a></p>\n<h1 id=\"user-content-using-libpressio\"><a class=\"heading-link\"\
    \ href=\"#using-libpressio\">Using LibPressio<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h1>\n<p>Example using the CLI from <a href=\"\
    https://github.com/robertu94/pressio-tools\"><code>pressio-tools</code></a>\n\
    We also have C, C++, Rust, Julia, and Python bindings.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pressio -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<h2 id=\"user-content-getting-started\"><a class=\"\
    heading-link\" href=\"#getting-started\">Getting Started<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>After skimming the example,\
    \ LibPressio has 6 major headers that you will need to use:</p>\n<table>\n<thead>\n\
    <tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>pressio.h</code></td>\n\
    <td>Error reporting and aquiring handles to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<h2 id=\"user-content-supported-compressors-and-metrics\"><a\
    \ class=\"heading-link\" href=\"#supported-compressors-and-metrics\">Supported\
    \ Compressors and Metrics<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>Libpressio provides a number of builtin compressor and metrics\
    \ modules.\nAll of these are <strong>disabled by default</strong>.\nThey can be\
    \ enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code> variable\
    \ to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information on\
    \ writing a compressor plugin see [Writing a Compressor Plugin](@ref writingacompressor)\n\
    For information on writing a metrics plugin see [Writing a Metrics Plugin](@ref\
    \ writingametric)</p>\n<h3 id=\"user-content-compressor-plugins\"><a class=\"\
    heading-link\" href=\"#compressor-plugins\">Compressor Plugins<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>1st party compressors\
    \ plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the [compressor settings page](@ref compressors)\
    \ for information on how to configure them.</p>\n<h3 id=\"user-content-metrics-plugins\"\
    ><a class=\"heading-link\" href=\"#metrics-plugins\">Metrics Plugins<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>1st party compressors\
    \ plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the [metrics results page](@ref metrics)\
    \ for information on what they produce</p>\n<h3 id=\"user-content-io-plugins\"\
    ><a class=\"heading-link\" href=\"#io-plugins\">IO Plugins<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>1st party compressors\
    \ plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the [io settings page](@ref io) for information\
    \ on how to configure them</p>\n<h1 id=\"user-content-installation\"><a class=\"\
    heading-link\" href=\"#installation\">Installation<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h1>\n<h2 id=\"user-content-installing-libpressio-using-spack\"\
    ><a class=\"heading-link\" href=\"#installing-libpressio-using-spack\">Installing\
    \ LibPressio using Spack<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\"\
    >spack</a>.  This example will install libpressio with only the SZ3 plugin.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<h2 id=\"user-content-doing-a-development-build-with-spack\"\
    ><a class=\"heading-link\" href=\"#doing-a-development-build-with-spack\">Doing\
    \ a development build with spack<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>The easiest way to do a development build of libpressio\
    \ is to use Spack envionments.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> one time setup: create\
    \ an envionment</span>\nspack env create -d mydevenviroment\nspack env activate\
    \ mydevenvionment\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one time\
    \ setup: tell spack to set LD_LIBRARY_PATH with the spack envionment's library\
    \ paths</span>\nspack config add modules:prefix_inspections:lib64:[LD_LIBRARY_PATH]\n\
    spack config add modules:prefix_inspections:lib:[LD_LIBRARY_PATH]\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> one time setup: install libpressio-tools\
    \ and checkout </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> libpressio\
    \ for development</span>\nspack add libpressio-tools\nspack develop libpressio@git.master\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compile and install (repeat\
    \ as needed)</span>\nspack install </pre></div>\n<h2 id=\"user-content-manual-installation\"\
    ><a class=\"heading-link\" href=\"#manual-installation\">Manual Installation<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Libpressio\
    \ unconditionally requires:</p>\n<ul>\n<li><code>cmake</code></li>\n<li><code>pkg-config</code></li>\n\
    <li><a href=\"https://github.com/robertu94/std_compat\"><code>std_compat</code></a></li>\n\
    <li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code> or later</li>\n<li>\n<code>clang-7.0.0</code>\
    \ or later using either <code>libc++</code> or <code>libstdc++</code>.  Beware\
    \ that system libraries may need to be recompiled with <code>libc++</code> if\
    \ using <code>libc++</code>\n</li>\n</ul>\n</li>\n</ul>\n<p>Dependency versions\
    \ and optional dependencies are documented <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<h2 id=\"user-content-configuring-libpressio-manually\"\
    ><a class=\"heading-link\" href=\"#configuring-libpressio-manually\">Configuring\
    \ LibPressio Manually<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>LibPressio uses a fairly standard CMake buildsystem.\nFor\
    \ more information on <a href=\"https://robertu94.github.io/learning/cmake\" rel=\"\
    nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration options\
    \ for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\nFor information\
    \ on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<h1 id=\"user-content-api-stability\"><a class=\"heading-link\"\
    \ href=\"#api-stability\">API Stability<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h1>\n<p>Please refer to <a href=\"docs/stability.md\"\
    >docs/stability.md</a>.</p>\n<h1 id=\"user-content-how-to-contribute\"><a class=\"\
    heading-link\" href=\"#how-to-contribute\">How to Contribute<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>Please refer to <a\
    \ href=\"CONTRIBUTORS.md\">CONTRIBUTORS.md</a> for a list of contributors, sponsors,\
    \ and contribution guidelines.</p>\n<h1 id=\"user-content-bug-reports\"><a class=\"\
    heading-link\" href=\"#bug-reports\">Bug Reports<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h1>\n<p>Please files bugs to the Github Issues\
    \ page on the CODARCode libpressio repository.</p>\n<p>Please read this post on\
    \ <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\" rel=\"nofollow\"\
    >how to file a good bug report</a>.\_ After reading this post, please provide\
    \ the following information specific to libpressio:</p>\n<ul>\n<li>Your OS version\
    \ and distribution information, usually this can be found in <code>/etc/os-release</code>\n\
    </li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n</li>\n<li>the version\
    \ of each of libpressio's dependencies listed in the README that you have installed.\
    \ Where possible, please provide the commit hashes.</li>\n</ul>\n<h1 id=\"user-content-citing-libpressio\"\
    ><a class=\"heading-link\" href=\"#citing-libpressio\">Citing LibPressio<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>If\
    \ you find LibPressio useful, please cite this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n\
    \  title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n\
    \  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di,\
    \ Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on\
    \ Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n\
    \  year={2021},\n  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 21
  subscribers_count: 5
  topics: []
  updated_at: 1695425179.0
roblatham00/cashersize:
  data_format: 2
  description: Exercise caching in the mochi context
  filenames:
  - spack.yaml
  full_name: roblatham00/cashersize
  latest_release: null
  readme: '<p>Your project "cachersize" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652377734.0
rohankumardubey/libtree:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: rohankumardubey/libtree
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    ><img src=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    \ alt=\"Test\" style=\"max-width: 100%;\"></a>\n<a href=\"https://aur.archlinux.org/packages/libtree/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7e7cc860b359b4e8c852178856fed7ba2f3ceb557ab7e2c021ab84d695412362/68747470733a2f2f696d672e736869656c64732e696f2f6175722f76657273696f6e2f6c6962747265653f6c6f676f3d417263682d4c696e7578\"\
    \ alt=\"AUR version\" data-canonical-src=\"https://img.shields.io/aur/version/libtree?logo=Arch-Linux\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1 id=\"user-content-libtree\"><a class=\"\
    heading-link\" href=\"#libtree\">libtree<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h1>\n<p>A tool that:</p>\n<ul>\n<li>\U0001F333 turns\
    \ <code>ldd</code> into a tree</li>\n<li>\u261D\uFE0F explains why shared libraries\
    \ are found and why not</li>\n<li>\U0001F4E6 optionally deploys executables and\
    \ dependencies into a single directory</li>\n</ul>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"doc/screenshot.png\"><img src=\"doc/screenshot.png\"\
    \ alt=\"example\" style=\"max-width: 100%;\"></a></p>\n<h2 id=\"user-content-installation\"\
    ><a class=\"heading-link\" href=\"#installation\">Installation<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Download the <a href=\"\
    https://github.com/haampie/libtree/releases\"><strong>latest release</strong></a>\
    \ from Github.</p>\n<p><strong>Static executable</strong></p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>wget -qO libtree https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64\n\
    chmod +x libtree\n./libtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<p><strong>Static executable\
    \ + optional dependencies</strong></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>wget -qO libtree.tar.gz https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64.tar.gz\n\
    mkdir libtree\ntar -xf libtree.tar.gz -C libtree\n<span class=\"pl-k\">export</span>\
    \ PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$PWD</span>/libtree:<span class=\"pl-smi\">$PATH</span><span class=\"pl-pds\"\
    >\"</span></span>\nlibtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<h2 id=\"user-content-deploying-binaries--dependencies-into-a-folder\"\
    ><a class=\"heading-link\" href=\"#deploying-binaries--dependencies-into-a-folder\"\
    >Deploying binaries + dependencies into a folder<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ libtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which man<span\
    \ class=\"pl-pds\">)</span></span> -d man.bundle --chrpath --strip\nman\n\u251C\
    \u2500\u2500 libmandb-2.9.1.so [runpath]\n\u2502   \u251C\u2500\u2500 libman-2.9.1.so\
    \ [runpath]\n\u2502   \u2502   \u251C\u2500\u2500 libpipeline.so.1 [ld.so.conf]\n\
    \u2502   \u2502   \u2514\u2500\u2500 libseccomp.so.2 [ld.so.conf]\n\u2502   \u2514\
    \u2500\u2500 libgdbm.so.6 [ld.so.conf]\n\u251C\u2500\u2500 libman-2.9.1.so (collapsed)\
    \ [runpath]\n\u2514\u2500\u2500 libpipeline.so.1 (collapsed) [ld.so.conf]\n\n\
    Deploying to <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/bin/man<span class=\"pl-pds\">\"</span></span> =<span class=\"\
    pl-k\">&gt;</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/bin/man<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/lib/man-db/libmandb-2.9.1.so<span class=\"pl-pds\">\"</span></span>\
    \ =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>man.bundle/usr/lib/libmandb-2.9.1.so<span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/man-db/libman-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libman-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/lib/x86_64-linux-gnu/libpipeline.so.1.5.2<span class=\"pl-pds\"\
    >\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1.5.2<span class=\"\
    pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1<span class=\"pl-pds\">\"\
    </span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2<span class=\"pl-pds\"\
    >\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6<span class=\"pl-pds\"\
    >\"</span></span>\n\n$ tree man.bundle/\nman.bundle/\n\u2514\u2500\u2500 usr\n\
    \    \u251C\u2500\u2500 bin\n    \u2502\_\_ \u2514\u2500\u2500 man\n    \u2514\
    \u2500\u2500 lib\n        \u251C\u2500\u2500 libgdbm.so.6 -<span class=\"pl-k\"\
    >&gt;</span> libgdbm.so.6.0.0\n        \u251C\u2500\u2500 libgdbm.so.6.0.0\n \
    \       \u251C\u2500\u2500 libman-2.9.1.so\n        \u251C\u2500\u2500 libmandb-2.9.1.so\n\
    \        \u251C\u2500\u2500 libpipeline.so.1 -<span class=\"pl-k\">&gt;</span>\
    \ libpipeline.so.1.5.2\n        \u251C\u2500\u2500 libpipeline.so.1.5.2\n    \
    \    \u251C\u2500\u2500 libseccomp.so.2 -<span class=\"pl-k\">&gt;</span> libseccomp.so.2.5.1\n\
    \        \u2514\u2500\u2500 libseccomp.so.2.5.1\n\n3 directories, 9 files</pre></div>\n\
    <h2 id=\"user-content-verbose-output\"><a class=\"heading-link\" href=\"#verbose-output\"\
    >Verbose output<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>By default certain standard depenendencies are not shown. For more verbose\
    \ output use</p>\n<ul>\n<li>\n<code>libtree -v $(which man)</code> to show skipped\
    \ libraries without their children</li>\n<li>\n<code>libtree -a $(which apt-get)</code>\
    \ to show the full recursive list of libraries</li>\n</ul>\n<p>Use the <code>--path</code>\
    \ or <code>-p</code> flags to show paths rather than sonames:</p>\n<ul>\n<li><code>libtree\
    \ -p $(which tar)</code></li>\n</ul>\n<h2 id=\"user-content-changing-search-paths\"\
    ><a class=\"heading-link\" href=\"#changing-search-paths\">Changing search paths<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p><code>libtree</code>\
    \ follows the rules of <code>ld.so</code> to locate libraries, but does not use\
    \ <code>ldconfig</code>'s\ncache. Instead it parses <code>/etc/ld.so.conf</code>\
    \ at runtime. In fact you can change the search\npath config by setting <code>--ldconf\
    \ mylibs.conf</code>. Search paths can be added as well via\n<code>LD_LIBRARY_PATH=\"\
    path1:path2:$LD_LIBRARY_PATH\" libtree ...</code>.</p>\n<h2 id=\"user-content-building\"\
    ><a class=\"heading-link\" href=\"#building\">Building<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<ul>\n<li>\n<strong>From source</strong>:\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/haampie/libtree.git\n\
    <span class=\"pl-c1\">cd</span> libtree\nmkdir build\n<span class=\"pl-c1\">cd</span>\
    \ build\ncmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>/path/to/cxxopts;/path/to/elfio;/path/to/termcolor<span\
    \ class=\"pl-pds\">\"</span></span> ..\nmake -j\nmake install</pre></div>\n</li>\n\
    <li>\n<strong>Using <a href=\"https://github.com/spack/spack\">spack</a></strong>:\n\
    <pre><code>spack install libtree +chrpath +strip\nspack load libtree\n</code></pre>\n\
    </li>\n</ul>\n<h2 id=\"user-content-known-issues\"><a class=\"heading-link\" href=\"\
    #known-issues\">Known issues<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<ul>\n<li>When deploying libs with <code>libtree app -d folder.bundle\
    \ --chrpath</code>, the runpaths are only\nchanged when the binaries already have\
    \ an an rpath or runpath. This is a limitation of\n<code>chrpath</code>. Another\
    \ option is to use <code>patchelf</code> instead, but this tool is known to break\n\
    binaries sometimes.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664232270.0
salotz/snailpacks:
  data_format: 2
  description: Spack repo for multimedia development
  filenames:
  - examples/c-embed-python/spack.yaml
  full_name: salotz/snailpacks
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics:
  - spack
  - spack-repo
  - scopes-lang
  - multimedia
  - game-development
  - package-manager
  - development-environment
  updated_at: 1648089720.0
simonpintarelli/acclapack-tests:
  data_format: 2
  description: null
  filenames:
  - spack-envs/rocm/spack.yaml
  full_name: simonpintarelli/acclapack-tests
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667393188.0
simonpintarelli/nlcglib:
  data_format: 2
  description: Nonlinear CG methods for wave-function optimization in DFT
  filenames:
  - spack-envs/q-e-sirius-cpu-only/spack.yaml
  full_name: simonpintarelli/nlcglib
  latest_release: v0.9.1
  stargazers_count: 6
  subscribers_count: 2
  topics: []
  updated_at: 1671059412.0
spack/gitlab-runners:
  data_format: 2
  description: Images used to run Gitlab pipelines in the cloud
  filenames:
  - spack.yaml
  full_name: spack/gitlab-runners
  latest_release: v2023-07-01
  readme: '<p>This repository contains images that are used to run Gitlab pipelines
    to validate PRs in Spack.</p>

    <p>The recipes have been modified from ones in: <a href="https://github.com/UO-OACISS/e4s">https://github.com/UO-OACISS/e4s</a></p>

    '
  stargazers_count: 2
  subscribers_count: 11
  topics: []
  updated_at: 1685684158.0
spack/localized-docs:
  data_format: 2
  description: Localized documentation for Spack
  filenames:
  - spack.yaml
  full_name: spack/localized-docs
  latest_release: null
  readme: "<h1 id=\"user-content-localized-documentation-for-spack\"><a class=\"heading-link\"\
    \ href=\"#localized-documentation-for-spack\">Localized Documentation for Spack<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h1>\n<p>This\
    \ repository contains translations of <a href=\"/spack/spack\">Spack</a>'s\ndocumentation.\
    \  It implements the workflow described in the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">Sphinx docs</a>.</p>\n<p>The instructions here describe how\
    \ you can contribute by:</p>\n<ol>\n<li>Adding to an existing translation, and</li>\n\
    <li>Creating a translation in a new language.</li>\n</ol>\n<h2 id=\"user-content-prerequisites\"\
    ><a class=\"heading-link\" href=\"#prerequisites\">Prerequisites<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<ol>\n<li>\n<p>First,\
    \ init the <code>spack</code> submodule:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">git clone https://github.com/spack/localized-docs</span>\n\
    $ <span class=\"pl-s1\"><span class=\"pl-c1\">cd</span> localized-docs</span>\n\
    $ <span class=\"pl-s1\">git submodule init</span>\n$ <span class=\"pl-s1\">git\
    \ submodule update</span></pre></div>\n</li>\n<li>\n<p>To use this repository\
    \ you'll need Sphinx, some plugins for it, and\n<code>gettext</code>.  To install\
    \ these dependencies, using <code>pip</code> and <code>brew</code>, you\ncan run:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >pip3 install -r requirements.txt</span>\n$ <span class=\"pl-s1\">brew install\
    \ gettext</span></pre></div>\n<p>Using Spack, you can just take advantage of the\
    \ <code>spack.yaml</code> file at\nthe root of this repo:</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre><span class=\"pl-c1\">spack install</span>\n\
    <span class=\"pl-c1\">spack env activate .</span></pre></div>\n<p>This will install\
    \ the tools you need and put them in your <code>PATH</code>.</p>\n</li>\n</ol>\n\
    <h2 id=\"user-content-adding-to-an-existing-translation\"><a class=\"heading-link\"\
    \ href=\"#adding-to-an-existing-translation\">Adding to an existing translation<span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Translations\
    \ in this repository are stored in <code>.po</code> files under\n<code>translations</code>.\
    \  There is one translation per languages, and each file is\nnamed according to\
    \ its\n<a href=\"https://www.gnu.org/software/gettext/manual/html_node/Language-Codes.html#Language-Codes\"\
    \ rel=\"nofollow\">ISO-639 language code</a>.\nSo, the Japanese translation data\
    \ for Spack is stored in\n<code>translations/ja.po</code>.</p>\n<p>If you want\
    \ to add to an existing translation, all you need to do is edit\nthe appropriate\
    \ <code>.po</code> file and add translated strings to it.  <code>.po</code> files\n\
    are comprised of <code>msgid</code>/<code>msgstr</code> pairs.  The <code>msgid</code>\
    \ corresponds to an\nEnglish string in the original documentation, and the <code>msgstr</code>\
    \ is its\ntranslation in the target language.  For example, for Japanese, the\n\
    translation of \"Basic Usage\" is stored like this:</p>\n<pre><code>#: ../spack/lib/spack/docs/basic_usage.rst:10\n\
    msgid \"Basic Usage\"\nmsgstr \"\u57FA\u672C\u7684\u306A\u4F7F\u3044\u65B9\"\n\
    </code></pre>\n<p>To add a translation:</p>\n<ol>\n<li>Update <code>msgstr</code>\
    \ elements in the appropriate <code>.po</code> files;</li>\n<li>Run <code>make</code>;</li>\n\
    <li>Commit the results;</li>\n<li>Submit a pull request so that we can merge your\
    \ changes.</li>\n</ol>\n<p>That's all!  Merged pull requests will automatically\
    \ trigger a rebuild of\nthe translated docs, and you should see your changes at\n\
    <a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\">spack.readthedocs.io</a>.</p>\n\
    <p>If you want to look at the documentation while you're editing it, running\n\
    <code>make</code> also generates per-language builds of the docs in <code>html/&lt;lang&gt;</code>.\n\
    So, to see the Japanese documentation, you can run <code>make</code> and open\n\
    <code>html/ja/index.html</code> in a local web browser.</p>\n<h2 id=\"user-content-creating-a-new-translation\"\
    ><a class=\"heading-link\" href=\"#creating-a-new-translation\">Creating a new\
    \ translation<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>To create a new translation, add the language to the <code>languages</code>\
    \ list in\nthe <code>Makefile</code>.  For example, if the only language is Japanese\
    \ (<code>ja</code>) and\nyou want to add German (<code>de</code>), just add <code>de</code>:</p>\n\
    <div class=\"highlight highlight-source-makefile\"><pre><span class=\"pl-smi\"\
    >languages</span> = ja de</pre></div>\n<p>Running <code>make</code>, will create\
    \ files in <code>docs</code>, <code>locale</code>, and\n<code>translations</code>,\
    \ and <code>html</code>:</p>\n<pre><code>    translations/de.po          # German\
    \ translation file\n    translations/de.mo          # generated from de.po\n \
    \   locale/de/LC_MESSAGES/*.mo  # symlinks to translations/de.mo\n    docs/de/\
    \                    # a Sphinx build directory for German docs\n    html/de/\
    \                    # HTML built by Sphinx from docs/de\n</code></pre>\n<p>Add\
    \ everything <em>except</em> <code>html</code>, then commit. <code>html</code>\
    \ is ignored by default\n(see <code>.gitignore</code>), so you can just run this:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >git add <span class=\"pl-c1\">.</span></span>\n$ <span class=\"pl-s1\">git commit</span></pre></div>\n\
    <p>See instructions above for how to start translating.</p>\n<h2 id=\"user-content-workflow\"\
    ><a class=\"heading-link\" href=\"#workflow\">Workflow<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>This repository implements\
    \ the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">workflow described here</a>.\nMost users will only need to\
    \ concern themselves with <code>translations/*.po</code>\nfiles, but we provide\
    \ a short summary here so that you can understand how\neverything works.</p>\n\
    <p>Translation is done as follows:</p>\n<ol>\n<li>\n<p>First, we use (or rather\
    \ Sphinx uses) the <code>gettext</code> tool to extract\nstrings to be translated\
    \ from each <code>.rst</code> document in the Spack\ndocumentation. This results\
    \ in a set of <code>.pot</code> files in\n<code>templates/*.pot</code>.  These\
    \ contain keys (<code>msgid</code>s) for unique strings,\nas well as their location\
    \ (file and line number) in the documentation.</p>\n</li>\n<li>\n<p>We merge the\
    \ <code>.pot</code> files into a single <code>merged.pot</code> file to eliminate\n\
    duplicate strings in multiple files.</p>\n</li>\n<li>\n<p><code>merged.pot</code>\
    \ is used to create an initial <code>translations/&lt;lang&gt;.po</code>\nfile.\
    \  Translations are added to <code>msgstr</code> fields in the <code>.po</code>\
    \ file.</p>\n</li>\n<li>\n<p>A single <code>translations/&lt;lang&gt;.mo</code>\
    \ file is generated from the <code>.po</code>\nfile. The <code>.mo</code> file\
    \ is in a special binary format.</p>\n</li>\n<li>\n<p>We generate symlinks in\
    \ <code>locale/&lt;lang&gt;/LC_MESSAGES/*.mo</code> that all\npoint back to the\
    \ single, unified <code>translations/&lt;lang&gt;.mo</code> file.  The\n<code>locale</code>\
    \ directory can then be used with Sphinx to build translated\ndocumentation.</p>\n\
    </li>\n</ol>\n<p>The top-level <code>Makefile</code> implements this workflow,\
    \ so you don't have to\nthink too much about it.</p>\n<h2 id=\"user-content-license\"\
    ><a class=\"heading-link\" href=\"#license\">License<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>This repository is part\
    \ of Spack, which distributed under the terms of\nboth the MIT license and the\
    \ Apache License (Version 2.0). Users may\nchoose either license, at their option.</p>\n\
    <p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n\
    <p>See <a href=\"https://github.com/spack/localized-docs/blob/master/LICENSE-MIT\"\
    >LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/localized-docs//blob/master/LICENSE-APACHE\"\
    >LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/localized-docs/blob/master/COPYRIGHT\"\
    >COPYRIGHT</a>,\nand <a href=\"https://github.com/spack/localized-docs/blob/master/NOTICE\"\
    >NOTICE</a>\nfor details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-647188</p>\n"
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1621989548.0
spack/spack-ci-containers:
  data_format: 2
  description: Container recipes used by Spack for test purposes
  filenames:
  - clingo/spack.yaml
  full_name: spack/spack-ci-containers
  latest_release: null
  readme: '<h1 id="user-content-spack-ci-containers"><a class="heading-link" href="#spack-ci-containers">Spack
    CI containers<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This repository contains recipes for containers that are

    used to test Spack under CI.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-ci-containers/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1621989328.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-22.05/nvhpc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.02/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/gcc/spack.yaml
  - OLCF/summit/spack.yaml
  - NERSC/perlmutter/e4s-22.05/cuda/spack.yaml
  - NREL/configs/eagle/compilers/spack.yaml
  - NERSC/perlmutter/e4s-22.11/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/prod/spack.yaml
  - NREL/configs/eagle/base/spack.yaml
  - NREL/configs/rhodes/utilities/spack.yaml
  - OLCF/frontier/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cuda/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/nvhpc/spack.yaml
  - NREL/configs/eagle/utilities/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/tools/spack.yaml
  - OLCF/crusher/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.05/spack.yaml
  - OLCF/spock/spack.yaml
  - NREL/configs/rhodes/compilers/spack.yaml
  - NERSC/perlmutter/e4s-22.11/cuda/spack.yaml
  - NERSC/cori/e4s-21.02/prod/spack.yaml
  - NERSC/cori/e4s-20.10/prod/spack.yaml
  - NERSC/perlmutter/e4s-22.11/prod/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/spack.yaml
  - BOISESTATE/borah/applications/gromacs/_spack.yaml
  - NREL/configs/eagle/software/spack.yaml
  - NERSC/perlmutter/e4s-23.05/data/spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/Frank-Jupiter/spack.yaml
  - NERSC/perlmutter/e4s-23.05/nvhpc/spack.yaml
  - OLCF/andes/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cce/spack.yaml
  - BOISESTATE/borah/environments/b4s/_spack.yaml
  - NERSC/perlmutter/e4s-23.05/gcc/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/cce/spack.yaml
  - BOISESTATE/borah/environments/base/_spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.08/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-22.11/prod/nvhpc/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1 id="user-content-spack-configs"><a class="heading-link" href="#spack-configs">Spack
    Configs<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 54
  subscribers_count: 26
  topics: []
  updated_at: 1694684115.0
spack/spack-tutorial:
  data_format: 2
  description: Standalone Spack Tutorial Repository
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial
  latest_release: isc23
  readme: '<h1 id="user-content--spack-tutorial"><a class="heading-link" href="#-spack-tutorial">

    <img src="https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667"
    width="64" valign="middle" alt="Spack" data-canonical-src="https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg"
    style="max-width: 100%;"> Spack Tutorial<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h1>

    <p><a href="https://spack-tutorial.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/f38d9ceff55c2a7fea5d61861aa91b64fe00c220b83af1fd8af46da42ede70f5/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2d7475746f7269616c2f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/spack-tutorial/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is a multi-platform package manager that builds and installs multiple
    versions and configurations of software. It works on Linux, macOS, and many supercomputers.
    Spack is non-destructive: installing a new version of a package does not break
    existing installations, so many configurations of the same package can coexist.</p>

    <p>This repository houses Spack''s <a href="https://spack-tutorial.readthedocs.io/en/latest/"
    rel="nofollow"><strong>hands-on tutorial</strong></a>, which is a subset of Spack''s
    <a href="https://spack.readthedocs.io/" rel="nofollow"><strong>full documentation</strong></a>
    (or you can run <code>spack help</code> or <code>spack help --all</code>).</p>

    <p>This tutorial covers basic to advanced usage, packaging, developer features,
    and large HPC deployments.  You can do all of the exercises on your own laptop
    using a Docker container. Feel free to use these materials to teach users at your
    organization about Spack.</p>

    <h2 id="user-content-updating-the-tutorial"><a class="heading-link" href="#updating-the-tutorial">Updating
    the tutorial<span aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <ol>

    <li>Create a new branch named for the event/milestone that corresponds to the
    new version you want to create.</li>

    <li>Upload screen shot of first slide (244px wide, .png) to <a href="https://github.com/spack/spack-tutorial/tree/master/tutorial/images">images
    directory</a> following existing file-naming convention.</li>

    <li>Upload PDF of slide deck to <a href="https://github.com/spack/spack-tutorial/tree/master/_static/slides">slides
    directory</a> following existing file-naming convention.</li>

    <li>Update <a href="https://github.com/spack/spack-tutorial/blob/master/index.rst">index.rst</a>
    with event name and date; full citation; and file paths for image and PDF.</li>

    <li>Update this README (lines 3 and 7) with link to new version''s URL.</li>

    <li>Build docs locally.</li>

    <li>Push changes to GitHub and active new tag/version on Read the Docs.</li>

    <li>Build new version on Read the Docs.</li>

    </ol>

    <h2 id="user-content-updating-the-tutorial-container"><a class="heading-link"
    href="#updating-the-tutorial-container">Updating the tutorial container<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <p>The spack tutorial container is built from another <a href="https://github.com/spack/spack-tutorial-container">repository</a>
    by an automated process.  For instructions on how to create an updated version
    of the tutorial container, see these <a href="https://github.com/spack/spack-tutorial-container/blob/master/UPDATING.md">instructions</a>.  For
    a general description of the automated process used to build the tutorial container,
    read the <a href="https://github.com/spack/spack-tutorial-container/blob/master/DESCRIPTION.md">description</a>.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Spack is distributed under the terms of both the MIT license and the Apache
    License (Version 2.0). Users may choose either license, at their option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack/blob/develop/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack/blob/develop/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack/blob/develop/NOTICE">NOTICE</a> for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 31
  subscribers_count: 34
  topics:
  - tutorial
  updated_at: 1695414036.0
spack/spack-tutorial-container:
  data_format: 2
  description: Dockerfile and artifacts (minus build cache) to create Spack tutorial
    container.
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial-container
  latest_release: null
  readme: '<h1 id="user-content-spack-tutorial-container"><a class="heading-link"
    href="#spack-tutorial-container">Spack Tutorial Container<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h1>

    <p>This repository contains a container image you can use to do the

    <a href="https://spack.readthedocs.io/en/latest/tutorial.html" rel="nofollow">Spack
    Tutorial</a>.

    It''s exactly like the AWS images we use when we give the tutorial at

    conferences.</p>

    <h2 id="user-content-license"><a class="heading-link" href="#license">License<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1657127710.0
supercontainers/ecp-tutorial:
  data_format: 2
  description: ECP Tutorial
  filenames:
  - examples/spack/spack.yaml
  full_name: supercontainers/ecp-tutorial
  latest_release: null
  readme: "<h1 id=\"user-content-getting-started-with-containers-on-hpc\"><a class=\"\
    heading-link\" href=\"#getting-started-with-containers-on-hpc\">Getting Started\
    \ with Containers on HPC<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p>View this on <a href=\"https://supercontainers.github.io/ecp-tutorial/\"\
    \ rel=\"nofollow\">GitHub Pages</a>.</p>\n<h2 id=\"user-content-ecp-supercontainers-tutorial-session\"\
    ><a class=\"heading-link\" href=\"#ecp-supercontainers-tutorial-session\">ECP\
    \ Supercontainers Tutorial Session<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<div><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"\
    images/ecp.jpg\"><img src=\"images/ecp.jpg\" width=\"250\" style=\"max-width:\
    \ 100%;\"></a></div>\n<h2 id=\"user-content-details\"><a class=\"heading-link\"\
    \ href=\"#details\">Details<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>Short Tutorial Session</p>\n<p>Venue: ECP Annual Meeting\
    \ 2022</p>\n<p>Date: Friday, May 6, 2022  2:30pm - 4:00pm EDT</p>\n<p>Location:\
    \ Remote</p>\n<p>Topic Area: Programming Models &amp; Systems Software</p>\n<p>Keywords:\
    \ Containerized HPC, System Software and Runtime Systems, Scientific Software\
    \ Development, DevOps</p>\n<h2 id=\"user-content-tutorial-login-details\"><a class=\"\
    heading-link\" href=\"#tutorial-login-details\">Tutorial Login details<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>Appropriate login details\
    \ to our EC2 VM instances and an (optional) training account to the Cori supercomputer\
    \ will all be provided to you at the start of the tutorial session. Please claim\
    \ your own instance in the table at the bottom of the <a href=\"https://docs.google.com/document/d/1rmi5tSuk_7Q5YVDS1SD7TcxjoEYFgXK-ofvUV2jmL4Y/edit?usp=sharing\"\
    \ rel=\"nofollow\">Google Doc</a></p>\n<h3 id=\"user-content-ec2-login\"><a class=\"\
    heading-link\" href=\"#ec2-login\">EC2 Login<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>hostname: tutXX.supercontainers.org</p>\n\
    <p>user: tutorial</p>\n<p>password: Will be provided</p>\n<h3 id=\"user-content-nersc-login\"\
    ><a class=\"heading-link\" href=\"#nersc-login\">NERSC Login<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h3>\n<p>hostname: cori.nesrc.gov</p>\n\
    <p>Sign Up; Go to <a href=\"https://iris.nersc.gov/train\" rel=\"nofollow\">this\
    \ page</a> to sign up for the account.  Use training code <em>dJ2d</em>.  If you\
    \ already have a NERSC account, you can use that account.</p>\n<h2 id=\"user-content-abstract\"\
    ><a class=\"heading-link\" href=\"#abstract\">Abstract<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>Container computing has\
    \ revolutionized the way applications are developed and delivered. It offers opportunities\
    \ that never existed before for significantly improving efficiency of scientific\
    \ workflows and easily moving these workflows from the laptop to the supercomputer.\
    \ Tools like Docker, Shifter, Singularity and Charliecloud enable a new paradigm\
    \ for scientific and technical computing. However, to fully unlock its potential,\
    \ users and administrators need to understand how to utilize these new approaches.\
    \ This tutorial will introduce attendees to the basics of creating container images,\
    \ explain best practices, and cover more advanced topics such as creating images\
    \ to be run on HPC platforms using various container runtimes. The tutorial will\
    \ also explain how research scientists can utilize container-based computing to\
    \ accelerate their research and how these tools can boost the impact of their\
    \ research by enabling better reproducibility and sharing of their scientific\
    \ process without compromising security.</p>\n<p>This is an short version of the\
    \ highly successful tutorial presented at multiple SC conferences and multiple\
    \ ECP Summit Meetings.</p>\n<h2 id=\"user-content-prerequisites\"><a class=\"\
    heading-link\" href=\"#prerequisites\">Prerequisites<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>This is a hands-on tutorial.\
    \ Participants will need a laptop/workstation with an ssh client to make best\
    \ use of time during the tutorial.  We will be providing training user accounts\
    \ to both pre-configured EC2 instances as well as the Cori Supercomputer at NERSC.</p>\n\
    <div><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"images/AWS_logo.png\"\
    ><img src=\"images/AWS_logo.png\" width=\"250\" style=\"max-width: 100%;\"></a></div>\n\
    <p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards.\
    \ EC2 images and temporary login credentials will be distributed onsite at the\
    \ tutorial.</p>\n<p>After the tutorial, you can boot our tutorial image yourself\
    \ on Amazon EC2 to run through the tutorial again. We recommend you use your own\
    \ EC2 key and change the password.</p>\n<p>US-West-Oregon: ami-09bd35c8089302e0d</p>\n\
    <h3 id=\"user-content-optional-prerequisites\"><a class=\"heading-link\" href=\"\
    #optional-prerequisites\">Optional Prerequisites<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>Users can also install Docker and\
    \ Singularity prior to attending the tutorial session. Here, it may be beneficial\
    \ to create a docker and sylabs (singularity) account in advance at <a href=\"\
    https://cloud.docker.com/\" rel=\"nofollow\">https://cloud.docker.com/</a> and\
    \ <a href=\"https://cloud.sylabs.io/\" rel=\"nofollow\">https://cloud.sylabs.io/</a>\
    \ This accounts will be needed to create images on docker cloud/dockerhub and\
    \ sylabs cloud.</p>\n<p><a href=\"https://sylabs.io/guides/3.3/user-guide/\" rel=\"\
    nofollow\">Install Singularity on Linux</a></p>\n<p><a href=\"https://www.docker.com/products/docker-desktop\"\
    \ rel=\"nofollow\">Install Docker for Desktop</a></p>\n<h2 id=\"user-content-questions\"\
    ><a class=\"heading-link\" href=\"#questions\">Questions<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h2>\n<p>You can ask questions verbally\
    \ or with this <a href=\"https://docs.google.com/document/d/1rmi5tSuk_7Q5YVDS1SD7TcxjoEYFgXK-ofvUV2jmL4Y/edit?usp=sharing\"\
    \ rel=\"nofollow\">Google Doc</a>.\nPlease append your question below the others\
    \ in the document.</p>\n<p>We have also created a Slack Team for any and all related\
    \ HPC container discussions.  The invitation link is <a href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h2 id=\"user-content-schedule\"><a class=\"\
    heading-link\" href=\"#schedule\">Schedule<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>Note: times are listed in EDT</p>\n\
    <p>2:30 \u2013 2:45 <a href=\"https://drive.google.com/file/d/1KNnrpJI24u2XeL9GTg2HXkV_RHeupD6r/view?usp=sharing\"\
    \ rel=\"nofollow\">Introduction to Containers in HPC</a> (Younge)</p>\n<p>2:45\
    \ \u2013 3:00 <a href=\"/01-hands-on.md\">How to build your first Docker container</a>\
    \ (Canon)</p>\n<p>3:00 \u2013 3:15 <a href=\"/02-hands-on.md\">How to deploy a\
    \ container on a supercomputer</a> (Canon)</p>\n<p>3:15 - 3:45 Containers and\
    \ E4S (Shende)</p>\n<p>3:45 - 4:00 <a href=\"https://drive.google.com/file/d/1Rj2PxSwUHsAC1YtgTo40mod3gFeuYxoN/view?usp=sharing\"\
    \ rel=\"nofollow\">Best Practices and Wrap Up</a> (Canon)</p>\n"
  stargazers_count: 1
  subscribers_count: 7
  topics: []
  updated_at: 1650325690.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2023.10.11
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2023.10.11\"\
    ><img src=\"https://camo.githubusercontent.com/3c7e98ea04bb65e8c1fe3d010054b4ae068cb06ee48c21472afd331cd5772141/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032332e31302e31312d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2023.10.11-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.8431874\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f9eeab14f9dc1b1fd7367bfa5ac1e09e61a20b63357dfb9dba342d13bf36b869/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e383433313837342e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.8431874.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2 id=\"user-content-what-is-spectre\"\
    ><a class=\"heading-link\" href=\"#what-is-spectre\">What is SpECTRE?<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<p>SpECTRE is an open-source\
    \ code for multi-scale, multi-physics problems\nin astrophysics and gravitational\
    \ physics. In the future, we hope that\nit can be applied to problems across discipline\
    \ boundaries in fluid\ndynamics, geoscience, plasma physics, nuclear physics,\
    \ and\nengineering. It runs at petascale and is designed for future exascale\n\
    computers.</p>\n<p>SpECTRE is being developed in support of our collaborative\
    \ Simulating\neXtreme Spacetimes (SXS) research program into the multi-messenger\n\
    astrophysics of neutron star mergers, core-collapse supernovae, and\ngamma-ray\
    \ bursts.</p>\n<h2 id=\"user-content-citing-spectre\"><a class=\"heading-link\"\
    \ href=\"#citing-spectre\">Citing SpECTRE<span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a></h2>\n<p>Please cite SpECTRE in any publications\
    \ that make use of its code or data. Cite\nthe latest version that you use in\
    \ your publication. The DOI for this version\nis:</p>\n<ul>\n<li>DOI: <a href=\"\
    https://doi.org/10.5281/zenodo.8431874\" rel=\"nofollow\">10.5281/zenodo.8431874</a>\n\
    </li>\n</ul>\n<p>You can cite this BibTeX entry in your publication:</p>\n\n\n\
    <div class=\"highlight highlight-text-bibtex\"><pre><span class=\"pl-k\">@software</span>{<span\
    \ class=\"pl-en\">spectrecode</span>,\n    <span class=\"pl-s\">author</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Deppe, Nils and Throwe,\
    \ William and Kidder, Lawrence E. and Vu,</span>\n<span class=\"pl-s\">Nils L.\
    \ and Nelli, Kyle C. and Armaza, Crist\\'obal and Bonilla, Marceline S. and</span>\n\
    <span class=\"pl-s\">H\\'ebert, Fran\\c{c}ois and Kim, Yoonsoo and Kumar, Prayush\
    \ and Lovelace,</span>\n<span class=\"pl-s\">Geoffrey and Macedo, Alexandra and\
    \ Moxon, Jordan and O'Shea, Eamonn and</span>\n<span class=\"pl-s\">Pfeiffer,\
    \ Harald P. and Scheel, Mark A. and Teukolsky, Saul A. and Wittek,</span>\n<span\
    \ class=\"pl-s\">Nikolas A. and others<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">title</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>\\texttt{SpECTRE v2023.10.11}<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">version</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>2023.10.11<span class=\"pl-pds\">\"</span></span>,\n    <span\
    \ class=\"pl-s\">publisher</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>Zenodo<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\"\
    >doi</span> = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>10.5281/zenodo.8431874<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>https://spectre-code.org<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">howpublished</span>\
    \ =\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.8431874}{10.5281/zenodo.8431874}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2023<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>10<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2 id=\"\
    user-content-viewing-documentation\"><a class=\"heading-link\" href=\"#viewing-documentation\"\
    >Viewing Documentation<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>The documentation can be viewed at <a href=\"https://spectre-code.org/\"\
    \ rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 133
  subscribers_count: 16
  topics: []
  updated_at: 1697022401.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - thetagpu/spack.yaml
  - chifflot/v100/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1 id="user-content-spack-envs"><a class="heading-link" href="#spack-envs">spack-envs<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2 id="user-content-locally"><a class="heading-link" href="#locally">Locally<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: $spack/opt/spack</span>

    <span class="pl-c1">build_stage: $spack/var/spack/stage</span>


    <span class="pl-c1">spack env activate ~/Dev/spack-envs/local</span>

    <span class="pl-c1">spack install</span></pre></div>

    <h2 id="user-content-g5k"><a class="heading-link" href="#g5k">G5k<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: /my-spack/spack</span>

    <span class="pl-c1">build_stage: /tmp/spack-stage</span></pre></div>

    <h2 id="user-content-anl"><a class="heading-link" href="#anl">ANL<span aria-hidden="true"
    class="octicon octicon-link"></span></a></h2>

    <h3 id="user-content-cooley"><a class="heading-link" href="#cooley">Cooley<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    <p>Before using Spack to compile stuff on Cooley, we recommend to run <code>use_build_cooley</code>
    to get access to newer gcc, cmake, and mvapich versions.</p>

    <h3 id="user-content-thetagpu"><a class="heading-link" href="#thetagpu">ThetaGPU<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h3>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1678891926.0
toxa81/se:
  data_format: 2
  description: Software environments
  filenames:
  - catalog-config/core/spack.yaml
  full_name: toxa81/se
  latest_release: null
  readme: '<h1 id="user-content-software-environments"><a class="heading-link" href="#software-environments">Software
    environments<span aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Deployment steps</p>

    <ul>

    <li>clone spack <code>git clone https://github.com/spack/spack.git</code>

    </li>

    <li>enable spack <code>source enable-spack</code>

    </li>

    <li>srun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16</li>

    <li>install gcc-11.3.0 view <code>spack -e  ./env-spec/gcc-11.3.0/ install</code>

    </li>

    <li>install nvhpc-22.9 <code>srun -N1 --partition=nvgpu spack -e . install -j64</code>

    </li>

    </ul>

    <p>spack compiler find $(spack find --format {prefix.bin} gcc@11)</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669195550.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/intelmpi/bpmf-gpi/spack.yaml
  - var/spack/environments/karolina/bpmf-argo/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1635166163.0
ufs-community/UFS_UTILS:
  data_format: 2
  description: Utilities for the NCEP models.
  filenames:
  - ci/spack.yaml
  full_name: ufs-community/UFS_UTILS
  latest_release: ufs_utils_1_10_0
  readme: '<h1 id="user-content-ufs_utils"><a class="heading-link" href="#ufs_utils">UFS_UTILS<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h1>

    <p>Utilities for the NCEP models. This is part of the

    <a href="https://github.com/ufs-community">Unified Forecast System</a> project.</p>

    <p>Documentation for chgres_cube and other utilities can be found at

    <a href="https://noaa-emcufs-utils.readthedocs.io/en/latest/" rel="nofollow">https://noaa-emcufs-utils.readthedocs.io/en/latest/</a>.</p>

    <p>Complete documentation can be found at

    <a href="https://ufs-community.github.io/UFS_UTILS/" rel="nofollow">https://ufs-community.github.io/UFS_UTILS/</a>.</p>

    <h2 id="user-content-authors"><a class="heading-link" href="#authors">Authors<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <table>

    <thead>

    <tr>

    <th>Utility</th>

    <th>Programmer(s)</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>chgres_cube</td>

    <td>George Gayno, Jeff Beck, Larissa Reames</td>

    </tr>

    <tr>

    <td>cpld_gridgen</td>

    <td>Denise Worthen</td>

    </tr>

    <tr>

    <td>emcsfc_ice_blend</td>

    <td>George Gayno</td>

    </tr>

    <tr>

    <td>emcsfc_snow2mdl</td>

    <td>George Gayno</td>

    </tr>

    <tr>

    <td>fre-nctools</td>

    <td>GFDL progammer</td>

    </tr>

    <tr>

    <td>fvcom_tools</td>

    <td>David Wright, University of Michigan, Ming Hu, GSD/AMB</td>

    </tr>

    <tr>

    <td>gblevents</td>

    <td>Hang Lei</td>

    </tr>

    <tr>

    <td>gdas_init</td>

    <td>George Gayno</td>

    </tr>

    <tr>

    <td>global_cycle</td>

    <td>George Gayno, Shrinivas Moorthi, Xu Li</td>

    </tr>

    <tr>

    <td>grid_tools</td>

    <td>R. J. Purser (regional_esg_grid), Ben Blake (shave.fd), Gerard Ketefian (global_equiv_resol),
    Tsukasa Fujita, JMA (pmat2), GFDL programmer (topo filtering code).</td>

    </tr>

    <tr>

    <td>orog_mask_tools</td>

    <td>Ning Wang, Jordan Alpert, Shan Sun and Ning Wang</td>

    </tr>

    <tr>

    <td>sfc_climo_gen</td>

    <td>George Gayno</td>

    </tr>

    <tr>

    <td>vcoord_gen</td>

    <td>Fanglin Yang</td>

    </tr>

    <tr>

    <td>weight_gen</td>

    <td>George Gayno</td>

    </tr>

    </tbody>

    </table>

    <p>UFS_UTILS Code managers: George Gayno, Jeff Beck, Larissa Reames</p>

    <h2 id="user-content-prerequisites"><a class="heading-link" href="#prerequisites">Prerequisites<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>This package uses the <a href="https://github.com/NOAA-EMC/hpc-stack">hpc-stack</a>
    for the following NCEPLIBS packages:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    </ul>

    <p>And for the following third party libraries:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c Library</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran Library</a></li>

    <li><a href="https://github.com/esmf-org/esmf">ESMF</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="www.zlib.net">Zlib</a></li>

    <li><a href="https://www.hdfgroup.org/solutions/hdf5/" rel="nofollow">HDF5</a></li>

    <li><a href="http://www.libpng.org/pub/png/" rel="nofollow">PNG</a></li>

    </ul>

    <p>It also uses the following repositories:</p>

    <ul>

    <li><a href="https://github.com/ufs-community/ccpp-physics">Common Community Physics
    Package</a></li>

    </ul>

    <h2 id="user-content-installing"><a class="heading-link" href="#installing">Installing<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>On Orion, Jet, Hera and WCOSS2 do the following:</p>

    <ol>

    <li>Set the ''fixed'' directories using the <code>link_fixdirs.sh</code>

    script in <code>./fix</code>. Usage: <code>./link_fixdirs.sh $RUN_ENVIR $machine</code>,

    where <code>$RUN_ENVIR</code> is "emc" or "nco" (most developers

    should choose "emc") and <code>$machine</code> is the platform. Example:</li>

    </ol>

    <pre><code>./link_fixdirs.sh emc hera

    </code></pre>

    <ol start="2">

    <li>Then, invoke the build script:</li>

    </ol>

    <pre><code>./build_all.sh

    </code></pre>

    <h2 id="user-content-contents"><a class="heading-link" href="#contents">Contents<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The <code>sorc</code> directory contains the source code.</p>

    <p>The <code>reg_tests</code> directory contains the consistency test code.</p>

    <p>The <code>fix</code> directory contains links to directories containing

    large, static data files used by UFS_UTILS programs.</p>

    <p>The <code>tests</code> directory contains unit tests.</p>

    <p>The <code>ush</code> directory contains scripts to run UFS_UTILS programs.  Most

    are called from driver scripts.</p>

    <p>The <code>util</code> directory contains utility scripts.</p>

    <p>The <code>parm</code> directory contains parameter files used by

    the chgres_cube program.</p>

    <p>The <code>driver_scripts</code> directory contains high-level driver scripts
    to

    create a model grid on officially supported HPC platforms.</p>

    <p>The <code>modulefiles</code> directory contains modules loaded when building

    UFS_UTILS on supported HPC platforms.  They are also loaded at runtime

    by utility and consistency test scripts.</p>

    <p>The <code>docs</code> directory contains the control file for the doxygen

    documentation build, as well as some markdown files which are part of

    the documentation. It also contains (in the source subdirectory) the

    ReadTheDocs documentation files.</p>

    <p>The <code>cmake</code> directory contains CMake package find utilities, and
    utilities to

    run units tests on some supported HPC platforms.</p>

    <h2 id="user-content-references"><a class="heading-link" href="#references">References<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>Gayno G., Beck J., Carson L., <a href="./docs/20201105-0945a-pre-processing-chgres-cube-gayno-final.pdf">Pre-Processing:

    chgres_cube</a>,

    UFS MRW App Training, 5 November 2020.</p>

    <h2 id="user-content-disclaimer"><a class="heading-link" href="#disclaimer">Disclaimer<span
    aria-hidden="true" class="octicon octicon-link"></span></a></h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 18
  subscribers_count: 9
  topics:
  - nceplibs
  - ufs-utils
  - chgres-cube
  updated_at: 1693509134.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - benchmarks/spack/isambard-a64fx/compute-node/spack.yaml
  - benchmarks/spack/csd3-cascadelake/compute-node/spack.yaml
  - benchmarks/spack/archer2/compute-node/spack.yaml
  - benchmarks/spack/isambard-phase3/milan/spack.yaml
  - benchmarks/spack/myriad/cpu/spack.yaml
  - benchmarks/spack/isambard-phase3/ampere/spack.yaml
  - benchmarks/spack/myriad/a100/spack.yaml
  - benchmarks/spack/myriad/v100/spack.yaml
  - benchmarks/spack/isambard-macs/volta/spack.yaml
  - benchmarks/spack/cosma7/rockport-openmpi-compute-node/spack.yaml
  - benchmarks/spack/isambard-macs/rome/spack.yaml
  - benchmarks/spack/github-actions/default/spack.yaml
  - benchmarks/spack/isambard-phase3/instinct/spack.yaml
  - benchmarks/spack/myriad/p100/spack.yaml
  - benchmarks/spack/csd3-icelake/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1 id=\"user-content-excalibur-tests\"><a class=\"heading-link\" href=\"\
    #excalibur-tests\">ExCALIBUR tests<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h1>\n<p>Performance benchmarks and regression tests for the ExCALIBUR\
    \ project.</p>\n<p>These benchmarks are based on a similar project by\n<a href=\"\
    https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2\
    \ id=\"user-content-installation\"><a class=\"heading-link\" href=\"#installation\"\
    >Installation<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h2>\n\
    <p>We require Python version 3.7 or later. Install the <strong>excalibur-tests</strong>\
    \ package with <code>pip</code> by</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pip install -e <span class=\"pl-c1\">.</span></pre></div>\n<p>The <code>-e/--editable</code>\
    \ flag is recommended for two reasons.</p>\n<ul>\n<li>Spack installs packages\
    \ in a <code>opt</code> directory under the spack environment. With <code>-e</code>\
    \ the spack\nenvironment remains in your local directory and <code>pip</code>\
    \ creates symlinks to it. Without <code>-e</code> spack\nwill install packages\
    \ inside your python environment.</li>\n<li>For <a href=\"https://setuptools.pypa.io/en/latest/userguide/development_mode.html\"\
    \ rel=\"nofollow\">development</a>,\nthe <code>-e</code> flag to <code>pip</code>\
    \ links the installed package to the files in the local\ndirectory, instead of\
    \ copying, to allow making changes to the installed package.</li>\n</ul>\n<p>Note\
    \ that to use <code>-e</code> with a project configured with a <code>pyproject.toml</code>\
    \ you need <code>pip</code> version 22 or later.</p>\n<p>On most systems, it is\
    \ recommended to install the package in a virtual environment.\nFor example, using\
    \ the python3 <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow\"\
    >built-in virtual environment tool <code>venv</code></a>,\ncreate an environment\
    \ called <code>my_environment</code> with</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python3 -m venv ./my_environment</pre></div>\n<p>and activate it with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">source</span>\
    \ ./my_environment/bin/activate</pre></div>\n<h3 id=\"user-content-spack\"><a\
    \ class=\"heading-link\" href=\"#spack\">Spack<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h3>\n<p>The <code>pip install</code> command\
    \ will install a compatible version of <strong>ReFrame</strong> from\n<a href=\"\
    https://pypi.org/project/ReFrame-HPC/\" rel=\"nofollow\">PyPi</a>. However, you\
    \ will have to\nmanually provide an installation of <strong>Spack</strong>.</p>\n\
    <p><a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager\
    \ specifically designed for HPC\nfacilities. In some HPC facilities there may\
    \ be already a central Spack installation available.\nHowever, the version installed\
    \ is most likely too old to support all the features\nused by this package. Therefore\
    \ we recommend you install the latest version locally,\nfollowing the instructions\
    \ below.</p>\n<p><em><strong>Note</strong>: if you have already installed spack\
    \ locally and you want to upgrade to\na newer version, you might first have to\
    \ clear the cache to avoid conflicts:\n<code>spack clean -m</code></em></p>\n\
    <p>Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official instructions</a>\nto install the latest version of\
    \ Spack (summarised here for convenience, but not guaranteed to be\nup-to-date):</p>\n\
    <ul>\n<li>git clone spack:\n<code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code>\n\
    </li>\n<li>run spack setup script: <code>source ./spack/share/spack/setup-env.sh</code>\n\
    </li>\n<li>check spack is in <code>$PATH</code>, for example <code>spack --version</code>\n\
    </li>\n</ul>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable. This\
    \ is taken care of by the <code>setup-env.sh</code>\nscript as above, and you\
    \ can have your shell init script (e.g. <code>.bashrc</code>)\ndo that automatically\
    \ in every session, by adding the following lines to it:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame also requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRAC projects in\n\
    <a href=\"https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack\"\
    >https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack/</a>.\n\
    If you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system if known, otherwise it will automatically\ncreate a very basic environment\
    \ (see \"Usage on unsupported systems\" section below).</p>\n<h2 id=\"user-content-configuration\"\
    ><a class=\"heading-link\" href=\"#configuration\">Configuration<span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a></h2>\n<h3 id=\"user-content-reframe\"\
    ><a class=\"heading-link\" href=\"#reframe\">ReFrame<span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a></h3>\n<p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\"\
    \ rel=\"nofollow\">ReFrame</a> is a high-level\nframework for writing regression\
    \ tests for HPC systems.  For our tests we\nrequire ReFrame v4.1.3.</p>\n<p>We\
    \ provide a ReFrame configuration file with the settings of some systems that\n\
    are part of the ExCALIBUR or DiRAC projects.  You can point ReFrame to this file\
    \ by\nsetting the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILES\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILES</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILES=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-smi\">${PWD}</span>/benchmarks/reframe_config.py<span class=\"pl-pds\"\
    >\"</span></span></pre></div>\n<p>If you want to use a different ReFrame configuration\
    \ file, for example because\nyou use a different system, you can set this environment\
    \ variable to the path of\nthat file.</p>\n<p><strong>Note</strong>: in order\
    \ to use the Spack build system in ReFrame, the <code>spack</code>\nexecutable\
    \ must be in the <code>PATH</code> also on the compute nodes of a cluster, if\n\
    you want to run your benchmarks on them. This is taken care of by adding it\n\
    to your init file (see spack section above).</p>\n<p>However, you will also need\
    \ to set the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ (<code>export RFM_USE_LOGIN_SHELL=\"true\"</code>) in order to make ReFrame\
    \ use</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash -l</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a> line, which would load\nthe user's init script.</p>\n<h2 id=\"user-content-usage\"\
    ><a class=\"heading-link\" href=\"#usage\">Usage<span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a></h2>\n<p>Once you have set up Spack and ReFrame,\
    \ you can execute a benchmark with</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>reframe -c benchmarks/apps/BENCH_NAME -r --performance-report</pre></div>\n\
    <p>where <code>benchmarks/apps/BENCH_NAME</code> is the directory where the benchmark\
    \ is.  The command\nabove assumes you have the program <code>reframe</code> in\
    \ your PATH.  If you have followed the instructions\nto install using <code>pip</code>\
    \ into the default directory, it should have been automatically added.\nIf it\
    \ is not the case, call <code>reframe</code> with its relative or absolute path.</p>\n\
    <p>For example, to run the Sombrero benchmark in the <code>benchmarks/apps/sombrero</code>\
    \ directory you can\nuse</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>reframe -c benchmarks/apps/sombrero -r --performance-report</pre></div>\n\
    <p>For benchmarks that use the Spack build system, the tests define a default\
    \ Spack specification\nto be installed in the environment, but users can change\
    \ it when invoking ReFrame on the\ncommand line with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3 id=\"user-content-setting-environment-variables\"\
    ><a class=\"heading-link\" href=\"#setting-environment-variables\">Setting environment\
    \ variables<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>All the built-in fields of ReFrame regression classes can be set on a per-job\
    \ basis using the\n<code>-S</code> command-line option. One useful such field\
    \ is\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.env_vars\"\
    \ rel=\"nofollow\"><code>env_vars</code></a>,\nwhich controls the environment\
    \ variables used in a job.\nThe syntax to set dictionary items, like for <code>env_vars</code>,\
    \ is a comma-separated list of <code>key:value</code> pairs: <code>-S dict=key_1:value_1,key_2:value_2</code>.\n\
    For example</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S env_vars=OMP_PLACES:threads\n</code></pre>\n<p>runs the <code>benchmarks/apps/sombrero</code>\
    \ benchmark setting the environment variable <code>OMP_PLACES</code>\nto <code>threads</code>.</p>\n\
    <h3 id=\"user-content-selecting-system-and-queue-access-options\"><a class=\"\
    heading-link\" href=\"#selecting-system-and-queue-access-options\">Selecting system\
    \ and queue access options<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<p>The provided ReFrame configuration file contains the settings\
    \ for multiple systems.  If you\nuse it, the automatic detection of the system\
    \ may fail, as some systems may use clashing\nhostnames.  To avoid this, you can\
    \ use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3 id=\"user-content-usage-on-unsupported-systems\"\
    ><a class=\"heading-link\" href=\"#usage-on-unsupported-systems\">Usage on unsupported\
    \ systems<span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a></h3>\n\
    <p>The configuration provided in <a href=\"./reframe_config.py\"><code>reframe_config.py</code></a>\
    \ lets you run the\nbenchmarks on pre-configured HPC systems.  However you\ncan\
    \ use this framework on any system by choosing the \"default\" system with <code>--system\
    \ default</code>, or by using your own ReFrame configuration.  You can use the\
    \ \"default\" system to run\nbenchmarks in ReFrame without using a queue manager\
    \ or an MPI launcher (e.g. on a personal workstation).</p>\n<p>If you choose the\
    \ \"default\" system and a benchmark using the Spack build system,\na new empty\
    \ Spack environment will be automatically created in\n<code>benchmarks/spack/default</code>\
    \ when ReFrame is launched for the first time.\nYou should populate the environment\
    \ with the packages already installed on your system\nbefore running Spack to\
    \ avoid excessively rebuilding system packages. See the\n<em>Spack configuration</em>\
    \ section of <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for\
    \ instructions on how\nto set up a Spack environment.\nIn particular, make sure\
    \ that at least a compiler and an MPI library are added into the environment.\n\
    After the Spack environment is set up, tell ReFrame to use it by setting the environment\n\
    variable <code>EXCALIBUR_SPACK_ENV</code>, as described above.</p>\n<h3 id=\"\
    user-content-system-specific-flags\"><a class=\"heading-link\" href=\"#system-specific-flags\"\
    >System-specific flags<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h3>\n<p>While the aim is to automate as much system-specific configuration\
    \ as possible, there are some options that have to be provided by the user, such\
    \ as accounting details, and unfortunately the syntax can vary.\nThe file <a href=\"\
    ./SYSTEMS.md\"><code>SYSTEMS.md</code></a> contains information about the use\
    \ of this framework on specific systems.</p>\n<h2 id=\"user-content-contributing-new-systems-or-benchmarks\"\
    ><a class=\"heading-link\" href=\"#contributing-new-systems-or-benchmarks\">Contributing\
    \ new systems or benchmarks<span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a></h2>\n<p>Feel free to add new benchmark apps or support new systems\
    \ that are part of the\nExCALIBUR benchmarking collaboration.  Read <a href=\"\
    ./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 10
  subscribers_count: 7
  topics: []
  updated_at: 1694801756.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-38/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: v1.1.0
  stargazers_count: 21
  subscribers_count: 5
  topics:
  - jupyter
  - ipython
  - ipython-widget
  - ipywidget
  - jupyter-notebook
  - jupyterhub
  - notebook
  updated_at: 1686918926.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/lassen/spack.yaml
  - platformFiles/crusher/PrgEnv-cray/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1 id="user-content-useful-supplementary-materials-for-installing-the-xsdk"><a
    class="heading-link" href="#useful-supplementary-materials-for-installing-the-xsdk">Useful
    supplementary materials for installing the xSDK<span aria-hidden="true" class="octicon
    octicon-link"></span></a></h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics: []
  updated_at: 1669065329.0
