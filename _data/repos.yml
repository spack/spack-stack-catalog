2lambda123/CHM:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: 2lambda123/CHM
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-the-canadian-hydrological-model\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-canadian-hydrological-model\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Canadian\
    \ Hydrological Model</h1>\n<p>The Canadian Hydrological Model (CHM) is a novel\
    \ modular unstructured mesh based approach for hydrological modelling. It can\
    \ move between spatial scale, temporal scale, and spatial extents. It is designed\
    \ for developing and testing process representations for hydrological models.</p>\n\
    \n<ul>\n<li><a href=\"#usage\">Usage</a></li>\n<li><a href=\"#motivation\">Motivation</a></li>\n\
    <li><a href=\"#design-goals\">Design goals</a></li>\n<li><a href=\"#publications\"\
    >Publications</a></li>\n<li>\n<a href=\"#features\">Features</a>\n<ul>\n<li><a\
    \ href=\"#spatial-scales\">Spatial Scales</a></li>\n<li><a href=\"#visualization\"\
    >Visualization</a></li>\n<li><a href=\"#netcdf-support\">netCDF support</a></li>\n\
    <li><a href=\"#process-representations\">Process representations</a></li>\n<li><a\
    \ href=\"#unstructured-mesh\">Unstructured mesh</a></li>\n<li><a href=\"#parallel-computing\"\
    >Parallel computing</a></li>\n<li><a href=\"#uncertainty-analysis\">Uncertainty\
    \ analysis</a></li>\n</ul>\n</li>\n<li>\n<a href=\"#demonstration\">Demonstration</a>\n\
    <ul>\n<li><a href=\"#snowcast\">SnowCast</a></li>\n<li><a href=\"#large-extent\"\
    >Large extent</a></li>\n<li><a href=\"#point-scale\">Point scale</a></li>\n<li><a\
    \ href=\"#blowing-snow\">Blowing snow</a></li>\n</ul>\n</li>\n</ul>\n\n<h1><a\
    \ id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Usage</h1>\n<p>Details on how to use CHM, as well as more implimentation\
    \ details, can be found in the <a href=\"https://chm.readthedocs.io/en/dev/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n<h1><a id=\"user-content-motivation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#motivation\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Motivation</h1>\n\
    <p>Modelling of hydrological processes at any scale is hampered by large uncertainties\
    \ in parameters and forcing data, incomplete process representations (the scientific\
    \ conceptualization of a phenomena codified numerically), and arbitrary process\
    \ representation selections and linkages (collectively \u2018model structure\u2019\
    ). There is also consistent difficulty or an inability to easily test and estimate\
    \ the uncertainty due to variations in model structure, parameter values, number\
    \ of parameters, forcing data requirements, and spatial discretization requirements\
    \ (collectively \u2018model complexity\u2019).</p>\n<p>In this work, a new distributed\
    \ model framework is presented that can examine a variety of process representations,\
    \ process linkages and levels of model complexity. Algorithms can be easily interchanged,\
    \ removed, and decoupled while preserving the underlying model framework. Thus,\
    \ uncertainty propagation and subsequent feedbacks within the model structure\
    \ can be quantified. Unstructured meshes represent the spatial heterogeneity of\
    \ surface and sub-surface features in a computationally efficient manner and also\
    \ decreases number of parameters and initial conditions. The parallel architecture\
    \ allows for efficient uncertainty testing of parameter ranges. By utilizing unstructured\
    \ meshes, fewer than 5% of the computational elements of high-resolution structured\
    \ (raster) grids are usually necessary.  This preserves surface and sub-surface\
    \ heterogeneity but results in fewer parameters and initial conditions.</p>\n\
    <h1><a id=\"user-content-design-goals\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#design-goals\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Design goals</h1>\n<ul>\n<li>Multi-scale, multi-physics,\
    \ variable complexity and domain model</li>\n<li>Assessment of model structural,\
    \ parameter, and data uncertainty</li>\n<li>Easily test multiple hypotheses, avoid\
    \ rigid model structures</li>\n<li>Incorporate existing code</li>\n<li>Contribute\
    \ to decision support systems</li>\n</ul>\n<h1><a id=\"user-content-publications\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#publications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Publications</h1>\n\
    <p>The following publications provide an overview of CHM and its capabilities</p>\n\
    <ul>\n<li>V. Vionnet, Marsh, C.B., B. Menounos, S. Gascoin, N.E. Wayand, J. Shea,\
    \ K. Mukherjee, and J.W. Pomeroy. Multi-scale snowdrift-permitting modelling of\
    \ mountain snowpack. The Cryosphere Discussions, 2020:1--43, 2020.</li>\n<li>Marsh,\
    \ C.B., J.W. Pomeroy, and H.S. Wheater. The Canadian Hydrological Model (CHM)\
    \ v1.0: a multi-scale, multi-extent, variable-complexity hydrological model \u2013\
    \ design and overview. Geoscientific Model Development, 13(1):225--247, 2020.</li>\n\
    <li>Marsh, C.B, J. W. Pomeroy, R.J. Spiteri, and H.S Wheater. A Finite Volume\
    \ Blowing Snow Model for Use With Variable Resolution Meshes. Water Resources\
    \ Research, 56(2), 2020.</li>\n<li>Marsh, C.B, R. J. Spiteri, J.W. Pomeroy, and\
    \ H.S. Wheater. Multi-objective unstructured triangular mesh generation for use\
    \ in hydrological and land surface models. Computers &amp; Geosciences, 119:49--67,\
    \ 2018.</li>\n</ul>\n<h1><a id=\"user-content-features\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#features\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Features</h1>\n<h2><a id=\"user-content-spatial-scales\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spatial-scales\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spatial\
    \ Scales</h2>\n<p>CHM is applicable to multiple scales from the basin scale, to\
    \ the provincial/state scale and beyond. It may also be applied at a single point-scale.\n\
    <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-visualization\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#visualization\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Visualization</h2>\n\
    <p>Output is in the vtu file format, allowing for visualization, analysis, and\
    \ timeseries animation in <a href=\"https://www.paraview.org/\" rel=\"nofollow\"\
    >ParaView</a>. Date-time support has been added to ParaView via an filter <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\"\
    ><img src=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\" alt=\"\
    vtk-paraview-datetimefilter\" style=\"max-width: 100%;\"></a>.</p>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-netcdf-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#netcdf-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>netCDF support</h2>\n\
    <p>Input meterology may be either in a standard ASCII file, or as a netCDF file\
    \ allowing for ease of use when using climate model outputs.</p>\n<p>The below\
    \ figure shows virtual stations that correspond to the center of the 2.5 km GEM\
    \ numerical weather prediction output in netCDF format.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-process-representations\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#process-representations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Process\
    \ representations</h2>\n<p>Process represetenation will be extented to include\
    \ the entirety of the hydrological cycle. However, current representation includes\
    \ mostly surface and cold regions processes</p>\n<table>\n<thead>\n<tr>\n<th>Process</th>\n\
    <th>Module</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Canopy</td>\n<td>Open/forest\
    \ (exp/log) (Pomeroy et al., 1998; Ellis et al., 2010)</td>\n</tr>\n<tr>\n<td>Snowpack</td>\n\
    <td>2-layer Snobal (Marks et al, 1999); Multi-layer Snowpack (Lehning et al.,\
    \ 1999); Various albedo e.g., CLASS (Verseghy 1991)</td>\n</tr>\n<tr>\n<td>Soil</td>\n\
    <td>Frozen soil infiltration (Gray et al., 2001)</td>\n</tr>\n<tr>\n<td>Mass redistribution</td>\n\
    <td>PBSM3D (Marsh et al, 2018 in review); Snowslide (Bernhardt 2010)</td>\n</tr>\n\
    </tbody>\n</table>\n<p>Input meterology is spatially interpolated and down-scaled\
    \ from the input station or virtual-station (e.g., from numerical weather prediction)\
    \ to produce a spatially distributed driving dataset. There are a number of ways\
    \ to downscale these meterology.</p>\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n\
    <th>Type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Air temperature</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant, neutral stability) (Kunkel, 1989,\
    \ Dodson et al., 1997)</td>\n</tr>\n<tr>\n<td>Relative humidity</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant) (Kunkel, 1989)</td>\n</tr>\n<tr>\n\
    <td>Horizontal wind</td>\n<td>Topographic curvature (Liston, et al., 2006); Mason-Sykes\
    \ (Mason and Sykes, 1979); uniform wind</td>\n</tr>\n<tr>\n<td>Precipitation</td>\n\
    <td>Elevation based lapse (Thornton, 1997)</td>\n</tr>\n<tr>\n<td>Precipitation\
    \ Phase</td>\n<td>Linear; Psychometric (Harder and Pomeroy, 2013); Threshold</td>\n\
    </tr>\n<tr>\n<td>Solar radiation</td>\n<td>Terrain shadows (Marsh et al., 2011,\
    \ Dozier and Frew, 1990); Clear sky transmittance (Burridge, 1975); Transmittance\
    \ from observations; Cloud fraction estimates (Walcek, 1994); Direct/diffuse splitting\
    \ (Iqbal, 19xx)</td>\n</tr>\n<tr>\n<td>Longwave</td>\n<td>T, RH based (Sicart\
    \ et al., 2006); Constant (Marty et al., 2002)</td>\n</tr>\n</tbody>\n</table>\n\
    <h2><a id=\"user-content-unstructured-mesh\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#unstructured-mesh\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Unstructured mesh</h2>\n<p>CHM uses an unstructured\
    \ triangular mesh to representent the terrain. This mesh is generated by <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/mesher\"\
    ><img src=\"https://github.com/Chrismarsh/mesher\" alt=\"Mesher\" style=\"max-width:\
    \ 100%;\"></a>, a novel multi-objective unstructured mesh generation software\
    \ that allows mesh generation to be generated from an arbitrary number of hydrologically\
    \ important features while maintaining a variable spatial resolution. Triangle\
    \ quality is guaranteed as well as a smooth graduation from small to large triangles.\
    \ Including these additional features resulted in a better representation of spatial\
    \ heterogeneity versus classic topography-only mesh generation while significantly\
    \ reducing the total number of computational elements.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-parallel-computing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#parallel-computing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Parallel\
    \ computing</h2>\n<p>In CHM, parallelism is currently implemented via the shared\
    \ memory API OpenMP. As described above, modules may either be point-scale models\
    \ that are applied to each triangle independently or require knowledge of the\
    \ surrounding triangles. Mixing these two types of parallelism complicates the\
    \ implementation of parallel code. To provide as much seamless parallelism as\
    \ possible to the modules, each module declares the type of algorithm it is: data\
    \ parallel or domain parallel. Data parallel modules are point-scale models that\
    \ are applied to every triangle. Domain parallel modules are modules that require\
    \ knowledge of surrounding mesh points. Thus, after the topological sort is performed\
    \ to determine module execution order, the modules are scheduled together into\
    \ groups that share a parallelism type</p>\n<h2><a id=\"user-content-uncertainty-analysis\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#uncertainty-analysis\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Uncertainty\
    \ analysis</h2>\n<p>A key feature of CHM is the ability to, on the command line,\
    \ change any value specified by a configuration parameter. CHM provides a seamless\
    \ mechanism to easily allow modules to obtain parameter data from configuration\
    \ files.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"\
    pl-k\">import</span> <span class=\"pl-s1\">subprocess</span>\n<span class=\"pl-k\"\
    >import</span> <span class=\"pl-s1\">shutil</span>\n\n\n<span class=\"pl-s1\"\
    >prj_path</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"CHM.config\"\
    </span>\n\n<span class=\"pl-s1\">cf1</span> <span class=\"pl-c1\">=</span> <span\
    \ class=\"pl-s\">\"-c output.VistaView.file:vv_dodson.txt\"</span>\n<span class=\"\
    pl-s1\">cf2</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"-c output.UpperClearing.file:uc_dodson.txt\"\
    </span>\n<span class=\"pl-s1\">cf3</span> <span class=\"pl-c1\">=</span> <span\
    \ class=\"pl-s\">\"-c output.FiserraRidge.file:fr_dodson.txt\"</span>\n<span class=\"\
    pl-s1\">cf4</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"--add-module\
    \ Dodson_NSA_ta\"</span>\n<span class=\"pl-s1\">subprocess</span>.<span class=\"\
    pl-en\">check_call</span>([<span class=\"pl-s\">'./CHM %s %s %s %s %s'</span>\
    \ <span class=\"pl-c1\">%</span> (<span class=\"pl-s1\">prj_path</span>, <span\
    \ class=\"pl-s1\">cf1</span>, <span class=\"pl-s1\">cf2</span>, <span class=\"\
    pl-s1\">cf3</span>,<span class=\"pl-s1\">cf4</span>)], <span class=\"pl-s1\">shell</span><span\
    \ class=\"pl-c1\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<h1><a\
    \ id=\"user-content-demonstration\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#demonstration\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Demonstration</h1>\n<h2><a id=\"user-content-snowcast\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#snowcast\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>SnowCast</h2>\n<p><a href=\"\
    http://www.snowcast.ca\" rel=\"nofollow\">SnowCast</a> is an experimental, daily\
    \ data product that uses the Global Environmental Multiscale (GEM) model forecasts\
    \ from Environment and Climate Change Canada (ECCC) to drive the Canadian Hydrological\
    \ Model (CHM). Estimates of snowpack are provided over the a Bow River Basin,\
    \ centered over Banff, Canada.</p>\n<p>SnowCast is developed as part of <a href=\"\
    https://gwf.usask.ca/\" rel=\"nofollow\">Global Water Futures</a> and the <a href=\"\
    https://www.usask.ca/hydrology/\" rel=\"nofollow\">Centre for Hydrology</a>, University\
    \ of Saskatchewan.</p>\n<h2><a id=\"user-content-large-extent\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#large-extent\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Large extent</h2>\n<p>Hourly\
    \ solar radiation modelling for the territory of Yukon, Canada.\n<a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-point-scale\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#point-scale\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Point scale</h2>\n\
    <p>Comparison of CHM driving Snobal and Snowpack at the Upper Clearing site at\
    \ Marmot Creek Research Basin in Alberta, Canada\n<a target=\"_blank\" rel=\"\
    noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-blowing-snow\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#blowing-snow\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Blowing\
    \ snow</h2>\n<p>Blowing snow for a small sub-basin of Wolf Creek Reserach Basin,\
    \ located in the Yukon, Canada.\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1701550455.0
AMReX-Codes/pyamrex:
  data_format: 2
  description: GPU-Enabled, Zero-Copy AMReX Python Bindings including AI/ML
  filenames:
  - docs/spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: '24.02'
  readme: '<h1><a id="user-content-pyamrex" class="anchor" aria-hidden="true" tabindex="-1"
    href="#pyamrex"><span aria-hidden="true" class="octicon octicon-link"></span></a>pyAMReX</h1>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/e751dc39d18bc7613b561655f2f3551a2c999fc64fb85aeda826e0351492e168/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e"><img
    src="https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e"
    alt="Python3 API: Beta" title="Status: Beta" data-canonical-src="https://img.shields.io/badge/phase-beta-yellowgreen"
    style="max-width: 100%;"></a>

    <a href="https://pyamrex.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/a72575f4cba18887d71f6084dbe806f54cb6f8be5eedbb5e542adbb89e81e956/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7079616d7265782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/pyamrex/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://github.com/AMReX-Codes/pyamrex/discussions"><img src="https://camo.githubusercontent.com/1160c9b83b0d3a01df9f7384cf556f0cc92a304b6496afd616efe2ca068089b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667"
    alt="Discussions" data-canonical-src="https://img.shields.io/badge/chat-discussions-turquoise.svg"
    style="max-width: 100%;"></a><br>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    alt="linux" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    alt="macos" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    alt="windows" style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License pyAMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.8408733" rel="nofollow"><img src="https://camo.githubusercontent.com/cd9d78571166339d2799568898526d14004a42389158e25e813c645cfef06db3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e383430383733332d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.8408733-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>The Python binding pyAMReX bridges the compute in AMReX block-structured codes
    and data science:

    it provides zero-copy application GPU data access for AI/ML, in situ analysis,
    application coupling and enables rapid, massively parallel prototyping.

    pyAMReX enhances the <a href="https://amrex-codes.github.io" rel="nofollow">Block-Structured
    AMR Software Framework AMReX</a> and its applications.</p>

    <h2><a id="user-content-users" class="anchor" aria-hidden="true" tabindex="-1"
    href="#users"><span aria-hidden="true" class="octicon octicon-link"></span></a>Users</h2>

    <p>pyAMReX <a href="https://pyamrex.readthedocs.io/en/latest/install/users.html"
    rel="nofollow">can be installed</a> with package managers or from source.</p>

    <h3><a id="user-content-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h3>

    <p>Please see the <a href="https://pyamrex.readthedocs.io/en/latest/usage/how_to_run.html"
    rel="nofollow">manual</a> and our <a href="https://github.com/AMReX-Codes/pyamrex/tree/development/tests">test
    cases</a> for detailed examples.</p>

    <p>Use AMReX objects and APIs from Python:</p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>.<span class="pl-s1">space3d</span> <span class="pl-k">as</span>
    <span class="pl-s1">amr</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">IntVect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">IntVect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amr</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <h2><a id="user-content-developers" class="anchor" aria-hidden="true" tabindex="-1"
    href="#developers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Developers</h2>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <h3><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B17" rel="nofollow">C++17</a>
    compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.20.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.11.1+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.8+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://mpi4py.readthedocs.io" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (for
    CUDA support, needs 3.7.9+ and 4.2+ is recommended)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://pandas.pydata.org/" rel="nofollow">pandas</a> 2+: for DataFrame
    support</li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <p>Optional CUDA-capable dependencies for tests include:</p>

    <ul>

    <li>

    <a href="https://github.com/cupy/cupy#installation">cupy</a> 11.2+</li>

    <li>

    <a href="https://numba.readthedocs.io/en/stable/user/installing.html" rel="nofollow">numba</a>
    0.56+</li>

    <li>

    <a href="https://pytorch.org/get-started/locally/" rel="nofollow">torch</a> 1.12+</li>

    </ul>

    <h3><a id="user-content-install-dependencies" class="anchor" aria-hidden="true"
    tabindex="-1" href="#install-dependencies"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Install Dependencies</h3>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.20.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pip

    python3 -m pip install -U build packaging setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <p>Some of our tests depend on optional third-party modules (e.g., <code>pandas</code>,
    <code>cupy</code>, <code>numba</code>, and/or <code>pytorch</code>).

    If these are not installed then their tests will be skipped.</p>

    <h3><a id="user-content-configure-your-compiler" class="anchor" aria-hidden="true"
    tabindex="-1" href="#configure-your-compiler"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Configure your compiler</h3>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    python3 -m pip install -U -r requirements.txt

    python3 -m pip install -v --force-reinstall --no-deps <span class="pl-c1">.</span></pre></div>

    <p>If you are iterating on builds, it will faster to rely on <code>ccache</code>
    and to let CMake call the <code>pip</code> install logic:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build -DAMReX_SPACEDIM=<span class="pl-s"><span class="pl-pds">"</span>1;2;3<span
    class="pl-pds">"</span></span>

    cmake --build build --target pip_install -j 8</pre></div>

    <h3><a id="user-content-test" class="anchor" aria-hidden="true" tabindex="-1"
    href="#test"><span aria-hidden="true" class="octicon octicon-link"></span></a>Test</h3>

    <p>After successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests</span>

    python3 -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python3 -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python3 -m pytest tests/test_intvect.py::test_iv_conversions


    <span class="pl-c"><span class="pl-c">#</span> Run all tests, do not capture "print"
    output and be verbose</span>

    python3 -m pytest -s -vvvv tests/</pre></div>

    <h3><a id="user-content-build-options" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build-options"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Options</h3>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>"1;2;3"</td>

    <td>Dimension(s) of AMReX as a <code>;</code>-separated list</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>PYBIND11_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    <tr>

    <td><code>PYAMREX_LIBDIR</code></td>

    <td><em>None</em></td>

    <td>If set, search for pre-built a pyAMReX library</td>

    </tr>

    <tr>

    <td><code>PYAMREX_IPO</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Compile with interprocedural/link optimization (IPO/LTO)</td>

    </tr>

    <tr>

    <td><code>PYINSTALLOPTIONS</code></td>

    <td><em>None</em></td>

    <td>Additional options for <code>pip install</code>, e.g., <code>-v --user</code>

    </td>

    </tr>

    </tbody>

    </table>

    <p>Furthermore, pyAMReX adds a few selected CMake build options:</p>

    <table>

    <thead>

    <tr>

    <th>CMake Option</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMReX_SPACEDIM</code></td>

    <td>

    <strong>3</strong>, use <code>"1;2;3"</code> for all</td>

    <td>Dimension(s) of AMReX as a <code>;</code>-separated list</td>

    </tr>

    <tr>

    <td><code>pyAMReX_IPO</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Compile with interprocedural/link optimization (IPO/LTO)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_INSTALL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Enable install targets for pyAMReX</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_src</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_internal</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_repo</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>pyAMReX_amrex_branch</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>pyAMReX_amrex_repo</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_src</code></td>

    <td><em>None</em></td>

    <td>Absolute path to pybind11 source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_internal</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_repo</code></td>

    <td><code>https://github.com/pybind/pybind11.git</code></td>

    <td>Repository URI to pull and build pybind11 from</td>

    </tr>

    <tr>

    <td><code>pyAMReX_pybind11_branch</code></td>

    <td><code>v2.11.1</code></td>

    <td>Repository branch for <code>pyAMReX_pybind11_repo</code>

    </td>

    </tr>

    <tr>

    <td><code>Python_EXECUTABLE</code></td>

    <td>(newest found)</td>

    <td>Path to Python executable</td>

    </tr>

    </tbody>

    </table>

    <p>As one example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" tabindex="-1"
    href="#acknowledgements"><span aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgements</h2>

    <p>This work was supported by the Laboratory Directed Research and Development
    Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy
    Contract No. DE-AC02-05CH11231.</p>

    <h2><a id="user-content-copyright-notice" class="anchor" aria-hidden="true" tabindex="-1"
    href="#copyright-notice"><span aria-hidden="true" class="octicon octicon-link"></span></a>Copyright
    Notice</h2>

    <p>pyAMReX Copyright (c) 2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory, National Renewable Energy

    Laboratory Alliance for Sustainable Energy, LLC and Lawrence Livermore

    National Security, LLC (subject to receipt of any required approvals from the
    U.S.

    Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Intellectual Property Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights.  As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit others to do so.</p>

    <p>License for pyamrex can be found at <a href="LICENSE">LICENSE</a>.</p>

    '
  stargazers_count: 28
  subscribers_count: 16
  topics:
  - amrex
  - python
  updated_at: 1707025082.0
AMReX-Microelectronics/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  - Docs/spack.yaml
  full_name: AMReX-Microelectronics/artemis
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" tabindex="-1"
    href="#artemis"><span aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    '
  stargazers_count: 10
  subscribers_count: 5
  topics: []
  updated_at: 1696392722.0
AMReX-Microelectronics/artemis_bakup:
  data_format: 2
  description: null
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis_bakup
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" tabindex="-1"
    href="#artemis"><span aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a code
    for modeling micromagnetics and electrodynamic waves in next-generation microelectornics.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/92c92f18fa93aab19301f6c1d609d4dbba6d2833f441adfc8aba95635e8a1186/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/d8faa5dd5c10a3a416f5b36feb83f7d0b22a040a13c4becf398c5660b4c94ccb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/532de0ea13712920c2b2f644fe425c87090486691a9b3de2bdc0a121552707ad/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/68712ecce18e982a6a11d855fdcb3fd647bee2a05e6e550581d66f1c78e58b89/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/4c0961a0bcc2c026f3f3a20ea7dbd4f24c13f21991a145baf86385a18d2c408a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/fe112996993c23975e07c48ba70423ea5c9b716b2d60fbdcd8dfa620bd282ec3/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/c6a0dd9275b2fd160addee7f2d74ef088bb97a1598c29eab5bee1e9f153ae44a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/27d0f337e406f972927563ea93742777c7ce42cd1e4f5d204f9aa14b4e2e52d6/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/a0f2432f4678daa26dd446599ac3b93b3f25aa44d69c4d5e7db4fced70fe7a34/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/648674b11909d214d16a356f6a8c4f7d7d5578185f95afcc4e23327c5e4cff63/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1688585950.0
Alpine-DAV/spack_configs:
  data_format: 2
  description: spack envs
  filenames:
  - _experimental/envs/alpinedav/ubuntu_18_cuda_10.1_devel/spack.yaml
  - _experimental/envs/alpinedav/ubuntu_18_devel/spack.yaml
  full_name: Alpine-DAV/spack_configs
  latest_release: null
  readme: '<h1><a id="user-content-spack_configs" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack_configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack_configs</h1>

    <p>shared spack configs repo</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1639176281.0
C2SM/spack-c2sm:
  data_format: 2
  description: Repository for c2sm spack config and repo files
  filenames:
  - upstreams/daint/icon-dsl/spack.yaml
  full_name: C2SM/spack-c2sm
  latest_release: v0.20.1.5
  readme: '<h1><a id="user-content-the-spack-extension-of-c2sm-and-mch" class="anchor"
    aria-hidden="true" tabindex="-1" href="#the-spack-extension-of-c2sm-and-mch"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>The spack extension
    of C2SM and MCH</h1>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/3c31b5169516720383f9b49508fd95cfc457c5907282d9b1001af3280dc35326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616e7369636f6c6f72746167732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/ansicolortags/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is the package manager used by C2SM and MeteoSwiss to install and deploy
    software on supercomputers, local machines and the cloud.</p>

    <h2><a id="user-content-documentations" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentations</h2>

    <p><strong>Infos about c2sm-supported software and machines</strong></p>

    <ul>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/latest" rel="nofollow">spack-c2sm
    latest</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.4" rel="nofollow">spack-c2sm
    v0.20.1.4</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.3" rel="nofollow">spack-c2sm
    v0.20.1.3</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.20.1.0" rel="nofollow">spack-c2sm
    v0.20.1.0</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.12" rel="nofollow">spack-c2sm
    v0.18.1.12</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.10" rel="nofollow">spack-c2sm
    v0.18.1.10</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.9" rel="nofollow">spack-c2sm
    v0.18.1.9</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.8" rel="nofollow">spack-c2sm
    v0.18.1.8</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.7" rel="nofollow">spack-c2sm
    v0.18.1.7</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.6" rel="nofollow">spack-c2sm
    v0.18.1.6</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.5" rel="nofollow">spack-c2sm
    v0.18.1.5</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.4" rel="nofollow">spack-c2sm
    v0.18.1.4</a></p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.3" rel="nofollow">spack-c2sm
    v0.18.1.3</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.2" rel="nofollow">spack-c2sm
    v0.18.1.2</a> [deprecated]</p>

    </li>

    <li>

    <p><a href="https://C2SM.github.io/spack-c2sm/v0.18.1.1" rel="nofollow">spack-c2sm
    v0.18.1.1</a> [deprecated]</p>

    </li>

    </ul>

    <p><strong>General infos about spack</strong></p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/v0.20.1/" rel="nofollow">Official
    spack v0.20.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/v0.18.1/" rel="nofollow">Official
    spack v0.18.1</a></li>

    </ul>

    <h2><a id="user-content-workflow" class="anchor" aria-hidden="true" tabindex="-1"
    href="#workflow"><span aria-hidden="true" class="octicon octicon-link"></span></a>Workflow</h2>

    <p>With spack v0.18 we suggest local/individual spack instances and the use of
    spack environments.</p>

    <p>A user clones the spack repo</p>

    <div class="highlight highlight-source-shell"><pre>git clone --depth 1 --recurse-submodules
    --shallow-submodules -b v0.20.1.5 https://github.com/C2SM/spack-c2sm.git</pre></div>

    <p>gets spack in the command line</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">.</span>
    spack-c2sm/setup-env.sh</pre></div>

    <p>activates an environment</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate <span class="pl-k">&lt;</span>path_to_env<span
    class="pl-k">&gt;</span></pre></div>

    <p>and starts exploring</p>

    <div class="highlight highlight-source-shell"><pre>spack info <span class="pl-k">&lt;</span>package<span
    class="pl-k">&gt;</span>

    spack spec <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>and building</p>

    <div class="highlight highlight-source-shell"><pre>spack install <span class="pl-k">&lt;</span>spec<span
    class="pl-k">&gt;</span>

    spack dev-build <span class="pl-k">&lt;</span>spec<span class="pl-k">&gt;</span></pre></div>

    <p>a package.</p>

    <p>Updating spack-c2sm is in the hands of the user.</p>

    <div class="highlight highlight-source-shell"><pre>git pull

    git submodule update --recursive</pre></div>

    <p>After an update we advice to clean</p>

    <div class="highlight highlight-source-shell"><pre>spack uninstall -a

    spack clean -a

    rm -rf <span class="pl-k">~</span>/.spack</pre></div>

    <p>and rebuild.</p>

    <h2><a id="user-content-command-cheat-sheet" class="anchor" aria-hidden="true"
    tabindex="-1" href="#command-cheat-sheet"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Command cheat sheet</h2>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Clone</td>

    <td><code>git clone --depth 1 --recurse-submodules --shallow-submodules -b &lt;branch/tag&gt;
    https://github.com/C2SM/spack-c2sm.git</code></td>

    </tr>

    <tr>

    <td>Load</td>

    <td>

    <code>. spack-c2sm/setup-env.sh</code> autodetects machine <br>or<br><code>. spack-c2sm/setup-env.sh
    &lt;machine&gt;</code> forces machine<br>or<br><code>. spack-c2sm/setup-env.sh
    unknown</code> uses blank config<br><code>spack compiler find</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-compiler-find"
    rel="nofollow">autodetects compilers</a><br><code>spack external find --all</code>
    <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-external-find"
    rel="nofollow">autodetects externally installed packages</a>

    </td>

    </tr>

    <tr>

    <td>Update</td>

    <td>

    <code>git pull</code><br><code>git submodule update --recursive</code>

    </td>

    </tr>

    <tr>

    <td>Clean</td>

    <td>

    <code>spack uninstall -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-uninstall"
    rel="nofollow">uninstalls all packages</a><br><code>spack clean -a</code> <a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-clean"
    rel="nofollow">cleans all misc caches</a><br><code>rm -rf ~/.spack</code> removes
    user scope data</td>

    </tr>

    </tbody>

    </table>

    <p><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><strong>Spec syntax</strong></a>: <code>&lt;package&gt;</code><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#version-specifier"
    rel="nofollow"><code>@&lt;version&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-specifier"
    rel="nofollow"><code>%&lt;compiler&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#variants"
    rel="nofollow"><code>+&lt;variant&gt; ~&lt;variant&gt;</code></a><a href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies"
    rel="nofollow"><code>^&lt;sub-package&gt; +&lt;sub-package-variant&gt;</code></a><a
    href="https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-flags"
    rel="nofollow"><code>&lt;compiler flags&gt;</code></a></p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>Command</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Find</td>

    <td>

    <code>spack find</code> lists all installed packages. <br><code>spack find &lt;spec&gt;</code>
    lists all installed packages that match the spec.</td>

    </tr>

    <tr>

    <td>Info</td>

    <td><code>spack info &lt;package&gt;</code></td>

    </tr>

    <tr>

    <td>Spec</td>

    <td>

    <code>spack spec &lt;spec&gt;</code> concretizes abstract spec (unspecfied variant
    = <strong>any</strong>)<br><em>Spack is not required to use the default of an
    unspecified variant. The default value is only a tiebreaker for the concretizer.</em>

    </td>

    </tr>

    <tr>

    <td>Install</td>

    <td><code>spack install &lt;spec&gt;</code></td>

    </tr>

    <tr>

    <td>Locate</td>

    <td>

    <code>spack location --install-dir &lt;spec&gt;</code> prints location of <strong>all</strong>
    installs that satisfy the spec</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-load"
    rel="nofollow">Load env</a></td>

    <td>

    <code>spack load &lt;spec&gt;</code> loads run environment</td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Activate
    env</a></td>

    <td><code>spack env activate &lt;env_name&gt;</code></td>

    </tr>

    <tr>

    <td><a href="https://spack.readthedocs.io/en/v0.18.1/environments.html" rel="nofollow">Deactivate
    env</a></td>

    <td><code>spack deactivate</code></td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 7
  subscribers_count: 19
  topics: []
  updated_at: 1703137382.0
CHIP-SPV/chipStar-Spack:
  data_format: 2
  description: Support for building chipStar and related libraries via Spack
  filenames:
  - Environments/LevelZero/spack.yaml
  full_name: CHIP-SPV/chipStar-Spack
  latest_release: null
  readme: '

    <h1><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h1>

    <p><a href="https://github.com/CHIP-SPV/chipStar">chipStar</a> (formerly CHIP-SPV)

    is software that allows software written to use the

    <a href="https://https://github.com/ROCm-Developer-Tools/HIP" rel="nofollow">Heterogeneous-compute
    Interface for Portability

    (HIP)</a>

    interface and kernel language to target GPUs via the

    <a href="https://registry.khronos.org/spir" rel="nofollow">SPIR-V</a> intermediate
    language.

    chipStar can use either the Intel Level Zero runtime or an OpenCL

    runtime as a backend.</p>

    <p>This repository contains support for building chipStar and its

    dependencies via the <a href="https://github.com/spack/spack">Spack</a> package

    manager.</p>

    <p>Note: most development to date has been done with the Level Zero

    environment, and it is expected that substantial work is needed for

    the environment targeting the OpenCL backend to work.</p>

    <h1><a id="user-content-prerequisites" class="anchor" aria-hidden="true" tabindex="-1"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h1>

    <ul>

    <li>An x86_64 system running a common Linux distribution.  OpenSLES 15 is

    the best tested to date.</li>

    <li>A working Spack installation.</li>

    <li>A recent Clang installation that is registered with Spack as a compiler.

    Versions 15 and 16 are best tested, but 14 might work.  We suggest

    installing the compiler via Spack (i.e., by installing something like

    <code>llvm@16.0.2</code> and then using <code>spack compiler add</code> with the
    llvm

    package''s install location), because the <code>chipstar</code> package defined

    in this repository depends on the <code>llvm</code> package anyway.</li>

    <li>A recent (at least version 2023.1) Intel OneAPI compiler installation

    that is registered with Spack as a compiler.  The recommended way

    of doing this is by installing the Spack <code>intel-oneapi-compilers</code>

    package, then registering the location of its compilers with Spack.

    E.g.,</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>$ spack install intel-oneapi-compilers@2023

    $ spack compiler add <span class="pl-s"><span class="pl-pds">$(</span>spack location
    -i intel-oneapi-compilers@2023<span class="pl-pds">)</span></span>/compiler/latest/linux</pre></div>

    <h1><a id="user-content-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h1>

    <ol start="0">

    <li>Clone this repository to the target system.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ git clone https://github.com/CHIP-SPV/CHIP-SPV-Spack</pre></div>

    <ol start="2">

    <li>Activate the environment you want to build.  E.g., for the

    environment that just builds chipStar with Level Zero backend:</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ <span class="pl-c1">cd</span>
    CHIP-SPV-Spack/Environments/LevelZero

    $ spack env activate <span class="pl-c1">.</span></pre></div>

    <ol start="3">

    <li>Concretize the active environment.  (In Spack terminology,

    "to concretize" means to let Spack examine the package specifications

    it has been asked to build, plus the available package repositories,

    resolve dependencies and check constraints, and decide exactly which

    packages it will build, in which order, and with which configuration.)</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack concretize -f -U</pre></div>

    <p>We suggest examining the output from running the <code>spack concretize</code>

    command to make sure that Spack''s concretizer has truly decided to

    use the configuration options and especially the compilers that you

    want it to use.  Note that the environment and related configuration

    are purposefully not overly constrained to use the given compiler

    for every dependency package, so even though there are some packages

    that must be built with <code>%clang</code>, there are others that may be

    built (or re-used from already-installed packages) using <code>%gcc</code> such

    as the system''s GCC installation.</p>

    <p>If Spack''s concretizer  didn''t do what you want, you can re-concretize

    the environment and be more explicit about what you want using command-line

    configuration options (recommended) or by editing the environment''s

    <code>spack.yaml</code> file or other configuration options that your Spack installation

    is using.  (Use <code>spack config blame</code> to see which configuration files
    Spack is

    using.)  For instance, if you have both <code>clang@16.0.2</code> and <code>clang@15.0.7</code>

    installed and registered as Spack compilers, and you want to build

    using <code>clang@15.0.7</code>, you may have to use a concretize command like
    the

    following:</p>

    <div class="highlight highlight-source-shell"><pre>$ spack -c <span class="pl-s"><span
    class="pl-pds">"</span>packages:chipstar:require:''%clang@15.0.7''<span class="pl-pds">"</span></span>
    concretize -f -U</pre></div>

    <p>As before, verify from the output of the <code>spack concretize</code> command
    that it

    is using the compiler version you want, <code>clang@15.0.7</code> in this example.</p>

    <ol start="4">

    <li>Build the environment.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack install</pre></div>

    <p>Spack supports some options for controlling the build and installation,

    such as <code>-j</code> to limit the number of processes used for parallel builds,

    useful for being a good citizen on shared systems by not allowing Spack

    to use all available cores (its default).  See the Spack documentation for

    more information.</p>

    <p>Assuming all goes well with the build and install, a <code>spack find</code>

    should show the packages that you just built.</p>

    <ol start="5">

    <li>Use the installed software.  There are several ways you might

    update your environment to use the software, including:</li>

    </ol>

    <ul>

    <li><code>spack load chipstar</code></li>

    <li>Activating the environment that you used to build the software</li>

    <li>If your Spack configuration is such that it can generate module files

    and module files have been generated for the software you built

    via this environment, <code>module load chipstar</code>

    </li>

    </ul>

    <p>Note that you may need to modify your environment to be able to run

    programs produced using chipStar and the H4I libraries built

    using this Spack repository.  For instance, on some systems,

    one must load the <code>intel_compute_runtime</code> module before being

    able to run programs that use the Intel Level Zero runtime.</p>

    <h1><a id="user-content-todo" class="anchor" aria-hidden="true" tabindex="-1"
    href="#todo"><span aria-hidden="true" class="octicon octicon-link"></span></a>TODO</h1>

    <ul>

    <li>Clean up and verify the OpenCL-based environment.</li>

    <li>Ensure the OpenCL-based environment can use any OpenCL implementation.</li>

    <li>Incorporate H4I HIP libraries like H4I-HipBLAS into an environments.</li>

    <li>Support using the software installed by the environment via

    <code>module</code> command.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1687550793.0
CODARcode/z-checker-installer:
  data_format: 2
  description: one-key installation to install gnuplot, sz, zfp, and z-checker, and
    complete the configuration automatically for the testing.
  filenames:
  - libpressio-opt/spack.yaml
  full_name: CODARcode/z-checker-installer
  latest_release: 0.8.0
  readme: '<h1><a id="user-content-z-checker-installer" class="anchor" aria-hidden="true"
    tabindex="-1" href="#z-checker-installer"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Z-checker installer</h1>

    <p>(C) 2017-2021 by Mathematics and Computer Science (MCS), Argonne National Laboratory.</p>

    <p>See COPYRIGHT in top-level directory.</p>

    <p>Major authors: Sheng Di, Dingwen Tao, Hanqi Guo

    Other contributors: Robert Underwood, Hengzhi Chen</p>

    <h2><a id="user-content-3rd-party-librariestools" class="anchor" aria-hidden="true"
    tabindex="-1" href="#3rd-party-librariestools"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>3rd party libraries/tools</h2>

    <ul>

    <li>cmake (version: 3.13+)</li>

    <li>gcc (version: 7.3+)</li>

    <li>g++</li>

    <li>git</li>

    <li>curl</li>

    <li>texlive (e.g., execute ''sudo yum install texlive-*'' on linux)</li>

    <li>ghostscript(gsview) (z-checker-install.sh can install it automatically if
    missing)</li>

    <li>latexmk (z-checker-install.sh will install latexmk automatically if missing)</li>

    <li>gnuplot (z-checker-install.sh will install gnuplot automatically if missing)</li>

    <li>perl (used by only web-visualization support)</li>

    </ul>

    <p>Note: if you install only texlive (e.g., sudo yum install texlive), then you
    also need to install latex packages ''comment.sty'', ''subfigure.sty'', ''nopageno.sty''
    and ''morefloats.sty'' by running ''sudo yum -y install "tex(${latexpkg})"'' (e.g.,
    sudo yum -y install "tex(comment.sty)")</p>

    <p>The following libraries - libpng, tif22pnm and sam2p are used to convert slice
    image png files to eps. If plotSliceImag option is disabled (in zc.config), these
    three libraries are not needed.</p>

    <ul>

    <li>libpng (z-checker-install.sh will install tif22pnm automatically if missing;
    in fact, libpng can be installed using system installation command such as ''yum
    install libpng-devel'' on linux.)</li>

    <li>tif22pnm (z-checker-install.sh will install tif22pnm automatically if missing)</li>

    <li>sam2p (z-checker-install.sh will install sam2p automatically if missing)</li>

    </ul>

    <p>For simplicity,

    the Fedora users need to run the following command for installation:</p>

    <div class="highlight highlight-source-shell"><pre>sudo dnf install -y gcc gcc-c++
    git cmake zlib-devel libzstd-devel gfortran which xorg-x11-server-Xorg gnuplot
    libpng-devel findutils unzip latexmk texlive-<span class="pl-k">*</span>

    <span class="pl-k">&lt;</span><span class="pl-k">!</span>-- required texlive package:
    <span class="pl-s"><span class="pl-pds">"</span>tex(comment.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(pifont.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(natbib.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(amsmath.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(morefloats.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(geometry.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(nopageno.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(subfigure.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(enumitem.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(morefloats.sty)<span class="pl-pds">"</span></span>--<span
    class="pl-k">&gt;</span>

    git clone http://github.com/CODARcode/z-checker-installer

    <span class="pl-c1">cd</span> z-checker-installer

    ./z-checker-install.sh</pre></div>

    <p>the Ubuntu users need to run the following command for installation:</p>

    <div class="highlight highlight-source-shell"><pre>sudo sudo apt-get install -y
    gcc g++ git cmake zlib-devel gfortran gnuplot libpng-devel xorg openbox findutils
    unzip latexmk texlive-full texlive-fonts-recommends --no-install-recommends

    git clone http://github.com/CODARcode/z-checker-installer

    <span class="pl-c1">cd</span> z-checker-installer

    ./z-checker-install.sh</pre></div>

    <h2><a id="user-content-testinginstallation-method" class="anchor" aria-hidden="true"
    tabindex="-1" href="#testinginstallation-method"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Testing/Installation method</h2>

    <p>z-checker-install.sh will download latexmk, gnuplot, Z-checker, ZFP, and SZ
    and install them one by one automatically, and then add the patches to let ZFP
    and SZ fit for Z-checker.</p>

    <p>After installation, please download the two testing data sets, CESM-ATM and
    MD-simulation (exaalt). The two data sets are available only for the purpose of
    research of compression. Please ask for the data by contacting <a href="">sdi1@anl.gov</a>
    if interested.</p>

    <p>LibpressioOPT is a library that is able to search for the appropriate error
    bound setting based on user-sepcified metric values such as compression ratio
    and PSNR. Z-checker itself has some simple built-in algorithms to do this work,
    which may not be as accurate as LibpressioOPT. To this end, you also need to install
    spack and use spack to install some preliminary libraries. For more details, please
    read the z-checker-installer-instruction.pdf in the ./doc/ directory. If you don''t
    need LibpressioOPT, you just need to run ''./z-checker-installer.sh'' to install
    everything.</p>

    <h3><a id="user-content-quick-start" class="anchor" aria-hidden="true" tabindex="-1"
    href="#quick-start"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quick
    Start</h3>

    <p>Then, you are ready to conduct the compression checking.

    You can generate compression results with SZ and ZFP using the following simple
    steps:

    (Note: you have to run z-checker-install.sh to install the software before doing
    the following tests)</p>

    <ol>

    <li>

    <p>Configure the error bound setting and comparison cases in errBounds.cfg.</p>

    </li>

    <li>

    <p>Create a new test-case, by executing "createZCCase.sh [test-case-name]". You
    need to replace [test-case-name] by a meaningful name.

    For example:

    [user@localhost z-checker-installer] ./createZCCase.sh CESM-ATM-tylor-data</p>

    </li>

    <li>

    <p>Perform the checking by running the command "runZCCase.sh": runZCCase.sh [data_type]
    [error-bound-mode] [test-case-name] [data dir] [extension] [dimensions....].

    Example:

    [user@localhost z-checker-installer] ./runZCCase.sh -f REL CESM-ATM-tylor-data
    /home/shdi/CESM-testdata/1800x3600 dat 3600 1800</p>

    </li>

    </ol>

    <p>Then, you can find the report generated in z-checker-installer/Z-checker/[test-case-name]/report.</p>

    <h3><a id="user-content-step-by-step-checking" class="anchor" aria-hidden="true"
    tabindex="-1" href="#step-by-step-checking"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Step-by-step Checking</h3>

    <p>Unlike the above one-command checking, the following steps present the generation
    of compression results step by step.</p>

    <ol>

    <li>

    <p>Go to zfp/utils/, and then execute "zfp-zc-ratedistortion.sh [data directory]
    [dimension sizes....]". The compression results are stored in the compressionResults/
    directory.

    For example, suppose the directory of CESM-ATM data set is here: /home/shdi/CESM-testdata/1800x3600,
    then the command is "zfp-zc-ratedistortion.sh /home/shdi/CESM-testdata/1800x3600
    3600 1800". Note: the data files stored in the directory are also ending with
    .dat and the dimension sizes are the same (1800x3600) in this test-case.</p>

    </li>

    <li>

    <p>Similarly, go to SZ/example/, and then generate compression results by SZ compressor
    as follows: "sz-zc-ratedistortion.sh [data directory] [dimension sizes....]".
    The compression results are stored in the compressionResults/ directory.

    As for the example CESM-ATM, the test command is "sz-zc-ratedistortion.sh /home/shdi/CESM-testdata/1800x3600
    3600 1800".</p>

    </li>

    <li>

    <p>Then, go to Z-checker/examples/ directory, and run the command "./analyzeDataProperty.sh
    [data directory] [dimension sizes....]" to generate the data properties based
    on the data sets. This step has nothing to do with the compressors. The data analysis
    results are stored in the dataProperties/ directory.</p>

    </li>

    <li>

    <p>Generate the figure files: run the command "./generateReport.sh" simply. The
    results of comparing different compressors (such as sz and zfp in this test-case)
    are stored in the directory called compareCompressors/.</p>

    </li>

    </ol>

    <h3><a id="user-content-create-a-new-case" class="anchor" aria-hidden="true" tabindex="-1"
    href="#create-a-new-case"><span aria-hidden="true" class="octicon octicon-link"></span></a>Create
    a new case</h3>

    <p>"createZCCase.sh [test-case-name]" allows you to create a new test-case.  This
    command will create a new workspace directory in Z-checker, SZ, and zfp respectively.
    The compression results will be put in those workspace directories to avoid bing
    messed with other test-cases.</p>

    <p>For example, if you run the generateReport.sh in the directory ./Z-checker/examples,
    it is actually one test case, where the compression results and data analysis
    results will be put in the dataProperty/ and compressionResults/ under it.

    For another test case with another set of data or application, you can create
    a new workspace directory by the script createZCCase.sh (which calls ./Z-checker/createNewCase.sh).</p>

    <h3><a id="user-content-z-checker-updatesh" class="anchor" aria-hidden="true"
    tabindex="-1" href="#z-checker-updatesh"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>z-checker-update.sh</h3>

    <p>z-checker-update.sh can be used to update the repository (pull the new update
    from the server), so that you don''t have to perform the update manually.</p>

    <h3><a id="user-content-web-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#web-installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>web
    installation</h3>

    <p>Web installation allows to install a web server on the local machine, such
    that you can visualize the data through a local webpage and other people can view
    the data/results via that page if public ip is provided.

    z-checker-web-install.sh</p>

    <h3><a id="user-content-add-a-new-compressor" class="anchor" aria-hidden="true"
    tabindex="-1" href="#add-a-new-compressor"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Add a new compressor</h3>

    <ol>

    <li>Make a monitoring program (e.g., called testfloat_CompDecomp.c) for your compressor.
    An example can be found in SZ/example/testfloat_CompDecomp.c, which is used for
    SZ compressor.)</li>

    <li>Modify the manageCompressor.cfg based on the workspaceDir on your computer
    and directory containing the compiled executable monitoring program.</li>

    <li>Suppose the new compressor''s name is zz and the compression mode is called
    ''best''; then, run the following command to add the new compressor:

    ./manageCompressor -a zz -m best -c manageCompressor.cfg</li>

    <li>Then, open errBounds.cfg to modify the error bounds for the new compressor;
    and also modify the comparison cases as follows (the compressor name ''zz_b''
    was set in manageCompressor.cfg):

    comparisonCases="sz_f(1E-1),sz_d(1E-1),zfp(1E-1) sz_f(1E-2),sz_d(1E-2),zfp(1E-2)"
    --&gt; comparisonCases="sz_f(1E-1),sz_d(1E-1),zfp(1E-1),zz_b(1E-2) sz_f(1E-2),sz_d(1E-2),zfp(1E-2),zz_b(1E-2)"</li>

    <li>Finally, create a test case like this: ./createZCCase.sh case_name</li>

    <li>Perform the assessment by runZCCase.sh.</li>

    </ol>

    <h3><a id="user-content-remove-a-compressor" class="anchor" aria-hidden="true"
    tabindex="-1" href="#remove-a-compressor"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Remove a compressor</h3>

    <p>Remove sz_f (sz fast mode):

    $ manageCompressor -d sz -m fast -c manageCompressor-sz-f.cfg

    Remove sz_d (sz fast mode):

    $ manageCompressor -d sz -m deft -c manageCompressor-sz-d.cfg

    Remove zfp:

    $ manageCompressor -d zfp -c manageCompressor-zfp.cfg</p>

    <h3><a id="user-content-generate-z-checker-report-based-on-hdf5-files" class="anchor"
    aria-hidden="true" tabindex="-1" href="#generate-z-checker-report-based-on-hdf5-files"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Generate Z-checker
    report based on HDF5 files</h3>

    <p>You can generate Z-checker report directly based on an HDF5 file.

    To this end, you need to install HDF5 library before hand, and then compile the
    Z-checker/HDF5Reader as follows:</p>

    <p>You need to modify Makefile.linux2 by replacing "HDF5PATH = /home/sdi/Install/hdf5-1.10.1-install"
    by your HDF5 installation path.

    Then:

    make -f Makefile.linux2</p>

    <p>You will find the executable ''testHDF5_CompDecomp'' generated on Z-checker/HDF5Reader/test/
    directory.

    You can use this command to read HDF5 file and generate analysis results.</p>

    <p>After that, you can use ''installHDF5Reader.sh'' and ''runZCCase_hdf5.sh''
    to generate the .pdf report.

    More details can be found in testHDF5/README.txt</p>

    <h3><a id="user-content-generate-z-checker-report-based-on-adios2-files" class="anchor"
    aria-hidden="true" tabindex="-1" href="#generate-z-checker-report-based-on-adios2-files"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Generate Z-checker
    report based on ADIOS2 files</h3>

    <p>Go to the directory ADIOS2Header, and then do the following steps:</p>

    <ol>

    <li>Modify the ADIOS2''s installation path in Makefile</li>

    <li>make</li>

    <li>execute ''testAdios2''</li>

    </ol>

    <p>Example:

    testAdios2 -i myVector_cpp.bp -n 2 -v bpFloats bpInts -o [target output directory]</p>

    <p>The generated binary data files will be put in the target output directory.
    A meta file called ''varInfo.txt'' contains the extracted variables'' information
    and it will be put in the target output directory as well.

    varInfo.txt and the binary files can be processed by runZCCase.sh</p>

    '
  stargazers_count: 5
  subscribers_count: 7
  topics: []
  updated_at: 1658448853.0
COSIMA/spack-config:
  data_format: 2
  description: Spack configuration installed at /g/data/ik11/spack/ to provide ACCESS-OM3
    dependencies
  filenames:
  - environments/cesm-0_x_0/spack.yaml
  full_name: COSIMA/spack-config
  latest_release: access-om3-v0.2.0
  readme: "<h1><a id=\"user-content-cosima-spack-configuration\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#cosima-spack-configuration\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>COSIMA Spack\
    \ Configuration</h1>\n<p>This repository contains the spack configuration and\
    \ the spack environments used\nby COSIMA to deploy software on gadi.</p>\n<h2><a\
    \ id=\"user-content-installation-instructions\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#installation-instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation instructions</h2>\n\
    <p>Clone this repository and its submodules to some appropriate location (e.g.,\n\
    <code>/g/data/ik11/spack/0.20.1</code>):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ git clone --recursive https://github.com/COSIMA/spack-config.git /g/data/ik11/spack/0.20.1</pre></div>\n\
    <p>Next, create the python virtual environment:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ <span class=\"pl-c1\">cd</span> /g/data/ik11/spack/0.20.1\n$ ./bootstrap_venv.sh</pre></div>\n\
    <p>Finally, to use this spack installation one just needs to activate the python\n\
    environment:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$  <span\
    \ class=\"pl-c1\">.</span> /g/data/ik11/spack/0.20.1/venv/bin/activate\n$ which\
    \ spack\n<span class=\"pl-en\">spack</span> ()\n{ \n    <span class=\"pl-c1\"\
    >:</span> this is a shell <span class=\"pl-k\">function</span> <span class=\"\
    pl-en\">from:</span> /g/data/ik11/spack/0.20.1/spack/share/spack/setup-env.sh;\n\
    \    <span class=\"pl-c1\">:</span> the real spack script is here: /g/data/ik11/spack/0.20.1/spack/bin/spack<span\
    \ class=\"pl-k\">;</span>\n    _spack_shell_wrapper <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span><span class=\"pl-smi\">$@</span><span class=\"pl-pds\"\
    >\"</span></span><span class=\"pl-k\">;</span>\n    <span class=\"pl-k\">return</span>\
    \ <span class=\"pl-smi\">$?</span>\n}</pre></div>\n<h2><a id=\"user-content-installing-software\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-software\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ software</h2>\n<p>It is recommended that all software be installed using spack\n\
    environments. Currently the following environments are provided (the names\nshould\
    \ be self-explanatory):</p>\n<ol>\n<li><code>access-om3-0_1_0</code></li>\n<li><code>access-om3-devel</code></li>\n\
    <li><code>cesm-0_1_0</code></li>\n<li><code>common_tools_and_libraries</code></li>\n\
    </ol>\n<p>Installation of a spack environment is usually quite straightforward,\
    \ but\nbecause this can be a CPU intensive operation and take quite some time,\
    \ it is\nbest to do this in parallel and to use an interactive job.</p>\n<h3><a\
    \ id=\"user-content-step-by-step-instructions\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-by-step-instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step-by-step instructions:</h3>\n\
    <ol>\n<li>Activate spack environment</li>\n</ol>\n<p>First activate the spack\
    \ environment</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ spack\
    \ env activate <span class=\"pl-k\">&lt;</span>env<span class=\"pl-k\">&gt;</span></pre></div>\n\
    <p>where <code>&lt;env&gt;</code> by the actual name of the environment.</p>\n\
    <ol start=\"2\">\n<li>Download the sources</li>\n</ol>\n<p>As the compute nodes\
    \ do not have internet access, one needs to download all the\nnecessary sources\
    \ from the login node. This is done using a spack mirror.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$ spack mirror create -d sources -a</pre></div>\n\
    <p>Here <code>sources</code> is the name of a mirror that has already been configured.</p>\n\
    <ol start=\"3\">\n<li>Submit interactive job</li>\n</ol>\n<p>This should not use\
    \ more than a single node. Also, make sure to add <code>gdata/ik11</code>\nand\
    \ <code>scratch/ik11</code> to the storage options.</p>\n<ol start=\"4\">\n<li>Install\
    \ software</li>\n</ol>\n<p>Once the job has started, because it starts a completely\
    \ new shell session, one\nneeds to activate again both the python and the spack\
    \ environments:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$  <span\
    \ class=\"pl-c1\">.</span> /g/data/ik11/spack/0.20.1/venv/bin/activate\n$ spack\
    \ env activate <span class=\"pl-k\">&lt;</span>env<span class=\"pl-k\">&gt;</span></pre></div>\n\
    <p>Then one can simply do</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ spack install </pre></div>\n<p>In this case, although each individual\
    \ build will use some level of parallelism,\nspack will proceed through the installation\
    \ of the packages sequentially. To\nfully use parallelism one needs to tell spack\
    \ to create a Makefile and use this\nto install the software:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$ spack env depfile -o Makefile\n$ make\
    \ -j</pre></div>\n<p>In the end, all the packages should be available in some\
    \ subdirectory of\n<code>/g/data/ik11/spack/0.20.1/opt/</code> and the corresponding\
    \ environment modules are\ninstalled under a subdirectory of <code>/g/data/ik11/spack/0.20.1/modules</code>.\
    \ The\nactual subdirectories depend on the selected environement.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1692145219.0
CUP-ECS/beatnik:
  data_format: 2
  description: Initial Cabana/Cajita Low/High-order Z-model Interface Solver. Benchmark
    for evaluating the performance of algorithms requiring global communication. Beatnik
    is also a precursor to potential later a High Performance Parallel Interface solver.
  filenames:
  - configs/llnl/lassen/spack.yaml
  full_name: CUP-ECS/beatnik
  latest_release: v1.0.0
  readme: '<h1><a id="user-content-beatnik---a-prototype-high-performance-parallel-interface-benchmark"
    class="anchor" aria-hidden="true" tabindex="-1" href="#beatnik---a-prototype-high-performance-parallel-interface-benchmark"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Beatnik - A Prototype
    High Performance Parallel Interface Benchmark</h1>

    <h2><a id="user-content-description" class="anchor" aria-hidden="true" tabindex="-1"
    href="#description"><span aria-hidden="true" class="octicon octicon-link"></span></a>Description</h2>

    <p>Beatnik is a benchmark for global communication based on Pandya and Shkoller''s
    3D fluid interace "Z-Model" in the Cabana/Cajita mesh framework [1]. The goals

    of Beatnik are to:</p>

    <ol>

    <li>Provide an interesting and meaningful benchmark for numerical methods that
    require global communication, for example for far-field force calculations. This
    includes fast fourier transforms, distance sort cutoff-based methods, and (eventually)
    fast multi-pole methods.</li>

    <li>Understand the performance characteristics of different parallel decompositions
    of the Z-Model based on both a 2D decomposition based on logical mesh location
    location and a space-filling curve mesh decomposition.</li>

    <li>Provide a working prototype parallel implementation of the fluid interface
    model that other codes can use to create multi-scale models and codes.</li>

    </ol>

    <p>Beatnik uses a simple mesh-based representation of the surface manifold as
    a Cabana grid 2D mesh in I/J space and a regular block 2D decomposition of this
    manifold. The physical position of each element in the mesh is stored as a separate
    vector in the nodes of the mesh. This design results in simple and efficient computation
    and communication strategies for surface normals, artificial viscosity, and Fourier
    transforms elements. However, it complicates methods where the data decomposition
    and communication is based on the spatial location of manifold points, requiring
    them to either maintain a separate spatial decomposition of the surface or to
    continually construct a spatial decomposition. A surface mesh that decomposed
    the mesh by spatial location would be an interesting alternative but would have
    the opposite issue - communication for surface calculations would be more complex
    but the (expensive) far force methods that rely on spatial decompositions (e.g.
    distance sort and spatial tree methods like the fast multi-pole method) would
    be less expensive.</p>

    <h2><a id="user-content-building-beatnik" class="anchor" aria-hidden="true" tabindex="-1"
    href="#building-beatnik"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    Beatnik</h2>

    <p>Beatnik relies on multiple external packages to build, including:</p>

    <ul>

    <li>ECP CoPA''s Cabana/Grid particle and mesh framework [2]</li>

    <li>UT-Knoxville''s HeFFTe fast fourier transform library [3]</li>

    <li>A high-performance GPU-aware MPI implementation such as OpenMPI, MPICH, or
    MVAPICH</li>

    </ul>

    <p>To ease building Beatnik, the configs/ directory includes Spack configuration
    files for building in spack environments on multiple systems and test case run
    scripts for a variety of systems. In addition, the latest version of Spack includes
    a package description for directly building Beatnik. More information on building
    Beatnik can be found in the README.md file in the configs/ directory.</p>

    <h2><a id="user-content-running-beatnik" class="anchor" aria-hidden="true" tabindex="-1"
    href="#running-beatnik"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    Beatnik</h2>

    <p>By default, Beatnik solves a simple multi-mode rocket rig problem sized for
    a single serial CPU core with approximately 4GB of memory. It also includes command
    line options to change initial problem state, I/O frequency, and to weak-scale
    scale up the initial problem to larger number of processes. It also includes problem-specific
    command line parameters; setting these parameters accurately generally requires
    expertise in fluid interface models. However, we provide several useful examples
    drawn from the ZModel papers that recreate the results in those papers.</p>

    <h3><a id="user-content-general-command-line-parameters" class="anchor" aria-hidden="true"
    tabindex="-1" href="#general-command-line-parameters"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>General command line parameters</h3>

    <ul>

    <li>

    <code>-x [cuda|threads|serial]</code> - The node-level parallelism/accelerator
    backend to use</li>

    <li>

    <code>-F [write-frequency]</code> - Interval between timesteps when I/O is written</li>

    <li>

    <code>-O [solution order]</code> - Order of solver to use (''high'', ''medium'',
    or ''low''). ''low'' is the default.</li>

    <li>`-w [weak scaling factor] - Scale up the problem specification, including
    the x/y bounding box, to be N times larger</li>

    </ul>

    <h3><a id="user-content-problem-specific-command-line-parameters" class="anchor"
    aria-hidden="true" tabindex="-1" href="#problem-specific-command-line-parameters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Problem-specific command
    line parameters</h3>

    <ul>

    <li>

    <code>-n [i/j mesh dimension ]</code> - Number of points on the interface manifold
    in the I and J dimensions</li>

    <li>`-t [timesteps] - number of timesteps to simulate</li>

    <li>

    <code>-I [interface initialization]</code> - Function to use for interface initial
    condition. Currently only ''cos'' and ''sech2'' are supported.</li>

    <li>

    <code>-m [magnitude]</code> - The maximum magnitude of the initialization function.</li>

    <li>

    <code>-p [period]</code> - The number of periods of the interface in the initial
    bounding box</li>

    <li>

    <code>-a [atwood]</code> - Atwood''s constant for the difference in pressure between
    the two fluids</li>

    <li>

    <code>-g [gravity]</code> - Gravitational acceleration in the -Z direction</li>

    <li>

    <code>-a [atwood]</code> -  Atwood''s constant for the difference in pressure
    between the two fluids</li>

    <li>

    <code>-M [mu]</code> - Mu, the artificial viscosity constant used in the Z-Model</li>

    <li>

    <code>-e [epsilon]</code> - Epsilon, the desingularization constant used in the
    Z-Model expressed as a fraction of the distance between interface mesh points</li>

    </ul>

    <h3><a id="user-content-example-1-periodic-multi-mode-rocket-rig" class="anchor"
    aria-hidden="true" tabindex="-1" href="#example-1-periodic-multi-mode-rocket-rig"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example 1: Periodic
    Multi-mode Rocket Rig</h3>

    <p>The simplest test case and the one to which the rocketrig example program defaults
    is an initial interface distributed according to a cosine function. Simple usage
    examples:</p>

    <ol>

    <li>Serial execution: <code>bin/rocketrig -x serial</code>

    </li>

    <li>Cuda execution (on systems with GPUs) with a 512x512 mesh: <code>bin/rocketrig
    -x cuda -n 512</code>

    </li>

    <li>Cuda execution with a 1024x1024 problem scaled up to be sixteen times as large
    in terms of bounding box and number of total points with no I/O: bin/rocketrig
    -x cuda -n 1024 -F 0 -w 16`</li>

    </ol>

    <h3><a id="user-content-example-2-non-periodic-single-mode-gaussian-rollup" class="anchor"
    aria-hidden="true" tabindex="-1" href="#example-2-non-periodic-single-mode-gaussian-rollup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example 2: Non-periodic
    Single-mode Gaussian Rollup</h3>

    <p>Another test case is a single-mode rollup test where the intitial interface
    is set according to a hyperbolic secant function. This testcase recreates the
    the Gaussian perturbation results in Panda and Shkoller''s paper from sections
    2.3 and 2.4.  To run this testcase with a high-order model, use the following
    command line parameters. Note that this works best with a GPU accelerator, as
    the exact high-order far field force solver is very compute intensive and is generally
    impractical for non-trivial mesh sizes without GPU acceleration:

    <code>bin/rocketrig -x cuda -O high -n 64 -I sech2 -m 0.1 -p 9.0 -b free -a 0.15
    -M 2 -e 2</code></p>

    <h2><a id="user-content-planned-development-steps" class="anchor" aria-hidden="true"
    tabindex="-1" href="#planned-development-steps"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Planned Development Steps</h2>

    <p>Beatnik is being implemented in multiple distinct steps, with associated planned
    releases:</p>

    <ul>

    <li>

    <p>Version 1.0 Features</p>

    <ol>

    <li>A low-order model implementation that relies on Cabana Grid/HeFFTe Fourier
    transforms for estimating velocity interface at mesh points.</li>

    <li>A high-order model implementation based on brute-force exact computation of
    long-range forces</li>

    <li>A medium-order model that uses the Fourier transform for estimating interface
    velocity and the far-field force solver for estimating how the vorticity changes
    at each interface point.</li>

    <li>Support for periodic boundary conditions and free boundary conditions</li>

    <li>Simple benchmark examples including a single-mode Gaussian roll-up test and
    the multi-mode rocket rig experiment.</li>

    <li>Direct support for weak scaling of benchmarks through command line arguments</li>

    </ol>

    </li>

    <li>

    <p>Version 1.X Planned Features</p>

    <ol>

    <li>Rearchitecting of the z-model solve into explicitly-coupled surface mesh and
    spatial mesh solvers</li>

    <li>A spatial mesh cutoff-based approach for calculating far-field forces using
    the Cabana particle framework. The goal of this work is to understand the accuracy/performance
    tradeoffs in the Z-Model, particularly in the medium-order</li>

    <li>Improved timestep, desingularization, and artificial viscosity parameter handling.
    The goal of this is to provide good defaults when other input parameters are changed.</li>

    <li>Additional interface initialization options, including Gaussian random and
    file-based interface initialization (also useful for checkpointing)</li>

    <li>Support for coupling with other applications through either I/O (e.g. ADIOS)
    or Communication (e.g. Portage)</li>

    <li>Additional test case definitions</li>

    </ol>

    </li>

    <li>

    <p>Potential later (e.g. &gt;=2.0) features</p>

    <ol>

    <li>Direct fast multi-pole or P3M solver for scalable, high precision high-order
    model solves.</li>

    <li>Support for multiple interface manifolds in a single simulation.</li>

    </ol>

    </li>

    </ul>

    <h2><a id="user-content-acknowledgment-contributors-and-copyright-information"
    class="anchor" aria-hidden="true" tabindex="-1" href="#acknowledgment-contributors-and-copyright-information"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgment, Contributors,
    and Copyright Information</h2>

    <p>Beatnik is primarily available as open source under a 3-Clause BSD License.
    It is being developed at the University of New Mexico, Tennessee Tech University,
    and the University of Alabama under funding the U.S. Department of Energy''s Predictive
    Science Academic Alliance Partnership III (PSAAP-III) program. Contributors to
    Beatnik development include:</p>

    <ul>

    <li>Patrick G. Bridges (<a href="mailto:patrickb@unm.edu">patrickb@unm.edu</a>)</li>

    <li>Thomas Hines (<a href="mailto:tmhines3@ua.edu">tmhines3@ua.edu</a>)</li>

    <li>Jered Dominguez-Trujillo (<a href="mailto:jereddt@unm.edu">jereddt@unm.edu</a>)</li>

    <li>Jacob McCullough (<a href="mailto:jmccullough12@unm.edu">jmccullough12@unm.edu</a>)</li>

    <li>Jason Stewart (<a href="mailto:jastewart@unm.edu">jastewart@unm.edu</a>)</li>

    </ul>

    <p>The general structure of Beatnik and the rocketrig examples were taken from
    the ExaMPM proxy application (<a href="https://github.com/ECP-copa/ExaMPM">https://github.com/ECP-copa/ExaMPM</a>)
    developed by the ECP Center for Particle Applications (CoPA), which was also available
    under a 3-Clause BSD License when used for creating application structure.</p>

    <h2><a id="user-content-references" class="anchor" aria-hidden="true" tabindex="-1"
    href="#references"><span aria-hidden="true" class="octicon octicon-link"></span></a>References</h2>

    <ol>

    <li>

    <p>Gavin Pandya and Steve Shkoller. "3d Interface Models for Raleigh-Taylor Instability."
    Published as arxiv.org preprint <a href="https://arxiv.org/abs/2201.04538" rel="nofollow">https://arxiv.org/abs/2201.04538</a>,
    2022.</p>

    </li>

    <li>

    <p><a href="https://github.com/ECP-copa/Cabana/">https://github.com/ECP-copa/Cabana/</a></p>

    </li>

    <li>

    <p>Innovative Computing Laboratory. "heFFTe." URL: <a href="https://icl.utk.edu/fft/"
    rel="nofollow">https://icl.utk.edu/fft/</a></p>

    </li>

    </ol>

    '
  stargazers_count: 4
  subscribers_count: 4
  topics: []
  updated_at: 1696885371.0
Change72/WarpX-2312:
  data_format: 2
  description: null
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: Change72/WarpX-2312
  latest_release: null
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" tabindex="-1"
    href="#warpx"><span aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/9322d48a1ef1d4949f877013f47676310b6774d0e750615ed2cecf4ec2d7eca3/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/3f9d8b15b61c55052071805cafa2f278fb4a2dd4372acb0b7ee63620a65d15e7/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/0beb5ef504dfacd71832068b9c4531e7dd837a2f801f3bd55ff8b36d89aa6951/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86f588e641d33c0f54e4fe9494235aea0398003a5d5eac847133d2da8b9fccea/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/a1d9ef8a9eb8118b83cc146955af7c9fc3721e5d80e4eed459eb558c6f596b73/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/discussions"><img src="https://camo.githubusercontent.com/1160c9b83b0d3a01df9f7384cf556f0cc92a304b6496afd616efe2ca068089b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667"
    alt="Discussions" data-canonical-src="https://img.shields.io/badge/chat-discussions-turquoise.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/1a6f861e33c8f14a8e4119adb07d24668e8d2fc773bf9e83829fa62732251df0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/3d90ef357e4a9590dd0cf06c730de1b41c601ebe7ca2eb10beee42fd406053e0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/e7fb0089d24cbec0919fda1a3406c2bb3ddfc5e6e70c69420c4d6b59e4136f37/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/647bd6e78a284bf08e53bd7038f210400464c5a5ed8beedd3391512ebb2aaefb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/65fec93ca7f0122e02994a743ea08ff139c085192a9e94ac627b966b8058e3b4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1109/SC41404.2022.00008" rel="nofollow"><img src="https://camo.githubusercontent.com/c5d3f4fb049eab48f59d6f9bb6e34570ad406e2691f5dcda65167dec4ad0d08a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/92c92f18fa93aab19301f6c1d609d4dbba6d2833f441adfc8aba95635e8a1186/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/d8faa5dd5c10a3a416f5b36feb83f7d0b22a040a13c4becf398c5660b4c94ccb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/532de0ea13712920c2b2f644fe425c87090486691a9b3de2bdc0a121552707ad/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our discussions page at <a href="https://github.com/ECP-WarpX/WarpX/discussions">https://github.com/ECP-WarpX/WarpX/discussions</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/68712ecce18e982a6a11d855fdcb3fd647bee2a05e6e550581d66f1c78e58b89/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/4c0961a0bcc2c026f3f3a20ea7dbd4f24c13f21991a145baf86385a18d2c408a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/fe112996993c23975e07c48ba70423ea5c9b716b2d60fbdcd8dfa620bd282ec3/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/c6a0dd9275b2fd160addee7f2d74ef088bb97a1598c29eab5bee1e9f153ae44a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/27d0f337e406f972927563ea93742777c7ce42cd1e4f5d204f9aa14b4e2e52d6/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/a0f2432f4678daa26dd446599ac3b93b3f25aa44d69c4d5e7db4fced70fe7a34/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/648674b11909d214d16a356f6a8c4f7d7d5578185f95afcc4e23327c5e4cff63/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-copyright-notice" class="anchor" aria-hidden="true" tabindex="-1"
    href="#copyright-notice"><span aria-hidden="true" class="octicon octicon-link"></span></a>Copyright
    Notice</h2>

    <p>WarpX Copyright (c) 2018, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>Please see the full license agreement in <a href="LICENSE.txt">LICENSE.txt</a>.

    The SPDX license identifier is <code>BSD-3-Clause-LBNL</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1701817698.0
Chrismarsh/CHM:
  data_format: 2
  description: The Canadian Hydrological Model
  filenames:
  - spack.yaml
  full_name: Chrismarsh/CHM
  latest_release: 1.2.6
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-the-canadian-hydrological-model\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-canadian-hydrological-model\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Canadian\
    \ Hydrological Model</h1>\n<p>The Canadian Hydrological Model (CHM) is a novel\
    \ modular unstructured mesh based approach for hydrological modelling. It can\
    \ move between spatial scale, temporal scale, and spatial extents. It is designed\
    \ for developing and testing process representations for hydrological models.</p>\n\
    \n<ul>\n<li><a href=\"#usage\">Usage</a></li>\n<li><a href=\"#motivation\">Motivation</a></li>\n\
    <li><a href=\"#design-goals\">Design goals</a></li>\n<li><a href=\"#publications\"\
    >Publications</a></li>\n<li>\n<a href=\"#features\">Features</a>\n<ul>\n<li><a\
    \ href=\"#spatial-scales\">Spatial Scales</a></li>\n<li><a href=\"#visualization\"\
    >Visualization</a></li>\n<li><a href=\"#netcdf-support\">netCDF support</a></li>\n\
    <li><a href=\"#process-representations\">Process representations</a></li>\n<li><a\
    \ href=\"#unstructured-mesh\">Unstructured mesh</a></li>\n<li><a href=\"#parallel-computing\"\
    >Parallel computing</a></li>\n<li><a href=\"#uncertainty-analysis\">Uncertainty\
    \ analysis</a></li>\n</ul>\n</li>\n<li>\n<a href=\"#demonstration\">Demonstration</a>\n\
    <ul>\n<li><a href=\"#snowcast\">SnowCast</a></li>\n<li><a href=\"#large-extent\"\
    >Large extent</a></li>\n<li><a href=\"#point-scale\">Point scale</a></li>\n<li><a\
    \ href=\"#blowing-snow\">Blowing snow</a></li>\n</ul>\n</li>\n</ul>\n\n<h1><a\
    \ id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Usage</h1>\n<p>Details on how to use CHM, as well as more implimentation\
    \ details, can be found in the <a href=\"https://chm.readthedocs.io/en/dev/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n<h1><a id=\"user-content-motivation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#motivation\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Motivation</h1>\n\
    <p>Modelling of hydrological processes at any scale is hampered by large uncertainties\
    \ in parameters and forcing data, incomplete process representations (the scientific\
    \ conceptualization of a phenomena codified numerically), and arbitrary process\
    \ representation selections and linkages (collectively \u2018model structure\u2019\
    ). There is also consistent difficulty or an inability to easily test and estimate\
    \ the uncertainty due to variations in model structure, parameter values, number\
    \ of parameters, forcing data requirements, and spatial discretization requirements\
    \ (collectively \u2018model complexity\u2019).</p>\n<p>In this work, a new distributed\
    \ model framework is presented that can examine a variety of process representations,\
    \ process linkages and levels of model complexity. Algorithms can be easily interchanged,\
    \ removed, and decoupled while preserving the underlying model framework. Thus,\
    \ uncertainty propagation and subsequent feedbacks within the model structure\
    \ can be quantified. Unstructured meshes represent the spatial heterogeneity of\
    \ surface and sub-surface features in a computationally efficient manner and also\
    \ decreases number of parameters and initial conditions. The parallel architecture\
    \ allows for efficient uncertainty testing of parameter ranges. By utilizing unstructured\
    \ meshes, fewer than 5% of the computational elements of high-resolution structured\
    \ (raster) grids are usually necessary.  This preserves surface and sub-surface\
    \ heterogeneity but results in fewer parameters and initial conditions.</p>\n\
    <h1><a id=\"user-content-design-goals\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#design-goals\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Design goals</h1>\n<ul>\n<li>Multi-scale, multi-physics,\
    \ variable complexity and domain model</li>\n<li>Assessment of model structural,\
    \ parameter, and data uncertainty</li>\n<li>Easily test multiple hypotheses, avoid\
    \ rigid model structures</li>\n<li>Incorporate existing code</li>\n<li>Contribute\
    \ to decision support systems</li>\n</ul>\n<h1><a id=\"user-content-publications\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#publications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Publications</h1>\n\
    <p>The following publications provide an overview of CHM and its capabilities</p>\n\
    <ul>\n<li>V. Vionnet, Marsh, C.B., B. Menounos, S. Gascoin, N.E. Wayand, J. Shea,\
    \ K. Mukherjee, and J.W. Pomeroy. Multi-scale snowdrift-permitting modelling of\
    \ mountain snowpack. The Cryosphere Discussions, 2020:1--43, 2020.</li>\n<li>Marsh,\
    \ C.B., J.W. Pomeroy, and H.S. Wheater. The Canadian Hydrological Model (CHM)\
    \ v1.0: a multi-scale, multi-extent, variable-complexity hydrological model \u2013\
    \ design and overview. Geoscientific Model Development, 13(1):225--247, 2020.</li>\n\
    <li>Marsh, C.B, J. W. Pomeroy, R.J. Spiteri, and H.S Wheater. A Finite Volume\
    \ Blowing Snow Model for Use With Variable Resolution Meshes. Water Resources\
    \ Research, 56(2), 2020.</li>\n<li>Marsh, C.B, R. J. Spiteri, J.W. Pomeroy, and\
    \ H.S. Wheater. Multi-objective unstructured triangular mesh generation for use\
    \ in hydrological and land surface models. Computers &amp; Geosciences, 119:49--67,\
    \ 2018.</li>\n</ul>\n<h1><a id=\"user-content-features\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#features\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Features</h1>\n<h2><a id=\"user-content-spatial-scales\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spatial-scales\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spatial\
    \ Scales</h2>\n<p>CHM is applicable to multiple scales from the basin scale, to\
    \ the provincial/state scale and beyond. It may also be applied at a single point-scale.\n\
    <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-visualization\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#visualization\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Visualization</h2>\n\
    <p>Output is in the vtu file format, allowing for visualization, analysis, and\
    \ timeseries animation in <a href=\"https://www.paraview.org/\" rel=\"nofollow\"\
    >ParaView</a>. Date-time support has been added to ParaView via an filter <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\"\
    ><img src=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\" alt=\"\
    vtk-paraview-datetimefilter\" style=\"max-width: 100%;\"></a>.</p>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-netcdf-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#netcdf-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>netCDF support</h2>\n\
    <p>Input meterology may be either in a standard ASCII file, or as a netCDF file\
    \ allowing for ease of use when using climate model outputs.</p>\n<p>The below\
    \ figure shows virtual stations that correspond to the center of the 2.5 km GEM\
    \ numerical weather prediction output in netCDF format.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-process-representations\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#process-representations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Process\
    \ representations</h2>\n<p>Process represetenation will be extented to include\
    \ the entirety of the hydrological cycle. However, current representation includes\
    \ mostly surface and cold regions processes</p>\n<table>\n<thead>\n<tr>\n<th>Process</th>\n\
    <th>Module</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Canopy</td>\n<td>Open/forest\
    \ (exp/log) (Pomeroy et al., 1998; Ellis et al., 2010)</td>\n</tr>\n<tr>\n<td>Snowpack</td>\n\
    <td>2-layer Snobal (Marks et al, 1999); Multi-layer Snowpack (Lehning et al.,\
    \ 1999); Various albedo e.g., CLASS (Verseghy 1991)</td>\n</tr>\n<tr>\n<td>Soil</td>\n\
    <td>Frozen soil infiltration (Gray et al., 2001)</td>\n</tr>\n<tr>\n<td>Mass redistribution</td>\n\
    <td>PBSM3D (Marsh et al, 2018 in review); Snowslide (Bernhardt 2010)</td>\n</tr>\n\
    </tbody>\n</table>\n<p>Input meterology is spatially interpolated and down-scaled\
    \ from the input station or virtual-station (e.g., from numerical weather prediction)\
    \ to produce a spatially distributed driving dataset. There are a number of ways\
    \ to downscale these meterology.</p>\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n\
    <th>Type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Air temperature</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant, neutral stability) (Kunkel, 1989,\
    \ Dodson et al., 1997)</td>\n</tr>\n<tr>\n<td>Relative humidity</td>\n<td>Linear\
    \ lapse rates (measured, seasonal, constant) (Kunkel, 1989)</td>\n</tr>\n<tr>\n\
    <td>Horizontal wind</td>\n<td>Topographic curvature (Liston, et al., 2006); Mason-Sykes\
    \ (Mason and Sykes, 1979); uniform wind</td>\n</tr>\n<tr>\n<td>Precipitation</td>\n\
    <td>Elevation based lapse (Thornton, 1997)</td>\n</tr>\n<tr>\n<td>Precipitation\
    \ Phase</td>\n<td>Linear; Psychometric (Harder and Pomeroy, 2013); Threshold</td>\n\
    </tr>\n<tr>\n<td>Solar radiation</td>\n<td>Terrain shadows (Marsh et al., 2011,\
    \ Dozier and Frew, 1990); Clear sky transmittance (Burridge, 1975); Transmittance\
    \ from observations; Cloud fraction estimates (Walcek, 1994); Direct/diffuse splitting\
    \ (Iqbal, 19xx)</td>\n</tr>\n<tr>\n<td>Longwave</td>\n<td>T, RH based (Sicart\
    \ et al., 2006); Constant (Marty et al., 2002)</td>\n</tr>\n</tbody>\n</table>\n\
    <h2><a id=\"user-content-unstructured-mesh\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#unstructured-mesh\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Unstructured mesh</h2>\n<p>CHM uses an unstructured\
    \ triangular mesh to representent the terrain. This mesh is generated by <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/mesher\"\
    ><img src=\"https://github.com/Chrismarsh/mesher\" alt=\"Mesher\" style=\"max-width:\
    \ 100%;\"></a>, a novel multi-objective unstructured mesh generation software\
    \ that allows mesh generation to be generated from an arbitrary number of hydrologically\
    \ important features while maintaining a variable spatial resolution. Triangle\
    \ quality is guaranteed as well as a smooth graduation from small to large triangles.\
    \ Including these additional features resulted in a better representation of spatial\
    \ heterogeneity versus classic topography-only mesh generation while significantly\
    \ reducing the total number of computational elements.</p>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-parallel-computing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#parallel-computing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Parallel\
    \ computing</h2>\n<p>In CHM, parallelism is currently implemented via the shared\
    \ memory API OpenMP. As described above, modules may either be point-scale models\
    \ that are applied to each triangle independently or require knowledge of the\
    \ surrounding triangles. Mixing these two types of parallelism complicates the\
    \ implementation of parallel code. To provide as much seamless parallelism as\
    \ possible to the modules, each module declares the type of algorithm it is: data\
    \ parallel or domain parallel. Data parallel modules are point-scale models that\
    \ are applied to every triangle. Domain parallel modules are modules that require\
    \ knowledge of surrounding mesh points. Thus, after the topological sort is performed\
    \ to determine module execution order, the modules are scheduled together into\
    \ groups that share a parallelism type</p>\n<h2><a id=\"user-content-uncertainty-analysis\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#uncertainty-analysis\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Uncertainty\
    \ analysis</h2>\n<p>A key feature of CHM is the ability to, on the command line,\
    \ change any value specified by a configuration parameter. CHM provides a seamless\
    \ mechanism to easily allow modules to obtain parameter data from configuration\
    \ files.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"\
    pl-k\">import</span> <span class=\"pl-s1\">subprocess</span>\n<span class=\"pl-k\"\
    >import</span> <span class=\"pl-s1\">shutil</span>\n\n\n<span class=\"pl-s1\"\
    >prj_path</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"CHM.config\"\
    </span>\n\n<span class=\"pl-s1\">cf1</span> <span class=\"pl-c1\">=</span> <span\
    \ class=\"pl-s\">\"-c output.VistaView.file:vv_dodson.txt\"</span>\n<span class=\"\
    pl-s1\">cf2</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"-c output.UpperClearing.file:uc_dodson.txt\"\
    </span>\n<span class=\"pl-s1\">cf3</span> <span class=\"pl-c1\">=</span> <span\
    \ class=\"pl-s\">\"-c output.FiserraRidge.file:fr_dodson.txt\"</span>\n<span class=\"\
    pl-s1\">cf4</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s\">\"--add-module\
    \ Dodson_NSA_ta\"</span>\n<span class=\"pl-s1\">subprocess</span>.<span class=\"\
    pl-en\">check_call</span>([<span class=\"pl-s\">'./CHM %s %s %s %s %s'</span>\
    \ <span class=\"pl-c1\">%</span> (<span class=\"pl-s1\">prj_path</span>, <span\
    \ class=\"pl-s1\">cf1</span>, <span class=\"pl-s1\">cf2</span>, <span class=\"\
    pl-s1\">cf3</span>,<span class=\"pl-s1\">cf4</span>)], <span class=\"pl-s1\">shell</span><span\
    \ class=\"pl-c1\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<h1><a\
    \ id=\"user-content-demonstration\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#demonstration\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Demonstration</h1>\n<h2><a id=\"user-content-snowcast\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#snowcast\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>SnowCast</h2>\n<p><a href=\"\
    http://www.snowcast.ca\" rel=\"nofollow\">SnowCast</a> is an experimental, daily\
    \ data product that uses the Global Environmental Multiscale (GEM) model forecasts\
    \ from Environment and Climate Change Canada (ECCC) to drive the Canadian Hydrological\
    \ Model (CHM). Estimates of snowpack are provided over the a Bow River Basin,\
    \ centered over Banff, Canada.</p>\n<p>SnowCast is developed as part of <a href=\"\
    https://gwf.usask.ca/\" rel=\"nofollow\">Global Water Futures</a> and the <a href=\"\
    https://www.usask.ca/hydrology/\" rel=\"nofollow\">Centre for Hydrology</a>, University\
    \ of Saskatchewan.</p>\n<h2><a id=\"user-content-large-extent\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#large-extent\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Large extent</h2>\n<p>Hourly\
    \ solar radiation modelling for the territory of Yukon, Canada.\n<a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-point-scale\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#point-scale\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Point scale</h2>\n\
    <p>Comparison of CHM driving Snobal and Snowpack at the Upper Clearing site at\
    \ Marmot Creek Research Basin in Alberta, Canada\n<a target=\"_blank\" rel=\"\
    noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-blowing-snow\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#blowing-snow\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Blowing\
    \ snow</h2>\n<p>Blowing snow for a small sub-basin of Wolf Creek Reserach Basin,\
    \ located in the Yukon, Canada.\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    ><img src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 35
  subscribers_count: 11
  topics: []
  updated_at: 1703967247.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/22.05/rocm.spack.yaml
  - environments/23.05/rocm-x86_64/spack.yaml
  - environments/23.08/cuda-aarch64/spack.yaml
  - environments/21.08/spack.yaml
  - environments/22.05/cuda-x86_64.spack.yaml
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/23.08/cuda-x86_64/spack.yaml
  - environments/23.05/cuda-x86_64/spack.yaml
  - environments/23.02/cuda-x86_64/spack.yaml
  - environments/23.02/cuda-ppc64le/spack.yaml
  - environments/22.08/cuda-ppc64le.spack.yaml
  - environments/23.08/oneapi-x86_64/spack.yaml
  - environments/21.05/spack.yaml
  - environments/23.11/cuda-ppc64le/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: v23.11
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d548c41497648f97178f367a87401d9f73f533daf22804b7fef0b85f7d8e3ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/5d548c41497648f97178f367a87401d9f73f533daf22804b7fef0b85f7d8e3ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/b8248e747ce21198bc44bfd5d4a8f9e5ec64a7a2c68b6e619cbfb5301a954f91/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/b8248e747ce21198bc44bfd5d4a8f9e5ec64a7a2c68b6e619cbfb5301a954f91/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/1bfba11ecd687250fe889e3506d82375ddaaed674b6fd8cda2605a56dd15ad89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/1bfba11ecd687250fe889e3506d82375ddaaed674b6fd8cda2605a56dd15ad89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/e0d5e7562db6d38a29491be3391fe00bbcb5813c3a1a60a0e7bfbf4c32fa19be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/e0d5e7562db6d38a29491be3391fe00bbcb5813c3a1a60a0e7bfbf4c32fa19be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#e4s\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#useful-links\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n\
    <ul>\n<li>User Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\"\
    >https://e4s.readthedocs.io</a>\n</li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub:\
    \ <a href=\"https://github.com/E4S-Project/\">https://github.com/E4S-Project/</a>\n\
    </li>\n<li>E4S Slack Channel: <a href=\"https://e4s-project.slack.com\" rel=\"\
    nofollow\">https://e4s-project.slack.com</a>\n</li>\n<li>Slack Channel Invitation:\
    \ <a href=\"https://communityinviter.com/apps/e4s-project/e4s\" rel=\"nofollow\"\
    >https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n<li>E4S Dashboard:\
    \ <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"\
    https://github.com/E4S-Project/E4S-Project.github.io\">E4S-Project/E4S-Project.github.io</a>\
    \ - E4S Documentation repo that is hosted on <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>E4S is released as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 21
  subscribers_count: 10
  topics: []
  updated_at: 1700727642.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, time-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '24.02'
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" tabindex="-1"
    href="#warpx"><span aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/9322d48a1ef1d4949f877013f47676310b6774d0e750615ed2cecf4ec2d7eca3/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/3f9d8b15b61c55052071805cafa2f278fb4a2dd4372acb0b7ee63620a65d15e7/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/0beb5ef504dfacd71832068b9c4531e7dd837a2f801f3bd55ff8b36d89aa6951/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86f588e641d33c0f54e4fe9494235aea0398003a5d5eac847133d2da8b9fccea/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/a1d9ef8a9eb8118b83cc146955af7c9fc3721e5d80e4eed459eb558c6f596b73/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/discussions"><img src="https://camo.githubusercontent.com/1160c9b83b0d3a01df9f7384cf556f0cc92a304b6496afd616efe2ca068089b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667"
    alt="Discussions" data-canonical-src="https://img.shields.io/badge/chat-discussions-turquoise.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/1a6f861e33c8f14a8e4119adb07d24668e8d2fc773bf9e83829fa62732251df0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/3d90ef357e4a9590dd0cf06c730de1b41c601ebe7ca2eb10beee42fd406053e0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/e7fb0089d24cbec0919fda1a3406c2bb3ddfc5e6e70c69420c4d6b59e4136f37/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/647bd6e78a284bf08e53bd7038f210400464c5a5ed8beedd3391512ebb2aaefb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/65fec93ca7f0122e02994a743ea08ff139c085192a9e94ac627b966b8058e3b4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1109/SC41404.2022.00008" rel="nofollow"><img src="https://camo.githubusercontent.com/c5d3f4fb049eab48f59d6f9bb6e34570ad406e2691f5dcda65167dec4ad0d08a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/92c92f18fa93aab19301f6c1d609d4dbba6d2833f441adfc8aba95635e8a1186/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/d8faa5dd5c10a3a416f5b36feb83f7d0b22a040a13c4becf398c5660b4c94ccb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/532de0ea13712920c2b2f644fe425c87090486691a9b3de2bdc0a121552707ad/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our discussions page at <a href="https://github.com/ECP-WarpX/WarpX/discussions">https://github.com/ECP-WarpX/WarpX/discussions</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/68712ecce18e982a6a11d855fdcb3fd647bee2a05e6e550581d66f1c78e58b89/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/4c0961a0bcc2c026f3f3a20ea7dbd4f24c13f21991a145baf86385a18d2c408a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/fe112996993c23975e07c48ba70423ea5c9b716b2d60fbdcd8dfa620bd282ec3/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/c6a0dd9275b2fd160addee7f2d74ef088bb97a1598c29eab5bee1e9f153ae44a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/27d0f337e406f972927563ea93742777c7ce42cd1e4f5d204f9aa14b4e2e52d6/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/a0f2432f4678daa26dd446599ac3b93b3f25aa44d69c4d5e7db4fced70fe7a34/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/648674b11909d214d16a356f6a8c4f7d7d5578185f95afcc4e23327c5e4cff63/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-copyright-notice" class="anchor" aria-hidden="true" tabindex="-1"
    href="#copyright-notice"><span aria-hidden="true" class="octicon octicon-link"></span></a>Copyright
    Notice</h2>

    <p>WarpX Copyright (c) 2018, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>Please see the full license agreement in <a href="LICENSE.txt">LICENSE.txt</a>.

    The SPDX license identifier is <code>BSD-3-Clause-LBNL</code>.</p>

    '
  stargazers_count: 241
  subscribers_count: 14
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1707042744.0
EnzymeAD/CMake-Template:
  data_format: 2
  description: "\U0001F528 A template for using Enzyme with CMake"
  filenames:
  - spack.yaml
  full_name: EnzymeAD/CMake-Template
  latest_release: null
  readme: "<h1><a id=\"user-content-cmake-template\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#cmake-template\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>CMake-Template</h1>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#usage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <h3><a id=\"user-content-install-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#install-dependencies\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Install dependencies</h3>\n<ul>\n\
    <li>cmake</li>\n<li>make</li>\n<li>llvm</li>\n<li>enzyme</li>\n</ul>\n<p>Using\
    \ spack:</p>\n<pre><code>spack env activate .\nspack install\n</code></pre>\n\
    <p>Using homebrew:</p>\n<pre><code>brew bundle install\n</code></pre>\n<h3><a\
    \ id=\"user-content-configure-and-build\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#configure-and-build\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Configure and build</h3>\n<p>Configure the CMake\
    \ project using the version of Enzyme installed on the system:</p>\n<pre><code>mkdir\
    \ build &amp;&amp; cd build\ncmake ..\nmake\n</code></pre>\n<p>Configure the CMake\
    \ project using a custom Enzyme version:</p>\n<pre><code>mkdir build &amp;&amp;\
    \ cd build\ncmake -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics:
  - cmake
  - enzyme-ad
  - template
  updated_at: 1687815556.0
Exawind/exawind-builder:
  data_format: 2
  description: Scripts to help building Exawind codes on various systems
  filenames:
  - etc/spack/nrel-eagle/spack.yaml
  - etc/spack/spack/spack.yaml
  full_name: Exawind/exawind-builder
  latest_release: v0.1.0
  readme: '<h1><a id="user-content-exawind-code-builder" class="anchor" aria-hidden="true"
    tabindex="-1" href="#exawind-code-builder"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>ExaWind Code Builder</h1>

    <p><a href="https://exawind.github.io/exawind-builder" rel="nofollow">Documentation</a></p>

    <p>ExaWind Builder is a collection of bash scripts to configure and compile the

    codes used within the <a href="https://github.com/exawind">ExaWind</a> project
    on various

    high-performance computing (HPC) systems. The builder provides the following</p>

    <ul>

    <li>

    <p><strong>Platform configuration</strong>: Provides the minimal set of modules
    that must be

    loaded when compiling with different compilers and MPI libraries on different

    HPC systems.</p>

    </li>

    <li>

    <p><strong>Software configuration</strong>: Provides baseline CMake configuration
    that can be

    used to configure the various options when building a <em>project</em>, e.g.,

    enable/disable optional modules, automate specification of paths to various

    libraries, configure release vs. debug builds.</p>

    </li>

    <li>

    <p><strong>Build script generation</strong>: Generates an executable end-user
    script for a

    combination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>

    </li>

    <li>

    <p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific

    script that allows the user to recreate the exact environment used to build

    the codes during runtime.</p>

    </li>

    </ul>

    <p>The build scripts are intended for developers who might want to compile the

    codes with different configuration options, build different branches during

    their development cycle, or link to a different development version of a library

    that is currently not available in the standard installation on the system. Please
    see the

    <a href="https://exawind.github.io/exawind-builder" rel="nofollow">documentation</a>
    for

    details on how to use this to build ExaWind software.</p>

    <h2><a id="user-content-installation-and-usage" class="anchor" aria-hidden="true"
    tabindex="-1" href="#installation-and-usage"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Installation and usage</h2>

    <h3><a id="user-content-using-exawind-builder-with-pre-installed-exawind-environment"
    class="anchor" aria-hidden="true" tabindex="-1" href="#using-exawind-builder-with-pre-installed-exawind-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using exawind-builder
    with pre-installed ExaWind environment</h3>

    <p>ExaWind Builder is already installed and setup on OLCF Summit, NREL

    Eagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly

    to using build scripts from the central installation. Please consult <a href="https://exawind.github.io/exawind-builder/basic.html#basic-usage"
    rel="nofollow">user

    manual</a> to

    learn how to use the scripts.</p>

    <h3><a id="user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions"
    class="anchor" aria-hidden="true" tabindex="-1" href="#bootstrapping-exawind-builder-with-pre-configured-system-definitions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bootstrapping exawind-builder
    with pre-configured system definitions</h3>

    <p>ExaWind builder has <a href="https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems"
    rel="nofollow">pre-built

    configurations</a>

    for several systems. On these systems you can use the <code>bootstrap</code> script
    to

    quickly get up and running. Please consult <a href="https://exawind.github.io/exawind-builder/installation.html"
    rel="nofollow">installation

    manual</a>. The

    relevant steps are shown below.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Download bootstrap script</span>

    curl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Make it executable</span>

    chmod a+x bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Execute bootstrap and provide system/compiler
    combination</span>

    ./bootstrap.sh -s [SYSTEM] -c [COMPILER]


    <span class="pl-c"><span class="pl-c">#</span> Examples</span>

    ./bootstrap.sh -s spack -c clang       <span class="pl-c"><span class="pl-c">#</span>
    On MacOS with homebrew</span>

    ./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system

    ./bootstrap.sh -s eagle -c gcc         <span class="pl-c"><span class="pl-c">#</span>
    NREL Eagle</span>

    ./bootstrap.sh -s cori -c intel        <span class="pl-c"><span class="pl-c">#</span>
    NERSC Cori</span>

    ./bootstrap.sh -s snl-ascicgpu -c gcc  <span class="pl-c"><span class="pl-c">#</span>
    SNL GPU development machine</span></pre></div>

    <h3><a id="user-content-creating-new-system-configuration" class="anchor" aria-hidden="true"
    tabindex="-1" href="#creating-new-system-configuration"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Creating new system configuration</h3>

    <p>You can add new system definitions to exawind-builder for use on new systems

    that are not used by ExaWind team. Please see <a href="https://exawind.github.io/exawind-builder/advanced.html"
    rel="nofollow">manual

    installation</a> and

    <a href="https://exawind.github.io/exawind-builder/newsys.html" rel="nofollow">adding
    a new system</a>

    sections in the user manual.</p>

    <h2><a id="user-content-links" class="anchor" aria-hidden="true" tabindex="-1"
    href="#links"><span aria-hidden="true" class="octicon octicon-link"></span></a>Links</h2>

    <ul>

    <li><a href="https://www.exawind.org" rel="nofollow">ExaWind</a></li>

    <li><a href="https://github.com/exawind">ExaWind GitHub Organization</a></li>

    <li><a href="https://a2e.energy.gov/about/hfm" rel="nofollow">A2e HFM</a></li>

    </ul>

    '
  stargazers_count: 3
  subscribers_count: 6
  topics:
  - cmake
  - build
  - exawind
  - hpc
  - exawind-builder
  updated_at: 1643028069.0
FZJ-INM1-BDA/siibra-python:
  data_format: 2
  description: Software interfaces for interacting with brain atlases - Python client
  filenames:
  - .ebrains/spack/siibra-spack.yaml
  full_name: FZJ-INM1-BDA/siibra-python
  latest_release: null
  stargazers_count: 44
  subscribers_count: 8
  topics:
  - brain
  - atlas
  - neuroscience
  - bigbrain
  - bigbrainproject
  - humanbrainproject
  updated_at: 1699439990.0
FairRootGroup/FairMQ:
  data_format: 2
  description: C++ Message Queuing Library and Framework
  filenames:
  - spack.yaml
  full_name: FairRootGroup/FairMQ
  latest_release: v1.8.4
  readme: '

    <h1><a id="user-content-fairmq" class="anchor" aria-hidden="true" tabindex="-1"
    href="#fairmq"><span aria-hidden="true" class="octicon octicon-link"></span></a>FairMQ</h1>

    <p><a href="COPYRIGHT"><img src="https://camo.githubusercontent.com/f1b04dc9744be18d2e4a57e93eb675e9d34c7fd88dd2af920a23cbf2b6126c9b/68747470733a2f2f616c66612d63692e6773692e64652f736869656c64732f62616467652f6c6963656e73652d4c47504c2d2d332e302d6f72616e67652e737667"
    alt="license" data-canonical-src="https://alfa-ci.gsi.de/shields/badge/license-LGPL--3.0-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.1689985" rel="nofollow"><img src="https://camo.githubusercontent.com/61eb705b099605db7fd32ca363bc81333685424ab3d43368fb9eb92d2d20fcf8/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e313638393938352e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.1689985.svg"
    style="max-width: 100%;"></a>

    <a href="https://bestpractices.coreinfrastructure.org/projects/6915" rel="nofollow"><img
    src="https://camo.githubusercontent.com/1f8dec075c5bd5f9939e67adf475385a6ef6f10683061f1192c191ea31d3ffc3/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f363931352f6261646765"
    alt="OpenSSF Best Practices" data-canonical-src="https://bestpractices.coreinfrastructure.org/projects/6915/badge"
    style="max-width: 100%;"></a>

    <a href="https://github.com/FairRootGroup/FairMQ/actions/workflows/fair-software.yml"><img
    src="https://camo.githubusercontent.com/cf9de53206b2701f8f690c12ded388c94ec29b8b4366cc55a64f1442b196ae01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666169722d2d736f6674776172652e65752d2545322539372538462532302532302545322539372538462532302532302545322539372538422532302532302545322539372538462532302532302545322539372538462d79656c6c6f77"
    alt="fair-software.eu" data-canonical-src="https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B%20%20%E2%97%8F%20%20%E2%97%8F-yellow"
    style="max-width: 100%;"></a>

    <a href="https://repology.org/project/fairmq/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/a986833bc26fb382ffb3173c4f42c00cc0953f0b09ee7fc10e5c97df7f86c5a2/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f76657273696f6e2d666f722d7265706f2f737061636b2f666169726d712e737667"
    alt="Spack package" data-canonical-src="https://repology.org/badge/version-for-repo/spack/fairmq.svg"
    style="max-width: 100%;"></a></p>

    <p>C++ Message Queuing Library and Framework</p>

    <p>Docs: <a href="https://github.com/FairRootGroup/FairMQ/blob/dev/README.md#documentation">Book</a></p>

    <p>Find all FairMQ releases <a href="https://github.com/FairRootGroup/FairMQ/releases">here</a>.</p>

    <h2><a id="user-content-introduction" class="anchor" aria-hidden="true" tabindex="-1"
    href="#introduction"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

    <p>FairMQ is designed to help implementing large-scale data processing workflows
    needed in next-generation Particle Physics experiments. FairMQ is written in C++
    and aims to</p>

    <ul>

    <li>provide <strong>an asynchronous message passing abstraction</strong> of different
    data transport technologies,</li>

    <li>provide a reasonably <strong>efficient data transport</strong> service (zero-copy,
    high throughput),</li>

    <li>be <strong>data format agnostic</strong>, and</li>

    <li>provide <strong>basic building blocks</strong> that can be used to implement
    higher level data processing workflows.</li>

    </ul>

    <p>The core of FairMQ provides an abstract asynchronous message passing API with
    scalability protocols

    inspired by <a href="https://github.com/zeromq/libzmq">ZeroMQ</a> (e.g. PUSH/PULL,
    PUB/SUB).

    FairMQ provides multiple implementations for its API (so-called "transports",

    e.g. <code>zeromq</code> and <code>shmem</code> (latest release of the <code>ofi</code>
    transport in v1.4.56, removed since v1.5+)) to cover

    a variety of use cases

    (e.g. inter-thread, inter-process, inter-node communication) and machines (e.g.
    Ethernet, Infiniband).

    In addition to this core functionality FairMQ provides a framework for creating
    "devices" - actors which

    are communicating through message passing. FairMQ does not only allow the user
    to use different transport

    but also to mix them; i.e: A Device can communicate using different transport
    on different channels at the

    same time. Device execution is modelled as a simple state machine that shapes
    the integration points for

    the user task. Devices also incorporate a plugin system for runtime configuration
    and control.

    Next to the provided <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/devices">devices</a>
    and

    <a href="https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/plugins">plugins</a>
    the user can extend FairMQ

    by developing his own plugins to integrate his devices with external configuration
    and control services.</p>

    <p>FairMQ has been developed in the context of its mother project <a href="https://github.com/FairRootGroup/FairRoot">FairRoot</a>
    -

    a simulation, reconstruction and analysis framework.</p>

    <h2><a id="user-content-installation-from-source" class="anchor" aria-hidden="true"
    tabindex="-1" href="#installation-from-source"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Installation from Source</h2>

    <p>Recommended:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/FairRootGroup/FairMQ
    fairmq_source

    cmake -S fairmq_source -B fairmq_build -GNinja -DCMAKE_BUILD_TYPE=Release

    cmake --build fairmq_build

    ctest --test-dir fairmq_build --output-on-failure --schedule-random -j<span class="pl-k">&lt;</span>ncpus<span
    class="pl-k">&gt;</span>

    cmake --install fairmq_build --prefix <span class="pl-s"><span class="pl-pds">$(</span>pwd<span
    class="pl-pds">)</span></span>/fairmq_install</pre></div>

    <p>Please consult the <a href="https://cmake.org/cmake/help/latest/manual/cmake.1.html"
    rel="nofollow">manpages of your CMake version</a> for more options.</p>

    <p>If dependencies are not installed in standard system directories, you can hint
    the installation location via

    <code>-DCMAKE_PREFIX_PATH=...</code> or per dependency via <code>-D{DEPENDENCY}_ROOT=...</code>
    (<code>*_ROOT</code> variables can also be environment variables).</p>

    <h2><a id="user-content-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h2>

    <p>FairMQ ships as a CMake package, so in your <code>CMakeLists.txt</code> you
    can discover it like this:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">find_package</span>(FairCMakeModules
    1.0 <span class="pl-k">REQUIRED</span>)

    <span class="pl-c1">include</span>(FairFindPackage2)

    find_package2(FairMQ)

    find_package2_implicit_dependencies()</pre></div>

    <p>The <a href="https://fairrootgroup.github.io/FairCMakeModules/latest/module/FairFindPackage2.html"
    rel="nofollow"><code>FairFindPackage2</code> module</a> is part of the <a href="https://fairrootgroup.github.io/FairCMakeModules"
    rel="nofollow"><code>FairCMakeModules</code> package</a>.</p>

    <p>If FairMQ is not installed in system directories, you can hint the installation:</p>

    <div class="highlight highlight-source-cmake"><pre><span class="pl-c1">list</span>(PREPEND
    CMAKE_PREFIX_PATH /path/to/fairmq_install)</pre></div>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <ul>

    <li><a href="https://www.boost.org/" rel="nofollow">Boost</a></li>

    <li><a href="https://cmake.org/" rel="nofollow">CMake</a></li>

    <li><a href="http://www.doxygen.org/" rel="nofollow">Doxygen</a></li>

    <li>

    <a href="https://github.com/FairRootGroup/FairCMakeModules">FairCMakeModules</a>
    (optionally bundled)</li>

    <li><a href="https://github.com/FairRootGroup/FairLogger">FairLogger</a></li>

    <li>

    <a href="https://github.com/google/googletest">GTest</a> (optionally bundled)</li>

    <li><a href="http://zeromq.org/" rel="nofollow">ZeroMQ</a></li>

    </ul>

    <p>Which dependencies are required depends on which components are built.</p>

    <p>Supported platform is Linux. macOS is supported on a best-effort basis.</p>

    <h2><a id="user-content-cmake-options" class="anchor" aria-hidden="true" tabindex="-1"
    href="#cmake-options"><span aria-hidden="true" class="octicon octicon-link"></span></a>CMake
    options</h2>

    <p>On command line:</p>

    <ul>

    <li>

    <code>-DDISABLE_COLOR=ON</code> disables coloured console output.</li>

    <li>

    <code>-DBUILD_TESTING=OFF</code> disables building of tests.</li>

    <li>

    <code>-DBUILD_EXAMPLES=OFF</code> disables building of examples.</li>

    <li>

    <code>-DBUILD_DOCS=ON</code> enables building of API docs.</li>

    <li>

    <code>-DFAIRMQ_CHANNEL_DEFAULT_AUTOBIND=OFF</code> disable channel <code>autoBind</code>
    by default</li>

    <li>You can hint non-system installations for dependent packages, see the #installation-from-source
    section above</li>

    </ul>

    <p>After the <code>find_package(FairMQ)</code> call the following CMake variables
    are defined:</p>

    <table>

    <thead>

    <tr>

    <th>Variable</th>

    <th>Info</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>${FairMQ_PACKAGE_DEPENDENCIES}</code></td>

    <td>the list of public package dependencies</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_VERSION}</code></td>

    <td>the minimum <code>&lt;dep&gt;</code> version FairMQ requires</td>

    </tr>

    <tr>

    <td><code>${FairMQ_&lt;dep&gt;_COMPONENTS}</code></td>

    <td>the list of <code>&lt;dep&gt;</code> components FairMQ depends on</td>

    </tr>

    <tr>

    <td><code>${FairMQ_PACKAGE_COMPONENTS}</code></td>

    <td>the list of components FairMQ consists of</td>

    </tr>

    <tr>

    <td><code>${FairMQ_#COMPONENT#_FOUND}</code></td>

    <td>

    <code>TRUE</code> if this component was built</td>

    </tr>

    <tr>

    <td><code>${FairMQ_VERSION}</code></td>

    <td>the version in format <code>MAJOR.MINOR.PATCH</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_GIT_VERSION}</code></td>

    <td>the version in the format returned by <code>git describe --tags --dirty --match
    "v*"</code>

    </td>

    </tr>

    <tr>

    <td><code>${FairMQ_PREFIX}</code></td>

    <td>the actual installation prefix</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BINDIR}</code></td>

    <td>the installation bin directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_INCDIR}</code></td>

    <td>the installation include directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_LIBDIR}</code></td>

    <td>the installation lib directory</td>

    </tr>

    <tr>

    <td><code>${FairMQ_DATADIR}</code></td>

    <td>the installation data directory (<code>../share/fairmq</code>)</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CMAKEMODDIR}</code></td>

    <td>the installation directory of shipped CMake find modules</td>

    </tr>

    <tr>

    <td><code>${FairMQ_BUILD_TYPE}</code></td>

    <td>the value of <code>CMAKE_BUILD_TYPE</code> at build-time</td>

    </tr>

    <tr>

    <td><code>${FairMQ_CXX_FLAGS}</code></td>

    <td>the values of <code>CMAKE_CXX_FLAGS</code> and <code>CMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE}</code>
    at build-time</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <ol>

    <li>

    <a href="docs/Device.md#1-device">Device</a>

    <ol>

    <li><a href="docs/Device.md#11-topology">Topology</a></li>

    <li><a href="docs/Device.md#12-communication-patterns">Communication Patterns</a></li>

    <li><a href="docs/Device.md#13-state-machine">State Machine</a></li>

    <li><a href="docs/Device.md#15-multiple-devices-in-the-same-process">Multiple
    devices in the same process</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Transport.md#2-transport-interface">Transport Interface</a>

    <ol>

    <li>

    <a href="docs/Transport.md#21-message">Message</a>

    <ol>

    <li><a href="docs/Transport.md#211-ownership">Ownership</a></li>

    </ol>

    </li>

    <li><a href="docs/Transport.md#22-channel">Channel</a></li>

    <li><a href="docs/Transport.md#23-poller">Poller</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Configuration.md#3-configuration">Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#31-device-configuration">Device Configuration</a></li>

    <li>

    <a href="docs/Configuration.md#32-communication-channels-configuration">Communication
    Channels Configuration</a>

    <ol>

    <li><a href="docs/Configuration.md#321-json-parser">JSON Parser</a></li>

    <li><a href="docs/Configuration.md#322-suboptparser">SuboptParser</a></li>

    </ol>

    </li>

    <li><a href="docs/Configuration.md#33-introspection">Introspection</a></li>

    </ol>

    </li>

    <li>

    <a href="docs/Development.md#4-development">Development</a>

    <ol>

    <li><a href="docs/Development.md#41-testing">Testing</a></li>

    <li>

    <a href="docs/Development.md#42-static-analysis">Static Analysis</a>

    <ol>

    <li><a href="docs/Development.md#421-cmake-integration">CMake Integration</a></li>

    <li><a href="docs/Development.md#422-extra-compiler-arguments">Extra Compiler
    Arguments</a></li>

    </ol>

    </li>

    </ol>

    </li>

    <li>

    <a href="docs/Logging.md#5-logging">Logging</a>

    <ol>

    <li><a href="docs/Logging.md#51-log-severity">Log severity</a></li>

    <li><a href="docs/Logging.md#52-log-verbosity">Log verbosity</a></li>

    <li><a href="docs/Logging.md#53-color">Color for console output</a></li>

    <li><a href="docs/Logging.md#54-file-output">File output</a></li>

    <li><a href="docs/Logging.md#55-custom-sinks">Custom sinks</a></li>

    </ol>

    </li>

    <li><a href="docs/Examples.md#6-examples">Examples</a></li>

    <li>

    <a href="docs/Plugins.md#7-plugins">Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#71-usage">Usage</a></li>

    <li><a href="docs/Plugins.md#72-development">Development</a></li>

    <li>

    <a href="docs/Plugins.md#73-provided-plugins">Provided Plugins</a>

    <ol>

    <li><a href="docs/Plugins.md#731-pmix">PMIx</a></li>

    </ol>

    </li>

    </ol>

    </li>

    </ol>

    '
  stargazers_count: 80
  subscribers_count: 12
  topics:
  - fairroot
  - fairmq
  - zeromq
  - shmem
  - c-plus-plus
  updated_at: 1706568998.0
FairRootGroup/FairSoft:
  data_format: 2
  description: Repository for installation routines of the external software required
    by FairRoot
  filenames:
  - test/env/fairlogger/spack.yaml
  full_name: FairRootGroup/FairSoft
  latest_release: jan24
  readme: "<h1><a id=\"user-content-fairsoft\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#fairsoft\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>FairSoft</h1>\n<p>The FairSoft distribution provides\
    \ the software packages needed to compile and run the <a href=\"https://github.com/FairRootGroup/FairRoot\"\
    >FairRoot framework</a> and experiment packages based on FairRoot. FairSoft is\
    \ a source distribution with recurring releases for macOS and Linux.</p>\n<h2><a\
    \ id=\"user-content-installation-from-source\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#installation-from-source\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation from Source</h2>\n\
    <p>Choose between the classic (called \"Legacy\") installation method or the new\
    \ Spack-based one:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Legacy (Recommended)</strong></th>\n\
    <th><strong>Spack (EXPERIMENTAL)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>This is the classic bash/cmake based setup system.</td>\n<td>This is an ongoing\
    \ standardization and modernization effort based on Spack (which itself is still\
    \ under heavy development). Most things are already working. For early adopters.</td>\n\
    </tr>\n<tr>\n<td>Releases are reflected in the git history via tags and branches,\
    \ e.g.: <code>jan24</code>, <code>nov22</code>, <code>apr21p2</code>, <code>apr21_patches</code>\n\
    </td>\n<td>Always use the latest <code>dev</code> branch. Multiple releases are\
    \ described within the metadata contained in the repo (read on in the Installation\
    \ instructions on how to select a release).</td>\n</tr>\n<tr>\n<td>\u25BA <a href=\"\
    legacy/README.md\">continue</a>\n</td>\n<td>\u25BA <a href=\"docs/README.md\"\
    >continue</a>\n</td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-installation-of-pre-compiled-binaries\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation-of-pre-compiled-binaries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ of pre-compiled Binaries</h2>\n<p><em>Note</em>: FairSoft is primarily a source\
    \ distribution. Availability of latest releases as pre-compiled binaries may be\
    \ delayed.</p>\n<h3><a id=\"user-content-gsi-virgo-cluster\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#gsi-virgo-cluster\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>GSI Virgo Cluster</h3>\n<p>For\
    \ all <a href=\"https://hpc.gsi.de/virgo/platform/software.html#application-environment\"\
    \ rel=\"nofollow\">VAEs</a> at <code>/cvmfs/fairsoft.gsi.de/&lt;vae-os&gt;/fairsoft/&lt;release&gt;</code>.\
    \ Use by exporting the <code>SIMPATH</code> environment variable pointing to one\
    \ of the directories.</p>\n<h3><a id=\"user-content-macos-beta\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#macos-beta\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>macOS (beta)</h3>\n<p>FairSoft\
    \ config: <a href=\"FairSoftConfig.cmake\">default</a>, no other configs planned</p>\n\
    <ol>\n<li>Install <em>Command Line Tools for Xcode</em> from <a href=\"https://developer.apple.com/downloads\"\
    \ rel=\"nofollow\">https://developer.apple.com/downloads</a> (requires Apple account)</li>\n\
    <li>Install <a href=\"https://brew.sh/\" rel=\"nofollow\">Homebrew</a>\n</li>\n\
    <li>Run <code>brew update &amp;&amp; brew doctor</code> and fix potential issues\
    \ reported by these commands until <code>Your system is ready to brew.</code>\n\
    </li>\n<li>Run</li>\n</ol>\n<pre><code>brew tap fairrootgroup/fairsoft\nbrew install\
    \ fairsoft\n</code></pre>\n<ol start=\"5\">\n<li>Use via <code>export SIMPATH=$(brew\
    \ --prefix fairsoft)</code>\n</li>\n</ol>\n<p><em>Note</em>: macOS is a fast moving\
    \ target and it is possible the packages will stop working from one day to another\
    \ after some system component was updated. We try our best to keep up, one great\
    \ way to help is to provide detailed problem reports <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\
    >here on github</a>.</p>\n<h3><a id=\"user-content-other-platforms\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#other-platforms\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other platforms</h3>\n\
    <p>Binary packages for non-GSI Linux as well as Spack binary caches and/or pre-populated\
    \ install trees are planned for the future.</p>\n<h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n\
    <p>Please ask your questions, request features, and report issues by <a href=\"\
    https://github.com/FairRootGroup/FairSoft/issues/new\">creating a github issue</a>.</p>\n"
  stargazers_count: 13
  subscribers_count: 14
  topics: []
  updated_at: 1705588914.0
FluidNumerics/SELF:
  data_format: 2
  description: Spectral Element Library in Fortran
  filenames:
  - docker/deps/ubuntu2204/rocm/spack.yaml
  full_name: FluidNumerics/SELF
  latest_release: null
  readme: '<h1><a id="user-content-spectral-element-libraries-in-fortran-self" class="anchor"
    aria-hidden="true" tabindex="-1" href="#spectral-element-libraries-in-fortran-self"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spectral Element Libraries
    in Fortran (SELF)</h1>

    <p>Copyright 2020-2023 Fluid Numerics LLC</p>

    <p><a href="https://codecov.io/gh/FluidNumerics/SELF" rel="nofollow"><img src="https://camo.githubusercontent.com/a61f758b6dcd29955a901ec91809a85598237190df84e0a2397c5a4641f1d609/68747470733a2f2f636f6465636f762e696f2f67682f466c7569644e756d65726963732f53454c462f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d414b4b534c3543574b36"
    alt="codecov" data-canonical-src="https://codecov.io/gh/FluidNumerics/SELF/branch/main/graph/badge.svg?token=AKKSL5CWK6"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-licensing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#licensing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Licensing</h2>

    <p>SELF is licensed for use under a <a href="./LICENSE">non-commercial use visible-source
    license</a>. Fluid Numerics is a small family-owned business and wants to make
    SELF available to researchers for academic use. Under the license, you can use,
    modify, and redistribute SELF so long as attribution is given to Fluid Numerics.
    However, since we are interested in protecting our time-and-effort investment
    in SELF, sale and commercial-use of SELF is prohibited under the license.</p>

    <p>If you are interested in commercial licensure and would like support from Fluid
    Numerics, reach out to <a href="mailto:support@fluidnumerics.com">support@fluidnumerics.com</a></p>

    <h2><a id="user-content-about" class="anchor" aria-hidden="true" tabindex="-1"
    href="#about"><span aria-hidden="true" class="octicon octicon-link"></span></a>About</h2>

    <p>SELF is an object-oriented Fortran library that support the implementation
    of Spectral Element Methods for solving partial differential equations.</p>

    <p>The SELF API is designed based on the assumption that SEM developers and researchers
    need to be able to implement derivatives in 1-D and divergence, gradient, and
    curl in 2-D and 3-D on scalar, vector, and tensor functions using spectral collocation,
    continuous galerkin, and discontinuous galerkin spectral element methods. Additionally,
    as we enter the exascale era, we are currently faced with a zoo of compute hardware
    that is available. Because of this, SELF routines provide support for GPU acceleration
    through AMD''s HIP and support for multi-core, multi-node, and multi-GPU platforms
    with MPI.</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p><code>self</code> can be installed using CMake on Linux platforms that have
    the following packages already installed</p>

    <ul>

    <li>CMake (3.21-3.27)</li>

    <li>2008 standard compliant Fortran Compiler</li>

    <li>ROCm 5.7.0 or greater</li>

    <li>CUDA 11 or greater (if building for Nvidia GPU)</li>

    <li>HDF5</li>

    <li><a href="https://github.com/fluidnumerics/feq-parse">FEQParse</a></li>

    </ul>

    <h3><a id="user-content-prerequisites" class="anchor" aria-hidden="true" tabindex="-1"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h3>

    <p>All you need is a Fortran compiler that is compliant with the Fortran 2008
    standard and supports C interoperability. You can see which compilers are regularly
    tested on the <a href="https://github.com/FluidNumerics/feq-parse/actions/workflows/ci.yml">Github
    actions page</a>. Additionally, the table below lists the <a href="#supported-compilers">supported
    compilers</a></p>

    <h3><a id="user-content-cmake" class="anchor" aria-hidden="true" tabindex="-1"
    href="#cmake"><span aria-hidden="true" class="octicon octicon-link"></span></a>CMake</h3>

    <p>For a quick installation to <code>${HOME}/.local/self</code>,</p>

    <pre><code>mkdir build/

    cd build/

    cmake ../ -DCMAKE_INSTALL_PREFIX=${HOME}/.local/self

    make

    sudo make install

    </code></pre>

    <p>If you''d like to run the provided tests to verify your installation, use <code>ctest</code>
    to run the provided tests from within the <code>build/</code> directory</p>

    <pre><code>ctest .

    </code></pre>

    <p>The above steps install</p>

    <pre><code>${HOME}/.local/self/lib/libself-static.a

    ${HOME}/.local/self/lib/libself.so

    ${HOME}/.local/self/include/*.mod

    ${HOME}/.local/self/example/

    ${HOME}/.local/self/test

    </code></pre>

    <h2><a id="user-content-supported-compilers-operating-systems-and-software-stacks"
    class="anchor" aria-hidden="true" tabindex="-1" href="#supported-compilers-operating-systems-and-software-stacks"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Supported Compilers,
    Operating Systems, and software stacks</h2>

    <p>The following combinations are tested on the main branch of self :</p>

    <table>

    <thead>

    <tr>

    <th>Name</th>

    <th>Version</th>

    <th>Platform</th>

    <th>Build System</th>

    <th>Stack</th>

    <th>Architecture</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>GNU Fortran</td>

    <td>13.2.0</td>

    <td>Ubuntu 22.04.2 LTS</td>

    <td><code>cmake</code></td>

    <td>openmpi/5.0.0, feq-parse/2.0.3, hdf5/1.12.2</td>

    <td>x86_64 - gfx90a</td>

    </tr>

    <tr>

    <td>GNU Fortran</td>

    <td>13.2.0</td>

    <td>Ubuntu 22.04.2 LTS</td>

    <td><code>cmake</code></td>

    <td>openmpi/5.0.0, feq-parse/2.0.3, hdf5/1.12.2</td>

    <td>x86_64 - gfx906</td>

    </tr>

    </tbody>

    </table>

    <p>"Supported" for us means that we test <code>self</code> regularly on the platforms
    listed. Of course, we want to have <code>self</code> working on as many platforms
    as possible; <a href="https://github.com/FluidNumerics/SELF/issues/new/choose">open
    an issue</a> if you encounter any problems installing or running <code>self</code>
    on your own platform.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#support"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <h3><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h3>

    <ul>

    <li><a href="https://fluidnumerics.github.io/SELF" rel="nofollow"><strong>User
    &amp; Developer Documentation</strong></a></li>

    <li><a href="https://fluidnumerics.github.io/SELF/ford/" rel="nofollow"><strong>API
    Documentation</strong></a></li>

    </ul>

    <p>If you''d like to contribute, see <a href="./CONTRIBUTING.md">CONTRIBUTING.md</a>
    to get started.</p>

    <p>If you need help, <a href="https://github.com/FluidNumerics/SELF/issues/new">open
    an issue</a></p>

    '
  stargazers_count: 42
  subscribers_count: 6
  topics:
  - spectral-element-method
  - gpu-acceleration
  - gpu-computing
  - hpc
  - pde-solver
  updated_at: 1704762502.0
GEOS-DEV/GEOS:
  data_format: 2
  description: GEOS Simulation Framework
  filenames:
  - scripts/pygeosx_configs/blueos_3_ppc64le_ib_p9/spack.yaml
  - scripts/pygeosx_configs/toss_4_x86_64_ib/spack.yaml
  full_name: GEOS-DEV/GEOS
  latest_release: v1.0.1
  readme: '<p><a href="https://zenodo.org/badge/latestdoi/131810578" rel="nofollow"><img
    src="https://camo.githubusercontent.com/9c0760932d168b68bde7fb1623f1727acad25f306fc5609a1b38d392888ae7dd/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3133313831303537382e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/131810578.svg" style="max-width:
    100%;"></a>

    <a href="https://codecov.io/github/GEOS-DEV/GEOS" rel="nofollow"><img src="https://camo.githubusercontent.com/1c8900c4ee778b688be56b9a8e1618325ce04dbe7f3db14f033e4af735640493/68747470733a2f2f636f6465636f762e696f2f6769746875622f47454f532d4445562f47454f532f67726170682f62616467652e7376673f746f6b656e3d30565445485051473538"
    alt="codecov" data-canonical-src="https://codecov.io/github/GEOS-DEV/GEOS/graph/badge.svg?token=0VTEHPQG58"
    style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/GEOS-DEV/GEOS/actions/workflows/ci_tests.yml/badge.svg"><img
    src="https://github.com/GEOS-DEV/GEOS/actions/workflows/ci_tests.yml/badge.svg"
    alt="CI" style="max-width: 100%;"></a>

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2b6c2fc0d68b06cb042bb53ee5bcc4f8d55169fc19297eeff32d0cf3ca8b9b91/68747470733a2f2f72656164746865646f63732e636f6d2f70726f6a656374732f67656f73782d67656f73782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="docs" data-canonical-src="https://readthedocs.com/projects/geosx-geosx/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-welcome-to-the-geos-project" class="anchor" aria-hidden="true"
    tabindex="-1" href="#welcome-to-the-geos-project"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Welcome to the GEOS project!</h2>

    <p>GEOS is a simulation framework for modeling coupled flow, transport, and geomechanics

    in the subsurface.  The code provides advanced solvers for a number of target
    applications,

    including</p>

    <ul>

    <li>carbon sequestration,</li>

    <li>geothermal energy,</li>

    <li>and similar systems.</li>

    </ul>

    <p>A key focus of the project is achieving scalable performance on current and
    next-generation

    high performance computing systems.  We do this through a portable programming
    model and research into scalable algorithms.</p>

    <p>You may want to browse our

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Publications.html"
    rel="nofollow">publications</a>

    page for more details on the HPC, numerics,

    and applied engineering components of this effort.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Our documentation is hosted <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/?"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-who-develops-geos" class="anchor" aria-hidden="true" tabindex="-1"
    href="#who-develops-geos"><span aria-hidden="true" class="octicon octicon-link"></span></a>Who
    develops GEOS?</h2>

    <p>GEOS is an open source project and is developed by a community of researchers
    at

    several institutions.  The bulk of the code has been written by contributors from

    four main organizations:</p>

    <ul>

    <li>Lawrence Livermore National Laboratory,</li>

    <li>Stanford University,</li>

    <li>TotalEnergies,</li>

    <li>Chevron</li>

    </ul>

    <p>See our

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Contributors.html"
    rel="nofollow">authors</a>

    and

    <a href="https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Acknowledgements.html"
    rel="nofollow">acknowledgements</a>

    page for more details.</p>

    <h2><a id="user-content-how-does-geos-relate-to-the-earlier-geos-code" class="anchor"
    aria-hidden="true" tabindex="-1" href="#how-does-geos-relate-to-the-earlier-geos-code"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How does GEOS relate
    to the earlier GEOS code?</h2>

    <p>GEOS is the offshoot of an earlier code developed at LLNL also called GEOS.  The
    new

    code differs from our previous efforts in two important ways:</p>

    <ul>

    <li>This new code GEOS uses a fundamentally different programming model to achieve

    high performance on the complicated chip architectures common on today''s

    HPC systems.  This code is ready for exascale-class systems as they are delivered.</li>

    <li>The new code has been released as an open-source effort to encourage collaboration

    within the research and industrial community.  See the release notes below

    for details of the <a href="./LICENSE">LGPL 2.1 License</a> that has been adopted.</li>

    </ul>

    <h2><a id="user-content-release" class="anchor" aria-hidden="true" tabindex="-1"
    href="#release"><span aria-hidden="true" class="octicon octicon-link"></span></a>Release</h2>

    <p>For release details and restrictions, please read the <a href="./LICENSE">LICENSE</a>
    file.</p>

    <p>For copyrights, please read the <a href="./COPYRIGHT">COPYRIGHT</a> file.</p>

    <p>For contributors, please read the <a href="./CONTRIBUTORS">CONTRIBUTORS</a>
    file.</p>

    <p>For acknowledgements, please read the <a href="./ACKNOWLEDGEMENTS">ACKNOWLEDGEMENTS</a>
    file.</p>

    <p>For notice, please read the <a href="./NOTICE">NOTICE</a> file.</p>

    <p><code>LLNL-CODE-812638</code>  <code>OCEC-18-021</code></p>

    '
  stargazers_count: 190
  subscribers_count: 31
  topics:
  - hpc
  - reservoir-simulation
  - geomechanics
  - gpu
  - carbon-storage
  - llnl
  updated_at: 1707861018.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1658856345.0
HenryWinterbottom-NOAA/ufs_containers:
  data_format: 2
  description: This repository contains Docker and spack recipes for building Docker
    containers supporting UFS related applications.
  filenames:
  - configs/ufs_utils.spack.yaml
  full_name: HenryWinterbottom-NOAA/ufs_containers
  latest_release: null
  readme: "<p><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_pyutils/blob/develop/LICENSE\"\
    ><img src=\"https://camo.githubusercontent.com/e07eaae0e5aae158c14dfd8fdbf03144f0823ecb696ae28db7b2de14397589f3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76322e312d626c61636b\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/License-LGPL_v2.1-black\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c7128673eefb978ba86339a5f8b1cba37a58d14219d014708f1e91ddd808b89b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e75782d7562756e747525374363656e746f732d6c6967687467726579\"\
    ><img src=\"https://camo.githubusercontent.com/c7128673eefb978ba86339a5f8b1cba37a58d14219d014708f1e91ddd808b89b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e75782d7562756e747525374363656e746f732d6c6967687467726579\"\
    \ alt=\"Linux\" data-canonical-src=\"https://img.shields.io/badge/Linux-ubuntu%7Ccentos-lightgrey\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/9666fba46c09fda89dc5297a52b9d138317f7e5db0ba3c4b76c2586afac81ef4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e35253743332e36253743332e372d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/9666fba46c09fda89dc5297a52b9d138317f7e5db0ba3c4b76c2586afac81ef4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e35253743332e36253743332e372d626c7565\"\
    \ alt=\"Python Version\" data-canonical-src=\"https://img.shields.io/badge/Python-3.5%7C3.6%7C3.7-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/f83de6cc3609b0ab58cd84c194d3d669f586dc01bdc6d80e4bafc7702e63ef16/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f64652532305374796c652d626c61636b2d707572706c652e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/Code%20Style-black-purple.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_containers/actions/workflows/pycodestyle.yaml\"\
    ><img src=\"https://github.com/HenryWinterbottom-NOAA/ufs_containers/actions/workflows/pycodestyle.yaml/badge.svg\"\
    \ alt=\"Python Coding Standards\" style=\"max-width: 100%;\"></a></p>\n<h1><a\
    \ id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#overview\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Overview</h1>\n<p>This repository contains Docker and spack recipes\
    \ for building Docker\ncontainers supporting Unified Forecast System (UFS) related\n\
    applications.</p>\n<ul>\n<li>\n<strong>Authors:</strong> <a href=\"mailto:henry.winterbottom@noaa.gov\"\
    >Henry R. Winterbottom</a>\n</li>\n<li>\n<strong>Maintainers:</strong> Henry R.\
    \ Winterbottom</li>\n<li>\n<strong>Version:</strong> 0.0.1</li>\n<li>\n<strong>License:</strong>\
    \ LGPL v2.1</li>\n<li>\n<strong>Copyright</strong>: Henry R. Winterbottom</li>\n\
    </ul>\n<h1><a id=\"user-content-cloning\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#cloning\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Cloning</h1>\n<p>This repository utilizes several\
    \ sub-modules from various sources. To\nobtain the entire system, do as follows.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>user@host:$ git clone --recursive\
    \ https://github.com/HenryWinterbottom-NOAA/ufs_containers /path/to/ufs_containers</pre></div>\n\
    <h1><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Dependencies</h1>\n<p>The package dependencies and\
    \ the respective repository and manual\ninstallation attributes are provided in\
    \ the table below.</p>\n<div align=\"left\">\n<table>\n<thead>\n<tr>\n<th align=\"\
    center\">Dependency Package</th>\n<th align=\"center\"><div align=\"left\">Installation\
    \ Instructions</div></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"\
    ><div align=\"left\"><a href=\"https://github.com/HenryWinterbottom-NOAA/ufs_pyutils\"\
    ><code>ufs_pyutils</code></a></div></td>\n<td align=\"center\"><div align=\"left\"\
    ><code>git+https://www.github.com/HenryWinterbottom-NOAA/ufs_pyutils.git</code></div></td>\n\
    </tr>\n</tbody>\n</table>\n<h1><a id=\"user-content-installing-package-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-package-dependencies\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ Package Dependencies</h1>\n<p>In order to install the respective Python packages\
    \ upon which\n<code>ufs_diags</code> is dependent, do as follows.</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>user@host:$ <span class=\"pl-c1\">cd</span>\
    \ /path/to/ufs_containers\nuser@host:$ /path/to/pip install update\nuser@host:$\
    \ /path/to/pip install -r /path/to/ufs_containers/requirements.txt</pre></div>\n\
    <p>For additional information using <code>pip</code> and <code>requirements.txt</code>\
    \ type files, see <a href=\"https://pip.pypa.io/en/stable/reference/requirements-file-format/\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h1><a id=\"user-content-building-spack-configuration-files\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-spack-configuration-files\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ Spack Configuration Files</h1>\n<p>To build the configuration files that <code>spack</code>\
    \ requires, an application\nhas been provided and can be executed as described\
    \ below.</p>\n<div class=\"highlight highlight-source-shell\"><pre>user@host:$\
    \ <span class=\"pl-c1\">cd</span> /path/to/ufs_containers/scripts\nuser@host:$\
    \ ./build_specs.py -h\n\nUsage: build_specs.py [-h] [--spack_yaml SPACK_YAML]\
    \ yaml\n\nSpack stack package specification(s) application interface.\n\nPositional\
    \ Arguments:\n  yaml                  YAML-formatted file containing the Spack\
    \ containerized stack package specification.\n\nOptional Arguments:\n  -h, --help\
    \            show this <span class=\"pl-c1\">help</span> message and <span class=\"\
    pl-c1\">exit</span>\n  --spack_yaml, -out SPACK_YAML\n                       \
    \ A YAML-formatted file containing the spack specification attributes.\n\nuser@host:$\
    \ ./build_specs.py /path/to/ufs_containers/parm/spack_demo.yaml --spack_yaml /path/to/ufs_containers/scripts/spack.yaml</pre></div>\n\
    <p>The resulting YAML-formatted file containing the <code>spack</code> instructions\n\
    described within the <code>/path/to/ufs_containers/parm/spack_demo.yaml</code>\
    \ in\nthe previous step will appear as follows.</p>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre><span class=\"pl-ent\">spack</span>:\n  <span class=\"pl-ent\">container</span>:\n\
    \    <span class=\"pl-ent\">format</span>: <span class=\"pl-s\">docker</span>\n\
    \  <span class=\"pl-ent\">specs</span>:\n  - <span class=\"pl-s\">package_1</span>\n\
    \  - <span class=\"pl-s\">package_2</span>\n  - <span class=\"pl-s\">package_3</span></pre></div>\n\
    <p>Additional, supported applications, can be found beneath\n<code>/path/to/ufs_containers/parm</code>.</p>\n\
    <h1><a id=\"user-content-building-using-docker-services\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#building-using-docker-services\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building Using Docker Services</h1>\n\
    <p>To <code>build</code>, <code>push</code>, and <code>cleanup</code> all Docker\
    \ services images, do as follows.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>user@host:$ <span class=\"pl-c1\">cd</span> /path/to/ufs_containers/scripts\n\
    user@host:$ ./docker_services.py --help\n\nUsage: docker_services.py [-h] [-build]\
    \ [-cleanup] [-push] compose env\n\nDocker services interface.\n\nPositional Arguments:\n\
    \  compose     Docker compose YAML-formatted services file.\n  env         Docker\
    \ compose YAML-formatted environment configuration file.\n\nOptional Arguments:\n\
    \  -h, --help  show this <span class=\"pl-c1\">help</span> message and <span class=\"\
    pl-c1\">exit</span>\n  -build      Build the specified Docker service images.\n\
    \  -cleanup    Cleanup <span class=\"pl-k\">local</span> services images.\n  -push\
    \       Push existing images to their respective repositories.\n\nuser@host:$\
    \ ./docker_services.py /path/to/ufs_containers/Docker/docker_services.yaml /path/to/ufs_containers/Docker/docker_services_env.yaml\
    \ --build --push --cleanup</pre></div>\n<h1><a id=\"user-content-forking\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#forking\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Forking</h1>\n<p>If a user wishes\
    \ to contribute modifications done within their\nrespective fork(s) to the authoritative\
    \ repository, we request that\nthe user first submit an issue and that the fork\
    \ naming conventions\nfollow those listed below.</p>\n<ul>\n<li>\n<p><code>docs/user_fork_name</code>:\
    \ Documentation additions and/or corrections for the application(s).</p>\n</li>\n\
    <li>\n<p><code>feature/user_fork_name</code>: Additions, enhancements, and/or\
    \ upgrades for the application(s).</p>\n</li>\n<li>\n<p><code>fix/user_fork_name</code>:\
    \ Bug-type fixes for the application(s) that do not require immediate attention.</p>\n\
    </li>\n<li>\n<p><code>hotfix/user_fork_name</code>: Bug-type fixes which require\
    \ immediate attention to fix issues that compromise the integrity of the respective\
    \ application(s).</p>\n</li>\n</ul>\n</div>"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - docker
  - spack
  - docker-services
  updated_at: 1696729175.0
JCSDA/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/ufs-weather-model/spack.yaml
  - configs/templates/gsi-addon-dev/spack.yaml
  - configs/templates/skylab-dev/spack.yaml
  full_name: JCSDA/spack-stack
  latest_release: 1.6.0
  readme: '<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"><img
    src="https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png"
    width="425" style="max-width: 100%;"></a></p>

    <p>Spack-stack is a framework for installing software libraries to support

    NOAA''s Unified Forecast System (UFS) applications and the

    Joint Effort for Data assimilation Integration (JEDI) coupled to

    several Earth system prediction models (MPAS, NEPTUNE, UM, FV3, GEOS, UFS).</p>

    <p>Spack-stack supports installations on a range of R&amp;D and operational platforms.

    It provides a set of installation templates (package lists), default package settings,

    system configurations for a range of <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">macOS and Linux workstation, HPC, and cloud

    platforms</a>, and Spack extensions, and uses a fork of the

    <a href="https://github.com/spack/spack">Spack repository</a>. <a href="https://spack.io/"
    rel="nofollow">Spack</a> is a

    community-supported, multi-platform package manager

    developed by Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about Spack, see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for Spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">Spack
    documentation</a>.</p>

    <p><strong>To get started with spack-stack</strong>, either by using an existing

    installation on a <a href="https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html"
    rel="nofollow">supported platform</a>

    or by <a href="https://spack-stack.readthedocs.io/en/latest/CreatingEnvironments.html"
    rel="nofollow">creating a new installation</a>, see the

    <a href="https://spack-stack.readthedocs.io/en/latest/Overview.html#getting-started"
    rel="nofollow">Getting Started</a> documentation page.

    Full documentation with table of contents can be found at <a href="https://spack-stack.readthedocs.io/en/latest/"
    rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a>.</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li>

    <a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a>: <a href="https://www.github.com/AlexanderRichert-NOAA">Alex
    Richert</a>, <a href="https://www.github.com/Hang-Lei-NOAA">Hang Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed
    Hartnett</a>

    </li>

    <li>

    <a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a>: <a href="https://www.github.com/climbfuji">Dom
    Heinzeller</a>, <a href="https://github.com/srherbener">Steve Herbener</a>

    </li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>: <a href="https://github.com/ulmononian">Cam Book</a>, <a href="https://github.com/natalie-perlin">Natalie
    Perlin</a>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    '
  stargazers_count: 18
  subscribers_count: 11
  topics: []
  updated_at: 1706055973.0
LLNL/DiHydrogen:
  data_format: 2
  description: null
  filenames:
  - .gitlab/spack/environments/pascal/spack.yaml
  - .gitlab/spack/environments/quartz/spack.yaml
  full_name: LLNL/DiHydrogen
  latest_release: v0.3.0
  readme: '<h1><a id="user-content-dihydrogen" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dihydrogen"><span aria-hidden="true" class="octicon octicon-link"></span></a>DiHydrogen</h1>

    <p>DiHydrogen is the second version of the

    <a href="https://github.com/llnl/elemental">Hydrogen</a> fork of the well-known

    distributed linear algebra library,

    <a href="https://github.com/elemental/elemental">Elemental</a>.  DiHydrogen aims

    to be a basic distributed multilinear algebra interface with a

    particular emphasis on the needs of the distributed machine learning

    effort, <a href="https://github.com/llnl/lbann">LBANN</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>DiHydrogen is distributed under the terms of the Apache License (Version 2.0).</p>

    <p>All new contributions must be made under the Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/LLNL/DiHydrogen/blob/develop/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/NOTICE">NOTICE</a> for
    details.</p>

    <p>SPDX-License-Identifier: Apache-2.0</p>

    <p>LLNL-CODE-800100</p>

    '
  stargazers_count: 5
  subscribers_count: 11
  topics:
  - cpp
  - math-physics
  updated_at: 1706928333.0
LLNL/Tribol:
  data_format: 2
  description: Modular interface physics library featuring state-of-the-art contact
    physics methods.
  filenames:
  - scripts/spack/configs/blueos_3_ppc64le_ib_p9/spack.yaml
  full_name: LLNL/Tribol
  latest_release: null
  readme: '<h1><a id="user-content-tribol-contact-interface-physics-library" class="anchor"
    aria-hidden="true" tabindex="-1" href="#tribol-contact-interface-physics-library"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Tribol: Contact Interface
    Physics Library</h1>

    <p>High fidelity simulations modeling complex interactions of moving bodies require
    specialized contact algorithms to

    enforce zero-interpenetration constraints between surfaces. Tribol provides a
    unified interface for various

    contact algorithms, including contact search, detection and enforcement, thereby
    enabling the research and development

    of advanced contact algorithms.</p>

    <h2><a id="user-content-quick-start-guide" class="anchor" aria-hidden="true" tabindex="-1"
    href="#quick-start-guide"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quick
    Start Guide</h2>

    <h3><a id="user-content-clone-the-repository" class="anchor" aria-hidden="true"
    tabindex="-1" href="#clone-the-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Clone the repository</h3>

    <pre><code>git clone --recursive git@github.com:LLNL/Tribol.git

    </code></pre>

    <h3><a id="user-content-setup-for-development" class="anchor" aria-hidden="true"
    tabindex="-1" href="#setup-for-development"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Setup for development</h3>

    <p>Development tools can optionally be installed through the Spack package manager.
    Development tools are typically not

    needed when using Tribol. The command to install development tools is</p>

    <pre><code>python3 scripts/uberenv/uberenv.py --project-json=scripts/spack/devtools.json
    --spack-env-file=scripts/spack/configs/&lt;platform&gt;/spack.yaml --prefix=../tribol_devtools

    </code></pre>

    <p>where <code>&lt;platform&gt;</code> is one of <code>blueos_3_ppc64le_ib_p9</code>,
    <code>linux_ubuntu_20</code>, <code>linux_ubuntu_22</code>, <code>toss_4_x86_64_ib</code>,
    or

    <code>toss_4_x86_64_ib_cray</code>. Please verify <code>scripts/spack/configs/&lt;platform&gt;/spack.yaml</code>
    matches your system configuration.</p>

    <h3><a id="user-content-installing-dependencies" class="anchor" aria-hidden="true"
    tabindex="-1" href="#installing-dependencies"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Installing dependencies</h3>

    <p>Tribol dependency installation is managed through uberenv, which invokes a
    local instance of the spack package manager

    to install and manage dependencies. To install dependencies, run</p>

    <pre><code>python3 scripts/uberenv/uberenv.py --spack-env-file=scripts/spack/configs/&lt;platform&gt;/spack.yaml
    --prefix=../tribol_libs

    </code></pre>

    <p>See additional options by running</p>

    <pre><code>python3 scripts/uberenv/uberenv.py --help

    </code></pre>

    <p>Tribol is tested on three platforms:</p>

    <ul>

    <li>Ubuntu 22.04 LTS (via Windows WSL 2)</li>

    <li>TOSS 4</li>

    <li>BlueOS</li>

    </ul>

    <p>See <code>scripts/spack/packages/tribol/package.py</code> for possible variants
    in the spack spec. The file

    <code>scripts/spack/specs.json</code> lists spack specs which are known to build
    successfully on different platforms.  Note the

    development tools can be built with dependencies using the <code>+devtools</code>
    variant.</p>

    <h3><a id="user-content-build-the-code" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build-the-code"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    the code</h3>

    <p>After running uberenv, a host config file is created in the tribol repo root
    directory.  Use the <code>config-build.py</code>

    script to create build and install directories and invoke CMake.</p>

    <pre><code>python3 ./config-build.py -hc &lt;host-config&gt;

    </code></pre>

    <p>Enter the build directory and run</p>

    <pre><code>make -j

    </code></pre>

    <p>to build Tribol.</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>The Tribol contact physics library requires:</p>

    <ul>

    <li>CMake 3.14 or higher</li>

    <li>C++14 compiler</li>

    <li>MPI</li>

    <li>mfem</li>

    <li>axom</li>

    </ul>

    <p>Tribol has optional dependencies on:</p>

    <ul>

    <li>CUDA</li>

    <li>HIP</li>

    <li>RAJA</li>

    <li>Umpire</li>

    </ul>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Tribol is distributed under the terms of the MIT license. All new contributions
    must be

    made under this license.</p>

    <p>See <a href="LICENSE">LICENSE</a> and <a href="NOTICE">NOTICE</a> for details.</p>

    <p>SPDX-License-Identifier: MIT</p>

    <p>LLNL-CODE-846697</p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spdx-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPDX
    usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as MIT contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (MIT)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" tabindex="-1"
    href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>External
    Packages</h2>

    <p>Tribol bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 18
  subscribers_count: 7
  topics:
  - math-physics
  updated_at: 1706672650.0
LLNL/Umpire:
  data_format: 2
  description: An application-focused API for memory management on NUMA & GPU architectures
  filenames:
  - .spack_env/darwin/spack.yaml
  full_name: LLNL/Umpire
  latest_release: v2023.06.0
  readme: '<h1><a id="user-content---umpire-v2023060" class="anchor" aria-hidden="true"
    tabindex="-1" href="#--umpire-v2023060"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/16f93148e0fba6da82ea7e29bc163792e4adfa6d97964ef301f27bb5804fe1ce/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"><img
    src="https://camo.githubusercontent.com/16f93148e0fba6da82ea7e29bc163792e4adfa6d97964ef301f27bb5804fe1ce/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"
    width="128" valign="middle" alt="Umpire" data-canonical-src="https://cdn.rawgit.com/LLNL/Umpire/develop/share/umpire/logo/umpire-logo.png"
    style="max-width: 100%;"></a>  Umpire v2023.06.0</h1>

    <p><a href="https://travis-ci.com/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/7b035b6565b7e96277667acd970a34d855ba58259be899a270de459ba1a42393/68747470733a2f2f7472617669732d63692e636f6d2f4c4c4e4c2f556d706972652e7376673f6272616e63683d646576656c6f70"
    alt="Travis Build Status" data-canonical-src="https://travis-ci.com/LLNL/Umpire.svg?branch=develop"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/davidbeckingsale/Umpire/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/67d5cb2c08560bb4582131e7ab385863faee5e7f89266ef73c47bdc7c0ff4544/68747470733a2f2f6465762e617a7572652e636f6d2f64617669646265636b696e6773616c652f556d706972652f5f617069732f6275696c642f7374617475732f4c4c4e4c2e556d706972653f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/davidbeckingsale/Umpire/_apis/build/status/LLNL.Umpire?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://umpire.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c43adcc35db9b22246733d2caaad138c624a56e87031c1e8e5f72f0c3752d0f5/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756d706972652f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/umpire/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/dec8e40b05ba312fc266977dc2ea2803d478e338856c3b8838437a8c72cf7264/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f556d706972652f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/Umpire/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a> <a href="https://gitter.im/LLNL/Umpire?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/b97e5039e17f725e41c4f915579646596c1bee4d17b93bcd958360b41c38c4d8/68747470733a2f2f6261646765732e6769747465722e696d2f4c4c4e4c2f556d706972652e737667"
    alt="Join the chat at https://gitter.im/LLNL/Umpire" data-canonical-src="https://badges.gitter.im/LLNL/Umpire.svg"
    style="max-width: 100%;"></a></p>

    <p>Umpire is a resource management library that allows the discovery, provision,

    and management of memory on machines with multiple memory devices like NUMA and
    GPUs.</p>

    <p>Umpire uses CMake and BLT to handle builds. Since BLT is included as a

    submodule, first make sure you run:</p>

    <pre><code>$ git submodule init &amp;&amp; git submodule update

    </code></pre>

    <p>Then, make sure that you have a modern compiler loaded, and the configuration
    is as

    simple as:</p>

    <pre><code>$ mkdir build &amp;&amp; cd build

    $ cmake ..

    </code></pre>

    <p>CMake will provide output about which compiler is being used. Once CMake has

    completed, Umpire can be built with Make:</p>

    <pre><code>$ make

    </code></pre>

    <p>For more advanced configuration you can use standard CMake variables.</p>

    <h1><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>Both user and code documentation is available <a href="http://umpire.readthedocs.io/"
    rel="nofollow">here</a>.</p>

    <p>The Umpire <a href="https://umpire.readthedocs.io/en/develop/sphinx/tutorial.html"
    rel="nofollow">tutorial</a> provides a step by step introduction to Umpire features.</p>

    <p>If you have build problems, we have comprehensive <a href="https://umpire.readthedocs.io/en/develop/sphinx/advanced_configuration.html"
    rel="nofollow">build system documentation</a> too!</p>

    <h1><a id="user-content-getting-involved" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-involved"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Involved</h1>

    <p>Umpire is an open-source project, and we welcome contributions from the community.</p>

    <h2><a id="user-content-mailing-list" class="anchor" aria-hidden="true" tabindex="-1"
    href="#mailing-list"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mailing
    List</h2>

    <p>The Umpire mailing list is hosted on Google Groups, and is a great place to
    ask questions:</p>

    <ul>

    <li><a href="https://groups.google.com/forum/#!forum/umpire-users" rel="nofollow">Umpire
    Users Google Group</a></li>

    </ul>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits; it''s all great!</p>

    <p>To contribute, make a <a href="https://github.com/LLNL/Umpire/compare">pull
    request</a>, with <code>develop</code> as the destination branch.

    We use Travis to run CI tests, and your branch must pass these tests before being
    merged.</p>

    <p>For more information, see the <a href="https://github.com/LLNL/Umpire/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h1><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h1>

    <p>Thanks to all of Umpire''s

    <a href="https://github.com/LLNL/Umpire/graphs/contributors">contributors</a>.</p>

    <p>Umpire was created by David Beckingsale (<a href="mailto:david@llnl.gov">david@llnl.gov</a>).</p>

    <h2><a id="user-content-citing-umpire" class="anchor" aria-hidden="true" tabindex="-1"
    href="#citing-umpire"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citing
    Umpire</h2>

    <p>If you are referencing Umpire in a publication, please use the following citation:</p>

    <ul>

    <li>D. Beckingsale, M. Mcfadden, J. Dahm, R. Pankajakshan and R. Hornung, <a href="https://ieeexplore.ieee.org/document/8907404"
    rel="nofollow">"Umpire: Application-Focused Management and Coordination of Complex
    Hierarchical Memory,"</a> in IBM Journal of Research and Development. 2019. doi:
    10.1147/JRD.2019.2954403</li>

    </ul>

    <h1><a id="user-content-release" class="anchor" aria-hidden="true" tabindex="-1"
    href="#release"><span aria-hidden="true" class="octicon octicon-link"></span></a>Release</h1>

    <p>Umpire is released under an MIT license. For more details, please see the

    <a href="./LICENSE">LICENSE</a> and <a href="./RELEASE">RELEASE</a> files.</p>

    <p><code>LLNL-CODE-747640</code>

    <code>OCEC-18-031</code></p>

    '
  stargazers_count: 287
  subscribers_count: 16
  topics:
  - hpc
  - memory-management
  - gpu
  - blt
  - portability
  - radiuss
  - cpp
  updated_at: 1707436757.0
LLNL/UnifyFS:
  data_format: 2
  description: 'UnifyFS: A file system for burst buffers'
  filenames:
  - .spack-env/unifyfs-lsf-gcc4_9_3/spack.yaml
  - .spack-env/unifyfs-slurm-gcc12_1_1/spack.yaml
  - .spack-env/unifyfs-lsf-gcc11_2_1/spack.yaml
  full_name: LLNL/UnifyFS
  latest_release: v2.0
  readme: "<h1><a id=\"user-content-unifyfs-a-distributed-burst-buffer-file-system\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#unifyfs-a-distributed-burst-buffer-file-system\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UnifyFS:\
    \ A Distributed Burst Buffer File System</h1>\n<p>Node-local burst buffers are\
    \ becoming an indispensable hardware resource on\nlarge-scale supercomputers to\
    \ buffer the bursty I/O from scientific\napplications. However, there is a lack\
    \ of software support for burst buffers to\nbe efficiently shared by applications\
    \ within a batch-submitted job and recycled\nacross different batch jobs. In addition,\
    \ burst buffers need to cope with a\nvariety of challenging I/O patterns from\
    \ data-intensive scientific\napplications.</p>\n<p>UnifyFS is a user-level burst\
    \ buffer file system under active development.\nUnifyFS supports scalable and\
    \ efficient aggregation of I/O bandwidth from burst\nbuffers while having the\
    \ same life cycle as a batch-submitted job. While UnifyFS\nis designed for N-N\
    \ write/read, UnifyFS compliments its functionality with the\nsupport for N-1\
    \ write/read. It efficiently accelerates scientific I/O based on\nscalable metadata\
    \ indexing, co-located I/O delegation, and server-side read\nclustering and pipelining.</p>\n\
    <h2><a id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#documentation\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Documentation</h2>\n<p>UnifyFS documentation\
    \ is at <a href=\"https://unifyfs.readthedocs.io\" rel=\"nofollow\">https://unifyfs.readthedocs.io</a>.</p>\n\
    <p>For instructions on how to build and install UnifyFS,\nsee <a href=\"http://unifyfs.readthedocs.io/en/dev/build.html\"\
    \ rel=\"nofollow\">Build UnifyFS</a>.</p>\n<h2><a id=\"user-content-build-status\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#build-status\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build Status</h2>\n\
    <p>Status of UnifyFS development branch (dev):</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    ><img src=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://unifyfs.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/32daa6ee48d97cb528194d1ea7f20969e697b70bcd7fc76a159c9c10a5ed371b/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756e69667966732f62616467652f3f76657273696f6e3d646576\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/unifyfs/badge/?version=dev\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-unifyfs-citation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#unifyfs-citation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UnifyFS\
    \ Citation</h2>\n<p>We recommend that you use this citation for UnifyFS:</p>\n\
    <ul>\n<li>Michael Brim, Adam Moody, Seung-Hwan Lim, Ross Miller, Swen Boehm, Cameron\
    \ Stanavige, Kathryn Mohror, Sarp Oral, \u201CUnifyFS: A User-level Shared File\
    \ System for Unified Access to Distributed Local Storage,\u201D 37th IEEE International\
    \ Parallel &amp; Distributed Processing Symposium (IPDPS 2023), St. Petersburg,\
    \ FL, May 2023.</li>\n</ul>\n<h2><a id=\"user-content-contribute-and-develop\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contribute-and-develop\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contribute\
    \ and Develop</h2>\n<p>If you would like to help, please see our <a href=\"https://unifyfs.readthedocs.io/en/dev/contribute-ways.html\"\
    \ rel=\"nofollow\">contributing guidelines</a>.</p>\n"
  stargazers_count: 94
  subscribers_count: 20
  topics:
  - system-software
  - burst-buffers
  - file-system
  updated_at: 1705862353.0
LLNL/axom:
  data_format: 2
  description: CS infrastructure components for HPC applications
  filenames:
  - scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/blueos_3_ppc64le_ib_p9/spack.yaml
  full_name: LLNL/axom
  latest_release: v0.8.1
  readme: '<h1><a id="" class="anchor" aria-hidden="true" tabindex="-1" href="#"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a target="_blank"
    rel="noopener noreferrer" href="/share/axom/logo/axom_logo_transparent.png?raw=true"><img
    src="/share/axom/logo/axom_logo_transparent.png?raw=true" width="250" valign="middle"
    alt="Axom" style="max-width: 100%;"></a></h1>

    <p><a href="https://dev.azure.com/axom/axom/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/2e86a2917fe6af2683654deb988253bb0643de772d9b144c44792e0dee8267c5/68747470733a2f2f6465762e617a7572652e636f6d2f61786f6d2f61786f6d2f5f617069732f6275696c642f7374617475732f4c4c4e4c2e61786f6d3f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/axom/axom/_apis/build/status/LLNL.axom?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://axom.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/8723959c981c1cd7fa64e597cc73c149d9a423922f12dcaa572a9ddf30bb689c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f61786f6d2f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/axom/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/blob/develop/LICENSE"><img src="https://camo.githubusercontent.com/aa27bfae9200ad81b9c64e82edafa3aef061e2b59e4089eb0841297d510d5db9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/License-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/releases/latest"><img src="https://camo.githubusercontent.com/6532c8239e2f1f30a988264904337c2f4904be4b6867e704eb39e6c48a4b6f0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4c4c4e4c2f61786f6d2e737667"
    alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/LLNL/axom.svg"
    style="max-width: 100%;"></a></p>

    <p>Axom provides robust, flexible software infrastructure for the development
    of multi-physics applications and computational tools.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Latest docs on Develop branch: <a href="https://axom.readthedocs.io" rel="nofollow">https://axom.readthedocs.io</a></p>

    <p>To access docs for other versions: <a href="https://readthedocs.org/projects/axom/"
    rel="nofollow">https://readthedocs.org/projects/axom/</a></p>

    <h2><a id="user-content-getting-involved" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-involved"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Involved</h2>

    <p>Axom is an open-source project and we welcome contributions from the community.</p>

    <h2><a id="user-content-mailing-list" class="anchor" aria-hidden="true" tabindex="-1"
    href="#mailing-list"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mailing
    List</h2>

    <p>The project maintains two email lists:</p>

    <ul>

    <li>''<a href="mailto:axom-users@llnl.gov">axom-users@llnl.gov</a>'' is how Axom
    users can contact developers for questions, report issues, etc.</li>

    <li>''<a href="mailto:axom-dev@llnl.gov">axom-dev@llnl.gov</a>'' is for communication
    among team members.</li>

    </ul>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits.</p>

    <p>To contribute, make a <a href="https://github.com/llnl/axom/compare">pull request</a>,
    with <code>develop</code>

    as the destination branch. We use CI testing and your branch must pass these tests
    before

    being merged.</p>

    <p>For more information, see the <a href="https://github.com/llnl/axom/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Thanks to all of Axom''s

    <a href="https://github.com/llnl/axom/graphs/contributors">contributors</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Copyright (c) 2017-2024, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Axom project are retained by contributors.

    No copyright assignment is required to contribute to Axom.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution

    <code>LLNL-CODE-741217</code> <code>OCEC-17-187</code></p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spdx-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPDX
    usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" tabindex="-1"
    href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>External
    Packages</h2>

    <p>Axom bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: CLI11<br>

    PackageHomePage: <a href="https://github.com/CLIUtils/CLI11">https://github.com/CLIUtils/CLI11</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: fmt<br>

    PackageHomePage: <a href="https://github.com/fmtlib/fmt">https://github.com/fmtlib/fmt</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sol<br>

    PackageHomePage: <a href="https://github.com/ThePhD/sol2">https://github.com/ThePhD/sol2</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sparsehash<br>

    PackageHomePage: <a href="https://github.com/sparsehash/sparsehash">https://github.com/sparsehash/sparsehash</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 131
  subscribers_count: 24
  topics:
  - hpc
  - parallel-computing
  - llnl
  - cpp
  - c-plus-plus
  - app-infrastructure
  - radiuss
  - fortran
  updated_at: 1707250659.0
LLNL/benchpark:
  data_format: 2
  description: An open collaborative repository for reproducible specifications of
    HPC benchmarks and cross site benchmarking environments
  filenames:
  - configs/LLNL-Magma-Penguin-icelake-OmniPath/spack.yaml
  - configs/nosite-AWS_PCluster_Hpc7a-zen4-EFA/spack.yaml
  - configs/LLNL-Pascal-Penguin-broadwell-P100-OmniPath/spack.yaml
  full_name: LLNL/benchpark
  latest_release: null
  stargazers_count: 21
  subscribers_count: 8
  topics:
  - benchmark
  - hpc
  updated_at: 1705771552.0
LLNL/hiop:
  data_format: 2
  description: HPC solver for nonlinear optimization problems
  filenames:
  - scripts/platforms/marianas/spack.yaml
  - scripts/platforms/newell/spack.yaml
  full_name: LLNL/hiop
  latest_release: v1.0.3
  readme: "<h1><a id=\"user-content-hiop---hpc-solver-for-optimization\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#hiop---hpc-solver-for-optimization\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>HiOp - HPC\
    \ solver for optimization</h1>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\"><img src=\"\
    https://github.com/LLNL/hiop/workflows/tests/badge.svg\" alt=\"tests\" style=\"\
    max-width: 100%;\"></a></p>\n<p>HiOp is an optimization solver for solving certain\
    \ mathematical optimization problems expressed as nonlinear programming problems.\
    \ HiOp is a lightweight HPC solver that leverages application's existing data\
    \ parallelism to parallelize the optimization iterations by using specialized\
    \ parallel linear algebra kernels.</p>\n<p>Please cite the user manual whenever\
    \ HiOp is used:</p>\n<pre><code>@TECHREPORT{hiop_techrep,\n  title={{HiOp} --\
    \ {U}ser {G}uide},\n  author={Petra, Cosmin G. and Chiang, NaiYuan and Jingyi\
    \ Wang},\n  year={2018},\n  institution = {Center for Applied Scientific Computing,\
    \ Lawrence Livermore National Laboratory},\n  number = {LLNL-SM-743591}\n}\n</code></pre>\n\
    <p>In addition, when using the quasi-Newton solver please cite:</p>\n<pre><code>@ARTICLE{Petra_18_hiopdecomp,\n\
    title = {A memory-distributed quasi-Newton solver for nonlinear programming problems\
    \ with a small number of general constraints},\njournal = {Journal of Parallel\
    \ and Distributed Computing},\nvolume = {133},\npages = {337-348},\nyear = {2019},\n\
    issn = {0743-7315},\ndoi = {https://doi.org/10.1016/j.jpdc.2018.10.009},\nurl\
    \ = {https://www.sciencedirect.com/science/article/pii/S0743731518307731},\nauthor\
    \ = {Cosmin G. Petra},\n}\n</code></pre>\n<p>and when using the the PriDec solver\
    \ please cite:</p>\n<pre><code>@article{wang2023,\n  archivePrefix = {arXiv},\n\
    \  author = {J. Wang and C. G. Petra},\n  title = {A Sequential Quadratic Programming\
    \ Algorithm for Nonsmooth Problems with Upper-$\\mathcal{C}^2$ Objective},\n \
    \ journal = {SIAM Journal on Optimization},\n  volume = {33},\n  number = {3},\n\
    \  pages = {2379-2405},\n  year = {2023},\n  doi = {10.1137/22M1490995}\n}\n@INPROCEEDINGS{wang2021,\n\
    \  author={J. Wang and N. Chiang and C. G. Petra},\n  booktitle={2021 20th International\
    \ Symposium on Parallel and Distributed Computing (ISPDC)}, \n  title={An asynchronous\
    \ distributed-memory optimization solver for two-stage stochastic programming\
    \ problems}, \n  year={2021},\n  volume={},\n  number={},\n  pages={33-40},\n\
    \  doi={10.1109/ISPDC52870.2021.9521613}}\n }\n</code></pre>\n<h2><a id=\"user-content-buildinstall-instructions\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#buildinstall-instructions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build/install\
    \ instructions</h2>\n<p>HiOp uses a CMake-based build system. A standard build\
    \ can be done by invoking in the 'build' directory the following</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> cmake\
    \ ..\n$<span class=\"pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span>\
    \ make <span class=\"pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make\
    \ install</pre></div>\n<p>This sequence will build HiOp, run integrity and correctness\
    \ tests, and install the headers and the library in the directory '_dist-default-build'\
    \ in HiOp's root directory.</p>\n<p>Command <code>make test</code> runs extensive\
    \ tests of the various modules of HiOp to check integrity and correctness. The\
    \ tests suite range from unit testing to solving concrete optimization problems\
    \ and checking the performance of HiOp solvers on these problems against known\
    \ solutions. By default <code>make test</code> runs <code>mpirun</code> locally,\
    \ which may not work on some HPC machines. For these HiOp allows using <code>bsub</code>\
    \ to schedule <code>make test</code> on the compute nodes; to enable this, the\
    \ use should use <em>-DHIOP_TEST_WITH_BSUB=ON</em> with cmake when building and\
    \ run <code>make test</code> in a bsub shell session, for example,</p>\n<pre><code>bsub\
    \ -P your_proj_name -nnodes 1 -W 30\nmake test\nCTRL+D\n</code></pre>\n<p>The\
    \ installation can be customized using the standard CMake options. For example,\
    \ one can provide an alternative installation directory for HiOp by using</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span>\
    \ cmake -DCMAKE_INSTALL_PREFIX=/usr/lib/hiop ..<span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span></span></pre></div>\n<h3><a id=\"user-content-selected-hiop-specific-build-options\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#selected-hiop-specific-build-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selected\
    \ HiOp-specific build options</h3>\n<ul>\n<li>Enable/disable MPI: <em>-DHIOP_USE_MPI=[ON/OFF]</em>\
    \ (by default ON)</li>\n<li>GPU support: <em>-DHIOP_USE_GPU=ON</em>. MPI can be\
    \ either off or on. For more build system options related to GPUs, see \"Dependencies\"\
    \ section below.</li>\n<li>Enable/disable \"developer mode\" build that enforces\
    \ more restrictive compiler rules and guidelines: <em>-DHIOP_DEVELOPER_MODE=ON</em>.\
    \ This option is by default off.</li>\n<li>Additional checks and self-diagnostics\
    \ inside HiOp meant to detect abnormalities and help to detect bugs and/or troubleshoot\
    \ problematic instances: <em>-DHIOP_DEEPCHECKS=[ON/OFF]</em> (by default ON).\
    \ Disabling HIOP_DEEPCHECKS usually provides 30-40% execution speedup in HiOp.\
    \ For full strength, it is recommended to use HIOP_DEEPCHECKS with debug builds.\
    \ With non-debug builds, in particular the ones that disable the assert macro,\
    \ HIOP_DEEPCHECKS does not perform all checks and, thus, may overlook potential\
    \ issues.</li>\n</ul>\n<p>For example:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_MPI=ON -DHIOP_DEEPCHECKS=ON\
    \ ..\n$<span class=\"pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span>\
    \ make <span class=\"pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make\
    \ install</pre></div>\n<h3><a id=\"user-content-other-useful-options-to-use-with-cmake\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#other-useful-options-to-use-with-cmake\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other useful\
    \ options to use with CMake</h3>\n<ul>\n<li>\n<em>-DCMAKE_BUILD_TYPE=Release</em>\
    \ will build the code with the optimization flags on</li>\n<li>\n<em>-DCMAKE_CXX_FLAGS=\"\
    -O3\"</em> will enable a high level of compiler code optimization</li>\n</ul>\n\
    <h3><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Dependencies</h3>\n<p>A complete list of dependencies\
    \ is maintained <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/hiop/package.py\"\
    >here</a>.</p>\n<p>For a minimal build, HiOp requires LAPACK and BLAS. These dependencies\
    \ are automatically detected by the build system. MPI is optional and by default\
    \ enabled. To disable use cmake option '-DHIOP_USE_MPI=OFF'.</p>\n<p>HiOp has\
    \ support for NVIDIA <strong>GPU-based computations</strong> via CUDA and Magma.\
    \ To enable the use of GPUs, use cmake with '-DHIOP_USE_GPU=ON'. The build system\
    \ will automatically search for CUDA Toolkit. For non-standard CUDA Toolkit installations,\
    \ use '-DHIOP_CUDA_LIB_DIR=/path' and '-DHIOP_CUDA_INCLUDE_DIR=/path'. For \"\
    very\" non-standard CUDA Toolkit installations, one can specify the directory\
    \ of cuBlas libraries as well with '-DHIOP_CUBLAS_LIB_DIR=/path'.</p>\n<h3><a\
    \ id=\"user-content-using-raja-and-umpire-portability-libraries\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#using-raja-and-umpire-portability-libraries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using RAJA\
    \ and Umpire portability libraries</h3>\n<p>Portability libraries allow running\
    \ HiOp's linear algebra either on host (CPU) or a device (GPU). RAJA and Umpire\
    \ are disabled by default. You can turn them on together by passing <code>-DHIOP_USE_RAJA=ON</code>\
    \ to CMake. If the two libraries are not automatically found, specify their installation\
    \ directories like this:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_RAJA=ON -DRAJA_DIR=/path/to/raja/dir\
    \ -Dumpire_DIR=/path/to/umpire/dir</pre></div>\n<p>If the GPU support is enabled,\
    \ RAJA will run all HiOp linear algebra kernels on GPU, otherwise RAJA will run\
    \ the kernels on CPU using an OpenMP execution policy.</p>\n<h3><a id=\"user-content-support-for-gpu-computations\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#support-for-gpu-computations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Support\
    \ for GPU computations</h3>\n<p>When GPU support is on, HiOp requires Magma linear\
    \ solver library and CUDA Toolkit. Both are detected automatically in most cases.\
    \ The typical cmake command to enable GPU support in HiOp is</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> cmake\
    \ -DHIOP_USE_GPU=ON ..</pre></div>\n<p>When Magma is not detected, one can specify\
    \ its location by passing <code>-DHIOP_MAGMA_DIR=/path/to/magma/dir</code> to\
    \ cmake.</p>\n<p>For custom CUDA Toolkit installations, the locations to the (missing/not\
    \ found) CUDA libraries can be specified to cmake via <code>-DNAME=/path/cuda/directory/lib</code>,\
    \ where <code>NAME</code> can be any of</p>\n<pre><code>CUDA_cublas_LIBRARY\n\
    CUDA_CUDART_LIBRARY\nCUDA_cudadevrt_LIBRARY\nCUDA_cusparse_LIBRARY\nCUDA_cublasLt_LIBRARY\n\
    CUDA_nvblas_LIBRARY\nCUDA_culibos_LIBRARY\n</code></pre>\n<p>Below is an example\
    \ for specifiying <code>cuBlas</code>, <code>cuBlasLt</code>, and <code>nvblas</code>\
    \ libraries, which were <code>NOT_FOUND</code> because of a non-standard CUDA\
    \ Toolkit instalation:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span\
    \ class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_GPU=ON -DCUDA_cublas_LIBRARY=/usr/local/cuda-10.2/targets/x86_64-linux/lib/lib64\
    \ -DCUDA_cublasLt_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ -DCUDA_nvblas_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>A detailed example on how to compile HiOp straight\
    \ of the box on <code>summit.olcf.ornl.gov</code> is available <a href=\"README_summit.md\"\
    >here</a>.</p>\n<p>RAJA and UMPIRE dependencies are usually detected by HiOp's\
    \ cmake build system.</p>\n<h3><a id=\"user-content-kron-reduction\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#kron-reduction\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Kron reduction</h3>\n<p>Kron\
    \ reduction functionality of HiOp is disabled by default. One can enable it by\
    \ using</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span class=\"\
    pl-k\">&gt;</span> rm -rf <span class=\"pl-k\">*</span><span class=\"pl-k\">;</span>\
    \ cmake -DHIOP_WITH_KRON_REDUCTION=ON -DUMFPACK_DIR=/Users/petra1/work/installs/SuiteSparse-5.7.1\
    \ -DMETIS_DIR=/Users/petra1/work/installs/metis-4.0.3 .. <span class=\"pl-k\"\
    >&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span> make install</pre></div>\n\
    <p>Metis is usually detected automatically and needs not be specified under normal\
    \ circumstances.</p>\n<p>UMFPACK (part of SuiteSparse) and METIS need to be provided\
    \ as shown above.</p>\n<h1><a id=\"user-content-interfacing-with-hiop\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#interfacing-with-hiop\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Interfacing\
    \ with HiOp</h1>\n<p>HiOp supports three types of optimization problems, each\
    \ with a separate input formats in the form of the C++ interfaces <code>hiopInterfaceDenseConstraints</code>,<code>hiopInterfaceSparse</code>\
    \ and <code>hiopInterfaceMDS</code>. These interfaces are specified in <a href=\"\
    src/Interface/hiopInterface.hpp\">hiopInterface.hpp</a> and documented and discussed\
    \ as well in the <a href=\"doc/hiop_usermanual.pdf\">user manual</a>.</p>\n<p><em><code>hiopInterfaceDenseConstraints</code>\
    \ interface</em> supports NLPs with <strong>billions</strong> of variables with\
    \ and without bounds but only limited number (&lt;100) of general, equality and\
    \ inequality constraints. The underlying algorithm is a limited-memory quasi-Newton\
    \ interior-point method and generally scales well computationally (but it may\
    \ not algorithmically) on thousands of cores. This interface uses MPI for parallelization</p>\n\
    <p><em><code>hiopInterfaceSparse</code> interface</em> supports general sparse\
    \ and large-scale NLPs. This functionality is similar to that of the state-of-the-art\
    \ <a href=\"https://github.com/coin-or/Ipopt\">Ipopt</a> (without being as robust\
    \ and flexible as Ipopt is). Acceleration for this class of problems can be achieved\
    \ via OpenMP or CUDA, however, this is work in progress and you are encouraged\
    \ to contact HiOp's developers for up-to-date information.</p>\n<p><em><code>hiopInterfaceMDS</code>\
    \ interface</em> supports mixed dense-sparse NLPs and achives parallelization\
    \ using GPUs and RAJA portability abstraction layer.</p>\n<p>More information\
    \ on the HiOp interfaces are <a href=\"src/Interface/README.md\">here</a>.</p>\n\
    <h2><a id=\"user-content-running-hiop-tests-and-applications\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#running-hiop-tests-and-applications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ HiOp tests and applications</h2>\n<p>HiOp is using NVBlas library when built\
    \ with CUDA support. If you don't specify\nlocation of the <code>nvblas.conf</code>\
    \ configuration file, you may get an annoying\nwarnings. HiOp provides default\
    \ <code>nvblas.conf</code> file and installs it at the same\nlocation as HiOp\
    \ libraries. To use it, set environment variable as</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>$ <span class=\"pl-k\">export</span> NVBLAS_CONFIG_FILE=<span\
    \ class=\"pl-k\">&lt;</span>hiop install dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n\
    <p>or, if you are using C-shell, as</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ setenv NVBLAS_CONFIG_FILE <span class=\"pl-k\">&lt;</span>hiop install\
    \ dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n<h2><a id=\"\
    user-content-existing-issues\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#existing-issues\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Existing issues</h2>\n<p>Users are highly encouraged to report any\
    \ issues they found from using HiOp.\nOne known issue is that there is some minor\
    \ inconsistence between HiOp and linear package STRUMPACK.\nWhen STRUMPACK is\
    \ compiled with MPI (and Scalapack), user must set flag <code>HIOP_USE_MPI</code>\
    \ to <code>ON</code> when compiling HiOp.\nOtherwise HiOp won't load MPI module\
    \ and will return an error when links to STRUMPACK, since the later one requires\
    \ a valid MPI module.\nSimilarly, if both Magma and STRUMPACK are linked to HiOp,\
    \ user must guarantee the all the packages are compiled by the same CUDA compiler.\n\
    User can check other issues and their existing status from <a href=\"https://github.com/LLNL/hiop\"\
    >https://github.com/LLNL/hiop</a></p>\n<h2><a id=\"user-content-acknowledgments\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#acknowledgments\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h2>\n\
    <p>HiOp has been developed under the financial support of:</p>\n<ul>\n<li>Department\
    \ of Energy, Office of Advanced Scientific Computing Research (ASCR): Exascale\
    \ Computing Program (ECP) and Applied Math Program.</li>\n<li>Department of Energy,\
    \ Advanced Research Projects Agency-Energy (ARPA\u2011E)</li>\n<li>Lawrence Livermore\
    \ National Laboratory Institutional Scientific Capability Portfolio (ISCP)</li>\n\
    <li>Lawrence Livermore National Laboratory, through the LDRD program</li>\n</ul>\n\
    <h1><a id=\"user-content-contributors\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#contributors\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Contributors</h1>\n<p>HiOp is written by Cosmin G.\
    \ Petra (<a href=\"mailto:petra1@llnl.gov\">petra1@llnl.gov</a>), Nai-Yuan Chiang\
    \ (<a href=\"mailto:chiang7@llnl.gov\">chiang7@llnl.gov</a>), and Jingyi \"Frank\"\
    \ Wang (<a href=\"mailto:wang125@llnl.gov\">wang125@llnl.gov</a>) from LLNL and\
    \ has received important contributions from Asher Mancinelli (PNNL), Slaven Peles\
    \ (ORNL), Cameron Rutherford (PNNL), Jake K. Ryan (PNNL), and Michel Schanen (ANL).</p>\n\
    <h1><a id=\"user-content-copyright\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#copyright\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Copyright</h1>\n<p>Copyright (c) 2017-2021, Lawrence Livermore National\
    \ Security, LLC. All rights reserved. Produced at the Lawrence Livermore National\
    \ Laboratory. LLNL-CODE-742473. HiOp is free software; you can modify it and/or\
    \ redistribute it under the terms of the BSD 3-clause license. See <a href=\"\
    /COPYRIGHT\">COPYRIGHT</a> and <a href=\"/LICENSE\">LICENSE</a> for complete copyright\
    \ and license information.</p>\n"
  stargazers_count: 203
  subscribers_count: 17
  topics:
  - hpc
  - nonlinear-optimization
  - nonlinear-programming
  - nonlinear-programming-algorithms
  - interior-point-method
  - parallel-programming
  - mpi
  - bfgs
  - quasi-newton
  - constrained-optimization
  - solver
  - optimization
  - acopf
  - gpu-support
  - cuda
  - math-physics
  - radiuss
  - interior-point-optimizer
  - nonsmooth-optimization
  - rocm
  updated_at: 1707327981.0
LLNL/hubcast:
  data_format: 2
  description: An event driven synchronization application for bridging GitHub and
    GitLab
  filenames:
  - spack.yaml
  full_name: LLNL/hubcast
  latest_release: null
  readme: "<div align=\"center\">\n<h1><a id=\"\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"logo/logo.svg\"\
    ><img src=\"logo/logo.svg\" width=\"400\" alt=\"Hubcast logo\" style=\"max-width:\
    \ 100%;\"></a>\n<br clear=\"all\">\n</h1>\n<p><strong><a href=\"#features\">Features</a>\
    \ \_ \u2022 \_ <a href=\"/docs/getting-started.md\">Getting Started</a> \_ \u2022\
    \ \_ <a href=\"/docs/getting-started.md\">Config</a> \_ \u2022 \_ <a href=\"/docs/CONTRIBUTING.md\"\
    >Contributing</a> \_ \u2022 \_ <a href=\"https://github.com/LLNL/hubcast/releases\"\
    >Changelog</a></strong></p>\n</div>\n<p>Hubcast is an event driven synchronization\
    \ application for bridging GitHub and GitLab. It automates various workflow tasks\
    \ and handles jobs like:</p>\n<ul>\n<li>Syncing branches from GitHub to GitLab.</li>\n\
    <li>Reporting CI job statuses back to GitHub from GitLab Workflow Runs.</li>\n\
    </ul>\n<h2><a id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>License</h2>\n<p>Licensed under the Apache License,\
    \ Version 2.0 (the \"License\");\nyou may not use this file except in compliance\
    \ with the License.\nYou may obtain a copy of the License at</p>\n<p><a href=\"\
    http://www.apache.org/licenses/LICENSE-2.0\" rel=\"nofollow\">http://www.apache.org/licenses/LICENSE-2.0</a></p>\n\
    <p>Unless required by applicable law or agreed to in writing, software\ndistributed\
    \ under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES\
    \ OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the\
    \ specific language governing permissions and\nlimitations under the License.</p>\n\
    <p>SPDX-License-Identifier: Apache-2.0</p>\n<p>LLNL-CODE-847946</p>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics:
  - ci
  - github-app
  - gitlab-ci
  updated_at: 1707419378.0
LLNL/serac:
  data_format: 2
  description: Serac is a high order nonlinear thermomechanical simulation code
  filenames:
  - scripts/spack/devtools_configs/toss_3_x86_64_ib/spack.yaml
  - scripts/spack/configs/docker/ubuntu20/spack.yaml
  - scripts/spack/configs/darwin/spack.yaml
  - scripts/spack/configs/linux_ubuntu_18/spack.yaml
  - scripts/spack/configs/linux_ubuntu_22/spack.yaml
  - scripts/spack/devtools_configs/blueos_3_ppc64le_ib_p9/spack.yaml
  full_name: LLNL/serac
  latest_release: null
  readme: '<h1><a id="" class="anchor" aria-hidden="true" tabindex="-1" href="#"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a target="_blank"
    rel="noopener noreferrer" href="/share/serac/logo/serac-logo-blue.png?raw=true"><img
    src="/share/serac/logo/serac-logo-blue.png?raw=true" width="150" alt="Serac" style="max-width:
    100%;"></a></h1>

    <p><a href="https://dev.azure.com/llnl-serac/serac/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/037c40c18167c2f51c531cab7f2ecc11128fd35f9de4f86069791798bc097f0a/68747470733a2f2f6465762e617a7572652e636f6d2f6c6c6e6c2d73657261632f73657261632f5f617069732f6275696c642f7374617475732f4c4c4e4c2e73657261633f6272616e63684e616d653d646576656c6f70"
    alt="Build Status" data-canonical-src="https://dev.azure.com/llnl-serac/serac/_apis/build/status/LLNL.serac?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://serac.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00fb910871e6439ba9db142b3d74c89f026b9fcc43c7d2c2e3a8aba22f0f47f0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73657261632f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/serac/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/serac" rel="nofollow"><img src="https://camo.githubusercontent.com/6024e4752532a6f5e3c2922749432d9a05441d39d538e4817c32971a0b65cac8/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f73657261632f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d444f344b464d504e4d30"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/serac/branch/develop/graph/badge.svg?token=DO4KFMPNM0"
    style="max-width: 100%;"></a>

    <a href="./LICENSE"><img src="https://camo.githubusercontent.com/46ab19c2c0af8a73620c60806fe8512ebe91f6db426ef8cf0855c60f04c4e5dd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/license-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>Serac is a 3D implicit nonlinear thermal-structural simulation code. Its primary
    purpose is to investigate multiphysics

    abstraction strategies and implicit finite element-based algorithm development
    for emerging computing architectures.

    It also serves as a proxy-app for LLNL''s Smith code and heavily leverages the
    <a href="https://mfem.org/" rel="nofollow">MFEM finite element library</a>.</p>

    <blockquote>

    <p>This project is under heavy development and is currently a pre-alpha release.
    Functionality and interfaces may change rapidly

    as development progresses.</p>

    </blockquote>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Build, run, and design documentation can be found at <a href="https://serac.readthedocs.io"
    rel="nofollow">readthedocs</a>.</p>

    <p>Source documentation can be found <a href="https://serac.readthedocs.io/en/latest/doxygen/html/index.html"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, and documentation
    edits.</p>

    <p>For more information, see the <a href="./CONTRIBUTING.md">contributing guide</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Copyright (c) 2019-2023, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Serac project are retained by contributors.

    No copyright assignment is required to contribute to Serac.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution<br>

    <code>LLNL-CODE-805541</code></p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spdx-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPDX
    usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" tabindex="-1"
    href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>External
    Packages</h2>

    <p>Serac bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: Axom<br>

    PackageHomePage: <a href="https://github.com/LLNL/axom">https://github.com/LLNL/axom</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: MFEM<br>

    PackageHomePage: <a href="https://github.com/mfem/mfem">https://github.com/mfem/mfem</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 155
  subscribers_count: 13
  topics:
  - math-physics
  - finite-elements
  - proxy-application
  - simulation
  - cpp
  updated_at: 1706526968.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/spack-nightly/int32-double/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int64-single/spack.yaml
  - docker/sundials-ci/spack-nightly/int64-double/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.7.0
  readme: '<h1><a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" aria-hidden="true" tabindex="-1" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SUNDIALS: SUite of
    Nonlinear and DIfferential/ALgebraic equation Solvers</h1>

    <h3><a id="user-content-version-670-dec-2023" class="anchor" aria-hidden="true"
    tabindex="-1" href="#version-670-dec-2023"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Version 6.7.0 (Dec 2023)</h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form

    $$M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form

    $$y'' = f(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form

    $$y'' = f(t,y,p), \quad y(t_0) = y_0(p)$$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form

    $$F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0''$$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form

    $$F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p)$$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form

    $$F(u) = 0 \quad \text{or} \quad G(u) = u$$</p>

    </li>

    </ul>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#support"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2><a id="user-content-citing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#citing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Yu Pan, Slaven Peles, Cosmin Petra, Steven B. Roberts, H. Hunter Schwartz,

    Jean M. Sexton, Dan Shumaker, Steve G. Smith, Shahbaj Sohal, Allan G. Taylor,

    Hilari C. Tiedeman, Chris White, Ting Yan, and Ulrike M. Yang.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 435
  subscribers_count: 35
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1707277172.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 22.08/0.18.1/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-for-lumi" class="anchor"
    aria-hidden="true" tabindex="-1" href="#spack-configuration-files-for-lumi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files for LUMI</h1>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1675956191.0
MuonColliderSoft/mucoll-spack:
  data_format: 2
  description: Muon Collider software repository for Spack
  filenames:
  - environments/mucoll-release/spack.yaml
  - environments/mucoll-common/spack.yaml
  full_name: MuonColliderSoft/mucoll-spack
  latest_release: v2.8
  readme: "<h1><a id=\"user-content-spack-package-repository-for-muon-collider-software-stack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spack-package-repository-for-muon-collider-software-stack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n<a href=\"\
    https://github.com/spack/spack\">Spack</a> package repository for Muon Collider\
    \ software stack</h1>\n<p>This repository holds a set of Spack recipes for Muon\
    \ Collider software (under namespace <code>mucoll</code>) based on <a href=\"\
    https://key4hep.github.io/key4hep-doc/\" rel=\"nofollow\">Key4hep</a> stack. It\
    \ extends the corresponding <a href=\"https://github.com/key4hep/key4hep-spack\"\
    >key4hep-stack</a> repository, which is required for installation, overriding\
    \ several packages by the ones customised for Muon Collider simulation studies.</p>\n\
    <p>After installing <a href=\"https://github.com/key4hep/spack\">Spack</a> and\
    \ downloading the <a href=\"https://github.com/key4hep/key4hep-spack\">key4hep-spack</a>\
    \ and <a href=\"https://github.com/MuonColliderSoft/mucoll-spack\">mucoll-spack</a>\
    \ repositories, the whole software stack can be installed using the following\
    \ commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Add repositories</span>\nspack repo add ./key4hep-spack\n\
    spack repo add ./mucoll-spack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a Spack environment</span>\nspack env create sim\nspack env activate\
    \ sim\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy package configurations</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Install the software stack</span>\nspack add mucoll-stack\nspack\
    \ concretize --reuse\nspack install --fail-fast\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Load the Muon Collider environment</span>\n<span class=\"\
    pl-c1\">source</span> <span class=\"pl-smi\">$MUCOLL_STACK</span></pre></div>\n\
    <h2><a id=\"user-content-setting-up-the-environment\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#setting-up-the-environment\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up the environment</h2>\n\
    <p>When signing in to a machine with the installed sofware stack (VM or Docker\
    \ container), it has to be loaded into the environment:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack env activate sim\n<span class=\"pl-c1\"\
    >source</span> <span class=\"pl-smi\">$MUCOLL_STACK</span></pre></div>\n<h2><a\
    \ id=\"user-content-package-versioning\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#package-versioning\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Package versioning</h2>\n<p>Preferred convention\
    \ for version names in Spack is numbers separated by dots, without leading zeros,\
    \ e.g. <code>1.2.13</code>.\nConversion to tag names in <code>mucoll</code> packages\
    \ is provided by <code>MCIlcsoftpackage</code> class defined in <code>packages/mucoll-stack/mucoll_utils.py</code>,\
    \ e.g. for <a href=\"https://github.com/MuonColliderSoft/lcgeo/releases/tag/v00-17-MC\"\
    ><code>lcgeo</code></a> package version <code>0.17</code> corresponds to tag name\
    \ <code>v00-17-MC</code>.</p>\n<h2><a id=\"user-content-adding-new-versions-for-individual-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#adding-new-versions-for-individual-packages\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new\
    \ versions for individual packages</h2>\n<p>After a new tag for the package is\
    \ created, e.g. <code>v00-17-MC</code> in <code>lcgeo</code> repository, it can\
    \ be added to this Spack repository in two steps:</p>\n<ol>\n<li>Get the archive\
    \ checksum for the new tag</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack checksum lcgeo 0.17\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Validates archive URL and returns the checksum</span>\n    version(<span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>0.17<span class=\"pl-pds\">'</span></span>,\
    \ sha256=<span class=\"pl-s\"><span class=\"pl-pds\">'</span>5ab33aaf5bc37deba82c2dde78cdce6c0041257222ed7ea052ecdd388a41cf9b<span\
    \ class=\"pl-pds\">'</span></span>)</pre></div>\n<ol start=\"2\">\n<li>Add the\
    \ returned version definition to the corresponding package file: <a href=\"packages/lcgeo/package.py\"\
    ><code>packages/lcgeo/package.py</code></a>\n</li>\n</ol>\n<blockquote>\n<p>NOTE:\
    \ This repository only contains packages maintained by the Muon Collider collaboration.\n\
    If the version of interest is missing from Spack for some other package, the line\
    \ with a new version definition should be added to the package file in the corresponding\
    \ repository.<br>\nTo see locations of other repositories: <code>spack repo list</code></p>\n\
    </blockquote>\n<h2><a id=\"user-content-creating-a-new-stack-release\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#creating-a-new-stack-release\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ a new stack release</h2>\n<p>To introduce a new release version for the whole\
    \ software stack, update the version number in <a href=\"packages/mucoll-stack/package.py\"\
    ><code>packages/mucoll-stack/package.py</code></a> and then update versions of\
    \ all the relevant packages in [environments/mucoll-release/packages.yaml].<br>\n\
    Test this new configuration in a fresh environment:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a development environment</span>\nspack env create dev\nspack env activate\
    \ dev\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy the package configuration</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Add stack with updated version to the environment</span>\nspack\
    \ add mucoll-stack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Check\
    \ which packages would be installed</span>\nspack spec --reuse -NIt</pre></div>\n\
    <p>Packages that are already installed in the <code>sim</code> environment are\
    \ known to Spack and will be reused, providing a clear indication of which part\
    \ of the dependency tree will be modified by the new release.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1679435634.0
NCAR/spack-derecho:
  data_format: 2
  description: Spack production user software stack on the Derecho system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-derecho
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NCAR Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>derecho</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Thu Aug 31 09:31:25 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>c33150e8d9241c6175a6b599b2afde1e6ea3c891</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.09</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/derecho/23.09</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/derecho/23.09/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 3
  subscribers_count: 9
  topics: []
  updated_at: 1695826459.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NCAR Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Thu Mar 30 18:51:24 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fd3fc5c8cd67abe692e5e38bae52f29fb32700a3</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.04</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/23.04</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/23.04/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 4
  subscribers_count: 13
  topics: []
  updated_at: 1705084500.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-23.08/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/cuda/spack.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/data/spack.yaml
  - spack-configs/perlmutter-e4s-23.08/prod/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/data/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/perlmutter-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/tools/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/math-libs/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The\
    \ Spack Infrastructure Project makes use of <a href=\"https://spack.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">spack package manager</a> to install spack software stack on\
    \ NERSC systems. This project contains spack configuration (<code>spack.yaml</code>)\
    \ required to build the spack stacks. The spack stack is based on <a href=\"https://e4s.io/\"\
    \ rel=\"nofollow\">Extreme-Scale Scientific Software Stack</a> (E4S) where we\
    \ install spack packages provided by E4S and use the recommended spack branch.\
    \ We leverage <a href=\"https://docs.gitlab.com/ee/ci/\" rel=\"nofollow\">Gitlab\
    \ CI</a> to automate deployment to ensure reproducible and automated builds. For\
    \ more details about this project you can see the documentation at <a href=\"\
    https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <h2><a id=\"user-content-software-deployment-overview\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#software-deployment-overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Software Deployment Overview</h2>\n\
    <p>The software deployment consist of the following steps</p>\n<ol>\n<li>Acquire\
    \ Spack Configuration from E4S project <a href=\"https://github.com/E4S-Project/e4s\"\
    >https://github.com/E4S-Project/e4s</a>\n</li>\n<li>Create one or more spack configuration\
    \ files (spack.yaml) with list of E4S packages and integrate spack configuration\
    \ for NERSC system</li>\n<li>Create a Gitlab Job to trigger the pipeline for TDS\
    \ and Deployment system</li>\n<li>Create a Modulefile as entry point to stack</li>\n\
    <li>Write User Documentation</li>\n<li>Share spack configuration with open-source\
    \ community</li>\n<li>Send announcement to all NERSC users</li>\n</ol>\n<h3><a\
    \ id=\"user-content-step-1-acquire-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-1-acquire-spack-configuration\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 1: Acquire Spack Configuration</h3>\n\
    <p>At NERSC, we plan our software deployment with E4S releases which is typically\
    \ every 3 months however we perform deployment every 6 months. Once E4S has released\
    \ the spack configuration we acquire the spack configuration which is typically\
    \ found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >https://github.com/E4S-Project/e4s/tree/master/environments</a>. We also acquire\
    \ the spack <a href=\"https://github.com/spack/spack/branches\">branch</a> used\
    \ by E4S team as our baseline, this would be documented in the release notes.\
    \ The name of branch map to the E4S version so version 23.05 will have a branch\
    \ <a href=\"https://github.com/spack/spack/tree/e4s-23.05\">e4s-23.05</a>.</p>\n\
    <p>Next, we copy the packages into our project and create the spack configuration</p>\n\
    <h3><a id=\"user-content-step-2-create-spack-configuration\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-2-create-spack-configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 2:\
    \ Create Spack Configuration</h3>\n<p>In this step we create the spack configuration.\
    \ First we create a sub-directory in <em>spack-configs</em> with the naming convention\
    \ to distinguish E4S version. This typically includes the\nname of the system\
    \ such as <code>cori</code> or <code>perlmutter</code> followed by name of e4s\
    \ version such as <code>e4s-23.05</code>.</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">tree -L 1 spack-configs</span>\n<span class=\"pl-c1\"\
    >spack-configs</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-20.10</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-21.02</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 cori-e4s-21.05</span>\n<span class=\"pl-c1\">\u251C\
    \u2500\u2500 cori-e4s-22.02</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-21.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.05</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\"\
    >\u251C\u2500\u2500 perlmutter-e4s-23.05</span>\n<span class=\"pl-c1\">\u251C\u2500\
    \u2500 perlmutter-spack-develop</span>\n<span class=\"pl-c1\">\u2514\u2500\u2500\
    \ perlmutter-user-spack</span>\n\n<span class=\"pl-c1\">10 directories, 0 files</span></pre></div>\n\
    <p>Inside one of the stacks, you will see several sub-directories that are used\
    \ for defining a sub-stack. These sub-stacks correspond to <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">spack environments</a>. The <code>prod</code> directory is\
    \ used for production deployment to install from the buildcache.</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">tree -L\
    \ 3 spack-configs/perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\">spack-configs/perlmutter-e4s-22.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cce</span>\n<span class=\"pl-c1\">\u2502\
    \_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500\
    \ cuda</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 definitions.yaml</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"\
    pl-c1\">\u2514\u2500\u2500 prod</span>\n<span class=\"pl-c1\">    \u251C\u2500\
    \u2500 cce</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">    \u251C\u2500\u2500 cuda</span>\n<span class=\"pl-c1\"\
    >    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\"> \
    \   \u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">    \u2514\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">        \u2514\u2500\u2500 spack.yaml</span>\n\n<span class=\"\
    pl-c1\">9 directories, 9 files</span></pre></div>\n<p>We create a special file\
    \ named <code>definitions.yaml</code> that is used for declaring definitions that\
    \ is referenced in <code>spack.yaml</code>. This file is appended to all spack\
    \ configuration. We do this\nto ensure all specs are defined in one place.</p>\n\
    <p>During this step, we will create the spack configuration and specify our preferred\
    \ compilers and package preference. We install software in buildcache so it can\
    \ be relocated to production path. In order to accomplish this task, we use <a\
    \ href=\"https://spack.readthedocs.io/en/latest/pipelines.html\" rel=\"nofollow\"\
    >spack pipelines</a> that uses <code>spack ci generate</code> and <code>spack\
    \ ci rebuild</code> to perform parallel pipeline execution. During this step,\
    \ we determine which packages to install from E4S and add our own packages to\
    \ comply with our site preference.</p>\n<h3><a id=\"user-content-step-3-create-gitlab-job-for-automation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-3-create-gitlab-job-for-automation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 3:\
    \ Create Gitlab Job for Automation</h3>\n<p>Once spack configuration is written,\
    \ we create a gitlab job to trigger the pipeline. This can be done by specifying\
    \ a job in <a href=\"https://github.com/NERSC/spack-infrastructure/blob/main/.gitlab-ci.yml\"\
    >.gitlab-ci.yml</a>.</p>\n<p>The gitlab job can be triggered through <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\" rel=\"\
    nofollow\">scheduled pipelines</a>, <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web-interface</a>, or merge request to the project. A typical\
    \ gitlab job will look something like this. Shown below is for E4S 23.05 generate\
    \ job. We make use of gitlab feature named <a href=\"https://docs.gitlab.com/ee/ci/yaml/index.html#extends\"\
    \ rel=\"nofollow\">extends</a> which allows us to reuse configuration. The <code>spack\
    \ ci generate</code> command will be the same for each substack. There is two\
    \ jobs, first is the generate step performed by <code>spack ci generate</code>\
    \ and this triggers the downstream job created by spack.</p>\n<div class=\"highlight\
    \ highlight-source-yaml\"><pre><span class=\"pl-ent\">.perlmutter-e4s-23.05-generate</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">generate</span>\n\
    \  <span class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    ]</span>\n  <span class=\"pl-ent\">tags</span>: <span class=\"pl-s\">[perlmutter-e4s]</span>\n\
    \  <span class=\"pl-ent\">interruptible</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">allow_failure</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">rules</span>:\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"schedule\" || $CI_PIPELINE_SOURCE\
    \ == \"web\") &amp;&amp; ($PIPELINE_NAME == \"PERLMUTTER_E4S_23.05\")</span>\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"merge_request_event\")</span>\n      <span class=\"pl-ent\">changes</span>:\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/$STACK_NAME/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">before_script</span>:\n    <span class=\"pl-s\">- *copy_perlmutter_settings</span>\n\
    \    <span class=\"pl-s\">- *startup_modules</span>\n  <span class=\"pl-ent\"\
    >script</span>:\n    <span class=\"pl-s\">- *e4s_23_05_setup </span>\n    - <span\
    \ class=\"pl-s\">cd $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/$STACK_NAME</span>\n\
    \    - <span class=\"pl-s\">cat $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/definitions.yaml\
    \ &gt;&gt; spack.yaml</span>\n    - <span class=\"pl-s\">spack env activate --without-view\
    \  .</span>\n    - <span class=\"pl-s\">spack env st</span>\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>- spack -d concretize -f | tee $CI_PROJECT_DIR/concretize.log\
    \    </span>\n    - <span class=\"pl-s\">spack -d ci generate --check-index-only\
    \ --artifacts-root \"$CI_PROJECT_DIR/jobs_scratch_dir\" --output-file \"${CI_PROJECT_DIR}/jobs_scratch_dir/pipeline.yml\"\
    </span>\n  <span class=\"pl-ent\">artifacts</span>: \n    <span class=\"pl-ent\"\
    >paths</span>:\n    - <span class=\"pl-s\">${CI_PROJECT_DIR}/jobs_scratch_dir</span>\n\
    \n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-generate</span>:\n  <span\
    \ class=\"pl-ent\">extends</span>: <span class=\"pl-s\">.perlmutter-e4s-23.05-generate</span>\n\
    \  <span class=\"pl-ent\">variables</span>:\n    <span class=\"pl-ent\">STACK_NAME</span>:\
    \ <span class=\"pl-s\">cce</span>\n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-build</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">build</span>\n  <span\
    \ class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    , \"perlmutter-e4s-23.05-cce-generate\"]</span>\n  <span class=\"pl-ent\">allow_failure</span>:\
    \ <span class=\"pl-c1\">true</span>\n  <span class=\"pl-ent\">rules</span>:\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"schedule\" || $CI_PIPELINE_SOURCE == \"web\") &amp;&amp; ($PIPELINE_NAME\
    \ == \"PERLMUTTER_E4S_23.05\")</span>\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"merge_request_event\")</span>\n\
    \      <span class=\"pl-ent\">changes</span>:\n      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/cce/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">trigger</span>:\n    <span class=\"pl-ent\">include</span>:\n\
    \      - <span class=\"pl-ent\">artifact</span>: <span class=\"pl-s\">jobs_scratch_dir/pipeline.yml</span>\n\
    \        <span class=\"pl-ent\">job</span>: <span class=\"pl-s\">perlmutter-e4s-23.05-cce-generate</span>\n\
    \    <span class=\"pl-ent\">strategy</span>: <span class=\"pl-s\">depend</span></pre></div>\n\
    <h3><a id=\"user-content-step-4-create-modulefile\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-4-create-modulefile\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 4: Create Modulefile</h3>\n\
    <p>In this step, we create a modulefile as entry point to software stack and setup\
    \ <code>spack</code>. We do not create spack generated modules for spack packages,\
    \ instead one is expected to use <code>spack load</code>.  Shown below are the\
    \ modulefiles available on NERSC system, they are typically called <code>e4s/&lt;version&gt;</code>\
    \ with a symbolic link to module <code>spack/e4s-&lt;version&gt;</code></p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml -t av e4s</span>\n<span\
    \ class=\"pl-c1\">/global/common/software/nersc/pm-2022.12.0/extra_modulefiles:</span>\n\
    <span class=\"pl-c1\">e4s/22.05</span>\n<span class=\"pl-c1\">e4s/22.11</span>\n\
    <span class=\"pl-c1\">spack/e4s-22.05</span>\n<span class=\"pl-c1\">spack/e4s-22.11</span></pre></div>\n\
    <p>Shown below is the content of our modulefile, the setup is subject to change</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml --raw show e4s</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">   /global/common/software/nersc/pm-2022.12.0/extra_modulefiles/e4s/22.11.lua:</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">whatis([[</span>\n<span class=\"pl-c1\">        The Extreme-scale\
    \ Scientific Software Stack (E4S) is a collection of open source software packages\
    \ for running scientific applications on high-performance computing (HPC) platforms.</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n<span class=\"pl-c1\">help([[ The Extreme-scale\
    \ Scientific Software Stack (E4S) is a community effort to provide open source\
    \ software packages for developing, deploying and running scientific applications\
    \ on high-performance computing (HPC) platforms. E4S provides from-source builds\
    \ and containers of a broad collection of HPC software packages.</span>\n\n<span\
    \ class=\"pl-c1\">References:</span>\n<span class=\"pl-c1\">  - E4S User Docs:\
    \ https://e4s.readthedocs.io/en/latest/index.html</span>\n<span class=\"pl-c1\"\
    >  - E4S 22.11 Docs: https://docs.nersc.gov/applications/e4s/perlmutter/22.11/</span>\n\
    <span class=\"pl-c1\">  - E4S Homepage: https://e4s-project.github.io/</span>\n\
    <span class=\"pl-c1\">  - E4S GitHub: https://github.com/E4S-Project/e4s</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n\n<span class=\"pl-c1\">local root =\
    \ \"/global/common/software/spackecp/perlmutter/e4s-22.11/default/spack\"</span>\n\
    \n<span class=\"pl-c1\">setenv(\"SPACK_GNUPGHOME\", pathJoin(os.getenv(\"HOME\"\
    ), \".gnupg\"))</span>\n<span class=\"pl-c1\">setenv(\"SPACK_SYSTEM_CONFIG_PATH\"\
    , \"/global/common/software/spackecp/perlmutter/spack_settings\")</span>\n<span\
    \ class=\"pl-c1\">-- setup spack shell functionality</span>\n<span class=\"pl-c1\"\
    >local shell = myShellType()</span>\n<span class=\"pl-c1\">if (mode() == \"load\"\
    ) then</span>\n<span class=\"pl-c1\">    local spack_setup = ''</span>\n<span\
    \ class=\"pl-c1\">    if (shell == \"sh\" or shell == \"bash\" or shell == \"\
    zsh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.sh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"csh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.csh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"fish\")  then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.fish\")</span>\n<span class=\"pl-c1\">    end</span>\n\
    \n<span class=\"pl-c1\">    -- If we are unable to find spack setup script let's\
    \ terminate now.</span>\n<span class=\"pl-c1\">    if not isFile(spack_setup)\
    \ then</span>\n<span class=\"pl-c1\">        LmodError(\"Unable to find spack\
    \ setup script \" .. spack_setup .. \"\\n\")</span>\n<span class=\"pl-c1\">  \
    \  end</span>\n\n<span class=\"pl-c1\">    execute{cmd=\"source \" .. spack_setup,\
    \ modeA={\"load\"}}</span>\n\n<span class=\"pl-c1\">    LmodMessage([[</span>\n\
    <span class=\"pl-c1\">    _______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">     The Extreme-Scale Scientific Software Stack (E4S) is\
    \ accessible via the Spack package manager.</span>\n\n<span class=\"pl-c1\"> \
    \    In order to access the production stack, you will need to load a spack environment.\
    \ Here are some tips to get started:</span>\n\n\n<span class=\"pl-c1\">     'spack\
    \ env list' - List all Spack environments</span>\n<span class=\"pl-c1\">     'spack\
    \ env activate gcc' - Activate the \"gcc\" Spack environment</span>\n<span class=\"\
    pl-c1\">     'spack env status' - Display the active Spack environment</span>\n\
    <span class=\"pl-c1\">     'spack load amrex' - Load the \"amrex\" Spack package\
    \ into your user environment</span>\n\n<span class=\"pl-c1\">     For additional\
    \ support, please refer to the following references:</span>\n\n<span class=\"\
    pl-c1\">       NERSC E4S Documentation: https://docs.nersc.gov/applications/e4s/</span>\n\
    <span class=\"pl-c1\">       E4S Documentation: https://e4s.readthedocs.io</span>\n\
    <span class=\"pl-c1\">       Spack Documentation: https://spack.readthedocs.io/en/latest/</span>\n\
    <span class=\"pl-c1\">       Spack Slack: https://spackpm.slack.com</span>\n\n\
    <span class=\"pl-c1\">    ______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">    ]])</span>\n<span class=\"pl-c1\">-- To remove spack\
    \ from shell we need to remove a few environment variables, alias and remove $SPACK_ROOT/bin\
    \ from $PATH</span>\n<span class=\"pl-c1\">elseif (mode() == \"unload\" or mode()\
    \ == \"purge\") then</span>\n<span class=\"pl-c1\">    if (shell == \"sh\" or\
    \ shell == \"bash\" or shell == \"zsh\") then</span>\n<span class=\"pl-c1\"> \
    \     execute{cmd=\"unset SPACK_ENV\",modeA={\"unload\"}}</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unset SPACK_ROOT\",modeA={\"unload\"}}</span>\n<span\
    \ class=\"pl-c1\">      execute{cmd=\"unset -f spack\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">    elseif (shell == \"csh\") then</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unsetenv SPACK_ENV\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">      execute{cmd=\"unsetenv SPACK_ROOT\",modeA={\"unload\"\
    }}</span>\n<span class=\"pl-c1\">      execute{cmd=\"unalias spack\",modeA={\"\
    unload\"}}</span>\n<span class=\"pl-c1\">    end</span>\n\n<span class=\"pl-c1\"\
    >    -- Need to remove $SPACK_ROOT/bin from $PATH which removes the 'spack' command</span>\n\
    <span class=\"pl-c1\">    remove_path(\"PATH\", pathJoin(root, \"bin\"))</span>\n\
    \n<span class=\"pl-c1\">    -- Remove alias spacktivate. Need to pipe to /dev/null\
    \ as invalid alias can report error to stderr</span>\n<span class=\"pl-c1\"> \
    \   execute{cmd=\"unalias spacktivate &gt; /dev/null\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">end</span></pre></div>\n<h3><a id=\"user-content-step-5-user-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-5-user-documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 5:\
    \ User Documentation</h3>\n<p>User documentation is fundamental to help assist\
    \ users with using E4S at NERSC. We document every E4S release with its <em>Release\
    \ Date</em> and <em>End of Support</em> date along with a documentation page outlining\
    \ the software stack. Our E4S documentation is available at <a href=\"https://docs.nersc.gov/applications/e4s/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/</a>. The release date\
    \ is when documentation is live. We perform this action in conjunction with release\
    \ of modulefile so that user gain access to software stack.</p>\n<p>Upon completion\
    \ of this task, we are ready to make announcement to our NERSC users</p>\n<h3><a\
    \ id=\"user-content-step-6-sharing-spack-configuration-with-open-source-community\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-6-sharing-spack-configuration-with-open-source-community\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 6:\
    \ Sharing spack configuration with open-source community</h3>\n<p>In this step,\
    \ we share our spack configuration with open-source community that may benefit\
    \ the wider community. We share our spack configuration at <a href=\"https://github.com/spack/spack-configs\"\
    >https://github.com/spack/spack-configs</a>. In addition, we update the <a href=\"\
    https://e4s.readthedocs.io/en/latest/facility_e4s.html\" rel=\"nofollow\">E4S\
    \ Facility Dashboard</a> that shows all the E4S deployments across all the facilities.</p>\n\
    <h3><a id=\"user-content-step-7-public-announcement\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-7-public-announcement\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 7: Public Announcement</h3>\n\
    <p>This is the final step of the deployment process, where we make a public announcement\
    \ in NERSC weekly email, along with various slack channels such as Nersc User\
    \ Group (NUG), Spack, ECP and E4S slack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#current-challenges\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Current\
    \ Challenges</h2>\n<p>There are several challenges with building spack stack at\
    \ NERSC which can be summarized as follows</p>\n<ul>\n<li>\n<p><strong>System\
    \ OS + Cray Programming Environment (CPE) changes</strong>: A system upgrade such\
    \ as change to <code>glibc</code> or upgrades in CPE can lead to full software\
    \ stack rebuild, especially if you have external packages set for packages like\
    \ <code>cray-mpich</code>, <code>cray-libsci</code> which generally change between\
    \ versions</p>\n</li>\n<li>\n<p><strong>Incompatibile compilers</strong>: Some\
    \ packages can't be built with certain compilers (<code>nvhpc</code>, <code>aocc</code>)\
    \ which could be due to several factors.</p>\n<ul>\n<li>An application doesn't\
    \ have support though it was be added in newer version but you don't have it in\
    \ your spack release used for deployment</li>\n<li>Lack of support in spack package\
    \ recipe or spack-core base including spack-cray detection. This may require getting\
    \ fix and cherry-pick commit or waiting for new version</li>\n<li>Spack Cray detection\
    \ is an important part in build errors including how one specifies externals via\
    \ <code>modules</code> vs <code>prefix</code> both could be provided and it requires\
    \ experimentation. An example of this is trying to get <code>cray-mpich</code>\
    \ external one could set something like this with modules or prefix</li>\n</ul>\n\
    <div class=\"highlight highlight-source-yaml\"><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n\
    \    <span class=\"pl-ent\">buildable</span>: <span class=\"pl-c1\">false</span>\n\
    \    <span class=\"pl-ent\">externals</span>:\n    - <span class=\"pl-ent\">spec</span>:\
    \ <span class=\"pl-s\">cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"\
    pl-ent\">prefix</span>: <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n\
    \      <span class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<p>If you need elevated privledge or assistance with\
    \ this project please contact one of the maintainers:</p>\n<ul>\n<li>Shahzeb Siddiqui\
    \ - <a href=\"mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>\n</li>\n\
    <li>Erik Palmer - <a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>\n</li>\n\
    <li>Justin Cook - <a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>\n</li>\n\
    <li>E4S Team: Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\">sameer@cs.uoregon.edu</a>),\
    \ Christopher Peyralans (<a href=\"mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>),\
    \ Wyatt Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>),\
    \ Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</li>\n\
    </ul>\n"
  stargazers_count: 8
  subscribers_count: 14
  topics: []
  updated_at: 1673545287.0
NERSC/timemory:
  data_format: 2
  description: 'Modular C++ Toolkit for Performance Analysis and Logging. Profiling
    API and Tools for C, C++, CUDA, Fortran, and Python. The C++ template API is essentially
    a framework to creating tools: it is designed to provide a unifying interface
    for recording various performance measurements alongside data logging and interfaces
    to other tools.'
  filenames:
  - docker/cpu/spack.yaml
  full_name: NERSC/timemory
  latest_release: v3.2.3
  readme: "<h1><a id=\"user-content-timemory\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#timemory\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>timemory</h1>\n<h2><a id=\"user-content-timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Timing +\
    \ Memory + Hardware Counter Utilities for C / C++ / CUDA / Python</h2>\n<p><a\
    \ href=\"https://travis-ci.org/NERSC/timemory\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e771c5877a01c9ad3c5f9ac404fafcbb19d8f1647e63f72448851af6753c1d9c/68747470733a2f2f7472617669732d63692e6f72672f4e455253432f74696d656d6f72792e7376673f6272616e63683d6d6173746572\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/NERSC/timemory.svg?branch=master\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/jrmadsen/timemory/branch/master\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/310167bff27e3bfcff0843c04e63901359e8ed7672b1dabbe55d9fb4378d3ba7/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38786b37326f6f7477736566693863312f6272616e63682f6d61737465723f7376673d74727565\"\
    \ alt=\"Build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/8xk72ootwsefi8c1/branch/master?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/NERSC/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d4fac988b58c397453b2f2631379b0e47366ef6750df318103caabf9b65ca0c/68747470733a2f2f636f6465636f762e696f2f67682f4e455253432f74696d656d6f72792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/NERSC/timemory/branch/master/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/NERSC/timemory\"\
    >timemory on GitHub (Source code)</a></p>\n<p><a href=\"https://timemory.readthedocs.io\"\
    \ rel=\"nofollow\">timemory General Documentation (ReadTheDocs)</a></p>\n<p><a\
    \ href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\
    >timemory Source Code Documentation (Doxygen)</a></p>\n<p><a href=\"https://cdash.nersc.gov/index.php?project=TiMemory\"\
    \ rel=\"nofollow\">timemory Testing Dashboard (CDash)</a></p>\n<p><a href=\"https://github.com/NERSC/timemory-tutorials\"\
    >timemory Tutorials</a></p>\n<ul>\n<li>\n<p><a href=\"https://www.youtube.com/watch?v=K1Pazcw7zVo\"\
    \ rel=\"nofollow\">ECP 2021 Tutorial Day 1 (YouTube)</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://www.youtube.com/watch?v=-zIpZDiwrmI\" rel=\"nofollow\">ECP 2021\
    \ Tutorial Day 2 (YouTube)</a></p>\n</li>\n</ul>\n<p><a href=\"https://github.com/NERSC/timemory/wiki\"\
    >timemory Wiki</a></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>GitHub</td>\n<td><code>git clone https://github.com/NERSC/timemory.git</code></td>\n\
    </tr>\n<tr>\n<td>PyPi</td>\n<td><code>pip install timemory</code></td>\n</tr>\n\
    <tr>\n<td>Spack</td>\n<td><code>spack install timemory</code></td>\n</tr>\n<tr>\n\
    <td>conda-forge</td>\n<td><code>conda install -c conda-forge timemory</code></td>\n\
    </tr>\n<tr>\n<td></td>\n<td><a href=\"https://anaconda.org/conda-forge/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/13d88311b8a3ad78d2eef315c0144a27a104d75e9a610a215d6fc1251318275d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265636970652d74696d656d6f72792d677265656e2e737667\"\
    \ alt=\"Conda Recipe\" data-canonical-src=\"https://img.shields.io/badge/recipe-timemory-green.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/533b6f62d054e5318ac8873adf8b287aee649fa0b56ac1c1de77b09f4e00b2aa/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/bafca219a0c269a4ab94502e87e4a06788840125f4b0bf838158aaf5eb141c18/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/978fa080053b7937c5fb17a7bd59e5be69923086146a430e861f1dda4cb0eb9e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f706e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/conda/pn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"></a></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-purpose\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #purpose\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Purpose</h2>\n\
    <p>The goal of timemory is to create an open-source performance measurement and\
    \ analyis package\nwith modular and reusable components which can be used to adapt\
    \ to any existing C/C++\nperformance measurement and analysis API and is arbitrarily\
    \ extendable by users within their\napplication.\nTimemory is not just another\
    \ profiling tool, it is a profling <em>toolkit</em> which streamlines building\
    \ custom\nprofiling tools through modularity and then utilizes the toolkit to\
    \ provides several pre-built tools.</p>\n<p>In other words, timemory provides\
    \ many pre-built tools, libraries, and interfaces but, due to it's modularity,\n\
    codes can re-use only individual pieces -- such as the classes for measuring different\
    \ timing intervals, memory usage,\nand hardware counters -- without the timemory\
    \ \"runtime management\".</p>\n<h2><a id=\"user-content-building-and-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-and-installing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ and Installing</h2>\n<p>Timemory uses a standard CMake installation.\nSeveral\
    \ installation examples can be found in the <a href=\"https://github.com/NERSC/timemory/wiki/Installation-Examples\"\
    >Wiki</a>. See the <a href=\"https://timemory.readthedocs.io/en/develop/installation.html\"\
    \ rel=\"nofollow\">installation documentation</a> for detailed information on\
    \ the CMake options.</p>\n<h2><a id=\"user-content-documentation\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p>The full\
    \ documentation is available at <a href=\"https://timemory.readthedocs.io\" rel=\"\
    nofollow\">timemory.readthedocs.io</a>.\nDetailed source documentation is provided\
    \ in the <a href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"\
    nofollow\">doygen</a>\nsection of the full documentation.\nTutorials are available\
    \ in the <a href=\"https://github.com/NERSC/timemory-tutorials\">github.com/NERSC/timemory-tutorials</a>.</p>\n\
    <h2><a id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#overview\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Overview</h2>\n<p><strong><em>The primary objective of the timemory\
    \ is the development of a common framework for binding together software\nmonitoring\
    \ code (i.e. performance analysis, debugging, logging) into a compact and highly-efficient\
    \ interface.</em></strong></p>\n<p>Timemory arose out of the need for a universal\
    \ adapator kit for the various APIs provided several existing tools\nand a straight-forward\
    \ and intuitive method for creating new tools. Timemory makes it possible to bundle\n\
    together deterministic performance measurements, statistical performance\nmeasurements\
    \ (i.e. sampling), debug messages, data logging, and data validation into the\
    \ same interface for\ncustom application-specific software monitoring interfaces,\
    \ easily building tools like <code>time</code>,\n<code>netstat</code>, instrumentation\
    \ profilers, sampling profilers, and writing implementations for MPI-P, MPI-T,\
    \ OMPT,\nKokkosP, etc. Furthermore, timemory can forward its markers to several\
    \ third-party profilers such as\n<a href=\"https://github.com/RRZE-HPC/likwid\"\
    >LIKWID</a>, <a href=\"https://github.com/LLNL/Caliper\">Caliper</a>,\n<a href=\"\
    https://www.cs.uoregon.edu/research/tau/home.php\" rel=\"nofollow\">TAU</a>, <a\
    \ href=\"https://github.com/gperftools/gperftools\">gperftools</a>,\n<a href=\"\
    https://perfetto.dev/docs/\" rel=\"nofollow\">Perfetto</a>, VTune, Allinea-MAP,\
    \ CrayPAT, Nsight-Systems, Nsight-Compute, and NVProf.</p>\n<p>Timemory provides\
    \ a front-end <a href=\"https://timemory.readthedocs.io/en/develop/api/library.html\"\
    \ rel=\"nofollow\">C/C++/Fortran API</a>\nand <a href=\"https://timemory.readthedocs.io/en/develop/api/python.html\"\
    \ rel=\"nofollow\">Python API</a> which allows arbitrary selection\nof 50+ different\
    \ components from timers to hardware counters to interfaces with third-party tools.\
    \ This is all\nbuilt generically from the toolkit API with type-safe bundles of\
    \ tools such as:\n<code>component_tuple&lt;wall_clock, papi_vector, nvtx_marker,\
    \ user_bundle&gt;</code>\nwhere <code>wall_clock</code> is a wall-clock timer,\n\
    <code>papi_vector</code> is a handle for hardware counters,\n<code>nvxt_marker</code>\
    \ creates notations in the NVIDIA CUDA profilers, and\n<code>user_bundle</code>\
    \ is a generic component which downstream users can insert more components into\
    \ at runtime.</p>\n<p>Performance measurement components written with timemory\
    \ are arbitrarily scalable up to any number of threads and\nprocesses and fully\
    \ support intermixing different measurements at different locations within the\
    \ program -- this\nuniquely enables timemory to be deployed to collect performance\
    \ data at scale in HPC because highly detailed collection can\noccur at specific\
    \ locations within the program where ubiquitous collection would simulatenously\
    \ degrade performance\nsignificantly and require a prohibitive amount of memory.</p>\n\
    <p>Timemory can be used as a backend to bundle instrumentation and sampling tools\
    \ together, support serialization to JSON/XML,\nand provide statistics among other\
    \ uses. It can also be utilized as a front-end to invoke\ncustom instrumentation\
    \ and sampling tools. Timemory uses the abstract term \"component\" for a structure\n\
    which encapsulates some performance analysis operation. The structure might encapsulate\
    \ function\ncalls to another tool, record timestamps for timing, log values provided\
    \ by the application,\nprovide a operator for replacing a function in the code\
    \ dynamically, audit the incoming arguments\nand/or outgoing return value from\
    \ function, or just provide stubs which can be overloaded by the linker.</p>\n\
    <h3><a id=\"user-content-visualization-and-analysis\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#visualization-and-analysis\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Visualization and Analysis</h3>\n\
    <p>The native output format of timemory is JSON and text; other output formats\
    \ such as XML are also supported.\nThe text format is intended to be human readable.\
    \ The JSON data\nis intended for analysis and comes in two flavors: hierarchical\
    \ and flat. Basic plotting capabilities are\navailable via <code>timemory-plotting</code>\
    \ but users are highly encouraged to use <a href=\"https://github.com/hatchet/hatchet\"\
    >hatchet</a>\nfor analyzing the heirarchical JSON data in pandas dataframes. <a\
    \ href=\"https://github.com/hatchet/hatchet\">Hatchet</a> supports\nfiltering,\
    \ unions, addition, subtractions, output to <code>dot</code> and flamegraph formats,\
    \ and an interactive Jupyter notebook.\nAt present, timemory supports 45+ metric\
    \ types for analysis in Hatchet.</p>\n<h3><a id=\"user-content-categories\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#categories\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Categories</h3>\n<p>There are\
    \ 4 primary categories in timemory: components, operations, bundlers, and storage.\
    \ Components provide\nthe specifics of how to perform a particular behavior, operations\
    \ provide the scaffold for requesting that\na component perform an operation in\
    \ complex scenarios, bundlers group components into a single generic handle,\n\
    and storage manages data collection over the lifetime of the application. When\
    \ all four categories are combined,\ntimemory effectively resembles a standard\
    \ performance analysis tool which passively collects data and provides\nreports\
    \ and analysis at the termination of the application. Timemory, however, makes\
    \ it <em>very easy</em> to subtract\nstorage from the equation and, in doing so,\
    \ transforms timemory into a toolkit for customized data collection.</p>\n<ol>\n\
    <li>\n<strong><em>Components</em></strong>\n<ul>\n<li>Individual classes which\
    \ encapsulate one or more measurement, analysis, logging, or third-party library\
    \ action(s)</li>\n<li>Any data specific to one instance of performing the action\
    \ is stored within the instance of the class</li>\n<li>Any configuration data\
    \ specific to that type is typically stored within static member functions which\
    \ return a reference to the configuration data</li>\n<li>These classes are designed\
    \ to support direct usage within other tools, libraries, etc.</li>\n<li>Examples\
    \ include:\n<ul>\n<li>\n<code>tim::component::wall_clock</code> : a simple wall-clock\
    \ timer</li>\n<li>\n<code>tim::component::vtune_profiler</code> : a simple component\
    \ which turns the VTune Profiler on and off (when VTune is actively profiling\
    \ application)</li>\n<li>\n<code>tim::component::data_tracker_integer</code> :\
    \ associates an integer values with a label as the application executes (e.g.\
    \ number of loop iterations used somewhere)</li>\n<li>\n<code>tim::component::papi_vector</code>\
    \ : uses the PAPI library to collect hardware-counters values</li>\n<li>\n<code>tim::component::user_bundle</code>\
    \ : encapsulates an array of components which the user can dynamically manipulate\
    \ during runtime</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Operations</em></strong>\n\
    <ul>\n<li>Templated classes whose primary purpose is to provide the implementation\
    \ for performing some action on a component, e.g. <code>tim::operation::start&lt;wall_clock&gt;</code>\
    \ will attempt to call the <code>start()</code> member function on a <code>wall_clock</code>\
    \ component instance</li>\n<li>Default implementations generally have one or two\
    \ public functions: a constructor and/or a function call operator\n<ul>\n<li>These\
    \ generally accept any/all arguments and use SFINAE to determine whether the operation\
    \ can be performed with or without the given arguments (i.e. does <code>wall_clock</code>\
    \ have a <code>store(int)</code> function? <code>store()</code>?)</li>\n</ul>\n\
    </li>\n<li>Operations are (generally) not directly utilized by the user and are\
    \ typically optimized out of the binary</li>\n<li>Examples include:\n<ul>\n<li>\n\
    <code>tim::operation::start</code> : instruct a component to start collection</li>\n\
    <li>\n<code>tim::operation::sample</code> : instruct a component to take individual\
    \ measurement</li>\n<li>\n<code>tim::operation::derive</code> : extra data from\
    \ other components if it is available</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n\
    <strong><em>Bundlers</em></strong>\n<ul>\n<li>Provide a generic handle for multiple\
    \ components</li>\n<li>Member functions generally accept any/all arguments and\
    \ use operations classes to correctly to handle differences between different\
    \ capabilities of the components it is bundling</li>\n<li>Examples include:\n\
    <ul>\n<li><code>tim::auto_tuple</code></li>\n<li><code>tim::component_tuple</code></li>\n\
    <li><code>tim::component_list</code></li>\n<li><code>tim::lightweight_tuple</code></li>\n\
    </ul>\n</li>\n<li>Various flavors provide different implicit behaviors and allocate\
    \ memory differently\n<ul>\n<li>\n<code>auto_tuple</code> starts all components\
    \ when constructed and stops all components when destructed whereas <code>component_tuple</code>\
    \ requires an explicit start</li>\n<li>\n<code>component_tuple</code> allocates\
    \ all components on the stack and components are \"always on\" whereas <code>component_list</code>\
    \ allocates components on the heap and thus components can be activated/deactivated\
    \ at runtime</li>\n<li>\n<code>lightweight_tuple</code> does not implicitly perform\
    \ any expensive actions, such as call-stack tracking in \"Storage\"</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>\n<strong><em>Storage</em></strong>\n<ul>\n<li>Provides\
    \ persistent storage for multiple instances of components over the lifetime of\
    \ a thread in the application</li>\n<li>Responsible for maintaining the hierarchy\
    \ and order of component measurements, i.e. call-stack tracking</li>\n<li>Responsible\
    \ for combining component data from multiple threads and/or processes and outputting\
    \ the results</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: <code>tim::lightweight_tuple</code>\
    \ is the recommended bundle for those seeking to use timemory as a toolkit for\
    \ implementing custom tools and interfaces</p>\n</blockquote>\n<h2><a id=\"user-content-features\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#features\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Features</h2>\n\
    <ul>\n<li>C++ Template API\n<ul>\n<li>Modular and fully-customizable</li>\n<li>Adheres\
    \ to C++ standard template library paradigm of \"you don't pay for what you don't\
    \ use\"</li>\n<li>Simplifies and facilitates creation and implementation of performance\
    \ measurement tools\n<ul>\n<li>Create your own instrumentation profiler</li>\n\
    <li>Create your own instrumentation library</li>\n<li>Create your own sampling\
    \ profiler</li>\n<li>Create your own sampling library</li>\n<li>Create your own\
    \ execution wrappers</li>\n<li>Supplement timemory-provided tools with your own\
    \ custom component(s)</li>\n<li>Thread-safe data aggregation</li>\n<li>Aggregate\
    \ collection over multiple processes (MPI and UPC++ support)</li>\n<li>Serialization\
    \ to text, JSON, XML</li>\n</ul>\n</li>\n<li>Components are composable with other\
    \ components</li>\n<li>Variadic component bundlers which maintain complete type-safety\n\
    <ul>\n<li>Components can be bundled together into a single handle without abstractions</li>\n\
    </ul>\n</li>\n<li>Components can store data in any valid C++ data type</li>\n\
    <li>Components can return data in any valid C++ data type</li>\n</ul>\n</li>\n\
    <li>C / C++ / CUDA / Fortran Library API\n<ul>\n<li>Straight-forward collection\
    \ of functions and macros for creating built-in performance analysis to your code</li>\n\
    <li>Component collection can be arbitrarily inter-mixed\n<ul>\n<li>E.g. collect\
    \ \"A\" and \"B\" in one region, \"A\" and \"C\" in another region</li>\n</ul>\n\
    </li>\n<li>Component collection can be dynamically manipulated at runtime\n<ul>\n\
    <li>E.g. add/remove \"A\" at any point, on any thread, on any process</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>Python API\n<ul>\n<li>Decorators and context-managers\
    \ for functions or regions in code</li>\n<li>Python function profiling</li>\n\
    <li>Python line-by-line profiling</li>\n<li>Every component in <code>timemory-avail</code>\
    \ is provided as a stand-alone Python class\n<ul>\n<li>Provide low-overhead measurements\
    \ for building your own Python profiling tools</li>\n</ul>\n</li>\n</ul>\n</li>\n\
    <li>Python Analysis via <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\"\
    >pandas</a>\n</li>\n<li>Command-line Tools\n<ul>\n<li>\n<a href=\"source/tools/timemory-avail/README.md\"\
    >timemory-avail</a>\n<ul>\n<li>Provides available components, settings, and hardware\
    \ counters</li>\n<li>Quick API reference tool</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timem/README.md\">timem</a> (UNIX)\n<ul>\n<li>Extended version of\
    \ UNIX <code>time</code> command-line tool that includes additional information\
    \ on memory usage, context switches, and hardware counters</li>\n<li>Support collecting\
    \ hardware counters (Linux-only, requires PAPI)</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timemory-run/README.md\">timemory-run</a> (Linux)\n<ul>\n<li>Dynamic\
    \ instrumentation profiling tool</li>\n<li>Supports runtime instrumentation and\
    \ binary re-writing</li>\n</ul>\n</li>\n<li>\n<a href=\"source/tools/timemory-nvml/README.md\"\
    >timemory-nvml</a>\n<ul>\n<li>Data collection similar to <code>nvidia-smi</code>\n\
    </li>\n</ul>\n</li>\n<li>\n<code>timemory-python-profiler</code>\n<ul>\n<li>Python\
    \ function profiler supporting all timemory components</li>\n<li><code>from timemory.profiler\
    \ import Profile</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-trace</code>\n\
    <ul>\n<li>Python line-by-line profiler supporting all timemory components</li>\n\
    <li><code>from timemory.trace import Trace</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-line-profiler</code>\n\
    <ul>\n<li>Python line-by-line profiler based on <a href=\"https://pypi.org/project/line-profiler/\"\
    \ rel=\"nofollow\">line-profiler</a> package</li>\n<li>Extended to use components:\
    \ cpu-clock, memory-usage, context-switches, etc. (all components which collect\
    \ scalar values)</li>\n<li><code>from timemory.line_profiler import LineProfiler</code></li>\n\
    </ul>\n</li>\n</ul>\n</li>\n<li>Instrumentation Libraries\n<ul>\n<li>\n<a href=\"\
    source/tools/timemory-mpip/README.md\">timemory-mpip</a>: MPI Profiling Library\
    \ (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ncclp/README.md\">timemory-ncclp</a>:\
    \ NCCL Profiling Library (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ompt/README.md\"\
    >timemory-ompt</a>: OpenMP Profiling Library</li>\n<li>\n<a href=\"source/tools/timemory-compiler-instrument/README.md\"\
    >timemory-compiler-instrument</a>: Compiler instrumentation Library</li>\n<li>\n\
    <a href=\"source/tools/kokkos-connector/README.md\">kokkos-connector</a>: Kokkos\
    \ Profiling Libraries</li>\n</ul>\n</li>\n</ul>\n<h2><a id=\"user-content-samples\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#samples\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Samples</h2>\n\
    <p>Various macros are defined for C in <a href=\"source/timemory/timemory.h\"\
    >source/timemory/compat/timemory_c.h</a>\nand <a href=\"source/timemory/variadic/macros.hpp\"\
    >source/timemory/variadic/macros.hpp</a>. Numerous samples of\ntheir usage can\
    \ be found in the examples.</p>\n<h3><a id=\"user-content-sample-c-template-api\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#sample-c-template-api\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Sample C++\
    \ Template API</h3>\n<div class=\"highlight highlight-source-c++\"><pre>#<span\
    \ class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>timemory/timemory.hpp<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"\
    pl-k\">namespace</span> <span class=\"pl-en\">comp</span> <span class=\"pl-k\"\
    >=</span> tim::component;\n<span class=\"pl-k\">using</span> <span class=\"pl-k\"\
    >namespace</span> <span class=\"pl-en\">tim</span><span class=\"pl-k\">;</span>\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">//</span> specific set of components</span>\n\
    using <span class=\"pl-c1\">specific_t</span> = component_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;;\n<span class=\"pl-k\">using</span> <span class=\"pl-c1\"\
    >generic_t</span>  = component_tuple&lt;comp::user_global_bundle&gt;;\n\n<span\
    \ class=\"pl-k\">int</span>\n<span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span>** argv)\n{\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> configure default settings</span>\n\
    \    <span class=\"pl-c1\">settings::flat_profile</span>() = <span class=\"pl-c1\"\
    >true</span>;\n    <span class=\"pl-c1\">settings::timing_units</span>() = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span class=\"pl-pds\">\"\
    </span></span>;\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> initialize\
    \ with cmd-line</span>\n    <span class=\"pl-c1\">timemory_init</span>(argc, argv);\n\
    \    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> add argparse support</span>\n\
    \    <span class=\"pl-c1\">timemory_argparse</span>(&amp;argc, &amp;argv);\n\n\
    \    <span class=\"pl-c\"><span class=\"pl-c\">//</span> create a region \"main\"\
    </span>\n    <span class=\"pl-c1\">specific_t</span> m{ <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span> };\n \
    \   m.<span class=\"pl-c1\">start</span>();\n    m.<span class=\"pl-c1\">stop</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">settings::enabled</span>() = <span\
    \ class=\"pl-c1\">false</span>;\n    <span class=\"pl-c1\">specific_t</span> h{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden<span class=\"pl-pds\"\
    >\"</span></span> };\n    h.<span class=\"pl-c1\">start</span>().<span class=\"\
    pl-c1\">stop</span>();\n    <span class=\"pl-c1\">settings::enabled</span>() =\
    \ <span class=\"pl-c1\">true</span>;\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Add peak_rss component to specific_t</span>\n    mpl::<span class=\"\
    pl-c1\">push_back_t</span>&lt;<span class=\"pl-c1\">specific_t</span>, comp::peak_rss&gt;\
    \ wprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>with peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n    \n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> create region collecting only peak_rss</span>\n    component_tuple&lt;comp::peak_rss&gt;\
    \ oprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>only peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> convert component_tuple to a type that starts/stops upon construction/destruction</span>\n\
    \    {\n        scope::config _scope{};\n        <span class=\"pl-k\">if</span>(<span\
    \ class=\"pl-c1\">true</span>)  _scope += scope::flat{};\n        <span class=\"\
    pl-k\">if</span>(<span class=\"pl-c1\">false</span>) _scope += scope::timeline{};\n\
    \        <span class=\"pl-c1\">convert_t</span>&lt;<span class=\"pl-c1\">specific_t</span>,\
    \ auto_tuple&lt;&gt;&gt; scoped{ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>scoped start/stop + flat<span class=\"pl-pds\">\"</span></span>, _scope\
    \ };\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> will yield auto_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;</span>\n    }\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of strings</span>\n    runtime::configure&lt;comp::user_global_bundle&gt;({\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> });\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of enumeration ids</span>\n\
    \    runtime::configure&lt;comp::user_global_bundle&gt;({ TIMEMORY_WALL_CLOCK,\
    \ TIMEMORY_CPU_CLOCK });\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ configure the generic bundle via component instances</span>\n    comp::user_global_bundle::configure&lt;comp::page_rss,\
    \ comp::papi_vector&gt;();\n    \n    <span class=\"pl-c1\">generic_t</span> g{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>generic<span class=\"pl-pds\"\
    >\"</span></span>, quirk::config&lt;quirk::auto_start&gt;{} };\n    g.<span class=\"\
    pl-c1\">stop</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3><a id=\"user-content-sample-c--c-library-api\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sample-c--c-library-api\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Sample C / C++ Library API</h3>\n\
    <div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/library.h<span\
    \ class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/timemory.h<span class=\"\
    pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">int</span>\n<span class=\"pl-en\"\
    >main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span>**\
    \ argv)\n{\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> configure\
    \ settings</span>\n    <span class=\"pl-k\">int</span> overwrite       = <span\
    \ class=\"pl-c1\">0</span>;\n    <span class=\"pl-k\">int</span> update_settings\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> default to flat-profile</span>\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_FLAT_PROFILE<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> force timing units</span>\n    overwrite\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_TIMING_UNITS<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> initialize with cmd-line</span>\n\
    \    <span class=\"pl-c1\">timemory_init_library</span>(argc, argv);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> check if inited, init with name</span>\n\
    \    <span class=\"pl-k\">if</span>(!<span class=\"pl-c1\">timemory_library_is_initialized</span>())\n\
    \        <span class=\"pl-c1\">timemory_named_init_library</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>ex-c<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> define the default set\
    \ of components</span>\n    <span class=\"pl-c1\">timemory_set_default</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock, cpu_clock<span class=\"\
    pl-pds\">\"</span></span>);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ create a region \"main\"</span>\n    <span class=\"pl-c1\">timemory_push_region</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>);\n    <span class=\"pl-c1\">timemory_pop_region</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">timemory_pause</span>();\n    <span\
    \ class=\"pl-c1\">timemory_push_region</span>(<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_pop_region</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_resume</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> Add/remove component(s) to the current set of components</span>\n \
    \   <span class=\"pl-c1\">timemory_add_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_remove_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> get an identifier for\
    \ a region and end it</span>\n    <span class=\"pl-c1\">uint64_t</span> idx =\
    \ <span class=\"pl-c1\">timemory_get_begin_record</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> assign an existing identifier for a region</span>\n\
    \    <span class=\"pl-c1\">timemory_begin_record</span>(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>indexed/2<span class=\"pl-pds\">\"</span></span>,\
    \ &amp;idx);\n    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n \
    \   <span class=\"pl-c\"><span class=\"pl-c\">//</span> create region collecting\
    \ a specific set of data</span>\n    <span class=\"pl-c1\">timemory_begin_record_enum</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>enum<span class=\"pl-pds\">\"\
    </span></span>, &amp;idx, TIMEMORY_PEAK_RSS, TIMEMORY_COMPONENTS_END);\n    <span\
    \ class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"pl-c1\"\
    >timemory_begin_record_types</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>types<span class=\"pl-pds\">\"</span></span>, &amp;idx, <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> replace current set of components and then\
    \ restore previous set</span>\n    <span class=\"pl-c1\">timemory_push_components</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\"\
    >\"</span></span>);\n    <span class=\"pl-c1\">timemory_pop_components</span>();\n\
    \n    <span class=\"pl-c1\">timemory_push_components_enum</span>(<span class=\"\
    pl-c1\">2</span>, TIMEMORY_WALL_CLOCK, TIMEMORY_CPU_CLOCK);\n    <span class=\"\
    pl-c1\">timemory_pop_components</span>();\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize_library</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3><a id=\"user-content-sample-fortran-api\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sample-fortran-api\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Sample Fortran API</h3>\n<div class=\"\
    highlight highlight-source-fortran\"><pre><span class=\"pl-k\">program</span>\
    \ fortran_example\n    use timemory\n    use iso_c_binding, only : C_INT64_T\n\
    \    <span class=\"pl-k\">implicit none</span>\n    <span class=\"pl-k\">integer</span>(C_INT64_T)\
    \ <span class=\"pl-k\">::</span> idx\n\n    ! initialize with explicit name\n\
    \    <span class=\"pl-k\">call</span> timemory_init_library(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>ex-fortran<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! initialize with name extracted from get_command_argument(<span class=\"\
    pl-c1\">0</span>, ...)\n    ! <span class=\"pl-k\">call</span> timemory_init_library(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! define the default set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_set_default(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock,\
    \ cpu_clock<span class=\"pl-pds\">\"</span></span>)\n\n    ! Start region <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! Add peak_rss <span class=\"pl-k\">to</span> the current\
    \ set of components\n    <span class=\"pl-k\">call</span> timemory_add_components(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\"\
    >\"</span></span>)\n\n    ! Nested region <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span> nested under <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! End the <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>inner<span class=\"pl-pds\">\"</span></span> region\n    <span class=\"\
    pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner<span class=\"pl-pds\">\"</span></span>)\n\n    ! remove peak_rss\n\
    \    <span class=\"pl-k\">call</span> timemory_remove_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! begin a region and get an identifier\n    idx <span class=\"pl-k\">=</span>\
    \ timemory_get_begin_record(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>indexed<span\
    \ class=\"pl-pds\">\"</span></span>)\n\n    ! replace current set of components\n\
    \    <span class=\"pl-k\">call</span> timemory_push_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Nested region <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> with only page_rss components\n    <span class=\"\
    pl-k\">call</span> timemory_push_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\n    ! <span\
    \ class=\"pl-k\">Stop</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> region with only page_rss components\n   \
    \ <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! restore previous set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_pop_components()\n\n    ! end the <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span> region\n    <span\
    \ class=\"pl-k\">call</span> timemory_end_record(idx)\n\n    ! End <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>\n\
    \    <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Output the results\n    <span class=\"pl-k\">call</span> timemory_finalize_library()\n\
    \n<span class=\"pl-k\">end program</span> fortran_example</pre></div>\n<h3><a\
    \ id=\"user-content-sample-python-api\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#sample-python-api\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Sample Python API</h3>\n<h4><a id=\"user-content-decorator\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#decorator\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Decorator</h4>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">bundle</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">marker</span>\n\n<span class=\"\
    pl-en\">@<span class=\"pl-en\">marker</span>([<span class=\"pl-s\">\"cpu_clock\"\
    </span>, <span class=\"pl-s\">\"peak_rss\"</span>])</span>\n<span class=\"pl-k\"\
    >def</span> <span class=\"pl-en\">foo</span>():\n    <span class=\"pl-k\">pass</span></pre></div>\n\
    <h4><a id=\"user-content-context-manager\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#context-manager\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Context Manager</h4>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">timemory</span>.<span class=\"pl-s1\">profiler</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-s1\">profile</span>\n\n<span class=\"pl-k\">def</span>\
    \ <span class=\"pl-en\">bar</span>():\n    <span class=\"pl-k\">with</span> <span\
    \ class=\"pl-en\">profile</span>([<span class=\"pl-s\">\"wall_clock\"</span>,\
    \ <span class=\"pl-s\">\"cpu_util\"</span>]):\n        <span class=\"pl-en\">foo</span>()</pre></div>\n\
    <h4><a id=\"user-content-individual-components\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#individual-components\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Individual Components</h4>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span\
    \ class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">component</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-v\">WallClock</span>\n\n<span\
    \ class=\"pl-k\">def</span> <span class=\"pl-en\">spam</span>():\n\n    <span\
    \ class=\"pl-s1\">wc</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >WallClock</span>(<span class=\"pl-s\">\"spam\"</span>)\n    <span class=\"pl-s1\"\
    >wc</span>.<span class=\"pl-en\">start</span>()\n\n    <span class=\"pl-en\">bar</span>()\n\
    \n    <span class=\"pl-s1\">wc</span>.<span class=\"pl-en\">stop</span>()\n  \
    \  <span class=\"pl-s1\">data</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">wc</span>.<span class=\"pl-en\">get</span>()\n    <span class=\"pl-en\"\
    >print</span>(<span class=\"pl-s1\">data</span>)</pre></div>\n<h4><a id=\"user-content-argparse-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#argparse-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Argparse\
    \ Support</h4>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"\
    pl-k\">import</span> <span class=\"pl-s1\">argparse</span>\n\n<span class=\"pl-s1\"\
    >parser</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">argparse</span>.<span\
    \ class=\"pl-v\">ArgumentParser</span>(<span class=\"pl-s\">\"example\"</span>)\n\
    <span class=\"pl-c\"># ...</span>\n<span class=\"pl-s1\">timemory</span>.<span\
    \ class=\"pl-en\">add_arguments</span>(<span class=\"pl-s1\">parser</span>)\n\n\
    <span class=\"pl-s1\">args</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">parser</span>.<span class=\"pl-en\">parse_args</span>()</pre></div>\n\
    <h4><a id=\"user-content-component-storage\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#component-storage\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Component Storage</h4>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">timemory</span>.<span class=\"pl-s1\">storage</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-v\">WallClockStorage</span>\n\n<span class=\"\
    pl-c\"># data for current rank</span>\n<span class=\"pl-s1\">data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">get</span>()\n<span class=\"pl-c\"># combined data on rank zero\
    \ but all ranks must call it</span>\n<span class=\"pl-s1\">dmp_data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">dmp_get</span>()</pre></div>\n<h2><a id=\"user-content-versioning\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#versioning\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Versioning</h2>\n\
    <p>Timemory originated as a very simple tool for recording timing and memory measurements\
    \ (hence the name) in C, C++, and Python and only supported\nthree modes prior\
    \ to the 3.0.0 release: a fixed set of timers, a pair of memory measurements,\
    \ and the combination of the two.\n<strong>Prior to the 3.0.0 release, timemory\
    \ was almost completely rewritten from scratch</strong> with the sole exceptions\
    \ of some C/C++ macro, e.g.\n<code>TIMEMORY_AUTO_TIMER</code>, and some Python\
    \ decorators and context-manager, e.g. <code>timemory.util.auto_timer</code>,\
    \ whose behavior were\nable to be fully replicated in the new release. Thus, while\
    \ it may appear that timemory is a mature project at v3.0+, it\nis essentially\
    \ still in it's first major release.</p>\n<h2><a id=\"user-content-citing-timemory\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-timemory\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citing timemory</h2>\n\
    <p>To reference timemory in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Madsen, J.R. et al. (2020) Timemory: Modular Performance Analysis for\
    \ HPC. In: Sadayappan P., Chamberlain B., Juckeland G., Ltaief H. (eds) High Performance\
    \ Computing. ISC High Performance 2020. Lecture Notes in Computer Science, vol\
    \ 12151. Springer, Cham</li>\n</ul>\n<h2><a id=\"user-content-additional-information\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#additional-information\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Additional\
    \ Information</h2>\n<p>For more information, refer to the <a href=\"https://timemory.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n"
  stargazers_count: 336
  subscribers_count: 16
  topics:
  - python
  - cpp
  - cplusplus
  - performance
  - c
  - cross-platform
  - cross-language
  - memory-measurements
  - mpi
  - cuda
  - papi
  - hardware-counters
  - analysis
  - roofline
  - performance-measurement
  - instrumentation-api
  - gotcha
  - cupti
  - modular-design
  updated_at: 1707466309.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 56
  subscribers_count: 20
  topics: []
  updated_at: 1707762799.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<h1><a id="user-content-gsi-utils" class="anchor" aria-hidden="true" tabindex="-1"
    href="#gsi-utils"><span aria-hidden="true" class="octicon octicon-link"></span></a>GSI-Utils</h1>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 2
  subscribers_count: 8
  topics: []
  updated_at: 1690297134.0
NOAA-EMC/NCEPLIBS-bufr:
  data_format: 2
  description: The NCEPLIBS-bufr library contains routines and utilites for working
    with the WMO BUFR format.
  filenames:
  - spack/spack.yaml
  full_name: NOAA-EMC/NCEPLIBS-bufr
  latest_release: v12.0.1
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/NOAA-EMC/NCEPLIBS-bufr/workflows/Build%20and%20Test/badge.svg"><img
    src="https://github.com/NOAA-EMC/NCEPLIBS-bufr/workflows/Build%20and%20Test/badge.svg"
    alt="Status" style="max-width: 100%;"></a></p>

    <h2><a id="user-content-nceplibs-bufr-library" class="anchor" aria-hidden="true"
    tabindex="-1" href="#nceplibs-bufr-library"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NCEPLIBS-bufr library</h2>

    <p>The NCEPLIBS-bufr library contains routines and utilites for working

    with the <a href="https://library.wmo.int/index.php?lvl=notice_display&amp;id=10684#.Y70OSNLMJH7"
    rel="nofollow">WMO

    BUFR</a>

    format. It is part of the

    <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> project.</p>

    <p>For full documentation of the library, see <a href="https://noaa-emc.github.io/NCEPLIBS-bufr/"
    rel="nofollow">https://noaa-emc.github.io/NCEPLIBS-bufr/</a>.</p>

    <p>NCEPLIBS-bufr is used by numerous other projects including:</p>

    <ul>

    <li>

    <a href="https://github.com/NOAA-EMC/gfs-utils">gfs-utils</a> from NOAA''s global

    workflow.</li>

    <li>NCAR''s <a href="https://ral.ucar.edu/solutions/products/gridpoint-statistical-interpolation-gsi"
    rel="nofollow">Gridpoint Statistical Interpolation

    (GSI)</a>.</li>

    <li>

    <a href="https://github.com/NOAA-EMC/obsproc">obsproc</a> in the <a href="https://nomads.ncep.noaa.gov/"
    rel="nofollow">NOAA

    Operational Model Archive and Distribution System (NOMADS)</a>.</li>

    <li>

    <a href="https://github.com/NOAA-EMC/prepobs">prepobs</a> from the <a href="https://www.nco.ncep.noaa.gov/pmb/prod_overview/"
    rel="nofollow">The NCEP Production Suite</a>.</li>

    <li>

    <a href="https://github.com/NOAA-EMC/bufr-dump">bufr-dump</a> which is run by

    all of the NOAA model data assimilation systems when it''s time to

    collect data for use in the analyses.</li>

    <li>the <a href="https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast"
    rel="nofollow">Global Ensemble Forecast

    System(GEFS)</a>.</li>

    <li>the <a href="https://rapidrefresh.noaa.gov/hrrr/" rel="nofollow">High-Resolution
    Rapid Refresh model

    (HRRR)</a>.</li>

    <li>NOAA''s <a href="https://rapidrefresh.noaa.gov/" rel="nofollow">Rapid Refresh
    (RAP)</a> assimilation/modeling system.</li>

    </ul>

    <p>To submit bug reports, feature requests, or other code-related issues including
    installation and usage questions, please create a <a href="https://github.com/NOAA-EMC/NCEPLIBS-bufr/issues">GitHub
    issue</a>. For general NCEPLIBS inquiries, contact <a href="mailto:edward.hartnett@noaa.gov">Edward
    Hartnett</a> (secondary point of contact <a href="mailto:alexander.richert@noaa.gov">Alex
    Richert</a>).</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Jack Woollen, Jeff Ator, Dennis Keyser, Stacey Bender, Diane Stokes, Edward
    Hartnett,

    Jeff Whitaker, Rahul Mahajan, Alex Richert, Ron McLaren, and Dom Heinzeller.</p>

    <p>Code manager: <a href="mailto:jeff.ator@noaa.gov">Jeff Ator</a></p>

    <h2><a id="user-content-how-to-build-and-install" class="anchor" aria-hidden="true"
    tabindex="-1" href="#how-to-build-and-install"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>How to Build and Install</h2>

    <p>Download tarball from

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-bufr/releases">Releases</a> and

    unpack.</p>

    <pre>mkdir build &amp;&amp; cd build

    cmake -DCMAKE_INSTALL_PREFIX=path1 -DMASTER_TABLE_DIR=path2 ..

    make -j4

    ctest

    make install

    </pre>

    <p>Both <code>path1</code> and <code>path2</code> may be full or relative pathnames

    on the system, up to a maximum of 90 characters each.</p>

    <p>Installation of the library and utilities will be under <code>path1</code>.

    Installation of the master BUFR tables will be under <code>path2</code>, or

    under <code>path1</code> if <code>-DMASTER_TABLE_DIR=path2</code> is omitted

    from the above cmake command.</p>

    <p>If Python interoperability is desired, <code>-DENABLE_PYTHON=ON</code> can
    also

    be added to the above cmake command.  However, version 3 of Python

    must be installed and available on the system.</p>

    <h2><a id="user-content-references" class="anchor" aria-hidden="true" tabindex="-1"
    href="#references"><span aria-hidden="true" class="octicon octicon-link"></span></a>References</h2>

    <p>Hartnett, E., Ator, J, Lei, H., Richert, A., Woollen, J., King, A.,

    Hartnett, A., <a href="https://www.researchgate.net/publication/376390180_NCEPLIBS_GRIB_and_BUFR_Libraries_Maintaining_and_Modernizing_NOAA''s_Libraries_for_WMO_Data_Formats"
    rel="nofollow">NCEPLIBS GRIB and BUFR Libraries: Maintaining and

    Modernizing NOAA''s Libraries for WMO Data

    Formats</a>,

    American Geophysical Union (AGU) 2023. (See also

    <a href="https://www.researchgate.net/publication/376582005_Poster_-_IN51B-0416_NCEPLIBS_GRIB_and_BUFR_Libraries_Maintaining_and_Modernizing_NOAA''s_Libraries_for_WMO_Data_Formats"
    rel="nofollow">poster</a>).</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" tabindex="-1"
    href="#disclaimer"><span aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 33
  subscribers_count: 5
  topics:
  - bufr
  updated_at: 1707642870.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: upp-srw-v2.1.0
  readme: '<h1><a id="user-content-unified-post-processor-upp" class="anchor" aria-hidden="true"
    tabindex="-1" href="#unified-post-processor-upp"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Unified Post Processor (UPP)</h1>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High-Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecast System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Analysis and

    Forecast System (HAFS), and the Medium-Range Weather (MRW) and Short-

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model-derived brightness
    temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages or for

    further downstream post-processing, e.g., statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <h2><a id="user-content-user-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#user-support"><span aria-hidden="true" class="octicon octicon-link"></span></a>User
    Support</h2>

    <p>Support for the UFS UPP is provided through <a href="https://github.com/NOAA-EMC/UPP/discussions">GitHub
    Discussions</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>User Guide for latest standalone public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <h2><a id="user-content-developer-information" class="anchor" aria-hidden="true"
    tabindex="-1" href="#developer-information"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Developer Information</h2>

    <p>Please review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Fernando Andrade-Maldonado</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" tabindex="-1"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>The UPP requires certain NCEPLIBS packages to be installed via the

    spack-stack project. For instructions on installing these packages as a

    bundle via spack-stack, see: <a href="https://spack-stack.readthedocs.io/en/latest/"
    rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a>.

    The <code>UPP/modulefiles</code> directory indicates which package versions are

    used and supported on Level 1 systems.</p>

    <p>Required NCEPLIBS packages:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf">netcdf</a></li>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">zlib</a></li>

    <li><a href="https://github.com/HDFGroup/hdf5">hdf5</a></li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" tabindex="-1"
    href="#building"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" tabindex="-1"
    href="#disclaimer"><span aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <h2><a id="user-content-upp-terms-of-use-notice" class="anchor" aria-hidden="true"
    tabindex="-1" href="#upp-terms-of-use-notice"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>UPP Terms of Use Notice</h2>

    <p>The UPP Terms of Use Notice is available at: <a href="https://github.com/NOAA-EMC/UPP/wiki/UPP-Terms-of-Use-Notice">https://github.com/NOAA-EMC/UPP/wiki/UPP-Terms-of-Use-Notice</a></p>

    '
  stargazers_count: 28
  subscribers_count: 14
  topics: []
  updated_at: 1705527282.0
NOAA-EMC/fv3atm:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/fv3atm
  latest_release: null
  readme: '<h1><a id="user-content-fv3atm" class="anchor" aria-hidden="true" tabindex="-1"
    href="#fv3atm"><span aria-hidden="true" class="octicon octicon-link"></span></a>fv3atm</h1>

    <p>This repository contains a driver and key subcomponents of the

    atmospheric component of the NOAA''s <a href="https://ufscommunity.org/" rel="nofollow">Unified
    Forecast System

    (UFS)</a> weather model.</p>

    <p>The subcomponents include:</p>

    <ul>

    <li>The Finite-Volume Cubed-Sphere (FV3) dynamical core, originally

    from the <a href="https://www.gfdl.noaa.gov/" rel="nofollow">Geophysical Fluid
    Dynamics

    Laboratory</a>.</li>

    <li>The Common Community Physics Package (CCPP) supported by the

    <a href="https://dtcenter.org/community-code/common-community-physics-package-ccpp"
    rel="nofollow">Developmental Testbed Center

    (DTC)</a>,

    including:

    <ul>

    <li>

    <a href="https://github.com/NCAR/ccpp-framework">CCPP Framework</a>.</li>

    <li><a href="https://github.com/NCAR/ccpp-physics">CCPP Physics</a></li>

    </ul>

    </li>

    <li>wrapper code to call <a href="https://stochastic-physics.readthedocs.io/en/latest/"
    rel="nofollow">UFS stochastic

    physics</a>

    </li>

    <li>The io code handles netCDF I/O.</li>

    <li>The cpl coupler code connects the different components and allows

    them to communicate.</li>

    </ul>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" tabindex="-1"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This package requires the following

    <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> packages:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    </ul>

    <p>If the INLINE_POST cmake variable is set, the upp library will be

    needed:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/EMC_post">Unified Post Processing Library</a></li>

    </ul>

    <p>This package also requires the following external packages:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c Library</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran Library</a></li>

    <li><a href="https://github.com/esmf-org/esmf">ESMF</a></li>

    <li><a href="https://github.com/NOAA-GFDL/FMS">GFDL''s Flexible Modeling System</a></li>

    </ul>

    <h2><a id="user-content-obtaining-fv3atm" class="anchor" aria-hidden="true" tabindex="-1"
    href="#obtaining-fv3atm"><span aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining
    fv3atm</h2>

    <p>To obtain fv3atm, clone the git repository, and update the submodules:</p>

    <pre><code>git clone https://github.com/NOAA-EMC/fv3atm.git

    cd fv3atm

    git submodule update --init --recursive

    </code></pre>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" tabindex="-1"
    href="#disclaimer"><span aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 28
  subscribers_count: 24
  topics: []
  updated_at: 1707461437.0
ORNL/ReSolve:
  data_format: 2
  description: Library of GPU-resident linear solvers
  filenames:
  - buildsystem/spack/ascent/spack.yaml
  full_name: ORNL/ReSolve
  latest_release: null
  readme: "<h1><a id=\"user-content-resolve\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#resolve\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>ReSolve</h1>\n<p>ReSolve is a library of GPU-resident\
    \ linear solvers. It contains iterative and direct solvers designed to run on\
    \ NVIDIA and AMD GPUs, as well as on CPU devices.</p>\n<p>The User Guide and developer's\
    \ documentation is available <a href=\"https://resolve.readthedocs.io/\" rel=\"\
    nofollow\">online</a>,\nincluding Doxygen-generated <a href=\"https://resolve.readthedocs.io/en/develop/doxygen/html/index.html\"\
    \ rel=\"nofollow\">source code documentation</a>.</p>\n<h2><a id=\"user-content-getting-started\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#getting-started\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting\
    \ started</h2>\n<p>Dependencies:</p>\n<ul>\n<li>KLU, AMD and COLAMD libraries\
    \ from SuiteSparse &gt;= 5.0</li>\n<li>CMake &gt;= 3.22</li>\n<li>CUDA &gt;= 11.4\
    \ (optional)</li>\n<li>HIP/ROCm &gt;= 5.6 (optional)</li>\n</ul>\n<p>To build\
    \ it:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ git clone https://github.com/ORNL/ReSolve.git\n\
    $ mkdir build <span class=\"pl-k\">&amp;&amp;</span> <span class=\"pl-c1\">cd</span>\
    \ build\n$ cmake ../ReSolve\n$ make</pre></div>\n<h2><a id=\"user-content-to-install-the-library\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#to-install-the-library\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To install\
    \ the library</h2>\n<p>In the directory where you built the library run</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ make install</pre></div>\n\
    <p>To change the install location please use the CMAkePresets.json file as mentioned\
    \ in <a href=\"#test-and-deploy\">test and deploy</a></p>\n<p>To run it, download\
    \ <a href=\"https://github.com/NREL/opf_matrices/tree/master/acopf/activsg10k\"\
    >test linear systems</a> and then edit script <a href=\"runResolve\"><code>runResolve</code></a>\
    \ to match locations of your linear systems and binary installation. The script\
    \ will emulate nonlinear solver calling the linear solver repeatedly.</p>\n<h2><a\
    \ id=\"user-content-to-use-the-resolve-library-in-your-own-project\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#to-use-the-resolve-library-in-your-own-project\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To use the\
    \ ReSolve library in your own project</h2>\n<p>Make sure Resolve library is installed\
    \ (see above)</p>\n<p>Below is an example CMakeList.txt file to use ReSolve library\
    \ in your project</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span\
    \ class=\"pl-c1\">cmake_minimum_required</span>(<span class=\"pl-k\">VERSION</span>\
    \ 3.20)\n<span class=\"pl-c1\">project</span>(my_app <span class=\"pl-k\">LANGUAGES</span>\
    \ CXX)\n\n<span class=\"pl-c1\">find_package</span>(ReSolve <span class=\"pl-k\"\
    >CONFIG</span> \n  <span class=\"pl-k\">PATHS</span> <span class=\"pl-smi\">${ReSolve_DIR}</span>\
    \ <span class=\"pl-smi\">${ReSolve_DIR}</span>/share/resolve/cmake\n  <span class=\"\
    pl-k\">ENV</span> <span class=\"pl-k\">LD_LIBRARY_PATH</span> <span class=\"pl-k\"\
    >ENV</span> DYLD_LIBRARY_PATH\n  <span class=\"pl-k\">REQUIRED</span>)\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Build your executable </span>\n\
    add_executable(my_app my_app.cpp)\n<span class=\"pl-c1\">target_link_libraries</span>(my_app\
    \ <span class=\"pl-k\">PRIVATE</span> ReSolve::ReSolve)</pre></div>\n<h2><a id=\"\
    user-content-contributing\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contributing</h2>\n<p>For all contributions to ReSolve please follow\
    \ the <a href=\"CONTRIBUTING.md\">developer guidelines</a></p>\n<h2><a id=\"user-content-test-and-deploy\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#test-and-deploy\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Test and\
    \ Deploy</h2>\n<p>ReSolve as a library is tested every merge request via Gitlab\
    \ pipelines that execute various library tests including a test of ReSolve being\
    \ consumed as package within an external project as mentioned in <a href=\"#to-use-the-resolve-library-in-your-own-project\"\
    >Using ReSolve in your own Project</a></p>\n<p>To test your own install of ReSolve\
    \ simply run from your ReSolve build directory</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ make <span class=\"pl-c1\">test</span></pre></div>\n<p>After you <code>make\
    \ install</code> you can test your installation by running</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$ make test_install</pre></div>\n<p>from\
    \ your build directory.</p>\n<h3><a id=\"user-content-important-notes\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#important-notes\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Important Notes</h3>\n\
    <p>You can find default Cmake Configurations in the CMakePresets.json file, which\
    \ allows for easy switching between different CMake Configs. To create your own\
    \ CMake Configuration we encourage you to utlize a CmakeUserPresets.json file.\
    \ To learn more about cmake-presets please checkout the cmake <a href=\"https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html\"\
    \ rel=\"nofollow\">docs</a></p>\n<p>For example if you wanted to build and install\
    \ ReSolve on a High Performance Computing Cluster such as PNNL's Deception or\
    \ ORNL's Ascent we encourage you to utilize our cluster preset. Using this preset\
    \ will set CMAKE_INSTALL_PREFIX to an install folder. To use this preset simply\
    \ call the preset flag in the cmake build step.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -B build --preset cluster</pre></div>\n<h2><a id=\"user-content-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#support\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Support</h2>\n\
    <p>For technical questions or to report a bug please submit a <a href=\"https://github.com/ORNL/ReSolve/issues\"\
    >GitHub issue</a>.\nFor non-technical issues please contact Kasia \u015Awirydowicz\
    \ <a href=\"mailto:kasia.swirydowicz@pnnl.gov\">kasia.swirydowicz@pnnl.gov</a>\
    \ or Slaven Peles <a href=\"mailto:peless@ornl.gov\">peless@ornl.gov</a>.</p>\n\
    <h2><a id=\"user-content-authors-and-acknowledgment\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#authors-and-acknowledgment\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Authors and acknowledgment</h2>\n\
    <p>Primary authors of this project are Kasia \u015Awirydowicz and Slaven Peles.</p>\n\
    <p>ReSolve project would not be possible without significant contributions from\
    \ (in alphabetic order):</p>\n<ul>\n<li>Maksudul Alam</li>\n<li>Ryan Danehy</li>\n\
    <li>Nicholson Koukpaizan</li>\n<li>Jaelyn Litzinger</li>\n<li>Phil Roth</li>\n\
    <li>Cameron Rutherford</li>\n</ul>\n<p>Development of this code was supported\
    \ by the Exascale Computing Project (ECP), Project Number: 17-SC-20-SC,\na collaborative\
    \ effort of two DOE organizations\u2014the Office of Science and the National\
    \ Nuclear Security\nAdministration\u2014responsible for the planning and preparation\
    \ of a capable exascale ecosystem\u2014including software,\napplications, hardware,\
    \ advanced system engineering, and early testbed platforms\u2014to support the\
    \ nation's exascale\ncomputing imperative.</p>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>Copyright \xA9 2023, UT-Battelle, LLC, and Battelle Memorial Institute.</p>\n\
    <p>ReSolve is a free software distributed under a BSD-style license. See the\n\
    <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> files for details.\
    \ All new\ncontributions to ReSolve must be made under the smae licensing terms.</p>\n\
    <p><strong>Please Note</strong> If you are using ReSolve with any third party\
    \ libraries linked\nin (e.g., KLU), be sure to review the respective license of\
    \ the package as that\nlicense may have more restrictive terms than the ReSolve\
    \ license.</p>\n"
  stargazers_count: 46
  subscribers_count: 6
  topics: []
  updated_at: 1705294375.0
PawseySC/hpc-container-training:
  data_format: 2
  description: 'Training material on using containers in an HPC setting. '
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/hpc-container-training
  latest_release: null
  readme: '<h1><a id="user-content-readme" class="anchor" aria-hidden="true" tabindex="-1"
    href="#readme"><span aria-hidden="true" class="octicon octicon-link"></span></a>Readme</h1>

    '
  stargazers_count: 4
  subscribers_count: 5
  topics:
  - docker
  - singularity
  - hpc
  - pawsey
  - training-materials
  updated_at: 1682469853.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Automated deployment system for the scientific software stack in use
    at Pawsey
  filenames:
  - systems/setonix/environments/cray_devel/spack.yaml
  - systems/setonix/environments/wrf/spack.yaml
  - systems/setonix/environments/cray_s3_clients/spack.yaml
  - systems/setonix/environments/bench/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-pawsey-spack-configuration" class="anchor" aria-hidden="true"
    tabindex="-1" href="#pawsey-spack-configuration"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Pawsey Spack Configuration</h1>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_TAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <h3><a id="user-content-singularity" class="anchor" aria-hidden="true" tabindex="-1"
    href="#singularity"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h3>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <h3><a id="user-content-software-stack-modulefile" class="anchor" aria-hidden="true"
    tabindex="-1" href="#software-stack-modulefile"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Software stack modulefile</h3>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <h2><a id="user-content-repository-structure" class="anchor" aria-hidden="true"
    tabindex="-1" href="#repository-structure"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Repository structure</h2>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <h2><a id="user-content-the-scripts-directory" class="anchor" aria-hidden="true"
    tabindex="-1" href="#the-scripts-directory"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>The <code>scripts</code> directory</h2>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <h2><a id="user-content-the-systemssystem-directory" class="anchor" aria-hidden="true"
    tabindex="-1" href="#the-systemssystem-directory"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>The <code>systems/&lt;system&gt;</code> directory</h2>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <h2><a id="user-content-notes" class="anchor" aria-hidden="true" tabindex="-1"
    href="#notes"><span aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h2>

    <h3><a id="user-content-module-categories-in-use" class="anchor" aria-hidden="true"
    tabindex="-1" href="#module-categories-in-use"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Module categories in use</h3>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <h3><a id="user-content-testing-modules" class="anchor" aria-hidden="true" tabindex="-1"
    href="#testing-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a>Testing
    Modules</h3>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1687655533.0
RMeli/my-spack:
  data_format: 2
  description: Spack environments
  filenames:
  - envs/alps/dlaf/oneapi-mt/spack.yaml
  - envs/local/dlaf/mkl-mt-mpich-cuda-scalapack-pika/spack.yaml
  - envs/alps/cp2k/cpu/openblas/spack.yaml
  - envs/alps/sirius/cuda/spack.yaml
  full_name: RMeli/my-spack
  latest_release: null
  readme: '<h1><a id="user-content-my-spack" class="anchor" aria-hidden="true" tabindex="-1"
    href="#my-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>My
    Spack</h1>

    <p>Spack-related stuff for @RMeli.</p>

    <h2><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    tabindex="-1" href="#package-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Package Repository</h2>

    <p><a href="https://spack.readthedocs.io/en/latest/repositories.html" rel="nofollow">Spack
    Package Repositories</a></p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1706256608.0
SC-SGS/CPPuddle:
  data_format: 2
  description: Utility library to handle small, reusable pools of both device memory
    buffers (via allocators) and device executors (with multiple scheduling policies).
  filenames:
  - spack.yaml
  full_name: SC-SGS/CPPuddle
  latest_release: v0.3.1
  readme: "<h3><a id=\"user-content-cppuddle\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#cppuddle\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>CPPuddle</h3>\n<p><a href=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml\"\
    ><img src=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml/badge.svg\"\
    \ alt=\"ctest\" style=\"max-width: 100%;\"></a>\n<a href=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/view/Octo-Tiger%20and%20Dependencies/job/CPPuddle/job/master/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fb52bcf1fb6b241adb67e33da2e2093e2f6e3569a3f400b53f7b8f65bd12958/68747470733a2f2f73696d7367732e696e666f726d6174696b2e756e692d7374757474676172742e64652f6a656e6b696e732f6275696c645374617475732f69636f6e3f6a6f623d4350507564646c652532466d617374657226636f6e6669673d616c6c6275696c6473\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=CPPuddle%2Fmaster&amp;config=allbuilds\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h4><a id=\"user-content-purpose\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Purpose</h4>\n<p>This repository\
    \ was initially created to explore how to best use HPX and Kokkos together!\n\
    For fine-grained GPU tasks, we needed a way to avoid excessive allocations of\
    \ one-usage GPU buffers (as allocations block the device for all streams) and\
    \ creation/deletion of GPU executors (as those are usually tied to a stream which\
    \ is expensive to create as well).</p>\n<p>We currently test/use CPPuddle in <a\
    \ href=\"https://github.com/STEllAR-GROUP/octotiger\">Octo-Tiger</a>, together\
    \ with <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>.\n\
    In this use-case, allocating GPU buffers for all sub-grids in advance would have\
    \ wasted a lot of memory. On the other hand, unified memory would have caused\
    \ unnecessary GPU to CPU page migrations (as the old input data gets overwritten\
    \ anyway). Allocating buffers on-the-fly would have blocked the device. Hence,\
    \ we currently test this buffer management solution!</p>\n<h4><a id=\"user-content-tools-provided-by-this-repository\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#tools-provided-by-this-repository\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tools provided\
    \ by this repository</h4>\n<ul>\n<li>Allocators that reuse previousely allocated\
    \ buffers if available (works with normal heap memory, pinned memory, aligned\
    \ memory, CUDA/HIP device memory, and Kokkos Views). Note that separate buffers\
    \ do not coexist on a single chunk of continuous memory, but use different allocations.</li>\n\
    <li>Executor pools and various scheduling policies (round robin, priority queue,\
    \ multi-gpu), which rely on reference counting to gauge the current load of a\
    \ executor instead of querying the device itself. Tested with CUDA, HIP and Kokkos\
    \ executors provided by HPX / HPX-Kokkos.</li>\n<li>Special Executors/Allocators\
    \ for on-the-fly work GPU aggregation (using HPX).</li>\n</ul>\n<h4><a id=\"user-content-requirements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#requirements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h4>\n\
    <ul>\n<li>C++17</li>\n<li>CMake (&gt;= 3.16)</li>\n<li>Optional (for the header-only\
    \ utilities / test): CUDA, Boost, <a href=\"https://github.com/STEllAR-GROUP/hpx\"\
    >HPX</a>, <a href=\"https://github.com/kokkos/kokkos\">Kokkos</a>, <a href=\"\
    https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>\n</li>\n</ul>\n<p>The\
    \ submodules can be used to obtain the optional dependencies which are required\
    \ for testing the header-only utilities. If these tests are not required, the\
    \ submodule (and the respective buildscripts in /scripts) can be ignored safely.</p>\n\
    <h4><a id=\"user-content-build--install\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#build--install\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Build / Install</h4>\n<ul>\n<li>\n<p>A spack\
    \ package for CPPuddle is available in the <a href=\"https://github.com/G-071/octotiger-spack\"\
    >octotiger-spack repository</a></p>\n</li>\n<li>\n<p>Basic CMake build</p>\n</li>\n\
    </ul>\n<pre><code>  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF\
    \                                                             \n  cmake --build\
    \ /path/to/build --target install  \n</code></pre>\n<p>If installed correctly,\
    \ CPPuddle can be used in other CMake-based projects via</p>\n<pre><code>find_package(CPPuddle\
    \ REQUIRED)\n</code></pre>\n<ul>\n<li>Recommended CMake build:</li>\n</ul>\n<pre><code>\
    \  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle\
    \ -DCPPUDDLE_WITH_HPX=ON -DCPPUDDLE_WITH_HPX_AWARE_ALLOCATORS=ON -DCPPUDDLE_WITH_TESTS=OFF\
    \ -DCPPUDDLE_WITH_COUNTERS=OFF                                               \
    \              \n</code></pre>\n"
  stargazers_count: 7
  subscribers_count: 4
  topics: []
  updated_at: 1704863594.0
SCOREC/centos7-spack-config:
  data_format: 2
  description: spack config for erp cluster
  filenames:
  - v0190_gcc910/spack.yaml
  - v0201_1/spack.yaml
  full_name: SCOREC/centos7-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-centos7-spack-config" class="anchor" aria-hidden="true"
    tabindex="-1" href="#centos7-spack-config"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>centos7-spack-config</h1>

    <p>centos7 spack configuration and scripts</p>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list

    config.yaml - global config

    install.sh - package installation commands

    modules.yaml - hierarchical layout for lua modules

    packages.yaml - system installed packages

    README.md - this file

    setupSpack.sh - env needed for executing spack commands</p>

    '
  stargazers_count: 1
  subscribers_count: 6
  topics: []
  updated_at: 1696768501.0
SCOREC/dcs-spack-config:
  data_format: 2
  description: Spack config for CCI DCS (AiMOS) system
  filenames:
  - spack.yaml
  - rhel8NvhpcWdmapp/spack.yaml
  full_name: SCOREC/dcs-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-dcs-spack-config" class="anchor" aria-hidden="true"
    tabindex="-1" href="#dcs-spack-config"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>dcs-spack-config</h1>

    <p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies

    with the IBM XL compilers and Spectrum-MPI.</p>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list</p>

    <p>config.yaml - global config</p>

    <p>install.sh - package installation commands</p>

    <p>modules.yaml - hierarchical layout for lua modules</p>

    <p>packages.yaml - system installed packages</p>

    <p>README.md - this file</p>

    <p>setupSpack.sh - env needed for executing spack commands</p>

    <p>spack.yaml - list of packages to install</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" tabindex="-1"
    href="#setup"><span aria-hidden="true" class="octicon octicon-link"></span></a>setup</h2>

    <pre><code>git clone git@github.com:spack/spack.git spack

    cd !$

    git checkout v0.13.3

    # add the simmetrix-simmodsuite package from the develop branch

    git cherry-pick 5ddf5e2

    # create the environment

    spack env create v0133

    spack env activate v0133

    # copy the yaml files into the v0133

    cp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.

    # copy the compiler yaml file into the spack etc dir

    cp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.

    </code></pre>

    <h2><a id="user-content-install-cmake" class="anchor" aria-hidden="true" tabindex="-1"
    href="#install-cmake"><span aria-hidden="true" class="octicon octicon-link"></span></a>install
    cmake</h2>

    <p>The bootstrap step of the cmake install fails with the XL compilers.  I

    installed it manually outside of the environment with spack and gcc4.8.5</p>

    <pre><code>spack install cmake%gcc@4.8.5_rhel7

    </code></pre>

    <p>Then added the path to <code>packages.yaml</code>.</p>

    <h2><a id="user-content-resuming-work-in-an-environment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#resuming-work-in-an-environment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>resuming work in an environment</h2>

    <pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh

    spack env activate v0133

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633029356.0
SCOREC/drp-spack-config:
  data_format: 2
  description: CCI DRP Spack configuration
  filenames:
  - openFoam24/spack.yaml
  full_name: SCOREC/drp-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-drp-spack-config" class="anchor" aria-hidden="true"
    tabindex="-1" href="#drp-spack-config"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>drp-spack-config</h1>

    <p>CCI DRP Spack configuration</p>

    <h1><a id="user-content-contents" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>contents</h1>

    <p>openFoam24 - spack environment for an OpenFoam Organization 2.4.0 install</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1593654195.0
SCOREC/pcms:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: SCOREC/pcms
  latest_release: null
  readme: '<h1><a id="user-content-pcms-parallel-coupler-for-multimodel-simulations"
    class="anchor" aria-hidden="true" tabindex="-1" href="#pcms-parallel-coupler-for-multimodel-simulations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>PCMS: Parallel Coupler
    For Multimodel Simulations</h1>

    <p>Adios2-based xgc_coupler for XGC and GENE</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <ul>

    <li>CMake 3.19+</li>

    <li>MPI</li>

    <li>FFTW 3.3.8+</li>

    <li>redev 3.0.0+ (<a href="https://github.com/SCOREC/redev">https://github.com/SCOREC/redev</a>)</li>

    <li>Omega_h 10.2.0+ with MPI enabled (<a href="https://github.com/SCOREC/omega_h">https://github.com/SCOREC/omega_h</a>)</li>

    <li>Catch2 2.* (for unit tests) (<a href="https://github.com/catchorg/Catch2/tree/v2.13.8">https://github.com/catchorg/Catch2/tree/v2.13.8</a>)</li>

    </ul>

    <h2><a id="user-content-build-instructions" class="anchor" aria-hidden="true"
    tabindex="-1" href="#build-instructions"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Build Instructions</h2>

    <h2><a id="user-content-build-with-modules" class="anchor" aria-hidden="true"
    tabindex="-1" href="#build-with-modules"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Build with modules</h2>

    <p>SCOREC Rhel7 environment</p>

    <pre><code>module unuse /opt/scorec/spack/lmod/linux-rhel7-x86_64/Core

    module use /opt/scorec/spack/v0154_2/lmod/linux-rhel7-x86_64/Core

    module load \

    gcc/10.1.0 \

    mpich \

    cmake/3.20.0 \

    fftw \

    gdb

    </code></pre>

    <p>Build, install, and test</p>

    <pre><code>git clone git@github.com:SCOREC/wdmapp_testcases.git #test data

    git clone git@github.com:SCOREC/wdmapp_coupling.git


    cmake -S wdmapp_coupling -B buildWdmCpl \

    -Dredev_ROOT=/path/to/redev/install \

    -DOmega_h_ROOT=/path/to/omegah/install \

    -DCMAKE_INSTALL_PREFIX=$PWD/buildWdmCpl/install \

    -DPCMS_TEST_DATA_DIR=$PWD/wdmapp_testcases \

    -DCatch2_ROOT=/path/to/catch2/install


    cmake --build buildWdmCpl --target install


    ctest --test-dir buildWdmCpl --output-on-failure

    </code></pre>

    <h2><a id="user-content-spack-based-build" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-based-build"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    based build</h2>

    <ol>

    <li>

    <p>Install spack</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">mkdir
    /lore/<span class="pl-smi">$USER</span>/spack</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> /lore/<span class="pl-smi">$USER</span>/spack</span>

    $ <span class="pl-s1">git clone -c feature.manyFiles=true -b releases/v0.20 https://github.com/spack/spack.git</span>

    $ <span class="pl-s1"><span class="pl-c1">.</span> spack/share/spack/setup-env.sh</span></pre></div>

    <p>We can also add the spack setup line into the <code>~/.bashrc</code> with `echo
    ". spack/share/spack/setup-env.sh" &gt;&gt; ~/.bashrc". This will load the spack
    setup script every time we start our terminal session.</p>

    </li>

    <li>

    <p>Get PCMS spack repo

    The following commands will add the pcms recipe files to spack. They are not currently
    installed inthe upstream spack repository.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">git
    clone https://github.com/jacobmerson/pcms-spack.git</span>

    $ <span class="pl-s1">spack repo add pcms-spack/pcms</span></pre></div>

    </li>

    <li>

    <p>Add Spack binary mirror

    Addding the binary mirrors will avoid some compilation by downloading prebuilt
    binaries when available.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">spack
    mirror add v0.20.1 https://binaries.spack.io/v0.20.1</span>

    $ <span class="pl-s1">spack buildcache keys --install --trust</span></pre></div>

    </li>

    <li>

    <p>Install PCMS repo</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">mkdir
    /lore/<span class="pl-smi">$USER</span>/pcms-coupler</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> /lore/<span class="pl-smi">$USER</span>/pcms-coupler</span>

    $ <span class="pl-s1">git clone -b pcms-spack https://github.com/jacobmerson/pcms</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> pcms/spack</span>

    $ <span class="pl-s1">spack env create -d env spack.yaml</span>

    $ <span class="pl-s1"><span class="pl-c1">cd</span> env</span>

    $ <span class="pl-s1">spack env activate <span class="pl-c1">.</span></span>

    $ <span class="pl-s1">spack install</span></pre></div>

    </li>

    </ol>

    <p>At this point hopefully, spack will now install all of the relavant dependencies
    and a baseline build of PCMS. The default environment has PCMS in develop mode.
    To modify and recompile PCMS you can modify the code and rerun <code>spack install</code>.</p>

    <h3><a id="user-content-build-todo" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build-todo"><span aria-hidden="true" class="octicon octicon-link"></span></a>BUILD
    TODO</h3>

    <ul>

    <li>create a spack environment that''s part of this project that can build the
    whole stack.

    most of the pieces are in place for this, but it will require createing a package
    for redev

    and of the SCOREC version of Omega_h

    <ul>

    <li>scorec version 10.1.0 of Omega_h is in spack@develop

    <a href="https://github.com/spack/spack/blob/8ddaa08ed2aacb4b5e587a33c625492cbdd4886e/var/spack/repos/builtin/packages/omega-h/package.py#L21">https://github.com/spack/spack/blob/8ddaa08ed2aacb4b5e587a33c625492cbdd4886e/var/spack/repos/builtin/packages/omega-h/package.py#L21</a>

    </li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 2
  subscribers_count: 19
  topics: []
  updated_at: 1681842553.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.20.1/v1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#rhel7-spack-config\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n\
    <p>rhel7 spack configuration and scripts</p>\n<p>The <code>install.sh</code> script\
    \ maintained in this repo is for documentation purposes (e.g., in case we had\
    \ to reinstall the entire stack from scratch) and should not be executed as it\
    \ will not use all of our existing package installs.  More discussion of package\
    \ installation is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#useful-commands\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>useful commands</h2>\n\
    <p>regenerate lmod module tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n\
    <h2><a id=\"user-content-installing-new-packages\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#installing-new-packages\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>installing new packages</h2>\n\
    <p>Our spack repo is tracking the master spack branch.  Spack package updates\
    \ could result in additional installation of packages with little or no package\
    \ source code changes.  These additional installs can be avoided when installing\
    \ new packages by first examining the output of the <code>spack spec -I</code>\
    \ command.  If a utility/infrastructure level package, such as cmake or mpich,\
    \ is marked with a <code>[+]</code> symbol in the leftmost column then it means\
    \ that the existing install will be used.  If spack does not default to using\
    \ the existing install you can append the hash of the package to the spec command.</p>\n\
    <p>For example, lets see what happens when we ask for a pumi install using gcc\
    \ 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global\
    \ config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical\
    \ layout for lua modules\npackages.yaml - system installed packages\nREADME.md\
    \ - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1683174256.0
ScottWales/spack-environments:
  data_format: 2
  description: null
  filenames:
  - envs/base/spack.yaml
  full_name: ScottWales/spack-environments
  latest_release: null
  readme: "<h1><a id=\"user-content-ngm-spack-environments--containers\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#ngm-spack-environments--containers\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>NGM Spack\
    \ Environments &amp; Containers</h1>\n<h2><a id=\"user-content-repository-layout\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#repository-layout\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repository\
    \ Layout</h2>\n<ul>\n<li>\n<code>bin/</code>: User scripts</li>\n<li>\n<code>ci/</code>:\
    \ CI scripts</li>\n<li>\n<code>config/</code>: Spack config files</li>\n<li>\n\
    <code>containers/</code>: Dockerfiles</li>\n<li>\n<code>envs/</code>: Environments</li>\n\
    <li>\n<code>etc/</code>: Config files and build scripts</li>\n<li>\n<code>repos/</code>:\
    \ Spack Packages</li>\n</ul>\n<h2><a id=\"user-content-using-containers\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#using-containers\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using containers</h2>\n\
    <h3><a id=\"user-content-run-container-on-gadi\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#run-container-on-gadi\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Run container on Gadi</h3>\n<p>Load\
    \ the container module</p>\n<pre><code>module use /scratch/hc46/hc46_gitlab/ngm/modules\n\
    module load lfric-v0/gcc-openmpi\n</code></pre>\n<p>The <code>imagerun</code>\
    \ helper script will run a command in the container</p>\n<pre><code>imagerun unifiedmodel_hofx.x\n\
    </code></pre>\n<p><code>imagerun</code> will also set up bind mode MPI automatically,\
    \ use it inside of <code>mpirun</code></p>\n<pre><code>mpirun -n 4 imagerun unifiedmodel_hofx.x\n\
    </code></pre>\n<h3><a id=\"user-content-run-container-on-a-generic-system\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#run-container-on-a-generic-system\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Run container\
    \ on a generic system</h3>\n<p>Run from a container using Apptainer</p>\n<pre><code>apptainer\
    \ run jopa-intel-openmpi.sif unifiedmodel_hofx.x\n</code></pre>\n<p>Configure\
    \ Bind-mode MPI by mounting your system MPI to /bind/openmpi@4</p>\n<pre><code>mpirun\
    \ -n 4 apptainer run --bind /apps/openmpi/4.1.4:/bind/openmpi@4 \\\n    jopa-intel-openmpi.sif\
    \ unifiedmodel_hofx.x\n</code></pre>\n<h2><a id=\"user-content-installing-on-a-bare-system\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-on-a-bare-system\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ on a bare system</h2>\n<h3><a id=\"user-content-installing-environments-on-nci-gadi\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-environments-on-nci-gadi\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ environments on NCI Gadi</h3>\n<p>To install an environment on Gadi run</p>\n\
    <pre><code>./bin/install_gadi.sh ENV\n</code></pre>\n<p>with ENV the name of a\
    \ directory under <code>envs/</code>.</p>\n<h3><a id=\"user-content-installing-environments-on-aws-ec2\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-environments-on-aws-ec2\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ environments on AWS EC2</h3>\n<p>To install an environment on EC2 run</p>\n\
    <pre><code>./bin/install_aws.sh ENV\n</code></pre>\n<p>The instance should be\
    \ running Amazon Linux. Spack, Mamba and their\ndependencies will be installed\
    \ if not present.</p>\n<h3><a id=\"user-content-installing-environments-on-a-generic-system\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-environments-on-a-generic-system\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ environments on a generic system</h3>\n<p>Installing an environment locally\
    \ requires <code>spack</code> and <code>mamba</code> to be installed\nand active.</p>\n\
    <p>To install an environment run</p>\n<pre><code>./bin/install.sh ENV\n</code></pre>\n\
    <h3><a id=\"user-content-setting-compiler-and-mpi-version\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#setting-compiler-and-mpi-version\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting Compiler and MPI version</h3>\n\
    <p>By default the environment will be built with Spack's defaults for compiler\
    \ and MPI.</p>\n<p>To use a different version set the <code>SPACK_COMPILER</code>\
    \ and <code>SPACK_MPI</code> environment\nvariables, e.g.</p>\n<pre><code>export\
    \ SPACK_COMPILER=intel@2021.8.0\nexport SPACK_MPI=openmpi@4.1.4\n\n./bin/install.sh\
    \ lfric-v0\n</code></pre>\n<p>will install the <code>lfric-v0</code> environment\
    \ with that compiler and MPI.</p>\n"
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1688057708.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/runner/_archived/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/_archived/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu22.04-amd64-oneapi-2024.0.1/spack.yaml
  - docker-recipes/archived/special/superlu-sc/spack.yaml
  - docker-recipes/archived/rhel7-runner-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu20.04-amd64-clang-16/spack.yaml
  - docker-recipes/runner/ubuntu22.04-amd64-oneapi-2024.0.0/spack.yaml
  - docker-recipes/runner/_archived/ubuntu20.04-x86_64-gcc-11.2/spack.yaml
  - docker-recipes/runner/_archived/ubuntu20.04-x86_64-gcc-11.4-spack/spack.yaml
  - docker-recipes/runner/ubuntu22.04-amd64-oneapi-2023.2.1/spack.yaml
  - docker-recipes/runner/_archived/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/alinux2023-arm64-gcc-11.4/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 18
  subscribers_count: 7
  topics: []
  updated_at: 1705236288.0
adamqc/dealii-docker:
  data_format: 2
  description: null
  filenames:
  - complex/spack.yaml
  full_name: adamqc/dealii-docker
  latest_release: null
  readme: '<h1><a id="user-content-dealii-docker-images" class="anchor" aria-hidden="true"
    tabindex="-1" href="#dealii-docker-images"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>deal.II Docker images</h1>

    <p>This repository automatically builds the dealii library every week using GitHub

    Actions. The build is done by using spack, and will result in two Docker images:</p>

    <ul>

    <li>

    <code>adamqc/dealii-real:latest</code>: build with PETSc real numbers</li>

    <li>

    <code>adamqc/dealii-complex:latest</code>: build with PETSc complex numbers</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1695213497.0
ai2cm/fv3net:
  data_format: 2
  description: explore the FV3 data for parameterization
  filenames:
  - docker/ufs_utils/spack.yaml
  full_name: ai2cm/fv3net
  latest_release: release/cyclegan_initial
  readme: '<h1><a id="user-content-fv3net" class="anchor" aria-hidden="true" tabindex="-1"
    href="#fv3net"><span aria-hidden="true" class="octicon octicon-link"></span></a>fv3net</h1>

    <p><a href="https://circleci.com/gh/ai2cm/fv3net/tree/master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/b3e080c75d8b7187fbfaeb6a0e44426f4b4ce818305d3917a4334f4e5970b14c/68747470733a2f2f636972636c6563692e636f6d2f67682f616932636d2f6676336e65742f747265652f6d61737465722e7376673f7374796c653d737667"
    alt="CircleCI" data-canonical-src="https://circleci.com/gh/ai2cm/fv3net/tree/master.svg?style=svg"
    style="max-width: 100%;"></a></p>

    <p>Improving the GFDL FV3 model physics with machine learning. See the <a href="https://vulcanclimatemodeling.com/docs/fv3net/"
    rel="nofollow">documentation</a> for more information on using this suite of tools.</p>

    <p>Disclaimer: This is a work in progress.</p>

    '
  stargazers_count: 15
  subscribers_count: 10
  topics: []
  updated_at: 1707630820.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent8/envs/avx/rproject/spack.yaml
  - cent7/python_376/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1><a id="user-content-spack-environments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>SPACK Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2><a id="user-content-software-deployment-for-centos-8x" class="anchor" aria-hidden="true"
    tabindex="-1" href="#software-deployment-for-centos-8x"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Software deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3><a id="user-content-compilers" class="anchor" aria-hidden="true" tabindex="-1"
    href="#compilers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3><a id="user-content-lu-software" class="anchor" aria-hidden="true" tabindex="-1"
    href="#lu-software"><span aria-hidden="true" class="octicon octicon-link"></span></a>LU
    Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4><a id="user-content-available-environments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#available-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Available Environments</h4>

    <h5><a id="user-content-solhawk" class="anchor" aria-hidden="true" tabindex="-1"
    href="#solhawk"><span aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-avxavx2avx512" class="anchor" aria-hidden="true" tabindex="-1"
    href="#avxavx2avx512"><span aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-python-and-r-packages" class="anchor" aria-hidden="true"
    tabindex="-1" href="#python-and-r-packages"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Python and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-x86_64" class="anchor" aria-hidden="true" tabindex="-1"
    href="#x86_64"><span aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2><a id="user-content-centos-7x-software" class="anchor" aria-hidden="true"
    tabindex="-1" href="#centos-7x-software"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>CentOS 7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657632897.0
aminaramoon/config:
  data_format: 2
  description: null
  filenames:
  - packages/spack.yaml
  full_name: aminaramoon/config
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1673135222.0
boutproject/BOUT-configs:
  data_format: 2
  description: Configuration scripts for BOUT++
  filenames:
  - lassen/spack_env/bout_petsc_with_hypre/spack.yaml
  full_name: boutproject/BOUT-configs
  latest_release: null
  readme: "<h1><a id=\"user-content-configuration-scripts\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#configuration-scripts\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Configuration scripts</h1>\n<p>This\
    \ repo contains scripts to setup the environment and provide build\nconfigurations\
    \ for BOUT++ on deployment machines.</p>\n<p>There is one sub-directory for each\
    \ machine (\"cori\", \"lassen\", \"perlmutter\").\nSee the README of each sub-directory\
    \ for machine specific instructions.</p>\n<p>The repo includes <code>spack</code>\
    \ (release v0.21.1) as a submodule, used to create\nreproducible, self-contained\
    \ environments on different machines.</p>\n<p>\U0001F6A7 This repo is under active\
    \ development, <code>perlmutter</code> configuration\nis in a stable state, other\
    \ machines are under update.\nIssues and PRs to <code>main</code> are welcome.</p>\n\
    <h2><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Usage</h2>\n<p>Clone the repo and initialize submodules</p>\n<pre><code>git\
    \ clone --recurse-submodules https://github.com/boutproject/BOUT-configs.git\n\
    </code></pre>\n<p>Enter the machine sub-directory desired and follow the instructions.\n\
    Typical usage is to <code>source setup-env.sh</code> to activate the spack enviroment,\n\
    which will install any needed software dependencies through <code>spack</code>,\
    \ and\nconfigure BOUT++ using either scripts under the machine's <code>scripts</code>\
    \ directory\nor with the user's own configuration.</p>\n<h2><a id=\"user-content-contact\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contact\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>Feel free to contact Giorgis Georgakoudis <a href=\"mailto:georgakoudis1@llnl.gov\"\
    >georgakoudis1@llnl.gov</a> for comments,\nsuggestions, or questions.</p>\n"
  stargazers_count: 2
  subscribers_count: 19
  topics: []
  updated_at: 1704439098.0
camierjs/okina-jit:
  data_format: 2
  description: null
  filenames:
  - config/docker/spack.yaml
  full_name: camierjs/okina-jit
  latest_release: null
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed\
    \ under the terms of the BSD-3 license. All new contributions\nmust be made under\
    \ this license. See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>\
    \ for\ndetails.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release\
    \ Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1689268998.0
charmoniumQ/wf-reg-test:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: charmoniumQ/wf-reg-test
  latest_release: zenodo-release-1
  readme: "<h1><a id=\"user-content-workflow-registry-tester\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#workflow-registry-tester\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Workflow Registry Tester</h1>\n\
    <p>Software tends to break or \"collapse\" over time, even if it is unchanged,\
    \ due to non-obvious changes in the computational environment.\nCollapse in computational\
    \ experiments undermines long-term credibility and hinders day-to-day operations.\n\
    We propose to create a public dataset of automatically executable computational\
    \ experiments.\nThis data could be used to identify best practices, make continuous\
    \ testing feasible, and repair broken programs.\nThese techniques increase the\
    \ replicability of computational experiments.</p>\n<p>This software collects the\
    \ data for that dataset by attempting to automatically execute computational experiments.\n\
    Conceptually, we intend to collect the following:</p>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">registry</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >registries</span>:\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\"\
    >experiment</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">registry</span>:\n\
    \        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">version</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">experiment</span>:\n \
    \           <span class=\"pl-k\">for</span> <span class=\"pl-s1\">i</span> <span\
    \ class=\"pl-c1\">in</span> <span class=\"pl-en\">range</span>(<span class=\"\
    pl-s1\">num_repetitions</span>):\n                <span class=\"pl-s1\">execution</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-en\">execute</span>(<span class=\"\
    pl-s1\">version</span>)\n                <span class=\"pl-s1\">data</span>.<span\
    \ class=\"pl-en\">append</span>((\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">date</span>,   <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">output</span>,\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">logs</span>,   <span class=\"pl-s1\">execuiton</span>.<span\
    \ class=\"pl-s1\">res_usage</span>,\n                    <span class=\"pl-s1\"\
    >version</span>.<span class=\"pl-s1\">date</span>,     <span class=\"pl-s1\">version</span>.<span\
    \ class=\"pl-s1\">code</span>,\n                    <span class=\"pl-s1\">experiment</span>.<span\
    \ class=\"pl-s1\">name</span>,  <span class=\"pl-s1\">registry</span>.<span class=\"\
    pl-s1\">name</span>,\n                ))</pre></div>\n<h1><a id=\"user-content-raw-data\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#raw-data\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Raw data</h1>\n\
    <p>Human-readable view can be found at: <a href=\"https://htmlpreview.github.io/?https://github.com/charmoniumQ/wf-reg-test/blob/main/data/results.html\"\
    \ rel=\"nofollow\"><code>./data/results.html</code></a></p>\n<p>Machine-readable\
    \ view can be found at: <a href=\"https://github.com/charmoniumQ/wf-reg-test/blob/main/data\"\
    ><code>./data</code></a></p>\n<h1><a id=\"user-content-reproducing\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#reproducing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Reproducing</h1>\n<p>See <a href=\"\
    REPRODUCING.md\"><code>REPRODUCING.md</code></a> for instructions on reproducing\
    \ these results.</p>\n<h1><a id=\"user-content-todo\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#todo\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>TODO</h1>\n<p>See <a href=\"TODO.md\"><code>TODO.md</code></a>\
    \ for instructions on reproducing these results.</p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n\
    <p>See <a href=\"CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions\
    \ on setting up a development environment.</p>\n"
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1685641852.0
chipbuster/ljkdfhsgblkdsjhfglksdjfhg:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: chipbuster/ljkdfhsgblkdsjhfglksdjfhg
  latest_release: null
  readme: "<h1><a id=\"user-content-cmake-template\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#cmake-template\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>CMake-Template</h1>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#usage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <h3><a id=\"user-content-install-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#install-dependencies\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Install dependencies</h3>\n<ul>\n\
    <li>cmake</li>\n<li>make</li>\n<li>llvm</li>\n<li>enzyme</li>\n</ul>\n<p>Using\
    \ spack:</p>\n<pre><code>spack env activate .\nspack install\n</code></pre>\n\
    <p>Using homebrew:</p>\n<pre><code>brew bundle install\n</code></pre>\n<h3><a\
    \ id=\"user-content-configure-and-build\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#configure-and-build\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Configure and build</h3>\n<p>Configure the CMake\
    \ project using the version of Enzyme installed on the system:</p>\n<pre><code>mkdir\
    \ build &amp;&amp; cd build\ncmake ..\nmake\n</code></pre>\n<p>Configure the CMake\
    \ project using a custom Enzyme version:</p>\n<pre><code>mkdir build &amp;&amp;\
    \ cd build\ncmake -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1698092884.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<h1><a id=\"user-content-d-seams\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#d-seams\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>d-SEAMS</h1>\n<p><strong>Deferred Structural Elucidation\
    \ Analysis for Molecular Simulations</strong></p>\n<p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6c587786c40763574c1a811ef06e3c7aa93f0daacec04b672e12243c4b066847/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <h1><a id=\"user-content-citation\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#citation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citation</h1>\n<ul>\n<li>\n<p>This has been published at the <a href=\"\
    https://doi.org/10.1021/acs.jcim.0c00031\" rel=\"nofollow\">Journal of Chemical\
    \ Information and Modeling\n(JCIM)</a></p>\n</li>\n<li>\n<p>You may also read\
    \ <a href=\"https://arxiv.org/abs/1909.09830\" rel=\"nofollow\">the preprint on\
    \ arXiv</a></p>\n</li>\n</ul>\n<p>If you use this software please cite the following:</p>\n\
    <pre><code>Goswami, R., Goswami, A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred\
    \ Structural Elucidation Analysis for Molecular Simulations. Journal of Chemical\
    \ Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n</code></pre>\n\
    <p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<h1><a id=\"\
    user-content-compilation\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\"\
    \ href=\"#compilation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Compilation</h1>\n<p>We use a deterministic build system to generate\
    \ both bug reports and uniform\nusage statistics. This also handles the <code>lua</code>\
    \ scripting engine.</p>\n<p>\\note The lua functions are documented on the <a\
    \ href=\"https://docs.dseams.info/md_markdown_luafunctions\" rel=\"nofollow\"\
    >on the API Docs</a></p>\n<p>We also provide a <code>conda</code> environment\
    \ as a fallback, which is also recommended for MacOS users.</p>\n<h2><a id=\"\
    user-content-build\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build</h2>\n\
    <h3><a id=\"user-content-conda-working-now\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#conda-working-now\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Conda (working now)</h3>\n<p>Although we strongly\
    \ suggest using <code>nix</code>, for MacOS systems, the following\ninstructions\
    \ may be more suitable. We will assume the presence of <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\"\
    \ rel=\"nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-k\">~</span>/seams-core\n\
    micromamba create -f environment.yml\nmicromamba activate dseams\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Now the installation can proceed.</p>\n<p>\\note\
    \ we do not install <code>lua-luafilesystem</code> within the <code>conda</code>\
    \ environment because it is outdated on <code>osx</code></p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>mkdir build\n<span class=\"pl-c1\">cd</span> build\n\
    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span\
    \ class=\"pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake\
    \ install\n<span class=\"pl-smi\">$CONDA_PREFIX</span>/bin/yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<h3><a\
    \ id=\"user-content-spack-not-working-at-the-moment\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#spack-not-working-at-the-moment\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack (not working at the moment)</h3>\n\
    <p>Manually this can be done in a painful way as follows:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack install eigen@3.3.9 lua@5.2\nspack install\
    \ catch2 fmt yaml-cpp openblas boost cmake ninja meson\nspack load catch2 fmt\
    \ yaml-cpp openblas boost cmake ninja meson eigen@3.3.9 lua@5.2\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span\
    \ class=\"pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> After loading the packages</span>\nluarocks install luafilesystem</pre></div>\n\
    <p>Now we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<h3><a id=\"user-content-nix-not-working-at-the-moment\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#nix-not-working-at-the-moment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Nix (not\
    \ working at the moment)</h3>\n<p>Since this project is built with <code>nix</code>,\
    \ we can simply do the following from the\nroot directory (longer method):</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Make sure there are no artifacts</span>\nrm -rf build\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This will take a long time\
    \ the first time as it builds the dependencies</span>\nnix-build <span class=\"\
    pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>A faster method of building the software is by using the <a href=\"https://dseams.cachix.org/\"\
    \ rel=\"nofollow\">cachix binary cache</a> as shown:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install cachix</span>\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Use the binary cache</span>\n\
    cachix use dseams\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with\
    \ the cache than building from scratch</span>\nnix-build <span class=\"pl-c1\"\
    >.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <h3><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Usage</h3>\n<p>Having installed the <code>yodaStruct</code> binary\
    \ and library, we can now use it.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>yodaStruct -c lua_inputs/config.yml</pre></div>\n<p>\\note The paths in\
    \ the <code>.yml</code> should be <strong>relative to the folder from which the\
    \ binary is called</strong>.</p>\n<p>If you're confused about how to handle the\
    \ relative paths, run the command <code>yodaStruct -c lua_inputs/config.yml</code>\
    \ in the top-level directory, and set the paths relative to the top-level directory.\
    \ This is the convention used in the examples as well.</p>\n<h3><a id=\"user-content-language-server-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#language-server-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Language\
    \ Server Support</h3>\n<p>To generate a <code>compile_commands.json</code> file\
    \ for working with a language server\nlike <a href=\"https://github.com/MaskRay/ccls\"\
    >ccls</a> use the following commands:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\n\
    nix-shell --pure\nmkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span\
    \ class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES\
    \ ../\ncp compile_commands.json ../</pre></div>\n<p>Note that there is no need\
    \ to actually compile the project if you simply need to\nget the compiler database\
    \ for the language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<h2><a id=\"user-content-development\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#development\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Development</h2>\n<p>We can simply use the <code>nix</code>\
    \ environment:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> From the project root</span>\n\
    nix-shell --pure</pre></div>\n<h1><a id=\"user-content-running\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#running\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n<p>This is built\
    \ completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install systemwide\n\
    nix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply install the\
    \ software, and ensure that <code>input/</code> is a child directory.</p>\n<pre\
    \ lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<h2><a id=\"user-content-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#tests\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tests</h2>\n\
    <p>Apart from the <a href=\"https://docs.dseams.info/pages.html\" rel=\"nofollow\"\
    >examples</a>, the test-suite\ncan be run with the <code>yodaStruct_test</code>\
    \ binary, which will drop into the\n<code>nix</code> environment before building\
    \ and executing <code>gdb</code>:</p>\n<pre lang=\"{bash}\"><code># Just run this\n\
    ./testBuild.sh\n# At this point the binary and library are copied into the root\n\
    # One might, in a foolhardy attempt, use gdb at this point\n# Here be dragons\
    \ :)\n# USE NIX\n# Anyway\ngdb --args ./yodaStruct -c lua_inputs/config.yml\n\
    # quit gdb with quit\n# Go run the test binary\ncd shellBuild\n./yodaStruct_test\n\
    </code></pre>\n<p>Do note that the regular installation via <code>nix-env</code>\
    \ runs the tests before the installation</p>\n<h1><a id=\"user-content-developer-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#developer-documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developer\
    \ Documentation</h1>\n\n<p>While developing, it is sometimes expedient to update\
    \ the packages used. It is\nthen useful to note that we use <a href=\"https://github.com/nmattia/niv/\"\
    >niv</a> to handle our pinned packages (apart from\nthe ones built from Github).\
    \ Thus, one might need, say:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>niv update nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with\
    \ nix:</p>\n<div class=\"highlight highlight-source-shell\"><pre>nix-build <span\
    \ class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Outputs are in ./result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ If you get a CMake error</span>\nrm -rf build\nnix-store --delete /nix/store/<span\
    \ class=\"pl-smi\">$whatever</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> $whatever is the derivation complaining</span>\nnix-collect-garbage\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> then try again [worst case\
    \ scenario]</span></pre></div>\n<h2><a id=\"user-content-leaks-and-performance\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#leaks-and-performance\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Leaks and\
    \ performance</h2>\n<p>While testing for leaks, use <code>clang</code> (for\n\
    <a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\">AddressSanitizer</a>\n\
    and\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<h1><a id=\"user-content-overview\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#overview\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h1>\n\
    <p>As of Mon Jan 20 15:57:18 2020, the lines of code calculated by\n<a href=\"\
    http://cloc.sourceforge.net/\" rel=\"nofollow\">cloc</a> are as follows:</p>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"\
    ><img src=\"images/cloc-2020-01-20_15-56.png\" alt=\"Cloc Lines\" style=\"max-width:\
    \ 100%;\"></a></p>\n<h1><a id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Contributing</h1>\n<p>Please ensure that all\
    \ contributions are formatted according to the\n<a href=\"./clang-format\">clang-format</a>\
    \ configuration file.</p>\n<p>Specifically, consider using the following:</p>\n\
    <ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\">Sublime\
    \ Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"https://github.com/lassik/emacs-format-all-the-code\"\
    >format-all</a> for Emacs</p>\n</li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\"\
    >vim-clang-format</a> for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <h2><a id=\"user-content-commit-hook\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#commit-hook\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Commit Hook</h2>\n<p>Note that we expect compliance with the <code>clang-format</code>\
    \ as mentioned above, and this may be enforced by using the provided scripts for\
    \ a pre-commit hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<h2><a id=\"user-content-development-builds\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#development-builds\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development\
    \ Builds</h2>\n<p>The general idea is to drop into an interactive shell with the\
    \ dependencies and then use <code>cmake</code> as usual.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>nix-shell --pure --run bash --show-trace --verbose\n\
    <span class=\"pl-c1\">cd</span> build\ncmake .. -DCMAKE_BUILD_TYPE=Debug -DNO_WARN=TRUE\
    \ \\\n -DFIND_EIGEN=TRUE \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n -G <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Ninja<span class=\"pl-pds\">\"\
    </span></span>\nninja\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Test</span>\n\
    <span class=\"pl-c1\">cd</span> ../\nyodaStruct -c lua_inputs/config.yml\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Debug</span>\ngdb --args yodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>To load debugging symbols from the\
    \ shared library, when you are inside <code>gdb</code> (from the top-level directory,\
    \ for instance), use the following command:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>add-symbol-file build/libyodaLib.so</pre></div>\n<p>Then you can set breakpoints\
    \ in the C++ code; for instance:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>b seams_input.cpp:408</pre></div>\n<h1><a id=\"user-content-acknowledgements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#acknowledgements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h1>\n\
    <p>The following tools are used in this project:</p>\n<ul>\n<li>\n<a href=\"https://cmake.org/\"\
    \ rel=\"nofollow\">CMake</a> for compilation (<a href=\"https://github.com/cginternals/cmake-init\"\
    >cmake-init</a> was used as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\"\
    \ rel=\"nofollow\">Clang</a> because it is more descriptive with better tools</li>\n\
    <li>\n<a href=\"https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the\
    \ developer API</li>\n<li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\"\
    \ rel=\"nofollow\">clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"\
    https://github.com/barisione/clang-format-hooks\">clang-format-hooks</a> for <code>git</code>\
    \ hooks to enforce formatting</li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\"\
    \ rel=\"nofollow\">lua</a> for the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\"\
    \ rel=\"nofollow\">yaml</a> for the configuration</li>\n</ul>\n<h2><a id=\"user-content-third-party-libraries\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#third-party-libraries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Third Party\
    \ Libraries</h2>\n<p>The libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n<li>\n<a href=\"https://github.com/renatoGarcia/icecream-cpp\"\
    >icecream-cpp</a> for pretty-printing and debugging</li>\n</ul>\n"
  stargazers_count: 31
  subscribers_count: 5
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1704121445.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - quantum-espresso-amd/spack.yaml
  - hmmer-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<h1><a id="user-content-benchmark-containers" class="anchor" aria-hidden="true"
    tabindex="-1" href="#benchmark-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Benchmark Containers</h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
eflows4hpc/workflow-registry:
  data_format: 2
  description: Registry to store workflow descriptions
  filenames:
  - minimal_workflow/wordcount/spack.yaml
  - kaust/exageostat/spack.yaml
  full_name: eflows4hpc/workflow-registry
  latest_release: 2nd_stack_release
  readme: "<h1><a id=\"user-content-workflow-registry\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#workflow-registry\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Workflow Registry</h1>\n<p>This is\
    \ a repository to store the Workflow descriptions using the eFlows4HPC methodology.\
    \ This description consist of at least the TOSCA description of the worklfow,\
    \ the code of the their different steps and their required software per step.</p>\n\
    <h2><a id=\"user-content-repository-structure\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#repository-structure\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Repository structure</h2>\n<p>Workflow\
    \ descriptions have to be included inside this repository according to the following\
    \ structure.</p>\n<pre><code>workflow-registry\n  |- workflow_1\n  |    |- tosca\n\
    \  |    |    |- types.yml               TOSCA description of the different components\
    \ involved in the workflow\n  |    |       ... \n  |    |- step_1\n  |    |  \
    \  |- spack.yml               Sofware requirements for this workflow step as a\
    \ Spack environment specification \n  |    |    |- src                     PyCOMPSs\
    \ code of the workflow step\n  |    |       ...\n  |    |- step_2\n  |       \
    \  ....\n  |- workflow_2                                \n  |\t...\n\n</code></pre>\n\
    <h2><a id=\"user-content-including-new-workflows\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#including-new-workflows\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Including new Workflows</h2>\n\
    <p>To include new workflows in the repository, first create a new fork of the\
    \ repository and  include a new folder for the workflow with a subfolder for the\
    \ TOSCA description and the different workflow steps. Finally, create a pull request\
    \ with the new workflow description. This pull request will be reviewed and included\
    \ in the repository.</p>\n"
  stargazers_count: 4
  subscribers_count: 11
  topics: []
  updated_at: 1707040007.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - env-bipp-izar/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<h1><a id="user-content-ska-spack-env" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a>ska-spack-env</h1>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
epfl-scitas/spack-sdploy:
  data_format: 2
  description: Toolset to deploy software stacks
  filenames:
  - samples/spack.yaml
  full_name: epfl-scitas/spack-sdploy
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-sdploy\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#spack-sdploy\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>spack-sdploy</h1>\n<p>Spack extension for automatic\
    \ package configuration and deployment.</p>\n<h2><a id=\"user-content-how-to-install\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-to-install\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to install</h2>\n\
    <p>You can try out this Spack extension be executing 4 easy steps:</p>\n<ul>\n\
    <li>Set up and activate a local python environment</li>\n<li>Set up and activate\
    \ <code>spack</code>\n</li>\n<li>Install <code>spack-sdploy</code> dependencies</li>\n\
    <li>Clone and configure spack-sdploy</li>\n</ul>\n<p>This 4 steps are now detailed\
    \ in the next section.</p>\n<h3><a id=\"user-content-step-by-step-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-by-step-installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step-by-step\
    \ installation</h3>\n<p>Just for a matter of completeness, all the steps needed\
    \ get up and running with\nspack-sdploy extension will be covered, which can be\
    \ a bit pedantic.</p>\n<h4><a id=\"user-content-set-up-and-activate-a-local-python-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#set-up-and-activate-a-local-python-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Set up and\
    \ activate a local python environment</h4>\n<p>It is recommended that a Python\
    \ environment be used to support sdploy. This same\nPython can also be used to\
    \ run Spack.</p>\n<pre><code>python3 -m venv &lt;path-to-environment-directory&gt;\n\
    . &lt;path-to-environment-directory&gt;/bin/activate\n</code></pre>\n<p>For more\
    \ information on how to create a virtual environment in Python refer to\nthe PEP\
    \ 405 \u2013 Python Virtual Environments documentation.</p>\n<h4><a id=\"user-content-set-up-and-activate-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#set-up-and-activate-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Set up and\
    \ activate Spack</h4>\n<p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\"\
    \ rel=\"nofollow\">Spack documentation</a>\non how to install Spack. For sake\
    \ of completeness, we copy paste the commands here:</p>\n<pre><code>git clone\
    \ -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n\
    </code></pre>\n<h4><a id=\"user-content-install-spack-sdploy-dependencies\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#install-spack-sdploy-dependencies\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Install\
    \ <code>spack-sdploy</code> dependencies</h4>\n<p>Up to now the only dependency\
    \ of spack-sdploy if jinja2. Once you have activated\nPython environment, you\
    \ can simply use pip to install the packages.</p>\n<pre><code>pip install jinja2\n\
    </code></pre>\n<h4><a id=\"user-content-clone-and-configure-spack-sdploy\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#clone-and-configure-spack-sdploy\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Clone and\
    \ configure spack-sdploy</h4>\n<pre><code>git clone git@github.com:epfl-scitas/spack-sdploy\n\
    </code></pre>\n<p>To activate the spack-sdploy extension you must add it to the\
    \ config.yaml. If\nyou already have another Spack installation and just want to\
    \ try out\nspack-sdploy may very well create a temporary directory to store the\n\
    configuration and then use the SPACK_USER_CONFIG_PATH variable to point this new\n\
    directory.</p>\n<pre><code>mkdir temporary_config\nexport SPACK_USER_CONFIG_PATH=/path/to/temporary_config\n\
    </code></pre>\n<p>and then, inside the temporary_config directory, write a config.yaml\
    \ file with\nthe following contents:</p>\n<pre><code>config:\n  extensions:\n\
    \  - /path/to/spack-sdploy\n</code></pre>\n<p>Be sure you do not change the spack-dploy\
    \ directory. Spack forces the extensions\nto follow strict rules. Please see the\n\
    <a href=\"https://spack.readthedocs.io/en/latest/extensions.html\" rel=\"nofollow\"\
    >Spack Extensions</a>\ndocumentation for more details about this subject. At this\
    \ point you should now\nbe able to call <code>spack -h</code> and see the new\
    \ Spack commands deployed by the\nspack-sdploy extension.</p>\n<h2><a id=\"user-content-how-to-use\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-to-use\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to use</h2>\n\
    <p>At the present time, spack-sdploy will add 2 commands to your already existing\n\
    Spack commands. These commandes are:</p>\n<pre><code>spack write-spack-yaml\n\
    spack write-packages-yaml\n</code></pre>\n<p>In the future we may change the names\
    \ of these commands, but for now lets just\nimagine these are short and easy to\
    \ type commands.</p>\n<p>As you may have guessed it (if you haven't that's ok),\
    \ write-spack-yaml will\nwrite the spack.yaml file and write-packages-yaml will\
    \ write the packages.yaml\nfile. Of course, Spack does not (yet!) guess what you\
    \ may want to install and\nfor that purpose, both these commands will read all\
    \ the specs you want in your\nspack.yaml file by reading another file you have\
    \ previously written and which\nwe call by stack.yaml.</p>\n<p>For the time being,\
    \ spack-sdploy already comes with a dummy stack.yaml so we can\nget started using\
    \ the new commands.</p>\n<h2><a id=\"user-content-write-spack-yaml\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#write-spack-yaml\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>write-spack-yaml</h2>\n\
    <pre><code>spack write-spack-yaml\n</code></pre>\n<h2><a id=\"user-content-write-packages-yaml\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#write-packages-yaml\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>write-packages-yaml</h2>\n\
    <pre><code>spack write-packages-yaml\n</code></pre>\n<h2><a id=\"user-content-write-activate-list\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#write-activate-list\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>write-activate-list</h2>\n\
    <pre><code>spack write-activate-list -p &lt;platform&gt; -s &lt;stack&gt;\n</code></pre>\n\
    <p>Write to file named <code>packages_to_activate</code> list of packages to activate,\
    \ using <code>spack activate &lt;package&gt;</code>. Packages are writen one per\
    \ line.</p>\n<p>Packages to activate can be marked in the stack file in two possible\
    \ ways: by adding the keyword <code>activate: true</code> in the metadata section\
    \ of a list of packages or by adding the keyword <code>activate: true</code> to\
    \ an individual package. Duplicates are removed.</p>\n"
  stargazers_count: 1
  subscribers_count: 8
  topics: []
  updated_at: 1707117642.0
esm-tools/esm_tools:
  data_format: 2
  description: Simple Infrastructure for Earth System Simulations
  filenames:
  - configs/spack_envs/albedo-spack.yaml
  full_name: esm-tools/esm_tools
  latest_release: v6.0.0
  stargazers_count: 22
  subscribers_count: 8
  topics: []
  updated_at: 1705943798.0
eth-cscs/spack-batteries-included:
  data_format: 2
  description: Installing spack without system dependencies
  filenames:
  - build/3_more_tools/spack.yaml
  full_name: eth-cscs/spack-batteries-included
  latest_release: develop
  readme: "<p><a href=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml\"\
    ><img src=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\"\
    \ alt=\"Update spack develop version\" style=\"max-width: 100%;\"></a></p>\n<h1><a\
    \ id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#-spack-with-batteries-included-linuxx86_64\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\U0001F50B\
    \ Spack with batteries included (linux/x86_64)</h1>\n<p><a href=\"https://github.com/spack/spack\"\
    >Spack</a> is a package manager, and package managers should be trivial to install.</p>\n\
    <p>This repo offers a single, static executable for Spack:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">wget -qO\
    \ spack.x https://github.com/eth-cscs/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n\
    $ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x\
    \ install curl tls=mbedtls</span></pre></div>\n<h2><a id=\"user-content-what-version-of-spack-is-shipped\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#what-version-of-spack-is-shipped\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What version\
    \ of Spack is shipped?</h2>\n<p>The URL above gives you a rolling release of Spack's\
    \ develop branch, which is updated\nhourly. The exact commit SHA is included as\
    \ a file and can be retrieved like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"\
    pl-k\">&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints\
    \ the Spack commit sha]</span></pre></div>\n<h2><a id=\"user-content-supported-platforms\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#supported-platforms\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ platforms</h2>\n<ul>\n<li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n\
    <li>Debian 8 and above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and\
    \ above</li>\n<li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for\
    \ Linux 2 with any of the above distro's.</li>\n</ul>\n<p>The system dependencies\
    \ are <code>glibc 2.17</code> and above and optionally the <code>fusermount</code>\n\
    executable. If your system supports rootless containers it likely has <code>fusermount</code>\n\
    installed already!</p>\n<h2><a id=\"user-content-how-does-it-work\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-does-it-work\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How does it work?</h2>\n<p><code>spack.x</code>\
    \ consists of a modified version of the AppImage runtime concatenated\nwith a\
    \ big squashfs file which includes <code>binutils</code>, <code>bzip2</code>,\
    \ <code>clingo</code>, <code>curl</code>,\n<code>file</code>, <code>git</code>,\
    \ <code>gmake</code>, <code>gpg</code>, <code>gzip</code>, <code>openssl</code>,\
    \ <code>patch</code>, <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>,\
    \ <code>tar</code>, <code>unzip</code>, <code>xz</code>, <code>zstd</code> and\
    \ their dependencies.</p>\n<p>When you run <code>spack.x [args]</code> it will\
    \ use <code>fusermount</code> to\nmount this squashfs file in a temporary directory,\
    \ and then execute the\nentrypoint executable <a href=\"build/6_spack/spack\"\
    >spack</a>.</p>\n<p>The <code>spack</code> executable sets some environment variables\
    \ like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code> to the bin and lib\
    \ folders of the squashfs file, and then it\nexecutes <code>python3 spack_src/bin/spack\
    \ [args]</code>.</p>\n<p>When the command is done running, the runtime unmounts\
    \ the squashfs file again.</p>\n<h2><a id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>My system\
    \ doesn't allow me to use <code>fusermount</code>, what now?</h2>\n<p><code>fusermount</code>\
    \ is used to mount a squashfs file included in the binary. If you\ndon't want\
    \ that, you can just extract it:</p>\n<pre><code>$ spack.x --squashfs-extract\n\
    $ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\
    </code></pre>\n<p>but working with the extracted <code>spack</code> folder can\
    \ come with a performance\npenalty on shared filesystems in HPC centers.</p>\n\
    <h2><a id=\"user-content-differences-and-improvements-over-appimage-runtime\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#differences-and-improvements-over-appimage-runtime\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Differences\
    \ and improvements over AppImage runtime</h2>\n<ul>\n<li>spack.x uses <code>zstd</code>\
    \ for faster decompression;</li>\n<li>spack.x itself is an entirely static binary;</li>\n\
    <li>spack.x does not need to dlopen libfuse.so.</li>\n</ul>\n<h2><a id=\"user-content-troubleshooting\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#troubleshooting\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Troubleshooting</h2>\n\
    <p><strong>immutability</strong> The squashfs mountpoint is a readonly folder,\
    \ meaning that\nspack can't write to spack/{var,opt} folders. spack.x is configured\
    \ to use some\nnon-standard directories, see <code>spack.x config blame config</code>\
    \ for details.</p>\n<p>Note, spack.x applies <a href=\"https://github.com/spack/spack/pull/20158/\"\
    >this patch</a>\nto ensure that log files are written to the <code>config:misc_cache</code>\
    \ folder.</p>\n<p><strong>openssl</strong>: By default spack.x uses <code>ca-certificates-mozilla</code>\
    \ for downloading\npackage sources over https. If you somehow need to use system\
    \ certificates,\nset <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAINFO</code>\
    \ or <code>SSL_CERT_FILE</code> and <code>GIT_SSL_CERT</code>.</p>\n<h2><a id=\"\
    user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#can-i-run-spackx-inside-a-container\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Can I run spack.x inside a container?</h2>\n\
    <p>Yes, but please don't! Since <code>fusermount</code> is a setuid binary, you\
    \ will need to\nrun a privileged container, which is never a good idea.</p>\n\
    <p>The recommended way to run spack.x inside a container is to just extract it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >spack.x --squashfs-extract</span>\n$ <span class=\"pl-s1\">./spack/spack --version</span></pre></div>\n\
    <p>If you insist on running spack.x in Docker, this is one way to do it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >sudo docker run --privileged --device /dev/fuse -it -v <span class=\"pl-smi\"\
    >$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n# <span class=\"pl-s1\"\
    >apt update <span class=\"pl-k\">&amp;&amp;</span> apt install fuse <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n# <span\
    \ class=\"pl-s1\">spack.x --version</span></pre></div>\n<h2><a id=\"user-content-running-an-executable-shipped-with-spackx-directly\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#running-an-executable-shipped-with-spackx-directly\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ an executable shipped with spack.x directly</h2>\n<p>If you want to run an executable\
    \ shipped with <code>spack.x</code> directly instead\nof invoking spack (the default\
    \ entrypoint), try this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x which python</span>\n<span\
    \ class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n\
    <hr>\n<h2><a id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#how-do-i-build-spackx-myself\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How do I\
    \ build spack.x myself?</h2>\n<p>Initially you may need docker to get a rootfs\
    \ filesystem for centos 7.</p>\n<p>Building goes like this:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">make rootfs-with-spack</span>\n\
    <span class=\"pl-c1\">make</span></pre></div>\n<p>You'll find the output in</p>\n\
    <pre><code>build/output\n</code></pre>\n"
  stargazers_count: 22
  subscribers_count: 3
  topics:
  - spack
  - squashfs
  - libfuse
  updated_at: 1683613383.0
eth-cscs/spack-stack:
  data_format: 2
  description: fast spack builds on slow filesystem
  filenames:
  - recipe/nvhpc.spack.yaml
  - packages/nvhpc/spack.yaml
  full_name: eth-cscs/spack-stack
  latest_release: null
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1684144105.0
eugeneswalker/exawind-containers:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/exawind-containers
  latest_release: null
  readme: '<h2><a id="user-content-working-with-the-docker-image-ecpe4sexawindlatest"
    class="anchor" aria-hidden="true" tabindex="-1" href="#working-with-the-docker-image-ecpe4sexawindlatest"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Working with the Docker
    image (ecpe4s/exawind:latest)</h2>

    <ol>

    <li>Build the Docker image</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Launch a container from the image</li>

    </ol>

    <pre><code>$&gt; docker run -it --rm ecpe4s/exawind


    root@8df184bdac63:/# which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    root@8df184bdac63:/# which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2><a id="user-content-working-with-the-singularity-image-exawindsif" class="anchor"
    aria-hidden="true" tabindex="-1" href="#working-with-the-singularity-image-exawindsif"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Working with the Singularity
    image (exawind.sif)</h2>

    <ol>

    <li>Build the Docker image:</li>

    </ol>

    <pre><code>$&gt; ./build-docker-image.sh

    </code></pre>

    <ol start="2">

    <li>Save the Docker image as a docker-archive</li>

    </ol>

    <pre><code>$&gt; docker save -o exawind.tar ecpe4s/exawind:latest

    </code></pre>

    <ol start="3">

    <li>Build the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./build-singularity-image.sh

    </code></pre>

    <ol start="4">

    <li>Run the Singularity image:</li>

    </ol>

    <pre><code>$&gt; ./exawind.sif


    Exawind Singularity&gt; which naluX

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX


    Exawind Singularity&gt; which amr_wind

    /opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind

    </code></pre>

    <h2><a id="user-content-run-selected-exawind-regression-tests" class="anchor"
    aria-hidden="true" tabindex="-1" href="#run-selected-exawind-regression-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run Selected ExaWind
    Regression Tests</h2>

    <ol>

    <li>

    <p>Launch a container using either the Docker or Singularity image (see above)</p>

    </li>

    <li>

    <p>Clone this repository in the newly launched container and run the tests (here
    illustrated with Singularity)</p>

    </li>

    </ol>

    <pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers
    ~/exawind-containers

    Exawind Singularity&gt; cd ~/exawind-containers/demo



    Exawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh

    PASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15



    Exawind Singularity&gt; ./run-nalu-wind-tests.sh

    PASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11

    PASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13

    ...



    Exawind Singularity&gt; ./run-amr-wind-tests.sh

    finished abl_bndry_output

    finished abl_godunov

    ...

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1626420401.0
eugeneswalker/llvm-containers:
  data_format: 2
  description: null
  filenames:
  - ppc64le/spack.yaml
  - x86_64/spack.yaml
  full_name: eugeneswalker/llvm-containers
  latest_release: null
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1615486265.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - gnu/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675202595.0
haampie/sirius-appimage:
  data_format: 2
  description: SIRIUS AppImage (using just the bare minimum)
  filenames:
  - libtree/spack.yaml
  full_name: haampie/sirius-appimage
  latest_release: null
  readme: "<h1><a id=\"user-content-creating-an-appimage-from-a-spack-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#creating-an-appimage-from-a-spack-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ an AppImage from a spack environment</h1>\n<p>HPC container runtimes often use\
    \ squashfs as an archive to store an image, which is then mounted on compute nodes\
    \ and made writeable using overlayfs where the top layer is a ramfs. This trick\
    \ gives good performance particularly on shared filesystems, since the squashfs\
    \ file is a single blob on the disk and has good caching behavior.</p>\n<p>However,\
    \ perfect isolation from the host system is not always possible, in particular\
    \ when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into\
    \ the container, and the question is what the point of containers really is if\
    \ they still depend on the host system.</p>\n<p>Instead of using containers, one\
    \ can still deploy applications as a single self-contained blob on the filesystem\
    \ by using the AppImage runtime. The basic idea is to create an executable which\
    \ unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo\
    \ shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\"\
    >SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a>\
    \ and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\"\
    >AppImage runtime</a>.</p>\n<h2><a id=\"user-content-building\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#building\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./build.sh</span></pre></div>\n\
    <h2><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running</h2>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n<span class=\"pl-c1\"\
    >SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git\
    \ hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    <span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\"\
    >build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time\
    \     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI\
    \ ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                 \
    \     : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\
    \n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n\
    <span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"\
    pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n\
    <span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"\
    pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"\
    pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n\
    <span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in\
    \ Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=\
    \   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double}\
    \ default value for APW linearization energies</span>\n<span class=\"pl-c1\">\
    \  --auto_enu allow search of APW linearization energies</span>\n<span class=\"\
    pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\"\
    >  --rel      use scalar-relativistic solver</span></pre></div>\n<h2><a id=\"\
    user-content-running-on-piz-daint\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#running-on-piz-daint\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Running on piz daint</h2>\n<p>For Piz Daint I've modified\
    \ the <code>sirius/spack.yaml</code> a bit so that it links against system libmpi.so\
    \ (<code>^cray-mpich</code> that is):</p>\n<pre><code>daint103 $ ./build.sh\n\
    ...\n\ndaint103 $ du -sh sirius.app # binary size (includes compressed squashfs)\n\
    26M\tsirius.app\n\ndaint103 $ ./sirius.app --appimage-extract # runtime allows\
    \ you to extract\nsquashfs-root/AppRun\nsquashfs-root/usr\nsquashfs-root/usr/bin\n\
    squashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\nsquashfs-root/usr/lib\n\
    squashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\n\
    squashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n\
    ...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\
    \ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf\
    \ # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\n\
    srun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\n\
    input file does not exist\n===========================================================================================================\n\
    \                            #         Total          %   Parent %        Median\
    \           Min           Max\n-----------------------------------------------------------------------------------------------------------\n\
    sirius                      1       2.30 ms     100.00     100.00       2.30 ms\
    \       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms   \
    \   60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize\
    \        1     333.28 us      14.52      14.52     333.28 us     333.28 us   \
    \  333.28 us\n\n===========================================================================================================\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1616508538.0
hipdac-lab/SC23-AMRIC:
  data_format: 2
  description: 'Artifacts of SC''23 paper "AMRIC: A Novel In Situ Lossy Compression
    Framework for Efficient I/O in Adaptive Mesh Refinement Applications"'
  filenames:
  - warpx_directory/WarpX/Docs/spack.yaml
  full_name: hipdac-lab/SC23-AMRIC
  latest_release: v0.1.0
  readme: "<h1><a id=\"user-content-amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>AMRIC: A\
    \ Novel In Situ Lossy Compression Framework for Efficient I/O in Adaptive Mesh\
    \ Refinement Applications</h1>\n<p><a href=\"https://zenodo.org/badge/latestdoi/658166802\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d0d2e976dd91e413f1525d14e8ca69f13f70ff17c5c7e104fd4bff574a3cd689/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3635383136363830322e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/658166802.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>AMRIC is a novel in-situ lossy compression framework\
    \ that leverages the HDF5 filter to enhance both I/O efficiency and compression\
    \ quality for Adaptive Mesh Refinement (AMR) applications. AMRIC was integrated\
    \ into the <a href=\"https://amrex-codes.github.io/amrex/\" rel=\"nofollow\">AMReX</a>\
    \ framework and evaluated on two real-world AMR applications, Nyx and WarpX.</p>\n\
    <p>While preparing the artifacts, we executed them on a single node from the Chameleon\
    \ Cloud, equipped with two Intel Xeon Gold 6242 CPUs and 192 GB of memory (specifically,\
    \ <code>compute_skylake</code> configuration). We recommend that reviewers also\
    \ use the Chameleon Cloud for artifact evaluation.</p>\n<h2><a id=\"user-content-method-1-use-singularity-image-recommended\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#method-1-use-singularity-image-recommended\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Method 1:\
    \ Use Singularity Image (Recommended)</h2>\n<p>The entire workflow takes approximately\
    \ 10 minutes to execute, including downloading container image and preparing environment\
    \ (3 mins), running WarpX simulation (3 mins), running Nyx simulation (3 mins),\
    \ and evaluating compression performance (1 min).</p>\n<h3><a id=\"user-content-minimum-system-requirements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#minimum-system-requirements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimum\
    \ system requirements</h3>\n<p>OS: Ubuntu (20.04 is recommended)</p>\n<p>Memory:\
    \ &gt;= 16 GB RAM</p>\n<p>Processor: &gt;= 8 cores</p>\n<p>Storage: &gt;= 32 GBs</p>\n\
    <h3><a id=\"user-content-step-1-install-singularity\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-1-install-singularity\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 1: Install Singularity</h3>\n\
    <p>Install <a href=\"https://singularity-tutorial.github.io/01-installation/\"\
    \ rel=\"nofollow\">Singularity</a></p>\n<h3><a id=\"user-content-step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-2-download-the-pre-built-singularity-image-file-via-gdown\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 2:\
    \ Download the pre-built Singularity image file via gdown</h3>\n<p>Press Enter\
    \ after finishing.</p>\n<pre><code>sudo pip3 install gdown\ngdown https://drive.google.com/uc?id=14v_xUmET-HvCFO3LqmD4sNJL65jBcd0L&amp;export=download\n\
    </code></pre>\n<p>or via GitHub</p>\n<pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC-Image.git\n\
    cat SC23-AMRIC-Image/img/amric.sif-* &gt; amric.sif\n</code></pre>\n<h3><a id=\"\
    user-content-step-3-build-and-run-the-image-file-need-root-privilege\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-3-build-and-run-the-image-file-need-root-privilege\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 3:\
    \ Build and run the image file (need root privilege)</h3>\n<pre><code>sudo singularity\
    \ build --sandbox artiAmr amric.sif\nsudo singularity shell --writable artiAmr\n\
    </code></pre>\n<h3><a id=\"user-content-step-4-set-up-environmental-variables\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-4-set-up-environmental-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 4:\
    \ Set up environmental variables</h3>\n<pre><code>export OMPI_DIR=/opt/ompi \n\
    export OMPI_VERSION=4.1.1\nexport PATH=$OMPI_DIR/bin:$PATH\nexport LD_LIBRARY_PATH=$OMPI_DIR/lib:$LD_LIBRARY_PATH\n\
    export MANPATH=$OMPI_DIR/share/man:$MANPATH\nexport C_INCLUDE_PATH=/opt/ompi/include:$C_INCLUDE_PATH\n\
    export CPLUS_INCLUDE_PATH=/opt/ompi/include:$CPLUS_INCLUDE_PATH\nexport OMPI_ALLOW_RUN_AS_ROOT=1\n\
    export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1\n</code></pre>\n<h3><a id=\"user-content-step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 5:\
    \ Run WarpX simulation with no compression, AMReX's original compression, and\
    \ AMRIC</h3>\n<pre><code>cd /home/wpx256/\n. bash.sh\n</code></pre>\n<h3><a id=\"\
    user-content-step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 6:\
    \ Run NYX simulation with no compression, AMReX's original compression, and AMRIC</h3>\n\
    <pre><code>cd /home/nyx128/\n. bash.sh\n</code></pre>\n<h3><a id=\"user-content-step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 7:\
    \ Evaluate WarpX's data quality and compression ratio for original AMReX compression\
    \ and our AMRIC</h3>\n<pre><code>cd /home/wpx256/diags/\n. decomp.sh &gt; temp.txt\n\
    . qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 8:\
    \ Evaluate NYX's data quality and compression ratio for original AMReX compression\
    \ and our AMRIC</h3>\n<pre><code>cd /home/nyx128/run/\n. decomp.sh &gt; temp.txt\n\
    . qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 9:\
    \ Compare I/O perf for baselines (i.e., no compression and ori AMReX compression)\
    \ and AMRIC in WarpX</h3>\n<pre><code>cd /home/wpx256/otfile/\n. io.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 10:\
    \ Compare I/O performance between baselines and AMRIC in NYX</h3>\n<pre><code>cd\
    \ /home/nyx128/otfile/\n. io.sh\n</code></pre>\n<h2><a id=\"user-content-method-2-build-from-source\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#method-2-build-from-source\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Method 2:\
    \ Build From Source</h2>\n<h3><a id=\"user-content-minimum-system--software-libraries-requirements\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#minimum-system--software-libraries-requirements\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimum\
    \ system &amp; software libraries requirements</h3>\n<p>OS: Linux (Ubuntu is recommended)</p>\n\
    <p>Memory: &gt;= 16 GB RAM</p>\n<p>Processor: &gt;= 8 cores</p>\n<p>gcc/9.4.0\
    \ (or 9.3.0)</p>\n<p>cmake (&gt;= 3.23)</p>\n<p>OpenMPI/4.1.1 (install scripts\
    \ provided, or spectrum-mpi)</p>\n<p>python/3.8</p>\n<p>hdf5/1.12.2 (install scripts\
    \ provided)</p>\n<h3><a id=\"user-content-step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 1:\
    \ Download AMRIC, checkpoint files, and set up environmental variables (2 mins)</h3>\n\
    <pre><code>git clone https://github.com/hipdac-lab/SC23-AMRIC.git\ncd SC23-AMRIC\n\
    export AMRIC_HOME=$(pwd)\necho \"# start of AMRIC env\" &gt;&gt; ~/.bashrc\necho\
    \ export AMRIC_HOME=$(pwd) &gt;&gt; ~/.bashrc\n</code></pre>\n<h3><a id=\"user-content-step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 2:\
    \ Load or install CMake and numpy. For example, in Ubuntu</h3>\n<pre><code>pip3\
    \ install numpy\nsudo snap install cmake --classic\n</code></pre>\n<h3><a id=\"\
    user-content-step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 3:\
    \ Load or install OpenMPI. For example, in Ubuntu (7 mins)</h3>\n<pre><code>sudo\
    \ bash openmpi.sh \n. mpi_env.sh\n</code></pre>\n<h3><a id=\"user-content-step-4-download-and-install-the-hdf5-library-4-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-4-download-and-install-the-hdf5-library-4-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 4:\
    \ Download and install the HDF5 library (4 mins)</h3>\n<pre><code>. hdf5.sh\n\
    </code></pre>\n<h3><a id=\"user-content-step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 5:\
    \ Install optimized SZ3 compressor and H5Z-SZ3 compression filter (5 mins)</h3>\n\
    <pre><code>. compressor.sh\n</code></pre>\n<h3><a id=\"user-content-step-6-install-amrex-and-nyx-with-amric-8-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-6-install-amrex-and-nyx-with-amric-8-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 6:\
    \ Install AMReX and Nyx with AMRIC (8 mins)</h3>\n<pre><code>. nyx.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-7-install-warpx-with-amric-9-mins\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-7-install-warpx-with-amric-9-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 7:\
    \ Install WarpX with AMRIC (9 mins)</h3>\n<pre><code>. warpx.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-8-download-qcat-compression-analysis-tool-1-min\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-8-download-qcat-compression-analysis-tool-1-min\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 8:\
    \ Download qcat (compression analysis tool, 1 min)</h3>\n<pre><code>. qcat.sh\n\
    </code></pre>\n<h3><a id=\"user-content-step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 9:\
    \ Run WarpX with no compression, AMReX\u2019s original compression, and AMRIC\
    \ (3 mins)</h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX\n. runwarpx.sh\n\
    </code></pre>\n<h3><a id=\"user-content-step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 10:\
    \ Run NYX with no compression, AMReX\u2019s original compression, and AMRIC (3\
    \ mins).</h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density\n. runnyx.sh\n</code></pre>\n\
    <h3><a id=\"user-content-step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 11:\
    \ Evaluate WarpX\u2019s data quality and compression ratio for original AMReX\
    \ compression and our AMRIC.</h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/diags\n\
    cp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des-w .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss-w\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack-w .\ncp $AMRIC_HOME/qcat/install/bin/compareData\
    \ .\n. decomp.sh &gt; out.txt\n. qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 12:\
    \ Evaluate NYX\u2019s data quality and compression ratio for original AMReX compression\
    \ and our AMRIC.</h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/run\ncp\
    \ $AMRIC_HOME/qcat/install/bin/compareData .\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des\
    \ .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack\
    \ .\n. decomp.sh &gt; out.txt\n. qualityCR.sh\n</code></pre>\n<h3><a id=\"user-content-step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 13:\
    \ Compare I/O performance between baselines (i.e., no compression and ori AMReX\
    \ compression) and AMRIC in WarpX.</h3>\n<pre><code>cd $AMRIC_HOME/warpx_directory/WarpX/otfile\n\
    . io.sh\n</code></pre>\n<h3><a id=\"user-content-step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 14:\
    \ Compare I/O performance between baselines (i.e., no compression and ori AMReX\
    \ compression) and AMRIC in Nyx.</h3>\n<pre><code>cd $AMRIC_HOME/Nyx/Exec/AMR-density/otfile\n\
    . io.sh\n</code></pre>\n<h2><a id=\"user-content-expected-evaluation-results\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#expected-evaluation-results\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Expected\
    \ Evaluation Results</h2>\n<h3><a id=\"user-content-the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for WarpX\u2019s data quality and compression ratio (method 1 step 6)\
    \ are:</h3>\n<pre><code>----- Data Quality for original AMReX Compression -----\n\
    PSNR = 58.600102\n---------- Data Quality for AMRIC-SZ-L/R ----------\nPSNR =\
    \ 61.749515\n---------- Data Quality for AMRIC-SZInterp ----------\nPSNR = 59.146966\n\
    ---------- CR for original AMReX Compression ----------\nCR is: 14.62\n----------\
    \ CR for AMRIC-SZ-L/R ----------\nCR is: 108.94\n---------- CR for AMRIC-SZInterp\
    \ ----------\nCR is: 131.41\n</code></pre>\n<h3><a id=\"user-content-the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for Nyx\u2019s data quality and compression ratio (method 1 step 7)\
    \ are:</h3>\n<pre><code>----- Data Quality for original AMReX Compression -----\n\
    PSNR = 61.977332\n---------- Data Quality for AMRIC-SZ_L/R ----------\nPSNR =\
    \ 66.650492\n---------- Data Quality for AMRIC-SZInterp ----------\nPSNR = 66.566370\n\
    ---------- CR for original AMReX Compression ----------\nCR is: 6.53\n----------\
    \ CR for AMRIC-SZ_L/R ----------\nCR is: 13.08\n---------- CR for AMRIC-SZInterp\
    \ ----------\nCR is: 11.25\n</code></pre>\n<h3><a id=\"user-content-the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for WarpX\u2019s I/O performance  (method 1 step 8) are:</h3>\n<pre><code>----------\
    \ Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression\
    \ Total time = 1.514 seconds\nNo Compression Preprocess time = 0.216 seconds\n\
    No Compression writing time = 1.322 seconds\n...\n------------------------ END\
    \ ------------------------\n------ Writing Time for original AMReX Compression\
    \ ------\n***** run 0 *****\noriginal AMReX Total time = 4.734 seconds\noriginal\
    \ AMReX Preprocess time = 0.189 seconds\noriginal AMReX Writing+Compression time\
    \ = 4.493 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 1.115 seconds\nAMRIC-SZ_L/R Preprocess time = 0.223 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.906 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 1.878 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.950 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.937 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n<h3><a id=\"user-content-the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The expected\
    \ results for Nyx\u2019s I/O performance  (method 1 step 9) are:</h3>\n<pre><code>----------\
    \ Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression\
    \ Total time = 0.195 seconds\nNo Compression Preprocess time = 0.016 seconds\n\
    No Compression writing time = 0.177 seconds\n...\n------------------------ END\
    \ ------------------------\n----- Writing Time for original AMReX Compression\
    \ -----\n***** run 0 *****\noriginal AMReX Total time = 0.674 seconds\noriginal\
    \ AMReX Preprocess time = 0.020 seconds\noriginal AMReX Writing+Compression time\
    \ = 0.649 seconds\n...\n------------------------ END ------------------------\n\
    ---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R\
    \ Total time = 0.182 seconds\nAMRIC-SZ_L/R Preprocess time = 0.018 seconds\nAMRIC-SZ_L/R\
    \ Writing+Compression time = 0.155 seconds\n...\n------------------------ END\
    \ ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n\
    ***** run 0 *****\nAMRIC-SZ_Interp Total time = 0.230 seconds\nAMRIC-SZ_Interp\
    \ Preprocess time = 0.102 seconds\nAMRIC-SZ_Interp Writing+Compression time =\
    \ 0.122 seconds\n...\n------------------------ END ------------------------\n\
    </code></pre>\n"
  stargazers_count: 3
  subscribers_count: 2
  topics: []
  updated_at: 1699637463.0
hpc/mpifileutils:
  data_format: 2
  description: File utilities designed for scalability and performance.
  filenames:
  - spack.yaml
  full_name: hpc/mpifileutils
  latest_release: v0.11.1
  readme: '<h1><a id="user-content-mpifileutils" class="anchor" aria-hidden="true"
    tabindex="-1" href="#mpifileutils"><span aria-hidden="true" class="octicon octicon-link"></span></a>mpiFileUtils</h1>

    <p>mpiFileUtils provides both a library called <a href="src/common/README.md">libmfu</a>
    and a suite of MPI-based tools to manage large datasets, which may vary from large
    directory trees to large files. High-performance computing users often generate
    large datasets with parallel applications that run with many processes (millions
    in some cases). However those users are then stuck with single-process tools like
    cp and rm to manage their datasets. This suite provides MPI-based tools to handle
    typical jobs like copy, remove, and compare for such datasets, providing speedups
    of up to 20-30x.  It also provides a library that simplifies the creation of new
    tools or can be used in applications.</p>

    <p>Documentation is available on <a href="http://mpifileutils.readthedocs.io"
    rel="nofollow">ReadTheDocs</a>.</p>

    <h2><a id="user-content-daos-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#daos-support"><span aria-hidden="true" class="octicon octicon-link"></span></a>DAOS
    Support</h2>

    <p>mpiFileUtils supports a DAOS backend for dcp, dsync, and dcmp. Custom serialization
    and deserialization for DAOS containers to and from a POSIX filesystem is provided
    with daos-serialize and daos-deserialize. Details and usage examples are provided
    in <a href="DAOS-Support.md">DAOS Support</a>.</p>

    <h2><a id="user-content-contributors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributors</h2>

    <p>We welcome contributions to the project.  For details on how to help, see our
    <a href="CONTRIBUTING.md">Contributor Guide</a></p>

    <h3><a id="user-content-copyrights" class="anchor" aria-hidden="true" tabindex="-1"
    href="#copyrights"><span aria-hidden="true" class="octicon octicon-link"></span></a>Copyrights</h3>

    <p>Copyright (c) 2013-2015, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory

    CODE-673838</p>

    <p>Copyright (c) 2006-2007,2011-2015, Los Alamos National Security, LLC.

    (LA-CC-06-077, LA-CC-10-066, LA-CC-14-046)</p>

    <p>Copyright (2013-2015) UT-Battelle, LLC under Contract No.

    DE-AC05-00OR22725 with the Department of Energy.</p>

    <p>Copyright (c) 2015, DataDirect Networks, Inc.</p>

    <p>All rights reserved.</p>

    <h2><a id="user-content-build-status" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build-status"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Status</h2>

    <p>The current status of the mpiFileUtils master branch is <a href="https://travis-ci.org/hpc/mpifileutils"
    rel="nofollow"><img src="https://camo.githubusercontent.com/1f9278aff5e30f0b4fc00de0ccf20f2b185b1f9cf95e3a80d204210a1d62ee41/68747470733a2f2f7472617669732d63692e6f72672f6870632f6d706966696c657574696c732e706e673f6272616e63683d6d6173746572"
    alt="Build Status" data-canonical-src="https://travis-ci.org/hpc/mpifileutils.png?branch=master"
    style="max-width: 100%;"></a>.</p>

    '
  stargazers_count: 155
  subscribers_count: 29
  topics: []
  updated_at: 1706054395.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/5819b92f1cc8b5c1ad3c32b04e570ab6fcd993dc8388e1821fb2d601ee2c653f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/f944e4986dcda6a59f77a14d6f503238e4811f8c4bfef8479068d13873036548/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <h2><a id="user-content-available-modules" class="anchor" aria-hidden="true" tabindex="-1"
    href="#available-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    modules</h2>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>ReconX</code> - provider of different reconstruction schemes</li>

    <li>

    <code>TOVSolverX</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    started</h2>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    <h2><a id="user-content-related-talks-and-tutorials" class="anchor" aria-hidden="true"
    tabindex="-1" href="#related-talks-and-tutorials"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Related talks and tutorials</h2>

    <ul>

    <li>"<a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html" rel="nofollow">Using
    CarpetX: A Guide for Early Adopters</a>".

    Recorded seminar talk by Erik Schnetter, providing an overview of the current
    capabilities of CarpetX.</li>

    <li>"<a href="https://einsteintoolkit.github.io/et2022uidaho/lectures/38-Tutorial8/index.html"
    rel="nofollow">Tutorial: GPUs and the Einstein Toolkit</a>".

    Recorded tutorial by Lorenzo Ennoggi, Jay Kalinani and Federico Lopez Armengol
    during the North American Einstein Toolkit workshop 2022, presenting a brief overview
    on AsterX, followed by a hands-on session.</li>

    <li>"<a href="https://drive.google.com/file/d/1Z4i--W56mxeNIu598LQTpEEowX56FOoD/view?usp=sharing"
    rel="nofollow">AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes</a>".

    Slides based on the talk by Jay Kalinani at the APS April Meeting 2023.</li>

    </ul>

    '
  stargazers_count: 17
  subscribers_count: 11
  topics: []
  updated_at: 1698593900.0
jedwards4b/spackenvironments:
  data_format: 2
  description: my spack environments for software builds
  filenames:
  - esmfserialbld/spack.yaml
  - esmfbld/spack.yaml
  full_name: jedwards4b/spackenvironments
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664981968.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - anl/polaris/polaris.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1658934301.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/rhodes/utilities/spack.yaml
  - configs/rhodes/compilers/spack.yaml
  - configs/eagle/compilers/spack.yaml
  - configs/eagle/software/spack.yaml
  - envs/exawind/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" aria-hidden="true" tabindex="-1" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666717629.0
js947/spack-docker-test:
  data_format: 2
  description: testing spack's containerize command
  filenames:
  - spack.yaml
  full_name: js947/spack-docker-test
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"><img
    src="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"
    alt="Build container" style="max-width: 100%;"></a></p>

    <h1><a id="user-content-spack-docker-test" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-docker-test"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-docker-test</h1>

    <p>testing spack''s containerize command</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1606954982.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-nightly-clang/spack.yaml
  - environments/key4hep-ci/spack.yaml
  - environments/key4hep-release/spack.yaml
  - environments/key4hep-nightly-debug/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" tabindex="-1" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software.</p>

    <p>Consult the the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep documentation
    website</a> and the

    <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack documentation</a>
    for more details.</p>

    <h2><a id="user-content-spack-versions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-versions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Versions</h2>

    <p>The spack recipes in this repository should work with any version of spack
    (0.19

    is known to work and it''s possible older versions work too, newer than 0.19

    works). Some of the environments require spack 0.20 or newer since they use (or

    they include a file that uses) the <code>require</code> keyword which was introduced
    in

    <a href="https://github.com/spack/spack/releases/tag/v0.20.0">spack 0.20</a>.</p>

    <h2><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    tabindex="-1" href="#repository-contents"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Repository Contents</h2>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the

    repository contains a collection of environments used to build the stack in

    <code>environments</code> and some scripts used for publishing on cvmfs and other
    utilities

    in <code>scripts</code>. The builds run in Gitlab CI runners and the workflows
    can be found

    in the file <code>.gitlab-ci.yml</code> in the <a href="https://gitlab.cern.ch/key4hep/k4-deploy"
    rel="nofollow">gitlab

    repository</a>.</p>

    <p>Additionally, the file <code>.latest-commit</code> contains the latest commit
    of Spack used

    for the recent builds, which is updated from time to time to keep up with the

    develop branch of Spack.</p>

    <h2><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    tabindex="-1" href="#central-installations"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Central Installations</h2>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org</code>
    (for

    CentOS 7) and <code>/cvmfs/sw-nightlies.hsf.org</code> (for CentOS 7, AlmaLinux
    9 and

    Ubuntu) see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    <h2><a id="user-content-requirements" class="anchor" aria-hidden="true" tabindex="-1"
    href="#requirements"><span aria-hidden="true" class="octicon octicon-link"></span></a>Requirements</h2>

    <p>To compile the key4hep stack some system packages are required; without these,

    the spack concretization or compilation can fail. The packages needed are an

    OpenGL implementation that can be installed:</p>

    <div class="highlight highlight-source-shell"><pre>yum install -y mesa-libGL mesa-libGL-devel
    mesa-libGLU mesa-libGLU-devel      <span class="pl-c"><span class="pl-c">#</span>
    Centos 7</span>

    apt install -y libgl1-mesa-glx libgl1-mesa-dev libglu1-mesa libglu1-mesa-dev  <span
    class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    dnf install -y mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel      <span
    class="pl-c"><span class="pl-c">#</span> AlmaLinux 9</span></pre></div>

    <p>The environments that make use of these libraries or headers expect them to
    be

    found under <code>/usr</code>, which is the typical location when they are installed

    system-wide (for example in <code>/usr/include</code> or <code>/usr/lib</code>).</p>

    <p>Alternatively, one can install

    <a href="https://gitlab.cern.ch/linuxsupport/rpms/HEP_OSlibs" rel="nofollow">HEP_OSlibs</a>,
    which will

    install the previous and more libraries.</p>

    <p>In addition, for Ubuntu and Alma 9 the compilers are picked up from the system,

    so, for example, building in an image without <code>gcc</code> or <code>glibc</code>
    won''t work. These

    commands should install most of the compilers and the development tools:</p>

    <div class="highlight highlight-source-shell"><pre>apt install -y build-essential
    gfortran                            <span class="pl-c"><span class="pl-c">#</span>
    Ubuntu</span>

    dnf groupinstall -y <span class="pl-s"><span class="pl-pds">"</span>Development
    Tools<span class="pl-pds">"</span></span> <span class="pl-k">&amp;&amp;</span>
    dnf install -y gfortran <span class="pl-c"><span class="pl-c">#</span> AlmaLinux
    9</span></pre></div>

    <p>Dockerfiles with the images that are used to build the key4hep stack can be

    found in <a href="https://github.com/key4hep/key4hep-images">https://github.com/key4hep/key4hep-images</a>.</p>

    '
  stargazers_count: 8
  subscribers_count: 10
  topics: []
  updated_at: 1682439760.0
lanl/CELLAR:
  data_format: 2
  description: The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based
    adaptive mesh refinement data structures and execution for parallel computing
    architectures.
  filenames:
  - spack/snow/spack.yaml
  - spack/ci/spack.yaml
  - spack/darwin-power9/spack.yaml
  full_name: lanl/CELLAR
  latest_release: null
  readme: '<h1><a id="user-content-cellar-----eap-core" class="anchor" aria-hidden="true"
    tabindex="-1" href="#cellar-----eap-core"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>CELLAR  -  EAP Core</h1>

    <p>CELLAR is a C++ project that forms the foundation of cell based AMR for applications</p>

    <p>It provides the following:</p>

    <ul>

    <li>AMR Mesh Datastructure</li>

    <li>AMR Mesh Reconstruction</li>

    <li>Communication Patterns</li>

    <li>C++ Error Handling and Tracing</li>

    <li>Performance Monitoring</li>

    <li>C++/Fortran Interop</li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" tabindex="-1"
    href="#building"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>The easiest way to install dependencies is using <a href="https://spack.io"
    rel="nofollow">Spack</a>.

    After

    <a href="https://spack.readthedocs.io/en/latest/getting_started.html" rel="nofollow">installing
    Spack</a>,

    you can start build dependencies.</p>

    <p>The following instructions assume that you have Spack 0.13 or newer. You can
    check your

    Spack version like so:</p>

    <pre><code>$ spack --version

    0.13.0

    </code></pre>

    <p>First, add <a href="https://github.com/lanl/cellar-spack">lanl/cellar-spack</a>

    to your list of spack repos.</p>

    <p>Once you have the <code>lanl/cellar-spack</code> installed, then you can install
    all

    dependencies using

    <a href="https://spack.readthedocs.io/en/latest/tutorial_environments.html#" rel="nofollow">Spack
    environments</a>.

    You''ll need to use a modern-ish C++ compiler that supports C++14:</p>

    <pre><code>$ module load gcc/9.3.0

    $ spack compiler find

    $ cd path/to/eap-core

    </code></pre>

    <p>Then issue the following commands. This will build all of eap-core''s dependencies.:</p>

    <pre><code>$ spack env create -d spack/default

    $ spack env activate -d $PWD/spack/default

    $ spack install

    </code></pre>

    <p>Any time you open a new shell, you''ll need to re-activate the Spack environment:</p>

    <pre><code>$ spack env activate -d $PWD/spack/default

    </code></pre>

    <p>Now you''re ready to build eap-core. First configure the project using CMake:</p>

    <pre><code>mkdir build &amp;&amp; cd build

    cmake ..

    </code></pre>

    <p>And then build:</p>

    <pre><code>make -j

    </code></pre>

    <p>For snow, substitute in spack/snow in the above instructions in place of spack/default.
    If you need

    to change the environment use "spack env deactivate".</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Code contributors should read the <a href="DEVELOPERS.md">Developers Guide</a>
    prior to

    sending a pull request.</p>

    '
  stargazers_count: 3
  subscribers_count: 7
  topics: []
  updated_at: 1694614627.0
lanl/SICM:
  data_format: 2
  description: Simplified Interface to Complex Memory
  filenames:
  - spack.yaml
  full_name: lanl/SICM
  latest_release: null
  readme: '<h1><a id="user-content-sicm" class="anchor" aria-hidden="true" tabindex="-1"
    href="#sicm"><span aria-hidden="true" class="octicon octicon-link"></span></a>SICM</h1>

    <p>Simplified Interface to Complex Memory</p>

    <p><a href="https://github.com/lanl/SICM/actions"><img src="https://github.com/lanl/SICM/actions/workflows/sicm.yml/badge.svg"
    alt="GitHub Actions" style="max-width: 100%;"></a></p>

    <h2><a id="user-content-introduction" class="anchor" aria-hidden="true" tabindex="-1"
    href="#introduction"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

    <p>This project is split into two interfaces: <code>low</code> and <code>high</code>.</p>

    <p>The <code>low</code> interface provides a minimal interface for application
    wanting to

    manage their own memory on heterogeneous memory tiers. It also provides an

    arena allocator that application developers can use to create <code>jemalloc</code>
    arenas

    on different memory tiers and allocate to those tiers.</p>

    <p>The <code>high</code> interface attempts to automatically manage the memory
    tiers for the

    application. It provides an LLVM compiler pass (and compiler wrappers) to

    automatically transform applications to make the appropriate <code>high</code>
    interface

    calls, as well as a runtime library which provides profiling for the

    application.  The profiling is currently meant to be used offline; that is,

    after enabling the profiling for an application run, the results are printed

    out at the end of the run, and that information must be fed into a second run

    to make use of it. An online approach is planned.</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>The only dependencies that you will need for the low-level interface

    are <code>libnuma</code> and <code>jemalloc</code>. We require that <code>jemalloc</code>
    be

    configured with the <code>je_</code> prefix (using the <code>--with-jemalloc-prefix</code>
    flag).

    <code>CMake</code> will use <code>pkg-config</code> to find <code>jemalloc</code>.</p>

    <p>For the high-level interface, you need an installation of LLVM. LLVM 4.0 and

    later have been tested, although 3.9 may possibly work. For the profiling, you

    will also need an installation of <code>libpfm</code>, which is a small helper
    library for

    <code>perf</code> that is available on most distributions.</p>

    <p>Additionally, several other packages are required, and can be installed through
    a package manager:</p>

    <h3><a id="user-content-binaries" class="anchor" aria-hidden="true" tabindex="-1"
    href="#binaries"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binaries</h3>

    <ul>

    <li>A modern C compiler</li>

    <li>A modern C++ compiler</li>

    <li>A modern Fortran compiler</li>

    <li>CMake 3.0+</li>

    <li>Make</li>

    <li>numactl</li>

    <li>automake + friends (if jemalloc needs to be built)</li>

    </ul>

    <h3><a id="user-content-development-libraries" class="anchor" aria-hidden="true"
    tabindex="-1" href="#development-libraries"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Development Libraries</h3>

    <p>These packages are usually named <code>lib*-dev</code> or <code>lib*-devel</code>:</p>

    <ul>

    <li>numa</li>

    </ul>

    <p>Additional packages are required for the high level interface:</p>

    <ul>

    <li>hwloc</li>

    <li>llvm</li>

    <li>omp (if OpenMP is not available by default on your compilers)</li>

    <li>pfm4</li>

    </ul>

    <h2><a id="user-content-compilation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#compilation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h2>

    <pre><code>export PKG_CONFIG_PATH=&lt;jemalloc prefix&gt;/lib/pkgconfig:$PKG_CONFIG_PATH

    mkdir build

    cd build

    cmake .. -DCMAKE_INSTALL_PREFIX=&lt;prefix&gt;

    make

    make install

    </code></pre>

    <h2><a id="user-content-low-level-api" class="anchor" aria-hidden="true" tabindex="-1"
    href="#low-level-api"><span aria-hidden="true" class="octicon octicon-link"></span></a>Low-Level
    API</h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_init</code></td>

    <td>Detects all memory devices on system, returns a list of them.</td>

    </tr>

    <tr>

    <td><code>sicm_fini</code></td>

    <td>Frees up a device list and associated SICM data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_find_device</code></td>

    <td>Return the first device that matches a given type and page size.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc</code></td>

    <td>Allocates to a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_free</code></td>

    <td>Frees memory on a device.</td>

    </tr>

    <tr>

    <td><code>sicm_can_place_exact</code></td>

    <td>Returns whether or not a device supports exact placement.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc_exact</code></td>

    <td>Allocate memory on a device with an exact base address.</td>

    </tr>

    <tr>

    <td><code>sicm_numa_id</code></td>

    <td>Returns the NUMA ID that a device is on.</td>

    </tr>

    <tr>

    <td><code>sicm_device_page_size</code></td>

    <td>Returns the page size of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_eq</code></td>

    <td>Returns if two devices are equal or not.</td>

    </tr>

    <tr>

    <td><code>sicm_move</code></td>

    <td>Moves memory from one device to another.</td>

    </tr>

    <tr>

    <td><code>sicm_pin</code></td>

    <td>Pin the current process to a device''s memory.</td>

    </tr>

    <tr>

    <td><code>sicm_capacity</code></td>

    <td>Returns the capacity of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_avail</code></td>

    <td>Returns the amount of memory available on a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_model_distance</code></td>

    <td>Returns the distance of a given memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_is_near</code></td>

    <td>Returns whether or not a given memory device is nearby the current NUMA node.</td>

    </tr>

    <tr>

    <td><code>sicm_latency</code></td>

    <td>Measures the latency of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear2</code></td>

    <td>Measures a memory device''s linear access bandwidth.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random2</code></td>

    <td>Measures random access bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear3</code></td>

    <td>Measures the linear bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random3</code></td>

    <td>Measures the random access bandwidth of a memory device.</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-arena-allocator-api" class="anchor" aria-hidden="true"
    tabindex="-1" href="#arena-allocator-api"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Arena Allocator API</h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_arenas_list</code></td>

    <td>List all arenas created in the arena allocator.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_create</code></td>

    <td>Create a new arena on the given device.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_destroy</code></td>

    <td>Frees up an arena, deleting all associated data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_default</code></td>

    <td>Sets an arena as the default for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_default</code></td>

    <td>Gets the default arena for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_device</code></td>

    <td>Gets the device for a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_device</code></td>

    <td>Sets the memory device for a given arena. Moves all allocated memory already
    allocated to the arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_size</code></td>

    <td>Gets the size of memory allocated to the given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc</code></td>

    <td>Allocate to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc_aligned</code></td>

    <td>Allocate aligned memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_realloc</code></td>

    <td>Resize allocated memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_lookup</code></td>

    <td>Returns which arena a given pointer belongs to.</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-high-level-interface" class="anchor" aria-hidden="true"
    tabindex="-1" href="#high-level-interface"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>High-Level Interface</h2>

    <p>The high-level interface is normally used with the compiler wrappers located
    in

    <code>bin/</code>. Users should use these wrappers to compile their applications,
    and a

    compiler pass will automatically transform the code so that it calls the

    high-level interface with the appropriate arguments, including initialization,

    destruction, and the proper allocation functions. Assuming the high-level

    interface is linked to the application as a shared library, it automatically

    initializes itself.  All heap allocation routines are replaced by calls to

    <code>void* sh_alloc(int id, size_t sz)</code>, which associates an ID with a
    given

    allocation and allocates the memory into an arena with other allocations of

    that ID.</p>

    <h2><a id="user-content-programming-practices" class="anchor" aria-hidden="true"
    tabindex="-1" href="#programming-practices"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Programming Practices</h2>

    <ol>

    <li>All blocks use curly braces

    <ul>

    <li>Even one-line blocks</li>

    </ul>

    </li>

    <li>Constants on the left side of <code>==</code>

    <ul>

    <li><code>if(NULL == foo) { ...</code></li>

    </ul>

    </li>

    <li>Functions with no arguments are <code>(void)</code>

    </li>

    <li>No C++-style comments in C code</li>

    <li>No GCC extensions except in GCC-only code</li>

    <li>No C++ code in libraries

    <ul>

    <li>Discouraged in components</li>

    </ul>

    </li>

    <li>Always define preprocessor macros

    <ul>

    <li>Define logicals to 0 or 1 (vs. define or not define)</li>

    <li>Use <code>#if FOO</code>, not <code>#ifdef FOO</code>

    </li>

    </ul>

    </li>

    </ol>

    '
  stargazers_count: 26
  subscribers_count: 24
  topics: []
  updated_at: 1702677503.0
lcompilers/lpython:
  data_format: 2
  description: Python compiler
  filenames:
  - spack.yaml
  full_name: lcompilers/lpython
  latest_release: v0.20.0
  readme: '<h1><a id="user-content-lpython" class="anchor" aria-hidden="true" tabindex="-1"
    href="#lpython"><span aria-hidden="true" class="octicon octicon-link"></span></a>LPython</h1>

    <p>LPython is a Python compiler. It is in heavy development, currently in alpha

    stage. LPython works on Windows, macOS and Linux. Some of the goals of LPython

    include:</p>

    <ul>

    <li>The best possible performance for numerical, array-oriented code</li>

    <li>Run on all platforms</li>

    <li>Compile a subset of Python yet be fully compatible with Python</li>

    <li>Explore designs so that LPython eventually can compile all Python code</li>

    <li>Fast compilation</li>

    <li>Excellent user-friendly diagnostic messages: error, warnings, hints, notes,

    etc.</li>

    <li>Ahead-of-Time compilation to binaries, plus interactive usage (Jupyter notebook)</li>

    <li>Transforming Python code to C++, Fortran and other languages</li>

    </ul>

    <p>And more.</p>

    <h1><a id="user-content-sponsors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#sponsors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sponsors</h1>

    <p>LPython has been sponsored by <a href="https://www.gsitechnology.com/" rel="nofollow">GSI
    Technology</a>.

    Our summer students were sponsored by Google Summer of Code via Python Software

    Foundation. The intermediate representation and backends are shared with

    LFortran, see that project for a list of sponsors.</p>

    <h1><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h1>

    <h2><a id="user-content-step-0-prerequisites" class="anchor" aria-hidden="true"
    tabindex="-1" href="#step-0-prerequisites"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Step 0: Prerequisites</h2>

    <p>Here is the list of requirements needed to build LPython:</p>

    <ul>

    <li>Conda</li>

    </ul>

    <p>For Windows, these are additionally required:</p>

    <ul>

    <li>Miniforge Prompt</li>

    <li>Visual Studio (with "Desktop Development with C++" workload)</li>

    </ul>

    <p>Please follow the steps for your desired platform.</p>

    <h2><a id="user-content-step-1-install-conda" class="anchor" aria-hidden="true"
    tabindex="-1" href="#step-1-install-conda"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Step 1: Install Conda</h2>

    <p>This step involves installing Conda using a conda-forge distribution called
    Miniforge.</p>

    <p>Please follow the instructions here to install Conda on your platform:</p>

    <p>Miniforge download link (for Linux, MacOS and Windows): <a href="https://github.com/conda-forge/miniforge/#download">https://github.com/conda-forge/miniforge/#download</a></p>

    <h2><a id="user-content-step-2-setting-up" class="anchor" aria-hidden="true" tabindex="-1"
    href="#step-2-setting-up"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    2: Setting up</h2>

    <p>This step involves setting up the required configuration to run the programs
    in LPython.</p>

    <h3><a id="user-content-linux" class="anchor" aria-hidden="true" tabindex="-1"
    href="#linux"><span aria-hidden="true" class="octicon octicon-link"></span></a>Linux</h3>

    <p>Run the below command to install <code>binutils-dev</code> package on Linux.</p>

    <div class="highlight highlight-source-shell"><pre>sudo apt install binutils-dev</pre></div>

    <h3><a id="user-content-windows" class="anchor" aria-hidden="true" tabindex="-1"
    href="#windows"><span aria-hidden="true" class="octicon octicon-link"></span></a>Windows</h3>

    <p>Please follow the below steps for Windows:</p>

    <ul>

    <li>

    <p>Install Visual Studio, for example the version 2022.</p>

    <ul>

    <li>You can download the

    Community version for free from: <a href="https://visualstudio.microsoft.com/downloads/"
    rel="nofollow">https://visualstudio.microsoft.com/downloads/</a>.</li>

    <li>After installing Visual Studio and running the Visual Studio Installer, you
    must install the "Desktop Development with C++" workload which will install Visual
    C++ Compiler (MSVC).</li>

    </ul>

    </li>

    <li>

    <p>Launch the Miniforge prompt from the Desktop.</p>

    <ul>

    <li>It is recommended to use MiniForge instead of Powershell as the main terminal
    to build and write code for LPython.</li>

    </ul>

    </li>

    <li>

    <p>In the MiniForge Prompt, initialize the MSVC compiler using the below command:</p>

    <div class="highlight highlight-source-shell"><pre>call <span class="pl-s"><span
    class="pl-pds">"</span>C:\Program Files\Microsoft Visual Studio\2022\Community\Common7\Tools\VsDevCmd<span
    class="pl-pds">"</span></span> -arch=x64</pre></div>

    </li>

    <li>

    <p>You can optionally test MSVC via:</p>

    <div class="highlight highlight-source-shell"><pre>cl /<span class="pl-k">?</span>

    link /<span class="pl-k">?</span></pre></div>

    <p>Both commands must print several pages of help text.</p>

    </li>

    </ul>

    <h2><a id="user-content-step-3-build-lpython" class="anchor" aria-hidden="true"
    tabindex="-1" href="#step-3-build-lpython"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Step 3: Build LPython</h2>

    <ul>

    <li>

    <p>Clone LPython using the following commands</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/lcompilers/lpython.git

    <span class="pl-c1">cd</span> lpython</pre></div>

    <p>You may also use GitHub Desktop to do the same.</p>

    </li>

    </ul>

    <h3><a id="user-content-linux-and-macos" class="anchor" aria-hidden="true" tabindex="-1"
    href="#linux-and-macos"><span aria-hidden="true" class="octicon octicon-link"></span></a>Linux
    and MacOS</h3>

    <ul>

    <li>

    <p>Create a Conda environment using the pre-existing file:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_unix.yml

    conda activate lp</pre></div>

    </li>

    <li>

    <p>Generate prerequisite files; build in Debug Mode:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    if you are developing on top of a forked repository; please run following command
    first</span>

    <span class="pl-c"><span class="pl-c">#</span> ./generate_default_tag.sh</span>



    ./build0.sh

    ./build1.sh</pre></div>

    </li>

    </ul>

    <h3><a id="user-content-windows-1" class="anchor" aria-hidden="true" tabindex="-1"
    href="#windows-1"><span aria-hidden="true" class="octicon octicon-link"></span></a>Windows</h3>

    <ul>

    <li>

    <p>Create a Conda environment using the pre-existing file:</p>

    <div class="highlight highlight-source-shell"><pre>conda env create -f environment_win.yml

    conda activate lp</pre></div>

    </li>

    <li>

    <p>Generate prerequisite files; build in Release Mode:</p>

    <div class="highlight highlight-source-shell"><pre>call build0.bat

    call build1.bat</pre></div>

    </li>

    <li>

    <p>Tests and examples</p>

    <div class="highlight highlight-source-shell"><pre>ctest

    src<span class="pl-cce">\b</span>in<span class="pl-cce">\l</span>python examples<span
    class="pl-cce">\e</span>xpr2.py

    src<span class="pl-cce">\b</span>in<span class="pl-cce">\l</span>python examples<span
    class="pl-cce">\e</span>xpr2.py -o a.out

    a.out</pre></div>

    </li>

    <li>

    <p>Whenever you are updating a test case file, you also need to update all the
    reference results associated with that test case:</p>

    <pre><code>python run_tests.py -u --skip-run-with-dbg

    </code></pre>

    </li>

    <li>

    <p>To see all the options associated with LPython test suite, use:</p>

    <pre><code>python run_tests.py --help

    </code></pre>

    </li>

    </ul>

    <h2><a id="user-content-tests" class="anchor" aria-hidden="true" tabindex="-1"
    href="#tests"><span aria-hidden="true" class="octicon octicon-link"></span></a>Tests:</h2>

    <h3><a id="user-content-linux-or-macos" class="anchor" aria-hidden="true" tabindex="-1"
    href="#linux-or-macos"><span aria-hidden="true" class="octicon octicon-link"></span></a>Linux
    or MacOS</h3>

    <ul>

    <li>

    <p>Run tests:</p>

    <div class="highlight highlight-source-shell"><pre>ctest

    ./run_tests.py</pre></div>

    </li>

    <li>

    <p>Update test references:</p>

    <pre><code>./run_tests.py -u

    </code></pre>

    </li>

    <li>

    <p>Run integration tests:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    integration_tests

    ./run_tests.py</pre></div>

    </li>

    <li>

    <p>Troubleshooting on MacOS latest version:</p>

    <ul>

    <li>

    <p>In case of recently updated MacOS, you may get a warning like below in some
    test cases:</p>

    <div class="highlight highlight-source-shell"><pre>ld: warning: object file (test_list_index2.out.tmp.o)
    was built <span class="pl-k">for</span> newer macOS version (14.0) than being
    linked (13.3)</pre></div>

    <p>This leads to mismatch of hashes with expected output in some test cases, this
    can be resolved by updating command line tools. Below is a snippet for the same.</p>

    <div class="highlight highlight-source-shell"><pre>git clean -dfx

    sudo rm -rf /Library/Developer/CommandLineTools <span class="pl-c"><span class="pl-c">#</span>
    make sure you know what you''re doing here</span>

    sudo xcode-select --install

    ./build.sh

    ./run_tests.py</pre></div>

    </li>

    </ul>

    </li>

    </ul>

    <h3><a id="user-content-windows-2" class="anchor" aria-hidden="true" tabindex="-1"
    href="#windows-2"><span aria-hidden="true" class="octicon octicon-link"></span></a>Windows</h3>

    <ul>

    <li>

    <p>Run integration tests</p>

    <div class="highlight highlight-source-shell"><pre>python run_tests.py --skip-run-with-dbg</pre></div>

    </li>

    <li>

    <p>Update reference tests</p>

    <div class="highlight highlight-source-shell"><pre>python run_tests.py -u --skip-run-with-dbg</pre></div>

    </li>

    </ul>

    <h2><a id="user-content-speed-up-integration-tests-on-macos" class="anchor" aria-hidden="true"
    tabindex="-1" href="#speed-up-integration-tests-on-macos"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Speed up Integration Tests on MacOS</h2>

    <p>Integration tests run slowly because Apple checks the hash of each

    executable online before running.</p>

    <p>You can turn off that feature in the Privacy tab of the Security and Privacy
    item of System Preferences &gt; Developer Tools &gt; Terminal.app &gt; "allow
    the apps below

    to run software locally that does not meet the system''s security

    policy."</p>

    <h2><a id="user-content-examples-linux-or-macos" class="anchor" aria-hidden="true"
    tabindex="-1" href="#examples-linux-or-macos"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Examples (Linux or MacOS)</h2>

    <p>You can run the following examples manually in a terminal:</p>

    <div class="highlight highlight-source-shell"><pre>./src/bin/lpython examples/expr2.py

    ./src/bin/lpython examples/expr2.py -o expr

    ./expr

    ./src/bin/lpython --show-ast examples/expr2.py

    ./src/bin/lpython --show-asr examples/expr2.py

    ./src/bin/lpython --show-cpp examples/expr2.py

    ./src/bin/lpython --show-llvm examples/expr2.py

    ./src/bin/lpython --show-c examples/expr2.py</pre></div>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>We welcome contributions from anyone, even if you are new to compilers or to

    open source. It might sound daunting to contribute to a compiler at first, but

    please do, it is not complicated. We will help you with technical issues and

    help improve your contribution so that it can be merged.</p>

    <p>To contribute, submit a Pull Request (PR) against our repository at:</p>

    <p><a href="https://github.com/lcompilers/lpython">https://github.com/lcompilers/lpython</a></p>

    <p>and don''t forget to clean your history, see <a href="./doc/src/rebasing.md">example</a>.</p>

    <p>Please report any bugs you may find at our issue tracker:

    <a href="https://github.com/lcompilers/lpython/issues">https://github.com/lcompilers/lpython/issues</a>.
    Or, even better, fork the

    repository on GitHub and create a PR. We welcome all changes, big or small, and

    we will help you make a PR if you are new to git.</p>

    <p>If you have any questions or need help, please ask us at Zulip (<a href="https://lfortran.zulipchat.com/"
    rel="nofollow"><img src="https://camo.githubusercontent.com/f075ed3a1bcc7bc6d681d5b1b96c7235827bcfa73790e55a1c98bf969736b4e9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667"
    alt="project chat" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg"
    style="max-width: 100%;"></a>)

    or our <a href="https://groups.io/g/lfortran" rel="nofollow">mailinglist</a>.</p>

    <p>See the <a href="CONTRIBUTING.md">CONTRIBUTING</a> document for more information.</p>

    <h1><a id="user-content-star-history" class="anchor" aria-hidden="true" tabindex="-1"
    href="#star-history"><span aria-hidden="true" class="octicon octicon-link"></span></a>Star
    History</h1>

    <p><a href="https://star-history.com/#lcompilers/lpython&amp;Date" rel="nofollow"><img
    src="https://camo.githubusercontent.com/78c421eab5b4c6b49d5511402a66758420f313ca898a23fef0b6473f42f050d8/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c636f6d70696c6572732f6c707974686f6e26747970653d44617465"
    alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=lcompilers/lpython&amp;type=Date"
    style="max-width: 100%;"></a></p>

    '
  stargazers_count: 1199
  subscribers_count: 29
  topics:
  - compiler
  - high-performance
  - python
  updated_at: 1707809207.0
lezzidan/spack:
  data_format: 2
  description: Spack clone
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss-aws-aarch64/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/aws-isc/spack.yaml
  full_name: lezzidan/spack
  latest_release: null
  readme: "<h1><a id=\"user-content--spack\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\"\
    \ href=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/70b0104a5a00f472f39f523bb50f576c7d5456c58b0068304f1ecd8e5054ae8c/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/build-containers.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/build-containers.yml/badge.svg\"\
    \ alt=\"Containers\" style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fca79013ca8059644742ad2936823670fa01342c0e60d57949ee69f693dccde3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/psf/black\"><img\
    \ src=\"https://camo.githubusercontent.com/7d770c433d6198d89f8c1e2f187b904a9721d176259d0e97157337741cc8e837/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"\
    \ alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/code%20style-black-000000.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/e8580758c789c07a64e14287a71a75290dcddc6fee61b8a2e64f07bf7dca1ec9/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p><a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <h2><a id=\"user-content-tutorial\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Tutorial</h2>\n<p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<h2><a id=\"user-content-community\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#community\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Community</h2>\n<p>Spack is an open source project.\
    \  Questions, discussion, and\ncontributions are welcome. Contributions can be\
    \ anything from new\npackages to bugfixes, documentation, or even new core features.</p>\n\
    <p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<a href=\"\
    https://github.com/spack/spack/discussions\"><strong>Github Discussions</strong></a>:\
    \ not just for discussions, also Q&amp;A.</li>\n<li>\n<strong>Mailing list</strong>:\
    \ <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\">groups.google.com/d/forum/spack</a>\n\
    </li>\n<li>\n<strong>Twitter</strong>: <a href=\"https://twitter.com/spackpm\"\
    \ rel=\"nofollow\">@spackpm</a>. Be sure to\n<code>@mention</code> us!</li>\n\
    </ul>\n<h2><a id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Contributing</h2>\n<p>Contributing to Spack\
    \ is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2><a id=\"user-content-releases\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Releases</h2>\n<p>For multi-user site deployments or other use cases\
    \ that need very stable\nsoftware installations, we recommend using Spack's\n\
    <a href=\"https://github.com/spack/spack/releases\">stable releases</a>.</p>\n\
    <p>Each Spack release series also has a corresponding branch, e.g.\n<code>releases/v0.14</code>\
    \ has <code>0.14.x</code> versions of Spack, and <code>releases/v0.13</code> has\n\
    <code>0.13.x</code> versions. We backport important bug fixes to these branches\
    \ but\nwe do not advance the package versions or make other changes that would\n\
    change the way Spack concretizes dependencies within a release branch.\nSo, you\
    \ can base your Spack deployment on a release branch and <code>git pull</code>\n\
    to get fixes, without the package churn that comes with <code>develop</code>.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<p>See the <a href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\"\
    \ rel=\"nofollow\">docs on releases</a>\nfor more details.</p>\n<h2><a id=\"user-content-code-of-conduct\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#code-of-conduct\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Code of\
    \ Conduct</h2>\n<p>Please note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"\
    ><strong>Code of Conduct</strong></a>. By participating in\nthe Spack community,\
    \ you agree to abide by its rules.</p>\n<h2><a id=\"user-content-authors\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#authors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>Many thanks\
    \ go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\"\
    >tgamblin@llnl.gov</a>.</p>\n<h3><a id=\"user-content-citing-spack\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Citing Spack</h3>\n<p>If you\
    \ are referencing Spack in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee,\n\
    Adam Moody, Bronis R. de Supinski, and W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<p>On GitHub, you can copy\
    \ this citation in APA or BibTeX format via the \"Cite this repository\"\nbutton.\
    \ Or, see the comments in <code>CITATION.cff</code> for the raw BibTeX.</p>\n\
    <h2><a id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>License</h2>\n<p>Spack is distributed under the terms of both the\
    \ MIT license and the\nApache License (Version 2.0). Users may choose either license,\
    \ at their\noption.</p>\n<p>All new contributions must be made under both the\
    \ MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\"\
    >LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\"\
    >LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\"\
    >COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\"\
    >NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1684418839.0
m-s-will/nyx:
  data_format: 2
  description: null
  filenames:
  - nyx/inputs/spack/spack.yaml
  full_name: m-s-will/nyx
  latest_release: null
  readme: '<h1><a id="user-content-nyx-with-ascent-in-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#nyx-with-ascent-in-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Nyx with Ascent in Container</h1>

    <p>This project contains a Dockerfile and all necessary components to create a
    Docker container for Nyx.

    The container is available on <a href="https://hub.docker.com/repository/docker/mswill/elwe_nyx"
    rel="nofollow">Dockerhub</a>, however these versions may not always be up to date.</p>

    <h2><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#building-the-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Building the container</h2>

    <p>The Ascent actions can be changed by editing <a href="https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml">ascent_actions.yaml</a>.

    When finished with the customization, the container can be rebuilt by navigating
    into the source directory and executing:</p>

    <pre><code>$ docker build -t &lt;mytag&gt; .

    </code></pre>

    <p>The Nyx simulation is being run during container creation and provides a Cinema
    database.</p>

    <h2><a id="user-content-running-the-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#running-the-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Running the container</h2>

    <p>After either pulling or building the container, it can be run by calling:</p>

    <pre><code>$ docker run -p 80:80 &lt;mytag&gt;.

    </code></pre>

    <p><code>-p 80:80</code> makes port 80 available on the outside which is needed
    for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code>
    in our browser.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1619455896.0
mdorier/test-ssg-cori:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: mdorier/test-ssg-cori
  latest_release: null
  readme: '<h1><a id="user-content-building" class="anchor" aria-hidden="true" tabindex="-1"
    href="#building"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building</h1>

    <p>Setup spack and sds-repo, clone this repository and <code>cd</code> in it,
    then:</p>

    <pre><code>spack env create ssg-test spack.yaml

    spack env activate ssg-test

    spack install

    spack env deactivate

    </code></pre>

    <p>Then to build the code:</p>

    <pre><code>export CRAYPE_LINK_TYPE=dynamic

    module swap PrgEnv-intel PrgEnv-gnu

    module swap gcc/8.3.0 gcc/9.3.0

    spack env activate ssg-test

    mkdir build

    cd build

    cmake ..

    make

    </code></pre>

    <h1><a id="user-content-running" class="anchor" aria-hidden="true" tabindex="-1"
    href="#running"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running</h1>

    <p>From the <code>build</code> directory:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 128 ./test-server

    # one of the server will print "Credential: X", copy the X

    </code></pre>

    <p>In another terminal window, with current working directory set to <code>build</code>:</p>

    <pre><code>export MPICH_GNI_NDREG_ENTRIES=1024

    export HG_NA_LOG_LEVEL=debug

    export ABT_THREAD_STACKSIZE=2097152

    srun -C haswell -n 1 ./test-client X # replace X with the copied value

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1614179535.0
mfem/mfem:
  data_format: 2
  description: Lightweight, general, scalable C++ library for finite element methods
  filenames:
  - config/docker/spack.yaml
  full_name: mfem/mfem
  latest_release: v4.6
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed\
    \ under the terms of the BSD-3 license. All new contributions\nmust be made under\
    \ this license. See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>\
    \ for\ndetails.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release\
    \ Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 1477
  subscribers_count: 121
  topics:
  - finite-elements
  - high-order
  - high-performance-computing
  - parallel-computing
  - amr
  - computational-science
  - fem
  - scientific-computing
  - hpc
  - math-physics
  - radiuss
  updated_at: 1707486851.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ORNL/Crusher/spack.yaml
  - ANL/Cooley/spack.yaml
  - ANL/Aurora/spack.yaml
  - ORNL/Summit/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" tabindex="-1" href="#platform-configurations-for-mochi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Platform configurations
    for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    tabindex="-1" href="#using-spackyaml-files"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Using spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Then, execute the following commands

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    $ spack env activate myenv

    $ spack repo add /where/you/cloned/mochi-spack-packages

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    tabindex="-1" href="#contributing-to-this-repository"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 4
  subscribers_count: 3
  topics: []
  updated_at: 1682086466.0
mochi-hpc/flamestore:
  data_format: 2
  description: Storage system for Deep Learning models designed using the Mochi components.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/flamestore
  latest_release: null
  readme: '<h1><a id="user-content-what-is-flamestore" class="anchor" aria-hidden="true"
    tabindex="-1" href="#what-is-flamestore"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>What is FlameStore?</h1>

    <p>FlameStore is a Mochi component to access Keras deep learning models

    and store them in various backends (right now: in memory, on a local

    file system, or on a composition of SDSKV and BAKE providers).</p>

    <p>FlameStore is developped by Matthieu Dorier (<a href="mailto:mdorier@anl.gov">mdorier@anl.gov</a>).

    More information on how to install and use is available

    <a href="https://xgitlab.cels.anl.gov/sds/flamestore/wikis/home" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1700115196.0
mochi-hpc/mochi-bake:
  data_format: 2
  description: A microservice (i.e., Mochi provider) for high performance bulk storage
    of raw data regions
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bake
  latest_release: v0.6.4
  readme: "<h1><a id=\"user-content-bake\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#bake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Bake</h1>\n<p>Bake is a microservice (i.e., Mochi provider) for high\
    \ performance bulk\nstorage of raw data regions.  Bake uses modular backends to\
    \ store data\non persistent memory, conventional file systems, or other storage\
    \ media.</p>\n<p>See <a href=\"https://www.mcs.anl.gov/research/projects/mochi/\"\
    \ rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a> and\n\
    <a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a>\
    \ for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively\
    \ to data storage.  Capabilities such as\nindexing, name spaces, and sharding\
    \ must be provided by other microservice\ncomponents.</p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>The easiest way to install Bake is through spack:</p>\n<p><code>spack install\
    \ bake</code></p>\n<p>This will install BAKE and its dependencies.  Please refer\
    \ to the end of the\ndocument for manual compilation instructions.</p>\n<h2><a\
    \ id=\"user-content-architecture\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#architecture\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Architecture</h2>\n<p>Like most Mochi services, BAKE relies on a client/provider\
    \ architecture.\nA provider, identified by its <em>address</em> and <em>multiplex\
    \ id</em>, manages one or more\n<em>BAKE targets</em>, referenced externally by\
    \ their <em>target id</em>.</p>\n<p>A target can be thought of as a storage device.\
    \  This may be (for example) a\nPMDK volume or a local file system.</p>\n<h2><a\
    \ id=\"user-content-setting-up-a-bake-target\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#setting-up-a-bake-target\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up a BAKE target</h2>\n\
    <p>BAKE requires the backend storage file to be created beforehand using\n<code>bake-mkpool</code>.\
    \ For instance:</p>\n<p><code>bake-mkpool -s 500M /dev/shm/foo.dat</code></p>\n\
    <p>creates a 500 MB file at <em>/dev/shm/foo.dat</em> to be used by BAKE as a\
    \ target.\nBake will use the <code>pmem</code> (persistent memory) backend by\
    \ default, which means\nthat the underlying file will memory mapped for access\
    \ usign the PMDK\nlibrary.  You can also providie an explicit prefix (such as\
    \ <code>file:</code> for the\nconventional file backend or <code>pmem:</code>\
    \ for the persistent memory backend) to\ndictate a specific target type.</p>\n\
    <h2><a id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#starting-a-daemon\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>BAKE ships with a\
    \ default daemon program that can setup providers and attach\nto storage targets.\
    \ This daemon can be started as follows:</p>\n<p><code>bake-server-daemon [options]\
    \ &lt;listen_address&gt; &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n\
    <p>The program takes a set of options followed by an address at which to listen\
    \ for\nincoming RPCs, and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n\
    <p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234\
    \ /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n\
    <ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the\
    \ address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em>\
    \ or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates\
    \ that, if multiple BAKE targets are used (as above),\nthese targets should be\
    \ managed by multiple providers, accessible through\ndifferent multiplex ids 1,\
    \ 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage.\
    \ The <em>targets</em> mode indicates that a single provider should be used to\n\
    manage all the storage targets.</p>\n<h2><a id=\"user-content-integrating-bake-into-a-larger-service\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#integrating-bake-into-a-larger-service\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Integrating\
    \ Bake into a larger service</h2>\n<p>Bake is not intended to be a standalone\
    \ user-facing service.  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\"\
    \ rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for\
    \ guidance on how to\nintegrate it with other providers using Mochi's Bedrock\
    \ capability.</p>\n<h2><a id=\"user-content-client-api-example\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#client-api-example\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Client API example</h2>\n<p>Data\
    \ is stored in <code>regions</code> within a <code>target</code> using explicit\
    \ create,\nwrite, and persist operations.  The caller cannot dictate the region\
    \ id\nthat will be used to reference a region; this identifier is generated\n\
    by Bake at creation time.  The region size must be specified at creation\ntime\
    \ as well; there is no mechanism for extending the size of an existing\nregion.</p>\n\
    <div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">#include</span>\
    \ <span class=\"pl-s\">&lt;bake-client.h&gt;</span>\n\n<span class=\"pl-smi\"\
    >int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">int</span>\
    \ <span class=\"pl-s1\">argc</span>, <span class=\"pl-smi\">char</span> <span\
    \ class=\"pl-c1\">*</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >argv</span>)\n{\n    <span class=\"pl-smi\">char</span> <span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">svr_addr_str</span>; <span class=\"pl-c\">// string\
    \ address of the BAKE server</span>\n    <span class=\"pl-smi\">hg_addr_t</span>\
    \ <span class=\"pl-s1\">svr_addr</span>; <span class=\"pl-c\">// Mercury address\
    \ of the BAKE server</span>\n    <span class=\"pl-smi\">margo_instance_id</span>\
    \ <span class=\"pl-s1\">mid</span>; <span class=\"pl-c\">// Margo instance id</span>\n\
    \    <span class=\"pl-smi\">bake_client_t</span> <span class=\"pl-s1\">bcl</span>;\
    \ <span class=\"pl-c\">// BAKE client</span>\n    <span class=\"pl-smi\">bake_provider_handle_t</span>\
    \ <span class=\"pl-s1\">bph</span>; <span class=\"pl-c\">// BAKE handle to provider</span>\n\
    \    <span class=\"pl-smi\">uint8_t</span> <span class=\"pl-s1\">mplex_id</span>;\
    \ <span class=\"pl-c\">// multiplex id of the provider</span>\n    <span class=\"\
    pl-smi\">uint32_t</span> <span class=\"pl-s1\">target_number</span>; <span class=\"\
    pl-c\">// target to use</span>\n    <span class=\"pl-smi\">bake_region_id_t</span>\
    \ <span class=\"pl-s1\">rid</span>; <span class=\"pl-c\">// BAKE region id handle</span>\n\
    \t<span class=\"pl-smi\">bake_target_id_t</span><span class=\"pl-c1\">*</span>\
    \ <span class=\"pl-s1\">bti</span>; <span class=\"pl-c\">// array of target ids</span>\n\
    \n\t<span class=\"pl-c\">/* ... setup variables ... */</span>\n\n\t<span class=\"\
    pl-c\">/* Initialize Margo */</span>\n\t<span class=\"pl-s1\">mid</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">margo_init</span>(..., <span\
    \ class=\"pl-c1\">MARGO_CLIENT_MODE</span>, <span class=\"pl-c1\">0</span>, <span\
    \ class=\"pl-c1\">-1</span>);\n\t<span class=\"pl-c\">/* Lookup the server */</span>\n\
    \t<span class=\"pl-en\">margo_addr_lookup</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr_str</span>, <span class=\"pl-c1\">&amp;</span><span\
    \ class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-c\">/* Creates the BAKE\
    \ client */</span>\n\t<span class=\"pl-en\">bake_client_init</span>(<span class=\"\
    pl-s1\">mid</span>, <span class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bcl</span>);\n\
    \t<span class=\"pl-c\">/* Creates the provider handle */</span>\n\t<span class=\"\
    pl-en\">bake_provider_handle_create</span>(<span class=\"pl-s1\">bcl</span>, <span\
    \ class=\"pl-s1\">svr_addr</span>, <span class=\"pl-s1\">mplex_id</span>, <span\
    \ class=\"pl-c1\">&amp;</span><span class=\"pl-s1\">bph</span>);\n\t<span class=\"\
    pl-c\">/* Asks the provider for up to target_number target ids */</span>\n\t<span\
    \ class=\"pl-smi\">uint32_t</span> <span class=\"pl-s1\">num_targets</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-c1\">0</span>;\n\t<span class=\"pl-s1\"\
    >bti</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">calloc</span>(<span\
    \ class=\"pl-s1\">num_targets</span>, <span class=\"pl-k\">sizeof</span>(<span\
    \ class=\"pl-c1\">*</span><span class=\"pl-s1\">bti</span>));\n\t<span class=\"\
    pl-en\">bake_probe</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >target_number</span>, <span class=\"pl-s1\">bti</span>, <span class=\"pl-c1\"\
    >&amp;</span><span class=\"pl-s1\">num_targets</span>);\n\t<span class=\"pl-k\"\
    >if</span>(<span class=\"pl-s1\">num_targets</span> <span class=\"pl-c1\">&lt;</span>\
    \ <span class=\"pl-s1\">target_number</span>) {\n\t\t<span class=\"pl-en\">fprintf</span>(<span\
    \ class=\"pl-s1\">stderr</span>, <span class=\"pl-s\">\"Error: provider has only\
    \ %d storage targets\\n\"</span>, <span class=\"pl-s1\">num_targets</span>);\n\
    \t}\n\t<span class=\"pl-c\">/* Create a region */</span>\n\t<span class=\"pl-smi\"\
    >size_t</span> <span class=\"pl-s1\">size</span> <span class=\"pl-c1\">=</span>\
    \ ...; <span class=\"pl-c\">// size of the region to create</span>\n\t<span class=\"\
    pl-en\">bake_create</span>(<span class=\"pl-s1\">bph</span>, <span class=\"pl-s1\"\
    >bti</span>[<span class=\"pl-s1\">target_number</span><span class=\"pl-c1\">-</span><span\
    \ class=\"pl-c1\">1</span>], <span class=\"pl-s1\">size</span>, <span class=\"\
    pl-c1\">&amp;</span><span class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\"\
    >/* Write data into the region at offset 0 */</span>\n\t<span class=\"pl-smi\"\
    >char</span><span class=\"pl-c1\">*</span> <span class=\"pl-s1\">buf</span> <span\
    \ class=\"pl-c1\">=</span> ...;\n\t<span class=\"pl-en\">bake_write</span>(<span\
    \ class=\"pl-s1\">bph</span>, <span class=\"pl-s1\">rid</span>, <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-s1\">buf</span>, <span class=\"pl-s1\">size</span>);\n\
    \t<span class=\"pl-c\">/* Make all modifications persistent */</span>\n\t<span\
    \ class=\"pl-en\">bake_persist</span>(<span class=\"pl-s1\">bph</span>, <span\
    \ class=\"pl-s1\">rid</span>);\n\t<span class=\"pl-c\">/* Release provider handle\
    \ */</span>\n\t<span class=\"pl-en\">bake_provider_handle_release</span>(<span\
    \ class=\"pl-s1\">bph</span>);\n\t<span class=\"pl-c\">/* Release BAKE client\
    \ */</span>\n\t<span class=\"pl-en\">bake_client_finalize</span>(<span class=\"\
    pl-s1\">bcl</span>);\n\t<span class=\"pl-c\">/* Cleanup Margo resources */</span>\n\
    \t<span class=\"pl-en\">margo_addr_free</span>(<span class=\"pl-s1\">mid</span>,\
    \ <span class=\"pl-s1\">svr_addr</span>);\n\t<span class=\"pl-en\">margo_finalize</span>(<span\
    \ class=\"pl-s1\">mid</span>);\n\t<span class=\"pl-k\">return</span> <span class=\"\
    pl-c1\">0</span>;\n}</pre></div>\n<p>Note that a <code>bake_region_id_t</code>\
    \ object is persistent.  It can be written\n(into a file or a socket) and stored\
    \ or sent to another program. These\nregion ids are what uniquely reference a\
    \ region within a given target.</p>\n<p>The rest of the client-side API can be\
    \ found in <code>bake-client.h</code>.</p>\n<h2><a id=\"user-content-provider-api\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#provider-api\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider\
    \ API</h2>\n<p>The bake-server-daemon source is a good example of how to create\
    \ providers and\nattach storage targets to them. The provider-side API is located\
    \ in\n<em>bake-server.h</em>, and consists of mainly two functions:</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre><span class=\"pl-smi\">int</span>\
    \ <span class=\"pl-en\">bake_provider_register</span>(<span class=\"pl-smi\">margo_instance_id</span>\
    \                     <span class=\"pl-s1\">mid</span>,\n                    \
    \       <span class=\"pl-smi\">uint16_t</span>                              <span\
    \ class=\"pl-s1\">provider_id</span>,\n                           <span class=\"\
    pl-k\">const</span> <span class=\"pl-k\">struct</span> <span class=\"pl-smi\"\
    >bake_provider_init_info</span><span class=\"pl-c1\">*</span> <span class=\"pl-s1\"\
    >args</span>,\n                           <span class=\"pl-smi\">bake_provider_t</span><span\
    \ class=\"pl-c1\">*</span>                      <span class=\"pl-s1\">provider</span>);</pre></div>\n\
    <p>This creates a provider at the given provider id using the specified margo\n\
    instance.  The <code>args</code> parameter can be used to modify default settings,\n\
    including passing in a fully specified json configuration block.  See\n<code>bake-server.h</code>\
    \ for details.</p>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"\
    pl-smi\">int</span> <span class=\"pl-en\">bake_provider_attach_target</span>(<span\
    \ class=\"pl-smi\">bake_provider_t</span>   <span class=\"pl-s1\">provider</span>,\n\
    \                                <span class=\"pl-k\">const</span> <span class=\"\
    pl-smi\">char</span><span class=\"pl-c1\">*</span>       <span class=\"pl-s1\"\
    >target_name</span>,\n                                <span class=\"pl-smi\">bake_target_id_t</span><span\
    \ class=\"pl-c1\">*</span> <span class=\"pl-s1\">target_id</span>);</pre></div>\n\
    <p>This makes the provider manage the given storage target.</p>\n<p>Other functions\
    \ are available to create and detach targets from a provider.</p>\n<h2><a id=\"\
    user-content-generic-bake-benchmark\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#generic-bake-benchmark\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Generic Bake benchmark</h2>\n<p>By using <code>--enable-benchmark</code>\
    \ when compiling Bake (or <code>+benchmark</code> when using Spack),\nyou will\
    \ build a <code>bake-benchmark</code> program that can be used as a configurable\
    \ benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure\
    \ Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n<p>The benchmark\
    \ is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a\
    \ server, while non-zero ranks act as clients. The server will not create\na Bake\
    \ target. The Bake target needs to be created (with <code>bake-makepool</code>)\
    \ beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing\
    \ the sequence\nof benchmarks to execute. An example of such a file is located\
    \ in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code>\
    \ array corresponds to a benchmark. The <code>type</code> field indicates\nthe\
    \ type of benchmark to execute. The <code>repetitions</code> field indicates how\
    \ many times the\nbenchmark should be repeated.</p>\n<p>The following table describes\
    \ each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n\
    <th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n\
    </tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to\
    \ the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n\
    <td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for\
    \ each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n\
    <td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's\
    \ buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n\
    <td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n\
    <td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions,\
    \ or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether\
    \ to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n\
    </tbody>\n</table>\n<h2><a id=\"user-content-manual-installation\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#manual-installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Manual installation</h2>\n<p>BAKE\
    \ depends on the following libraries:</p>\n<ul>\n<li>uuid (install uuid-dev package\
    \ on ubuntu)</li>\n<li>PMDK (see instructions below)</li>\n<li>json-c</li>\n<li>mochi-abt-io</li>\n\
    <li>mochi-margo</li>\n</ul>\n<p>Bake will automatically identify these dependencies\
    \ at configure time using\npkg-config. To compile BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n\
    <li><code>mkdir build</code></li>\n<li><code>cd build</code></li>\n<li><code>../configure\
    \ --prefix=/home/carns/working/install</code></li>\n<li><code>make</code></li>\n\
    </ul>\n<p>If any dependencies are installed in a nonstandard location, then\n\
    modify the configure step listed above to include the following argument:</p>\n\
    <ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1633975151.0
mochi-hpc/mochi-doc:
  data_format: 2
  description: Documentations and tutorials for Margo, Thallium, Argobots, Mercury,
    and other Mochi libraries.
  filenames:
  - code/spack.yaml
  full_name: mochi-hpc/mochi-doc
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"><img
    src="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"
    alt="build" style="max-width: 100%;"></a></p>

    <h1><a id="user-content-mochi-documentation" class="anchor" aria-hidden="true"
    tabindex="-1" href="#mochi-documentation"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Mochi documentation</h1>

    <p>This repository contains a Sphinx-based documentation

    for the Mochi libraries: Margo, Thallium, Argobots, Mercury,

    ABT-IO, and SSG, as well as corresponding code examples.</p>

    <h2><a id="user-content-building-the-documentation" class="anchor" aria-hidden="true"
    tabindex="-1" href="#building-the-documentation"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Building the documentation</h2>

    <p>To build and/or contribute to this documentation, you must have a Sphinx and

    a few related extensions installed.  These can be installed as follows using

    Python''s <code>pip</code>.</p>

    <pre><code>pip install sphinx

    pip install sphinx_rtd_theme

    pip install sphinx_copybutton

    pip install recommonmark

    pip install breathe

    </code></pre>

    <p>Alternatively, those required packages may also be available in your

    platform''s primary package manager.  For example, in Ubuntu 23.04 you could

    do the following instead of using pip:</p>

    <pre><code>sudo apt install python3-breathe python3-recommonmark python3-sphinx-copybutton
    python3-sphinx-rtd-theme

    </code></pre>

    <p>You must also install the <code>doxygen</code> documentation system.  This
    is likely

    available in your platform''s primary package manager.  For example on Ubuntu:</p>

    <pre><code>sudo apt install doxygen

    </code></pre>

    <p>Once you have these dependencies installed, clone this

    repository and cd into it. You can change the documentation

    by editing the files in the source subdirectory (these files

    use the .rst format). You can build the documentation

    using the following command.</p>

    <pre><code>cd docs

    make html

    </code></pre>

    <p>And check the result by opening the <code>build/html/index.html</code> page

    that has been created in the docs directory.</p>

    <h2><a id="user-content-building-the-code-examples" class="anchor" aria-hidden="true"
    tabindex="-1" href="#building-the-code-examples"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Building the code examples</h2>

    <p>To build the code, you will need spack and the

    <a href="https://github.com/mochi-hpc/mochi-spack-packages">mochi repo</a> setup.</p>

    <pre><code>cd code

    spack env create mochi-doc-env spack.yaml

    spack env activate mochi-doc-env

    spack install

    mkdir build

    cd build

    cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc

    make

    </code></pre>

    '
  stargazers_count: 5
  subscribers_count: 4
  topics: []
  updated_at: 1702435305.0
mochi-hpc/mochi-sdskv:
  data_format: 2
  description: simple margo-projected keyval service
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-sdskv
  latest_release: v0.1.14
  readme: "<h1><a id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sdskv-sds-keyval\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>SDSKV (SDS Key/Val)</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>SDSKV can easily be installed using Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n\
    <p>This will install SDSKV (and any required dependencies).\nAvailable backends\
    \ will be <em>Map</em> (in-memory C++ std::map, useful for testing)\nand BwTree\
    \ (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code>\
    \ and <code>+leveldb</code> respectively. For example:</p>\n<p><code>spack install\
    \ sdskeyval+bdb+leveldb</code></p>\n<p>Note that if you are using a system boost\
    \ path in spack (in your\npackages.yaml) rather than letting spack build boost,\
    \ then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages\
    \ on\nyour system.</p>\n<h2><a id=\"user-content-architecture\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#architecture\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>List most\
    \ mochi services, SDSKV relies on a client/provider architecture.\nA provider,\
    \ identified by its <em>address</em> and <em>multiplex id</em>, manages one or\
    \ more\ndatabases, referenced externally by their database id.</p>\n<h2><a id=\"\
    user-content-starting-a-daemon\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#starting-a-daemon\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Starting a daemon</h2>\n<p>SDSKV ships with a default daemon program\
    \ that can setup providers and\ndatabases. This daemon can be started as follows:</p>\n\
    <p><code>sdskv-server-daemon [OPTIONS] &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb]\
    \ &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb] ...</code></p>\n<p>For example:</p>\n\
    <p><code>sdskv-server-daemon tcp://localhost:1234 foo:bdb bar</code></p>\n<p>listen_addr\
    \ is the address at which to listen; database names should be provided in the\
    \ form\n<em>name:type</em> where <em>type</em> is <em>map</em> (std::map), <em>bwt</em>\
    \ (BwTree), <em>bdb</em> (Berkeley DB), or <em>ldb</em> (LevelDB).</p>\n<p>For\
    \ database that are persistent like BerkeleyDB or LevelDB, the name should be\
    \ a path to the\nfile where the database will be put (this file should not exist).</p>\n\
    <p>The following additional options are accepted:</p>\n<ul>\n<li>\n<code>-f</code>\
    \ provides the name of the file in which to write the address of the daemon.</li>\n\
    <li>\n<code>-m</code> provides the mode (providers or databases).</li>\n</ul>\n\
    <p>The providers mode indicates that, if multiple SDSKV databases are used (as\
    \ above),\nthese databases should be managed by multiple providers, accessible\
    \ through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\n\
    to manage. The targets mode indicates that a single provider should be used to\n\
    manage all the databases. This provider will be accessible at multiplex id 1.</p>\n\
    <h2><a id=\"user-content-client-api\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#client-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Client API</h2>\n<p>The client API is available in <em>sdskv-client.h</em>.\n\
    The codes in the <em>test</em> folder illustrate how to use it.</p>\n<h2><a id=\"\
    user-content-provider-api\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#provider-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Provider API</h2>\n<p>The server-side API is available in <em>sdskv-server.h</em>.\n\
    The code of the daemon (<em>src/sdskv-server-daemon.c</em>) can be used as an\
    \ example.</p>\n<h3><a id=\"user-content-custom-key-comparison-function\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#custom-key-comparison-function\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Custom key\
    \ comparison function</h3>\n<p>It is possible to specify a custom function for\
    \ comparing/sorting keys\nwhen creating a provider. A comparison function must\
    \ have the following prototype:</p>\n<p><code>int (*)(const void* key1, size_t\
    \ keysize1, const void* key2, size_t keysize2)</code></p>\n<p>Its return value\
    \ must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0 if key1 &gt; key2.\n\
    It must define a total order of the key space.</p>\n<h2><a id=\"user-content-c-api\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#c-api\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ API</h2>\n\
    <p>An object-oriented C++ API is available in <code>sdskv-client.hpp</code> and\
    \ <code>sdskv-server.hpp</code>.\nOn the client side this API provides the <code>client</code>,\
    \ <code>provider_handle</code>, and <code>database</code> objects.\nExamples of\
    \ usage of these objects can be found in the <code>test/sdskv-cxx-test.cc</code>.\n\
    On the server side, this API provides a <code>provider</code> object.</p>\n<h2><a\
    \ id=\"user-content-benchmark\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#benchmark\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Benchmark</h2>\n<p>SDSKV can be compiled with <code>--enable-benchmark</code>\
    \ (or <code>+benchmark</code> in Spack). In this case,\nSDSKV requires the JsonCPP\
    \ and MPI dependencies (when compiling manually, use <code>CXX=mpicxx</code> in\n\
    your configure step, for example), and it will build and install the <code>sdskv-benchmark</code>\
    \ program.</p>\n<p>This program is an MPI program that reads a JSON file describing\
    \ a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server.\
    \ Other ranks act as clients, all executing\nthis access pattern.</p>\n<p>The\
    \ following is an example of a JSON file.</p>\n<div class=\"highlight highlight-source-json\"\
    ><pre>{\n\t<span class=\"pl-ent\">\"protocol\"</span> : <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span\
    \ class=\"pl-ent\">\"seed\"</span> : <span class=\"pl-c1\">0</span>,\n\t<span\
    \ class=\"pl-ent\">\"server\"</span> : {\n\t\t<span class=\"pl-ent\">\"use-progress-thread\"\
    </span> : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-ent\">\"rpc-thread-count\"\
    </span> : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-ent\">\"database\"\
    </span> : {\n\t\t\t<span class=\"pl-ent\">\"type\"</span> : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\">\"</span></span>,\n\
    \t\t\t<span class=\"pl-ent\">\"name\"</span> : <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t\
    <span class=\"pl-ent\">\"path\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/dev/shm<span class=\"pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span\
    \ class=\"pl-ent\">\"benchmarks\"</span> : [\n\t{\n\t\t<span class=\"pl-ent\"\
    >\"type\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span\
    \ class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-ent\">\"repetitions\"\
    </span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-ent\">\"num-entries\"\
    </span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-ent\">\"key-sizes\"\
    </span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span> ],\n\
    \t\t<span class=\"pl-ent\">\"val-sizes\"</span> : [ <span class=\"pl-c1\">24</span>,\
    \ <span class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-ent\">\"erase-on-teardown\"\
    </span> : <span class=\"pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-ent\"\
    >\"type\"</span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>get<span\
    \ class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-ent\">\"repetitions\"\
    </span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-ent\">\"num-entries\"\
    </span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-ent\">\"key-sizes\"\
    </span> : <span class=\"pl-c1\">64</span>,\n\t\t<span class=\"pl-ent\">\"val-sizes\"\
    </span> : <span class=\"pl-c1\">128</span>,\n\t\t<span class=\"pl-ent\">\"erase-on-teardown\"\
    </span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n<p>The JSON\
    \ file starts with the protocol to use, and a seed for the random-number generator\
    \ (RNG).\nThe actual seed used on each rank will actually be a function of this\
    \ global seed and the rank of\nthe client. The RNG will be reset with this seed\
    \ after each benchmark.</p>\n<p>The <code>server</code> field sets up the provider\
    \ and the database. Database types can be <code>map</code>, <code>ldb</code>,\
    \ or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which\
    \ is a list of benchmarks to execute. Each benchmark is composed\nof three steps.\
    \ A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em>\
    \ phase. The setup phase may for\nexample store a bunch of keys in the database\
    \ that the execution phase will read by (in the case of a\n<em>get</em> benchmark,\
    \ for example). The teardown phase will usually remove all the keys that were\
    \ written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n\
    <p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>,\
    \ <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n\
    <code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>),\
    \ and a number of repetitions. The benchmark will be\nexecuted as many times as\
    \ requested (without resetting the RNG in between repetitions). Taking the\nexample\
    \ of the <code>put</code> benchmark above, each repetition will put 30 key/value\
    \ pairs into the database.\nThe key size will be chosen randomly in a uniform\
    \ manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size\
    \ will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded).\
    \ Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI\
    \ barrier between clients is executed in between each benchmark and in between\
    \ the setup,\nexecution, and teardown phases, so that the execution phase is always\
    \ executed at the same time\non all the clients. Once all the repetitions are\
    \ done for a given benchmark entry, the program\nwill report statistics on the\
    \ timings: average time, variance, standard deviation, mininum, maximum,\nmedian,\
    \ first and third quartiles. Note that these times are for a repetition, not for\
    \ single operations\nwithin a repetition. To get the timing of each individual\
    \ operation, it is then necessary to divide\nthe times by the number of key/value\
    \ pairs involved in the benchmark.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1635867720.0
mochi-hpc/mochi-thallium:
  data_format: 2
  description: Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and
    providing an object-oriented way to use these libraries.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-thallium
  latest_release: v0.12.0
  readme: '<h1><a id="user-content-thallium" class="anchor" aria-hidden="true" tabindex="-1"
    href="#thallium"><span aria-hidden="true" class="octicon octicon-link"></span></a>Thallium</h1>

    <p>Thallium is a C++ interface to <a href="https://github.com/mochi-hpc/mochi-margo/">Margo</a>.

    It offers a modern, object-oriented way of developing HPC data services. More

    information can be found on <a href="https://mochi.readthedocs.io/en/latest/"
    rel="nofollow">Mochi''s readthedocs</a>

    website.</p>

    '
  stargazers_count: 10
  subscribers_count: 4
  topics: []
  updated_at: 1685720588.0
mochi-hpc/py-mochi-bake:
  data_format: 2
  description: Python wrapper for BAKE
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-bake
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1633975348.0
mochi-hpc/py-mochi-s4m:
  data_format: 2
  description: Python library using Mochi to broadcast data
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-s4m
  latest_release: null
  readme: '<h1><a id="user-content-mochi-s4m-share-for-me" class="anchor" aria-hidden="true"
    tabindex="-1" href="#mochi-s4m-share-for-me"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Mochi S4M (Share for Me)</h1>

    <p>This service provides a simple non-blocking broadcast/receive

    mechanism based on Mochi.</p>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <p>Make sure you have <a href="https://spack.io/" rel="nofollow">spack</a> installed
    and setup.

    If needed, install it and set it up as follows:</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>You then need to clone the <code>mochi-spack-packages</code> repository

    and make it available to spack:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Finally, you can install S4M as follows:</p>

    <pre><code>$ spack install py-mochi-s4m

    </code></pre>

    <h2><a id="user-content-using" class="anchor" aria-hidden="true" tabindex="-1"
    href="#using"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using</h2>

    <p>S4M has a very simple API consisting of an <code>S4MService</code> class with

    two functions: <code>broadcast</code>, and <code>receive</code>. It requires mpi4py
    to

    bootstrap the set of processes. The <a href="test/test.py">test.py</a> file

    provides a comprehensive use case.</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1663070268.0
mochi-hpc/py-mochi-sonata:
  data_format: 2
  description: Python binding to the Mochi Sonata microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-sonata
  latest_release: null
  readme: '<p>Py-Sonata is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-sonata">Sonata
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975502.0
mpbelhorn/olcf-spack:
  data_format: 2
  description: Spack fork used on OLCF resources
  filenames:
  - share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml
  - share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  full_name: mpbelhorn/olcf-spack
  latest_release: null
  readme: "<h1><a id=\"user-content--spack\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\"\
    \ href=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    ><img src=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\
    \ width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\"\
    \ style=\"max-width: 100%;\"></a> Spack</h1>\n<p><a href=\"https://github.com/spack/spack/actions\"\
    ><img src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\"\
    \ alt=\"Unit Tests\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\
    ><img src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\"\
    \ alt=\"Bootstrapping\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions?query=workflow%3A%22macOS+builds+nightly%22\"\
    ><img src=\"https://github.com/spack/spack/workflows/macOS%20builds%20nightly/badge.svg?branch=develop\"\
    \ alt=\"macOS Builds (nightly)\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/70b0104a5a00f472f39f523bb50f576c7d5456c58b0068304f1ecd8e5054ae8c/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/fca79013ca8059644742ad2936823670fa01342c0e60d57949ee69f693dccde3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://slack.spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/e8580758c789c07a64e14287a71a75290dcddc6fee61b8a2e64f07bf7dca1ec9/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\"\
    \ alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"\
    max-width: 100%;\"></a></p>\n<p>Spack is a multi-platform package manager that\
    \ builds and installs\nmultiple versions and configurations of software. It works\
    \ on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing\
    \ a\nnew version of a package does not break existing installations, so many\n\
    configurations of the same package can coexist.</p>\n<p>Spack offers a simple\
    \ \"spec\" syntax that allows users to specify versions\nand configuration options.\
    \ Package files are written in pure Python, and\nspecs allow package authors to\
    \ write a single script for many different\nbuilds of the same package.  With\
    \ Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n\
    <p>See the\n<a href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"\
    nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install\
    \ spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$\
    \ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd\
    \ spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2><a id=\"user-content-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p><a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a>\
    \ is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n\
    <p>For a cheat sheet on Spack syntax, run <code>spack help --spec</code>.</p>\n\
    <h2><a id=\"user-content-tutorial\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#tutorial\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Tutorial</h2>\n<p>We maintain a\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\"\
    \ rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to\
    \ advanced usage, packaging, developer features, and large HPC\ndeployments. \
    \ You can do all of the exercises on your own laptop using a\nDocker container.</p>\n\
    <p>Feel free to use these materials to teach users at your organization\nabout\
    \ Spack.</p>\n<h2><a id=\"user-content-community\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#community\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Community</h2>\n<p>Spack is an open source project.\
    \  Questions, discussion, and\ncontributions are welcome. Contributions can be\
    \ anything from new\npackages to bugfixes, documentation, or even new core features.</p>\n\
    <p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\"\
    \ rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, visit <a href=\"\
    https://slack.spack.io\" rel=\"nofollow\">slack.spack.io</a>.</li>\n<li>\n<strong>Mailing\
    \ list</strong>: <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\"\
    >groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>: <a\
    \ href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure\
    \ to\n<code>@mention</code> us!</li>\n</ul>\n<h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n\
    <p>Contributing to Spack is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\"\
    >pull request</a>.\nWhen you send your request, make <code>develop</code> the\
    \ destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack\
    \ repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation\
    \ tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"\
    nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with our CI process.\
    \ To run these tests locally, and for\nhelpful tips on git, see our\n<a href=\"\
    https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\
    >Contribution Guide</a>.</p>\n<p>Spack's <code>develop</code> branch has the latest\
    \ contributions. Pull requests\nshould target <code>develop</code>, and users\
    \ who want the latest package versions,\nfeatures, etc. can use <code>develop</code>.</p>\n\
    <h2><a id=\"user-content-releases\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#releases\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Releases</h2>\n<p>For multi-user site deployments or other use cases\
    \ that need very stable\nsoftware installations, we recommend using Spack's\n\
    <a href=\"https://github.com/spack/spack/releases\">stable releases</a>.</p>\n\
    <p>Each Spack release series also has a corresponding branch, e.g.\n<code>releases/v0.14</code>\
    \ has <code>0.14.x</code> versions of Spack, and <code>releases/v0.13</code> has\n\
    <code>0.13.x</code> versions. We backport important bug fixes to these branches\
    \ but\nwe do not advance the package versions or make other changes that would\n\
    change the way Spack concretizes dependencies within a release branch.\nSo, you\
    \ can base your Spack deployment on a release branch and <code>git pull</code>\n\
    to get fixes, without the package churn that comes with <code>develop</code>.</p>\n\
    <p>The latest release is always available with the <code>releases/latest</code>\
    \ tag.</p>\n<p>See the <a href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\"\
    \ rel=\"nofollow\">docs on releases</a>\nfor more details.</p>\n<h2><a id=\"user-content-code-of-conduct\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#code-of-conduct\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Code of\
    \ Conduct</h2>\n<p>Please note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"\
    ><strong>Code of Conduct</strong></a>. By participating in\nthe Spack community,\
    \ you agree to abide by its rules.</p>\n<h2><a id=\"user-content-authors\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#authors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>Many thanks\
    \ go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\"\
    >contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\"\
    >tgamblin@llnl.gov</a>.</p>\n<h3><a id=\"user-content-citing-spack\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Citing Spack</h3>\n<p>If you\
    \ are referencing Spack in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee,\n\
    Adam Moody, Bronis R. de Supinski, and W. Scott Futral.\n<a href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\"\
    \ rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software\
    \ Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas,\
    \ November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>Spack is distributed under the terms of both the MIT license and the\nApache\
    \ License (Version 2.0). Users may choose either license, at their\noption.</p>\n\
    <p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n\
    <p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n\
    <a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>,\
    \ and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a>\
    \ for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1580743748.0
mpbelhorn/olcf-spack-environments:
  data_format: 2
  description: Spack environments for OLCF resources.
  filenames:
  - hosts/frontier/envs/base/spack.yaml
  - hosts/peak/envs/base/spack.yaml
  - hosts/ascent/envs/base-rh7/spack.yaml
  - hosts/borg/envs/base/spack.yaml
  - hosts/summit/envs/base/spack.yaml
  - hosts/ascent/envs/base/spack.yaml
  full_name: mpbelhorn/olcf-spack-environments
  latest_release: null
  readme: '<h1><a id="user-content-olcf-spack-environments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#olcf-spack-environments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>OLCF Spack Environments</h1>

    <p>This repo contains the infrastructure and environment definitions to deploy

    site-provided software on OLCF resources via Spack environments.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started</h2>

    <p>Clone this repo and it''s facility-modified spack fork somewhere on an OLCF

    filesystem:</p>

    <pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git

    </code></pre>

    <p>or</p>

    <pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments

    </code></pre>

    <p>Next, initialize spack and the build environment. This is done by calling</p>

    <pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base
    . ./init-facility-spack.sh

    </code></pre>

    <p>This will configure the spack build- and run-time environment build and install

    the facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this
    repo for the

    current machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both
    of these

    variables are optional. If omitted, each variable will take on their default

    values:</p>

    <pre><code>FACSPACK_MY_ENVS="/sw/${_THIS_HOST}/spack-envs"

    FACSPACK_ENV_NAME="base"

    </code></pre>

    <p>such that sourcing this script by itself</p>

    <pre><code>. ./init-facility-spack.sh

    </code></pre>

    <p>will setup the runtime shell environment to manipulate the production spack

    environment on the current system.</p>

    <p>This repo will always track at least one spack environment per machine named

    <code>base</code> which is the complete standard software environment used in
    production

    for that machine. Furthermore, only the user account with owner permissions on

    the production environment may be used to manipulate it in the default

    <code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent
    multiple

    users from concurrently modifying the production environment. Users may set an

    alternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using
    any

    tracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file
    in this repo.</p>

    <p>From these variables, a unique path per each environment name will be

    constructed:</p>

    <pre><code>FACSPACK_ENV="${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}"

    </code></pre>

    <p>The value of <code>${_THIS_HOST}</code> is determined automatically from the
    hostname on

    which the init script is being run. For each system and environment tracked in

    this repo that you wish to work on, ensure that the final expanded value of

    <code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>

    <p>Configuration paths in our <code>spack.yaml</code> environments that are not
    fixed to

    universal values are expressed in terms of relative paths to either the spack

    instance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.

    These paths are referenced in the <code>spack.yaml</code> files via environment
    variables

    set by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code>
    environment files to

    define portable and relocatable spack environments which can be re-deployed in

    arbitrary private locations by any users without needing to modify the

    environment file.</p>

    <p>The following variables are exported in Spack''s runtime environment by

    <code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code>
    the enviornment

    files tracked in this repo.</p>

    <ul>

    <li>

    <code>${FACSPACK_ENV}</code>:

    Path to where spack environment will be installed. Contains subdirs <code>opt</code>

    and <code>modules</code>.</li>

    <li>

    <code>${FACSPACK_ENV_MODULEROOT}</code>:

    Shortcut to <code>${FACSPACK_ENV}/modules</code> under which static and

    spack-generated modules are generated. Contains subdirectories <code>spack</code>,

    <code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static
    modulefiles

    respectively.</li>

    <li>

    <code>${FACSPACK_CONF_COMMON}</code>:

    Path to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>

    <li>

    <code>${FACSPACK_CONF_HOST}</code>:

    Path to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>

    </li>

    </ul>

    <p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>

    files which cannot de-reference environment variables. These affect</p>

    <ul>

    <li>Mirrors</li>

    <li>Extensions</li>

    </ul>

    <p>Spack does not internally expand environment variables in the configuration
    of

    these items so they must be expressed as hard-coded full path strings. The

    default values in this repo should point to permanent world-readable paths on

    the OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>

    <h2><a id="user-content-spack-fork" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-fork"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Fork</h2>

    <p>The upstream development branch of spack is not used directly. Instead, the
    OLCF

    has implemented some customizations that are tracked in the "olcf-X.Y.Z"

    branches of a <a href="https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0">facility
    fork of spack</a>

    where <code>X.Y.Z</code> refers to the tagged release of upstream spack from which
    the

    OLCF-modified branch is forked.</p>

    '
  stargazers_count: 4
  subscribers_count: 2
  topics: []
  updated_at: 1704744678.0
okanteh24/msds_hpc:
  data_format: 2
  description: null
  filenames:
  - classes/04_2/spack_containers/spack.yaml
  full_name: okanteh24/msds_hpc
  latest_release: null
  readme: '<h1><a id="user-content-ds-7347-high-performance-computing-hpc-and-data-science"
    class="anchor" aria-hidden="true" tabindex="-1" href="#ds-7347-high-performance-computing-hpc-and-data-science"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>DS 7347 High-Performance
    Computing (HPC) and Data Science</h1>

    <h2><a id="user-content-assignments" class="anchor" aria-hidden="true" tabindex="-1"
    href="#assignments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Assignments</h2>

    <table>

    <thead>

    <tr>

    <th align="left">Key</th>

    <th align="left">Value</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="left">A</td>

    <td align="left">Assignment</td>

    </tr>

    <tr>

    <td align="left">L</td>

    <td align="left">Lab</td>

    </tr>

    <tr>

    <td align="left">P</td>

    <td align="left">Project</td>

    </tr>

    </tbody>

    </table>

    <table>

    <thead>

    <tr>

    <th align="left">Assignment</th>

    <th align="left">Issued</th>

    <th align="left">Due</th>

    <th align="left">Deliverable</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="left">A1</td>

    <td align="left">04-26</td>

    <td align="left">NA</td>

    <td align="left">Fork class repo.</td>

    </tr>

    <tr>

    <td align="left">A2</td>

    <td align="left">04-28</td>

    <td align="left">05-03</td>

    <td align="left"><code>assignments/assignment_02.md</code></td>

    </tr>

    <tr>

    <td align="left">A3</td>

    <td align="left">05-05</td>

    <td align="left">NA</td>

    <td align="left">Detail the CPU, GPU, memory, and hard drive for your own computer.</td>

    </tr>

    <tr>

    <td align="left">A4.1</td>

    <td align="left">05-10</td>

    <td align="left">05-17</td>

    <td align="left"><code>assignments/assignment_04.sh</code></td>

    </tr>

    <tr>

    <td align="left">L1</td>

    <td align="left">05-12</td>

    <td align="left">05-19</td>

    <td align="left"><code>assignments/lab_01.{yaml,md}</code></td>

    </tr>

    <tr>

    <td align="left">A4.2</td>

    <td align="left">05-17</td>

    <td align="left">05-24</td>

    <td align="left"><code>assignments/assignment_04.dockerfile</code></td>

    </tr>

    <tr>

    <td align="left">L2</td>

    <td align="left">05-19</td>

    <td align="left">05-26</td>

    <td align="left"><code>assignments/lab_02.{dockerfile,png,jpg}</code></td>

    </tr>

    <tr>

    <td align="left">A5.1</td>

    <td align="left">05-24</td>

    <td align="left">05-31</td>

    <td align="left"><code>assignments/assignment_05.out</code></td>

    </tr>

    <tr>

    <td align="left">P1</td>

    <td align="left">05-26</td>

    <td align="left">06-02</td>

    <td align="left"><code>project/proposal.md</code></td>

    </tr>

    <tr>

    <td align="left">L3</td>

    <td align="left">06-07</td>

    <td align="left">06-21</td>

    <td align="left"><code>assignments/lab_03.{yaml,sh,make or cmake}</code></td>

    </tr>

    <tr>

    <td align="left">P2</td>

    <td align="left">06-09</td>

    <td align="left">06-16</td>

    <td align="left">Create new GitHub repo from project template.</td>

    </tr>

    <tr>

    <td align="left">P3</td>

    <td align="left">06-16</td>

    <td align="left">06-21</td>

    <td align="left">Prototype of multi-job Slurm submit script.</td>

    </tr>

    <tr>

    <td align="left">A5.2</td>

    <td align="left">06-21</td>

    <td align="left">06-23</td>

    <td align="left"><code>assignments/assignment_05.txt</code></td>

    </tr>

    <tr>

    <td align="left">P4</td>

    <td align="left">06-23</td>

    <td align="left">06-28</td>

    <td align="left">Implement one subtask of your workflow using "easiest" installation
    path.</td>

    </tr>

    <tr>

    <td align="left">P5</td>

    <td align="left">06-30</td>

    <td align="left">NA</td>

    <td align="left">Explore various file formats for your data and compare performance.</td>

    </tr>

    <tr>

    <td align="left">P6</td>

    <td align="left">07-05</td>

    <td align="left">07-12</td>

    <td align="left">Complete non-optimized and basic workflow, reduce data or analysis
    complexity if needed.</td>

    </tr>

    <tr>

    <td align="left">P7</td>

    <td align="left">07-14</td>

    <td align="left">07-19</td>

    <td align="left">Report three targets for optimization and baseline performance</td>

    </tr>

    <tr>

    <td align="left">P8</td>

    <td align="left">07-19</td>

    <td align="left">07-28</td>

    <td align="left">Implement initial improvements for your three optimization targets</td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1658639789.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - linux-centos7-broadwell/or-slurm/spack.yaml
  - linux-rhel8-ppc64le/summit/spack.yaml
  - linux-sles15-zen2/spock/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_environments.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2><a id="user-content-purpose" class="anchor" aria-hidden="true" tabindex="-1"
    href="#purpose"><span aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 5
  subscribers_count: 20
  topics: []
  updated_at: 1705687927.0
openPMD/openPMD-api:
  data_format: 2
  description: ':floppy_disk: C++ & Python API for Scientific I/O'
  filenames:
  - spack.yaml
  full_name: openPMD/openPMD-api
  latest_release: 0.15.2
  readme: "<h1><a id=\"user-content-c--python-api-for-scientific-io-with-openpmd\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#c--python-api-for-scientific-io-with-openpmd\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ &amp;\
    \ Python API for Scientific I/O with openPMD</h1>\n<p><a href=\"https://github.com/openPMD/openPMD-standard/releases\"\
    ><img src=\"https://camo.githubusercontent.com/5d13f841c93684a76b33b3bfea77f0972f8d14291c5180eac269e1cad9dc341c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\"\
    \ alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d0fc2114159b7b68214de4f99a704161635ae9a5f2500903a0735598634331a5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/ff7083cc261bcd9f3693e400b5c5ab2bc0c7e24d7b0b456ffe7b34ee19af0e1f/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\"\
    \ alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"\
    https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"\
    max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/20a8ccdee703984a1e590f3213ce07587f7467115d7742291cd7d77b254707bf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b7df96f0665c4aeee252301c6cdaf28fa395ee36730464abaa93956ccf5544f4/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/66b24447775c3b5b6d1fb8a72efa1a837bd07012711189a76c944b2943a1d83b/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\"\
    \ alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a4d2f864cd8cc403a0a9af3b8a008fccdbe8b3476c8d39a02ecda3097212cdcb/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/502c10b6946e49f3d3a5758800dc5e01cb40a0c4cc5ea8bb17a9e2471c98e327/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f687ccda5d5e831448209e00847229d69a109d4d0c9d0f24ef2c19fd1c50fe7/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\"\
    \ alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c4197235edfc513c73649de993970af6f8067123ce78821c0249dd0c6747ed9c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\"\
    \ alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\
    ><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\"\
    \ alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5420d1b718d3805a368c5cd2a9c33e294819c7235e8e533d3b8f1b2b2bc6c4b4/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\"\
    \ alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5348e1f24701566268367aea654dee73cbea5ea91b3d94819085fd552dff34b5/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\"\
    \ alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD is an open meta-data schema\
    \ that provides meaning and self-description for data sets in science and engineering.\n\
    See <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a>\
    \ for details of this schema.</p>\n<p>This library provides a reference API for\
    \ openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable,\
    \ hierarchical file formats, this library implements various backends such as\
    \ HDF5, ADIOS2 and JSON.\nWriting &amp; reading through those backends and their\
    \ associated files are supported for serial and <a href=\"https://www.mpi-forum.org/docs/\"\
    \ rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#usage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <h3><a id=\"user-content-c\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#c\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++</h3>\n\
    <p><a href=\"https://isocpp.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b4039af8871849eff8d3350af5ac6e8f02048d6dc71ce1e941b5ab9f219325ea/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\"\
    \ alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span>\
    \ s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span\
    \ class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"\
    pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>\
    \ &amp; [step, it] : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span>\
    \ &lt;&lt; step &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span\
    \ class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\"\
    >const</span> &amp; [name, mesh] : it.<span class=\"pl-smi\">meshes</span> ) {\n\
    \        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\
    \  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; name &lt;&lt; <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\"\
    >\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\"\
    >for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp;\
    \ val : mesh.<span class=\"pl-c1\">attributes</span>() )\n            std::cout\
    \ &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"\
    pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\
    \    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span>\
    \ <span class=\"pl-k\">const</span> &amp; [name, species] : it.<span class=\"\
    pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"\
    </span></span> &lt;&lt; name &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\"\
    >auto</span> <span class=\"pl-k\">const</span>&amp; val : species.<span class=\"\
    pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt;\
    \ val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n\
    <h3><a id=\"user-content-python\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#python\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Python</h3>\n<p><a href=\"https://www.python.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/e751dc39d18bc7613b561655f2f3551a2c999fc64fb85aeda826e0351492e168/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\"\
    \ alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span>\
    \ <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"\
    pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span\
    \ class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\"\
    >io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\
    \n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"\
    pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span\
    \ class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n  \
    \  <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\
    \n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span\
    \ class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n\
    \        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}'\
    \ attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\"\
    >k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"\
    pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span\
    \ class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span\
    \ class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"\
    pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"\
    pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n  \
    \          <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n\
    <h3><a id=\"user-content-more\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#more\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>More!</h3>\n<p>Curious?\nOur manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\"\
    \ rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n\
    <h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Dependencies</h2>\n<p>Required:</p>\n<ul>\n<li>CMake\
    \ 3.15.0+</li>\n<li>C++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+,\
    \ icpc 19+, icpx</li>\n</ul>\n<p>Shipped internally in <code>share/openPMD/thirdParty/</code>:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> 2.13.10+\
    \ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\">BSL-1.0</a>)</li>\n\
    <li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> 2.11.1+ (<a\
    \ href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)</li>\n\
    <li>\n<a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a> 3.9.1+ (<a\
    \ href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\">MIT</a>)</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> 3.7.1+ (<a href=\"\
    https://github.com/ToruNiina/toml11/blob/master/LICENSE\">MIT</a>)</li>\n</ul>\n\
    <p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\"\
    \ rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\"\
    \ rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either\
    \ with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n\
    </ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python\
    \ 3.8 - 3.12</li>\n<li>pybind11 2.11.1+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py\
    \ 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n\
    <li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n<li>CUDA C++\
    \ (optional, currently used only in tests)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/132ae648808a03cbf50ea3f9834f3e797f087ad259ebdc21b8d94804f9f57700/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fd019b54503cfc07bcb5b636086070bf8a09e73e1f88653a551cd3f47231df28/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/4c10ad19fca3dd28135f3b21f3e7a9950dad57fbb3d4c9f90d8d369aafd757e1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d5db8554037acd8a410130359282ed8e0ba8e5c6d4ec232b6898667459d763b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/33b82ea6e40ffa2127d4e4e0fcd64e8aa96692b222c51bf6f93e1996dac79b21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\"\
    \ alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our community loves to help each other.\n\
    Please <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\"\
    >report installation problems</a> in case you should get stuck.</p>\n<p>Choose\
    \ <em>one</em> of the install methods below to get started:</p>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://spack.io\" rel=\"nofollow\">Spack</a></h3>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/942d8d86fcbe5f3670631c12617a3d205a84acb9304609abfa364280d96d8588/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\"\
    \ alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/7b52f21df7ad363012112cd9c32c25dd554bd25cac3c84c92a04c6207274acd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b376c2ae3f321777bb8b0dd09bce8bf2340611f6c0eb2ce8207323e0fab04f20/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\"\
    \ alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \    +python -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack load\
    \ openpmd-api</pre></div>\n<h3><a id=\"user-content-conda\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#conda\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a></h3>\n\
    <p><a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img\
    \ src=\"https://camo.githubusercontent.com/6fe3005c57558bc59b43aa7228a48663428f0dd49c264d35af536f6d052b12b3/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6445f5e527792585ad3b382fce8128892407ba1bb5af6508af00abd8ccf08cfd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/502a7a44785416f67a8fb94dbc02547a993fb42195f308e821661c28319060ad/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \           OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\n\
    conda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n\
    <h3><a id=\"user-content-brew\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#brew\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"https://brew.sh\" rel=\"nofollow\">Brew</a></h3>\n<p><a\
    \ href=\"https://github.com/openPMD/homebrew-openPMD\"><img src=\"https://camo.githubusercontent.com/5ef9bc9e32e5b1966642b44b62543b570d72da9d2583fea7b32cae6fce75495d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\"\
    \ alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7b52f21df7ad363012112cd9c32c25dd554bd25cac3c84c92a04c6207274acd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/d44878e96acfad216c259071aaeb3dc3a3abc44a9cdf5d12c5fce6d07e4c1762/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\"\
    \ alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<h3><a id=\"\
    user-content-pypi\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #pypi\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a></h3>\n<p><a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9401a82878058d507a0199407fc2722229b0bf78eb31fdeaa054bd881d0bc769/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\"\
    \ alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6445f5e527792585ad3b382fce8128892407ba1bb5af6508af00abd8ccf08cfd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8feb288d963f4caa697d0b3b5182e71edbf4106ae4bcc66ce0dd1921cba5c6f6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\"\
    \ alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/24f7c205d4b2824ef9506cc27543baa4d040b9a7c0e91355d7da11fc17b74c17/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\"\
    \ alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9)\
    \ or on exotic processor architectures, this install method <em>compiles from\
    \ source</em> against the found installations of HDF5, ADIOS2, and/or MPI (in\
    \ system paths, from other package managers, or loaded via a module system, ...).</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> optional:                   --user</span>\npython3\
    \ -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n\
    <p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional:                                    --user</span>\npython3\
    \ -m pip install -U pip packaging setuptools wheel\npython3 -m pip install -U\
    \ cmake\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:      \
    \                                                             --user</span>\n\
    openPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n\
    <p>For some exotic architectures and compilers, you might need to disable a compiler\
    \ feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\"\
    \ rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter\
    \ linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                               \
    \                 --user</span>\npython3 -m pip install openpmd-api --no-binary\
    \ openpmd-api</pre></div>\n<p>Additional CMake options can be passed via individual\
    \ environment variables, which need to be prefixed with <code>openPMD_CMAKE_</code>.</p>\n\
    <h3><a id=\"user-content-from-source\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#from-source\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>From Source</h3>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/e35be8f08546231b86c7e9290cb559ec981380d6cb27512296820d120f233eeb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\"\
    \ alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD-api can also be built and installed\
    \ from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\
    \nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests,\
    \ with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which\
    \ python3)</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\"\
    >.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\n\
    ctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required\
    \ for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target\
    \ install</pre></div>\n<p>The following options can be added to the <code>cmake</code>\
    \ call to control features.\nCMake controls options with prefixed <code>-D</code>,\
    \ e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n\
    <td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n\
    <td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code\
    \ <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro\
    \ independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_INSTALL_RPATH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Add RPATHs to installed binaries</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n\
    <td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n\
    </table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n\
    <sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without\
    \ specific cause is highly discouraged</em></p>\n<p>Additionally, the following\
    \ libraries are shipped internally.\nThe following options allow to switch to\
    \ external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n\
    <th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.10+</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>pybind11</td>\n<td>2.11.1+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_TOML11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>toml11</td>\n<td>3.7.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this\
    \ will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and\
    \ installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code>\
    \ to the <code>cmake</code> command.\nYou can only build a static or a shared\
    \ library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\n\
    In order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code>\
    \ to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and\
    \ command line tools are built.\nIn order to skip building those, pass <code>OFF</code>\
    \ to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_CUDA_EXAMPLES</code></td>\n<td>ON/<strong>OFF</strong>\n\
    </td>\n<td>Use CUDA in examples</td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-linking-to-your-project\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#linking-to-your-project\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Linking to your project</h2>\n<p>The install will\
    \ contain header files and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n\
    <h3><a id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>CMake</h3>\n<p>If your project is using CMake for its build, one can\
    \ conveniently use our provided <code>openPMDConfig.cmake</code> package, which\
    \ is installed alongside the library.</p>\n<p>First set the following environment\
    \ hint if openPMD-api was <em>not</em> installed in a system path:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional: only needed if installed outside of system paths</span>\n\
    <span class=\"pl-k\">export</span> CMAKE_PREFIX_PATH=<span class=\"pl-smi\">$HOME</span>/somepath:<span\
    \ class=\"pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n<p>Use the following\
    \ lines in your project's <code>CMakeLists.txt</code>:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ supports:                       COMPONENTS MPI NOMPI HDF5 ADIOS2</span>\nfind_package(openPMD\
    \ 0.15.0 CONFIG)\n\n<span class=\"pl-k\">if</span>(openPMD_FOUND)\n    <span class=\"\
    pl-c1\">target_link_libraries</span>(YourTarget <span class=\"pl-k\">PRIVATE</span>\
    \ openPMD::openPMD)\n<span class=\"pl-k\">endif</span>()</pre></div>\n<p><em>Alternatively</em>,\
    \ add the openPMD-api repository source directly to your project and use it via:</p>\n\
    <div class=\"highlight highlight-source-cmake\"><pre><span class=\"pl-c1\">add_subdirectory</span>(<span\
    \ class=\"pl-s\">\"path/to/source/of/openPMD-api\"</span>)\n\n<span class=\"pl-c1\"\
    >target_link_libraries</span>(YourTarget <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n\
    <p>For development workflows, you can even automatically download and build openPMD-api\
    \ from within a depending CMake project.\nJust replace the <code>add_subdirectory</code>\
    \ call with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"\
    pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077\
    \ <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_SHARED_LIBS\
    \ <span class=\"pl-k\">OFF</span>)  <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> precedence over BUILD_SHARED_LIBS if needed</span>\nset(openPMD_INSTALL\
    \ <span class=\"pl-c1\">OFF</span>)            <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> or instead use:</span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> set(openPMD_INSTALL ${BUILD_SHARED_LIBS})  # only install if used as\
    \ a shared library</span>\nset(openPMD_USE_PYTHON <span class=\"pl-c1\">OFF</span>)\n\
    FetchContent_Declare(openPMD\n  GIT_REPOSITORY <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"\
    </span>\n  GIT_TAG        <span class=\"pl-s\">\"0.15.0\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n\
    <h3><a id=\"user-content-manually\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#manually\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Manually</h3>\n<p>If your (Linux/OSX) project is build by calling\
    \ the compiler directly or uses a manually written <code>Makefile</code>, consider\
    \ using our <code>openPMD.pc</code> helper file for <code>pkg-config</code>, which\
    \ are installed alongside the library.</p>\n<p>First set the following environment\
    \ hint if openPMD-api was <em>not</em> installed in a system path:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional: only needed if installed outside of system paths</span>\n\
    <span class=\"pl-k\">export</span> PKG_CONFIG_PATH=<span class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span\
    \ class=\"pl-smi\">$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and\
    \ compiler flags for your project are available via:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ switch to check if openPMD-api was build as static library</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> (via BUILD_SHARED_LIBS=OFF) or as shared\
    \ library (default)</span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config\
    \ --variable=static openPMD<span class=\"pl-pds\">)</span></span><span class=\"\
    pl-pds\">\"</span></span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>true<span class=\"pl-pds\">\"</span></span> ]\n\
    <span class=\"pl-k\">then</span>\n    pkg-config --libs --static openPMD\n   \
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib\
    \ -lopenPMD -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so\
    \ /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config\
    \ --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib\
    \ -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n\
    <h2><a id=\"user-content-author-contributions\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#author-contributions\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Author Contributions</h2>\n<p>openPMD-api\
    \ is developed by many people.\nIt was initially started by the <a href=\"https://hzdr.de/crp\"\
    \ rel=\"nofollow\">Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\
    >libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\"\
    \ rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"\
    https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe\
    \ following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\
    >contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\"\
    >Axel Huebl (LBNL, previously HZDR)</a>:\nproject lead, releases, documentation,\
    \ automated CI/CD, Python bindings, Dask, installation &amp; packaging, prior\
    \ reference implementations</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\"\
    >Franz Poeschel (CASUS)</a>:\nJSON &amp; ADIOS2 backend, data staging/streaming,\
    \ reworked class design</li>\n<li>\n<a href=\"https://github.com/C0nsultant\"\
    >Fabian Koller (HZDR)</a>:\ninitial library design and implementation with HDF5\
    \ &amp; ADIOS1 backend</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu\
    \ (LBNL)</a>:\nnon-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n\
    </ul>\n<p>Maintained by the following research groups:</p>\n<ul>\n<li>\n<a href=\"\
    https://www.casus.science/casus/team/\" rel=\"nofollow\">Computational Radiation\
    \ Physics (CRD)</a> at CASUS/HZDR, led by <a href=\"https://github.com/bussmann\"\
    >Michael Bussmann</a>\n</li>\n<li>\n<a href=\"https://atap.lbl.gov/accelerator-modeling-program/\"\
    \ rel=\"nofollow\">Accelerator Modeling Program (AMP)</a> at LBNL, led by <a href=\"\
    https://github.com/jlvay\">Jean-Luc Vay</a>\n</li>\n<li>\n<a href=\"https://crd.lbl.gov/divisions/scidata/sdm/\"\
    \ rel=\"nofollow\">Scientific Data Management (SDM)</a> at LBNL, led by <a href=\"\
    https://github.com/john18\">Kesheng (John) Wu</a>\n</li>\n</ul>\n<p>Further thanks\
    \ go to improvements and contributions from:</p>\n<ul>\n<li>\n<a href=\"https://github.com/CFGrote\"\
    >Carsten Fortmann-Grote (EU XFEL GmbH, now MPI-EvolBio)</a>:\ndraft of our Python\
    \ unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\">Dominik\
    \ Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n\
    <li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\n\
    support on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\"\
    >James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"\
    https://github.com/psychocoderHPC\">Ren\xE9 Widera (HZDR)</a>:\ndesign improvements\
    \ for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\"\
    >Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n\
    <a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation\
    \ improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\xE9\
    mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n\
    <a href=\"https://github.com/LDAmorim\">L\xEDgia Diana Amorim (LBNL)</a>:\npackage\
    \ integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\"\
    >Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"\
    https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing,\
    \ documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\"\
    >Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"\
    https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask prototyping\
    \ &amp; ADIOS2 benchmarking</li>\n<li>\n<a href=\"https://github.com/jakirkham\"\
    >John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n<li>\n<a href=\"\
    https://github.com/eschnett\">Erik Schnetter (PITP)</a>:\nC++ API bug fixes</li>\n\
    <li>\n<a href=\"https://github.com/jeanbez\">Jean Luca Bez (LBNL)</a>:\nHDF5 performance\
    \ tuning</li>\n<li>\n<a href=\"https://github.com/bernhardmgruber\">Bernhard Manfred\
    \ Gruber (CERN)</a>:\nCMake fix for parallel HDF5</li>\n<li>\n<a href=\"https://github.com/DerNils-git\"\
    >Nils Schild (IPP)</a>:\nCMake improvements for subprojects</li>\n</ul>\n<h3><a\
    \ id=\"user-content-grants\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#grants\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Grants</h3>\n<p>The openPMD-api authors acknowledge support via the\
    \ following programs.\nSupported by the CAMPA collaboration, a project of the\
    \ U.S. Department of Energy, Office of Science, Office of Advanced Scientific\
    \ Computing Research and Office of High Energy Physics, Scientific Discovery through\
    \ Advanced Computing (SciDAC) program.\nPreviously supported by the Consortium\
    \ for Advanced Modeling of Particles Accelerators (CAMPA), funded by the U.S.\
    \ DOE Office of Science under Contract No. DE-AC02-05CH11231.\nSupported by the\
    \ Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S.\
    \ Department of Energy organizations (Office of Science and the National Nuclear\
    \ Security Administration).\nThis project has received funding from the European\
    \ Unions Horizon 2020 research and innovation programme under grant agreement\
    \ No 654220.\nThis work was partially funded by the Center of Advanced Systems\
    \ Understanding (CASUS), which is financed by Germany's Federal Ministry of Education\
    \ and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism\
    \ (SMWK) with tax funds on the basis of the budget approved by the Saxon State\
    \ Parliament.\nSupported by the HElmholtz Laser Plasma Metadata Initiative (HELPMI)\
    \ project (ZT-I-PF-3-066), funded by the \"Initiative and Networking Fund\" of\
    \ the Helmholtz Association in the framework of the \"Helmholtz Metadata Collaboration\"\
    \ project call 2022.</p>\n<h3><a id=\"user-content-transitive-contributions\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#transitive-contributions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Transitive\
    \ Contributions</h3>\n<p>openPMD-api stands on the shoulders of giants and we\
    \ are grateful for the following projects included as direct dependencies:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\">ADIOS2</a> by <a href=\"\
    https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky, N. Podhorszki, W.F.\
    \ Godoy (ORNL), team, collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"\
    https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\xFD</a> and <a href=\"\
    https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n\
    <li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a>\
    \ and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a>\
    \ by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"\
    https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> by <a href=\"\
    https://github.com/ToruNiina\">Toru Niina</a> and <a href=\"https://github.com/ToruNiina/toml11#Contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\"\
    >pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a>\
    \ and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n\
    </li>\n<li>all contributors to the evolution of modern C++ and early library preview\
    \ developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n\
    </li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a>\
    \ and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n\
    </li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"\
    nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\
    \ and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among\
    \ others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\"\
    >openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR,\
    \ now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\
    >contributors</a>\n</li>\n</ul>\n"
  stargazers_count: 129
  subscribers_count: 11
  topics:
  - openpmd
  - openscience
  - hdf5
  - adios
  - mpi
  - hpc
  - research
  - file-handling
  - python3
  - opendata
  - metadata
  - cpp17
  updated_at: 1707251098.0
player1537-playground/triple-r:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537-playground/triple-r
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1614701026.0
pnnl/ExaGO:
  data_format: 2
  description: High-performance power grid optimization for stochastic, security-constrained,
    and multi-period ACOPF problems.
  filenames:
  - buildsystem/spack/ascent/spack.yaml
  - buildsystem/container/spack.yaml
  - buildsystem/spack/crusher/spack.yaml
  full_name: pnnl/ExaGO
  latest_release: v1.6.0
  readme: "<h1><a id=\"user-content-exascale-grid-optimization-toolkit-exagotm-----\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#exascale-grid-optimization-toolkit-exagotm-----\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n<b>Exa</b>scale\
    \ <b>G</b>rid <b>O</b>ptimization toolkit (ExaGO<sup>TM</sup>) <a href=\"https://github.com/pre-commit/pre-commit\"\
    ><img src=\"https://camo.githubusercontent.com/a8cba9888a55d8a038324b73da057a30a40f34b0eae64c2f93196d5d837df1bd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7072652d2d636f6d6d69742d656e61626c65642d627269676874677265656e3f6c6f676f3d7072652d636f6d6d6974\"\
    \ alt=\"pre-commit\" data-canonical-src=\"https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\
    \ alt=\"PNNL GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\
    \ alt=\"ORNL Ascent GitLab Push Mirror\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\
    \ alt=\"pre-commit GitHub Action\" style=\"max-width: 100%;\"></a> <a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    ><img src=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\
    \ alt=\"Spack CPU Build\" style=\"max-width: 100%;\"></a>\n</h1>\n\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"viz/images/network_gen_load_us.png\"\
    ><img src=\"viz/images/network_gen_load_us.png\" style=\"max-width: 100%;\"></a></p>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/manual/figures/three_in_one.png\"\
    ><img src=\"docs/manual/figures/three_in_one.png\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>ExaGO<sup>TM</sup> is a package for solving large-scale  power grid\
    \ optimization problems on parallel and distributed architectures, particularly\
    \ targeted for exascale machines with heteregenous architectures (GPU). Combinations\
    \ of stochastic, contingency-constrained, multiperiod ACOPF problems can be solved\
    \ with ExaGO. The package is written in C/C++ with python bindings available for\
    \ python-based applications. An overview of the package is given on this page.\
    \ For extended information, including the modeling details and formulations, see\
    \ the <a href=\"docs/manual/manual.pdf\">ExaGO manual</a>.</p>\n<p>ExaGO<sup>TM</sup>\
    \ includes the following applications for solving different power grid optimization\
    \ problems:</p>\n<ul>\n<li>\n<a href=\"docs/web/opflow.md\">OPFLOW</a> solves\
    \ an AC optimal power flow either on CPU and GPU</li>\n<li>\n<a href=\"docs/web/tcopflow.md\"\
    >TCOPFLOW</a> solves a multi-period optimal power flow</li>\n<li>\n<a href=\"\
    docs/web/scopflow.md\">SCOPFLOW</a> solves a security-constrained (contingency-constrained)\
    \ optimal power. Both single-period and multi-period problems can be solved.</li>\n\
    <li>\n<a href=\"docs/web/sopflow.md\">SOPFLOW</a> solves a stochastic optimal\
    \ power flow with (optional) security constraints for single and multiple periods.</li>\n\
    </ul>\n<p>ExaGO<sup>TM</sup> applications are interfaced with the following optimization\
    \ solver packaages:</p>\n<ul>\n<li>\n<a href=\"https://github.com/coin-or/Ipopt\"\
    >Ipopt</a> is a popular optimization package for solving nonlinear optimization\
    \ problems that uses an interior-point algorithm.</li>\n<li>\n<a href=\"https://github.com/LLNL/hiop\"\
    >HiOp</a> is a HPC package for optimization. ExaGO interfaces with two of its\
    \ solvers -- a mixed sparse-dense interior-point solver (NewtonMDS) and a sparse\
    \ interior-point solver (HiOPSparse). NewtonMDS  allows execution of the optimization\
    \ either on CPU and GPU. The sparse HiOp solver is currently supported on CPU\
    \ only.</li>\n</ul>\n<p>Note that not all applications can utilize all solvers\
    \ yet. The following table lists the solver-application compatibility.</p>\n<table>\n\
    <thead>\n<tr>\n<th align=\"center\">Solver</th>\n<th align=\"center\">OPFLOW</th>\n\
    <th align=\"center\">TCOPFLOW</th>\n<th align=\"center\">SCOPLOW</th>\n<th align=\"\
    center\">SOPFLOW</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Ipopt</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\">Y</td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td align=\"center\">HiOp</td>\n\
    <td align=\"center\">Y</td>\n<td align=\"center\"></td>\n<td align=\"center\"\
    >Y</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<p>Additionally,\
    \ note that SCOPFLOW and SOPFLOW with HiOp solver use Ipopt to solve a portion\
    \ of the problem (base problem). So one must also configure with Ipopt when using\
    \ HiOp solver for these applications.</p>\n<h2><a id=\"user-content-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n\
    <p>Details installation instructions are given at <a href=\"./INSTALL.md\">INSTALL.md</a>\
    \ for information on acquiring, building and installing ExaGO.</p>\n<p>If you\
    \ are a developer with access to the project, we also provide public binaries\
    \ that are generated through our GitHub actions workflows documented in <a href=\"\
    .github/workflows/README.md\">README.md</a>, and with documentation about usage\
    \ in the packages section of our repository. Check out a short (&lt; 60s demo)\
    \ of pulling down a version of ExaGO:</p>\n<p><a href=\"https://asciinema.org/a/KCi5TmUXc6zWDj7JYHzfSFxmw\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/036a31e6b78284e2773e8c365f25415ca9f4d6c5bf012a91311694943e2c6cda/68747470733a2f2f61736369696e656d612e6f72672f612f4b436935546d555863367a57446a374a59487a665346786d772e706e67\"\
    \ alt=\"asciicast\" data-canonical-src=\"https://asciinema.org/a/KCi5TmUXc6zWDj7JYHzfSFxmw.png\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-developer-guide\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#developer-guide\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developer\
    \ Guide</h2>\n<p>You can view the following helpful documentation sources:</p>\n\
    <ul>\n<li>\n<a href=\"docs/web/test_add.md\">test_add.md</a> markdown file for\
    \ information on adding tets (outdated)</li>\n<li>\n<a href=\"buildsystem/README.md\"\
    >README.md</a> for our bash / spack buildsystem used in GitHub/GitLab CI/CD</li>\n\
    <li>\n<a href=\"buildsystem/spack/README.md\">README.md</a> for our spack specific\
    \ build scripts that support CI tcl modules on HPC target platforms</li>\n<li>\n\
    <a href=\"docs/devcontainer/README.md\">README.md</a> for our devcontianer configuration\
    \ information (codespace support coming soon)</li>\n<li>\n<a href=\"docs/exago_policy_compatibility.md\"\
    >exago_policy_compatiblility</a> for xSDK compatibility guidelines, and ways to\
    \ enforce compliance</li>\n<li>\n<a href=\"docs/python_bindings.md\">python_bindings.md</a>\
    \ for documentation about or Python bindings</li>\n<li>\n<a href=\"performance_analysis/README.md\"\
    >README.md</a> for information about profiling ExaGO with spack</li>\n<li>\n<a\
    \ href=\".github/workflows/README.md\">README.md</a> for details about our GitHub\
    \ actions</li>\n<li>\n<a href=\"docs/web/README.ci_clusters.md\">README.ci_clusters.md</a>\
    \ for CI cluster workflow documentation</li>\n<li>\n<a href=\"docs/web/README.summit.md\"\
    >README.summit.md</a> for ORNL's Summit specific configuration</li>\n</ul>\n<h2><a\
    \ id=\"user-content-vizualisation\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#vizualisation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Vizualisation</h2>\n<p>Our ChatGrid frontend deployed with React,\
    \ PSQL and LangChain has documentation in <a href=\"viz/README.md\">README.md</a>\
    \ as well as a pdf <a href=\"viz/README.pdf\">README.pdf</a> in the <code>viz</code>\
    \ subdirectory. Several of our tutorials install this through commands in Jupyter\
    \ Notebooks as well.</p>\n<h2><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#usage\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Usage</h2>\n<p>Instructions for executing the different\
    \ ExaGO<sup>TM</sup> applications is given below.</p>\n<ul>\n<li><a href=\"docs/web/opflow.md\"\
    >OPFLOW</a></li>\n<li><a href=\"docs/web/tcopflow.md\">TCOPFLOW</a></li>\n<li><a\
    \ href=\"docs/web/sopflow.md\">SOPFLOW</a></li>\n<li><a href=\"docs/web/scopflow.md\"\
    >SCOPFLOW</a></li>\n<li><a href=\"docs/web/pflow.md\">PFLOW</a></li>\n</ul>\n\
    <p>We also provide our user manual as a pdf <a href=\"docs/manual/manual.pdf\"\
    >manual.pdf</a> -&gt; need to update this regularly with CI / move to quarto docs.</p>\n\
    <h2><a id=\"user-content-tutorials\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#tutorials\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Tutorials</h2>\n<ul>\n<li>If you are using a devcontainer with VSCode,\
    \ the following tutorials are provided:\n<ul>\n<li>\n<a href=\"docs/devcontainer/tutorial.ipynb\"\
    >tutorial.ipynb</a> for basic configuration infromation and I/O</li>\n<li>\n<a\
    \ href=\"docs/devcontainer/mpi4py-tutorial.ipynb\">mpi4py-tutorial.ipynb</a> for\
    \ mpi4py pointers and best practices</li>\n<li>\n<a href=\"docs/devcontainer/viz-tutorial.ipynb\"\
    >viz-tutorial.ipynb</a> for spinning up our frontend visualization with ChatGrid\
    \ integration</li>\n</ul>\n</li>\n<li>Otherwise, you can check out our more in\
    \ depth application tutorials in the <code>tutorials</code>subdirectory:\n<ul>\n\
    <li>\n<a href=\"tutorials/demo1.ipynb\">demo1.ipynb</a> run OPFLOW, SCOPFLOW and\
    \ visualize your output</li>\n<li>\n<a href=\"tutorials/demo2.ipynb\">demo2.ipynb</a>\
    \ run SOPFLOW on many ranks using MPI, and visualize outpu\n<ul>\n<li>TODO - add\
    \ fixes from <code>mpi4py</code> devcontainer example into this notebook to show\
    \ working MPI workflow</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3><a id=\"user-content-options\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#options\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Options</h3>\n\
    <p>Each application has a different set of options that are described in depth\
    \ in the usage notes. These options can be passed optionally through an options\
    \ file (<code>-optionsfile &lt;option_file&gt;</code>), or directly on the command\
    \ line.</p>\n<p>Since options may be specified in more than one location (on the\
    \ command line, and through an options file), it is worth noting that the option\
    \ specified on the command line supersede those in the options file. For example,\
    \ if <code>opflowoptions</code> options file set the network file via the option\
    \ <code>-netfile case9mod.m</code>, the following behavior occurs:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> This uses case9mod.m</span>\n./opflow -optionsfile opflowoptions\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This uses case118.m</span>\n\
    ./opflow -netfile case118.m -options_file opflowoptions</pre></div>\n<h2><a id=\"\
    user-content-visualization-experimental\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#visualization-experimental\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Visualization (experimental)</h2>\n\
    <p>ExaGO has an experimental visualization to display the results of <code>OPFLOW</code>\
    \ application on a map. See the <a href=\"viz/README.md\">visualization README</a>\
    \ for more information.</p>\n<h2><a id=\"user-content-contributing\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Please\
    \ see <a href=\"docs/developer_guidelines.md\">the developer guidelines</a> before\
    \ attempting to contribute.\nFeel free to raise an issue or contact the team if\
    \ the guidelines are ambiguous or you have a particular question.</p>\n<h2><a\
    \ id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#authors\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Authors</h2>\n<ul>\n<li>Shrirang Abhyankar</li>\n<li>Slaven Peles</li>\n\
    <li>Asher Mancinelli</li>\n<li>Cameron Rutherford</li>\n<li>Bruce Palmer</li>\n\
    <li>Jaelyn Litzinger</li>\n<li>William Perkins</li>\n<li>Sayef Azad Sakin</li>\n\
    <li>Joseph Macam</li>\n<li>Ryan Danehy</li>\n<li>Nicholson Koukpaizan</li>\n</ul>\n\
    <h2><a id=\"user-content-acknowledgement\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#acknowledgement\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Acknowledgement</h2>\n<p>This package is developed\
    \ as a part of <a href=\"https://www.exascaleproject.org/research-project/exasgd/\"\
    \ rel=\"nofollow\">ExaSGD</a> project under the <a href=\"https://www.exascaleproject.org/\"\
    \ rel=\"nofollow\">Exascale computing project</a>.</p>\n<h2><a id=\"user-content-copyright\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#copyright\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Copyright</h2>\n\
    <p>Copyright \xA9 2020, Battelle Memorial Institute.</p>\n<p>ExaGO<sup>TM</sup>\
    \ is a free software distributed under a BSD 2-clause license. You may reuse,\
    \ modify, and redistribute the software. See the <a href=\"LICENSE\">license</a>\
    \ file for details.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#disclaimer\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Disclaimer</h2>\n<p>This material\
    \ was prepared as an account of work sponsored by an agency of the United States\
    \ Government.  Neither the United States Government nor the United States Department\
    \ of Energy, nor Battelle, nor any of their employees, nor any jurisdiction or\
    \ organization that has cooperated in the development of these materials, makes\
    \ any warranty, express or implied, or assumes any legal liability or responsibility\
    \ for the accuracy, completeness, or usefulness or any information, apparatus,\
    \ product, software, or process disclosed, or represents that its use would not\
    \ infringe privately owned rights.\nReference herein to any specific commercial\
    \ product, process, or service by trade name, trademark, manufacturer, or otherwise\
    \ does not necessarily constitute or imply its endorsement, recommendation, or\
    \ favoring by the United States Government or any agency thereof, or Battelle\
    \ Memorial Institute. The views and opinions of authors expressed herein do not\
    \ necessarily state or reflect those of the United States Government or any agency\
    \ thereof.</p>\n"
  stargazers_count: 20
  subscribers_count: 10
  topics: []
  updated_at: 1704234725.0
range3/pmembench:
  data_format: 2
  description: Micro-benchmarks created using PMDK and Intel Optane DCPMM performance
    comparisons for all generations, including the very last persistent memory, 300
    series.
  filenames:
  - spack/envs/chris90/spack.yaml
  - spack/envs/pegasus/spack.yaml
  full_name: range3/pmembench
  latest_release: null
  readme: '<h1><a id="user-content-pmembench" class="anchor" aria-hidden="true" tabindex="-1"
    href="#pmembench"><span aria-hidden="true" class="octicon octicon-link"></span></a>pmembench</h1>

    <h2><a id="user-content-pmem2bench" class="anchor" aria-hidden="true" tabindex="-1"
    href="#pmem2bench"><span aria-hidden="true" class="octicon octicon-link"></span></a>pmem2bench</h2>

    <p><a href="eval/README.md">Click here for an evaluation using the Intel Optane
    DCPMM 300/200/100 series!</a></p>

    <h2><a id="user-content-pmemobjbench" class="anchor" aria-hidden="true" tabindex="-1"
    href="#pmemobjbench"><span aria-hidden="true" class="octicon octicon-link"></span></a>pmemobjbench</h2>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1704890871.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<h1><a id=\"user-content-libpressio\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#libpressio\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>LibPressio</h1>\n<p><em>the stable version of this\
    \ code is found at <a href=\"https://github.com/CODARcode/libpressio\">at the\
    \ CODARCode organization</a> it is updated about anually</em></p>\n<p>Pressio\
    \ is latin for compression.  LibPressio is a C++ library with C compatible bindings\
    \ to abstract between different lossless and lossy compressors and their configurations.\
    \  It solves the problem of having to having to write separate application level\
    \ code for each lossy compressor that is developed.  Instead, users write application\
    \ level code using LibPressio, and the library will make the correct underlying\
    \ calls to the compressors.  It provides interfaces to represent data, compressors\
    \ settings, and compressors.</p>\n<p>Documentation for the <code>master</code>\
    \ branch can be <a href=\"https://robertu94.github.io/libpressio/\" rel=\"nofollow\"\
    >found here</a></p>\n<h1><a id=\"user-content-using-libpressio\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#using-libpressio\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using LibPressio</h1>\n<p>Example\
    \ using the CLI from <a href=\"https://github.com/robertu94/pressio-tools\"><code>pressio-tools</code></a>\n\
    We also have C, C++, Rust, Julia, and Python bindings.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pressio -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<h2><a id=\"user-content-getting-started\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#getting-started\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n\
    <p>After skimming the example, LibPressio has 6 major headers that you will need\
    \ to use:</p>\n<table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td><code>pressio.h</code></td>\n<td>Error reporting and aquiring\
    \ handles to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<h2><a id=\"user-content-supported-compressors-and-metrics\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#supported-compressors-and-metrics\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ Compressors and Metrics</h2>\n<p>Libpressio provides a number of builtin compressor\
    \ and metrics modules.\nAll of these are <strong>disabled by default</strong>.\n\
    They can be enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code>\
    \ variable to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information\
    \ on writing a compressor plugin see <a href=\"docs/WritingACompressorPlugin.md\"\
    >Writing a Compressor Plugin</a>\nFor information on writing a metrics plugin\
    \ see <a href=\"docs/WritingAMetricsPlugin.md\">Writing a Metrics Plugin</a></p>\n\
    <h3><a id=\"user-content-compressor-plugins\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#compressor-plugins\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Compressor Plugins</h3>\n<p>1st party\
    \ compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the <a href=\"build/Compressors.md\"\
    >compressor settings page</a> for information on how to configure them.</p>\n\
    <h3><a id=\"user-content-metrics-plugins\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#metrics-plugins\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Metrics Plugins</h3>\n<p>1st party compressors\
    \ plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the <a href=\"build/Metrics.md\">metrics\
    \ results page</a> for information on what they produce</p>\n<h3><a id=\"user-content-io-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#io-plugins\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>IO Plugins</h3>\n\
    <p>1st party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the <a href=\"build/IO.md\">io settings page</a>\
    \ for information on how to configure them</p>\n<h1><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h1>\n\
    <h2><a id=\"user-content-installing-libpressio-using-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-libpressio-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ LibPressio using Spack</h2>\n<p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\"\
    >spack</a>.  This example will install libpressio with only the SZ3 plugin.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<h2><a id=\"user-content-doing-a-development-build-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#doing-a-development-build-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Doing a\
    \ development build with spack</h2>\n<p>The easiest way to do a development build\
    \ of libpressio is to use Spack envionments.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> one time setup: create\
    \ an envionment</span>\nspack env create -d mydevenviroment\nspack env activate\
    \ mydevenvionment\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one time\
    \ setup: tell spack to set LD_LIBRARY_PATH with the spack envionment's library\
    \ paths</span>\nspack config add modules:prefix_inspections:lib64:[LD_LIBRARY_PATH]\n\
    spack config add modules:prefix_inspections:lib:[LD_LIBRARY_PATH]\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> one time setup: install libpressio-tools\
    \ and checkout </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> libpressio\
    \ for development</span>\nspack add libpressio-tools\nspack develop libpressio@git.master\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compile and install (repeat\
    \ as needed)</span>\nspack install </pre></div>\n<h2><a id=\"user-content-manual-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#manual-installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manual Installation</h2>\n\
    <p>Libpressio unconditionally requires:</p>\n<ul>\n<li><code>cmake</code></li>\n\
    <li><code>pkg-config</code></li>\n<li><a href=\"https://github.com/robertu94/std_compat\"\
    ><code>std_compat</code></a></li>\n<li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code>\
    \ or later</li>\n<li>\n<code>clang-7.0.0</code> or later using either <code>libc++</code>\
    \ or <code>libstdc++</code>.  Beware that system libraries may need to be recompiled\
    \ with <code>libc++</code> if using <code>libc++</code>\n</li>\n</ul>\n</li>\n\
    </ul>\n<p>Dependency versions and optional dependencies are documented <a href=\"\
    https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<h2><a id=\"user-content-configuring-libpressio-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#configuring-libpressio-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ LibPressio Manually</h2>\n<p>LibPressio uses a fairly standard CMake buildsystem.\n\
    For more information on <a href=\"https://robertu94.github.io/learning/cmake\"\
    \ rel=\"nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration\
    \ options for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\n\
    For information on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<h1><a id=\"user-content-api-stability\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#api-stability\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>API Stability</h1>\n<p>Please\
    \ refer to <a href=\"docs/stability.md\">docs/stability.md</a>.</p>\n<h1><a id=\"\
    user-content-how-to-contribute\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#how-to-contribute\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>How to Contribute</h1>\n<p>Please refer to <a href=\"CONTRIBUTORS.md\"\
    >CONTRIBUTORS.md</a> for a list of contributors, sponsors, and contribution guidelines.</p>\n\
    <h1><a id=\"user-content-bug-reports\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#bug-reports\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Bug Reports</h1>\n<p>Please files bugs to the Github Issues page on\
    \ the CODARCode libpressio repository.</p>\n<p>Please read this post on <a href=\"\
    https://codingnest.com/how-to-file-a-good-bug-report/\" rel=\"nofollow\">how to\
    \ file a good bug report</a>.\_ After reading this post, please provide the following\
    \ information specific to libpressio:</p>\n<ul>\n<li>Your OS version and distribution\
    \ information, usually this can be found in <code>/etc/os-release</code>\n</li>\n\
    <li>the output of <code>cmake -L $BUILD_DIR</code>\n</li>\n<li>the version of\
    \ each of libpressio's dependencies listed in the README that you have installed.\
    \ Where possible, please provide the commit hashes.</li>\n</ul>\n<h1><a id=\"\
    user-content-citing-libpressio\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#citing-libpressio\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing LibPressio</h1>\n<p>If you find LibPressio useful, please cite\
    \ this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n  title={Productive\
    \ and Performant Generic Lossy Data Compression with LibPressio},\n  author={Underwood,\
    \ Robert and Malvoso, Victoriana and Calhoun, Jon C and Di, Sheng and Cappello,\
    \ Franck},\n  booktitle={2021 7th International Workshop on Data Analysis and\
    \ Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n  year={2021},\n\
    \  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 21
  subscribers_count: 6
  topics: []
  updated_at: 1706565664.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<h1><a id="user-content-roibin-sz-experiments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#roibin-sz-experiments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>ROIBIN-SZ Experiments</h1>

    <h2><a id="user-content-system-information" class="anchor" aria-hidden="true"
    tabindex="-1" href="#system-information"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>System Information</h2>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <h2><a id="user-content-where-is-the-implementation-of-roibin-sz3" class="anchor"
    aria-hidden="true" tabindex="-1" href="#where-is-the-implementation-of-roibin-sz3"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Where is the implementation
    of ROIBIN-SZ3?</h2>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    started</h2>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <h3><a id="user-content-obtaining-data" class="anchor" aria-hidden="true" tabindex="-1"
    href="#obtaining-data"><span aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining
    Data</h3>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <h3><a id="user-content-quality-assessment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#quality-assessment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Quality Assessment</h3>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <h3><a id="user-content-container-install-for-ease-of-setup" class="anchor" aria-hidden="true"
    tabindex="-1" href="#container-install-for-ease-of-setup"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Container Install (for ease of setup)</h3>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <h4><a id="user-content-singularity" class="anchor" aria-hidden="true" tabindex="-1"
    href="#singularity"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h4>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <h4><a id="user-content-docker" class="anchor" aria-hidden="true" tabindex="-1"
    href="#docker"><span aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h4>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <h3><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#building-the-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Building the container</h3>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <h3><a id="user-content-manual-install-for-scale" class="anchor" aria-hidden="true"
    tabindex="-1" href="#manual-install-for-scale"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Manual Install (for scale)</h3>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <h2><a id="user-content-running-the-experiments" class="anchor" aria-hidden="true"
    tabindex="-1" href="#running-the-experiments"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Running the Experiments</h2>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <h3><a id="user-content-example-output" class="anchor" aria-hidden="true" tabindex="-1"
    href="#example-output"><span aria-hidden="true" class="octicon octicon-link"></span></a>Example
    Output</h3>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <h2><a id="user-content-results-for-figures" class="anchor" aria-hidden="true"
    tabindex="-1" href="#results-for-figures"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Results for Figures</h2>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1648861627.0
roblatham00/phonebook:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: roblatham00/phonebook
  latest_release: null
  readme: '<p>Your project "YP" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1682697472.0
rohankumardubey/libtree:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: rohankumardubey/libtree
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    ><img src=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\
    \ alt=\"Test\" style=\"max-width: 100%;\"></a>\n<a href=\"https://aur.archlinux.org/packages/libtree/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e22cad709c40ea40e72b03313e4a660481222a373c9217b71809265e991f747e/68747470733a2f2f696d672e736869656c64732e696f2f6175722f76657273696f6e2f6c6962747265653f6c6f676f3d417263682d4c696e7578\"\
    \ alt=\"AUR version\" data-canonical-src=\"https://img.shields.io/aur/version/libtree?logo=Arch-Linux\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-libtree\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#libtree\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>libtree</h1>\n<p>A tool that:</p>\n\
    <ul>\n<li>\U0001F333 turns <code>ldd</code> into a tree</li>\n<li>\u261D\uFE0F\
    \ explains why shared libraries are found and why not</li>\n<li>\U0001F4E6 optionally\
    \ deploys executables and dependencies into a single directory</li>\n</ul>\n<p><a\
    \ target=\"_blank\" rel=\"noopener noreferrer\" href=\"doc/screenshot.png\"><img\
    \ src=\"doc/screenshot.png\" alt=\"example\" style=\"max-width: 100%;\"></a></p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Installation</h2>\n<p>Download the <a href=\"https://github.com/haampie/libtree/releases\"\
    ><strong>latest release</strong></a> from Github.</p>\n<p><strong>Static executable</strong></p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>wget -qO libtree https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64\n\
    chmod +x libtree\n./libtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<p><strong>Static executable\
    \ + optional dependencies</strong></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>wget -qO libtree.tar.gz https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64.tar.gz\n\
    mkdir libtree\ntar -xf libtree.tar.gz -C libtree\n<span class=\"pl-k\">export</span>\
    \ PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$PWD</span>/libtree:<span class=\"pl-smi\">$PATH</span><span class=\"pl-pds\"\
    >\"</span></span>\nlibtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which\
    \ man<span class=\"pl-pds\">)</span></span></pre></div>\n<h2><a id=\"user-content-deploying-binaries--dependencies-into-a-folder\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#deploying-binaries--dependencies-into-a-folder\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Deploying\
    \ binaries + dependencies into a folder</h2>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ libtree <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which man<span\
    \ class=\"pl-pds\">)</span></span> -d man.bundle --chrpath --strip\nman\n\u251C\
    \u2500\u2500 libmandb-2.9.1.so [runpath]\n\u2502   \u251C\u2500\u2500 libman-2.9.1.so\
    \ [runpath]\n\u2502   \u2502   \u251C\u2500\u2500 libpipeline.so.1 [ld.so.conf]\n\
    \u2502   \u2502   \u2514\u2500\u2500 libseccomp.so.2 [ld.so.conf]\n\u2502   \u2514\
    \u2500\u2500 libgdbm.so.6 [ld.so.conf]\n\u251C\u2500\u2500 libman-2.9.1.so (collapsed)\
    \ [runpath]\n\u2514\u2500\u2500 libpipeline.so.1 (collapsed) [ld.so.conf]\n\n\
    Deploying to <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/bin/man<span class=\"pl-pds\">\"</span></span> =<span class=\"\
    pl-k\">&gt;</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/bin/man<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/lib/man-db/libmandb-2.9.1.so<span class=\"pl-pds\">\"</span></span>\
    \ =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>man.bundle/usr/lib/libmandb-2.9.1.so<span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/man-db/libman-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libman-2.9.1.so<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>/usr/lib/x86_64-linux-gnu/libpipeline.so.1.5.2<span class=\"pl-pds\"\
    >\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1.5.2<span class=\"\
    pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>man.bundle/usr/lib/libpipeline.so.1<span class=\"pl-pds\">\"\
    </span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2.5.1<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libseccomp.so.2<span class=\"pl-pds\"\
    >\"</span></span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/lib/x86_64-linux-gnu/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span> =<span class=\"pl-k\">&gt;</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6.0.0<span\
    \ class=\"pl-pds\">\"</span></span>\n  creating symlink <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>man.bundle/usr/lib/libgdbm.so.6<span class=\"pl-pds\"\
    >\"</span></span>\n\n$ tree man.bundle/\nman.bundle/\n\u2514\u2500\u2500 usr\n\
    \    \u251C\u2500\u2500 bin\n    \u2502\_\_ \u2514\u2500\u2500 man\n    \u2514\
    \u2500\u2500 lib\n        \u251C\u2500\u2500 libgdbm.so.6 -<span class=\"pl-k\"\
    >&gt;</span> libgdbm.so.6.0.0\n        \u251C\u2500\u2500 libgdbm.so.6.0.0\n \
    \       \u251C\u2500\u2500 libman-2.9.1.so\n        \u251C\u2500\u2500 libmandb-2.9.1.so\n\
    \        \u251C\u2500\u2500 libpipeline.so.1 -<span class=\"pl-k\">&gt;</span>\
    \ libpipeline.so.1.5.2\n        \u251C\u2500\u2500 libpipeline.so.1.5.2\n    \
    \    \u251C\u2500\u2500 libseccomp.so.2 -<span class=\"pl-k\">&gt;</span> libseccomp.so.2.5.1\n\
    \        \u2514\u2500\u2500 libseccomp.so.2.5.1\n\n3 directories, 9 files</pre></div>\n\
    <h2><a id=\"user-content-verbose-output\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#verbose-output\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Verbose output</h2>\n<p>By default certain standard\
    \ depenendencies are not shown. For more verbose output use</p>\n<ul>\n<li>\n\
    <code>libtree -v $(which man)</code> to show skipped libraries without their children</li>\n\
    <li>\n<code>libtree -a $(which apt-get)</code> to show the full recursive list\
    \ of libraries</li>\n</ul>\n<p>Use the <code>--path</code> or <code>-p</code>\
    \ flags to show paths rather than sonames:</p>\n<ul>\n<li><code>libtree -p $(which\
    \ tar)</code></li>\n</ul>\n<h2><a id=\"user-content-changing-search-paths\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#changing-search-paths\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Changing\
    \ search paths</h2>\n<p><code>libtree</code> follows the rules of <code>ld.so</code>\
    \ to locate libraries, but does not use <code>ldconfig</code>'s\ncache. Instead\
    \ it parses <code>/etc/ld.so.conf</code> at runtime. In fact you can change the\
    \ search\npath config by setting <code>--ldconf mylibs.conf</code>. Search paths\
    \ can be added as well via\n<code>LD_LIBRARY_PATH=\"path1:path2:$LD_LIBRARY_PATH\"\
    \ libtree ...</code>.</p>\n<h2><a id=\"user-content-building\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#building\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<ul>\n<li>\n<strong>From\
    \ source</strong>:\n<div class=\"highlight highlight-source-shell\"><pre>git clone\
    \ https://github.com/haampie/libtree.git\n<span class=\"pl-c1\">cd</span> libtree\n\
    mkdir build\n<span class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_PREFIX_PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/cxxopts;/path/to/elfio;/path/to/termcolor<span\
    \ class=\"pl-pds\">\"</span></span> ..\nmake -j\nmake install</pre></div>\n</li>\n\
    <li>\n<strong>Using <a href=\"https://github.com/spack/spack\">spack</a></strong>:\n\
    <pre><code>spack install libtree +chrpath +strip\nspack load libtree\n</code></pre>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-known-issues\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#known-issues\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Known issues</h2>\n<ul>\n<li>When deploying\
    \ libs with <code>libtree app -d folder.bundle --chrpath</code>, the runpaths\
    \ are only\nchanged when the binaries already have an an rpath or runpath. This\
    \ is a limitation of\n<code>chrpath</code>. Another option is to use <code>patchelf</code>\
    \ instead, but this tool is known to break\nbinaries sometimes.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664232270.0
salotz/snailpacks:
  data_format: 2
  description: Spack repo for multimedia development
  filenames:
  - examples/c-embed-chibi/spack.yaml
  - examples/c-embed-python/spack.yaml
  full_name: salotz/snailpacks
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics:
  - spack
  - spack-repo
  - scopes-lang
  - multimedia
  - game-development
  - package-manager
  - development-environment
  updated_at: 1648089720.0
sandialabs/optimism:
  data_format: 2
  description: Computational solid mechanics made easy with Jax
  filenames:
  - spack.yaml
  full_name: sandialabs/optimism
  latest_release: null
  readme: "<h1><a id=\"user-content-optimism-computational-solid-mechanics-made-easy-with-jax\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#optimism-computational-solid-mechanics-made-easy-with-jax\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>OptimiSM:\
    \ Computational solid mechanics made easy with Jax</h1>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer\" href=\"https://github.com/sandialabs/optimism/actions/workflows/ci-build.yml/badge.svg\"\
    ><img src=\"https://github.com/sandialabs/optimism/actions/workflows/ci-build.yml/badge.svg\"\
    \ alt=\"Continuous integration\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"\
    user-content-what-is-optimism\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#what-is-optimism\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>What is OptimiSM?</h2>\n<p>OptimiSM is a library for posing and solving\
    \ problems in solid\nmechanics using the finite element method.\nThe central theme\
    \ of this project is exploring how to get better\nperformance and robustness by\
    \ taking advantages of the tools of\nvariational calculus.\nOptimiSM uses Lagrangian\
    \ field theory to pose hard nonlinear solid\nmechanics problems as optimization\
    \ problems, and then uses powerful\noptimization methods to solve them efficiently\
    \ and reliably.</p>\n<p>To do this, OptimiSM relies on Google's\n<a href=\"https://github.com/google/jax\"\
    >JAX</a> library for automatic\ndifferentiation and just-in-time compiling for\
    \ performance.</p>\n<h2><a id=\"user-content-why-use-optimism\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#why-use-optimism\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Why use OptimiSM?</h2>\n<p>These\
    \ days, there are lots of finite element software libraries out\nthere.  Why would\
    \ you want to use OptimiSM?</p>\n<ul>\n<li>OptimiSM is for <strong>rapid development</strong>:\
    \ OptimiSM is written in Python and\nuses the NumPy/SciPy stack. This means that\
    \ it's easy to read,\nunderstand, and extend. If you're like us, and you prefer\
    \ working in\nPython/NumPy to C++, you'll find OptimiSM a more pleasant place\
    \ to\nwork (and play) than heavily abstracted finite element libraries,\neven\
    \ the well-designed ones.<br>\nOptimiSM makes use of Jax's just-in-time compilation\
    \ to get good\nperformance, so the simplicity of Python coding doesn't condemn\
    \ you\nto toy problems.</li>\n<li>OptimiSM provides <strong>robust solvers</strong>:\
    \ OptimiSM takes a different\napproach than most finite element libraries.  <em>All</em>\
    \ problems are\nformulated by encoding them in a scalar-valued functional and\
    \ then\nminimizing that functional. This includes nonlinear phenomena like\nfinite\
    \ deformations and contact, and even irreversible (dissipative)\nphenomena like\
    \ plasticity and viscoelasticity. A big motivation for\ncreating this library\
    \ was proving to others (and ourselves) that\nreal-world, complex problems could\
    \ be written in this way, and that\nit could pay off for solving hard problems.\
    \ By imposing a\nminimization structure, the OptimiSM solvers can avoid stagnating\
    \ in\nhard problems and also avoid converging to spurious unstable\nconfigurations.\
    \ In other words, OptimiSM helps you find the solutions\nthat <em>should</em>\
    \ be out there and prevents you from finding \"solutions\"\nthat really aren't\
    \ solutions. Check out the <a href=\"\">examples</a> to see some\ncases that are\
    \ difficult or impossible to solve correctly even with\ncommerical codes.</li>\n\
    <li>OptimiSM gives <strong>sensitivities</strong> for design optimization, inverse\n\
    analysis, and training of machine learning models.</li>\n</ul>\n<h2><a id=\"user-content-installation-instructions\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation-instructions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ instructions</h2>\n<p>At the moment, OptimiSM is meant to be used as a development\
    \ package.\nFirst, fork and clone the code repository from GitHub.\nNext, you\
    \ have a choice: you can pick a basic installation which\nrequires only a minimal\
    \ set of dependencies, or the recommended\ninstallation, which requires some additional\
    \ packages. The main\ndifference of the recommended installation is that it requires\
    \ the\n<code>scikit-sparse</code> package, which provides a sparse Cholesky\n\
    preconditioner. This is needed if you want to run large-scale\nproblems; without\
    \ it, you'll only be able to use a dense matrix\npreconditioner (which is both\
    \ slower and uses up much more memory).</p>\n<ul>\n<li>Basic installation: If\
    \ you just want to try some examples out and\ntest-drive OptimiSM, install the\
    \ basic installation by navigating into\nthe base project directory and executing</li>\n\
    </ul>\n<div class=\"highlight highlight-source-shell\"><pre>pip install -e <span\
    \ class=\"pl-c1\">.</span></pre></div>\n<ul>\n<li>Recommended installation: The\
    \ <code>scikit-sparse</code> package requires the\n<a href=\"https://people.engr.tamu.edu/davis/suitesparse.html\"\
    \ rel=\"nofollow\">SuiteSparse</a>\nlibrary to be present. If you have access\
    \ to a package manager on your\nsystem, this is the easiest way to get it. On\
    \ a Mac platform,\nthis would be done with MacPorts by running</li>\n</ul>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>sudo port install SuiteSparse</pre></div>\n\
    <p>or with Homebrew by</p>\n<div class=\"highlight highlight-source-shell\"><pre>brew\
    \ install suite-sparse</pre></div>\n<p>On a Fedora system, you would run</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>sudo dnf install suitesparse-devel</pre></div>\n\
    <p>Of course, you could compile the source yourself if you wish. Check to\nmake\
    \ sure the version you download is supported by the <code>scikit-sparse</code>\n\
    package. The source is available from the <a href=\"https://people.engr.tamu.edu/davis/suitesparse.html\"\
    \ rel=\"nofollow\">SuiteSparse\nwebsite</a> (a\nGitHub link is also provided there).</p>\n\
    <p>Once the SuiteSparse library is in place, navigate into the\n<code>optimism</code>\
    \ directory and execute</p>\n<div class=\"highlight highlight-source-shell\"><pre>pip\
    \ install -e <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>.[sparse]<span\
    \ class=\"pl-pds\">\"</span></span></pre></div>\n<p>Note that you can always start\
    \ with the basic installation, and if you\nwant to switch to the recommended version\
    \ later, you can just get\nSuiteSpase and run the above recommended installation\
    \ command to get\nthe additional functionality. You don't need to remove the basic\n\
    package first.</p>\n<h2><a id=\"user-content-sample-installation-on-osx-using-homebrew\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#sample-installation-on-osx-using-homebrew\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Sample Installation\
    \ on OSX using Homebrew</h2>\n<p>From the <code>optimism</code> directory:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>brew install suite-sparse\n\
    brew install python-tk \n\nINC=/usr/local/Cellar/suite-sparse/5.11.0/include\n\
    LIB=/usr/local/Cellar/suite-sparse/5.11.0/lib\npip=/usr/local/opt/python/bin/pip3\n\
    SUITESPARSE_INCLUDE_DIR=<span class=\"pl-smi\">$INC</span> SUITESPARSE_LIBRARY_DIR=<span\
    \ class=\"pl-smi\">$LIB</span> <span class=\"pl-smi\">$pip</span> install -e <span\
    \ class=\"pl-c1\">.</span> sparse</pre></div>\n<h2><a id=\"user-content-installation-using-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ using spack</h2>\n<p>Utilizing spack can alleviate some of the steps and headaches\
    \ encountered in build described above to use spack to build optimism in a development\
    \ environment, use the following instructions.</p>\n<p>If you don't already have\
    \ spack, you can clone the git repo using the following command</p>\n<pre><code>git\
    \ clone https://github.com/spack/spack.git\n</code></pre>\n<p>Once you have spack\
    \ you can do the following in the optimism directory</p>\n<pre><code>source /path/to/spack/share/spack/setup-env.sh\n\
    spack env activate .\nspack concretize -f\nspack install\n</code></pre>\n<p>The\
    \ above will install all dependencies needed for optimism (including suite sparse\
    \ and testing dependencies).</p>\n<p>Finally, you can install optimism via pip\
    \ with</p>\n<pre><code>pip install -e .[sparse,test]\n</code></pre>\n<p>Note that\
    \ in each new terminal you will need to source the <code>setup-env.sh</code> script\
    \ from spack and activate the env in the optimism folder.</p>\n<h2><a id=\"user-content-citing-optimism\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-optimism\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citing OptimiSM</h2>\n\
    <p>If you use OptimiSM in your research, please cite</p>\n<pre><code>@software{OptimiSM,\n\
    \  author = {Michael R. Tupek and Brandon Talamini},\n  title = {{OptimiSM}},\n\
    \  url = {https://github.com/sandialabs/optimism},\n  version = {0.0.1},\n  year\
    \ = {2021},\n}\n</code></pre>\n<p><em><strong>TODO</strong></em>: add citation\
    \ for contact paper</p>\n<h2><a id=\"user-content-reference-documentation\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#reference-documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reference\
    \ documentation</h2>\n<p>For details about the OptimiSM API, see the <a href=\"\
    \">documentation</a>.</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#contact\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n<p>OptimiSM was\
    \ created and is maintained by Michael Tupek\n<a href=\"mailto:tupek2@llnl.gov\"\
    >tupek2@llnl.gov</a> and Brandon Talamini <a href=\"mailto:talamini1@llnl.gov\"\
    >talamini1@llnl.gov</a>.</p>\n<p>SCR#: 2709.0</p>\n"
  stargazers_count: 20
  subscribers_count: 5
  topics:
  - snl-science-libs
  updated_at: 1704018916.0
simonpintarelli/acclapack-tests:
  data_format: 2
  description: null
  filenames:
  - spack-envs/rocm/spack.yaml
  full_name: simonpintarelli/acclapack-tests
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667393188.0
simonpintarelli/nlcglib:
  data_format: 2
  description: Nonlinear CG methods for wave-function optimization in DFT
  filenames:
  - spack-envs/q-e-sirius-cpu-only/spack.yaml
  full_name: simonpintarelli/nlcglib
  latest_release: v0.9.1
  stargazers_count: 6
  subscribers_count: 2
  topics: []
  updated_at: 1705083092.0
spack/github-actions-buildcache:
  data_format: 2
  description: Spack build cache for Github Actions
  filenames:
  - spack.yaml
  full_name: spack/github-actions-buildcache
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-buildcache-for-github-actions\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spack-buildcache-for-github-actions\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack buildcache\
    \ for GitHub Actions</h1>\n<p>This repo provides a buildcache to speed up Spack\
    \ in your GitHub Actions.</p>\n<p>Currently it provides binaries from Spack <code>develop</code>\
    \ for</p>\n<ul>\n<li><code>%gcc@13 os=ubuntu22.04 target=x86_64_v3</code></li>\n\
    <li><code>%gcc@12 os=ubuntu22.04 target=x86_64_v3</code></li>\n<li><code>%gcc@11\
    \ os=ubuntu22.04 target=x86_64_v3</code></li>\n<li><code>%clang@15 os=ubuntu22.04\
    \ target=x86_64_v3</code></li>\n</ul>\n<p>To use it, add an environment <code>spack.yaml</code>\
    \ to the root of your own repository</p>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre><span class=\"pl-ent\">spack</span>:\n  <span class=\"pl-ent\">view</span>:\
    \ <span class=\"pl-s\">my_view</span>\n  <span class=\"pl-ent\">specs</span>:\n\
    \  - <span class=\"pl-s\">python@3.11</span>\n\n  <span class=\"pl-ent\">config</span>:\n\
    \    <span class=\"pl-ent\">install_tree</span>:\n      <span class=\"pl-ent\"\
    >root</span>: <span class=\"pl-s\">/opt/spack</span>\n\n  <span class=\"pl-ent\"\
    >packages</span>:\n    <span class=\"pl-ent\">all</span>:\n      <span class=\"\
    pl-ent\">require</span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>%gcc@12\
    \ target=x86_64_v3<span class=\"pl-pds\">'</span></span></pre></div>\n<p>and Spack\
    \ install it in a GitHub Action:</p>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre><span class=\"pl-ent\">name</span>: <span class=\"pl-s\">Build</span>\n\n\
    <span class=\"pl-ent\">on</span>: <span class=\"pl-s\">push</span>\n\n<span class=\"\
    pl-ent\">jobs</span>:\n  <span class=\"pl-ent\">example</span>:\n    <span class=\"\
    pl-ent\">runs-on</span>: <span class=\"pl-s\">ubuntu-22.04</span>\n    <span class=\"\
    pl-ent\">steps</span>:\n    - <span class=\"pl-ent\">name</span>: <span class=\"\
    pl-s\">Checkout</span>\n      <span class=\"pl-ent\">uses</span>: <span class=\"\
    pl-s\">actions/checkout@v4</span>\n\n    - <span class=\"pl-ent\">name</span>:\
    \ <span class=\"pl-s\">Setup Spack</span>\n      <span class=\"pl-ent\">uses</span>:\
    \ <span class=\"pl-s\">spack/setup-spack@v2</span>\n\n    - <span class=\"pl-ent\"\
    >name</span>: <span class=\"pl-s\">Concretize</span>\n      <span class=\"pl-ent\"\
    >run</span>: <span class=\"pl-s\">spack -e . concretize</span>\n\n    - <span\
    \ class=\"pl-ent\">name</span>: <span class=\"pl-s\">Install</span>\n      <span\
    \ class=\"pl-ent\">run</span>: <span class=\"pl-s\">spack -e . install --no-check-signature</span>\n\
    \n    - <span class=\"pl-ent\">name</span>: <span class=\"pl-s\">Run</span>\n\
    \        <span class=\"pl-ent\">run</span>: <span class=\"pl-s\">./my_view/bin/python\
    \ -c 'print(\"hello world\")'</span></pre></div>\n<h2><a id=\"user-content-caching-your-own-binaries\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#caching-your-own-binaries\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Caching\
    \ your own binaries</h2>\n<p>If you want to cache your own binaries too, there\
    \ are three steps to take:</p>\n<ol>\n<li>\n<p>Use padding in the install root,\
    \ and add an additional mirror to <code>spack.yaml</code>:</p>\n<div class=\"\
    highlight highlight-source-yaml\"><pre><span class=\"pl-ent\">spack</span>:\n\
    \  <span class=\"pl-ent\">config</span>:\n    <span class=\"pl-ent\">install_tree</span>:\n\
    \      <span class=\"pl-ent\">root</span>: <span class=\"pl-s\">/opt/spack</span>\n\
    \      <span class=\"pl-ent\">padded_length</span>: <span class=\"pl-c1\">128</span>\n\
    \  <span class=\"pl-ent\">mirrors</span>:\n    <span class=\"pl-ent\">local-buildcache</span>:\
    \ <span class=\"pl-s\">oci://ghcr.io/&lt;username&gt;/spack-buildcache</span></pre></div>\n\
    </li>\n<li>\n<p>Configure the permissions for <code>GITHUB_TOKEN</code>:</p>\n\
    <div class=\"highlight highlight-source-yaml\"><pre><span class=\"pl-ent\">jobs</span>:\n\
    \  <span class=\"pl-ent\">example</span>:\n    <span class=\"pl-ent\">runs-on</span>:\
    \ <span class=\"pl-s\">ubuntu-22.04</span>\n    <span class=\"pl-ent\">permissions</span>:\n\
    \      <span class=\"pl-ent\">packages</span>: <span class=\"pl-s\">write</span></pre></div>\n\
    </li>\n<li>\n<p>Add an extra job step that pushes installed Spack packages to\
    \ the local\nbuildcache:</p>\n<div class=\"highlight highlight-source-yaml\"><pre><span\
    \ class=\"pl-ent\">jobs</span>:\n  <span class=\"pl-ent\">example</span>:\n  \
    \  <span class=\"pl-ent\">steps</span>:\n    - <span class=\"pl-ent\">name</span>:\
    \ <span class=\"pl-s\">Push packages and update index</span>\n      <span class=\"\
    pl-ent\">run</span>: <span class=\"pl-s\">|</span>\n<span class=\"pl-s\">    \
    \    spack -e . mirror set --push --oci-username ${{ github.actor }} --oci-password\
    \ \"${{ secrets.GITHUB_TOKEN }}\" local-buildcache</span>\n<span class=\"pl-s\"\
    >        spack -e . buildcache push --base-image ubuntu:22.04 --unsigned --update-index\
    \ local-buildcache</span>\n<span class=\"pl-s\"></span>      <span class=\"pl-ent\"\
    >if</span>: <span class=\"pl-s\">${{ !cancelled() }}</span></pre></div>\n<p>NOTE:\
    \ Make sure to add <code>if: ${{ !cancelled() }}</code>, so that binaries for\
    \ successfully\ninstalled packages are available also when a dependent fails to\
    \ build.</p>\n</li>\n</ol>\n<h3><a id=\"user-content-caching-your-own-binaries-in-private-repos-and-buildcaches\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#caching-your-own-binaries-in-private-repos-and-buildcaches\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Caching\
    \ your own binaries in <em>private</em> repos and buildcaches</h3>\n<p>When your\
    \ local buildcache is stored in a private GitHub package,\nyou need to specify\
    \ the OCI credentials already <em>before</em> <code>spack concretize</code>.\n\
    This is because Spack needs to fetch the buildcache index. Also, remember to\n\
    remove the <code>--push</code> flag from <code>spack mirror set</code>, since\
    \ fetching needs\ncredentials too:</p>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre><span class=\"pl-ent\">jobs</span>:\n  <span class=\"pl-ent\">example-private</span>:\n\
    \    <span class=\"pl-ent\">steps</span>:\n    - <span class=\"pl-ent\">name</span>:\
    \ <span class=\"pl-s\">Login</span>\n      <span class=\"pl-ent\">run</span>:\
    \ <span class=\"pl-s\">spack -e . mirror set --oci-username ${{ github.actor }}\
    \ --oci-password \"${{ secrets.GITHUB_TOKEN }}\" local-buildcache</span>\n\n \
    \   - <span class=\"pl-ent\">name</span>: <span class=\"pl-s\">Concretize</span>\n\
    \      <span class=\"pl-ent\">run</span>: <span class=\"pl-s\">spack -e . concretize</span>\n\
    \n    - <span class=\"pl-ent\">name</span>: <span class=\"pl-s\">Install</span>\n\
    \      <span class=\"pl-ent\">run</span>: <span class=\"pl-s\">spack -e . install\
    \ --no-check-signature</span>\n\n    - <span class=\"pl-ent\">name</span>: <span\
    \ class=\"pl-s\">Push packages and update index</span>\n      <span class=\"pl-ent\"\
    >run</span>: <span class=\"pl-s\">spack -e . buildcache push --base-image ubuntu:22.04\
    \ --unsigned --update-index local-buildcache</span></pre></div>\n<p>From a security\
    \ perspective, notice that the <code>GITHUB_TOKEN</code> is exposed to every\n\
    subsequent job step. (This is no different from <code>docker login</code>, which\
    \ also likes\nto store credentials in the home directory.)</p>\n<h2><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n\
    <p>If you want to make more packages available, contribute to\n<a href=\"spack.yaml\"\
    >spack.yaml</a>.</p>\n<h2><a id=\"user-content-build-strategy\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#build-strategy\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Build strategy</h2>\n<p>Since\
    \ compiling software in GitHub actions is relatively slow, this stack is\nbuilt\
    \ using <code>concretizer:reuse:dependencies</code>. That means that the latest\n\
    versions of the packages listed in <a href=\"spack.yaml\">spack.yaml</a> are built,\
    \ but\ntheir dependencies are only updated when a package compatibility rule requires\n\
    it. The stack is currently built on demand, not on a schdule.</p>\n<h2><a id=\"\
    user-content-license\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #license\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>This project is part of Spack. Spack is distributed under the terms of both\
    \ the\nMIT license and the Apache License (Version 2.0). Users may choose either\n\
    license, at their option.</p>\n<p>All new contributions must be made under both\
    \ the MIT and Apache-2.0 licenses.</p>\n<p>See LICENSE-MIT, LICENSE-APACHE, COPYRIGHT,\
    \ and NOTICE for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-811652</p>\n"
  stargazers_count: 5
  subscribers_count: 5
  topics: []
  updated_at: 1707067801.0
spack/gitlab-runners:
  data_format: 2
  description: Images used to run Gitlab pipelines in the cloud
  filenames:
  - spack.yaml
  full_name: spack/gitlab-runners
  latest_release: v2024-01-29
  readme: '<p>This repository contains images that are used to run Gitlab pipelines
    to validate PRs in Spack.</p>

    <p>The recipes have been modified from ones in: <a href="https://github.com/UO-OACISS/e4s">https://github.com/UO-OACISS/e4s</a></p>

    '
  stargazers_count: 2
  subscribers_count: 11
  topics: []
  updated_at: 1685684158.0
spack/localized-docs:
  data_format: 2
  description: Localized documentation for Spack
  filenames:
  - spack.yaml
  full_name: spack/localized-docs
  latest_release: null
  readme: "<h1><a id=\"user-content-localized-documentation-for-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#localized-documentation-for-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Localized\
    \ Documentation for Spack</h1>\n<p>This repository contains translations of <a\
    \ href=\"/spack/spack\">Spack</a>'s\ndocumentation.  It implements the workflow\
    \ described in the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">Sphinx docs</a>.</p>\n<p>The instructions here describe how\
    \ you can contribute by:</p>\n<ol>\n<li>Adding to an existing translation, and</li>\n\
    <li>Creating a translation in a new language.</li>\n</ol>\n<h2><a id=\"user-content-prerequisites\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#prerequisites\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h2>\n\
    <ol>\n<li>\n<p>First, init the <code>spack</code> submodule:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">git clone\
    \ https://github.com/spack/localized-docs</span>\n$ <span class=\"pl-s1\"><span\
    \ class=\"pl-c1\">cd</span> localized-docs</span>\n$ <span class=\"pl-s1\">git\
    \ submodule init</span>\n$ <span class=\"pl-s1\">git submodule update</span></pre></div>\n\
    </li>\n<li>\n<p>To use this repository you'll need Sphinx, some plugins for it,\
    \ and\n<code>gettext</code>.  To install these dependencies, using <code>pip</code>\
    \ and <code>brew</code>, you\ncan run:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">pip3 install -r requirements.txt</span>\n$ <span\
    \ class=\"pl-s1\">brew install gettext</span></pre></div>\n<p>Using Spack, you\
    \ can just take advantage of the <code>spack.yaml</code> file at\nthe root of\
    \ this repo:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span\
    \ class=\"pl-c1\">spack install</span>\n<span class=\"pl-c1\">spack env activate\
    \ .</span></pre></div>\n<p>This will install the tools you need and put them in\
    \ your <code>PATH</code>.</p>\n</li>\n</ol>\n<h2><a id=\"user-content-adding-to-an-existing-translation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#adding-to-an-existing-translation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding to\
    \ an existing translation</h2>\n<p>Translations in this repository are stored\
    \ in <code>.po</code> files under\n<code>translations</code>.  There is one translation\
    \ per languages, and each file is\nnamed according to its\n<a href=\"https://www.gnu.org/software/gettext/manual/html_node/Language-Codes.html#Language-Codes\"\
    \ rel=\"nofollow\">ISO-639 language code</a>.\nSo, the Japanese translation data\
    \ for Spack is stored in\n<code>translations/ja.po</code>.</p>\n<p>If you want\
    \ to add to an existing translation, all you need to do is edit\nthe appropriate\
    \ <code>.po</code> file and add translated strings to it.  <code>.po</code> files\n\
    are comprised of <code>msgid</code>/<code>msgstr</code> pairs.  The <code>msgid</code>\
    \ corresponds to an\nEnglish string in the original documentation, and the <code>msgstr</code>\
    \ is its\ntranslation in the target language.  For example, for Japanese, the\n\
    translation of \"Basic Usage\" is stored like this:</p>\n<pre><code>#: ../spack/lib/spack/docs/basic_usage.rst:10\n\
    msgid \"Basic Usage\"\nmsgstr \"\u57FA\u672C\u7684\u306A\u4F7F\u3044\u65B9\"\n\
    </code></pre>\n<p>To add a translation:</p>\n<ol>\n<li>Update <code>msgstr</code>\
    \ elements in the appropriate <code>.po</code> files;</li>\n<li>Run <code>make</code>;</li>\n\
    <li>Commit the results;</li>\n<li>Submit a pull request so that we can merge your\
    \ changes.</li>\n</ol>\n<p>That's all!  Merged pull requests will automatically\
    \ trigger a rebuild of\nthe translated docs, and you should see your changes at\n\
    <a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\">spack.readthedocs.io</a>.</p>\n\
    <p>If you want to look at the documentation while you're editing it, running\n\
    <code>make</code> also generates per-language builds of the docs in <code>html/&lt;lang&gt;</code>.\n\
    So, to see the Japanese documentation, you can run <code>make</code> and open\n\
    <code>html/ja/index.html</code> in a local web browser.</p>\n<h2><a id=\"user-content-creating-a-new-translation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#creating-a-new-translation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ a new translation</h2>\n<p>To create a new translation, add the language to\
    \ the <code>languages</code> list in\nthe <code>Makefile</code>.  For example,\
    \ if the only language is Japanese (<code>ja</code>) and\nyou want to add German\
    \ (<code>de</code>), just add <code>de</code>:</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-smi\">languages</span> = ja de</pre></div>\n<p>Running\
    \ <code>make</code>, will create files in <code>docs</code>, <code>locale</code>,\
    \ and\n<code>translations</code>, and <code>html</code>:</p>\n<pre><code>    translations/de.po\
    \          # German translation file\n    translations/de.mo          # generated\
    \ from de.po\n    locale/de/LC_MESSAGES/*.mo  # symlinks to translations/de.mo\n\
    \    docs/de/                    # a Sphinx build directory for German docs\n\
    \    html/de/                    # HTML built by Sphinx from docs/de\n</code></pre>\n\
    <p>Add everything <em>except</em> <code>html</code>, then commit. <code>html</code>\
    \ is ignored by default\n(see <code>.gitignore</code>), so you can just run this:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >git add <span class=\"pl-c1\">.</span></span>\n$ <span class=\"pl-s1\">git commit</span></pre></div>\n\
    <p>See instructions above for how to start translating.</p>\n<h2><a id=\"user-content-workflow\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#workflow\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Workflow</h2>\n\
    <p>This repository implements the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\"\
    \ rel=\"nofollow\">workflow described here</a>.\nMost users will only need to\
    \ concern themselves with <code>translations/*.po</code>\nfiles, but we provide\
    \ a short summary here so that you can understand how\neverything works.</p>\n\
    <p>Translation is done as follows:</p>\n<ol>\n<li>\n<p>First, we use (or rather\
    \ Sphinx uses) the <code>gettext</code> tool to extract\nstrings to be translated\
    \ from each <code>.rst</code> document in the Spack\ndocumentation. This results\
    \ in a set of <code>.pot</code> files in\n<code>templates/*.pot</code>.  These\
    \ contain keys (<code>msgid</code>s) for unique strings,\nas well as their location\
    \ (file and line number) in the documentation.</p>\n</li>\n<li>\n<p>We merge the\
    \ <code>.pot</code> files into a single <code>merged.pot</code> file to eliminate\n\
    duplicate strings in multiple files.</p>\n</li>\n<li>\n<p><code>merged.pot</code>\
    \ is used to create an initial <code>translations/&lt;lang&gt;.po</code>\nfile.\
    \  Translations are added to <code>msgstr</code> fields in the <code>.po</code>\
    \ file.</p>\n</li>\n<li>\n<p>A single <code>translations/&lt;lang&gt;.mo</code>\
    \ file is generated from the <code>.po</code>\nfile. The <code>.mo</code> file\
    \ is in a special binary format.</p>\n</li>\n<li>\n<p>We generate symlinks in\
    \ <code>locale/&lt;lang&gt;/LC_MESSAGES/*.mo</code> that all\npoint back to the\
    \ single, unified <code>translations/&lt;lang&gt;.mo</code> file.  The\n<code>locale</code>\
    \ directory can then be used with Sphinx to build translated\ndocumentation.</p>\n\
    </li>\n</ol>\n<p>The top-level <code>Makefile</code> implements this workflow,\
    \ so you don't have to\nthink too much about it.</p>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>This repository is part of Spack, which distributed under the terms of\nboth\
    \ the MIT license and the Apache License (Version 2.0). Users may\nchoose either\
    \ license, at their option.</p>\n<p>All new contributions must be made under both\
    \ the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/localized-docs/blob/master/LICENSE-MIT\"\
    >LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/localized-docs//blob/master/LICENSE-APACHE\"\
    >LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/localized-docs/blob/master/COPYRIGHT\"\
    >COPYRIGHT</a>,\nand <a href=\"https://github.com/spack/localized-docs/blob/master/NOTICE\"\
    >NOTICE</a>\nfor details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n\
    <p>LLNL-CODE-647188</p>\n"
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1621989548.0
spack/spack-ci-containers:
  data_format: 2
  description: Container recipes used by Spack for test purposes
  filenames:
  - clingo/spack.yaml
  full_name: spack/spack-ci-containers
  latest_release: null
  readme: '<h1><a id="user-content-spack-ci-containers" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-ci-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Spack CI containers</h1>

    <p>This repository contains recipes for containers that are

    used to test Spack under CI.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-ci-containers/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1621989328.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-23.08/nvhpc/spack.yaml
  - NREL/configs/eagle/compilers/spack.yaml
  - NERSC/perlmutter/e4s-22.11/cuda/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/nvhpc/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cuda/spack.yaml
  - NERSC/perlmutter/e4s-22.05/nvhpc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/Frank-Jupiter/spack.yaml
  - NERSC/perlmutter/e4s-23.05/nvhpc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.08/spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/NERSC-Cori/gcc-spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/cce/spack.yaml
  - BOISESTATE/borah/environments/compilers/_spack.yaml
  - NERSC/perlmutter/e4s-23.05/gcc/spack.yaml
  - NERSC/perlmutter/e4s-23.05/data/spack.yaml
  - NERSC/perlmutter/e4s-23.08/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.05/spack.yaml
  - NREL/configs/rhodes/utilities/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/gcc/spack.yaml
  - NREL/configs/rhodes/compilers/spack.yaml
  - NREL/configs/eagle/utilities/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/tools/spack.yaml
  - NREL/configs/eagle/software/spack.yaml
  - NERSC/perlmutter/e4s-23.08/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cce/spack.yaml
  - OLCF/frontier/spack.yaml
  - NERSC/perlmutter/e4s-22.11/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/spack.yaml
  - NERSC/cori/e4s-21.02/prod/spack.yaml
  - OLCF/summit/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 57
  subscribers_count: 30
  topics: []
  updated_at: 1707318862.0
spack/spack-tutorial:
  data_format: 2
  description: Standalone Spack Tutorial Repository
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial
  latest_release: sc23
  readme: '<h1><a id="user-content--spack-tutorial" class="anchor" aria-hidden="true"
    tabindex="-1" href="#-spack-tutorial"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667"><img
    src="https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667"
    width="64" valign="middle" alt="Spack" data-canonical-src="https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg"
    style="max-width: 100%;"></a> Spack Tutorial</h1>

    <p><a href="https://spack-tutorial.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/cc15a98bdbe77c2664a8d15480c99dd7372c06ce4afabe1571236cb260e94717/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2d7475746f7269616c2f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/spack-tutorial/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Spack is a multi-platform package manager that builds and installs multiple
    versions and configurations of software. It works on Linux, macOS, and many supercomputers.
    Spack is non-destructive: installing a new version of a package does not break
    existing installations, so many configurations of the same package can coexist.</p>

    <p>This repository houses Spack''s <a href="https://spack-tutorial.readthedocs.io/en/latest/"
    rel="nofollow"><strong>hands-on tutorial</strong></a>, which is a subset of Spack''s
    <a href="https://spack.readthedocs.io/" rel="nofollow"><strong>full documentation</strong></a>
    (or you can run <code>spack help</code> or <code>spack help --all</code>).</p>

    <p>This tutorial covers basic to advanced usage, packaging, developer features,
    and large HPC deployments.  You can do all of the exercises on your own laptop
    using a Docker container. Feel free to use these materials to teach users at your
    organization about Spack.</p>

    <h2><a id="user-content-updating-the-tutorial" class="anchor" aria-hidden="true"
    tabindex="-1" href="#updating-the-tutorial"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Updating the tutorial</h2>

    <ol>

    <li>Create a new branch named for the event/milestone that corresponds to the
    new version you want to create.</li>

    <li>Upload screen shot of first slide (244px wide, .png) to <a href="https://github.com/spack/spack-tutorial/tree/master/tutorial/images">images
    directory</a> following existing file-naming convention.</li>

    <li>Upload PDF of slide deck to <a href="https://github.com/spack/spack-tutorial/tree/master/_static/slides">slides
    directory</a> following existing file-naming convention.</li>

    <li>Update <a href="https://github.com/spack/spack-tutorial/blob/master/index.rst">index.rst</a>
    with event name and date; full citation; and file paths for image and PDF.</li>

    <li>Update this README (lines 3 and 7) with link to new version''s URL.</li>

    <li>Build docs locally.</li>

    <li>Push changes to GitHub and active new tag/version on Read the Docs.</li>

    <li>Build new version on Read the Docs.</li>

    </ol>

    <h2><a id="user-content-updating-the-tutorial-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#updating-the-tutorial-container"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Updating the tutorial container</h2>

    <p>The Spack tutorial container is automatically built from <a href="docker/Dockerfile">repository</a>
    by <a href=".github/workflows/containers.yaml">this GitHub action</a>. The latest
    version is available at</p>

    <pre><code>ghcr.io/spack/tutorial:latest

    </code></pre>

    <p>and is rebuilt on a schedule. It can also be <a href="https://github.com/spack/spack-tutorial/actions">triggered
    manually</a>.</p>

    <p>The tutorial image builds on top of the container image that runs in Spack
    CI, which is built in a different repository at <a href="https://github.com/spack/gitlab-runners/">spack/gitlab-runners</a></p>

    <h2><a id="user-content-automatically-generating-command-ouputs" class="anchor"
    aria-hidden="true" tabindex="-1" href="#automatically-generating-command-ouputs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Automatically generating
    command ouputs</h2>

    <p>The tutorial <code>rst</code> files include output from Spack commands. This
    process is automated, and it is

    recommended not to run commands manually.</p>

    <p><strong>Note:</strong> as a preliminary step, check your terminal width. All
    current outputs

    are generated on a fixed terminal width <strong>94</strong>; deviating from that
    can cause

    unnecessarily large diffs:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">tput
    cols</span>

    <span class="pl-c1">94</span></pre></div>

    <p>To regenerate the outputs, run:</p>

    <div class="highlight highlight-source-shell"><pre>make -C outputs -j <span class="pl-k">&lt;</span>N<span
    class="pl-k">&gt;</span></pre></div>

    <p>This runs each <code>outputs/&lt;section&gt;.sh</code> script in parallel in
    a container, and collects outputs in

    <code>outputs/raw/*</code>. When all complete succesfully, the outputs are post-processed
    and put in

    <code>outputs/</code>.</p>

    <p>In case you want to restrict to particular sections, or if you need to modify
    the container

    executable and flags, specify those as variables in <code>outputs/Make.user</code>:</p>

    <div class="highlight highlight-source-makefile"><pre><span class="pl-smi">sections</span>
    := basics scripting

    <span class="pl-smi">DOCKER</span> := sudo docker</pre></div>

    <ul>

    <li>

    <p><code>make</code> will regenerate the relevant outputs when <code>outputs/&lt;section&gt;.sh</code>
    files are modified.</p>

    </li>

    <li>

    <p>To start from scratch, run <code>make clean</code></p>

    </li>

    <li>

    <p><code>make run-&lt;tab&gt;</code> can also be used to regenerate a particular
    section, but notice it will only

    create raw outputs.</p>

    </li>

    </ul>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the Apache
    License (Version 2.0). Users may choose either license, at their option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack/blob/develop/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack/blob/develop/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack/blob/develop/NOTICE">NOTICE</a> for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 39
  subscribers_count: 37
  topics:
  - tutorial
  updated_at: 1707472309.0
spack/spack-tutorial-container:
  data_format: 2
  description: Dockerfile and artifacts (minus build cache) to create Spack tutorial
    container.
  filenames:
  - spack.yaml
  full_name: spack/spack-tutorial-container
  latest_release: null
  readme: '<h1><a id="user-content-spack-tutorial-container" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-tutorial-container"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Spack Tutorial Container</h1>

    <p>This repository contains a container image you can use to do the

    <a href="https://spack.readthedocs.io/en/latest/tutorial.html" rel="nofollow">Spack
    Tutorial</a>.

    It''s exactly like the AWS images we use when we give the tutorial at

    conferences.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-tutorial-container/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 3
  subscribers_count: 8
  topics: []
  updated_at: 1657127710.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2024.02.05
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/2bb6ac78e5a9f4f688a6a066cc71b62012101802fcdb478e6e4c6b6ec75dc694/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/50bc1b5f5c5db66a2e646b0f45f184d8012412c6f9b4c36cee47d4ccedbb4db1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/cdc7257a23f3adea0c43ac91edd0780291ab8375e99198bfe972bce4934c9b61/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/424f1f41d024411d8bd1fe155067d6e555c47bd1e69a71fd0936d8f10a9e0447/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2024.02.05\"\
    ><img src=\"https://camo.githubusercontent.com/0a4358c648a8820225074301c60d06b2a743e5efe475eb26e6476992bc283fbf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032342e30322e30352d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2024.02.05-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.10619885\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8df5d8c8d8e7ca081567a2815477bf9936b9c8c3dcc0569543a82550891b323a/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e31303631393838352e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.10619885.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#what-is-spectre\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What is\
    \ SpECTRE?</h2>\n<p>SpECTRE is an open-source code for multi-scale, multi-physics\
    \ problems\nin astrophysics and gravitational physics. In the future, we hope\
    \ that\nit can be applied to problems across discipline boundaries in fluid\n\
    dynamics, geoscience, plasma physics, nuclear physics, and\nengineering. It runs\
    \ at petascale and is designed for future exascale\ncomputers.</p>\n<p>SpECTRE\
    \ is being developed in support of our collaborative Simulating\neXtreme Spacetimes\
    \ (SXS) research program into the multi-messenger\nastrophysics of neutron star\
    \ mergers, core-collapse supernovae, and\ngamma-ray bursts.</p>\n<h2><a id=\"\
    user-content-citing-spectre\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#citing-spectre\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing SpECTRE</h2>\n<p>Please cite SpECTRE in any publications that\
    \ make use of its code or data. Cite\nthe latest version that you use in your\
    \ publication. The DOI for this version\nis:</p>\n<ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.10619885\"\
    \ rel=\"nofollow\">10.5281/zenodo.10619885</a>\n</li>\n</ul>\n<p>You can cite\
    \ this BibTeX entry in your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"\
    ><pre><span class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and Nelli, Kyle C. and Armaza, Crist\\\
    'obal and Bonilla, Marceline S. and</span>\n<span class=\"pl-s\">H\\'ebert, Fran\\\
    c{c}ois and Kim, Yoonsoo and Kumar, Prayush and Lovelace,</span>\n<span class=\"\
    pl-s\">Geoffrey and Macedo, Alexandra and Moxon, Jordan and O'Shea, Eamonn and</span>\n\
    <span class=\"pl-s\">Pfeiffer, Harald P. and Scheel, Mark A. and Teukolsky, Saul\
    \ A. and Wittek,</span>\n<span class=\"pl-s\">Nikolas A. and others<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> = <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2024.02.05}<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span> = <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>2024.02.05<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">publisher</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Zenodo<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"\
    pl-s\">doi</span> = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>10.5281/zenodo.10619885<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>https://spectre-code.org<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">howpublished</span>\
    \ =\n<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.10619885}{10.5281/zenodo.10619885}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2024<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>2<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2><a id=\"\
    user-content-viewing-documentation\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#viewing-documentation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Viewing Documentation</h2>\n<p>The documentation can\
    \ be viewed at <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 135
  subscribers_count: 16
  topics: []
  updated_at: 1707244031.0
taliaferro/.dotfiles:
  data_format: 2
  description: null
  filenames:
  - .spack/environments/default/spack.yaml
  full_name: taliaferro/.dotfiles
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1703277101.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - thetagpu/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1><a id="user-content-spack-envs" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-envs"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-envs</h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2><a id="user-content-locally" class="anchor" aria-hidden="true" tabindex="-1"
    href="#locally"><span aria-hidden="true" class="octicon octicon-link"></span></a>Locally</h2>

    <p>Using Fedora Asahi Remix 39, make sure that dev tools are installed on the
    system:</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">dnf
    group install "Development Tools"</span>

    <span class="pl-c1">dnf group install "Development Libraries"</span>

    <span class="pl-c1">dnf group install "C Development Tools and Libraries"</span>

    <span class="pl-c1">dnf install gcc-gfortran</span></pre></div>

    <p>Change the default configuration is needed:</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: $spack/opt/spack</span>

    <span class="pl-c1">build_stage: $spack/var/spack/stage</span></pre></div>

    <p>Activate the environment and install it:</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    env activate ~/Dev/spack-envs/local</span>

    <span class="pl-c1">spack install</span></pre></div>

    <h3><a id="user-content-last-successful-installations" class="anchor" aria-hidden="true"
    tabindex="-1" href="#last-successful-installations"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Last successful installations:</h3>

    <table>

    <thead>

    <tr>

    <th>Date</th>

    <th>

    <code>spack-envs</code> commit</th>

    <th>Spack commit</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>2024-01-15</td>

    <td>``</td>

    <td></td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-grid5000" class="anchor" aria-hidden="true" tabindex="-1"
    href="#grid5000"><span aria-hidden="true" class="octicon octicon-link"></span></a>Grid5000</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: /my-spack/spack</span>

    <span class="pl-c1">build_stage: /tmp/spack-stage</span></pre></div>

    <h2><a id="user-content-argonne-national-lab" class="anchor" aria-hidden="true"
    tabindex="-1" href="#argonne-national-lab"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Argonne National Lab</h2>

    <h3><a id="user-content-thetagpu" class="anchor" aria-hidden="true" tabindex="-1"
    href="#thetagpu"><span aria-hidden="true" class="octicon octicon-link"></span></a>ThetaGPU</h3>

    <p>To be done</p>

    <h3><a id="user-content-polaris" class="anchor" aria-hidden="true" tabindex="-1"
    href="#polaris"><span aria-hidden="true" class="octicon octicon-link"></span></a>Polaris</h3>

    <p>To be done</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1678891926.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/karolina/bpmf-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/intelmpi/bpmf-gpi/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1635166163.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/hpccf/farm/genomics/spack.yaml
  - environments/hpccf/farm/core/spack.yaml
  - environments/hpccf/franklin/cluster-core/spack.yaml
  - environments/hpccf/farm/r-stack/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<h1><a id="user-content-spack--uc-davis" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack--uc-davis"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Spack @ UC Davis</h1>

    <h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters" class="anchor"
    aria-hidden="true" tabindex="-1" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack repos and configs
    for UC Davis HPCCF Clusters</h2>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1676322811.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - benchmarks/spack/isambard-macs/volta/spack.yaml
  - benchmarks/spack/cosma7/rockport-openmpi-compute-node/spack.yaml
  - benchmarks/spack/isambard-a64fx/compute-node/spack.yaml
  - benchmarks/spack/csd3-rocky8/sapphirerapids/spack.yaml
  - benchmarks/spack/isambard-macs/pascal/spack.yaml
  - benchmarks/spack/isambard-macs/rome/spack.yaml
  - benchmarks/spack/csd3-rocky8/icelake/spack.yaml
  - benchmarks/spack/dial2/compute-node/spack.yaml
  - benchmarks/spack/isambard-macs/cascadelake/spack.yaml
  - benchmarks/spack/dial3/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1><a id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#excalibur-tests\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks\
    \ and regression tests for the ExCALIBUR project.</p>\n<p>These benchmarks are\
    \ based on a similar project by\n<a href=\"https://github.com/stackhpc/hpc-tests\"\
    >StackHPC</a>.</p>\n<p><em><strong>Note</strong>: at the moment the ExCALIBUR\
    \ benchmarks are a work-in-progress.</em></p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>We require Python version 3.7 or later. Install the <strong>excalibur-tests</strong>\
    \ package with <code>pip</code> by</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pip install -e <span class=\"pl-c1\">.</span></pre></div>\n<p>The <code>-e/--editable</code>\
    \ flag is recommended for two reasons.</p>\n<ul>\n<li>Spack installs packages\
    \ in a <code>opt</code> directory under the spack environment. With <code>-e</code>\
    \ the spack\nenvironment remains in your local directory and <code>pip</code>\
    \ creates symlinks to it. Without <code>-e</code> spack\nwill install packages\
    \ inside your python environment.</li>\n<li>For <a href=\"https://setuptools.pypa.io/en/latest/userguide/development_mode.html\"\
    \ rel=\"nofollow\">development</a>,\nthe <code>-e</code> flag to <code>pip</code>\
    \ links the installed package to the files in the local\ndirectory, instead of\
    \ copying, to allow making changes to the installed package.</li>\n</ul>\n<p>Note\
    \ that to use <code>-e</code> with a project configured with a <code>pyproject.toml</code>\
    \ you need <code>pip</code> version 22 or later.</p>\n<p>On most systems, it is\
    \ recommended to install the package in a virtual environment.\nFor example, using\
    \ the python3 <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow\"\
    >built-in virtual environment tool <code>venv</code></a>,\ncreate an environment\
    \ called <code>my_environment</code> with</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python3 -m venv ./my_environment</pre></div>\n<p>and activate it with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">source</span>\
    \ ./my_environment/bin/activate</pre></div>\n<h3><a id=\"user-content-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>The <code>pip install</code> command will install a compatible version of <strong>ReFrame</strong>\
    \ from\n<a href=\"https://pypi.org/project/ReFrame-HPC/\" rel=\"nofollow\">PyPi</a>.\
    \ However, you will have to\nmanually provide an installation of <strong>Spack</strong>.</p>\n\
    <p><a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager\
    \ specifically designed for HPC\nfacilities. In some HPC facilities there may\
    \ be already a central Spack installation available.\nHowever, the version installed\
    \ is most likely too old to support all the features\nused by this package. Therefore\
    \ we recommend you install the latest version locally,\nfollowing the instructions\
    \ below.</p>\n<p><em><strong>Note</strong>: if you have already installed spack\
    \ locally and you want to upgrade to\na newer version, you might first have to\
    \ clear the cache to avoid conflicts:\n<code>spack clean -m</code></em></p>\n\
    <p>Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official instructions</a>\nto install the latest version of\
    \ Spack (summarised here for convenience, but not guaranteed to be\nup-to-date):</p>\n\
    <ul>\n<li>git clone spack:\n<code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code>\n\
    </li>\n<li>run spack setup script: <code>source ./spack/share/spack/setup-env.sh</code>\n\
    </li>\n<li>check spack is in <code>$PATH</code>, for example <code>spack --version</code>\n\
    </li>\n</ul>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable. This\
    \ is taken care of by the <code>setup-env.sh</code>\nscript as above, and you\
    \ can have your shell init script (e.g. <code>.bashrc</code>)\ndo that automatically\
    \ in every session, by adding the following lines to it:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame also requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRAC projects in\n\
    <a href=\"https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack\"\
    >https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack/</a>.\n\
    If you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system if known, otherwise it will automatically\ncreate a very basic environment\
    \ (see \"Usage on unsupported systems\" section below).</p>\n<h2><a id=\"user-content-configuration\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuration</h2>\n\
    <h3><a id=\"user-content-reframe\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#reframe\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ReFrame</h3>\n<p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\"\
    \ rel=\"nofollow\">ReFrame</a> is a high-level\nframework for writing regression\
    \ tests for HPC systems.  For our tests we\nrequire ReFrame v4.1.3.</p>\n<p>We\
    \ provide a ReFrame configuration file with the settings of some systems that\n\
    are part of the ExCALIBUR or DiRAC projects.  You can point ReFrame to this file\
    \ by\nsetting the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILES\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILES</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILES=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-smi\">${PWD}</span>/benchmarks/reframe_config.py<span class=\"pl-pds\"\
    >\"</span></span></pre></div>\n<p>If you want to use a different ReFrame configuration\
    \ file, for example because\nyou use a different system, you can set this environment\
    \ variable to the path of\nthat file.</p>\n<p><strong>Note</strong>: in order\
    \ to use the Spack build system in ReFrame, the <code>spack</code>\nexecutable\
    \ must be in the <code>PATH</code> also on the compute nodes of a cluster, if\n\
    you want to run your benchmarks on them. This is taken care of by adding it\n\
    to your init file (see spack section above).</p>\n<p>However, you will also need\
    \ to set the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ (<code>export RFM_USE_LOGIN_SHELL=\"true\"</code>) in order to make ReFrame\
    \ use</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash -l</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a> line, which would load\nthe user's init script.</p>\n<h2><a id=\"\
    user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <p>Once you have set up Spack and ReFrame, you can execute a benchmark with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/BENCH_NAME\
    \ -r --performance-report</pre></div>\n<p>where <code>benchmarks/apps/BENCH_NAME</code>\
    \ is the directory where the benchmark is.  The command\nabove assumes you have\
    \ the program <code>reframe</code> in your PATH.  If you have followed the instructions\n\
    to install using <code>pip</code> into the default directory, it should have been\
    \ automatically added.\nIf it is not the case, call <code>reframe</code> with\
    \ its relative or absolute path.</p>\n<p>For example, to run the Sombrero benchmark\
    \ in the <code>benchmarks/apps/sombrero</code> directory you can\nuse</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/sombrero\
    \ -r --performance-report</pre></div>\n<p>For benchmarks that use the Spack build\
    \ system, the tests define a default Spack specification\nto be installed in the\
    \ environment, but users can change it when invoking ReFrame on the\ncommand line\
    \ with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3><a id=\"user-content-setting-environment-variables\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#setting-environment-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting\
    \ environment variables</h3>\n<p>All the built-in fields of ReFrame regression\
    \ classes can be set on a per-job basis using the\n<code>-S</code> command-line\
    \ option. One useful such field is\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.env_vars\"\
    \ rel=\"nofollow\"><code>env_vars</code></a>,\nwhich controls the environment\
    \ variables used in a job.\nThe syntax to set dictionary items, like for <code>env_vars</code>,\
    \ is a comma-separated list of <code>key:value</code> pairs: <code>-S dict=key_1:value_1,key_2:value_2</code>.\n\
    For example</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S env_vars=OMP_PLACES:threads\n</code></pre>\n<p>runs the <code>benchmarks/apps/sombrero</code>\
    \ benchmark setting the environment variable <code>OMP_PLACES</code>\nto <code>threads</code>.</p>\n\
    <h3><a id=\"user-content-selecting-system-and-queue-access-options\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#selecting-system-and-queue-access-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  To avoid this, you can use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3><a id=\"user-content-usage-on-unsupported-systems\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#usage-on-unsupported-systems\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage on\
    \ unsupported systems</h3>\n<p>The configuration provided in <a href=\"./reframe_config.py\"\
    ><code>reframe_config.py</code></a> lets you run the\nbenchmarks on pre-configured\
    \ HPC systems.  However you\ncan use this framework on any system by choosing\
    \ the \"default\" system with <code>--system default</code>, or by using your\
    \ own ReFrame configuration.  You can use the \"default\" system to run\nbenchmarks\
    \ in ReFrame without using a queue manager or an MPI launcher (e.g. on a personal\
    \ workstation).</p>\n<p>If you choose the \"default\" system and a benchmark using\
    \ the Spack build system,\na new empty Spack environment will be automatically\
    \ created in\n<code>benchmarks/spack/default</code> when ReFrame is launched for\
    \ the first time.\nYou should populate the environment with the packages already\
    \ installed on your system\nbefore running Spack to avoid excessively rebuilding\
    \ system packages. See the\n<em>Spack configuration</em> section of <a href=\"\
    ./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on how\n\
    to set up a Spack environment.\nIn particular, make sure that at least a compiler\
    \ and an MPI library are added into the environment.\nAfter the Spack environment\
    \ is set up, tell ReFrame to use it by setting the environment\nvariable <code>EXCALIBUR_SPACK_ENV</code>,\
    \ as described above.</p>\n<h3><a id=\"user-content-system-specific-flags\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#system-specific-flags\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System-specific\
    \ flags</h3>\n<p>While the aim is to automate as much system-specific configuration\
    \ as possible, there are some options that have to be provided by the user, such\
    \ as accounting details, and unfortunately the syntax can vary.\nThe file <a href=\"\
    ./SYSTEMS.md\"><code>SYSTEMS.md</code></a> contains information about the use\
    \ of this framework on specific systems.</p>\n<h3><a id=\"user-content-selecting-multiple-benchmarks\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#selecting-multiple-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ multiple benchmarks</h3>\n<p>ReFrame tests may contain tags that allow the user\
    \ to select which tests to run. These can be leveraged to defined sets of benchmarks.\
    \ To run all tests in a directory, pass the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-R\"\
    \ rel=\"nofollow\"><code>-R</code> flag</a> to ReFrame. Then filter down to a\
    \ specific tag by passing the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-0\"\
    \ rel=\"nofollow\"><code>-t</code> flag</a>.</p>\n<p>For example, the <a href=\"\
    https://github.com/ukri-excalibur/excalibur-tests/blob/1a7377e885977833c150569c32eb1db478f63087/benchmarks/examples/sombrero/sombrero.py#L113\"\
    >tag \"example\" is defined</a> in the sombrero example. To select the sombrero\
    \ example out of all benchmarks, run</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>reframe -c benchmarks/ -R -r -t example</pre></div>\n<p>Tests can contain\
    \ multiple tags. To create a custom set of benchmarks, add a new tag to the tests\
    \ you want to include in the set.</p>\n<h2><a id=\"user-content-contributing-new-systems-or-benchmarks\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing-new-systems-or-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\
    \ <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 14
  subscribers_count: 8
  topics: []
  updated_at: 1707148519.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-38/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: v1.1.0
  stargazers_count: 22
  subscribers_count: 6
  topics:
  - jupyter
  - ipython
  - ipython-widget
  - ipywidget
  - jupyter-notebook
  - jupyterhub
  - notebook
  updated_at: 1707548128.0
