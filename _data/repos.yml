AMReX-Codes/pyamrex:
  data_format: 2
  description: '[Experimental] AMReX Python Bindings'
  filenames:
  - spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: null
  readme: '<h1><a id="user-content-pyamrex" class="anchor" aria-hidden="true" href="#pyamrex"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>pyAMReX</h1>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width: 100%;"></a> <a target="_blank" rel="noopener noreferrer nofollow"
    href="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"><img
    src="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"
    alt="Python3 API: Pre-Alpha" title="Status: Pre-Alpha" data-canonical-src="https://img.shields.io/badge/phase-pre--alpha-yellowgreen"
    style="max-width: 100%;"></a>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License AMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a><br>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    alt="linux" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    alt="macos" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    alt="windows" style="max-width: 100%;"></a></p>

    <p>pyAMReX is part of AMReX.</p>

    <p>Due to its <strong>highly experimental</strong> nature, we develop it currently
    in a separate respository.</p>

    <p>We will add further information here once first development versions are ready
    for testing.</p>

    <h2><a id="user-content-users" class="anchor" aria-hidden="true" href="#users"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Users</h2>

    <p><em>to do</em></p>

    <ul>

    <li>pip/pypa</li>

    <li>conda-forge</li>

    <li>spack</li>

    <li>brew</li>

    <li>...</li>

    </ul>

    <h3><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h3>

    <p><em>to do</em></p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <h2><a id="user-content-developers" class="anchor" aria-hidden="true" href="#developers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Developers</h2>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <h3><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B17" rel="nofollow">C++17</a>
    compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.20.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.10.1+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.7+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://www.openmp.org" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (for
    CUDA support, needs 3.7.9+ and 4.2+ is recommended)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <p>Optional CUDA-capable dependencies for tests include:</p>

    <ul>

    <li>

    <a href="https://github.com/cupy/cupy#installation">cupy</a> 11.2+</li>

    <li>

    <a href="https://numba.readthedocs.io/en/stable/user/installing.html" rel="nofollow">numba</a>
    0.56+</li>

    <li>

    <a href="https://pytorch.org/get-started/locally/" rel="nofollow">torch</a> 1.12+</li>

    </ul>

    <h3><a id="user-content-install-dependencies" class="anchor" aria-hidden="true"
    href="#install-dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Install
    Dependencies</h3>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.20.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional:                                    --user</span>

    python3 -m pip install -U pip setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <h3><a id="user-content-configure-your-compiler" class="anchor" aria-hidden="true"
    href="#configure-your-compiler"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configure
    your compiler</h3>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    python3 -m pip install -U -r requirements.txt

    python3 -m pip install -v --force-reinstall --no-deps <span class="pl-c1">.</span></pre></div>

    <p>If you are iterating on builds, it will faster to rely on <code>ccache</code>
    and to let CMake call the <code>pip</code> install logic:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build

    cmake --build build --target pip_install -j 8</pre></div>

    <h3><a id="user-content-test" class="anchor" aria-hidden="true" href="#test"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Test</h3>

    <p>After successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests</span>

    python3 -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python3 -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python3 -m pytest tests/test_intvect.py::test_iv_conversions


    <span class="pl-c"><span class="pl-c">#</span> Run all tests, do not capture "print"
    output and be verbose</span>

    python3 -m pytest -s -vvvv tests/</pre></div>

    <h3><a id="user-content-build-options" class="anchor" aria-hidden="true" href="#build-options"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Options</h3>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>1/2/<strong>3</strong>

    </td>

    <td>Dimension of AMReX</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>PYBIND11_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    <tr>

    <td><code>PYAMREX_LIBDIR</code></td>

    <td><em>None</em></td>

    <td>If set, search for pre-built a pyAMReX library</td>

    </tr>

    <tr>

    <td><code>PYINSTALLOPTIONS</code></td>

    <td><em>None</em></td>

    <td>Additional options for <code>pip install</code>, e.g., <code>-v --user</code>

    </td>

    </tr>

    </tbody>

    </table>

    <p>For example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgements</h2>

    <p>This work was supported by the Laboratory Directed Research and Development
    Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy
    Contract No. DE-AC02-05CH11231.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>pyAMReX Copyright (c) 2021-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for pyamrex can be found at <a href="LICENSE">LICENSE</a>.</p>

    '
  stargazers_count: 12
  subscribers_count: 15
  topics:
  - amrex
  - python
  updated_at: 1663744274.0
AMReX-Microelectronics/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronic
  filenames:
  - Docs/spack.yaml
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" href="#artemis"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a development
    fork of WarpX for modeling micromagnetics and electrodynamic waves in next-generation
    microelectornics.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1665515384.0
Alpine-DAV/spack_configs:
  data_format: 2
  description: spack envs
  filenames:
  - _experimental/envs/alpinedav/ubuntu_18_devel/spack.yaml
  - _experimental/envs/olcf/summit/spack.yaml
  - _experimental/envs/alpinedav/ubuntu_18_cuda_10.1_devel/spack.yaml
  - _experimental/envs/llnl/pascal-cuda/spack.yaml
  - _experimental/envs/llnl/quartz/spack.yaml
  full_name: Alpine-DAV/spack_configs
  latest_release: null
  readme: '<h1><a id="user-content-spack_configs" class="anchor" aria-hidden="true"
    href="#spack_configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack_configs</h1>

    <p>shared spack configs repo</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1639176281.0
CUP-ECS/beatnik:
  data_format: 2
  description: Initial Cabana/Cajita Low/High-order Z-model Interface Solver. Benchmark
    for evaluating the performance of algorithms requiring global communication. Beatnik
    is also a precursor to potential later a High Performance Parallel Interface solver.
  filenames:
  - configs/unm-hopper/spack.yaml
  full_name: CUP-ECS/beatnik
  latest_release: null
  readme: '<h1><a id="user-content-beatnik---a--prototype-high-performance-parallel-interface-benchmark"
    class="anchor" aria-hidden="true" href="#beatnik---a--prototype-high-performance-parallel-interface-benchmark"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Beatnik - A  prototype
    High Performance Parallel Interface Benchmark</h1>

    <h2><a id="user-content-description" class="anchor" aria-hidden="true" href="#description"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Description</h2>

    <p>Beatnik is a benchmark for global communication based on Pandya and Shkoller''s
    3D fluid interace "Z-Model" in the Cabana/Cajita mesh framework [1]. The goals

    of Beatnik are to:</p>

    <ol>

    <li>Provide an interesting and meaningful benchmark for numerical methods that
    require global communication, particularly fast fourier transforms and fast multipole
    methods.</li>

    <li>Understand the performance characteristics of different parallel decompositions
    of the Z-Model based on both a 2D decomposition based on logical mesh location
    location and a space-filling curve mesh decomposition.</li>

    <li>Provide a working prototype parallel implementation of the fluid interface
    model that other implementations can use to understand the implementation.</li>

    </ol>

    <p>The initial Beatnik implementation of the Z-Model uses a simple mesh-based
    representation of the surface manifold with a regular decomposition as a Cajita
    2D mesh in I/J space and the physical position of each element in the mesh stored
    as a separate vector in the nodes of the mesh. This is efficient for the low-order
    z-model, as the computation of surface normals, artificial viscosity, and Fourier
    transforms for estimating interface velocities are straightforward in this representation.</p>

    <p>Because Beatnik does not yet include a mesh decomposition on with spatial decomppsotion
    of the manifold, its support for scalable far-field solvers in the higher-order
    interface solution models (e.g. the fast multipole method, P3M, or distance-sorting
    cutoff-based methods) is limited. In particular, Beatnik 1.0 currently only supports
    either O(N^2) brute-force calculation of far-field forces or the use of an external
    far-field force solver that re-sorts the mesh at each

    derivative calculation.</p>

    <p>In the future, we plan to add the ability to decompose the Beatnik mesh spatially
    but adding a ParticleMesh abstraction that implements Cajita meshes using

    Cabana particle abstractions. This will in turn enable the direct implementation
    of scalable far-field force methods. This work is planned for Beatnik 2.0.</p>

    <h2><a id="user-content-building-beatnik" class="anchor" aria-hidden="true" href="#building-beatnik"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building Beatnik</h2>

    <p>Beatnik relies on multiple external packages to build, including:</p>

    <ul>

    <li>LLNL''s build, link, test (BLT) library [2]</li>

    <li>ECP CoPA''s Cabana/Cajita particle and mesh framework [3]</li>

    <li>UT-Knoxville''s HeFFTe fast fourier transform library [4]</li>

    <li>The FFTW fast fourier transform library [5]</li>

    <li>A high-performance MPI implementation such as OpenMPI, MPICH, or MVAPICH

    As such, building Beatnik can be somewhat complicated.</li>

    <li>[Optional] UT-Austin''s PVFMM fast multipole solver [6]</li>

    </ul>

    <p>To ease building Beatnik, the configs/ directory includes Spack configuration
    files for building it in spack environments on multiple systems and test case
    run scripts for those systems, as well as a spack package description for directly
    building Beatnik. This spack package will be contributed back to the mainline
    Spack repository following the first public Beatnik release.</p>

    <h3><a id="user-content-building-beatnik-in-a-spack-environment" class="anchor"
    aria-hidden="true" href="#building-beatnik-in-a-spack-environment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Building Beatnik in a Spack Environment</h3>

    <p>Assuming that you have Spack already installed on your HPC systems (as described
    at XXX), you may use spack to create an environment for building and developing
    spack as follows:</p>

    <ol>

    <li>If not checked out from git recursively, checkout all needed Beatnik submodules,
    e.g. <code>git submodule init &amp;&amp; git submodule update --recursive</code>

    </li>

    <li>Create a build directory for housing the Spack environment and housing the
    out-of-source build, e.g. <code>mkdir build-hopper</code> on the UNM hopper compute
    cluster.</li>

    <li>Copy the appropriate spack.yaml file from configs/[systemname]/ to spack.yaml
    in the newly-created build directory, e.g. <code>cp configs/unm-hopper/spack.yaml
    build-hopper/</code>

    </li>

    <li>Perform any compiler setup needed using the system module system, as spack
    environments do not necessarily configure the compiler, e.g. <code>module load
    gcc/11.2.0</code>. This compiler should be compatible with one used in the spack.yaml
    file chosen, and ideally described in a README.md file in the associated configs/
    directory</li>

    <li>Change directory to the created build directory and create a spack environment
    in which to build Beatnik in that directory, e.g. <code>cd build-hopper; spack
    env create -d . spack.yaml</code>

    </li>

    <li>Activate, concretize, and install the resulting environment, e.g. <code>spack
    env activate -d . &amp;&amp; spack concretize &amp;&amp; spack install</code>

    </li>

    <li>Run cmake and make to create the appropriate Makefiles and build using them,
    e.g. <code>cmake .. &amp;&amp; make</code>.</li>

    </ol>

    <h3><a id="user-content-building-beatnik-directly-using-a-spack-package-description"
    class="anchor" aria-hidden="true" href="#building-beatnik-directly-using-a-spack-package-description"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building Beatnik directly
    using a Spack package description</h3>

    <p>XXX</p>

    <h3><a id="user-content-developing-beatnik-using-a-spack-package-description"
    class="anchor" aria-hidden="true" href="#developing-beatnik-using-a-spack-package-description"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Developing Beatnik
    using a Spack package description</h3>

    <p>XXX</p>

    <h3><a id="user-content-beatnik-build-time-configuration-options" class="anchor"
    aria-hidden="true" href="#beatnik-build-time-configuration-options"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Beatnik Build-Time Configuration Options</h3>

    <ul>

    <li>

    <code>ENABLE_PVFMM=ON</code> - Enables the PVFMM fast multipole solver for direct
    calculation of the Birchoff-Rott integral far-field forces. Activated at runtime
    through the option ''-b pvfmm''</li>

    </ul>

    <h2><a id="user-content-running-beatnik" class="anchor" aria-hidden="true" href="#running-beatnik"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running Beatnik</h2>

    <p>By default, Beatnik solves a simple multi-mode rocket rig problem sized for
    a

    single serial CPU core with approximately 4GB of memory. It also includes

    command line options to change initial problem state, I/O frequency, and to

    weak-scale scale up the initial problem to larger number of processes.</p>

    <h3><a id="user-content-general-command-line-parameters" class="anchor" aria-hidden="true"
    href="#general-command-line-parameters"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>General command line parameters</h3>

    <ul>

    <li>

    <code>-x [cuda|threads|serial]</code> - The node-level parallelism/accelerator
    backend to use</li>

    <li>

    <code>-F [write-frequency]</code> - Interval between timesteps when I/O is written</li>

    <li>

    <code>-O [solution order]</code> - Order of solver to use (''high'', ''medium'',
    or ''low''). ''low'' is the default.</li>

    <li>`-w [weak scaling factor] - Scale up the problem specification, including
    the x/y bounding box, to be N times larger</li>

    </ul>

    <h3><a id="user-content-problem-specific-command-line-parameters" class="anchor"
    aria-hidden="true" href="#problem-specific-command-line-parameters"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Problem-specific command line parameters</h3>

    <ul>

    <li>

    <code>-n [i/j mesh dimension ]</code> - Number of points on the interface manifold
    in the I and J dimensions</li>

    <li>

    <code>-I [interface initialization]</code> - Function to use for interface initial
    condition. Currently only ''cos'' and ''sech2'' are supported.</li>

    <li>

    <code>-m [magnitude]</code> - The maximum magnitude of the initialization function.</li>

    <li>

    <code>-p [period]</code> - The number of periods of the interface in the initial
    bounding box</li>

    <li>

    <code>-a [atwood]</code> - Atwood''s constant for the difference in pressure between
    the two fluids</li>

    <li>

    <code>-g [gravity]</code> - Gravitational acceleration in the -Z direction</li>

    <li>

    <code>-a [atwood]</code> -  Atwood''s constant for the difference in pressure
    between the two fluids</li>

    <li>

    <code>-M [mu]</code> - Mu, the artificial viscosity constant used in the Z-Model</li>

    <li>

    <code>-e [epsilon]</code> - Epsilon, the desingularization constant used in the
    Z-Model expressed as a fraction of the distance between interface mesh points</li>

    </ul>

    <h3><a id="user-content-example-1-periodic-multi-mode-rocket-rig" class="anchor"
    aria-hidden="true" href="#example-1-periodic-multi-mode-rocket-rig"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Example 1: Periodic Multi-mode Rocket
    Rig</h3>

    <p>The simplest test case and the one to which the rocketrig example program defaults
    is an initial interface distributed according to a cosine function. Simple usage
    examples:</p>

    <ol>

    <li>Serial execution: <code>bin/rocketrig -x serial</code>

    </li>

    <li>Cuda execution (on systems with GPUs) with a 512x512 mesh: <code>bin/rocketrig
    -x cuda -n 512</code>

    </li>

    <li>Cuda execution with a 1024x1024 problem scaled up to be sixteen times as large
    in terms of bounding box and number of total points: bin/rocketrig -x cuda -n
    1024 -F 0 -w 16`</li>

    </ol>

    <h3><a id="user-content-example-1-periodic-multi-mode-rocket-rig-1" class="anchor"
    aria-hidden="true" href="#example-1-periodic-multi-mode-rocket-rig-1"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Example 1: Periodic Multi-mode Rocket
    Rig</h3>

    <p>Another test case is a single-mode rollup test where the intitial interface
    is

    set according to a hyperbolic secant function. This testcase recreates the

    XXX experiment and the results in Panda and Shkoller''s paper from section XXX.<br>

    To run this testcase with a high-order model, use the following command line

    parameters. Note that we assume a GPU accelerator, as the exact high-order far

    field force solver is very compute intensive and is generally impractical for
    non-trivial mesh sizes without GPU acceleration:</p>

    <p><code>bin/rocketrig -x cuda -O high -n 64 -I sech2 -m 0.1 -p 9.0 -F 1 -a 0.15
    -M 2 -e 2</code></p>

    <h2><a id="user-content-planned-development-steps" class="anchor" aria-hidden="true"
    href="#planned-development-steps"><span aria-hidden="true" class="octicon octicon-link"></span></a>Planned
    Development Steps</h2>

    <p>Beatnik is being implemented in multiple distinct steps, with associated planned
    releases:</p>

    <ul>

    <li>

    <p>Version 1.0 Features</p>

    <ol>

    <li>A low-order model implementation that relies on Cajita/HeFFTe Fourier transforms
    for estimating velocity interface at mesh points.</li>

    <li>A high-order model implementation based on either exact or PVFMM for computing
    long-range forces</li>

    <li>A medium-order model that uses the Fourier transform for estimating interface
    velocity and the fast multipole method for estimating how the vorticity changes
    at each interface point.</li>

    <li>Support for periodic boundary conditions and free boundary conditions</li>

    <li>Multiple Benchmark examples, including a single-mode gaussian roll-up test
    and the rocket rig experiment.</li>

    <li>Direct support for weak scaling of benchmarks through command line arguments</li>

    </ol>

    </li>

    <li>

    <p>Version 1.1 Expected Features</p>

    <ol>

    <li>A cutoff-based approach for calculating far-field forces using the Cabana
    particle framework that accelerates far-field force calculations by avoiding the
    complex hierarchical communications and calculations in the fast multipole solver.</li>

    <li>Improved timestep, desingularization, and artificial viscosity handling to
    provide good defaults for the input parameters given</li>

    <li>Additional interface initializatin options, including gaussian random and
    file-based interface initialization (also used for checkpointing)</li>

    <li>Support for coupling with other applications through either I/O (e.g. ADIOS)
    or Communication (e.g. Portage) approaches</li>

    <li>Additional test cases</li>

    </ol>

    </li>

    <li>

    <p>Version 2.0 Expected Features</p>

    <ol>

    <li>Spatial partitioning of the mesh using a space-filling curve to better optimize
    the high-order model</li>

    <li>Direct fast multipole or P3M solver for scalable, high precision high-order
    model solves.</li>

    </ol>

    </li>

    </ul>

    <h2><a id="user-content-acknowledgement-contributors-and-copyright-information"
    class="anchor" aria-hidden="true" href="#acknowledgement-contributors-and-copyright-information"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgement, Contributors,
    and Copyright Information</h2>

    <p>Beatnik is primarily availble as open source under a 3-Clause BSD License.
    It is being developed at the University of New Mexico, University of Tennessee
    at Chatanooga, and the University of Alabama under funding the U.S. Department
    of Energy''s Predictive Science Academic Alliance Partnership III (PSAAP-III)
    program. Contributors to Beatnik development include the following:</p>

    <ul>

    <li>Patrick G. Bridges (<a href="mailto:patrickb@unm.edu">patrickb@unm.edu</a>)</li>

    <li>Thomas Hines (<a href="mailto:thomas-hines-01@utc.edu">thomas-hines-01@utc.edu</a>)</li>

    <li>Jered Dominguez-Trujillo (<a href="mailto:jereddt@unm.edu">jereddt@unm.edu</a>)</li>

    </ul>

    <p>The general structure of Beatnik and the rocketrig examples were taken from
    the ExaMPM proxy application (<a href="https://github.com/ECP-copa/ExaMPM">https://github.com/ECP-copa/ExaMPM</a>)
    developed by the ECP Center for Particle Applications (CoPA), which was also available
    under a 3-Clause BSD License when used for creating application structure.</p>

    <h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>References</h2>

    <p>[1] Gavin Pandya and Steve Shkoller. "3d Interface Models for Raleigh-Taylor
    Instability." Published as arxiv.org preprint <a href="https://arxiv.org/abs/2201.04538"
    rel="nofollow">https://arxiv.org/abs/2201.04538</a>, 2022.</p>

    <p>[2] <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a></p>

    <p>[3] <a href="https://github.com/ECP-copa/Cabana/">https://github.com/ECP-copa/Cabana/</a></p>

    <p>[4] Innovative Computing Laboratory. "heFFTe." URL: <a href="https://icl.utk.edu/fft/"
    rel="nofollow">https://icl.utk.edu/fft/</a></p>

    <p>[5] Matteo Frigo. "A Fast Fourier Transform Compiler," In the Proceedings of
    the 1999 ACM SIGPLAN Conference on Programming Language Design and Implementation
    (PLDI ''99), Atlanta, Georgia, May 1999</p>

    <p>[6] <a href="https://pvfmm.org" rel="nofollow">https://pvfmm.org</a></p>

    '
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1667423505.0
CUP-ECS/ping-pong-gpu:
  data_format: 2
  description: null
  filenames:
  - configs/unm-hopper/spack-openmpi+ucx.yaml
  - build-hpctoolkit/spack-spectrum.yaml
  - build-mvapich/spack-mvapich.yaml
  - build-xlc/spack-xlc-spectrum.yaml
  - configs/unm-hopper/spack-mpich+yaksa.yaml
  - configs/unm-hopper/spack-mpich+yaksa+ucx.yaml
  - build-xlc/spack-xlc-mvapich.yaml
  - configs/llnl-lassen/spack-mvapich.yaml
  - build-lassen-spectrum/spack.yaml
  - configs/llnl-lassen/spack-spectrum.yaml
  full_name: CUP-ECS/ping-pong-gpu
  latest_release: null
  readme: '<h1><a id="user-content-gpu-ping-pong-benchmark" class="anchor" aria-hidden="true"
    href="#gpu-ping-pong-benchmark"><span aria-hidden="true" class="octicon octicon-link"></span></a>GPU
    Ping Pong Benchmark</h1>

    <p>Basic regular mesh ping pong benchmark for GPUs written in Kokkos. Baseline
    for

    comparison is a Kokkos parallel loop that packs the data prior to sending. Mesh

    data structure extracted from UNM Fiesta CFD application.</p>

    <h2><a id="user-content-running" class="anchor" aria-hidden="true" href="#running"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running</h2>

    <p>Arguments:</p>

    <ul>

    <li>-n: Length of one face of the mesh being communicated (resulting communciation
    is n * n * 5 * 3 doubles</li>

    <li>-i: Number of iterations to perform</li>

    <li>-d: Face of mesh to communicate (0 = y/z, 1 = x/z, 2 = x/y)</li>

    <li>-m: Mode to use for sending and receiving (0 = MPI datatypes, 1 = Hand gpu
    pack, gpu-aware MPI, 2 = Hand gpu pack, host memory send)</li>

    </ul>

    <p>Example command line:

    <code>srun --mpi=pmi2 --ntasks 2 --gpus-per-task=1 --tasks-per-node=1 -p cup-ecs
    ping_pong -n 200 -i 100 -d 1 -m 0</code></p>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Spack configuration files for different MPIs are in the configs/ directory.
    Generally

    we create spack environments for building, use a setup script to load any necessary

    modules (generally the compiler, which the spack environment doesn''t necessarily

    provide), and activate the spack environment for the buiuld</p>

    <h2><a id="user-content-future-features" class="anchor" aria-hidden="true" href="#future-features"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Future features</h2>

    <ol>

    <li>Option to pack into pinned host memory instead of GPU memory</li>

    <li>Restructure to support other ping pong of data structures extracted from

    other applications.</li>

    <li>Option to change number of ghost cell layers sent</li>

    </ol>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1667693779.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/22.08/rocm.spack.yaml
  - environments/22.08/cuda-aarch64.spack.yaml
  - environments/22.08/cuda-ppc64le.spack.yaml
  - environments/22.08/oneapi.spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#e4s\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n<ul>\n<li>User\
    \ Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\">https://e4s.readthedocs.io</a>\n\
    </li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub: <a href=\"https://github.com/E4S-Project/\"\
    >https://github.com/E4S-Project/</a>\n</li>\n<li>Slack Channel: <a href=\"https://e4s-project.slack.com\"\
    \ rel=\"nofollow\">https://e4s-project.slack.com</a>\n</li>\n<li>E4S Dashboard:\
    \ <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\
    >E4S-Project/E4S-Project.github.io</a> - E4S Documentation repo that is hosted\
    \ on <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 16
  subscribers_count: 9
  topics: []
  updated_at: 1663940188.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, t-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/desktop/spack-ubuntu-cuda.yaml
  - Tools/machines/desktop/spack-macos-openmp.yaml
  - Tools/machines/desktop/spack-debian-cuda.yaml
  - Docs/spack.yaml
  - Tools/machines/desktop/spack-ubuntu-openmp.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '22.11'
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" href="#warpx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667"
    alt="Gitter" data-canonical-src="https://badges.gitter.im/ECP-WarpX/community.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1016/j.parco.2021.102833" rel="nofollow"><img src="https://camo.githubusercontent.com/1f6ca17eba9f0dbca214c58a50e39d5e4d2c5513476e963147c57c7b9f40f378/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313031362f6a2e706172636f2e323032312e3130323833332d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1016/j.parco.2021.102833-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced electromagnetic Particle-In-Cell code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our Gitter room at <a href="https://gitter.im/ECP-WarpX/community" rel="nofollow">https://gitter.im/ECP-WarpX/community</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 153
  subscribers_count: 16
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1667928829.0
ECP-WarpX/impactx:
  data_format: 2
  description: 'ImpactX: an s-based beam dynamics code including space charge effects'
  filenames:
  - docs/spack.yaml
  full_name: ECP-WarpX/impactx
  latest_release: '22.11'
  readme: "<h1><a id=\"user-content-impactx\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#impactx\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ImpactX</h1>\n<p><a href=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml\"\
    ><img src=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml/badge.svg\"\
    \ alt=\"CI Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://impactx.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1090ab96071a0b6311590a818911f8b10c5d65e31760367fbaed373f8d727e03/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f696d70616374782f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/impactx/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\"\
    \ alt=\"License ImpactX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://impactx.readthedocs.io/en/latest/install/users.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://doi.org/10.5281/zenodo.6954922\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/baf88cee0be27d736412a9f20b5bbbcf3474dd6522e2c3aed8acb112ef750bd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e363935343932322d626c75652e737667\"\
    \ alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.6954922-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.48550/arXiv.2208.02382\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0ce1f03bff8ee943abcb746f0129abb1a359bb5e010f3a5d95f5bda86b7fff59/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e34383535302f61725869762e323230382e30323338322d626c75652e737667\"\
    \ alt=\"DOI (paper)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(paper)-10.48550/arXiv.2208.02382-blue.svg\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://en.wikipedia.org/wiki/Software_release_life_cycle\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d8c054b6da1ff81634c84041dfe111aec24b166c8ea31edb0ade140ea2c9015/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646576656c6f706d656e742532307374617475732d626574612d6f72616e67652e737667\"\
    \ alt=\"Development Status\" data-canonical-src=\"https://img.shields.io/badge/development%20status-beta-orange.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://isocpp.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\"\
    \ alt=\"Language: C++17\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://python.org/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\"\
    \ alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>ImpactX: an s-based beam dynamics code\
    \ including space charge effects.\nThis is the next generation of the <a href=\"\
    https://github.com/impact-lbl/IMPACT-Z\">IMPACT-Z</a> code.</p>\n<h2><a id=\"\
    user-content-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n\
    <p>In order to learn how to install and run the code, please see the online documentation:\n\
    <a href=\"https://impactx.readthedocs.io\" rel=\"nofollow\">https://impactx.readthedocs.io</a></p>\n\
    <ul>\n<li>ImpactX Doxygen: <a href=\"https://impactx.readthedocs.io/en/latest/_static/doxyhtml\"\
    \ rel=\"nofollow\">https://impactx.readthedocs.io/en/latest/_static/doxyhtml</a>\n\
    </li>\n<li>AMReX Doxygen: <a href=\"https://amrex-codes.github.io/amrex/doxygen\"\
    \ rel=\"nofollow\">https://amrex-codes.github.io/amrex/doxygen</a>\n</li>\n<li>WarpX\
    \ Doxygen: <a href=\"https://warpx.readthedocs.io/en/latest/_static/doxyhtml\"\
    \ rel=\"nofollow\">https://warpx.readthedocs.io/en/latest/_static/doxyhtml</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contributing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contributing</h2>\n<p><a href=\"https://amrex-codes.github.io/\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\"\
    \ alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our workflow is described in <a href=\"\
    CONTRIBUTING.rst\">CONTRIBUTING.rst</a>.</p>\n<h2><a id=\"user-content-developer-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#developer-environment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developer Environment</h2>\n\
    <p>Please prepare you local development environment as follows.\nPick <em>one</em>\
    \ of the methods below:</p>\n<h3><a id=\"user-content-perlmutter-nersc\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#perlmutter-nersc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Perlmutter (NERSC)</h3>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>ssh perlmutter-p1.nersc.gov</pre></div>\n\
    <p>Now <code>cd</code> to your ImpactX source directory.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>module load cmake/3.22.0\nmodule swap PrgEnv-nvidia\
    \ PrgEnv-gnu\nmodule load cudatoolkit\nmodule load cray-hdf5-parallel/1.12.1.1\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Python</span>\nmodule load\
    \ cray-python/3.9.7.1\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\">-d</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$HOME</span>/sw/perlmutter/venvs/impactx<span class=\"pl-pds\">\"</span></span>\
    \ ]\n<span class=\"pl-k\">then</span>\n  <span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx/bin/activate\n<span\
    \ class=\"pl-k\">else</span>\n  python3 -m pip install --user --upgrade pip\n\
    \  python3 -m pip install --user virtualenv\n  python3 -m venv <span class=\"\
    pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx\n  <span class=\"pl-c1\">source</span>\
    \ <span class=\"pl-smi\">$HOME</span>/sw/perlmutter/venvs/impactx/bin/activate\n\
    \n  python3 -m pip install --upgrade pip\n  MPICC=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>cc -target-accel=nvidia80 -shared<span class=\"pl-pds\">\"</span></span>\
    \ python3 -m pip install -U --no-cache-dir -v mpi4py\n  python3 -m pip install\
    \ -r requirements.txt\n<span class=\"pl-k\">fi</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> GPU-aware MPI</span>\n<span class=\"pl-k\">export</span>\
    \ MPICH_GPU_SUPPORT_ENABLED=1\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ necessary to use CUDA-Aware MPI and run a job</span>\n<span class=\"pl-k\">export</span>\
    \ CRAY_ACCEL_TARGET=nvidia80\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optimize CUDA compilation for A100</span>\n<span class=\"pl-k\">export</span>\
    \ AMREX_CUDA_ARCH=8.0\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compiler\
    \ environment hints</span>\n<span class=\"pl-k\">export</span> CC=cc\n<span class=\"\
    pl-k\">export</span> CXX=CC\n<span class=\"pl-k\">export</span> FC=ftn\n<span\
    \ class=\"pl-k\">export</span> CUDACXX=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>which nvcc<span class=\"pl-pds\">)</span></span>\n<span class=\"pl-k\"\
    >export</span> CUDAHOSTCXX=CC</pre></div>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> configure</span>\ncmake\
    \ -S <span class=\"pl-c1\">.</span> -B build_perlmutter -DImpactX_COMPUTE=CUDA\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compile</span>\ncmake --build\
    \ build_perlmutter -j 10\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ test</span>\nsrun -N 1 --ntasks-per-gpu=1 -t 0:10:00 -C gpu -c 32 -G 4 --qos=debug\
    \ -A m3906_g ctest --test-dir build_perlmutter --output-on-failure\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> run</span>\n<span class=\"pl-c1\">cd</span>\
    \ build_perlmutter/bin\nsrun -N 1 --ntasks-per-gpu=1 -t 0:10:00 -C gpu -c 32 -G\
    \ 4 --qos=debug -A m3906_g ./impactx ../../examples/fodo/input_fodo.in</pre></div>\n\
    <h3><a id=\"user-content-cori-knl-nersc\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#cori-knl-nersc\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Cori KNL (NERSC)</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>ssh cori.nersc.gov</pre></div>\n<p>Now <code>cd</code> to your ImpactX source\
    \ directory.</p>\n<div class=\"highlight highlight-source-shell\"><pre>module\
    \ swap craype-haswell craype-mic-knl\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule\
    \ load cmake/3.22.1\nmodule load cray-hdf5-parallel/1.10.5.2\nmodule load cray-fftw/3.3.8.10\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Python</span>\nmodule load\
    \ cray-python/3.9.7.1\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\">-d</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\"\
    >$HOME</span>/sw/knl/venvs/impactx<span class=\"pl-pds\">\"</span></span> ]\n\
    <span class=\"pl-k\">then</span>\n  <span class=\"pl-c1\">source</span> <span\
    \ class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx/bin/activate\n<span class=\"\
    pl-k\">else</span>\n  python3 -m pip install --user --upgrade pip\n  python3 -m\
    \ pip install --user virtualenv\n  python3 -m venv <span class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx\n\
    \  <span class=\"pl-c1\">source</span> <span class=\"pl-smi\">$HOME</span>/sw/knl/venvs/impactx/bin/activate\n\
    \n  python3 -m pip install --upgrade pip\n  MPICC=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>cc -shared<span class=\"pl-pds\">\"</span></span> python3 -m\
    \ pip install -U --no-cache-dir -v mpi4py\n  python3 -m pip install -r requirements.txt\n\
    <span class=\"pl-k\">fi</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ tune exactly for KNL sub-architecture</span>\n<span class=\"pl-k\">export</span>\
    \ CXXFLAGS=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-march=knl<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">export</span> CFLAGS=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>-march=knl<span class=\"pl-pds\"\
    >\"</span></span></pre></div>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> configure</span>\ncmake\
    \ -S <span class=\"pl-c1\">.</span> -B build_knl\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> compile</span>\ncmake --build build_knl -j 8\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> test</span>\nsrun -C knl -N 1 -t\
    \ 30 -q debug ctest --test-dir build_knl --output-on-failure\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> run</span>\n<span class=\"pl-c1\">cd</span>\
    \ build_knl/bin\nsrun -C knl -N 1 -t 30 -q debug ./impactx ../../examples/fodo/input_fodo.in</pre></div>\n\
    <h3><a id=\"user-content-homebrew-macos\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#homebrew-macos\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Homebrew (macOS)</h3>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew update\nbrew install adios2      <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> for openPMD</span>\nbrew install ccache\nbrew install cmake\n\
    brew install fftw\nbrew install git\nbrew install hdf5-mpi    <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> for openPMD</span>\nbrew install libomp      <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for OpenMP</span>\nbrew install\
    \ pkg-config  <span class=\"pl-c\"><span class=\"pl-c\">#</span> for fftw</span>\n\
    brew install open-mpi</pre></div>\n<h3><a id=\"user-content-apt-debianubuntu\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#apt-debianubuntu\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Apt (Debian/Ubuntu)</h3>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>sudo apt update\nsudo apt install\
    \ build-essential ccache cmake g++ git libfftw3-mpi-dev libfftw3-dev libhdf5-openmpi-dev\
    \ libopenmpi-dev pkg-config python3 python3-matplotlib python3-numpy python3-scipy</pre></div>\n\
    <h3><a id=\"user-content-spack-linux\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #spack-linux\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack\
    \ (Linux)</h3>\n<div class=\"highlight highlight-source-shell\"><pre>spack env\
    \ create impactx-dev\nspack env activate impactx-dev\nspack add adios2       \
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> for openPMD</span>\nspack\
    \ add ccache\nspack add cmake\nspack add fftw\nspack add hdf5          <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> for openPMD</span>\nspack add mpi\nspack\
    \ add pkgconfig     <span class=\"pl-c\"><span class=\"pl-c\">#</span> for fftw</span>\n\
    spack add python\nspack add py-pip\nspack add py-setuptools\nspack add py-wheel\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> OpenMP support on macOS</span>\n\
    [[ <span class=\"pl-smi\">$OSTYPE</span> <span class=\"pl-k\">==</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span>darwin<span class=\"pl-pds\">'</span></span><span\
    \ class=\"pl-k\">*</span> ]] <span class=\"pl-k\">&amp;&amp;</span> spack add\
    \ llvm-openmp\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:\
    \ Linux only</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>spack add\
    \ cuda</span>\n\nspack install\npython3 -m pip install matplotlib numpy openpmd-api\
    \ pandas pytest scipy</pre></div>\n<p>In new terminals, re-activate the environment\
    \ with <code>spack env activate impactx-dev</code> again.</p>\n<h3><a id=\"user-content-conda-linuxmacoswindows\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#conda-linuxmacoswindows\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conda (Linux/macOS/Windows)</h3>\n\
    <div class=\"highlight highlight-source-shell\"><pre>conda create -n impactx-dev\
    \ -c conda-forge adios2 ccache cmake compilers git hdf5 fftw matplotlib ninja\
    \ numpy pandas pytest scipy\nconda activate impactx-dev\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> compile with -DImpactX_MPI=OFF</span></pre></div>\n\
    <h2><a id=\"user-content-get-the-source-code\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#get-the-source-code\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Get the Source Code</h2>\n<p>Before you start, you\
    \ will need a copy of the ImpactX source code:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>git clone git@github.com:ECP-WarpX/impactx.git\n<span class=\"pl-c1\">cd</span>\
    \ impactx</pre></div>\n<h2><a id=\"user-content-compile\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#compile\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Compile</h2>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> find dependencies &amp; configure</span>\n\
    cmake -S <span class=\"pl-c1\">.</span> -B build\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> compile</span>\ncmake --build build -j 4</pre></div>\n\
    <p>That's all!\nImpactX binaries are now in <code>build/bin/</code>.\nMost people\
    \ execute these binaries directly or copy them out.</p>\n<p>You can inspect and\
    \ modify build options after running <code>cmake -S . -B</code> build with either</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>ccmake build</pre></div>\n\
    <p>or by adding arguments with <code>-D&lt;OPTION&gt;=&lt;VALUE&gt;</code> to\
    \ the first CMake call, e.g.:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DImpactX_COMPUTE=CUDA\
    \ -DImpactX_MPI=OFF</pre></div>\n<h3><a id=\"user-content-python-compile\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#python-compile\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Python Compile</h3>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> find dependencies &amp; configure</span>\ncmake -S <span class=\"pl-c1\"\
    >.</span> -B build -DImpactX_PYTHON=ON\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> compile &amp; install</span>\ncmake --build build -j 4 --target\
    \ pip_install</pre></div>\n<h2><a id=\"user-content-run\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#run\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Run</h2>\n<p>An executable ImpactX binary with the current compile-time\
    \ options encoded in its file name will be created in <code>build/bin/</code>.</p>\n\
    <p>Additionally, a symbolic link named <code>impactx</code> can be found in that\
    \ directory, which points to the last built ImpactX executable.</p>\n<p>The command-line\
    \ syntax for this executable is:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">Usage: impactx &lt;inputs-file&gt; [some.overwritten.option=value]...</span>\n\
    \n<span class=\"pl-c1\">Mandatory arguments (remove the &lt;&gt;):</span>\n<span\
    \ class=\"pl-c1\">  inputs-file     the path to an input file; can be relative\
    \ to the current</span>\n<span class=\"pl-c1\">                  working directory\
    \ or absolute.</span>\n<span class=\"pl-c1\">                  Example: input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">Optional arguments (remove the []):</span>\n<span class=\"\
    pl-c1\">  options         this can overwrite any line in an inputs-file</span>\n\
    <span class=\"pl-c1\">                  Example: quad1.ds=0.5 sbend1.rc=1.5</span>\n\
    \n<span class=\"pl-c1\">Examples:</span>\n<span class=\"pl-c1\">  In the current\
    \ working directory, there is a file \"input_fodo.in\" and the</span>\n<span class=\"\
    pl-c1\">  \"impactx\" executable.</span>\n<span class=\"pl-c1\">  The line to\
    \ execute would look like this:</span>\n<span class=\"pl-c1\">    ./impactx input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">  In the current working directory, there is a file \"\
    input_fodo.in\" and the</span>\n<span class=\"pl-c1\">  executable \"impactx\"\
    \ is in a directory that is listed in the \"PATH\"</span>\n<span class=\"pl-c1\"\
    >  environment variable.</span>\n<span class=\"pl-c1\">  The line to execute would\
    \ look like this:</span>\n<span class=\"pl-c1\">    impactx input_fodo.in</span>\n\
    \n<span class=\"pl-c1\">  In the current working directory, there is a file \"\
    input_fodo.in\" and the</span>\n<span class=\"pl-c1\">  \"impactx\" executable.\
    \ We want to voerwrite the segment length of the beamline</span>\n<span class=\"\
    pl-c1\">  element \"quad1\" that is already defined in it. We also want to change\
    \ the</span>\n<span class=\"pl-c1\">  radius of curvature of the bending magnet\
    \ \"sbend1\" to a different value than</span>\n<span class=\"pl-c1\">  in the\
    \ file \"input_fodo.in\".</span>\n<span class=\"pl-c1\">  The line to execute\
    \ would look like this:</span>\n<span class=\"pl-c1\">    ./impactx input_fodo.in\
    \ quad1.ds=0.5 sbend1.rc=1.5</span></pre></div>\n<h2><a id=\"user-content-test\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#test\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Test</h2>\n<p>In order to run our\
    \ tests, you need to have a few Python packages installed:</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">python3 -m\
    \ pip install -U pip setuptools wheel pytest</span>\n<span class=\"pl-c1\">python3\
    \ -m pip install -r examples/requirements.txt</span></pre></div>\n<p>You can run\
    \ all our tests with:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">ctest --test-dir build --output-on-failure</span></pre></div>\n\
    <p>Further options:</p>\n<ul>\n<li>help: <code>ctest --test-dir build --help</code>\n\
    </li>\n<li>list all tests: <code>ctest --test-dir build -N</code>\n</li>\n<li>only\
    \ run tests that have \"FODO\" in their name: <code>ctest --test-dir build -R\
    \ FODO</code>\n</li>\n</ul>\n<h2><a id=\"user-content-acknowledgements\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#acknowledgements\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h2>\n<p>This\
    \ work was supported by the Laboratory Directed Research and Development Program\
    \ of Lawrence Berkeley National Laboratory under U.S. Department of Energy Contract\
    \ No. DE-AC02-05CH11231.</p>\n<h2><a id=\"user-content-copyright-notice\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#copyright-notice\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Copyright Notice</h2>\n<p>Copyright\
    \ (c) 2022, The Regents of the University of California, through Lawrence Berkeley\
    \ National Laboratory (subject to receipt of any required approvals from the U.S.\
    \ Dept. of Energy).\nAll rights reserved.</p>\n<p>If you have questions about\
    \ your rights to use or distribute this software, please contact Berkeley Lab's\
    \ Intellectual Property Office at <a href=\"mailto:IPO@lbl.gov\">IPO@lbl.gov</a>.</p>\n\
    <p>NOTICE. This Software was developed under funding from the U.S. Department\
    \ of Energy and the U.S. Government consequently retains certain rights.  As such,\
    \ the U.S. Government has been granted for itself and others acting on its behalf\
    \ a paid-up, nonexclusive, irrevocable, worldwide license in the Software to reproduce,\
    \ distribute copies to the public, prepare derivative works, and perform publicly\
    \ and display publicly, and to permit others to do so.</p>\n<p>Please see the\
    \ full license agreement in <a href=\"LICENSE.txt\">LICENSE.txt</a>, which is\
    \ the <code>BSD-3-Clause-LBNL</code> license.</p>\n"
  stargazers_count: 9
  subscribers_count: 7
  topics:
  - simulation
  - beam-dynamics
  - particle-in-cell
  - gpu
  - physics
  - pic
  - particle
  - accelerator
  - research
  updated_at: 1667486944.0
ExCALIBUR-NEPTUNE/NESO:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: ExCALIBUR-NEPTUNE/NESO
  latest_release: null
  readme: "<p>This is a test implementation of a PIC solver for 1+1D Vlasov Poisson,\
    \ written\nin C++/DPC++.\nThis is primarily designed to test the use of multiple\
    \ repos/workflows for\ndifferent code components.</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>CMake</li>\n\
    <li>Boost &gt;= 1.74 (for tests)</li>\n<li>SYCL implementation Hipsycl and fftw\
    \ or OneAPI and MKL.</li>\n<li>Nektar++</li>\n</ul>\n<h3><a id=\"user-content-building-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#building-with-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building with Spack</h3>\n<p>The\
    \ easiest way to install NESO is using the\n<a href=\"https://spack.readthedocs.io/en/latest/index.html\"\
    \ rel=\"nofollow\">Spack package manager</a>, although\nthis can take a few hours\
    \ the first time you do it or if you change\ncompilers. This repository has been\
    \ set up so you can use a\nvariation of the <a href=\"https://spack-tutorial.readthedocs.io/en/latest/tutorial_developer_workflows.html\"\
    \ rel=\"nofollow\">Spack developer\nworkflow</a>. Simply\nrun the following commands\
    \ at the top level of the repository:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>git submodule update --init  <span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Probably not necessary, but just to be safe</span>\nspack env activate -p -d\
    \ <span class=\"pl-c1\">.</span>\nspack install</pre></div>\n<p>This creates an\
    \ <a href=\"https://spack.readthedocs.io/en/latest/environments.html#anonymous-environments\"\
    \ rel=\"nofollow\">anonymous Spack\nenvironment</a>\nbased on the settings in\
    \ <a href=\"spack.yaml\">the spack.yaml file</a>. These\nconfigurations tell Spack\
    \ to install NESO and all of its\ndependencies. Rather\nthan pulling fresh NESO\
    \ source code from GitHub,\nit will use the copy of the code in your current working\n\
    directory. These packages will be installed in the usual Spack\nlocations. They\
    \ will also be linked into a <a href=\"https://spack.readthedocs.io/en/latest/environments.html#filesystem-views\"\
    \ rel=\"nofollow\">\"filesystem\nview\"</a>\nlocated at <code>.spack-env/view/</code>.\
    \ Environment variables such as <code>PATH</code>\nand <code>CMAKE_PREFIX_PATH</code>\
    \ were updated to include the view directory and\nits subdirectories when you\
    \ called <code>spack env activate...</code>.\nThe NESO build will be done in a\
    \ directory called something\nlike <code>spack-build-6gyyv2t</code> (the hash\
    \ at the end will differ).\nBinaries, however, are placed in the <code>bin</code>\
    \ directory at the\ntop level of the repository. They are not currently installed.\
    \ This is\na bug and will likely change in future.</p>\n<h4><a id=\"user-content-using-gcc\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-gcc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using GCC</h4>\n<p>By default,\
    \ the build (as set in <code>spack.yaml</code>) uses GCC, along with the\nFFTW\
    \ and hipSYCL libraries.</p>\n<h4><a id=\"user-content-building-with-oneapi\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#building-with-oneapi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Building with OneAPI</h4>\n<p>To\
    \ build with the Intel OneAPI compilers, modify <code>spack.yaml</code> by\ncommenting\
    \ out the <code>neso%gcc</code> spec and uncommenting the <code>neso%oneapi</code>\n\
    spec. The latter spec will use MKL instead of FFTW and OpenBLAS and\nDPC++ instead\
    \ of hipSYCL. It has been found that the oneAPI and clang\ncompilers struggle\
    \ to build NumPy and Boost due to very large memory\nrequirements. As such, the\
    \ spec has been set to use other compilers\nfor this (the Intel Classic compilers\
    \ by default). Feel free to\nexperiment with changing these or seeing if there\
    \ is a way to make the\nbuilds work with oneAPI.</p>\n<p>For this to work, you\
    \ must have the Intel compilers installed\nand <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html#compiler-configuration\"\
    \ rel=\"nofollow\">registered with\nSpack</a>. Note\nthat the Intel implementation\
    \ of SYCL currently requires the\nenvironment variable <code>LD_LIBRARY_PATH</code>\
    \ to be set at run-time. As such,\nthe binaries will only run when the environment\
    \ is active.</p>\n<p>Sometimes when switching between compilers, CMake doesn't\
    \ seem to\nfully reset on the first attempt of the build. It is not clear why\n\
    this is the case, but the issue seems to be resolved by running the\n<code>spack\
    \ install</code> command again.</p>\n<h4><a id=\"user-content-developing\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#developing\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Developing</h4>\n<p>As you develop\
    \ the code, there are a few options for how you\nrecompile. One is simply to run\
    \ <code>spack install</code> again. This will\nreuse the existing build directory\
    \ and reinstall the results of the\nbuild. The build environment used is determined\
    \ by the packages\nconfiguration for NESO (as specificed in the NESO <a href=\"\
    https://github.com/ExCALIBUR-NEPTUNE/NESO-Spack\">package\nrepository</a> and\
    \ is\nthe same as if you were doing a traditional Spack installation of a\nnamed\
    \ version of NESO. The main disadvantage of this approach is that\nSpack hides\
    \ the output of CMake during the build process and will only\nshow you any information\
    \ on the build if there is an error. This means\nyou will likely miss any compiler\
    \ warnings, unless you check the build\nlogs. Spack is also quite slow when running\
    \ like this, as it needs to\nrun its full dependency concretization process.</p>\n\
    <p>An alternative approach is to prefix your usual build commands with\n<code>spack\
    \ build-env neso</code>. This will cause the commands to be run in the\nsame build\
    \ environment used for <code>spack install</code>. For example, you\ncould run</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>spack build-env neso cmake\
    \ <span class=\"pl-c1\">.</span> -B build\nspack build-env neso cmake --build\
    \ build</pre></div>\n<p>This would cause the build to occur in the directory <code>build</code>.\
    \ This\napproach works quite well. The only slight downside is the commands are\n\
    a bit cumbersome.</p>\n<p>Finally, you can take advantage of the fact that the\
    \ filesystem view\nwhich was loaded when you activated the environment gives you\
    \ access\nto all of the resources for the build that you need. As such, you\n\
    could just run</p>\n<div class=\"highlight highlight-source-shell\"><pre>cmake\
    \ <span class=\"pl-c1\">.</span> -B build\ncmake --build build</pre></div>\n<p>CMake\
    \ will automatically be able to find all of the packages it needs\nin <code>.spack-env/view/</code>.\
    \ The downside of this approach is that there is\na risk CMake will end up using\
    \ a different compiler or compiler\nversion than was used to build all of the\
    \ dependencies. This is\nespecially likely if not using a system compiler. You\
    \ should\nensure you are aware of what compilers you have installed and, if\n\
    necessary, explicitly specify to CMake which you want to use.</p>\n<h3><a id=\"\
    user-content-manually-installing-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#manually-installing-dependencies\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Manually Installing Dependencies</h3>\n<h4><a\
    \ id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"#cmake\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CMake</h4>\n\
    <p>Ensure a recent version of <a href=\"https://cmake.org/download/\" rel=\"nofollow\"\
    >CMake</a> is available.\nIf necessary, install with</p>\n<pre><code>wget https://github.com/Kitware/CMake/releases/download/v3.23.1/cmake-3.23.1.tar.gz\n\
    tar xvf cmake-3.23.1.tar.gz\ncd cmake-3.23.1/\n./configure\nmake\n</code></pre>\n\
    <h4><a id=\"user-content-boost\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #boost\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Boost</h4>\n\
    <p>The test suite requires the <a href=\"https://www.boost.org/\" rel=\"nofollow\"\
    >Boost library</a> (version &gt;= 1.74).\nIf this is not available on your system,\
    \ it can be built from source by doing</p>\n<pre><code>wget https://boostorg.jfrog.io/artifactory/main/release/1.79.0/source/boost_1_79_0.tar.gz\n\
    tar xvf boost_1_79_0.tar.gz\ncd boost_1_79_0/\n./bootstrap.sh\n./b2\n</code></pre>\n\
    <p>If the install is not automatically found by cmake, specify the path to the\n\
    install dir at configure time:</p>\n<pre><code>cmake -DBoost_INCLUDE_DIR=/path/to/boost_1_79_0/\
    \ . -B build\n</code></pre>\n<h4><a id=\"user-content-nektar\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#nektar\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Nektar++</h4>\n<p>To build with Nektar++, ensure that\
    \ Nektar++ is installed on your system.\nDetailed instructions can be found in\
    \ the <a href=\"https://doc.nektar.info/userguide/latest/user-guidese3.html#x7-60001.3\"\
    \ rel=\"nofollow\">Nektar user guide</a>,\nbut briefly,</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>git clone https://gitlab.nektar.info/nektar/nektar\n\
    <span class=\"pl-c1\">cd</span> nektar\nmkdir build <span class=\"pl-k\">&amp;&amp;</span>\
    \ <span class=\"pl-c1\">cd</span> build\ncmake .. \ncmake --build <span class=\"\
    pl-c1\">.</span>\nmake install</pre></div>\n<p>should install Nektar++.</p>\n\
    <p>To build NESO with Nektar++, set the <code>Nektar++_DIR</code> flag in cmake,\
    \ e.g.</p>\n<pre><code>cmake -DNektar++_DIR=/path/to/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>where <code>/path/to/nektar/build/dist/lib64/nektar++/cmake</code>\
    \ is the folder containing\nthe <code>Nektar++Config.cmake</code> file.\nNote\
    \ that for this file to exist, you must do <code>make install</code> at the end\
    \ of the\nNektar++ build.</p>\n<h3><a id=\"user-content-manually-building-neso\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#manually-building-neso\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manually building\
    \ NESO</h3>\n<p>To build the code and the tests, do</p>\n<pre><code>cmake . -B\
    \ build\ncmake --build build\n</code></pre>\n<p>It may be necessary to tell CMake\
    \ the location of dependencies:</p>\n<ul>\n<li>Boost by setting <code>-DBoost_INCLUDE_DIR</code>\n\
    </li>\n<li>SYCL compiler by setting <code>-DCMAKE_CXX_COMPILER</code>\n</li>\n\
    <li>Nektar++ by setting the location of <code>Nektar++Config.cmake</code> using\
    \ <code>-DNektar++_DIR</code>\n</li>\n</ul>\n<p>For example:</p>\n<pre><code>cmake\
    \ -DCMAKE_CXX_COMPILER=dpcpp -DBoost_INCLUDE_DIR=/root/code/boost_1_78_0 -DNektar++_DIR=/root/code/nektar/build/dist/lib64/nektar++/cmake\
    \ . -B build\ncmake --build build\n</code></pre>\n<p>The executable <code>NESO</code>\
    \ is created in <code>bin</code>.</p>\n<h2><a id=\"user-content-system-specific-information\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#system-specific-information\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System-specific\
    \ information</h2>\n<h3><a id=\"user-content-dirac-csd3--cambridge\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#dirac-csd3--cambridge\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dirac (CSD3 @ Cambridge)</h3>\n\
    <pre><code>module unload intel/compilers/2017.4\nmodule unload intel/mkl/2017.4\n\
    module load gcc/11\nmodule load intel/oneapi/2022.1.0/compiler\nmodule load intel/oneapi/2022.1.0/mkl\n\
    module load intel/oneapi/2022.1.0/tbb\nexport  LD_LIBRARY_PATH=/usr/local/software/intel/oneapi/2022.1/compiler/latest/linux/lib:$LD_LIBRARY_PATH\n\
    </code></pre>\n<h2><a id=\"user-content-testing\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#testing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Testing</h2>\n<p>CMake also builds a suite unit tests (<code>&lt;build_dir&gt;/test/unitTests</code>)\n\
    and integration tests (<code>&lt;build_dir&gt;/test/integrationTests</code>).</p>\n\
    <p>A subset of the tests may be run using <code>ctest</code>\ne.g. <code>path/to/testExecutable\
    \ --gtest_filter=TestSuiteName.TestName</code>.\nSee the <a href=\"http://google.github.io/googletest/\"\
    \ rel=\"nofollow\">googletest user guide</a>\nfor more info, especially with regards\
    \ to running <a href=\"https://google.github.io/googletest/advanced.html#selecting-tests\"\
    \ rel=\"nofollow\">specific\ntests</a>.</p>\n<p>Alternatively, you can call\n\
    <a href=\"https://cmake.org/cmake/help/latest/manual/ctest.1.html\" rel=\"nofollow\"\
    >CTest</a> from\nwithin the build directory to execute your tests.</p>\n<h2><a\
    \ id=\"user-content-address-sanitizers\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#address-sanitizers\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Address Sanitizers</h2>\n<p>To debug for memory leaks, compile with\
    \ the options</p>\n<pre><code>cmake . -B -DENABLE_SANITIZER_ADDRESS=on -DENABLE_SANITIZER_LEAK=on\n\
    </code></pre>\n<h2><a id=\"user-content-licence\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#licence\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Licence</h2>\n<p>This is licenced under MIT.</p>\n<p>In order to comply\
    \ with the licences of dependencies, this software is not to be released as a\
    \ binary.</p>\n"
  stargazers_count: 2
  subscribers_count: 5
  topics: []
  updated_at: 1666702150.0
FTHPC/Correlation_Compressibility:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: FTHPC/Correlation_Compressibility
  latest_release: v0.1
  readme: "<h1><a id=\"user-content-compressibility-analysis-correlation_compressibility\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#compressibility-analysis-correlation_compressibility\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compressibility\
    \ Analysis (Correlation_Compressibility)</h1>\n<h2><a id=\"user-content-statement-of-purpose\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#statement-of-purpose\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Statement of Purpose</h2>\n<p>This\
    \ repo contains scripts to perform compressibility analysis on several leading\
    \ lossy compressors.\nThe compressibility analysis relies on deriving statistics\
    \ on scientific data and explore their relationships to their compression ratios\
    \ from various lossy compressors (based on various compression scheme).\nThe extracted\
    \ relationships between compression ratios and statistical predictors are modeled\
    \ via regression models, which provide a statistical framework to predict compression\
    \ ratios for the different studied lossy compressors.</p>\n<p>This repo contains\
    \ an automatic framework of scripts that perform the compression of scientific\
    \ datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding and Bit\
    \ Grooming), the derivation of the statistical predictors of compression ratios\
    \ (SVD, standard deviation, quantized entropy), and scripts to perform the training\
    \ of the regression models (linear and spline regressions) as well as the validation\
    \ of the regression predictions.\nA runtime analysis is also performed and associated\
    \ codes are provided.</p>\n<h3><a id=\"user-content-main-code-structures\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#main-code-structures\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Main code structures</h3>\n<p>Compression\
    \ metrics, including compression ratios, and derivation of statistical predictors\
    \ (SVD, standard deviation, quantized entropy) codes are found in <code>compress_package</code>\
    \ and are run via <code>scripts/run.sh</code> as described in the section \"How\
    \ to compute statistical predictors and compression analysis on datasets\".\n\
    Linear and spline regressions training and validation (functions <code>cr_regression_linreg</code>\
    \ and <code>cr_regression_gam</code> from the script <code>replicate_figures/functions_paper.R</code>).\n\
    Codes for the different runtime analysis are found in the folder <code>runtime_analysis</code>\
    \ and are automated with the script <code>runtime.sh</code>, the study includes\
    \ compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled)\
    \ variogram and local (tiled) variogram, and runtime for training and prediction\
    \ of the regressions.<br>\nFinally, the script <code>replicate_figures/graphs_paper_container.R</code>\
    \ replicates and saves all the figures from the paper ad as well as numbers from\
    \ the tables.</p>\n<p>For each dataset in the <code>dataset</code> folder, slicing\
    \ is performed for each variable field (e.g. density in Miranda), each slice is\
    \ stored in a class. The class is updated as compressions with the 8 compressors\
    \ is performed and updated as the statistical predictors are derived. Results\
    \ of each class are stored in a .csv file (example of csv files can be found at\
    \ <code>replicate_figures/generated_data/</code>).\nAll the datasets stored in\
    \ the <code>dataset</code> folder can be analyzed with the given set of codes,\
    \ one needs to source <code>scripts/config.json</code> with the appropriate dataset\
    \ name as described in the below section \"How to compute statistical predictors\
    \ and compression analysis on datasets\".\nThe regression analysis and its prediction\
    \ is then performed on R dataframes based on the aforementioned .csv files.</p>\n\
    <h2><a id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#system-information\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>System Information</h2>\n<p>The hardware and software\
    \ versions used for the performance evaluations can be found in the table below.\
    \ These nodes come from Clemson University's Palmetto Cluster.</p>\n<p>These nodes\
    \ have:</p>\n<table>\n<thead>\n<tr>\n<th>component</th>\n<th>version</th>\n<th>component</th>\n\
    <th>version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CPU</td>\n<td>Intel Xeon\
    \ 6148G (40 cores)</td>\n<td>sz2</td>\n<td>2.1.12.2</td>\n</tr>\n<tr>\n<td>GPU</td>\n\
    <td>2 Nvidia v100</td>\n<td>sz3</td>\n<td>3.1.3.1</td>\n</tr>\n<tr>\n<td>Memory</td>\n\
    <td>372GB</td>\n<td>zfp</td>\n<td>0.5.5</td>\n</tr>\n<tr>\n<td>Network</td>\n\
    <td>2 Mellanox MT27710 (HDR)</td>\n<td>mgard</td>\n<td>1.0.0</td>\n</tr>\n<tr>\n\
    <td>FileSystem</td>\n<td>BeeGFS 7.2.3 (24 targets)</td>\n<td>bit grooming</td>\n\
    <td>2.1.9</td>\n</tr>\n<tr>\n<td>Compiler</td>\n<td>GCC 8.4.1</td>\n<td>digit\
    \ rounding</td>\n<td>2.1.9</td>\n</tr>\n<tr>\n<td>OS</td>\n<td>CentOS 8.2.2004</td>\n\
    <td>R</td>\n<td>4.1.3</td>\n</tr>\n<tr>\n<td>MPI</td>\n<td>OpenMPI 4.0.5</td>\n\
    <td>Python</td>\n<td>3.9.12</td>\n</tr>\n<tr>\n<td>LibPressio</td>\n<td>0.83.4</td>\n\
    <td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-first-time-setup\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-setup\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>First time setup</h2>\n<h3><a\
    \ id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#container-installation-for-ease-of-setup\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Container Installation\
    \ (for ease of setup)</h3>\n<p>We provide a container for <code>x86_64</code>\
    \ image for ease of installation.</p>\n<p>This container differs from our experimental\
    \ setup slightly. The production build used <code>-march=native -mtune=native</code>\
    \ for architecture optimized builds where as the container does not use these\
    \ flags to maximize compatibility across <code>x86_64</code> hardware.</p>\n<p>NOTE\
    \ this file is &gt;= 11 GB , download with caution.</p>\n<h4><a id=\"user-content-docker\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#docker\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Docker</h4>\n<p>Many other systems\
    \ can use podman or docker.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>docker pull ghcr.io/fthpc/correlation_compressibility:latest\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>most systems</span>\ndocker run -it --rm ghcr.io/fthpc/correlation_compressibility:latest\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> if running on a SeLinux enforcing\
    \ system</span>\ndocker run -it --rm --security-opt label=disable ghcr.io/fthpc/correlation_compressibility:latest</pre></div>\n\
    <h3><a id=\"user-content-building-the-container\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#building-the-container\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Building the Container</h3>\n<p>You can build the\
    \ container yourself as follows:\nNOTE this process takes 3+ hours on a modern\
    \ laptop, and most clusters do not\nprovide sufficient permissions to run container\
    \ builds on the cluster.</p>\n<p>Additionally compiling MGRAD -- one of the compressors\
    \ we use takes &gt;= 4GB RAM per core, be cautious\nwith systems with low RAM.\
    \  You may be able compensate by using fewer cores by changing the spack install\n\
    instruction in the Dockerfile to have a <code>-j N</code> where <code>N</code>\
    \ is the number of cores you wish to use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> install/module load git-lfs,\
    \ needed to download example_data for building the container</span>\nsudo dnf\
    \ install git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span>Fedora/CentOS\
    \ Stream 8</span>\nsudo apt-get install git-lfs <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Ubuntu</span>\nspack install git-lfs<span class=\"pl-k\">;</span>\
    \ spack load git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> using\
    \ spack</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> clone this\
    \ repository</span>\ngit clone --recursive https://github.com/FTHPC/Correlation_Compressibility\n\
    <span class=\"pl-c1\">cd</span> Correlation_Compressibility\ndocker build <span\
    \ class=\"pl-c1\">.</span> -t correlation_compressibility</pre></div>\n<h3><a\
    \ id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#manual-installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Manual Installation</h3>\n<p>By default, it is recommended to follow\
    \ the install locations that are indicated on the top of <code>scripts/run.sh</code>\n\
    and the top of <code>config.json</code>. These two files provide the configuration\
    \ options to get the program running.</p>\n<p>Spack should be installed in the\
    \ following location: <code>$HOME/spack/</code></p>\n<p>This Github repo should\
    \ be cloned in the following location: <code>$HOME/Correlation_Compressibility/</code>\n\
    This location is also referenced as the <code>COMPRESS_HOME</code> environment\
    \ variable.</p>\n<p>A dataset folder called 'datasets' should be in the following\
    \ location: <code>$HOME/Correlation_Compressibility/datasets/</code>.</p>\n<p>Clone\
    \ the repo but make sure to install or load <code>git-lfs</code> first.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> install/module load git-lfs, needed to download example_data\
    \ for building the container</span>\nsudo dnf install git-lfs <span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span>Fedora/CentOS Stream 8</span>\nsudo apt-get install\
    \ git-lfs <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ubuntu</span>\nspack\
    \ install git-lfs<span class=\"pl-k\">;</span> spack load git-lfs <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> using spack</span>\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> clone this repository</span>\ngit clone https://github.com/FTHPC/Correlation_Compressibility\
    \ <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility</pre></div>\n\
    <p>If you forgot to install <code>git-lfs</code> before and have an empty file\
    \ in the  <code>datasets</code> folder, you should install <code>git-lfs</code>\n\
    and then run the following:</p>\n<pre><code>git lfs fetch\ngit lfs checkout\n\
    </code></pre>\n<p>Once Spack is installed, there is a <code>spack.yaml</code>\
    \ configuration file containing the Spack environment necessary to run the program.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span>\
    \ <span class=\"pl-smi\">$HOME</span>\ngit clone --depth=1 https://github.com/spack/spack\n\
    git clone --depth=1 https://github.com/robertu94/spack_packages \n<span class=\"\
    pl-c1\">source</span> ./spack/share/spack/setup-env.sh \nspack compiler find\n\
    spack external find \nspack repo add --scope=site ./spack_packages \n<span class=\"\
    pl-c1\">cd</span> <span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ \nspack env activate <span class=\"pl-c1\">.</span>\nspack install\n<span class=\"\
    pl-k\">export</span> COMPRESS_HOME=<span class=\"pl-smi\">$HOME</span>/Correlation_Compressibility\
    \ </pre></div>\n<p>These commands will install the environment. The environment\
    \ only needs to be installed once.\nIf you are using an older &lt; gcc11, then\
    \ you will need to add the following to the <code>spack.yaml</code> file:</p>\n\
    <pre><code>^libstdcompat+boost\n</code></pre>\n<p>after <code>^mgard@robertu94+cuda</code>\
    \ but before the <code>,</code>.</p>\n<h2><a id=\"user-content-replication-of-results\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-results\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication of\
    \ Results</h2>\n<h3><a id=\"user-content-how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-compute-statistical-predictors-and-compression-metrics-on-datasets\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to compute\
    \ statistical predictors and compression metrics on datasets</h3>\n<p>In order\
    \ to run the statistical analysis that computes the statistical predictors (SVD,\
    \ standard deviation, quantized entropy) of compression ratios, a dataset and\
    \ a configuration file must be specified.\nTEST is a dataset that is specified\
    \ within the <code>config.json</code> file.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh scripts/run.sh -c config.json -d TEST -n 2</pre></div>\n<p>The command\
    \ above performs the computation of statistical predictors and writes output to\
    \ the output file specified in the configuration file.\nThis will use local hardware\
    \ without a scheduler. Use <code>-n</code> to specify the MPI processes on your\
    \ local system. Default value is 32.\nIt is recommended that this value matches\
    \ your CPU core count.</p>\n<p>If one has the PBS scheduler and runs outside of\
    \ the container, feel free to use flags <code>-p</code> or <code>-s</code> for\
    \ job execution.\n<code>-p</code> will schedule multiple jobs based on the quantized\
    \ error bounds and error bound types for a specified dataset.\n<code>-s</code>\
    \ will schedule a single job grouping all the analysis for a specified dataset.</p>\n\
    <p>See <code>-h</code> for more options or help with syntax.</p>\n<p>If a dataset\
    \ is wanted to run, the <code>config.json</code> file provides options to add\
    \ datasets.\nThe following options must be added when adding another dataset in\
    \ the configuration file:</p>\n<div class=\"highlight highlight-source-json\"\
    ><pre><span class=\"pl-ent\">\"_comment\"</span> : \n{\n    <span class=\"pl-ent\"\
    >\"folder\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>folder containing h5 or binary files<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"data_dimensions\"</span>   : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>dimensions of the datasets within dataset_folder.\
    \ Either 1x2 or 1x3. EX: '1028, 1028'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"slice_dimensions\"</span>  : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>list of the dimensions wanted: EX: 'None' or\
    \ 'X, Y, Z'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\"\
    >\"output\"</span>            : <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>name of the output csv file: EX: 'test.csv'<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-ent\">\"dtype\"</span>             : <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>data type. can be 'float32' or 'float64'<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-ent\">\"parse_info\"\
    </span>        : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type of\
    \ parsing needed: 'None', 'slice', 'gaussian', 'gaussian_multi', 'spatialweight',\
    \ or 'scalarweight'<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"\
    pl-ent\">\"dataset_name\"</span>      : <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>necessary accessing 2D HDF5 files: 'standard' if not custom. custom\
    \ EX: 'Z'<span class=\"pl-pds\">\"</span></span>\n} </pre></div>\n<p>From this\
    \ section, .csv files are generated for each dataset and contain all the statistical\
    \ predictors described in the paper as well as compression metrcis including compresison\
    \ ratios for the 8 lossy compressors and 4 error bounds.</p>\n<h3><a id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To run the\
    \ training and prediction timing analysis demonstration</h3>\n<p>In order to run\
    \ the timing analysis, a dataset must be specified.\nThere are two datasets setup\
    \ within this demonstration.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>sh runtime_analysis/runtime.sh -d [DATASET]</pre></div>\n<p>[DATASET] can\
    \ be either [NYX] or [SCALE]</p>\n<p>After running the above script, an *.RData\
    \ file(s) will be produced giving the approprirate timing information of\nthe\
    \ training and prediction for the regression models.</p>\n<p>Note: A quicker and\
    \ more efficient quantized entropy method is demonstrated in <code>qentropy.cc</code></p>\n\
    <h4><a id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-following-below-runs-qentropycc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The following below runs <code>qentropy.cc</code>\n\
    </h4>\n<div class=\"highlight highlight-source-shell\"><pre>g++ -std=c++2a -O3\
    \ qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy</pre></div>\n\
    <p>Note: Please run the runtime analysis for both datasets before running the\
    \ following section.</p>\n<h3><a id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Replication\
    \ of figures: how to run statistical prediction of compression ratios and the\
    \ prediction validation</h3>\n<p>The script <code>graphs_paper_container.R</code>\
    \  saves the graphs presented in the paper and provides associated validation\
    \ metrics (correlation and median absolute error percentage).</p>\n<p>The script\
    \ <code>graphs_paper_container.R</code> will source the scripts  <code>load_dataset_paper.R</code>\
    \ and <code>functions_paper.R</code> that respectively load the dataset of interest\
    \ and perform the regression analysis (training and prediction in cross-validation).\n\
    As a consequence the scripts  <code>load_dataset_paper.R</code> and <code>functions_paper.R</code>\
    \ do not need to be run by the user.</p>\n<p>The script <code>graphs_paper_container.R</code>\
    \  is run via the command:\n<code>bash sh replicate.sh</code></p>\n<p>From running\
    \ the script once, it will save all Figures 1, 3, 4 and 5 into .png files from\
    \ the paper as well as corresponding validation metrics.\nFigure 2 is not saved\
    \ as it provides a simple vizualization of slices of the datasets.\nSlices of\
    \ the datasets are generated in the Section \"How to compute statistical predictors\
    \ and compression metrics\" and can be stored, however we do not save them here\
    \ to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in\
    \ the R console.\nAll printed validation metrics are save into a file named <code>figure_replication.log</code>.\n\
    Figures and the log-file are saved in the same folder as the one where R script\
    \ is run and the filename structure is <code>figY_*.png</code> with Y is the figure\
    \ number reference in the paper and <code>*</code> provides additional informnation\
    \ about the data and the compressor.<br>\nNumbers for Table 4 are saved in the\
    \ last section in .txt files <code>statistic_benchmark_runtime_X.txt</code> with\
    \ X the studied dataset (NYX or SCALE).</p>\n<p>In order to limit the container\
    \ size to aid reproducibility, we only added a restricted number of scientific\
    \ datasets in the container and we rely on csv files from our production runs\
    \ (saved as described above in the Section \"How to compute statistical predictors\
    \ on datasets\").\nMore datasets are available on <a href=\"https://sdrbench.github.io\"\
    \ rel=\"nofollow\">SDRBench</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1648227729.0
FZJ-INM1-BDA/siibra-python:
  data_format: 2
  description: Software interfaces for interacting with brain atlases - Python client
  filenames:
  - .ebrains/spack/siibra-spack.yaml
  full_name: FZJ-INM1-BDA/siibra-python
  latest_release: v0.3a27
  stargazers_count: 28
  subscribers_count: 7
  topics:
  - brain
  - atlas
  - neuroscience
  - bigbrain
  - bigbrainproject
  - humanbrainproject
  updated_at: 1667991472.0
FluidNumerics/SELF:
  data_format: 2
  description: Spectral Element Library in Fortran
  filenames:
  - env/moog/spack.yaml
  - env/oram/spack.yaml
  full_name: FluidNumerics/SELF
  latest_release: null
  readme: '<h1><a id="user-content-spectral-element-libraries-in-fortran-self" class="anchor"
    aria-hidden="true" href="#spectral-element-libraries-in-fortran-self"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Spectral Element Libraries in Fortran
    (SELF)</h1>

    <p>Copyright 2020-2022 Fluid Numerics LLC</p>

    <p><a href="https://self.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2cdea5d87038eae2bd52034d42848bdf0381c26e2ffe70a7a973e360004a19f6/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73656c662f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/self/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/FluidNumerics/SELF" rel="nofollow"><img src="https://camo.githubusercontent.com/190632c16f2de9b4028909a9987ec0987590d74593c0133a6346d70373fb45ca/68747470733a2f2f636f6465636f762e696f2f67682f466c7569644e756d65726963732f53454c462f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d414b4b534c3543574b36"
    alt="codecov" data-canonical-src="https://codecov.io/gh/FluidNumerics/SELF/branch/main/graph/badge.svg?token=AKKSL5CWK6"
    style="max-width: 100%;"></a>

    <a href="https://www.youtube.com/channel/UCW5e-TavOnw1AABGH-VMbRg?sub_confirmation=1"
    rel="nofollow"><img src="https://camo.githubusercontent.com/241f818a7c9fbbe538a27ae90073f54004dc794a7d2cab7ef50cb01c76e62cef/68747470733a2f2f696d672e736869656c64732e696f2f796f75747562652f6368616e6e656c2f73756273637269626572732f55435735652d5461764f6e773141414247482d564d6252673f7374796c653d736f6369616c"
    alt="Youtube" data-canonical-src="https://img.shields.io/youtube/channel/subscribers/UCW5e-TavOnw1AABGH-VMbRg?style=social"
    style="max-width: 100%;"></a>

    <a href="https://www.reddit.com/r/FluidNumerics/" rel="nofollow"><img src="https://camo.githubusercontent.com/86acef9558f5e18573c4b9b4275d2eb6f59608130be921982dd5b0377650324a/68747470733a2f2f696d672e736869656c64732e696f2f7265646469742f7375627265646469742d73756273637269626572732f666c7569646e756d65726963733f7374796c653d736f6369616c"
    alt="Reddit" data-canonical-src="https://img.shields.io/reddit/subreddit-subscribers/fluidnumerics?style=social"
    style="max-width: 100%;"></a></p>

    <p>Join the <a href="https://join.slack.com/t/higherordermethods/shared_invite/zt-1da6fpyjo-c4yNNXD_o0F3Yrxe8isgJg"
    rel="nofollow">Higher Order Methods Slack group</a></p>

    <p>SELF is licensed for use under the <a href="./LICENSE">Researcher Software
    License</a>. For other licensure, reach out to <a href="mailto:support@fluidnumerics.com">support@fluidnumerics.com</a>.</p>

    <h2><a id="user-content-about" class="anchor" aria-hidden="true" href="#about"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>About</h2>

    <p>SELF is an object-oriented Fortran library that support the implementation
    of Spectral Element Methods for solving partial differential equations.</p>

    <p>The SELF API is designed based on the assumption that SEM developers and researchers
    need to be able to implement derivatives in 1-D and divergence, gradient, and
    curl in 2-D and 3-D on scalar, vector, and tensor functions using spectral collocation,
    continuous galerkin, and discontinuous galerkin spectral element methods. Additionally,
    as we enter the exascale era, we are currently faced with a zoo of compute hardware
    that is available. Because of this, SELF routines provide support for GPU acceleration
    through AMD''s HIP and support for multi-core, multi-node, and multi-GPU platforms
    with MPI.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" href="#support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <h3><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h3>

    <p><a href="https://fluidnumerics.github.io/SELF" rel="nofollow"><strong>User
    &amp; Developer Documentation</strong></a>

    <a href="https://fluidnumerics.github.io/SELF/ford/" rel="nofollow"><strong>API
    Documentation</strong></a></p>

    <h3><a id="user-content-community" class="anchor" aria-hidden="true" href="#community"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Community</h3>

    <h3><a id="user-content-maintainers" class="anchor" aria-hidden="true" href="#maintainers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Maintainers</h3>

    <ul>

    <li><a href="https://fluidnumerics.com/people" rel="nofollow">Joseph Schoonover,
    Fluid Numerics LLC</a></li>

    </ul>

    <p>If you''d like to contribute, see <a href="./CONTRIBUTING.md">CONTRIBUTING.md</a>
    to get started.

    If you need help, <a href="https://github.com/FluidNumerics/SELF/issues/new">open
    an issue</a></p>

    '
  stargazers_count: 26
  subscribers_count: 5
  topics:
  - spectral-element-method
  - gpu-acceleration
  - gpu-computing
  - hpc
  - pde-solver
  updated_at: 1664329202.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1658856345.0
LLNL/UnifyFS:
  data_format: 2
  description: 'UnifyFS: A file system for burst buffers'
  filenames:
  - .spack-env/unifyfs-slurm-gcc10_2_1/spack.yaml
  - .spack-env/unifyfs-lsf-gcc4_9_3/spack.yaml
  - .spack-env/unifyfs-slurm-gcc4_9_3/spack.yaml
  - .spack-env/unifyfs-lsf-gcc8_3_1/spack.yaml
  full_name: LLNL/UnifyFS
  latest_release: v1.0
  readme: '<h1><a id="user-content-unifyfs-a-distributed-burst-buffer-file-system"
    class="anchor" aria-hidden="true" href="#unifyfs-a-distributed-burst-buffer-file-system"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>UnifyFS: A Distributed
    Burst Buffer File System</h1>

    <p>Node-local burst buffers are becoming an indispensable hardware resource on

    large-scale supercomputers to buffer the bursty I/O from scientific

    applications. However, there is a lack of software support for burst buffers to

    be efficiently shared by applications within a batch-submitted job and recycled

    across different batch jobs. In addition, burst buffers need to cope with a

    variety of challenging I/O patterns from data-intensive scientific

    applications.</p>

    <p>UnifyFS is a user-level burst buffer file system under active development.

    UnifyFS supports scalable and efficient aggregation of I/O bandwidth from burst

    buffers while having the same life cycle as a batch-submitted job. While UnifyFS

    is designed for N-N write/read, UnifyFS compliments its functionality with the

    support for N-1 write/read. It efficiently accelerates scientific I/O based on

    scalable metadata indexing, co-located I/O delegation, and server-side read

    clustering and pipelining.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>UnifyFS documentation is at <a href="https://unifyfs.readthedocs.io" rel="nofollow">https://unifyfs.readthedocs.io</a>.</p>

    <p>For instructions on how to build and install UnifyFS,

    see <a href="http://unifyfs.readthedocs.io/en/dev/build.html" rel="nofollow">Build
    UnifyFS</a>.</p>

    <h2><a id="user-content-build-status" class="anchor" aria-hidden="true" href="#build-status"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Status</h2>

    <p>Status of UnifyFS development branch (dev):</p>

    <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev"><img
    src="https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev"
    alt="Build Status" style="max-width: 100%;"></a></p>

    <p><a href="https://unifyfs.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/e83e6f0dfc2d353a5c6d482643646205f8fcc8e0b3327cb32dc9b27292e16823/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756e69667966732f62616467652f3f76657273696f6e3d646576"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/unifyfs/badge/?version=dev"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-contribute-and-develop" class="anchor" aria-hidden="true"
    href="#contribute-and-develop"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contribute
    and Develop</h2>

    <p>If you would like to help, please see our <a href="https://unifyfs.readthedocs.io/en/dev/contribute-ways.html"
    rel="nofollow">contributing guidelines</a>.</p>

    '
  stargazers_count: 83
  subscribers_count: 18
  topics:
  - system-software
  - burst-buffers
  - file-system
  updated_at: 1668025333.0
LLNL/hiop:
  data_format: 2
  description: HPC solver for nonlinear optimization problems
  filenames:
  - scripts/platforms/newell/spack.yaml
  - scripts/platforms/summit/spack.yaml
  - scripts/platforms/marianas/spack.yaml
  full_name: LLNL/hiop
  latest_release: v0.7.1
  readme: "<h1><a id=\"user-content-hiop---hpc-solver-for-optimization\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#hiop---hpc-solver-for-optimization\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>HiOp - HPC solver\
    \ for optimization</h1>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"\
    https://github.com/LLNL/hiop/workflows/tests/badge.svg\"><img src=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\"\
    \ alt=\"tests\" style=\"max-width: 100%;\"></a></p>\n<p>HiOp is an optimization\
    \ solver for solving certain mathematical optimization problems expressed as nonlinear\
    \ programming problems. HiOp is a lightweight HPC solver that leverages application's\
    \ existing data parallelism to parallelize the optimization iterations by using\
    \ specialized parallel linear algebra kernels.</p>\n<p>Please cite the user manual\
    \ whenever HiOp is used:</p>\n<pre><code>@TECHREPORT{hiop_techrep,\n  title={{HiOp}\
    \ -- {U}ser {G}uide},\n  author={Petra, Cosmin G. and Chiang, NaiYuan and Jingyi\
    \ Wang},\n  year={2018},\n  institution = {Center for Applied Scientific Computing,\
    \ Lawrence Livermore National Laboratory},\n  number = {LLNL-SM-743591}\n}\n</code></pre>\n\
    <p>In addition, when using the quasi-Newton solver please cite:</p>\n<pre><code>@ARTICLE{Petra_18_hiopdecomp,\n\
    title = {A memory-distributed quasi-Newton solver for nonlinear programming problems\
    \ with a small number of general constraints},\njournal = {Journal of Parallel\
    \ and Distributed Computing},\nvolume = {133},\npages = {337-348},\nyear = {2019},\n\
    issn = {0743-7315},\ndoi = {https://doi.org/10.1016/j.jpdc.2018.10.009},\nurl\
    \ = {https://www.sciencedirect.com/science/article/pii/S0743731518307731},\nauthor\
    \ = {Cosmin G. Petra},\n}\n</code></pre>\n<p>and when using the the PriDec solver\
    \ please cite:</p>\n<pre><code>@article{wang2022,\n  archivePrefix = {arXiv},\n\
    \  eprint = {arXiv:2204.09631},\n  author = {J. Wang and C. G. Petra},\n  title\
    \ = {An optimization algorithm for nonsmooth nonconvex problems with upper-$C^2$\
    \ objective},\n  publisher = {arXiv},\n  year = {2022},\n  journal={ (submitted)\
    \ },\n}\n@INPROCEEDINGS{wang2021,\n  author={Wang, Jingyi and Chiang, Nai-Yuan\
    \ and Petra, Cosmin G.},\n  booktitle={2021 20th International Symposium on Parallel\
    \ and Distributed Computing (ISPDC)}, \n  title={An asynchronous distributed-memory\
    \ optimization solver for two-stage stochastic programming problems}, \n  year={2021},\n\
    \  volume={},\n  number={},\n  pages={33-40},\n  doi={10.1109/ISPDC52870.2021.9521613}\n\
    }\n</code></pre>\n<h2><a id=\"user-content-buildinstall-instructions\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#buildinstall-instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Build/install instructions</h2>\n\
    <p>HiOp uses a CMake-based build system. A standard build can be done by invoking\
    \ in the 'build' directory the following</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake ..\n$<span class=\"pl-k\">&gt;</span>\
    \ make \n$<span class=\"pl-k\">&gt;</span> make <span class=\"pl-c1\">test</span>\n\
    $<span class=\"pl-k\">&gt;</span> make install</pre></div>\n<p>This sequence will\
    \ build HiOp, run integrity and correctness tests, and install the headers and\
    \ the library in the directory '_dist-default-build' in HiOp's root directory.</p>\n\
    <p>Command <code>make test</code> runs extensive tests of the various modules\
    \ of HiOp to check integrity and correctness. The tests suite range from unit\
    \ testing to solving concrete optimization problems and checking the performance\
    \ of HiOp solvers on these problems against known solutions. By default <code>make\
    \ test</code> runs <code>mpirun</code> locally, which may not work on some HPC\
    \ machines. For these HiOp allows using <code>bsub</code> to schedule <code>make\
    \ test</code> on the compute nodes; to enable this, the use should use <em>-DHIOP_TEST_WITH_BSUB=ON</em>\
    \ with cmake when building and run <code>make test</code> in a bsub shell session,\
    \ for example,</p>\n<pre><code>bsub -P your_proj_name -nnodes 1 -W 30\nmake test\n\
    CTRL+D\n</code></pre>\n<p>The installation can be customized using the standard\
    \ CMake options. For example, one can provide an alternative installation directory\
    \ for HiOp by using</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span\
    \ class=\"pl-k\">&gt;</span> cmake -DCMAKE_INSTALL_PREFIX=/usr/lib/hiop ..<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span></span></pre></div>\n<h3><a id=\"\
    user-content-selected-hiop-specific-build-options\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#selected-hiop-specific-build-options\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Selected HiOp-specific build options</h3>\n\
    <ul>\n<li>Enable/disable MPI: <em>-DHIOP_USE_MPI=[ON/OFF]</em> (by default ON)</li>\n\
    <li>GPU support: <em>-DHIOP_USE_GPU=ON</em>. MPI can be either off or on. For\
    \ more build system options related to GPUs, see \"Dependencies\" section below.</li>\n\
    <li>Enable/disable \"developer mode\" build that enforces more restrictive compiler\
    \ rules and guidelines: <em>-DHIOP_DEVELOPER_MODE=ON</em>. This option is by default\
    \ off.</li>\n<li>Additional checks and self-diagnostics inside HiOp meant to detect\
    \ abnormalities and help to detect bugs and/or troubleshoot problematic instances:\
    \ <em>-DHIOP_DEEPCHECKS=[ON/OFF]</em> (by default ON). Disabling HIOP_DEEPCHECKS\
    \ usually provides 30-40% execution speedup in HiOp. For full strength, it is\
    \ recommended to use HIOP_DEEPCHECKS with debug builds. With non-debug builds,\
    \ in particular the ones that disable the assert macro, HIOP_DEEPCHECKS does not\
    \ perform all checks and, thus, may overlook potential issues.</li>\n</ul>\n<p>For\
    \ example:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span class=\"\
    pl-k\">&gt;</span> cmake -DHIOP_USE_MPI=ON -DHIOP_DEEPCHECKS=ON ..\n$<span class=\"\
    pl-k\">&gt;</span> make \n$<span class=\"pl-k\">&gt;</span> make <span class=\"\
    pl-c1\">test</span>\n$<span class=\"pl-k\">&gt;</span> make install</pre></div>\n\
    <h3><a id=\"user-content-other-useful-options-to-use-with-cmake\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#other-useful-options-to-use-with-cmake\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other useful\
    \ options to use with CMake</h3>\n<ul>\n<li>\n<em>-DCMAKE_BUILD_TYPE=Release</em>\
    \ will build the code with the optimization flags on</li>\n<li>\n<em>-DCMAKE_CXX_FLAGS=\"\
    -O3\"</em> will enable a high level of compiler code optimization</li>\n</ul>\n\
    <h3><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Dependencies</h3>\n<p>A complete list of dependencies is maintained\
    \ <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/hiop/package.py\"\
    >here</a>.</p>\n<p>For a minimal build, HiOp requires LAPACK and BLAS. These dependencies\
    \ are automatically detected by the build system. MPI is optional and by default\
    \ enabled. To disable use cmake option '-DHIOP_USE_MPI=OFF'.</p>\n<p>HiOp has\
    \ support for NVIDIA <strong>GPU-based computations</strong> via CUDA and Magma.\
    \ To enable the use of GPUs, use cmake with '-DHIOP_USE_GPU=ON'. The build system\
    \ will automatically search for CUDA Toolkit. For non-standard CUDA Toolkit installations,\
    \ use '-DHIOP_CUDA_LIB_DIR=/path' and '-DHIOP_CUDA_INCLUDE_DIR=/path'. For \"\
    very\" non-standard CUDA Toolkit installations, one can specify the directory\
    \ of cuBlas libraries as well with '-DHIOP_CUBLAS_LIB_DIR=/path'.</p>\n<h3><a\
    \ id=\"user-content-using-raja-and-umpire-portability-libraries\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#using-raja-and-umpire-portability-libraries\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using RAJA and\
    \ Umpire portability libraries</h3>\n<p>Portability libraries allow running HiOp's\
    \ linear algebra either on host (CPU) or a device (GPU). RAJA and Umpire are disabled\
    \ by default. You can turn them on together by passing <code>-DHIOP_USE_RAJA=ON</code>\
    \ to CMake. If the two libraries are not automatically found, specify their installation\
    \ directories like this:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$<span class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_RAJA=ON -DRAJA_DIR=/path/to/raja/dir\
    \ -Dumpire_DIR=/path/to/umpire/dir</pre></div>\n<p>If the GPU support is enabled,\
    \ RAJA will run all HiOp linear algebra kernels on GPU, otherwise RAJA will run\
    \ the kernels on CPU using an OpenMP execution policy.</p>\n<h3><a id=\"user-content-support-for-gpu-computations\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#support-for-gpu-computations\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Support\
    \ for GPU computations</h3>\n<p>When GPU support is on, HiOp requires Magma linear\
    \ solver library and CUDA Toolkit. Both are detected automatically in most cases.\
    \ The typical cmake command to enable GPU support in HiOp is</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span> cmake\
    \ -DHIOP_USE_GPU=ON ..</pre></div>\n<p>When Magma is not detected, one can specify\
    \ its location by passing <code>-DHIOP_MAGMA_DIR=/path/to/magma/dir</code> to\
    \ cmake.</p>\n<p>For custom CUDA Toolkit installations, the locations to the (missing/not\
    \ found) CUDA libraries can be specified to cmake via <code>-DNAME=/path/cuda/directory/lib</code>,\
    \ where <code>NAME</code> can be any of</p>\n<pre><code>CUDA_cublas_LIBRARY\n\
    CUDA_CUDART_LIBRARY\nCUDA_cudadevrt_LIBRARY\nCUDA_cusparse_LIBRARY\nCUDA_cublasLt_LIBRARY\n\
    CUDA_nvblas_LIBRARY\nCUDA_culibos_LIBRARY\n</code></pre>\n<p>Below is an example\
    \ for specifiying <code>cuBlas</code>, <code>cuBlasLt</code>, and <code>nvblas</code>\
    \ libraries, which were <code>NOT_FOUND</code> because of a non-standard CUDA\
    \ Toolkit instalation:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$<span\
    \ class=\"pl-k\">&gt;</span> cmake -DHIOP_USE_GPU=ON -DCUDA_cublas_LIBRARY=/usr/local/cuda-10.2/targets/x86_64-linux/lib/lib64\
    \ -DCUDA_cublasLt_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ -DCUDA_nvblas_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>A detailed example on how to compile HiOp straight\
    \ of the box on <code>summit.olcf.ornl.gov</code> is available <a href=\"README_summit.md\"\
    >here</a>.</p>\n<p>RAJA and UMPIRE dependencies are usually detected by HiOp's\
    \ cmake build system.</p>\n<h3><a id=\"user-content-kron-reduction\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#kron-reduction\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Kron reduction</h3>\n<p>Kron reduction\
    \ functionality of HiOp is disabled by default. One can enable it by using</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$<span class=\"pl-k\">&gt;</span>\
    \ rm -rf <span class=\"pl-k\">*</span><span class=\"pl-k\">;</span> cmake -DHIOP_WITH_KRON_REDUCTION=ON\
    \ -DUMFPACK_DIR=/Users/petra1/work/installs/SuiteSparse-5.7.1 -DMETIS_DIR=/Users/petra1/work/installs/metis-4.0.3\
    \ .. <span class=\"pl-k\">&amp;&amp;</span> make -j <span class=\"pl-k\">&amp;&amp;</span>\
    \ make install</pre></div>\n<p>Metis is usually detected automatically and needs\
    \ not be specified under normal circumstances.</p>\n<p>UMFPACK (part of SuiteSparse)\
    \ and METIS need to be provided as shown above.</p>\n<h1><a id=\"user-content-interfacing-with-hiop\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#interfacing-with-hiop\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Interfacing with\
    \ HiOp</h1>\n<p>HiOp supports three types of optimization problems, each with\
    \ a separate input formats in the form of the C++ interfaces <code>hiopInterfaceDenseConstraints</code>,<code>hiopInterfaceSparse</code>\
    \ and <code>hiopInterfaceMDS</code>. These interfaces are specified in <a href=\"\
    src/Interface/hiopInterface.hpp\">hiopInterface.hpp</a> and documented and discussed\
    \ as well in the <a href=\"doc/hiop_usermanual.pdf\">user manual</a>.</p>\n<p><em><code>hiopInterfaceDenseConstraints</code>\
    \ interface</em> supports NLPs with <strong>billions</strong> of variables with\
    \ and without bounds but only limited number (&lt;100) of general, equality and\
    \ inequality constraints. The underlying algorithm is a limited-memory quasi-Newton\
    \ interior-point method and generally scales well computationally (but it may\
    \ not algorithmically) on thousands of cores. This interface uses MPI for parallelization</p>\n\
    <p><em><code>hiopInterfaceSparse</code> interface</em> supports general sparse\
    \ and large-scale NLPs. This functionality is similar to that of the state-of-the-art\
    \ <a href=\"https://github.com/coin-or/Ipopt\">Ipopt</a> (without being as robust\
    \ and flexible as Ipopt is). Acceleration for this class of problems can be achieved\
    \ via OpenMP or CUDA, however, this is work in progress and you are encouraged\
    \ to contact HiOp's developers for up-to-date information.</p>\n<p><em><code>hiopInterfaceMDS</code>\
    \ interface</em> supports mixed dense-sparse NLPs and achives parallelization\
    \ using GPUs and RAJA portability abstraction layer.</p>\n<p>More information\
    \ on the HiOp interfaces are <a href=\"src/Interface/README.md\">here</a>.</p>\n\
    <h2><a id=\"user-content-running-hiop-tests-and-applications\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#running-hiop-tests-and-applications\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running HiOp tests and applications</h2>\n\
    <p>HiOp is using NVBlas library when built with CUDA support. If you don't specify\n\
    location of the <code>nvblas.conf</code> configuration file, you may get an annoying\n\
    warnings. HiOp provides default <code>nvblas.conf</code> file and installs it\
    \ at the same\nlocation as HiOp libraries. To use it, set environment variable\
    \ as</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ <span class=\"\
    pl-k\">export</span> NVBLAS_CONFIG_FILE=<span class=\"pl-k\">&lt;</span>hiop install\
    \ dir<span class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n<p>or, if you\
    \ are using C-shell, as</p>\n<div class=\"highlight highlight-source-shell\"><pre>$\
    \ setenv NVBLAS_CONFIG_FILE <span class=\"pl-k\">&lt;</span>hiop install dir<span\
    \ class=\"pl-k\">&gt;</span>/lib/nvblas.conf</pre></div>\n<h2><a id=\"user-content-existing-issues\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#existing-issues\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Existing issues</h2>\n<p>Users\
    \ are highly encouraged to report any issues they found from using HiOp.\nOne\
    \ known issue is that there is some minor inconsistence between HiOp and linear\
    \ package STRUMPACK.\nWhen STRUMPACK is compiled with MPI (and Scalapack), user\
    \ must set flag <code>HIOP_USE_MPI</code> to <code>ON</code> when compiling HiOp.\n\
    Otherwise HiOp won't load MPI module and will return an error when links to STRUMPACK,\
    \ since the later one requires a valid MPI module.\nSimilarly, if both Magma and\
    \ STRUMPACK are linked to HiOp, user must guarantee the all the packages are compiled\
    \ by the same CUDA compiler.\nUser can check other issues and their existing status\
    \ from <a href=\"https://github.com/LLNL/hiop\">https://github.com/LLNL/hiop</a></p>\n\
    <h2><a id=\"user-content-acknowledgments\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#acknowledgments\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Acknowledgments</h2>\n<p>HiOp has been developed under the financial\
    \ support of:</p>\n<ul>\n<li>Department of Energy, Office of Advanced Scientific\
    \ Computing Research (ASCR): Exascale Computing Program (ECP) and Applied Math\
    \ Program.</li>\n<li>Department of Energy, Advanced Research Projects Agency-Energy\
    \ (ARPA\u2011E)</li>\n<li>Lawrence Livermore National Laboratory Institutional\
    \ Scientific Capability Portfolio (ISCP)</li>\n<li>Lawrence Livermore National\
    \ Laboratory, through the LDRD program</li>\n</ul>\n<h1><a id=\"user-content-contributors\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributors\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributors</h1>\n<p>HiOp is\
    \ written by Cosmin G. Petra (<a href=\"mailto:petra1@llnl.gov\">petra1@llnl.gov</a>),\
    \ Nai-Yuan Chiang (<a href=\"mailto:chiang7@llnl.gov\">chiang7@llnl.gov</a>),\
    \ and Jingyi \"Frank\" Wang (<a href=\"mailto:wang125@llnl.gov\">wang125@llnl.gov</a>)\
    \ from LLNL and has received important contributions from Asher Mancinelli (PNNL),\
    \ Slaven Peles (ORNL), Cameron Rutherford (PNNL), Jake K. Ryan (PNNL), and Michel\
    \ Schanen (ANL).</p>\n<h1><a id=\"user-content-copyright\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#copyright\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Copyright</h1>\n<p>Copyright (c) 2017-2021, Lawrence Livermore National\
    \ Security, LLC. All rights reserved. Produced at the Lawrence Livermore National\
    \ Laboratory. LLNL-CODE-742473. HiOp is free software; you can modify it and/or\
    \ redistribute it under the terms of the BSD 3-clause license. See <a href=\"\
    /COPYRIGHT\">COPYRIGHT</a> and <a href=\"/LICENSE\">LICENSE</a> for complete copyright\
    \ and license information.</p>\n"
  stargazers_count: 160
  subscribers_count: 14
  topics:
  - hpc
  - nonlinear-optimization
  - nonlinear-programming
  - nonlinear-optimization-algorithms
  - nonlinear-programming-algorithms
  - interior-point-method
  - parallel-programming
  - mpi
  - bfgs
  - quasi-newton
  - constrained-optimization
  - solver
  - optimization
  - acopf
  - gpu-support
  - cuda
  - math-physics
  - radiuss
  updated_at: 1665572709.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/e4s-quarterly/int64-extended/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int32-extended/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.4.1
  readme: '<h1><a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" aria-hidden="true" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SUNDIALS: SUite of
    Nonlinear and DIfferential/ALgebraic equation Solvers</h1>

    <h3><a id="user-content-version-641-oct-2022" class="anchor" aria-hidden="true"
    href="#version-641-oct-2022"><span aria-hidden="true" class="octicon octicon-link"></span></a>Version
    6.4.1 (Oct 2022)</h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form</p>

    <p>$$ M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0 $$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form</p>

    <p>$$ y'' = f(t,y), \quad y(t_0) = y_0 $$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form</p>

    <p>$$ y'' = f(t,y,p), \quad y(t_0) = y_0(p) $$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form</p>

    <p>$$ F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0'' $$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form</p>

    <p>$$ F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p) $$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form</p>

    <p>$$ F(u) = 0 \quad \text{or} \quad G(u) = u $$</p>

    </li>

    </ul>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" href="#support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2><a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Slaven Peles, Cosmin Petra, H. Hunter Schwartz, Jean M. Sexton,

    Dan Shumaker, Steve G. Smith, Allan G. Taylor, Hilari C. Tiedeman, Chris White,

    Ting Yan, and Ulrike M. Yang.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 310
  subscribers_count: 34
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1668169567.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 22.08/0.18.1/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-for-lumi" class="anchor"
    aria-hidden="true" href="#spack-configuration-files-for-lumi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Spack configuration files for LUMI</h1>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 12
  topics: []
  updated_at: 1661775740.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Thu Oct 13 17:19:43 MDT 2022</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>dcda3b5e879fab84fa4111dfbfa3ea321dc15de1</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>22.10</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td>c885b591e295faccaf118b9a63c44cd7e90c8298</td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/22.10</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/22.10/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 3
  subscribers_count: 11
  topics: []
  updated_at: 1667681992.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/decomposed/spack-gcc.yaml
  - spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/decomposed/spack-gcc-cuda.yaml
  - spack-configs/perlmutter-user-spack/spack.yaml
  - docs/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/ci/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/decomposed/spack-cce.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/perlmutter-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file. The documentation is available at\
    \ <a href=\"https://nersc-spack-infrastructure.rtfd.io/\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io/</a></p>\n\
    <h2><a id=\"user-content-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-configuration\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Configuration</h2>\n<p>The spack configuration\
    \ can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<table>\n<thead>\n<tr>\n<th>system</th>\n\
    <th>status</th>\n<th>PIPELINE_NAME</th>\n<th>description</th>\n<th>spack.yaml</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>Perlmutter</td>\n<td><strong>IN-PROGRESS</strong></td>\n\
    <td><code>PERLMUTTER_SPACK_DEVELOP</code></td>\n<td>This spack configuration is\
    \ based on <code>spack@develop</code> branch to see what packages can be built.\
    \ We expect this pipeline will fail and we are not expected to fix build failures.\
    \ The main purpose of this project is to build as many packages across all the\
    \ compilers, mpi, and blas providers of interest to see what works. Since we don't\
    \ know which package works during deployment, we will leverage data from this\
    \ pipeline to make informed decision what packages should be picked with given\
    \ compilers. This pipeline is our development and we should use this to experiment\
    \ new compilers. Note that we won't hardcode versions for packages since we want\
    \ to build with latest release. However we will hardcode external packages depending\
    \ on how the system is configured.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-spack-develop/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_22.05</code></td>\n\
    <td>This spack configuration will build E4S 22.05 on Perlmutter on scheduled pipeline</td>\n\
    <td><a href=\"https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/spack.yaml/\"\
    \ rel=\"nofollow\">https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/spack.yaml/</a></td>\n\
    </tr>\n<tr>\n<td>Muller</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>MULLER_E4S_22.05</code></td>\n\
    <td>This spack configuration will build E4S 22.05 on Muller on scheduled pipeline</td>\n\
    <td><a href=\"https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/spack.yaml/\"\
    \ rel=\"nofollow\">https://software.nersc.gov/-/ide/project/NERSC/spack-infrastructure/tree/main/-/spack-configs/perlmutter-e4s-22.05/ci/spack.yaml/</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>CORI_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on Cori using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Gerty</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>GERTY_E4S_22.02</code></td>\n\
    <td>This spack configuration will build E4S/22.02 on gerty using a scheduled pipeline.</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11_DEPLOY</code></td>\n\
    <td>This spack configuration is deployment configuration for E4S/21.11. For more\
    \ details on this stack see  <a href=\"https://docs.nersc.gov/applications/e4s/perlmutter/21.11/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/perlmutter/21.11/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Perlmutter</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>PERLMUTTER_E4S_21.11</code></td>\n\
    <td>This spack configuration is used for development for building E4S/21.11 using\
    \ scheduled pipeline.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Muller</td>\n<td><strong>COMPLETE</strong></td>\n<td><code>MULLER_E4S_21.11</code></td>\n\
    <td>This spack configuration was used to build E4S/21.11 on Muller using scheduled\
    \ pipeline. Once e4s/21.11 was built on Muller we followed up with building the\
    \ same spack configuration on Perlmutter.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/perlmutter-e4s-21.11/ci/muller/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.05\
    \ spack stack based on <a href=\"https://github.com/spack/spack/tree/e4s-21.05\"\
    >e4s-21.05</a> branch of spack. This stack can be accessed via <code>module load\
    \ e4s/21.05</code>.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.05/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration used for deployment purposes, this can be accessed via <code>module\
    \ load e4s/21.02</code> on Cori. For more details see <a href=\"https://docs.nersc.gov/applications/e4s/cori/21.02/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/21.02/</a>\n</td>\n\
    <td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs/cori-e4s-21.02/prod/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/21.02\
    \ spack configuration that push to buildcache.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-21.02/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration that push to build cache using <code>spack ci</code>.  This\
    \ project lives in <a href=\"https://software.nersc.gov/NERSC/e4s-2010\" rel=\"\
    nofollow\">https://software.nersc.gov/NERSC/e4s-2010</a> and configuration was\
    \ copied over here.</td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/spack.yaml</a></td>\n\
    </tr>\n<tr>\n<td>Cori</td>\n<td><strong>COMPLETE</strong></td>\n<td></td>\n<td>E4S/20.10\
    \ spack configuration for Cori used for deployment purpose. This stack can be\
    \ accessed via <code>module load e4s/20.10</code>. This is documented at <a href=\"\
    https://docs.nersc.gov/applications/e4s/cori/20.10/\" rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/cori/20.10/</a>\n\
    </td>\n<td><a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml\"\
    \ rel=\"nofollow\">https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/spack-configs/cori-e4s-20.10/prod/spack.yaml</a></td>\n\
    </tr>\n</tbody>\n</table>\n<h2><a id=\"user-content-running-ci-pipelines\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#running-ci-pipelines\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>. Please make sure you\
    \ login to the appropriate hostname when starting the gitlab runner.</p>\n<table>\n\
    <thead>\n<tr>\n<th>System</th>\n<th>Runner Name</th>\n<th>Hostname</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n\
    <td><code>login27</code></td>\n</tr>\n<tr>\n<td>cori</td>\n<td><code>cori-e4s</code></td>\n\
    <td><code>cori02</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    <td><code>login02</code></td>\n</tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n\
    <td><code>gert01</code></td>\n</tr>\n</tbody>\n</table>\n<p>The runner configuration\
    \ files are located in <code>~/.gitlab-runner</code> for user <strong>e4s</strong>.</p>\n\
    <p>The production pipelines are triggered via web-interface which requires approval\
    \ from a project maintainer. Production pipelines should be run when we need to\
    \ do full redeployment of stack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#current-challenges\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have external packages set for packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li><strong>Erik Palmer (<a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>)</strong></li>\n\
    <li><strong>Justin Cook (<a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 6
  subscribers_count: 13
  topics: []
  updated_at: 1667934572.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 40
  subscribers_count: 18
  topics: []
  updated_at: 1667496232.0
NOAA-EMC/GSI-Monitor:
  data_format: 2
  description: GSI Monitoring Tools
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-Monitor
  latest_release: null
  readme: "<h1><a id=\"user-content-gsi-monitor\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#gsi-monitor\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>GSI-Monitor</h1>\n<p>GSI Monitoring Tools</p>\n<p>These tools monitor\
    \ the Gridpoint Statsical Interpolation (GSI) package's data assimiliation, detecting\n\
    and reporting missing data sources, low obervational counts, and high penalty\
    \ values.</p>\n<p>Suite includes:</p>\n<pre><code>  ConMon   Conventional Monitor\
    \     \n  MinMon   GSI Minimization Monitor \n  OznMon   Ozone Monitor       \
    \     \n  RadMon   Radiance Monitor         \n</code></pre>\n<p>PoC:  <a href=\"\
    mailto:edward.safford@noaa.gov\">edward.safford@noaa.gov</a></p>\n"
  stargazers_count: 1
  subscribers_count: 0
  topics: []
  updated_at: 1662740187.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<h1><a id="user-content-gsi-utils" class="anchor" aria-hidden="true" href="#gsi-utils"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GSI-Utils</h1>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics: []
  updated_at: 1660063597.0
NOAA-EMC/WW3:
  data_format: 2
  description: WAVEWATCH III
  filenames:
  - model/ci/spack.yaml
  full_name: NOAA-EMC/WW3
  latest_release: 6.07.1
  readme: "<h1><a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2><a id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#general-features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 184
  subscribers_count: 49
  topics: []
  updated_at: 1666323818.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/jedi-ufs-all/spack.yaml
  - configs/templates/hpc-stack-dev/spack.yaml
  - configs/templates/ufs-srw-public-v2/spack.yaml
  - configs/templates/ufs-srw-dev/spack.yaml
  - configs/templates/gfs-v16.2/spack.yaml
  - configs/templates/hpc-dev-v1/spack.yaml
  - configs/templates/skylab-dev/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: 1.1.0
  readme: '<h1><a id="user-content-spack-stack" class="anchor" aria-hidden="true"
    href="#spack-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>Spack-stack enables the installation of software required

    for HPC system deployments of NOAA''s Unified Forecast System (UFS) and

    other weather and climate models, including components of the Joint

    Effort for Data assimilation Integration (JEDI).</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>.</li>

    </ul>

    <p>Spack-stack is a thin layer around a fork of the

    <a href="https://github.com/spack/spack">spack</a> repository. Spack is a

    community-supported, multi-platform, Python-based package manager

    originally developed by the Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about spack see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for

    spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack

    documentation</a>.</p>

    <p>The stack can be installed on a range of platforms, from Linux and

    macOS laptops to HPC systems, and comes pre-configured for many

    systems. Users can install the necessary packages for a particular

    application and later add the missing packages for another application

    without having to rebuild the entire stack.</p>

    <p>spack-stack is mainly a collection of Spack configuration files, but

    provides a Spack extension to simplify the installation process:</p>

    <ul>

    <li>

    <p><code>spack stack create</code> is provided to copy common, site-specific,
    and

    application-specific configuration files into a coherent Spack

    environment and to create container recipes</p>

    </li>

    <li>

    <p><code>spack stack setup-meta-modules</code> creates compiler, MPI and Python

    meta-modules for a convenient setup of a user environment using

    modules (lua and tcl)</p>

    </li>

    </ul>

    <p>Documentation for installing and using spack-stack can be found here:

    <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a></p>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>

    <p><a href="https://www.github.com/AlexanderRichert-NOAA">Alex Richert</a>, <a
    href="https://www.github.com/Hang-Lei-NOAA">Hang

    Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed

    Hartnett</a> NOAA-EMC</p>

    </li>

    <li>

    <p><a href="https://www.github.com/climbfuji">Dom Heinzeller</a>, JCSDA</p>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 8
  subscribers_count: 6
  topics: []
  updated_at: 1667415187.0
PDC-support/PDC-SoftwareStack:
  data_format: 2
  description: null
  filenames:
  - spack-settings/22.06/0.18.1/prod/spack.yaml
  full_name: PDC-support/PDC-SoftwareStack
  latest_release: null
  readme: '<h1><a id="user-content-pdc-software-stack" class="anchor" aria-hidden="true"
    href="#pdc-software-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>PDC
    Software Stack</h1>

    <p>Repository to store documentation, installation procedure, installation procedures
    and data for validation of installed software</p>

    <h2><a id="user-content-modules" class="anchor" aria-hidden="true" href="#modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Modules</h2>

    <p>Modules for easybuild and CrayPE are within the module folder.</p>

    <h2><a id="user-content-easybuild" class="anchor" aria-hidden="true" href="#easybuild"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EasyBuild</h2>

    <p>EasyBuild easyconfigs should be stored in <em>easybuild/easyconfigs</em> folder</p>

    <h2><a id="user-content-spack" class="anchor" aria-hidden="true" href="#spack"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack</h2>

    <p>Spack installation procedures for software should be store in the <em>spack</em>
    folder</p>

    <h2><a id="user-content-manual-installations" class="anchor" aria-hidden="true"
    href="#manual-installations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    installations</h2>

    <p>Procedures should be store in the <em>other</em> folder</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1666354279.0
ParaToolsInc/exago-crusher:
  data_format: 2
  description: Spack-based deployment of ROCm enabled ExaGO for OLCF Crusher
  filenames:
  - spack.yaml
  full_name: ParaToolsInc/exago-crusher
  latest_release: null
  readme: "<h1><a id=\"user-content-exago-on-olcf-crusher\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#exago-on-olcf-crusher\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>ExaGO on OLCF Crusher</h1>\n<p>ROCm-enabled ExaGO\
    \ on OLCF Crusher using Spack</p>\n<h2><a id=\"user-content-install-from-build-cache-example\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#install-from-build-cache-example\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Install\
    \ from Build Cache (Example)</h2>\n<ul>\n<li>View a demo video of these instructions\
    \ run at <a href=\"https://asciinema.org/a/508123\" rel=\"nofollow\">https://asciinema.org/a/508123</a>\n\
    </li>\n</ul>\n<pre><code>$crusher:~&gt; git clone https://github.com/ParaToolsInc/exago-crusher.git\n\
    $crusher:~&gt; cd exago-crusher\n\n$crusher:~/exago-crusher&gt; git clone https://github.com/spack/spack\n\
    $crusher:~/exago-crusher&gt; (cd spack &amp;&amp; git checkout dac31ef3c)\n\n\
    $crusher:~/exago-crusher&gt; export SPACK_DISABLE_LOCAL_CONFIG=1\n$crusher:~/exago-crusher&gt;\
    \ export SPACK_USER_CACHE_PATH=$(pwd)/_cache\n$crusher:~/exago-crusher&gt; . spack/share/spack/setup-env.sh\n\
    \n$crusher:~/exago-crusher&gt; spack mirror add paratools /gpfs/alpine/csc439/world-shared/E4S/ParaTools/exago\n\
    $crusher:~/exago-crusher&gt; spack buildcache keys -it\ngpg: key 4345F04B40005581:\
    \ public key \"University of Oregon - E4S\" imported\ngpg: Total number processed:\
    \ 1\ngpg:               imported: 1\ngpg: inserting ownertrust of 6\n\n$crusher:~/exago-crusher&gt;\
    \ time spack -e . concretize -f | tee concretize.log\n... output truncated for\
    \ brevity; see concretize.log in this repo for full output\nreal\t0m46.340s\n\
    user\t1m25.263s\nsys\t0m2.094s\n\n$crusher:~/exago-crusher&gt; time spack -e .\
    \ install --cache-only\n... output truncated for brevity\nreal\t7m40.626s\nuser\t\
    4m44.081s\nsys\t0m33.864s\n\n$crusher:~/exago-crusher&gt; spack find -lv exago\
    \ hiop ipopt coinhsl\n==&gt; 8 installed packages\n-- cray-sles15-zen3 / gcc@11.2.0\
    \ --------------------------------\nue74alo coinhsl@2015.06.23+blas\nmnelc7u exago@develop~cuda+hiop~ipo~ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nanahf5s exago@develop~cuda+hiop~ipo~ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\n2qog6zw exago@develop~cuda+hiop~ipo+ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\ndr3jlyb exago@develop~cuda+hiop~ipo+ipopt+mpi+python+raja+rocm\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nwtqj2hu hiop@0.6.2~cuda~cusolver~deepchecking~ginkgo~ipo~jsrun~kron+mpi+raja+rocm~shared+sparse\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nrlw4qhu hiop@0.6.2~cuda~cusolver~deepchecking~ginkgo~ipo~jsrun+kron+mpi+raja+rocm~shared+sparse\
    \ amdgpu_target=gfx90a build_type=RelWithDebInfo\nufjh4v7 ipopt@3.14.5+coinhsl~debug+metis~mumps\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657663349.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Configuration files for Spack at Pawsey
  filenames:
  - setonix/environments/env_wrf/spack.yaml
  - setonix/environments/env_astro/spack.yaml
  - setonix/environments/env_utils/spack.yaml
  - setonix/environments/env_apps/spack.yaml
  - setonix/environments/env_vis/spack.yaml
  - setonix/environments/env_num_libs/spack.yaml
  - setonix/environments/env_langs/spack.yaml
  - setonix/environments/env_io_libs/spack.yaml
  - setonix/environments/env_roms/spack.yaml
  - setonix/environments/env_bio/spack.yaml
  - setonix/environments/env_devel/spack.yaml
  - setonix/environments/env_python/spack.yaml
  - setonix/environments/env_s3_clients/spack.yaml
  - setonix/environments/env_bench/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-pawsey-spack-config" class="anchor" aria-hidden="true"
    href="#pawsey-spack-config"><span aria-hidden="true" class="octicon octicon-link"></span></a>pawsey-spack-config</h1>

    <p>Configuration files for Spack at Pawsey.</p>

    <h2><a id="user-content-setonix-setup" class="anchor" aria-hidden="true" href="#setonix-setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setonix setup</h2>

    <p>This can be found in the <code>setonix/</code> directory.<br>

    See <code>README.md</code> in there for further information.</p>

    <h2><a id="user-content-other-setups" class="anchor" aria-hidden="true" href="#other-setups"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Other setups</h2>

    <ul>

    <li>

    <code>joey/</code>: test deployment for the Setonix test system</li>

    <li>Current Pawsey systems

    <ul>

    <li><code>askapingest/</code></li>

    <li><code>garrawarla/</code></li>

    <li><code>magnus/</code></li>

    <li><code>topaz/</code></li>

    <li><code>zeus/</code></li>

    </ul>

    </li>

    <li>

    <code>examples/</code>: deployment examples and tests</li>

    <li>

    <code>deprecated/</code>: legacy deployments</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1641801068.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.15.4/spack.yaml
  - v0.18.1/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#rhel7-spack-config\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#useful-commands\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack\
    \ module lmod refresh\n</code></pre>\n<h2><a id=\"user-content-installing-new-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-new-packages\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new\
    \ packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack\
    \ package updates could result in additional installation of packages with little\
    \ or no package source code changes.  These additional installs can be avoided\
    \ when installing new packages by first examining the output of the <code>spack\
    \ spec -I</code> command.  If a utility/infrastructure level package, such as\
    \ cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column\
    \ then it means that the existing install will be used.  If spack does not default\
    \ to using the existing install you can append the hash of the package to the\
    \ spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi\
    \ install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\n\
    Input spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\n\
    Concretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo\
    \ ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]     \
    \ ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64\
    \ \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64\
    \ \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]  \
    \        ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]  \
    \            ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643231013.0
SouthernMethodistUniversity/mp_testing:
  data_format: 2
  description: null
  filenames:
  - mp/testing/08_pytorch/spack.yaml
  - mp/testing/05_openmm/spack.yaml
  - mp/testing/01_spack/spack_nvhpc.yaml
  - mp/testing/01_spack/spack_lammps.yaml
  full_name: SouthernMethodistUniversity/mp_testing
  latest_release: null
  readme: '<h1><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h1>

    <p><strong>All code in this repo is for testing. The code may not work and may
    change. Pull requests and issues welcome.</strong></p>

    <p>See <a href="quick_start_notes.md">Quick Start Notes</a> for a short overview
    of MP usage.</p>

    <h2><a id="user-content-usage-example" class="anchor" aria-hidden="true" href="#usage-example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage Example</h2>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/SouthernMethodistUniversity/mp_testing.git

    <span class="pl-c1">cd</span> mp_testing/demos/00_nemo

    ./submit_jobs.sh</pre></div>

    <h2><a id="user-content-applications" class="anchor" aria-hidden="true" href="#applications"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Applications</h2>

    <ul>

    <li>LAMMPS (NGC)</li>

    <li>AMBER</li>

    <li>NAMD (NGC)</li>

    <li>OpenMM</li>

    <li>Gaussian</li>

    <li>VASP</li>

    <li>CRYSTAL</li>

    <li>Q-Chem</li>

    <li>Quantum Espresso</li>

    </ul>

    <h2><a id="user-content-analysis-tools" class="anchor" aria-hidden="true" href="#analysis-tools"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Analysis Tools</h2>

    <ul>

    <li>Memory profiling</li>

    <li>Performance profiling</li>

    </ul>

    <h2><a id="user-content-librariesapis" class="anchor" aria-hidden="true" href="#librariesapis"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Libraries/APIs</h2>

    <ul>

    <li>Raja</li>

    <li>Magma</li>

    <li>heFFTe</li>

    <li>Pandas</li>

    <li>NumPy</li>

    <li>TensorFlow</li>

    <li>PyTorch</li>

    <li>DALI</li>

    </ul>

    <h2><a id="user-content-languages" class="anchor" aria-hidden="true" href="#languages"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Languages</h2>

    <ul>

    <li>C</li>

    <li>C++</li>

    <li>Python</li>

    <li>Some custom layer in C++/CUDA</li>

    <li>Fortran</li>

    <li>CUDA Fortran</li>

    <li>Julia</li>

    </ul>

    <h2><a id="user-content-molecular-dynamics" class="anchor" aria-hidden="true"
    href="#molecular-dynamics"><span aria-hidden="true" class="octicon octicon-link"></span></a>Molecular
    Dynamics</h2>

    <ul>

    <li>OpenMM</li>

    <li>AMBER</li>

    <li>Desmond</li>

    <li>GROMACS</li>

    <li>Mentioned MIC modes?</li>

    <li>NGC for Keras/TF and Pytorch</li>

    </ul>

    <h2><a id="user-content-issues" class="anchor" aria-hidden="true" href="#issues"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Issues</h2>

    <ul>

    <li>Can''t run enroot images directly via <code>enroot start hello_world.sqsh</code>.
    The OS

    needs squashfuse and fuse-overlayfs installed. I installed these on Easley and

    it works.</li>

    <li>Custom build and final images for containerized Spack environments fails due

    to apparently assuming that Spack already exists. See: <code>01_spack/spack_nvhpc.yaml</code>.</li>

    <li>Spack-blessed NVIDIA container fails to build due to public key error. See:
    <code>01_spack/spack_lammps.yaml</code>.</li>

    <li>

    <code>export ENROOT_MOUNT_HOME=1</code> to bind $HOME.</li>

    <li>Default flags and <code>target=zen2</code> gave LAMMPS run times of 4:44,
    while <code>target=zen2 cppflags=-O3</code>

    </li>

    <li>Running containers or non-hpc-x MPI produces warnings about <code>Unknown
    interface name</code> /

    <code>An invalid value was given for btl_tcp_if_include</code>. It appears not
    to see the Mellanox / IB correctly?</li>

    </ul>

    <h2><a id="user-content-maybe-useful" class="anchor" aria-hidden="true" href="#maybe-useful"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Maybe Useful</h2>

    <ul>

    <li><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/gpu-applications-catalog.pdf"
    rel="nofollow">https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/gpu-applications-catalog.pdf</a></li>

    <li><a href="https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html"
    rel="nofollow">https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html</a></li>

    <li><a href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html"
    rel="nofollow">https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html</a></li>

    <li><a href="https://secure.cci.rpi.edu/wiki/" rel="nofollow">https://secure.cci.rpi.edu/wiki/</a></li>

    </ul>

    <h2><a id="user-content-things-we-need-to-plan-for" class="anchor" aria-hidden="true"
    href="#things-we-need-to-plan-for"><span aria-hidden="true" class="octicon octicon-link"></span></a>Things
    we need to plan for</h2>

    <ul>

    <li>How and when do we decide we''re updating Nvidia Drivers / Cuda. I think we
    need to be very clear about this if we''re not going to maintain the latest and
    greatest. (we''re currently on 11.4, but 11.7 and associated drivers are available)</li>

    </ul>

    '
  stargazers_count: 2
  subscribers_count: 2
  topics: []
  updated_at: 1662600875.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/minimal/ubuntu20.04-aarch64/spack.yaml
  - docker-recipes/runner/ubuntu22.04-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu22.04-aarch64/spack.yaml
  - docker-recipes/minimal/ubuntu22.04-x86_64/spack.yaml
  - docker-recipes/minimal/ubuntu22.04-aarch64/spack.yaml
  - docker-recipes/minimal/rhel8-aarch64/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64/spack.yaml
  - docker-recipes/minimal/rhel8-x86_64/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu18.04-x86_64/spack.yaml
  - docker-recipes/runner/rhel8-aarch64/spack.yaml
  - docker-recipes/runner/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/minimal/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/minimal/rhel8-ppc64le/spack.yaml
  - docker-recipes/runner/rhel8-x86_64/spack.yaml
  - docker-recipes/runner/ubuntu20.04-ppc64le/spack.yaml
  - docker-recipes/runner/ubuntu20.04-x86_64-oneapi/spack.yaml
  - docker-recipes/runner/ubuntu20.04-aarch64/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 19
  subscribers_count: 6
  topics: []
  updated_at: 1667910765.0
adamqc/devcontainer:
  data_format: 2
  description: null
  filenames:
  - real/spack.yaml
  - complex/spack.yaml
  full_name: adamqc/devcontainer
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1646725990.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent8/envs/avx/lusoft/spack.yaml
  - cent8/envs/solhawk/spack.yaml
  - cent8/envs/avx512/lusoft/spack.yaml
  - cent8/envs/avx2/lusoft/spack.yaml
  - cent8/envs/x86_64/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1><a id="user-content-spack-environments" class="anchor" aria-hidden="true"
    href="#spack-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPACK
    Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2><a id="user-content-software-deployment-for-centos-8x" class="anchor" aria-hidden="true"
    href="#software-deployment-for-centos-8x"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Software deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3><a id="user-content-compilers" class="anchor" aria-hidden="true" href="#compilers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3><a id="user-content-lu-software" class="anchor" aria-hidden="true" href="#lu-software"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LU Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4><a id="user-content-available-environments" class="anchor" aria-hidden="true"
    href="#available-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    Environments</h4>

    <h5><a id="user-content-solhawk" class="anchor" aria-hidden="true" href="#solhawk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-avxavx2avx512" class="anchor" aria-hidden="true" href="#avxavx2avx512"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-python-and-r-packages" class="anchor" aria-hidden="true"
    href="#python-and-r-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>Python
    and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-x86_64" class="anchor" aria-hidden="true" href="#x86_64"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2><a id="user-content-centos-7x-software" class="anchor" aria-hidden="true"
    href="#centos-7x-software"><span aria-hidden="true" class="octicon octicon-link"></span></a>CentOS
    7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657632897.0
ashermancinelli/vimconfig:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: ashermancinelli/vimconfig
  latest_release: null
  readme: "<h1><a id=\"user-content-vimconfig\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#vimconfig\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>vimconfig</h1>\n<p>Lots and lots of different configurations for various\
    \ programs all wrapped up into one repo. Under heavy development so tread with\
    \ some caution :)</p>\n<h2><a id=\"user-content-how-to-use\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#how-to-use\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>How to use</h2>\n<p>The top directory has a\
    \ script to deal with installation - you should pretty much only interact with\
    \ the repo through that script.\nThe help message is quite descriptive:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ ./configure --h\n\n  Usage:\n\
    \n  -p <span class=\"pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>  \
    \         Sets install prefix. Default: /people/manc568/.local\n  -r <span class=\"\
    pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>           Path to RC file\
    \ <span class=\"pl-k\">for</span> given shell. Default: /qfs/people/manc568/.bashrc\n\
    \  -d                  Default installation. Installs ctags, vim, and bash\n \
    \ -s <span class=\"pl-k\">&lt;</span>pkg<span class=\"pl-k\">&gt;</span>     \
    \       Show installation script <span class=\"pl-k\">for</span> pacakge\n  -i\
    \                  One or more of the following list, separated by commas with\
    \ no spaces:\n\n       zsh\n       bash\n       ctags\n       vim\n       tmux\n\
    \       emacs\n       profiles\n       modules\n       rice\n       rice.sh\n\
    \       fresh</pre></div>\n<h2><a id=\"user-content-examples\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#examples\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<p>For example, to just install\
    \ my vim configuration, you'd do:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ ./configure -i vim</pre></div>\n<p>Or to install configs for multiple\
    \ programs:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ ./configure\
    \ -i vim,ctags,tmux,emacs,bash</pre></div>\n"
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1641783693.0
bfovet/config:
  data_format: 2
  description: My personal configuration files
  filenames:
  - spack-env/linux-ubuntu22.04-skylake/spack.yaml
  full_name: bfovet/config
  latest_release: null
  readme: '<h1><a id="user-content-config" class="anchor" aria-hidden="true" href="#config"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>config</h1>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1658465316.0
bsurc/spack-configs:
  data_format: 2
  description: spack configuration settings used at BSU research computing
  filenames:
  - BOISESTATE/borah/environments/base/_spack.yaml
  - BOISESTATE/borah/environments/compilers/_spack.yaml
  - NREL/configs/rhodes/utilities/spack.yaml
  - BOISESTATE/falcon/environments/applications/namd/_spack.yaml
  - BOISESTATE/falcon/environments/compilers/_spack.yaml
  - BOISESTATE/borah/applications/gromacs/_spack.yaml
  - BOISESTATE/borah/environments/b4s/_spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/prod/spack.yaml
  - NREL/configs/eagle/compilers/spack.yaml
  - NERSC/cori/e4s-20.10/prod/spack.yaml
  - NREL/configs/eagle/software/spack.yaml
  - NREL/configs/rhodes/base/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - NREL/configs/eagle/utilities/spack.yaml
  - BOISESTATE/falcon/environments/libraries/netcdf/_spack.yaml
  - UOREGON/E4S-Develop/spack-ubuntu20.04-ppc64le.yaml
  - UOREGON/E4S-21.05-Facility-Examples/NERSC-Cori/gcc-spack.yaml
  - UOREGON/E4S-Develop/spack-ubuntu20.04-x86_64.yaml
  - NERSC/cori/e4s-stacks/knl/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/prod/spack.yaml
  - BOISESTATE/falcon/environments/applications/vacuumms/_spack.yaml
  - BOISESTATE/falcon/environments/applications/gromacs-cp2k/_spack.yaml
  - NREL/configs/eagle/base/spack.yaml
  - NERSC/cori/e4s-21.02/prod/spack.yaml
  - BOISESTATE/falcon/environments/applications/wrf/_spack.yaml
  - NERSC/cori/e4s-21.05/spack.yaml
  - OLCF/crusher/spack.yaml
  - BOISESTATE/falcon/environments/base/_spack.yaml
  - BOISESTATE/falcon/environments/applications/lammps/_spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/Frank-Jupiter/spack.yaml
  - UOREGON/E4S-Develop/spack-ubuntu18.04-x86_64.yaml
  - NREL/configs/rhodes/compilers/spack.yaml
  full_name: bsurc/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1660257692.0
buildsi/splice-experiment:
  data_format: 2
  description: Preparing for the splice experiment (notes are currently here)
  filenames:
  - manual/ref/e4s/spack.yaml
  full_name: buildsi/splice-experiment
  latest_release: null
  readme: '<h1><a id="user-content-splice-experiment" class="anchor" aria-hidden="true"
    href="#splice-experiment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Splice
    Experiment</h1>

    <p>This is planning for the <a href="https://github.com/buildsi/spliced">spliced</a>
    experiment

    that we plan to run for the BUILDSI project. We will use a container base to the
    largest extent possible.

    To see our original manual setup, you can look in <a href="manual">manual</a>,
    or to read the original

    experiment plan and design, see <a href="plan.md">plan.md</a>. Note that although
    the original plan was to run this on HPC, the file-system had significant issues
    and it was entirely run in GitHub actions. For the interested user,

    examples of running scripts are provided for Singularity, Podman, and Docker,
    in the case you want to do this manually. The actual running of experiments happened
    in <a href="https://github.com/buildsi/splice-experiment-runs">this repository</a>.</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <h3><a id="user-content-1-experiment-derivation" class="anchor" aria-hidden="true"
    href="#1-experiment-derivation"><span aria-hidden="true" class="octicon octicon-link"></span></a>1.
    Experiment Derivation</h3>

    <p><em>data from this step is provided here</em></p>

    <p>To see our first experiment attempt setup, see <a href="attempts.md">attemps.md</a>
    where we tried using tests in spack for a ground truth. Ultimately we decided
    this was not good enough and we would use a set of known libraries with ABI issues
    (manually defined) in <a href="diffs">diffs</a>.</p>

    <h3><a id="user-content-2-running-experiments" class="anchor" aria-hidden="true"
    href="#2-running-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.
    Running Experiments</h3>

    <p>Running experiments is easy, and automated! We use the container build alongside
    this repostiory with a Github workflow in a separate repository and then can programatically
    get results. Simply:</p>

    <ol>

    <li>Ensure this repository is pushed (up to date), as the diffs/splices come from
    here.</li>

    <li>Go to <a href="https://github.com/buildsi/splice-experiment-runs/actions">buildsi/splice-experiment-runs
    Actions</a>

    </li>

    <li>Click on the "Spliced Analysis" workflow, and then "Run Workflow"</li>

    <li>The name in the box should correspond to the main package and dependency folder
    to run.</li>

    </ol>

    <p>When you are done, you can clone the <a href="https://github.com/buildsi/splice-experiment-artifacts">artifacts
    repository</a> to manually update artifacts, or just wait for it to update overnight.
    The full analysis (with the artifacts as a git submodule) is in <a href="https://github.com/buildsi/splice-experiment-results">buildsi/splice-experiment-results</a>.</p>

    <h2><a id="user-content-changelog" class="anchor" aria-hidden="true" href="#changelog"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Changelog:</h2>

    <ul>

    <li>version 0.0.1: original version with some tweaks</li>

    <li>version 0.0.11: updating cle from its master to resolve dependency install
    bugs <a href="https://github.com/vsoch/cle/commit/b631940d5598e457533866cbc7284123c2c08ef1">commit</a>

    </li>

    <li>version 0.0.12: refactor of spliced to include diff functionality</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1639367380.0
buildtesters/buildtest-nersc:
  data_format: 2
  description: null
  filenames:
  - buildspecs/apps/e4s/22.05/spack.yaml
  full_name: buildtesters/buildtest-nersc
  latest_release: null
  readme: '<h1><a id="user-content-buildtest-nersc" class="anchor" aria-hidden="true"
    href="#buildtest-nersc"><span aria-hidden="true" class="octicon octicon-link"></span></a>buildtest-nersc</h1>

    <p>This repository contains tests for Cori and Perlmutter using <a href="https://buildtest.readthedocs.io/en/devel/"
    rel="nofollow">buildtest</a> framework. A mirror of this repository is located
    on GitHub at <a href="https://github.com/buildtesters/buildtest-nersc">https://github.com/buildtesters/buildtest-nersc</a>
    that is public facing.</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <p>To get started, please <a href="https://docs.nersc.gov/connect/" rel="nofollow">connect
    to NERSC system</a> and clone this repo and buildtest:</p>

    <pre><code>git clone https://github.com/buildtesters/buildtest.git

    git clone https://software.nersc.gov/NERSC/buildtest-nersc.git

    </code></pre>

    <p>Note if you don''t have access to Gitlab server you may clone the mirror on
    Github:</p>

    <pre><code>git clone https://github.com/buildtesters/buildtest-nersc.git

    </code></pre>

    <p>You will need python 3.7 or higher to <a href="https://buildtest.readthedocs.io/en/devel/installing_buildtest.html"
    rel="nofollow">install buildtest</a>, on Cori/Perlmutter this can be done by loading
    <strong>python</strong>

    module and create a conda environment as shown below.</p>

    <pre><code>module load python

    conda create -n buildtest

    conda activate buildtest

    </code></pre>

    <p>Now let''s install buildtest, assuming you have cloned buildtest in $HOME directory
    source the setup script. For csh users you need to source <strong>setup.csh</strong></p>

    <pre><code>source ~/buildtest/setup.sh


    # csh users

    source ~/buildtest/setup.csh

    </code></pre>

    <p>Next, navigate to <code>buildtest-nersc</code> directory and set environment
    <code>BUILDTEST_CONFIGFILE</code> to point to <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/config.yml"
    rel="nofollow">config.yml</a> which is the configuration file for NERSC system.</p>

    <pre><code>cd buildtest-nersc

    export BUILDTEST_CONFIGFILE=$(pwd)/config.yml

    </code></pre>

    <p>Make sure the configuration is valid, this can be done by running the following.
    buildtest will validate the configuration file with the JSON schema :</p>

    <pre><code>buildtest config validate

    </code></pre>

    <p>Please make sure you are using tip of <a href="https://github.com/buildtesters/buildtest/tree/devel">devel</a>
    branch of buildtest when writing tests. You should sync your local devel branch
    with upstream

    fork, for more details see <a href="https://buildtest.readthedocs.io/en/devel/contributing/code_contribution_guide.html"
    rel="nofollow">contributing guide</a>.</p>

    <p>First time around you should discover all buildspecs this can be done via <code>buildtest
    buildspec find</code>.  The command below will find

    and validate all buildspecs in the <strong>buildtest-nersc</strong> repo and load
    them in buildspec cache. Note that one needs to specify <code>--root</code> to
    specify location where

    all buildspecs are located, we have not configured <a href="https://buildtest.readthedocs.io/en/devel/configuring_buildtest/overview.html#buildspec-roots"
    rel="nofollow">buildspec_root</a> in the configuration file since we don''t have
    a central location where this repo will reside.</p>

    <pre><code>cd buildtest-nersc

    buildtest buildspec find --root buildspecs --rebuild -q

    </code></pre>

    <p>The buildspecs are loaded in buildspec cache file (JSON) that is used by <code>buildtest
    buildspec find</code> for querying cache. Subsequent runs will

    read from cache.  For more details see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/buildspecs_interface.html"
    rel="nofollow">buildspec interface</a>.</p>

    <h2><a id="user-content-building-tests" class="anchor" aria-hidden="true" href="#building-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building Tests</h2>

    <p><strong>Note: All tests are written in YAML using .yml extension</strong></p>

    <p>To build tests use <code>buildtest build</code> command for example we build
    all tests in <code>system</code> directory as follows</p>

    <pre><code>buildtest build -b system/

    </code></pre>

    <p>You can specify multiple buildspecs either files or directory via <code>-b</code>
    option</p>

    <pre><code>buildtest build -b slurm/partition.yml -b slurmutils/

    </code></pre>

    <p>You can exclude a buildspec via <code>-x</code> option this behaves same way
    as <code>-b</code> option so you can specify

    a directory or filepath which could be absolute path, or relative path. This is
    useful when

    you want to run multiple tests grouped in directory but exclude a few.</p>

    <pre><code>buildtest build -b slurm -x slurm/sinfo.yml

    </code></pre>

    <p>buildtest can run tests via tags which can be useful when grouping tests, to
    see a list of available tags you

    can run: <code>buildtest buildspec find --tags</code></p>

    <p>For instance if you want to run all <code>lustre</code> tests you can run the
    following:</p>

    <pre><code>buildtest build --tags lustre

    </code></pre>

    <p>For more details on buildtest test please see the <a href="https://buildtest.readthedocs.io/en/devel/getting_started.html"
    rel="nofollow">buildtest tutorial</a></p>

    <h2><a id="user-content-tags-breakdown" class="anchor" aria-hidden="true" href="#tags-breakdown"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Tags Breakdown</h2>

    <p>When you write buildspecs, please make sure you attach one or more <code>tags</code>
    to the test that way your test will get picked up during one of the CI checks.
    Shown

    below is a summary of tag description</p>

    <ul>

    <li>

    <strong>daily</strong> - this tag is used for running daily system checks using
    gitlab CI. Tests should run relatively quick</li>

    <li>

    <strong>system</strong> - this tag is used for classifying all system tests that
    may include: system configuration, servers, network, cray tests. This tag should
    be used</li>

    <li>

    <strong>slurm</strong> - this tag is used for slurm test that includes slurm utility
    check, slurm controller, etc... This tag <strong>shouldn''t</strong> be used for
    job submission that is managed by <strong>jobs</strong> tag. The <code>slurm</code>
    tag tests should be short running test that use a Local Executor.</li>

    <li>

    <strong>jobs</strong> - this tag is used for testing slurm policies by submitting
    jobs to scheduler.</li>

    <li>

    <strong>compile</strong> - this tag is used for compilation of application (OpenMP,
    MPI, OpenACC, CUDA, upc, bupc, etc...)</li>

    <li>

    <strong>e4s</strong> - this tag is used for running tests for E4S stack via <code>spack
    test</code> or <a href="https://github.com/E4S-Project/testsuite">E4S Testsuite</a>.</li>

    <li>

    <strong>module</strong> - this tag is used for testing module system</li>

    <li>

    <strong>benchmark</strong> - this tag is used for benchmark tests. This can be
    application benchmarks, mini-benchmarks, kernels, etc...</li>

    </ul>

    <p>You can see breakdown of tags and buildspec summary with the following commands</p>

    <pre><code>buildtest buildspec summary

    buildtest buildspec find --group-by-tags

    </code></pre>

    <h2><a id="user-content-querying-tests" class="anchor" aria-hidden="true" href="#querying-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Querying Tests</h2>

    <p>You can use <code>buildtest report</code> and <code>buildtest inspect</code>
    to query tests. The commands differ slightly and data is

    represented differently. The <code>buildtest report</code> command will show output
    in tabular form and only show some of the metadata,

    if you want to access the entire test record use <code>buildtest inspect</code>
    command which displays the content in JSON format.

    For more details on querying tests see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a></p>

    <h2><a id="user-content-ci-setup" class="anchor" aria-hidden="true" href="#ci-setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CI Setup</h2>

    <p>Tests are run on schedule basis with one schedule corresponding to one gitlab
    job in <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/.gitlab-ci.yml"
    rel="nofollow">.gitlab-ci.yml</a>. The scheduled pipelines are configured in

    <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules</a>.
    Each schedule has a variable <code>TESTNAME</code> defined to control which pipeline

    is run since we have multiple gitlab jobs. In the <code>.gitlab-ci.yml</code>
    we make use of conditional rules using <a href="https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic"
    rel="nofollow">only</a>.</p>

    <p>The scheduled jobs are run at different intervals (1x/day, 1x/week, etc...)
    at different times of day to avoid overloading the system. The gitlab jobs

    will run jobs based on tags, alternately some tests may be defined by running
    all tests in a directory (<code>buildtest build -b apps</code>). If you want to
    add a new

    scheduled job, please define a <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules/new"
    rel="nofollow">new schedule</a> with an appropriate time. The

    <code>target branch</code> should be <code>devel</code> and define a unique variable
    used to distinguish scheduled jobs. Next, create a job in <code>.gitlab-ci.yml</code>
    that references the scheduled job and define variable <code>TESTNAME</code> in
    the scheduled pipeline.</p>

    <h2><a id="user-content-integrations" class="anchor" aria-hidden="true" href="#integrations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Integrations</h2>

    <p>This project has integration with Slack to notify CI builds to <a href="https://hpcbuildtest.slack.com"
    rel="nofollow">buildtest Slack</a> at <strong>#buildtest-nersc</strong> workspace.
    The integrations can be

    found at <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations</a>.</p>

    <p>This project has setup a push mirror to <a href="https://github.com/buildtesters/buildtest-nersc">https://github.com/buildtesters/buildtest-nersc</a>
    which can be seen at <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository"
    rel="nofollow">https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository</a>

    under <strong>Mirroring Repositories</strong>. If the push mirror is not setup,
    please add the mirror.</p>

    <h2><a id="user-content-cdash" class="anchor" aria-hidden="true" href="#cdash"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CDASH</h2>

    <p>buildtest will push test results to <a href="https://www.kitware.com/cdash/project/about.html"
    rel="nofollow">CDASH</a> server

    at <a href="https://my.cdash.org/index.php?project=buildtest-nersc" rel="nofollow">https://my.cdash.org/index.php?project=buildtest-nersc</a>
    using <code>buildtest cdash upload</code> command.</p>

    <h2><a id="user-content-contributing-guide" class="anchor" aria-hidden="true"
    href="#contributing-guide"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing
    Guide</h2>

    <p>To contribute back you will want to make sure your buildspec is validated before
    you contribute back, this could be

    done by running test manually <code>buildtest build</code> or see if buildspec
    is valid via <code>buildtest buildspec find</code>. It

    would be good to run your test and make sure it is working as expected, you can
    view test detail using <code>buildtest inspect name &lt;testname&gt;</code> or
    <code>buildtest inspect query &lt;testname&gt;</code>. For more

    details on querying test please see <a href="https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html</a>.</p>

    <p>If you want to contribute your tests, please see <a href="https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/CONTRIBUTING.md"
    rel="nofollow">CONTRIBUTING.md</a></p>

    <h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>References</h2>

    <ul>

    <li>buildtest documentation: <a href="https://buildtest.readthedocs.io/en/devel/"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/</a>

    </li>

    <li>buildtest schema docs: <a href="https://buildtesters.github.io/buildtest/"
    rel="nofollow">https://buildtesters.github.io/buildtest/</a>

    </li>

    <li>Getting Started: <a href="https://buildtest.readthedocs.io/en/devel/getting_started.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/getting_started.html</a>

    </li>

    <li>Writing Buildspecs: <a href="https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html</a>

    </li>

    <li>Contributing Guide: <a href="https://buildtest.readthedocs.io/en/devel/contributing.html"
    rel="nofollow">https://buildtest.readthedocs.io/en/devel/contributing.html</a>

    </li>

    </ul>

    '
  stargazers_count: 4
  subscribers_count: 4
  topics:
  - buildtest
  updated_at: 1657142158.0
celeritas-project/celeritas:
  data_format: 2
  description: Celeritas is a new Monte Carlo transport code designed for high-performance
    simulation of high-energy physics detectors.
  filenames:
  - scripts/spack.yaml
  full_name: celeritas-project/celeritas
  latest_release: v0.1.3
  readme: "<h1><a id=\"user-content-celeritas\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Celeritas</h1>\n<p>The Celeritas project implements HEP detector physics\
    \ on GPU accelerator\nhardware with the ultimate goal of supporting the massive\
    \ computational\nrequirements of the <a href=\"https://home.cern/science/accelerators/high-luminosity-lhc\"\
    \ rel=\"nofollow\">HL-LHC upgrade</a>.</p>\n<h1><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h1>\n<p>This project\
    \ requires external dependencies such as CUDA to build with full\nfunctionality.\
    \  However, any combination of these requirements can be omitted\nto enable limited\
    \ development on personal machines with fewer available\ncomponents. See <a href=\"\
    doc/infrastructure.rst\">the infrastructure documentation</a> for\ndetails on\
    \ installing.</p>\n<h2><a id=\"user-content-installing-with-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#installing-with-spack\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Installing with Spack</h2>\n<p><a\
    \ href=\"https://github.com/spack/spack\">Spack</a> is an HPC-oriented package\
    \ manager that\nincludes numerous scientific packages, including those used in\
    \ HEP. An included\nSpack \"environment\" (at <code>scripts/dev/env/celeritas-{platform}.yaml</code>)\
    \ defines\nthe required prerequisites for this project.</p>\n<ul>\n<li>Clone Spack\
    \ following its <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">getting started instructions</a>\n</li>\n<li>To install with\
    \ CUDA, run <code>spack external find cuda</code> and\n<code>spack install celeritas\
    \ +cuda cuda_arch=&lt;ARCH&gt;</code>, where <code>&lt;ARCH&gt;</code> is the\n\
    numeric portion of the <a href=\"https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/\"\
    \ rel=\"nofollow\">CUDA architecture flags</a>\n</li>\n</ul>\n<h2><a id=\"user-content-configuring-and-building-celeritas-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-and-building-celeritas-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ and building Celeritas manually</h2>\n<p>The Spack environment at <a href=\"\
    dev/scripts.yaml\">dev/scripts.yaml</a> lists the full\ndependencies used by the\
    \ CI for building, testing, and documenting. Install\nthose dependencies via Spack\
    \ or independently, then configure Celeritas.</p>\n<p>To configure Celeritas,\
    \ assuming the dependencies you want are located in the\n<code>CMAKE_PREFIX_PATH</code>\
    \ search path, and other environment variables such as <code>CXX</code>\nare set,\
    \ you should be able to just run CMake and build:</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">mkdir build</span>\n\
    $ <span class=\"pl-s1\"><span class=\"pl-c1\">cd</span> build <span class=\"pl-k\"\
    >&amp;&amp;</span> cmake ..</span>\n$ <span class=\"pl-s1\">make</span></pre></div>\n\
    <h1><a id=\"user-content-development\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #development\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development</h1>\n\
    <p>See the <a href=\"CONTRIBUTING.rst\">contribution guide</a> for the contribution\
    \ process,\n<a href=\"doc/appendices/development.rst\">the development guidelines</a>\
    \ for further\ndetails on coding in Celeritas, and <a href=\"doc/appendices/administration.rst\"\
    >the administration guidelines</a> for community standards and roles.</p>\n<h1><a\
    \ id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n\
    <p>The full code documentation (including API descriptions) is available by\n\
    setting the <code>CELERITAS_BUILD_DOCS=ON</code> configuration option. A mostly\
    \ complete\nversion of the <a href=\"https://celeritas.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">Celeritas documentation</a> is hosted on <code>readthedocs.io</code>.</p>\n\
    <h1><a id=\"user-content-citing-celeritas\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#citing-celeritas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Citing Celeritas</h1>\n<p>If using Celeritas in your work, we ask\
    \ that you cite the code using its\n<a href=\"https://www.osti.gov/doecode/biblio/94866\"\
    \ rel=\"nofollow\">DOECode</a> registration:</p>\n<blockquote>\n<p>Johnson, Seth\
    \ R., Amanda Lund, Soon Yung Jun, Stefano Tognini, Guilherme Lima, Paul Romano,\
    \ Philippe Canal, Ben Morgan, and Tom Evans. \u201CCeleritas,\u201D July 2022.\
    \ <a href=\"https://doi.org/10.11578/dc.20221011.1\" rel=\"nofollow\">https://doi.org/10.11578/dc.20221011.1</a>.</p>\n\
    </blockquote>\n<p>Additional references for code implementation details, benchmark\
    \ problem\nresults, etc., can be found in our continually evolving <a href=\"\
    doc/_static/celeritas.bib\">citation\nfile</a>.</p>\n"
  stargazers_count: 24
  subscribers_count: 9
  topics:
  - hep
  - cuda
  - computational-physics
  - monte-carlo
  updated_at: 1665752346.0
charmoniumQ/wf-reg-test:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: charmoniumQ/wf-reg-test
  latest_release: null
  readme: "<h1><a id=\"user-content-wf-reg-test\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#wf-reg-test\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>wf-reg-test</h1>\n<p>Software tends to break or \"collapse\" over\
    \ time, even if it is unchanged, due to non-obvious changes in the computational\
    \ environment.\nCollapse in computational experiments undermines long-term credibility\
    \ and hinders day-to-day operations.\nWe propose to create the first public dataset\
    \ of automatically executable scientific experiments.\nThis data could be used\
    \ to identify best practices, make continuous testing feasible, and repair broken\
    \ programs.\nThese techniques increase the replicability of computational experiments.</p>\n\
    <p>Conceptually, we intend to collect the following:</p>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">registry</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >registries</span>:\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\"\
    >experiment</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">registry</span>:\n\
    \        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">version</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">experiment</span>:\n \
    \           <span class=\"pl-k\">for</span> <span class=\"pl-s1\">i</span> <span\
    \ class=\"pl-c1\">in</span> <span class=\"pl-en\">range</span>(<span class=\"\
    pl-s1\">num_repetitions</span>):\n                <span class=\"pl-s1\">execution</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-en\">execute</span>(<span class=\"\
    pl-s1\">version</span>)\n                <span class=\"pl-s1\">data</span>.<span\
    \ class=\"pl-en\">append</span>((\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">date</span>,   <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">output</span>,\n                    <span class=\"pl-s1\">execution</span>.<span\
    \ class=\"pl-s1\">logs</span>,   <span class=\"pl-s1\">execuiton</span>.<span\
    \ class=\"pl-s1\">res_usage</span>,\n                    <span class=\"pl-s1\"\
    >version</span>.<span class=\"pl-s1\">date</span>,     <span class=\"pl-s1\">version</span>.<span\
    \ class=\"pl-s1\">code</span>,\n                    <span class=\"pl-s1\">experiment</span>.<span\
    \ class=\"pl-s1\">name</span>,  <span class=\"pl-s1\">registry</span>.<span class=\"\
    pl-s1\">name</span>,\n                ))</pre></div>\n<h1><a id=\"user-content-todo-list\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#todo-list\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>TODO list</h1>\n<ul>\n<li>\n\
    <p>Registries of computational experiments</p>\n<ul>\n<li>[x] <a href=\"https://nf-co.re/\"\
    \ rel=\"nofollow\">nf-core</a>: Nextflow</li>\n<li>[x] <a href=\"https://snakemake.github.io/snakemake-workflow-catalog/\"\
    \ rel=\"nofollow\">Snakemake Catalog</a>: Snakemake</li>\n<li>[ ] SAW ECMF: SAW\
    \ NGW</li>\n<li>[ ] <a href=\"https://workflowhub.eu/\" rel=\"nofollow\">WorkflowHub</a>:\
    \ Galaxy, CWL, Nextflow, Snakemake, KNIME</li>\n<li>[ ] <a href=\"https://dockstore.org/\"\
    \ rel=\"nofollow\">Dockstore</a>: WDL, CWL, Nextflow, Galaxy</li>\n<li>[ ] <a\
    \ href=\"https://pegasushub.io\" rel=\"nofollow\">PegasusHub</a>: Pegasus</li>\n\
    <li>[ ] <a href=\"https://github.com/wfcommons\">WfCommons</a>: Pegasus, Makeflow,\
    \ Nextlfow</li>\n<li>[ ] <a href=\"https://www.myexperiment.org/\" rel=\"nofollow\"\
    >myExperiment</a>: Taverna, RapidMiner, Kepler, Bioclipse, LONI, GWorkflowDL,\
    \ BioExtract</li>\n<li>[ ] GitHub?</li>\n</ul>\n</li>\n<li>\n<p>Computational\
    \ experiment runtimes</p>\n<ul>\n<li>[x] <a href=\"https://nextflow.io\" rel=\"\
    nofollow\">Nextflow</a>\n</li>\n<li>[x] <a href=\"https://snakemake.github.io/\"\
    \ rel=\"nofollow\">Snakemake</a>\n</li>\n<li>[ ] SAW NGW (proprietary)</li>\n\
    <li>[ ] Galaxy</li>\n<li>[ ] WDL</li>\n<li>[ ] Common Workflow Language (CWL)</li>\n\
    <li>[ ] Pegasus</li>\n<li>[ ] Makefile</li>\n</ul>\n</li>\n<li>\n<p>Tests</p>\n\
    <ul>\n<li>[x] Repeatable crash-freedom?</li>\n<li>[ ] If crashes, repeatable error-message?</li>\n\
    <li>[ ] If not crashes, repeatable bitwise-equivalent with holding zero, one,\
    \ two, three, or four of {/dev/{,u}random, datetime, ASL, single-core}?</li>\n\
    <li>[ ] Repeatable 5--95%-ile interval?</li>\n</ul>\n</li>\n<li>\n<p>Code analysis</p>\n\
    <ul>\n<li>[ ] SLoC by type?</li>\n<li>[ ] Dependency graph?</li>\n<li>[ ] Component\
    \ graph?</li>\n<li>[ ] Similarity of experiments?</li>\n<li>[ ] Detect presence\
    \ of best practices?\n<ul>\n<li>Tools for reproducibility</li>\n<li>Dependency\
    \ count, transitive dependency count</li>\n<li>SLoC count by language, transitive\
    \ SLoC count by language</li>\n<li>Documentation to code ratio</li>\n</ul>\n</li>\n\
    </ul>\n</li>\n<li>\n<p>Data analysis assumptions:</p>\n<ul>\n<li>Assumption: Time\
    \ symmetry</li>\n<li>Assumption: Group and problem identity is constant and one-dimensional</li>\n\
    <li>Assumption: Versions are indistinguishable\n<ul>\n<li>Except possibly last\
    \ version?</li>\n</ul>\n</li>\n<li>Caveat: predictor != intervention</li>\n<li>Caveat:\
    \ predictor only works with unawareness of its use as a predictor\n<ul>\n<li><a\
    \ href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Goodhart%27s_law</a></li>\n\
    <li><a href=\"https://en.wikipedia.org/wiki/Lucas_critique\" rel=\"nofollow\"\
    >https://en.wikipedia.org/wiki/Lucas_critique</a></li>\n</ul>\n</li>\n<li>Analysis\
    \ question: Do input variables predict rate of decay or do input variables + staleness\
    \ predict failure?</li>\n<li>Analysis question: between levels of reproducibility\n\
    <ul>\n<li>Set of factors are necessary and sufficient for reproducibility</li>\n\
    <li>Successful termination</li>\n<li>{Faketime, fake random, ASLR}</li>\n<li>Multi-threaded</li>\n\
    </ul>\n</li>\n<li>Analysis question: Model infant mortality or constant rate of\
    \ failure?</li>\n</ul>\n</li>\n<li>\n<p>Data analysis:</p>\n<ul>\n<li>[ ] Measure\
    \ rate of collapse over time?\n<ul>\n<li>Coefficient of staleness on successful\
    \ termination</li>\n</ul>\n</li>\n<li>[ ] Predictive accuracy of collapse over\
    \ time based on staleness, code anaylsis, and optionally history?\n<ul>\n<li>How\
    \ to use information from other simultaneously failing workflows?</li>\n</ul>\n\
    </li>\n<li>[ ] How effective is each non-determinism mitigation?\n<ul>\n<li>\n\
    <code>R</code> / <code>total</code>\n</li>\n<li>\n<code>R_easy</code> / <code>total</code>\n\
    </li>\n<li>\n<code>R_multi</code> / <code>total</code>\n</li>\n<li>\n<code>R_all</code>\
    \ / <code>total</code>\n</li>\n</ul>\n</li>\n<li>[ ] Improve efficiency of continuous\
    \ testing in simulation?\n<ul>\n<li>Generate time-to-collapse</li>\n<li>How to\
    \ use information from other simultaneously failing workflows?</li>\n</ul>\n</li>\n\
    <li>[ ] Code best practices\n<ul>\n<li>Influence of code metrics on decay rate,\
    \ <code>R_easy</code>, (<code>R_all</code> given not <code>R_easy</code>)</li>\n\
    <li>Interaction between code metrics on rate of decay?</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n<li>\n<p>Other questions:</p>\n<ul>\n<li>[ ] Cluster error messages?</li>\n\
    <li>[ ] Replicate Zhao's categories?</li>\n<li>[ ] Design automatic fixes?</li>\n\
    <li>[ ] Outcome preserving input minimization?\n<ul>\n<li><a href=\"https://seg.inf.unibe.ch/papers/ase22.pdf\"\
    \ rel=\"nofollow\">https://seg.inf.unibe.ch/papers/ase22.pdf</a></li>\n</ul>\n\
    </li>\n<li>[ ] How many failures occur in a unit-testable component?</li>\n<li>[\
    \ ] Compositional testing?</li>\n</ul>\n</li>\n</ul>\n<p>See <a href=\"CONTRIBUTING.md\"\
    ><code>CONTRIBUTING.md</code></a> for instructions on setting up a development\
    \ environment.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664573525.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<h1><a id=\"user-content-d-seams\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#d-seams\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>d-SEAMS</h1>\n<p><strong>Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations</strong></p>\n<p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82b492dd4f94cd6fe1783f1065487d3dbc0602c2a65b1717a5613df3b6e8f65f/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <h1><a id=\"user-content-citation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #citation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citation</h1>\n\
    <ul>\n<li>\n<p>This has been published at the <a href=\"https://doi.org/10.1021/acs.jcim.0c00031\"\
    \ rel=\"nofollow\">Journal of Chemical Information and Modeling\n(JCIM)</a></p>\n\
    </li>\n<li>\n<p>You may also read <a href=\"https://arxiv.org/abs/1909.09830\"\
    \ rel=\"nofollow\">the preprint on arXiv</a></p>\n</li>\n</ul>\n<p>If you use\
    \ this software please cite the following:</p>\n<pre><code>Goswami, R., Goswami,\
    \ A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations. Journal of Chemical Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n\
    </code></pre>\n<p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<h1><a id=\"\
    user-content-compilation\" class=\"anchor\" aria-hidden=\"true\" href=\"#compilation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compilation</h1>\n\
    <p>We use a deterministic build system to generate both bug reports and uniform\n\
    usage statistics. This also handles the <code>lua</code> scripting engine.</p>\n\
    <p>\\note The lua functions are documented on the <a href=\"https://docs.dseams.info/md_markdown_luafunctions\"\
    \ rel=\"nofollow\">on the API Docs</a></p>\n<p>We also provide a <code>conda</code>\
    \ environment as a fallback, which is also recommended for MacOS users.</p>\n\
    <h2><a id=\"user-content-build\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build</h2>\n\
    <h3><a id=\"user-content-conda\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #conda\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conda</h3>\n\
    <p>Although we strongly suggest using <code>nix</code>, for MacOS systems, the\
    \ following\ninstructions may be more suitable. We will assume the presence of\
    \ <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\" rel=\"\
    nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>micromamba create -f environment.yml\nmicromamba activate dseams</pre></div>\n\
    <p>Now the installation can proceed.</p>\n<p>\\note we do not install a new version\
    \ of <code>cmake</code> within the <code>conda</code> environment because of conflicts\
    \ with <code>lua</code></p>\n<div class=\"highlight highlight-source-shell\"><pre>mkdir\
    \ build\n<span class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Release\
    \ -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span class=\"\
    pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span class=\"\
    pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake install</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<h3><a\
    \ id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>Manually this can be done in a painful way as follows:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>spack install eigen@3.3.9 lua@5.2\nspack install\
    \ catch2 fmt yaml-cpp openblas boost cmake ninja meson\nspack load catch2 fmt\
    \ yaml-cpp openblas boost cmake ninja meson eigen@3.3.9 lua@5.2\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span\
    \ class=\"pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> After loading the packages</span>\nluarocks install luafilesystem</pre></div>\n\
    <p>Now we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<h3><a id=\"user-content-nix\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#nix\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Nix</h3>\n<p>Since this project is\
    \ built with <code>nix</code>, we can simply do the following from the\nroot directory\
    \ (longer method):</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Make sure there are no artifacts</span>\n\
    rm -rf build\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> This will take\
    \ a long time the first time as it builds the dependencies</span>\nnix-build <span\
    \ class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Optional</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Install\
    \ into your path</span>\nnix-env -if <span class=\"pl-c1\">.</span> <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>A faster method of building the software is by using the <a href=\"https://dseams.cachix.org/\"\
    \ rel=\"nofollow\">cachix binary cache</a> as shown:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install cachix</span>\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Use the binary cache</span>\n\
    cachix use dseams\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with\
    \ the cache than building from scratch</span>\nnix-build <span class=\"pl-c1\"\
    >.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <h3><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h3>\n\
    <p>Having installed the <code>yodaStruct</code> binary and library, we can now\
    \ use it.</p>\n<div class=\"highlight highlight-source-shell\"><pre>yodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>\\note The paths in the <code>.yml</code>\
    \ should be <strong>relative to the folder from which the binary is called</strong>.</p>\n\
    <p>If you're confused about how to handle the relative paths, run the command\
    \ <code>yodaStruct -c lua_inputs/config.yml</code> in the top-level directory,\
    \ and set the paths relative to the top-level directory. This is the convention\
    \ used in the examples as well.</p>\n<h3><a id=\"user-content-language-server-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#language-server-support\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Language Server\
    \ Support</h3>\n<p>To generate a <code>compile_commands.json</code> file for working\
    \ with a language server\nlike <a href=\"https://github.com/MaskRay/ccls\">ccls</a>\
    \ use the following commands:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\n\
    nix-shell --pure\nmkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span\
    \ class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES\
    \ ../\ncp compile_commands.json ../</pre></div>\n<p>Note that there is no need\
    \ to actually compile the project if you simply need to\nget the compiler database\
    \ for the language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<h2><a id=\"user-content-development\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development</h2>\n<p>We can simply use the <code>nix</code> environment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> From the project root</span>\nnix-shell --pure</pre></div>\n\
    <h1><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n\
    <p>This is built completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install\
    \ systemwide\nnix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply\
    \ install the software, and ensure that <code>input/</code> is a child directory.</p>\n\
    <pre lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<h2><a id=\"user-content-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#tests\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Tests</h2>\n<p>Apart from the <a href=\"\
    https://docs.dseams.info/pages.html\" rel=\"nofollow\">examples</a>, the test-suite\n\
    can be run with the <code>yodaStruct_test</code> binary, which will drop into\
    \ the\n<code>nix</code> environment before building and executing <code>gdb</code>:</p>\n\
    <pre lang=\"{bash}\"><code># Just run this\n./testBuild.sh\n# quit gdb with quit\n\
    # Go run the test binary\ncd shellBuild\n./yodaStruct_test\n</code></pre>\n<p>Do\
    \ note that the regular installation via <code>nix-env</code> runs the tests before\
    \ the installation</p>\n<h1><a id=\"user-content-developer-documentation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#developer-documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Developer Documentation</h1>\n\
    \n<p>While developing, it is sometimes expedient to update the packages used.\
    \ It is\nthen useful to note that we use <a href=\"https://github.com/nmattia/niv/\"\
    >niv</a> to handle our pinned packages (apart from\nthe ones built from Github).\
    \ Thus, one might need, say:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>niv update nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with\
    \ nix:</p>\n<div class=\"highlight highlight-source-shell\"><pre>nix-build <span\
    \ class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Outputs are in ./result</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ If you get a CMake error</span>\nrm -rf build\nnix-store --delete /nix/store/<span\
    \ class=\"pl-smi\">$whatever</span> <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> $whatever is the derivation complaining</span>\nnix-collect-garbage\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> then try again [worst case\
    \ scenario]</span></pre></div>\n<h2><a id=\"user-content-leaks-and-performance\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#leaks-and-performance\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Leaks and performance</h2>\n\
    <p>While testing for leaks, use <code>clang</code> (for\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\"\
    >AddressSanitizer</a>\nand\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<h1><a id=\"user-content-overview\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Overview</h1>\n<p>As of Mon Jan\
    \ 20 15:57:18 2020, the lines of code calculated by\n<a href=\"http://cloc.sourceforge.net/\"\
    \ rel=\"nofollow\">cloc</a> are as follows:</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"><img src=\"images/cloc-2020-01-20_15-56.png\"\
    \ alt=\"Cloc Lines\" style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n<p>Please\
    \ ensure that all contributions are formatted according to the\n<a href=\"./clang-format\"\
    >clang-format</a> configuration file.</p>\n<p>Specifically, consider using the\
    \ following:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\"\
    >Sublime Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"\
    https://github.com/lassik/emacs-format-all-the-code\">format-all</a> for Emacs</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\">vim-clang-format</a>\
    \ for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <h2><a id=\"user-content-commit-hook\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #commit-hook\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Commit\
    \ Hook</h2>\n<p>Note that we expect compliance with the <code>clang-format</code>\
    \ as mentioned above, and this may be enforced by using the provided scripts for\
    \ a pre-commit hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<h1><a id=\"user-content-acknowledgements\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#acknowledgements\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Acknowledgements</h1>\n<p>The\
    \ following tools are used in this project:</p>\n<ul>\n<li>\n<a href=\"https://cmake.org/\"\
    \ rel=\"nofollow\">CMake</a> for compilation (<a href=\"https://github.com/cginternals/cmake-init\"\
    >cmake-init</a> was used as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\"\
    \ rel=\"nofollow\">Clang</a> because it is more descriptive with better tools</li>\n\
    <li>\n<a href=\"https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the\
    \ developer API</li>\n<li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\"\
    \ rel=\"nofollow\">clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"\
    https://github.com/barisione/clang-format-hooks\">clang-format-hooks</a> for <code>git</code>\
    \ hooks to enforce formatting</li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\"\
    \ rel=\"nofollow\">lua</a> for the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\"\
    \ rel=\"nofollow\">yaml</a> for the configuration</li>\n</ul>\n<h2><a id=\"user-content-third-party-libraries\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#third-party-libraries\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Third Party Libraries</h2>\n\
    <p>The libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n</ul>\n"
  stargazers_count: 26
  subscribers_count: 4
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1665839076.0
dbkinghorn/Puget-Labs-Containers:
  data_format: 2
  description: Puget Labs container build files
  filenames:
  - quantum-espresso-amd/spack.yaml
  - lammps-amd/spack.yaml
  - namd-amd/spack.yaml
  - wrf-amd/spack.yaml
  - hmmer-amd/spack.yaml
  - hpl-amd/spack.yaml
  - hpcg-amd/spack.yaml
  - gromacs-amd/spack.yaml
  - openfoam-amd/spack.yaml
  full_name: dbkinghorn/Puget-Labs-Containers
  latest_release: null
  readme: '<h1><a id="user-content-puget-labs-containers" class="anchor" aria-hidden="true"
    href="#puget-labs-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Puget
    Labs Containers</h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Many of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks.</p>

    <p>Files included for each application include,</p>

    <ul>

    <li>Spack spec.yaml build specifications</li>

    <li>Dockerfiles (Multi-stage)</li>

    <li>Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1660670570.0
epfl-scitas/cryoem-docker-image:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: epfl-scitas/cryoem-docker-image
  latest_release: null
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1663761990.0
eth-cscs/spack-stack:
  data_format: 2
  description: fast spack builds on slow filesystem
  filenames:
  - packages/nvhpc/spack.yaml
  - compilers/2-gcc/spack.yaml
  - packages/tools/spack.yaml
  - compilers/3-llvm/spack.yaml
  - compilers/1-gcc/spack.yaml
  - packages/gcc/spack.yaml
  - packages/clang/spack.yaml
  full_name: eth-cscs/spack-stack
  latest_release: null
  readme: '<p>Bootstrap GCC, LLVM and NVHPC, and build an HPC software stack based
    on

    OpenMPI, with a few unique features:</p>

    <ol>

    <li>parallel package builds with single jobserver for all builds;</li>

    <li>avoiding relocation issues by fixing the install path to a new directory <code>/some-dir</code>
    of choice (no root access required);</li>

    <li>fast, in-memory builds.</li>

    </ol>

    <p><strong>Requirements</strong>:</p>

    <ul>

    <li><code>spack</code></li>

    <li>

    <code>bwrap</code> (when not already building inside a sandbox)</li>

    </ul>

    <p><strong>Usage</strong>:</p>

    <ol>

    <li>Copy <code>Make.user.example</code> to <code>Make.user</code> and change some
    variables.</li>

    <li>Run <code>make -j$(nproc)</code> to bootstrap compilers and packages.</li>

    <li>Run <code>make store.squashfs</code> to bundle those in a squashfs file.</li>

    <li>Run <code>make build.tar.gz</code> to create a tarball of all concrete environments
    and

    generated config files for posterity. This excludes the actual software.</li>

    </ol>

    <p><strong>Variables</strong></p>

    <p>A few variables in <code>Make.user</code>:</p>

    <ul>

    <li>

    <code>STORE</code>: where to install packages;</li>

    <li>

    <code>SPACK</code>: what <code>spack</code> to use;</li>

    <li>

    <code>SPACK_SYSTEM_CONFIG_PATH</code>: path to spack config dir (e.g. <a href="config/hohgant">config/hohgant</a>).</li>

    <li>

    <code>SANDBOX</code>: run commands in a sandbox (e.g. bubblewrap), see <code>Make.user.example</code>
    for details.</li>

    <li>

    <code>SPACK_INSTALL_FLAGS</code>: specify more install flags, like <code>--verbose</code>.</li>

    </ul>

    <p><strong>Reproducibility</strong></p>

    <p>When building on a production system instead of in a sandbox, there''s a few
    things to

    do to improve reproducibility:</p>

    <ol>

    <li>Always run <code>make</code> inside a clean environment:

    <pre><code>env --ignore-environment PATH=/usr/bin:/bin make

    </code></pre>

    </li>

    <li>Update <code>Make.user</code> to hide your home folder so that no user config
    is picked up:

    <pre><code>SANDBOX := bwrap --tmpfs ~ ...

    </code></pre>

    </li>

    <li>Set <code>LC_ALL</code>, <code>TZ</code> and <code>SOURCE_DATE_EPOCH</code>
    to something fixed in <code>Make.user</code>.</li>

    </ol>

    <p><strong>Unprivileged mounts</strong></p>

    <p>The squashfs file can then be mounted using <a href="https://github.com/eth-cscs/squashfs-mount">squashfs-mount</a>
    or <code>squashfuse</code></p>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1661852790.0
eugeneswalker/exago-crusher:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: eugeneswalker/exago-crusher
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657654737.0
eugeneswalker/facility-spack:
  data_format: 2
  description: null
  filenames:
  - uo-containers/22.08/release/e4s-22.08-cuda.spack.yaml
  - uo-containers/22.08/components/gpu-cuda-ppc64le-noex/spack.yaml
  - uo-containers/22.08/_archive/prep/cuda-ppc64le-noex/spack.yaml
  - uo-containers/22.11/components/cpu/spack.yaml
  - crusher/22.08/PrgEnv-cray/spack.yaml
  - uo-containers/22.08/_archive/prep/cpu/spack.yaml
  - crusher/22.08/mvapich2/failures/spack.yaml
  - uo-containers/22.08/release/_backup/e4s-22.08-cuda-aarch64-noex.spack.yaml
  - uo-containers/22.08/components/gpu-cuda-ppc64le/spack.yaml
  - perlmutter/22.05/PrgEnv-gnu/spack.yaml
  - crusher/22.05/mvapich2/spack.yaml
  - uo-containers/22.11/rocm.spack.yaml
  - perlmutter/22.08/PrgEnv-gnu/spack.yaml
  - uo-containers/22.11/components/gpu-rocm/spack.yaml
  - uo-containers/22.08/_archive/prep/cpu-ppc64le/spack.yaml
  - uo-containers/22.08/_archive/prep/cuda-noex/spack.yaml
  - aws/paratools/parallelcluster-3.1.4/exawind-demo/spack.yaml
  - arcticus/22.11/spack.yaml
  - perlmutter/22.08/mvapich2-3.0a/failures/spack.yaml
  - perlmutter/22.08/mvapich2-3.0a/spack.yaml
  - uo-containers/22.08/release/public/cuda-ppc64le.spack.yaml
  - crusher/22.11/PrgEnv-gnu/spack.yaml
  - perlmutter/22.05/PrgEnv-nvhpc/spack.yaml
  - perlmutter/22.11/PrgEnv-gnu/failures/spack.yaml
  - uo-containers/22.08/release/e4s-22.08-cuda-ppc64le.spack.yaml
  - uo-containers/22.08/release/_backup/e4s-22.08-cuda-noex.spack.yaml
  - uo-containers/22.11/components/oneapi-public-release/spack.yaml
  - crusher/22.08/PrgEnv-gnu/failures/spack.yaml
  - perlmutter/22.08/mvapich2-3.0a/ecp-data-vis-sdk/spack.yaml
  - frontera/22.05/spack.yaml
  - uo-containers/22.11/components/cpu-plus-gpu-oneapi/big.spack.yaml
  - uo-containers/22.08/release/_backup/e4s-22.08-rocm-noex.spack.yaml
  - oci/mvapich2/spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/together.w-failures.spack.yaml
  - arcticus/22.08/spack.yaml
  - uo-containers/22.08/components/cpu-plus-gpu-oneapi/spack.yaml
  - arcticus/develop/spack.yaml
  - uo-containers/22.11/release/containers/amd64-cuda/spack.yaml
  - uo-containers/22.11/components/gpu-cuda/spack.yaml
  - uo-containers/22.11/oneapi.spack.yaml
  - uo-containers/22.11/components/gpu-cuda-noex/spack.yaml
  - crusher/22.11/PrgEnv-cray/spack.yaml
  - uo-containers/22.11/components/gpu-cuda-ppc64le-noex/spack.yaml
  - crusher/22.08/PrgEnv-amd/spack.yaml
  - crusher/22.11/PrgEnv-amd/spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/spack.yaml
  - perlmutter/22.05/mvapich2-3.0a/spack.yaml
  - uo-containers/22.08/components/gpu-cuda-noex/spack.yaml
  - arcticus/22.08/failures/spack.yaml
  - applications/exago/crusher/spack.yaml
  - uo-containers/22.11/components/gpu-rocm-noex/spack.yaml
  - crusher/22.08/PrgEnv-gnu/spack.yaml
  - uo-containers/22.08/components/cpu/spack.yaml
  - uo-containers/22.08/release/public/cuda.spack.yaml
  - uo-containers/22.08/_archive/prep/cuda/spack.yaml
  - uo-containers/22.11/release/containers/ppc64le-cuda/spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/separately.wo-failures.spack.yaml
  - uo-containers/22.08/release/public/cpu.spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/together.wo-failures.spack.yaml
  - perlmutter/22.11/PrgEnv-gnu/spack.yaml
  - uo-containers/22.11/release/containers/aarch64-cuda/spack.yaml
  - aws/paratools/parallelcluster-3.1.4/spack.yaml
  - uo-containers/22.08/release/_backup/e4s-22.08-cuda-ppc64le-noex.spack.yaml
  - uo-containers/22.08/_archive/prep/cuda-aarch64-noex/spack.yaml
  - uo-containers/22.11/components/cpu-ppc64le/spack.yaml
  - crusher/22.11/mvapich2/spack.yaml
  - uo-containers/22.08/_archive/prep/oneapi/spack.yaml
  - oneapi/ubuntu20.04-runner-x86_64-oneapi/breakdowns/separately.w-failures.spack.yaml
  - uo-containers/22.08/components/gpu-rocm/spack.yaml
  - uo-containers/22.08/release/public/cuda-aarch64.spack.yaml
  - uo-containers/22.08/_archive/prep/rocm-noex/spack.yaml
  - uo-containers/22.08/components/gpu-cuda/spack.yaml
  - perlmutter/22.08/PrgEnv-gnu/failures/spack.yaml
  - uo-containers/22.08/release/e4s-22.08-rocm.spack.yaml
  - uo-containers/22.11/cuda.spack.yaml
  - uo-containers/22.11/release/containers/amd64-rocm/spack.yaml
  - uo-containers/22.11/release/containers/amd64-oneapi/cpu-gcc.spack.yaml
  - crusher/22.08/mvapich2/spack.yaml
  - uo-containers/22.08/components/gpu-rocm-noex/spack.yaml
  - uo-containers/22.08/_archive/prep/rocm/spack.yaml
  - uo-containers/22.08/release/public/oneapi.spack.yaml
  - bridges2/22.05/openmpi-4.1.1-gcc8.3.1/spack.yaml
  - uo-containers/22.08/release/public/rocm.spack.yaml
  - uo-containers/22.08/release/e4s-22.08-cpu.spack.yaml
  - uo-containers/22.08/release/e4s-22.08-oneapi.spack.yaml
  - perlmutter/22.11/mvapich2/spack.yaml
  - oci/adaptive-test-env/spack.yaml
  - crusher/22.08/PrgEnv-cray/failures/spack.yaml
  - uo-containers/22.11/components/cpu-plus-gpu-oneapi/spack.yaml
  - uo-containers/22.11/release/containers/amd64-oneapi/oneapi.spack.yaml
  - crusher/22.08/PrgEnv-amd/failures/spack.yaml
  - uo-containers/22.11/components/gpu-cuda-ppc64le/spack.yaml
  - uo-containers/22.08/_archive/prep/cuda-ppc64le/spack.yaml
  full_name: eugeneswalker/facility-spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1655395315.0
eugeneswalker/noaa-prototyping:
  data_format: 2
  description: null
  filenames:
  - oneapi/spack.yaml
  - nvhpc/spack.yaml
  - gnu/spack.yaml
  full_name: eugeneswalker/noaa-prototyping
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666800656.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-clang/spack.yaml
  - ubuntu-gcc/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1><a id="user-content-synergia2-containers" class="anchor" aria-hidden="true"
    href="#synergia2-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1646758059.0
giordano/julia-on-fugaku:
  data_format: 2
  description: null
  filenames:
  - benchmarks/blas-axpy/spack-env/spack.yaml
  full_name: giordano/julia-on-fugaku
  latest_release: null
  readme: "<h1><a id=\"user-content-julia-on-fugaku-2022-07-23\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#julia-on-fugaku-2022-07-23\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Julia on Fugaku (2022-07-23)</h1>\n\
    <p><em>Note: many links refer to internal documentation which is accessible only\
    \ to Fugaku users.</em></p>\n<h2><a id=\"user-content-storage\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#storage\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Storage</h2>\n<p>Before doing anything on Fugaku,\
    \ be aware that there are <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20220408_01\"\
    \ rel=\"nofollow\">tight\nlimits</a> on the size of (20 GiB)\nand the number of\
    \ inodes in (200k) your home directory.  If you use many Julia Pkg\nartifacts,\
    \ it's very likely you'll hit these limits.  You'll notice that you hit the limit\n\
    because any disk I/O operation will result in a <code>Disk quota exceeded</code>\
    \ error like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-e\">[user@fn01sv03 ~]</span>$ <span class=\"pl-s1\">touch\
    \ foo</span>\n<span class=\"pl-c1\">touch: cannot touch 'foo': Disk quota exceeded</span></pre></div>\n\
    <p>You can check the quota of your home directory with <code>accountd</code> for\
    \ the size, and <code>accountd -i</code> for the number of inodes.</p>\n<h3><a\
    \ id=\"user-content-using-the-data-directory\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#using-the-data-directory\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Using the data directory</h3>\n<p>In order to\
    \ avoid clogging up the home directory you may want to move the Julia depot to\
    \ the\ndata directory:</p>\n<div class=\"highlight highlight-source-shell\"><pre>DATADIR=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/data/&lt;YOUR GROUP&gt;/<span\
    \ class=\"pl-smi\">${USER}</span><span class=\"pl-pds\">\"</span></span>\n<span\
    \ class=\"pl-k\">export</span> JULIA_DEPOT_PATH=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span><span class=\"pl-smi\">${DATADIR}</span>/julia-depot<span class=\"\
    pl-pds\">\"</span></span></pre></div>\n<h2><a id=\"user-content-interactive-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#interactive-usage\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Interactive usage</h2>\n<p>The\
    \ login nodes you access via <code>login.fugaku.r-ccs.riken.jp</code> (<a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/AccessToTheSystem/LoggingInToTheFugakuComputerWithLocalAccount.html\"\
    \ rel=\"nofollow\">connection\ninstructions</a>)\nhave Cascade Lake CPUs, so they\
    \ aren't much useful if you want to run an aarch64 Julia.</p>\n<p>You can <a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/Overview.html\"\
    \ rel=\"nofollow\">submit jobs to the\nqueue</a>\nto run Julia code on the A64FX\
    \ compute nodes, but this can be cumbersone if you need quick\nfeedback during\
    \ development or debugging.  You can also request an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/InteractiveJob.html\"\
    \ rel=\"nofollow\">interactive\nnode</a>,\nfor example with:</p>\n<pre><code>pjsub\
    \ --interact -L \"node=1\" -L \"rscgrp=int\" -L \"elapse=30:00\" --sparam \"wait-time=600\"\
    \ --mpi \"max-proc-per-node=4\"\n</code></pre>\n<h2><a id=\"user-content-available-software\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#available-software\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Available software</h2>\n<p>Fugaku\
    \ uses the <a href=\"https://spack.io/\" rel=\"nofollow\">Spack package manager</a>.\
    \  For more information about how\nto use it, see the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/FugakuSpackGuide/\"\
    \ rel=\"nofollow\">Fugaku Spack User\nGuide</a>.</p>\n<p>Note that Spack is installed\
    \ in <code>/vol0004</code>, this means that if your home directory isn't\nmounted\
    \ on this volume you will have to <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20211130_02\"\
    \ rel=\"nofollow\">explicitly request the\npartition</a> in your submission\n\
    job scripts or commands, for example by adding <code>-x PJM_LLIO_GFSCACHE=/vol0004</code>\
    \ to the\n<code>pjsub</code> command, or the line</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>PJM\
    \ -x PJM_LLIO_GFSCACHE=/vol0004</span></pre></div>\n<p>in a job script.</p>\n\
    <h2><a id=\"user-content-using-julia-on-the-compute-nodes\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#using-julia-on-the-compute-nodes\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Using Julia on the compute nodes</h2>\n<p>There\
    \ is a Julia module built with Spack <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/UsingOSS/oss_e.html#packages-installed-on-the-compute-nodes\"\
    \ rel=\"nofollow\">available on the compute\nnodes</a>,\nbut as of this writing\
    \ (2022-07-23) the version of Julia provided is 1.6.3, so you may want\nto download\
    \ a more recent version from the <a href=\"https://julialang.org/downloads/\"\
    \ rel=\"nofollow\">official\nwebsite</a>.  Use the <code>aarch64</code> builds\
    \ for Glibc Linux,\npreferably <a href=\"https://julialang.org/downloads/#current_stable_release\"\
    \ rel=\"nofollow\">latest stable</a> or even\nthe <a href=\"https://julialang.org/downloads/nightlies/\"\
    \ rel=\"nofollow\">nightly build</a> if you feel confident.</p>\n<p>To enable\
    \ full vectorisation you may need to set the environment variable\n<code>JULIA_LLVM_ARGS=\"\
    -aarch64-sve-vector-bits-min=512\"</code>.  Example:\n<a href=\"https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\"\
    >https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623</a>. \
    \ However, note that\nare a couple of severe bugs when using 512-bit vectors:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/JuliaLang/julia/issues/44401\">https://github.com/JuliaLang/julia/issues/44401</a>\
    \ (may be an upstream LLVM bug:\n<a href=\"https://github.com/llvm/llvm-project/issues/53331\"\
    >https://github.com/llvm/llvm-project/issues/53331</a>)</li>\n<li>\n<a href=\"\
    https://github.com/JuliaLang/julia/issues/44263\">https://github.com/JuliaLang/julia/issues/44263</a>\
    \ (only in Julia v1.8+)</li>\n</ul>\n<p><em><strong>Note</strong></em>: Julia\
    \ v1.9, which is based on <a href=\"https://community.arm.com/arm-community-blogs/b/tools-software-ides-blog/posts/llvm-14\"\
    \ rel=\"nofollow\">LLVM\n14</a>,\nis able to natively autovectorise code for A64FX\
    \ <em>without</em> having to set\n<code>JULIA_LLVM_ARGS</code>, side stepping\
    \ the issues above altogether.</p>\n<h2><a id=\"user-content-mpijl\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#mpijl\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>MPI.jl</h2>\n<p><a href=\"https://github.com/JuliaParallel/MPI.jl\"\
    ><code>MPI.jl</code></a> with default JLL-provided MPICH works\nout of the box!\
    \  In order to\n<a href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\"\
    \ rel=\"nofollow\">configure</a> <code>MPI.jl</code> v0.19 to\nuse system-provided\
    \ Fujitsu MPI (based on OpenMPI) you have to specify the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/CompileCommands.html\"\
    \ rel=\"nofollow\">MPI C\ncompiler</a>\nfor A64FX with</p>\n<pre><code>julia --project\
    \ -e 'ENV[\"JULIA_MPI_BINARY\"]=\"system\"; ENV[\"JULIA_MPICC\"]=\"mpifcc\"; using\
    \ Pkg; Pkg.build(\"MPI\"; verbose=true)'\n</code></pre>\n<p><em><strong>Note #1</strong></em>:\
    \ <code>mpifcc</code> is available only on the compute nodes.  On the login nodes\
    \ that would be\n<code>mpifccpx</code>, but this is the cross compiler running\
    \ on Intel architecture, it's unlikely\nyou'll run an <code>aarch64</code> Julia\
    \ on there.  <a href=\"https://github.com/JuliaParallel/MPI.jl/issues/539\">Preliminary\n\
    tests</a> show that <code>MPI.jl</code> should work\nmostly fine with Fujitsu\
    \ MPI, but custom error handlers may not be available (read: trying\nto use them\
    \ causes segmentation faults).</p>\n<p><em><strong>Note #2</strong></em>: in <code>MPI.jl</code>\
    \ v0.20 Fujitsu MPI is a known ABI (it's the same as OpenMPI) and\nthere is nothing\
    \ special to do to configure it apart from <a href=\"https://juliaparallel.org/MPI.jl/dev/configuration/#Configuration-2\"\
    \ rel=\"nofollow\">choosing the system\nbinaries</a>.</p>\n<p><em><strong>Note\
    \ #3</strong></em>: we recommend using <code>MPI.jl</code>'s wrapper of <code>mpiexec</code>\
    \ to run MPI applications\nwith Julia:\n<a href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Julia-wrapper-for-mpiexec\"\
    \ rel=\"nofollow\"><code>mpiexecjl</code></a>.</p>\n<h3><a id=\"user-content-file-system-latency\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#file-system-latency\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>File system latency</h3>\n<p>Fugaku\
    \ has an advanced system to handle <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/index.html\"\
    \ rel=\"nofollow\">parallel file system\nlatency</a>.\nIn order.  In order to\
    \ speed up parallel applications run through MPI you may want to\ndistribute it\
    \ to the cache area of the second-layer storage on the first-layer storage using\n\
    <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/TheSecondLayerStrage.html#common-file-distribution-function-llio-transfer\"\
    \ rel=\"nofollow\"><code>llio_transfer</code></a>.\nIn particular, if you're using\
    \ Julia, you likely want to distribute the <code>julia</code> executable\nitself\
    \ together with its installation bundle.</p>\n<p>For example, assuming that you\
    \ are using the official binaries from the website, instead of\nthe Julia module\
    \ provided by Spack, you can do the following:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Directory for log of\
    \ `llio_transfer` and its wrapper `dir_transfer`</span>\nLOGDIR=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${TMPDIR}</span>/log<span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Create the log directory if necessary</span>\nmkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Get directory where Julia is placed</span>\nJL_BUNDLE=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>dirname <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>julia --startup-file=no\
    \ -O0 --compile=min -e <span class=\"pl-s\"><span class=\"pl-pds\">'</span>print(Sys.BINDIR)<span\
    \ class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span><span\
    \ class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Move Julia installation to\
    \ fast LLIO directory</span>\n/home/system/tool/dir_transfer -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Do not write\
    \ empty stdout/stderr files for MPI processes.</span>\n<span class=\"pl-k\">export</span>\
    \ PLE_MPI_STD_EMPTYFILE=off\n\nmpiexecjl --project=. -np ... julia ...\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Remove Julia installation directory\
    \ from the cache.</span>\n/home/system/tool/dir_transfer -p -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span></pre></div>\n<h2><a id=\"user-content-reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reverse\
    \ engineering Fujitsu compiler using LLVM output</h2>\n<p>The Fujitsu compiler\
    \ has <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/C/modeTradAndClangC.html\"\
    \ rel=\"nofollow\">two operation\nmodes</a>:\n\"trad\" (for \"traditional\") and\
    \ \"clang\" (enabled by the flag <code>-Nclang</code>).  In clang mode it's\n\
    based on LLVM (version 7 at the moment).  This means you can get it to emit LLVM\
    \ IR with\n<code>-emit-llvm</code>.  For example, with</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\"\
    >echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>int main(){}<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> fcc -Nclang -x\
    \ c - -S -emit-llvm -o -</span></pre></div>\n<p>you get</p>\n<div class=\"highlight\
    \ highlight-source-llvm\"><pre><span class=\"pl-c\">; ModuleID = '-'</span>\n\
    source_filename = <span class=\"pl-s\">\"-\"</span>\n<span class=\"pl-k\">target</span>\
    \ <span class=\"pl-k\">datalayout</span> = <span class=\"pl-s\">\"e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128\"\
    </span>\n<span class=\"pl-k\">target</span> <span class=\"pl-k\">triple</span>\
    \ = <span class=\"pl-s\">\"aarch64-unknown-linux-gnu\"</span>\n\n<span class=\"\
    pl-c\">; Function Attrs: norecurse nounwind readnone uwtable</span>\n<span class=\"\
    pl-k\">define</span> dso_local <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">@main</span>() <span class=\"pl-k\">local_unnamed_addr</span> #<span class=\"\
    pl-c1\">0</span> <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!8</span>\
    \ {\n  <span class=\"pl-k\">ret</span> <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!11</span>\n\
    }\n\n<span class=\"pl-k\">attributes</span> #<span class=\"pl-c1\">0</span> =\
    \ { <span class=\"pl-k\">norecurse</span> <span class=\"pl-k\">nounwind</span>\
    \ <span class=\"pl-k\">readnone</span> <span class=\"pl-k\">uwtable</span> <span\
    \ class=\"pl-s\">\"correctly-rounded-divide-sqrt-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"disable-tail-calls\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"less-precise-fpmad\"\
    </span>=<span class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim\"\
    </span>=<span class=\"pl-s\">\"true\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim-non-leaf\"\
    </span> <span class=\"pl-s\">\"no-infs-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"no-jump-tables\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> <span class=\"pl-s\">\"no-nans-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-signed-zeros-fp-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-trapping-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"stack-protector-buffer-size\"\
    </span>=<span class=\"pl-s\">\"8\"</span> <span class=\"pl-s\">\"target-cpu\"\
    </span>=<span class=\"pl-s\">\"a64fx\"</span> <span class=\"pl-s\">\"target-features\"\
    </span>=<span class=\"pl-s\">\"+crc,+crypto,+fp-armv8,+lse,+neon,+ras,+rdm,+sve,+v8.2a\"\
    </span> <span class=\"pl-s\">\"unsafe-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"use-soft-float\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> }\n\n<span class=\"pl-v\">!llvm.dbg.cu</span> = !{<span class=\"\
    pl-v\">!0</span>}\n<span class=\"pl-v\">!llvm.module.flags</span> = !{<span class=\"\
    pl-v\">!3</span>, <span class=\"pl-v\">!4</span>, <span class=\"pl-v\">!5</span>}\n\
    <span class=\"pl-v\">!llvm.ident</span> = !{<span class=\"pl-v\">!6</span>}\n\
    <span class=\"pl-v\">!llvm.compinfo</span> = !{<span class=\"pl-v\">!7</span>}\n\
    \n<span class=\"pl-v\">!0</span> = distinct <span class=\"pl-v\">!DICompileUnit</span>(language:\
    \ DW_LANG_C99, file: <span class=\"pl-v\">!1</span>, producer: <span class=\"\
    pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on\
    \ LLVM 7.1.0)\"</span>, isOptimized: <span class=\"pl-k\">true</span>, runtimeVersion:\
    \ <span class=\"pl-c1\">0</span>, emissionKind: LineTablesOnly, enums: <span class=\"\
    pl-v\">!2</span>)\n<span class=\"pl-v\">!1</span> = <span class=\"pl-v\">!DIFile</span>(filename:\
    \ <span class=\"pl-s\">\"-\"</span>, directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"\
    </span>)\n<span class=\"pl-v\">!2</span> = !{}\n<span class=\"pl-v\">!3</span>\
    \ = !{<span class=\"pl-k\">i32</span> <span class=\"pl-c1\">2</span>, !<span class=\"\
    pl-s\">\"Dwarf Version\"</span>, <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">4</span>}\n<span class=\"pl-v\">!4</span> = !{<span class=\"pl-k\">i32</span>\
    \ <span class=\"pl-c1\">2</span>, !<span class=\"pl-s\">\"Debug Info Version\"\
    </span>, <span class=\"pl-k\">i32</span> <span class=\"pl-c1\">3</span>}\n<span\
    \ class=\"pl-v\">!5</span> = !{<span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">1</span>, !<span class=\"pl-s\">\"wchar_size\"</span>, <span class=\"\
    pl-k\">i32</span> <span class=\"pl-c1\">4</span>}\n<span class=\"pl-v\">!6</span>\
    \ = !{!<span class=\"pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021\
    \ 10:55:52) (based on LLVM 7.1.0)\"</span>}\n<span class=\"pl-v\">!7</span> =\
    \ !{!<span class=\"pl-s\">\"C::clang\"</span>}\n<span class=\"pl-v\">!8</span>\
    \ = distinct <span class=\"pl-v\">!DISubprogram</span>(name: <span class=\"pl-s\"\
    >\"main\"</span>, scope: <span class=\"pl-v\">!9</span>, file: <span class=\"\
    pl-v\">!9</span>, line: <span class=\"pl-c1\">1</span>, type: <span class=\"pl-v\"\
    >!10</span>, isLocal: <span class=\"pl-k\">false</span>, isDefinition: <span class=\"\
    pl-k\">true</span>, scopeLine: <span class=\"pl-c1\">1</span>, isOptimized: <span\
    \ class=\"pl-k\">true</span>, unit: <span class=\"pl-v\">!0</span>, retainedNodes:\
    \ <span class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!9</span> = <span class=\"\
    pl-v\">!DIFile</span>(filename: <span class=\"pl-s\">\"&lt;stdin&gt;\"</span>,\
    \ directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"</span>)\n<span class=\"\
    pl-v\">!10</span> = <span class=\"pl-v\">!DISubroutineType</span>(types: <span\
    \ class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!11</span> = <span class=\"\
    pl-v\">!DILocation</span>(line: <span class=\"pl-c1\">1</span>, column: <span\
    \ class=\"pl-c1\">12</span>, scope: <span class=\"pl-v\">!8</span>)</pre></div>\n\
    <h2><a id=\"user-content-systembenchmarksjl\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#systembenchmarksjl\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>SystemBenchmarks.jl</h2>\n<p>I ran <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl\"\
    ><code>SystemBenchmarks.jl</code></a> on a\ncompute node.  Here are the results:\n\
    <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\"\
    >https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968</a>.</p>\n\
    <h2><a id=\"user-content-blas\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #blas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>BLAS</h2>\n\
    <p>OpenBLAS seems to have poor performance:</p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">2.589865257047898e10</span></pre></div>\n\
    <p>Up to v1.7, Julia uses OpenBLAS v0.3.17, which actually doesn't support A64FX\
    \ at all, so\nit's probably using the generic kernels.\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.19\"\
    ><code>v0.3.19</code></a> and\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.20\"\
    ><code>v0.3.20</code></a> improved support for\nthis chip, you can find a build\
    \ of 0.3.20 at\n<a href=\"https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\"\
    >https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz</a>,\n\
    but sadly there isn't a great performance improvement:</p>\n<div class=\"highlight\
    \ highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">lbt_forward</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>lib/libopenblas64_.so<span class=\"pl-pds\"\
    >\"</span></span>)\n<span class=\"pl-c1\">4856</span>\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.6362952057793587e10</span></pre></div>\n\
    <p>There is an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/Library/BLASLAPACKScaLAPACKLibrary.html#how-to-dynamically-load-and-use-blas-lapack-and-scalapack\"\
    \ rel=\"nofollow\">optimised\nBLAS</a>\nprovided by Fujitsu, with support for\
    \ SVE (with both LP64 and ILP64).  In order to use it,\ninstall <a href=\"https://github.com/giordano/FujitsuBLAS.jl\"\
    ><code>FujitsuBLAS.jl</code></a></p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ FujitsuBLAS, LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">get_config</span>()\nLinearAlgebra<span\
    \ class=\"pl-k\">.</span>BLAS<span class=\"pl-k\">.</span>LBTConfig\nLibraries<span\
    \ class=\"pl-k\">:</span> \n\u2514 [ILP64] libfjlapackexsve_ilp64<span class=\"\
    pl-k\">.</span>so\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">4.801227630694119e10</span></pre></div>\n\
    <p>The package <a href=\"https://github.com/carstenbauer/BLISBLAS.jl\"><code>BLISBLAS.jl</code></a>\
    \ similarly forwards\nBLAS calls to the <a href=\"https://github.com/flame/blis\"\
    >blis</a> library, which has optimised kernels\nfor A64FX.</p>\n<h2><a id=\"user-content-building-julia-from-source\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#building-julia-from-source\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building Julia\
    \ from source</h2>\n<h3><a id=\"user-content-with-gcc\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#with-gcc\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>with GCC</h3>\n<p>Building Julia from source with GCC (which is the\
    \ default if you don't set <code>CC</code> and <code>CXX</code>)\nworks fine,\
    \ it's just <em>slow</em>:</p>\n<pre><code>[...]\n    JULIA usr/lib/julia/corecompiler.ji\n\
    Core.Compiler \u2500\u2500\u2500\u2500 903.661 seconds\n[...]\nBase  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500271.257337 seconds\n\
    ArgTools  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 50.348227 seconds\n\
    Artifacts  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.193792 seconds\n\
    Base64  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.057241\
    \ seconds\nCRC32c  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.097865 seconds\nFileWatching  \u2500\u2500\u2500\u2500\u2500  1.169747\
    \ seconds\nLibdl  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.026215 seconds\nLogging  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  0.411966 seconds\nMmap  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.972844 seconds\nNetworkOptions \
    \ \u2500\u2500\u2500  1.159094 seconds\nSHA  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.067851 seconds\nSerialization\
    \  \u2500\u2500\u2500\u2500  2.942512 seconds\nSockets  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.568797 seconds\nUnicode  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.814165 seconds\nDelimitedFiles \
    \ \u2500\u2500\u2500  1.121546 seconds\nLinearAlgebra  \u2500\u2500\u2500\u2500\
    109.560774 seconds\nMarkdown  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  7.977584 seconds\nPrintf  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  1.635409 seconds\nRandom  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 13.843395 seconds\nTar  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.146368 seconds\n\
    Dates  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 16.694863 seconds\nDistributed  \u2500\u2500\u2500\u2500\u2500\u2500  8.163152\
    \ seconds\nFuture  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.060472 seconds\nInteractiveUtils  \u2500  5.245523 seconds\nLibGit2\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 15.469061 seconds\n\
    Profile  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  5.399918\
    \ seconds\nSparseArrays  \u2500\u2500\u2500\u2500\u2500 42.660136 seconds\nUUIDs\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.165799\
    \ seconds\nREPL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500 40.149298 seconds\nSharedArrays  \u2500\u2500\u2500\u2500\u2500 \
    \ 5.476926 seconds\nStatistics  \u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.130843\
    \ seconds\nSuiteSparse  \u2500\u2500\u2500\u2500\u2500\u2500 16.849304 seconds\n\
    TOML  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.714203 seconds\nTest  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500  3.538098 seconds\nLibCURL  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.547585 seconds\nDownloads  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.657012 seconds\nPkg  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 54.053634 seconds\n\
    LazyArtifacts  \u2500\u2500\u2500\u2500  0.019103 seconds\nStdlibs total  \u2500\
    \u2500\u2500\u2500427.178257 seconds\nSysimage built. Summary:\nTotal \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 698.447219 seconds \nBase: \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500 271.257337 seconds 38.8372%\nStdlibs: \u2500\u2500\u2500\u2500\
    \ 427.178257 seconds 61.1611%\n[...]\nPrecompilation complete. Summary:\nTotal\
    \ \u2500\u2500\u2500\u2500\u2500\u2500\u2500 1274.714700 seconds\nGeneration \u2500\
    \u2500 886.445205 seconds 69.5407%\nExecution \u2500\u2500\u2500 388.269495 seconds\
    \ 30.4593%\n</code></pre>\n<h3><a id=\"user-content-with-fujitsu-compiler\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#with-fujitsu-compiler\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>With Fujitsu compiler</h3>\n\
    <p><em>For reference, the version used for the last build I attempted was\n<a\
    \ href=\"https://github.com/JuliaLang/julia/commit/1ad2396f05fa63a71e5842c814791cd7c7715100\"\
    ><code>1ad2396f</code></a></em></p>\n<p>Compiling Julia from source with the Fujitsu\
    \ compiler is complicated.  In particular, it's\nan absolute pain to use the Fujitsu\
    \ compiler in trad mode.  You can have some more luck with\nclang mode.</p>\n\
    <p>Preparation.  Create the <code>Make.user</code> file with this content (I'm\
    \ not sure this file is\nactually necessary when using Clang mode, but it definitely\
    \ is with trad mode):</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-k\">override</span> <span class=\"pl-smi\">ARCH</span>\
    \ := aarch64\n<span class=\"pl-k\">override</span> <span class=\"pl-smi\">BUILD_MACHINE</span>\
    \ := aarch64-unknown-linux-gnu</pre></div>\n<p>Then you can compile with (<code>-Nclang</code>\
    \ is to select clang mode)</p>\n<pre><code>make -j50 CC=\"fcc -Nclang\" CFLAGS=\"\
    -Kopenmp\" CXX=\"FCC -Nclang\" CXXFLAGS=\"-Kopenmp\"\n</code></pre>\n<p>The compiler\
    \ in trad mode doesn't define the macro <code>__SIZEOF_POINTER__</code>, so compilation\n\
    would fail in\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115</a>.\n\
    The solution is to set the macro <code>-D__SIZEOF_POINTER__=8</code> in the <code>CFLAGS</code>\
    \ (or just not use\ntrad mode).  Then, you may get errors like</p>\n<pre><code>/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2000:13:\
    \ error: initializer element is not a compile-time constant\n            jl_typename_type,\n\
    \            ^~~~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    /vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2025:43: error: initializer\
    \ element is not a compile-time constant\n    jl_typename_type-&gt;types = jl_svec(13,\
    \ jl_symbol_type, jl_any_type /*jl_module_type*/,\n                          \
    \                ^~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    </code></pre>\n<p>This is the compiler's fault, which is supposed to be able to\
    \ handle this, but you can just\ndelete the assertions at lines\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446</a>.</p>\n\
    <p>If you're lucky enough, with all these changes, you may be able to build <code>usr/bin/julia</code>.\n\
    Unfortunately, last time I tried, run this executable causes a segmentation fault\
    \ in\n<code>dl_init</code>:</p>\n<pre><code>(gdb) run\nStarting program: /vol0003/ra000019/a04463/repo/julia/julia\
    \ \nMissing separate debuginfos, use: yum debuginfo-install glibc-2.28-151.el8.aarch64\n\
    [Thread debugging using libthread_db enabled]\nUsing host libthread_db library\
    \ \"/lib64/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation\
    \ fault.\n0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\n\
    Missing separate debuginfos, use: yum debuginfo-install FJSVxoslibmpg-2.0.0-25.14.1.el8.aarch64\
    \ elfutils-libelf-0.182-3.el8.aarch64\n(gdb) bt\n#0  0x000040000000def4 in _dl_init\
    \ () from /lib/ld-linux-aarch64.so.1\n#1  0x000040000020adb0 in _dl_catch_exception\
    \ () from /lib64/libc.so.6\n#2  0x00004000000125e4 in dl_open_worker () from /lib/ld-linux-aarch64.so.1\n\
    #3  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#4  0x0000400000011aa8\
    \ in _dl_open () from /lib/ld-linux-aarch64.so.1\n#5  0x0000400000091094 in dlopen_doit\
    \ () from /lib64/libdl.so.2\n#6  0x000040000020ad54 in _dl_catch_exception ()\
    \ from /lib64/libc.so.6\n#7  0x000040000020ae20 in _dl_catch_error () from /lib64/libc.so.6\n\
    #8  0x00004000000917f0 in _dlerror_run () from /lib64/libdl.so.2\n#9  0x0000400000091134\
    \ in dlopen@@GLIBC_2.17 () from /lib64/libdl.so.2\n#10 0x0000400000291f34 in load_library\
    \ (rel_path=0x400001e900c6 &lt;dep_libs+30&gt; \"libjulia-internal.so.1\", src_dir=&lt;optimized\
    \ out&gt;, err=1) at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:65\n\
    #11 0x0000400000291c78 in jl_load_libjulia_internal () at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:200\n\
    #12 0x000040000000de04 in call_init.part () from /lib/ld-linux-aarch64.so.1\n\
    #13 0x000040000000df08 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#14 0x0000400000001044\
    \ in _dl_start_user () from /lib/ld-linux-aarch64.so.1\nBacktrace stopped: previous\
    \ frame identical to this frame (corrupt stack?)\n</code></pre>\n"
  stargazers_count: 3
  subscribers_count: 2
  topics: []
  updated_at: 1664409856.0
goma/goma:
  data_format: 2
  description: A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport
  filenames:
  - spack.yaml
  full_name: goma/goma
  latest_release: v7.3.0
  readme: '<h1><a id="user-content-goma" class="anchor" aria-hidden="true" href="#goma"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Goma</h1>

    <p>A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport</p>

    <p>For more information see the <a href="https://www.gomafem.com" rel="nofollow">Goma
    website</a></p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Most of the documentation can be found at <a href="https://www.gomafem.com/documentation.html"
    rel="nofollow">https://www.gomafem.com/documentation.html</a></p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>See <a href="LICENSE">LICENSE</a> file. Some cmake modules under <code>cmake/</code>
    were modified from the Eigen library

    and are noted at the top of the cmake file.</p>

    <h2><a id="user-content-major-changes" class="anchor" aria-hidden="true" href="#major-changes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Major Changes</h2>

    <p>See <a href="CHANGES.md">CHANGES.md</a></p>

    <h2><a id="user-content-build-instructions" class="anchor" aria-hidden="true"
    href="#build-instructions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Instructions</h2>

    <p>See <a href="BUILD.md">BUILD.md</a></p>

    <h2><a id="user-content-spack-package" class="anchor" aria-hidden="true" href="#spack-package"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack package</h2>

    <p>The Spack package manager <a href="https://spack.io/" rel="nofollow">https://spack.io</a>
    can be used to install

    Goma and all of Goma''s third party libraries</p>

    <p>Currently available on the <code>develop</code> branch of spack.</p>

    <p>Example for a bash-like shell:</p>

    <pre><code>git clone https://github.com/spack/spack.git

    . spack/share/spack/setup-env.sh

    spack install goma

    </code></pre>

    <p>For more information on build options see:</p>

    <pre><code>spack info goma

    </code></pre>

    <p>For more information on using spack see the <a href="https://spack.readthedocs.io/en/latest/"
    rel="nofollow">spack documentation</a>.</p>

    <h2><a id="user-content-third-party-libraries" class="anchor" aria-hidden="true"
    href="#third-party-libraries"><span aria-hidden="true" class="octicon octicon-link"></span></a>Third
    party libraries</h2>

    <ul>

    <li>Metis 5.1.0 (Optional)</li>

    <li>SEACAS 2022-01-27 (Required: Exodus and Aprepro)</li>

    <li>BLAS/LAPACK (Configured through Trilinos)</li>

    <li>Trilinos matrix solvers 13.0.1 and up (Required: AztecOO, Amesos, Epetra,
    TPL LAPACK; Optional: Stratimikos [with Teko, Ifpack, Belos, Tpetra])</li>

    <li>PETSc matrix solvers (KSP, PC)</li>

    <li>MUMPS 5.4.0 (through Trilinos or PETSc only)</li>

    <li>Superlu_dist 7.2.0 (through Trilinos or PETSc only, Trilinos requires parmetis
    build)</li>

    <li>UMFPACK, SuiteSparse 5.10.1 (Optional)</li>

    <li>ARPACK/arpack-ng 3.8.0 (Optional)</li>

    <li>sparse 1.4b (Optional)</li>

    <li>Catch2 (Optional testing)</li>

    </ul>

    <h3><a id="user-content-run-the-tutorial" class="anchor" aria-hidden="true" href="#run-the-tutorial"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run the tutorial</h3>

    <p>To get started with Goma, use the following:</p>

    <ul>

    <li><a href="https://docs.gomafem.com/files/goma-beginners-tutorial.pdf" rel="nofollow">Tutorial
    instructions</a></li>

    <li><a href="https://docs.gomafem.com/files/goma_beginners_tutorial.tar.gz" rel="nofollow">Tutorial
    files tarball</a></li>

    </ul>

    '
  stargazers_count: 87
  subscribers_count: 24
  topics:
  - finite-elements
  - finite-element-analysis
  - simulation
  - parallel
  - multiphysics
  - fem
  - snl-applications
  updated_at: 1667083320.0
gyselax/gyselalibxx:
  data_format: 2
  description: Gyselalib++ is a collection of C++ components for writing gyrokinetic
    semi-lagrangian codes and similar
  filenames:
  - spack.yaml
  full_name: gyselax/gyselalibxx
  latest_release: null
  readme: '<h1><a id="user-content-gyselalib" class="anchor" aria-hidden="true" href="#gyselalib"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Gyselalib++</h1>

    <p>Gyselalib++ is a collection of C++ components for writing gyrokinetic semi-lagrangian
    codes and

    similar as well as a collection of such codes.</p>

    <h2><a id="user-content-compilation" class="anchor" aria-hidden="true" href="#compilation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h2>

    <p>to compile voice++:</p>

    <pre><code>git clone --recurse-submodules git@gitlab.maisondelasimulation.fr:gysela-developpers/voicexx.git

    cd voicexx

    mkdir build

    cd build

    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-Wall -Wno-sign-compare" ..

    make

    </code></pre>

    <h2><a id="user-content-execution" class="anchor" aria-hidden="true" href="#execution"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Execution</h2>

    <p>to run the tests:</p>

    <pre><code>ctest --output-on-failure

    </code></pre>

    <p>Then, just have a look at <code>tests/landau/growthrate_t0.0to45.0.png</code>:</p>

    <p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/b767f6df1712f338f85a7b0b813f7452888524845e8a67bf6223a02a8ca6dc83/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f67726f777468726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"><img
    src="https://camo.githubusercontent.com/b767f6df1712f338f85a7b0b813f7452888524845e8a67bf6223a02a8ca6dc83/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f67726f777468726174655f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/growthrate_t0.0to45.0.png" title="Landau damping rate" data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/growthrate_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width: 100%;"></a></p>

    <p>and <code>tests/landau/frequency_t0.0to45.0.png</code>:</p>

    <p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"><img
    src="https://camo.githubusercontent.com/4aa67726f68146816ee08dc5994ec66f3ac47f1de0f4ef1693d513c69ff71aee/68747470733a2f2f6769746c61622e6d6169736f6e64656c6173696d756c6174696f6e2e66722f677973656c612d646576656c6f70706572732f766f69636578782f2d2f6a6f62732f6172746966616374732f6d61696e2f7261772f6275696c642f74657374732f6c616e6461752f6666742f6672657175656e63795f74302e30746f34352e302e706e673f6a6f623d636d616b655f74657374735f52656c65617365"
    alt="tests/landau/fft/frequency_t0.0to45.0.png" title="Landau damping frequency"
    data-canonical-src="https://gitlab.maisondelasimulation.fr/gysela-developpers/voicexx/-/jobs/artifacts/main/raw/build/tests/landau/fft/frequency_t0.0to45.0.png?job=cmake_tests_Release"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>To install dependencies through spack, first follow the the 3 first steps of

    <a href="https://github.com/pdidev/spack">https://github.com/pdidev/spack</a></p>

    <p>Then execute the following:</p>

    <div class="highlight highlight-source-shell"><pre>spack env create voice spack.yaml

    spack env activate voice

    spack concretize --reuse

    spack install</pre></div>

    <p>For example, you can find a Dockerfile installing these dependencies on ubuntu
    in

    <code>voicexx_env/Dockerfile</code>.</p>

    '
  stargazers_count: 5
  subscribers_count: 1
  topics:
  - hpc
  - numerical-simulation
  - gyrokinetic
  - poisson-solver
  - vlasov-solver
  - plasma-physics
  - ddc
  updated_at: 1667829261.0
haampie/spack-intermediate-gcc-example:
  data_format: 2
  description: null
  filenames:
  - gcc-2/spack.yaml
  - gcc-1/spack.yaml
  full_name: haampie/spack-intermediate-gcc-example
  latest_release: null
  readme: '<h1><a id="user-content-simpler-example-of-dependencies-across-spack-environments"
    class="anchor" aria-hidden="true" href="#simpler-example-of-dependencies-across-spack-environments"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Simple(r) example of
    dependencies across spack environments</h1>

    <p>Run</p>

    <pre><code>make -j$(nproc)

    </code></pre>

    <p>to build a compiler in <code>./store-1</code> using system compiler, and another
    compiler

    in <code>./store-2</code> using the compiler of <code>./store-1</code>.</p>

    <p>This is useful if the system compiler can''t directly build the latest GCC.</p>

    <pre><code>make clean

    </code></pre>

    <p>removes all intermediate files, but does not remove stores.</p>

    <p>This <code>Makefile</code> is supposed to be somewhat human readable.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1668211431.0
hariharan-devarajan/brahma:
  data_format: 2
  description: Interceptor library for I/O calls using Gotcha
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/brahma
  latest_release: null
  readme: '<h1><a id="user-content-brahma" class="anchor" aria-hidden="true" href="#brahma"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Brahma</h1>

    <p>Interceptor library for I/O calls using Gotcha</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1659995517.0
hariharan-devarajan/tailorfs:
  data_format: 2
  description: null
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/tailorfs
  latest_release: null
  readme: ''
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1663026017.0
hepnos/HEPnOS:
  data_format: 2
  description: HEPnOS is a distributed object store for high energy physics applications,
    developed at Argonne National Laboratory.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS
  latest_release: v0.7.1
  readme: '<h1><a id="user-content-hepnos" class="anchor" aria-hidden="true" href="#hepnos"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS</h1>

    <p>HEPnOS is the <em>High-Energy Physics''s new Object Store</em>, a distributed
    storage

    system specially designed for HEP experiments and workflows for the FermiLab.

    HEPnOS relies on libraries developed at Argonne National Laboratory within the

    context of the Mochi project (ANL, CMU, LANL, HDF Group).</p>

    <p>For information on copyright and licensing, see the COPYRIGHT file.

    For information on how to use, see the <a href="https://xgitlab.cels.anl.gov/sds/HEPnOS/wikis/home"
    rel="nofollow">wiki</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641296454.0
hepnos/HEPnOS-ICARUS-Benchmark:
  data_format: 2
  description: A HEPnOS benchmark aimed at investigating performance issues with the
    ICARUS application access pattern.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-ICARUS-Benchmark
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1659444215.0
hepnos/HEPnOS-Wizard:
  data_format: 2
  description: Python utilities to generate HEPnOS configurations
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-Wizard
  latest_release: v0.0.2
  readme: '<h1><a id="user-content-hepnos-wizard" class="anchor" aria-hidden="true"
    href="#hepnos-wizard"><span aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS-Wizard</h1>

    <p>This package contains scripts to help setup valid configurations

    for the HEPnOS storage service.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641579766.0
hpc/mpifileutils:
  data_format: 2
  description: File utilities designed for scalability and performance.
  filenames:
  - spack.yaml
  full_name: hpc/mpifileutils
  latest_release: v0.11.1
  readme: '<h1><a id="user-content-mpifileutils" class="anchor" aria-hidden="true"
    href="#mpifileutils"><span aria-hidden="true" class="octicon octicon-link"></span></a>mpiFileUtils</h1>

    <p>mpiFileUtils provides both a library called <a href="src/common/README.md">libmfu</a>
    and a suite of MPI-based tools to manage large datasets, which may vary from large
    directory trees to large files. High-performance computing users often generate
    large datasets with parallel applications that run with many processes (millions
    in some cases). However those users are then stuck with single-process tools like
    cp and rm to manage their datasets. This suite provides MPI-based tools to handle
    typical jobs like copy, remove, and compare for such datasets, providing speedups
    of up to 20-30x.  It also provides a library that simplifies the creation of new
    tools or can be used in applications.</p>

    <p>Documentation is available on <a href="http://mpifileutils.readthedocs.io"
    rel="nofollow">ReadTheDocs</a>.</p>

    <h2><a id="user-content-daos-support" class="anchor" aria-hidden="true" href="#daos-support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>DAOS Support</h2>

    <p>mpiFileUtils supports a DAOS backend for dcp, dsync, and dcmp. Custom serialization
    and deserialization for DAOS containers to and from a POSIX filesystem is provided
    with daos-serialize and daos-deserialize. Details and usage examples are provided
    in <a href="DAOS-Support.md">DAOS Support</a>.</p>

    <h2><a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributors</h2>

    <p>We welcome contributions to the project.  For details on how to help, see our
    <a href="CONTRIBUTING.md">Contributor Guide</a></p>

    <h3><a id="user-content-copyrights" class="anchor" aria-hidden="true" href="#copyrights"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Copyrights</h3>

    <p>Copyright (c) 2013-2015, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory

    CODE-673838</p>

    <p>Copyright (c) 2006-2007,2011-2015, Los Alamos National Security, LLC.

    (LA-CC-06-077, LA-CC-10-066, LA-CC-14-046)</p>

    <p>Copyright (2013-2015) UT-Battelle, LLC under Contract No.

    DE-AC05-00OR22725 with the Department of Energy.</p>

    <p>Copyright (c) 2015, DataDirect Networks, Inc.</p>

    <p>All rights reserved.</p>

    <h2><a id="user-content-build-status" class="anchor" aria-hidden="true" href="#build-status"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Status</h2>

    <p>The current status of the mpiFileUtils master branch is <a href="https://travis-ci.org/hpc/mpifileutils"
    rel="nofollow"><img src="https://camo.githubusercontent.com/76717f664d99534173ac7e9fb8e904b0e4bd14fbd51ac6969a88de2e6e86a94f/68747470733a2f2f7472617669732d63692e6f72672f6870632f6d706966696c657574696c732e706e673f6272616e63683d6d6173746572"
    alt="Build Status" data-canonical-src="https://travis-ci.org/hpc/mpifileutils.png?branch=master"
    style="max-width: 100%;"></a>.</p>

    '
  stargazers_count: 130
  subscribers_count: 25
  topics: []
  updated_at: 1663748606.0
iarspider/cms-spack-repo:
  data_format: 2
  description: null
  filenames:
  - environments/CMSSW_12_6_X/spack.yaml
  full_name: iarspider/cms-spack-repo
  latest_release: null
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1638894331.0
jedwards4b/spackenvironments:
  data_format: 2
  description: my spack environments for software builds
  filenames:
  - paralleliobld/spack.yaml
  - esmfserialbld/spack.yaml
  full_name: jedwards4b/spackenvironments
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664981968.0
jeffersonscientific/seissol_compile:
  data_format: 2
  description: Compile (and similar) script for SeisSol
  filenames:
  - ss_spack_env_template.yaml
  full_name: jeffersonscientific/seissol_compile
  latest_release: null
  readme: '<h1><a id="user-content-seissol_compile" class="anchor" aria-hidden="true"
    href="#seissol_compile"><span aria-hidden="true" class="octicon octicon-link"></span></a>seissol_compile</h1>

    <p>Compile (and similar) script for SeisSol</p>

    <h1></h1>

    <p>To date, these scripts can be used to install SeisSol on Stanford Research
    Computing''s Sherlock HPC. The <code>compile_seissol_spack.sh</code> script primarily
    uses a <code>spack</code> built environment, and so can be adapted to another
    HPC relatively easily.</p>

    <p>The <code>compile_seissol_sherlock.sh</code> script might be refrenced as a
    template -- the idea being to use pre-built SW modules to build SeisSol, but it
    ultimately crashes and burns prety spetacularly. One issue is that the various
    components may have differend dependencies. Namely, some packages are built from
    a <code>gcc/10.1.0</code> toolchain and another from <code>gcc/12.1.0</code>.</p>

    <p>Files:</p>

    <ul>

    <li>

    <code>build_spack_env.sh</code>: a generic batchable bash script to build a spack
    environment.</li>

    <li>

    <code>ss_env.yaml</code>: Should be the einvironment file we use to define the
    <code>seissol</code> spack environment. Note that the environment includes some
    external package definitions and Sherlock''s built in <code>gcc</code> compilers,
    including the primary <code>gcc@12.1.0</code>. These will need to be modified
    to deploy on a different HPC. Compilers can be built natively in Spack, then automagically
    discovered and added, but ultimately it will still likely be neessary to modify
    their definition in the environment file.</li>

    <li>

    <code>compile_seissol_spack.sh</code>: Working (on Sherlock HPC) compile script.
    will build all the non-Spack components</li>

    <li>

    <code>compile_seissol_cees_sherlock</code>: An older compile script that attempts
    to use Sherlock''s standard SW to compile. It ultimately crashes and burns, but
    might be referenced as a template.</li>

    <li>

    <code>install_ss_spack.sh</code>: An early template to build the Spack environment
    from scratch, including building, and <code>find</code>ing compilers in Spack.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666893798.0
jkbk2004/FV3-vis:
  data_format: 2
  description: null
  filenames:
  - upp/ci/spack.yaml
  full_name: jkbk2004/FV3-vis
  latest_release: null
  readme: '<h1><a id="user-content-fv3atm" class="anchor" aria-hidden="true" href="#fv3atm"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>fv3atm</h1>

    <p>This repository contains a driver and key subcomponents of the

    atmospheric component of the NOAA''s <a href="https://ufscommunity.org/" rel="nofollow">Unified
    Forecast System

    (UFS)</a> weather model.</p>

    <p>The subcomponents include:</p>

    <ul>

    <li>The Finite-Volume Cubed-Sphere (FV3) dynamical core, originally

    from the <a href="https://www.gfdl.noaa.gov/" rel="nofollow">Geophysical Fluid
    Dynamics

    Laboratory</a>.</li>

    <li>The Common Community Physics Package (CCPP) supported by the

    <a href="https://dtcenter.org/community-code/common-community-physics-package-ccpp"
    rel="nofollow">Developmental Testbed Center

    (DTC)</a>,

    including:

    <ul>

    <li>

    <a href="https://github.com/NCAR/ccpp-framework">CCPP Framework</a>.</li>

    <li><a href="https://github.com/NCAR/ccpp-physics">CCPP Physics</a></li>

    </ul>

    </li>

    <li>wrapper code to call <a href="https://stochastic-physics.readthedocs.io/en/latest/"
    rel="nofollow">UFS stochastic

    physics</a>

    </li>

    <li>The io code handles netCDF I/O.</li>

    <li>The cpl coupler code connects the different components and allows

    them to communicate.</li>

    </ul>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This package requires the following

    <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> packages:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    </ul>

    <p>If the INLINE_POST cmake variable is set, the upp library will be

    needed:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/EMC_post">Unified Post Processing Library</a></li>

    </ul>

    <p>This package also requires the following external packages:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c Library</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran Library</a></li>

    <li><a href="https://github.com/esmf-org/esmf">ESMF</a></li>

    <li><a href="https://github.com/NOAA-GFDL/FMS">GFDL''s Flexible Modeling System</a></li>

    </ul>

    <h2><a id="user-content-obtaining-fv3atm" class="anchor" aria-hidden="true" href="#obtaining-fv3atm"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining fv3atm</h2>

    <p>To obtain fv3atm, clone the git repository, and update the submodules:</p>

    <pre><code>git clone https://github.com/NOAA-EMC/fv3atm.git

    cd fv3atm

    git submodule update --init --recursive

    </code></pre>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1660597003.0
jkbk2004/src:
  data_format: 2
  description: null
  filenames:
  - src/UPP/ci/spack.yaml
  - src/ufs-weather-model/WW3/model/ci/spack.yaml
  full_name: jkbk2004/src
  latest_release: null
  readme: "<h1><a id=\"user-content-ufs-short-range-weather-application\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#ufs-short-range-weather-application\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UFS Short-Range\
    \ Weather Application</h1>\n<p>The Unified Forecast System (UFS) is a community-based,\
    \ coupled, comprehensive Earth modeling system. It is designed to be the source\
    \ system for NOAA\u2019s operational numerical weather prediction applications\
    \ while enabling research, development, and contribution opportunities for the\
    \ broader weather enterprise. For more information about the UFS, visit the UFS\
    \ Portal at <a href=\"https://ufscommunity.org/\" rel=\"nofollow\">https://ufscommunity.org/</a>.</p>\n\
    <p>The UFS includes multiple applications (see a complete list at <a href=\"https://ufscommunity.org/science/aboutapps/\"\
    \ rel=\"nofollow\">https://ufscommunity.org/science/aboutapps/</a>) that support\
    \ different forecast durations and spatial domains. This documentation describes\
    \ the development branch of the UFS Short-Range Weather (SRW) Application, which\
    \ targets predictions of atmospheric behavior on a limited spatial domain and\
    \ on time scales from minutes to several days. The development branch of the application\
    \ is continually evolving as the system undergoes open development. The latest\
    \ SRW App release (v2.0.0) represents a snapshot of this continuously evolving\
    \ system.</p>\n<p>The UFS SRW App User's Guide associated with the development\
    \ branch is at: <a href=\"https://ufs-srweather-app.readthedocs.io/en/develop/\"\
    \ rel=\"nofollow\">https://ufs-srweather-app.readthedocs.io/en/develop/</a>, while\
    \ the guide specific to the SRW App v2.0.0 release can be found at: <a href=\"\
    https://ufs-srweather-app.readthedocs.io/en/release-public-v2/\" rel=\"nofollow\"\
    >https://ufs-srweather-app.readthedocs.io/en/release-public-v2/</a>. The repository\
    \ is at: <a href=\"https://github.com/ufs-community/ufs-srweather-app\">https://github.com/ufs-community/ufs-srweather-app</a>.</p>\n\
    <p>For instructions on how to clone the repository, build the code, and run the\
    \ workflow, see:\n<a href=\"https://github.com/ufs-community/ufs-srweather-app/wiki/Getting-Started\"\
    >https://github.com/ufs-community/ufs-srweather-app/wiki/Getting-Started</a></p>\n\
    <p>UFS Development Team. (2022, June 23). Unified Forecast System (UFS) Short-Range\
    \ Weather (SRW) Application (Version v2.0.0). Zenodo. <a href=\"https://doi.org/10.5281/zenodo.6505854\"\
    \ rel=\"nofollow\">https://doi.org/10.5281/zenodo.6505854</a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1661692471.0
jkbk2004/ww3-vis:
  data_format: 2
  description: null
  filenames:
  - model/ci/spack.yaml
  full_name: jkbk2004/ww3-vis
  latest_release: null
  readme: "<h1><a id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>The WAVEWATCH III Framework</h1>\n\
    <p>WAVEWATCH III<sup>\xAE</sup>  is a community wave modeling framework that includes\
    \ the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.</p>\n\
    <h2><a id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#general-features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>General Features</h2>\n<p>WAVEWATCH III<sup>\xAE</sup> solves the\
    \ random phase spectral action density\nbalance equation for wavenumber-direction\
    \ spectra. The model includes options\nfor shallow-water (surf zone) applications,\
    \ as well as wetting and drying of\ngrid points. Propagation of a wave spectrum\
    \ can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular)\
    \ grids. See\n<a href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\">About\
    \ WW3</a> for a\ndetailed description of WAVEWATCH III<sup>\xAE</sup> .</p>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The WAVEWATCH III<sup>\xAE</sup>  framework\
    \ package has two parts that need to be combined so\nall runs smoothly: the GitHub\
    \ repo itself, and a binary data file bundle that\nneeds to be obtained from our\
    \ ftp site. Steps to successfully acquire and install\nthe framework are outlined\
    \ in our <a href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\">Quick Start</a>\n\
    guide.</p>\n<h2><a id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#disclaimer\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Disclaimer</h2>\n<p>The United States Department of Commerce (DOC)\
    \ GitHub project code is provided\non an 'as is' basis and the user assumes responsibility\
    \ for its use. DOC has\nrelinquished control of the information and no longer\
    \ has responsibility to\nprotect the integrity, confidentiality, or availability\
    \ of the information. Any\nclaims against the Department of Commerce stemming\
    \ from the use of its GitHub\nproject will be governed by all applicable Federal\
    \ law. Any reference to\nspecific commercial products, processes, or services\
    \ by service mark,\ntrademark, manufacturer, or otherwise, does not constitute\
    \ or imply their\nendorsement, recommendation or favoring by the Department of\
    \ Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of\
    \ a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial\
    \ product\nor activity by DOC or the United States Government.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1661796370.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - nersc/perlmutter/perlmutter.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - configs/ellis/utilities/spack.yaml
  - configs/ellis/compilers/spack.yaml
  - configs/ellis/software/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" aria-hidden="true" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1666717629.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-release/spack.yaml
  - environments/key4hep-desy-release/spack.yaml
  - environments/key4hep-nightlies/spack.yaml
  - environments/key4hep-ci/spack.yaml
  - environments/key4hep-nightlies-rootmod/spack.yaml
  - environments/key4hep-nightlies-clang/spack.yaml
  - environments/key4hep-release-user/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    href="#repository-contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    href="#central-installations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 9
  subscribers_count: 8
  topics: []
  updated_at: 1664642827.0
lanl/CELLAR:
  data_format: 2
  description: The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based
    adaptive mesh refinement data structures and execution for parallel computing
    architectures.
  filenames:
  - spack/darwin-power9/spack.yaml
  - spack/default/spack.yaml
  - spack/ci/spack.yaml
  - spack/agaspar/spack.yaml
  - spack/snow/spack.yaml
  full_name: lanl/CELLAR
  latest_release: null
  readme: '<h1><a id="user-content-cellar-----eap-core" class="anchor" aria-hidden="true"
    href="#cellar-----eap-core"><span aria-hidden="true" class="octicon octicon-link"></span></a>CELLAR  -  EAP
    Core</h1>

    <p>CELLAR is a C++ project that forms the foundation of cell based AMR for applications</p>

    <p>It provides the following:</p>

    <ul>

    <li>AMR Mesh Datastructure</li>

    <li>AMR Mesh Reconstruction</li>

    <li>Communication Patterns</li>

    <li>C++ Error Handling and Tracing</li>

    <li>Performance Monitoring</li>

    <li>C++/Fortran Interop</li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>The easiest way to install dependencies is using <a href="https://spack.io"
    rel="nofollow">Spack</a>.

    After

    <a href="https://spack.readthedocs.io/en/latest/getting_started.html" rel="nofollow">installing
    Spack</a>,

    you can start build dependencies.</p>

    <p>The following instructions assume that you have Spack 0.13 or newer. You can
    check your

    Spack version like so:</p>

    <pre><code>$ spack --version

    0.13.0

    </code></pre>

    <p>First, add <a href="https://github.com/lanl/cellar-spack">lanl/cellar-spack</a>

    to your list of spack repos.</p>

    <p>Once you have the <code>lanl/cellar-spack</code> installed, then you can install
    all

    dependencies using

    <a href="https://spack.readthedocs.io/en/latest/tutorial_environments.html#" rel="nofollow">Spack
    environments</a>.

    You''ll need to use a modern-ish C++ compiler that supports C++14:</p>

    <pre><code>$ module load gcc/9.3.0

    $ spack compiler find

    $ cd path/to/eap-core

    </code></pre>

    <p>Then issue the following commands. This will build all of eap-core''s dependencies.:</p>

    <pre><code>$ spack env create -d spack/default

    $ spack env activate -d $PWD/spack/default

    $ spack install

    </code></pre>

    <p>Any time you open a new shell, you''ll need to re-activate the Spack environment:</p>

    <pre><code>$ spack env activate -d $PWD/spack/default

    </code></pre>

    <p>Now you''re ready to build eap-core. First configure the project using CMake:</p>

    <pre><code>mkdir build &amp;&amp; cd build

    cmake ..

    </code></pre>

    <p>And then build:</p>

    <pre><code>make -j

    </code></pre>

    <p>For snow, substitute in spack/snow in the above instructions in place of spack/default.
    If you need

    to change the environment use "spack env deactivate".</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Code contributors should read the <a href="DEVELOPERS.md">Developers Guide</a>
    prior to

    sending a pull request.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1667253429.0
lanl/cellar-gtest-mpi:
  data_format: 2
  description: null
  filenames:
  - spack/agaspar/spack.yaml
  full_name: lanl/cellar-gtest-mpi
  latest_release: null
  readme: "<h1><a id=\"user-content-google-test-for-mpi-gtest-mpi\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#google-test-for-mpi-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Google Test for MPI (gtest-mpi)</h1>\n\
    <p>This is a support library that helps users write Google Test unit tests that\n\
    rely on MPI.</p>\n<h2><a id=\"user-content-features\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Features</h2>\n<ul>\n<li>Serialized and rank-tagged Google Test output.</li>\n\
    <li>Rank-tagged failure reports.</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> is the easiest way\
    \ to install gtest-mpi. The gtest-mpi\npackage is available in\n<a href=\"https://gitlab.lanl.gov/agaspar/spack-repo\"\
    \ rel=\"nofollow\">agaspar/spack-repo</a>. Follow the\nREADME there to use that\
    \ spack repo. Once the agaspar-spack-repo repo is\ninstalled, installing gtest-mpi\
    \ is as simple as running:</p>\n<pre><code>spack install gtest-mpi\n</code></pre>\n\
    <p>When you want to use gtest-mpi, run <code>spack load gtest-mpi</code> to load\
    \ it into your\ncurrent environment.</p>\n<h3><a id=\"user-content-cmake\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>CMake</h3>\n<p>If you don't want to use spack,\
    \ you can install gtest-mpi directly using CMake.\ngtest-mpi uses CMake, so all\
    \ of your knowledge of CMake applies. gtest-mpi\nhas a dependency on Google Test,\
    \ and uses\n<a href=\"https://cmake.org/cmake/help/latest/module/FindGTest.html\"\
    \ rel=\"nofollow\">FindGTest.cmake</a> to\nfind it. Therefore, in order to install\
    \ gtest-mpi, you must first have a\nworking installation of <a href=\"https://github.com/google/googletest/\"\
    >Google Test</a>.</p>\n<p>Once you've installed Google Test, building and installing\
    \ gtest-mpi is just\nlike any other modern CMake package.</p>\n<pre><code>git\
    \ clone git@gitlab.lanl.gov:agaspar/gtest-mpi.git\ncd gtest-mpi\nmkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake install\n</code></pre>\n<h2><a id=\"user-content-using-gtest-mpi\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using gtest-mpi</h2>\n<h3><a\
    \ id=\"user-content-with-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #with-cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>With\
    \ CMake</h3>\n<p>If you don't need any custom startup logic, using gtest-mpi in\
    \ your own CMake\nproject is simple:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">find_package</span>(gtest-mpi 0.1 <span class=\"pl-k\"\
    >REQUIRED</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> gtest-mpi-main\
    \ provides a main function for you</span>\n<span class=\"pl-c1\">add_executable</span>(my-test\
    \ mytest.cpp)\n<span class=\"pl-c1\">target_link_libraries</span>(my-test gtest-mpi-main)</pre></div>\n\
    <p>Then you can write a Google Test just like you normally would:</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> mytest.cpp</span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-en\"\
    >TEST</span>(GTestMPI, Basic) {\n    <span class=\"pl-k\">int</span> rank;\n \
    \   <span class=\"pl-c1\">MPI_Comm_rank</span>(MPI_COMM_WORLD, &amp;rank);\n\n\
    \    <span class=\"pl-k\">bool</span> is_root = rank == <span class=\"pl-c1\"\
    >0</span>;\n\n    <span class=\"pl-k\">bool</span> is_anyone_root = <span class=\"\
    pl-c1\">false</span>;\n    <span class=\"pl-c1\">MPI_Allreduce</span>(\n     \
    \   &amp;is_root, &amp;is_anyone_root, <span class=\"pl-c1\">1</span>, MPI_CXX_BOOL,\
    \ MPI_LOR, MPI_COMM_WORLD);\n\n    <span class=\"pl-c1\">ASSERT_TRUE</span>(is_anyone_root);\n\
    }</pre></div>\n<p>If you need to write your own main function, that's also fairly\
    \ straighforward.\nIn your CMake project, you link against <code>gtest-mpi-lib</code>\
    \ instead of\n<code>gtest-mpi-main</code>. Then you must provide your own main\
    \ function:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> main.cpp</span>\n#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest-mpi/init.hpp<span\
    \ class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"\
    pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\
    \n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span> **argv) {\n    <span\
    \ class=\"pl-c1\">testing::InitGoogleTest</span>(&amp;argc, argv);\n    <span\
    \ class=\"pl-c1\">MPI_Init</span>(&amp;argc, &amp;argv);\n    <span class=\"pl-c1\"\
    >gtest_mpi::init</span>(&amp;argc, &amp;argv);\n\n    <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Your custom init logic goes here</span>\n\n    <span\
    \ class=\"pl-k\">int</span> exit_code = <span class=\"pl-c1\">RUN_ALL_TESTS</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Your custom finalize\
    \ logic goes here</span>\n\n    <span class=\"pl-c1\">gtest_mpi::finalize</span>();\n\
    \    <span class=\"pl-c1\">MPI_Finalize</span>();\n\n    <span class=\"pl-k\"\
    >return</span> exit_code;\n}</pre></div>\n<h3><a id=\"user-content-without-cmake\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#without-cmake\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Without CMake</h3>\n<p>CMake\
    \ is not required to use gtest-mpi, but it is recommended. If you wish to\nuse\
    \ a different build system, then adding <code>-lgtest-mpi-lib</code> and (optionally)\n\
    <code>-lgtest-mpi-main</code> to your link line will work.</p>\n<h2><a id=\"user-content-ctest\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#ctest\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>CTest</h2>\n<p>Here's an example of\
    \ adding a CTest using gtest-mpi to your CMake file:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">enable_testing</span>()\n\
    \n<span class=\"pl-c1\">add_test</span>(\n    <span class=\"pl-k\">NAME</span>\
    \ my-test\n    <span class=\"pl-k\">COMMAND</span>\n        <span class=\"pl-smi\"\
    >${MPIEXEC}</span> <span class=\"pl-smi\">${MPIEXEC_NUMPROC_FLAG}</span> 4 <span\
    \ class=\"pl-smi\">${MPIEXEC_PREFLAGS}</span>\n            $&lt;<span class=\"\
    pl-k\">TARGET_FILE</span>:my-test&gt; <span class=\"pl-smi\">${MPIEXEC_POSTFLAGS}</span>)</pre></div>\n\
    <p>These tests can be run using <code>ctest</code>.</p>\n"
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1668046366.0
laristra/ristra_spackages:
  data_format: 2
  description: 'A mirror of Ristra''s internal gitlab repository. '
  filenames:
  - env/x86_64/flecsi/spack.yaml
  - .gitlab-ci/env/root-build/spack.yaml
  - env/broadwell/flecsi/spack.yaml
  - .gitlab-ci/env/local-build/spack.yaml
  - env/power9le/flecsi/spack.yaml
  - .gitlab-ci/env/dry-run/spack.yaml
  full_name: laristra/ristra_spackages
  latest_release: null
  readme: '<h1><a id="user-content-ristra-spackages" class="anchor" aria-hidden="true"
    href="#ristra-spackages"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ristra
    Spackages</h1>

    <p>This repository contains the custom spackage files for the repos in laristra
    family.</p>

    <h2><a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Basic Usage</h2>

    <p>We assume the user wish to work in the home directory and already have a spack
    instance setup.  The minimum required version of spack is 0.15.2.</p>

    <p>To get the content of this repo</p>

    <pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git

    </code></pre>

    <p>To use the custom spackage files with your spack</p>

    <pre><code>$ spack repo add ristra_spackages/spack-repo

    ==&gt; Added repo with namespace ''lanl_ristra''.


    $ spack repo list

    ==&gt; 2 package repositories.

    lanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo

    builtin            /home/&lt;user&gt;/spack/var/spack/repos/builtin

    </code></pre>

    <p>[Optional]

    To ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code>
    into your spack config folder</p>

    <pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/

    </code></pre>

    <p>Please see the <a href="https://spack.readthedocs.io/en/latest/configuration.html"
    rel="nofollow">Spack documentation</a> for more detailed info.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1649449003.0
lfortran/lfortran:
  data_format: 2
  description: Official main repository for LFortran
  filenames:
  - spack.yaml
  full_name: lfortran/lfortran
  latest_release: null
  readme: "<h1><a id=\"user-content-lfortran\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#lfortran\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>LFortran</h1>\n<p><a href=\"https://lfortran.zulipchat.com/\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>LFortran is a modern open-source (BSD\
    \ licensed) interactive Fortran compiler\nbuilt on top of LLVM. It can execute\
    \ user's code interactively to allow\nexploratory work (much like Python, MATLAB\
    \ or Julia) as well as compile to\nbinaries with the goal to run user's code on\
    \ modern architectures such as\nmulti-core CPUs and GPUs.</p>\n<p>Website: <a\
    \ href=\"https://lfortran.org/\" rel=\"nofollow\">https://lfortran.org/</a></p>\n\
    <p>Try online: <a href=\"https://dev.lfortran.org/\" rel=\"nofollow\">https://dev.lfortran.org/</a></p>\n\
    <h1><a id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Documentation</h1>\n<p>All documentation, installation instructions,\
    \ motivation, design, ... is\navailable at:</p>\n<p><a href=\"https://docs.lfortran.org/\"\
    \ rel=\"nofollow\">https://docs.lfortran.org/</a></p>\n<p>Which is generated using\
    \ the files in the <code>doc</code> directory.</p>\n<h1><a id=\"user-content-development\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Development</h1>\n<p>We welcome\
    \ all contributions.\nThe main development repository is at GitHub:</p>\n<p><a\
    \ href=\"https://github.com/lfortran/lfortran\">https://github.com/lfortran/lfortran</a></p>\n\
    <p>Please send Pull Requests (PRs) and open issues there.</p>\n<p>See the <a href=\"\
    CONTRIBUTING.md\">CONTRIBUTING</a> document for more information.</p>\n<p>Main\
    \ mailinglist:</p>\n<p><a href=\"https://groups.io/g/lfortran\" rel=\"nofollow\"\
    >https://groups.io/g/lfortran</a></p>\n<p>You can also chat with us on Zulip (<a\
    \ href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a>).</p>\n<p>Note: We moved to the above GitHub\
    \ repository from GitLab on July 18, 2022.</p>\n<h1><a id=\"user-content-donations\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#donations\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Donations</h1>\n<p>You can support\
    \ LFortran's development by donating to NumFOCUS or Open\nCollective as well as\
    \ GitHub Sponsors:</p>\n<ul>\n<li><a href=\"https://numfocus.org/donate-to-lfortran\"\
    \ rel=\"nofollow\">https://numfocus.org/donate-to-lfortran</a></li>\n<li><a href=\"\
    https://opencollective.com/lfortran\" rel=\"nofollow\">https://opencollective.com/lfortran</a></li>\n\
    <li><a href=\"https://github.com/sponsors/lfortran\">https://github.com/sponsors/lfortran</a></li>\n\
    </ul>\n<p>All donations will be used strictly to fund LFortran development, by\
    \ supporting\ntasks such as paying developers to implement features, sprints,\
    \ improved\ndocumentation, fixing bugs, etc.</p>\n<p>The donations to LFortran\
    \ are managed by the NumFOCUS foundation. NumFOCUS is a\n501(c)3 non-profit foundation,\
    \ so if you are subject to US Tax law, your\ncontributions will be tax-deductible.</p>\n\
    <p>If you want to discuss another way to fund or help with the development, feel\n\
    free to contact Ond\u0159ej \u010Cert\xEDk (<a href=\"mailto:ondrej@certik.us\"\
    >ondrej@certik.us</a>).</p>\n<h1><a id=\"user-content-star-history\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#star-history\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Star History</h1>\n<p><a href=\"https://star-history.com/#lfortran/lfortran&amp;Date\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7e19634671b985a40376628d5d76d76ef6baf79368e0c4b6a409523464e705b7/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c666f727472616e2f6c666f727472616e26747970653d44617465\"\
    \ alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=lfortran/lfortran&amp;type=Date\"\
    \ style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 453
  subscribers_count: 12
  topics:
  - fortran
  - interactive
  - compiler
  - library
  - repl
  - jupyter
  - jupyter-notebook
  - jupyter-kernels
  updated_at: 1668277751.0
ma595/fenics-csd3-spack:
  data_format: 2
  description: Set up fenics spack on csd3
  filenames:
  - spack-skylake.yaml
  - spack-icelake.yaml
  full_name: ma595/fenics-csd3-spack
  latest_release: null
  readme: '<h1><a id="user-content-fenics-csd3-spack" class="anchor" aria-hidden="true"
    href="#fenics-csd3-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>fenics-csd3-spack</h1>

    <p>Follow instructions in icelake-spack-env.sh</p>

    <p>Or, copy existing <code>spack.yaml</code> files into cloned Spack repo. It
    is necessary to <code>module purge</code> environment first, otherwise the prepend
    path inside <code>spack.yaml</code> will lead to duplications.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667830944.0
mfem/mfem:
  data_format: 2
  description: Lightweight, general, scalable C++ library for finite element methods
  filenames:
  - config/docker/spack.yaml
  full_name: mfem/mfem
  latest_release: v4.5
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed under the terms\
    \ of the BSD-3 license. All new contributions\nmust be made under this license.\
    \ See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> for\n\
    details.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release Number:\
    \ LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 1070
  subscribers_count: 118
  topics:
  - finite-elements
  - high-order
  - high-performance-computing
  - parallel-computing
  - amr
  - computational-science
  - fem
  - scientific-computing
  - hpc
  - math-physics
  - radiuss
  updated_at: 1668256047.0
mochi-hpc-experiments/colza-experiments:
  data_format: 2
  description: Experiments using Colza for In Situ Analysis
  filenames:
  - theta/amr-wind/spack.yaml
  full_name: mochi-hpc-experiments/colza-experiments
  latest_release: ipdps2022
  readme: '<h1><a id="user-content-colza-experiments" class="anchor" aria-hidden="true"
    href="#colza-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Colza
    Experiments</h1>

    <p>This repository contains scripts to reproduce experiments

    related to the Colza elastic in situ analysis framework.

    These experiments were run on the Cori supercomputer.</p>

    <p>Each subfolder contains a README file explaining what the

    experiment in the subfolder does, how to install its

    dependencies, and how to run it.</p>

    <p>The ubuntu folder contains scripts that allow reproducing

    the most experiments on a single Linux workstation or a

    cluster of Linux machines.</p>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1655200495.0
mochi-hpc-experiments/example-yokan-poesie-composition:
  data_format: 2
  description: Example of Mochi service composing Poesie and Yokan via Bedrock
  filenames:
  - spack.yaml
  full_name: mochi-hpc-experiments/example-yokan-poesie-composition
  latest_release: null
  readme: '<h2><a id="user-content-example-yokanpoesie-composition" class="anchor"
    aria-hidden="true" href="#example-yokanpoesie-composition"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Example Yokan/Poesie composition</h2>

    <p>This repository contains an example of a <a href="https://mochi.readthedocs.io/en/latest/bedrock.html"
    rel="nofollow">Bedrock</a>

    configuration that spins up a Yokan provider for key/value storage and a Poesie
    provider for

    embedding a Python interpreter.</p>

    <p>The <em>test.cpp</em> file shows an example of first putting a key/value pair
    into the database

    using the Yokan API, then using the Poesie API to send a python code that retrieves
    said value.</p>

    <h3><a id="user-content-building-the-code" class="anchor" aria-hidden="true" href="#building-the-code"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building the code</h3>

    <p>The <em>spack.yaml</em> file in this repository allows creating a Spack environment
    with the

    required dependencies as follows, from inside the cloned repository (note that
    you must have installed

    <a href="https://github.com/mochi-hpc/mochi-spack-packages">mochi-spack-packages</a>
    as

    instructed <a href="https://mochi.readthedocs.io/en/latest/installing.html#installing-spack-and-the-mochi-repository"
    rel="nofollow">here</a>).</p>

    <pre><code>$ spack env create -d .

    $ spack env activate .

    $ spack install

    </code></pre>

    <p>You can then build the code as follows.</p>

    <pre><code>$ mkdir build

    $ cd build

    $ cmake ..

    $ make

    </code></pre>

    <h3><a id="user-content-running-the-code" class="anchor" aria-hidden="true" href="#running-the-code"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running the code</h3>

    <p>Open two terminals, making sure the Spack environment is activated in both.

    In the first termina, run the Bedrock daemon as follows.</p>

    <pre><code>$ bedrock na+sm -c src/config.json -v trace

    </code></pre>

    <p>Make a note of the address that the Bedrock server is reporting to be running
    on

    (e.g., <code>na+sm://15865-0</code>).</p>

    <p>In the second, run the <code>yokan-poesie-test</code> executable with the address
    as

    command-line argument, as follows.</p>

    <pre><code>$ ./yokan-poesie-test na+sm://15865-0

    </code></pre>

    <p>If everything goes well, the test program will print "some_value" before

    terminating.</p>

    <h3><a id="user-content-step-by-step-explanation" class="anchor" aria-hidden="true"
    href="#step-by-step-explanation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step-by-step
    explanation</h3>

    <p>The <em>config.json</em> file describes how our service should look like on
    one node.

    Our service contains a <a href="https://mochi.readthedocs.io/en/latest/yokan.html"
    rel="nofollow">Yokan</a>

    provider, which is the component that provides key/value storage.

    In the configuration of this component, we add a database called <em>my_kv_store</em>,

    of type <em>map</em>. This type corresponds to an in-memory, ordered map.</p>

    <p>The configuration then lists a Poesie provider, which is the component that
    will

    provide us with an embedded Python interpreter. Its configuration lists

    <em>my_python_vm</em> for this purpose.</p>

    <p>In the configuration of this VM, the <em>preamble</em> entry lets us provide
    some code

    to execute upon initializing the VM (i.e., when the server starts). We take

    advantage of this preamble to import <code>pyyokan_client</code>, the Python binding
    for

    Yokan''s client library, and create the <code>my_kv_store</code> variable of type

    <code>pyyokan_client.Database</code> to be a handle to the database managed by
    Yokan.

    The <code>__mid__</code> and <code>__address__</code> variables are added by Poesie
    automatically

    and respectively represents the Margo instance in use and the process'' own

    address.</p>

    <p>Moving over to the <em>test.c</em> file, the <code>write_with_yokan</code>
    function shows

    an example of using the Yokan C API to look up the database by its name

    to get its id, building a <code>yk_database_handle_t</code> to interact with the
    database,

    then putting "some_value" associated with the key "my_key" into the database.</p>

    <p>The <code>read_with_poesie</code> function uses the Poesie C API to create
    a

    <code>poesie_provider_handle_t</code>, look up the VM id by its name, then

    send over some Python code to be executed on the server.

    The Python code in question uses the <code>my_kv_store</code> variable, initialized

    in the preamble of the VM, to interact with the local database using

    Yokan''s Python API. Here it first gets the length of the value associated

    with "my_key", before actually fetching it into a <code>bytearray</code> buffer.</p>

    <p>The <code>__poesie_output__</code> variable is a special variable that the
    VM will

    lookup after executing the user code. Any object placed in this variable

    will be transformed into a string (using the object''s <code>__str__</code> method),

    before being sent back to the caller in as output. Poesie handles

    execution results this way because <code>return</code> cannot be called outside
    of

    functions. In the present exemple, the content of the key, which is a

    <code>bytearray</code>, is transformed into a unicode string using <code>.decode("utf-8")</code>.</p>

    <p>Note that if an exception is raised from the user code, Poesie will

    ignore the content of <code>__poesie_output__</code> and return the exception

    (converted into a string) as output instead.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1666024613.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - NERSC/Perlmutter/ss10/spack.yaml
  - ANL/ThetaGPU/spack.yaml
  - NERSC/Cori/spack.yaml
  - ANL/Theta/spack.yaml
  - ANL/Cooley/spack.yaml
  - ANL/Polaris/spack.yaml
  - ANL/Bebop/spack.yaml
  - ANL/Polaris/spack-ucx.yaml
  - NERSC/Perlmutter/ss11/spack.yaml
  - ANL/JLSE/spack.yaml
  - ORNL/Summit/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" href="#platform-configurations-for-mochi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Platform configurations for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    href="#contributing-to-this-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1641290694.0
mochi-hpc/mobject:
  data_format: 2
  description: Mobject is a prototype Mochi object storage system based on RADOS
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mobject
  latest_release: v0.6.1
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"mobject_logo.png\"\
    ><img src=\"mobject_logo.png\" alt=\"logo\" style=\"max-width: 100%;\"></a></p>\n\
    <h1><a id=\"user-content-mobject\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #mobject\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mobject</h1>\n\
    <p><a href=\"https://github.com/hyoklee/mobject/actions/workflows/spell.yml\"\
    ><img src=\"https://github.com/hyoklee/mobject/actions/workflows/spell.yml/badge.svg\"\
    \ alt=\"check spelling\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/hyoklee/mobject/actions/workflows/spack.yml\"\
    ><img src=\"https://github.com/hyoklee/mobject/actions/workflows/spack.yml/badge.svg\"\
    \ alt=\"spack mobject\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/hyoklee/mobject/actions/workflows/spack_bedrock.yml\"\
    ><img src=\"https://github.com/hyoklee/mobject/actions/workflows/spack_bedrock.yml/badge.svg\"\
    \ alt=\"spack mobject+bedrock\" style=\"max-width: 100%;\"></a></p>\n<p>Mobject\
    \ is a distributed object storage system\nbuilt using a composition of <a href=\"\
    https://mochi.readthedocs.io\" rel=\"nofollow\">Mochi</a> components:</p>\n<ul>\n\
    <li>\n<a href=\"https://github.com/mochi-hpc/mochi-bake\">mochi-bake</a> (for\
    \ bulk storage)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-bedrock\"\
    >mochi-bedrock</a>\n(for configuration and bootstrapping)</li>\n<li>\n<a href=\"\
    https://github.com/mochi-hpc/mochi-sdskv\">mochi-sdskv</a>\n(for metadata and\
    \ log indexing)</li>\n<li>\n<a href=\"https://github.com/mochi-hpc/mochi-ssg\"\
    >mochi-ssg</a> (for group membership)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"\
    https://mochi.readthedocs.io/en/latest/installing.html#installing-spack-and-the-mochi-repository\"\
    \ rel=\"nofollow\">Install Spack and Mochi Spack Repository</a>.</p>\n<p>Then,\
    \ run the following command to install mobject.</p>\n<pre><code>   spack install\
    \ mobject\n</code></pre>\n<h2><a id=\"user-content-hdf5-and-mobject\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#hdf5-and-mobject\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>HDF5 and Mobject</h2>\n<p><a\
    \ href=\"/include/librados-mobject-store.h\">Mobject API</a> is a subset of the\n\
    <a href=\"https://github.com/ceph/ceph/blob/main/src/include/rados/librados.h\"\
    >RADOS API</a>\nfrom Ceph\u2019s object storage layer.\nTherefore, <a href=\"\
    https://github.com/HDFGroup/vol-rados\">HDF5 RADOS VOL plugin-in</a>\ncan use\
    \ Mobject.</p>\n<h2><a id=\"user-content-faq\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#faq\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>FAQ</h2>\n<p>See <a href=\"doc/FAQ.md\">doc/FAQ.md</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1640785210.0
mochi-hpc/mochi-bedrock:
  data_format: 2
  description: Mochi bootstrapping service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bedrock
  latest_release: v0.5.2
  readme: '<h1><a id="user-content-bedrock" class="anchor" aria-hidden="true" href="#bedrock"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bedrock</h1>

    <p>Bedrock is Mochi''s service bootstrapping mechanism.

    For documentations and tutorials, please see

    <a href="https://mochi.readthedocs.io/en/latest/bedrock.html" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1640527359.0
mochi-hpc/mochi-doc:
  data_format: 2
  description: Documentations and tutorials for Margo, Thallium, Argobots, Mercury,
    and other Mochi libraries.
  filenames:
  - code/spack.yaml
  full_name: mochi-hpc/mochi-doc
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"><img
    src="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"
    alt="build" style="max-width: 100%;"></a></p>

    <h1><a id="user-content-mochi-documentation" class="anchor" aria-hidden="true"
    href="#mochi-documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    documentation</h1>

    <p>This repository contains a Sphinx-based documentation

    for the Mochi libraries: Margo, Thallium, Argobots, Mercury,

    ABT-IO, and SSG, as well as corresponding code examples.</p>

    <h2><a id="user-content-building-the-documentation" class="anchor" aria-hidden="true"
    href="#building-the-documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the documentation</h2>

    <p>To build and/or contribute to this documentation, you must have a Sphinx and

    a few related extensions installed.  These can be installed as follows using

    Python''s <code>pip</code>.</p>

    <pre><code>pip install sphinx

    pip install sphinx_rtd_theme

    pip install sphinx_copybutton

    pip install recommonmark

    pip install breathe

    </code></pre>

    <p>You must also install the <code>doxygen</code> documentation system.  This
    is likely

    available in your platform''s primary package manager.  For example on Ubuntu:</p>

    <pre><code>sudo apt install doxygen

    </code></pre>

    <p>Once you have these dependencies installed, clone this

    repository and cd into it. You can change the documentation

    by editing the files in the source subdirectory (these files

    use the .rst format). You can build the documentation

    using the following command.</p>

    <pre><code>cd docs

    make html

    </code></pre>

    <p>And check the result by opening the <code>build/html/index.html</code> page

    that has been created in the docs directory.</p>

    <h2><a id="user-content-building-the-code-examples" class="anchor" aria-hidden="true"
    href="#building-the-code-examples"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the code examples</h2>

    <p>To build the code, you will need spack and the

    <a href="https://github.com/mochi-hpc/mochi-spack-packages">mochi repo</a> setup.</p>

    <pre><code>cd code

    spack env create mochi-doc-env spack.yaml

    spack env activate mochi-doc-env

    spack install

    mkdir build

    cd build

    cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc

    make

    </code></pre>

    '
  stargazers_count: 3
  subscribers_count: 4
  topics: []
  updated_at: 1646801350.0
mochi-hpc/mochi-margo:
  data_format: 2
  description: Argobots bindings for the Mercury RPC library
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-margo
  latest_release: v0.10
  readme: "<h1><a id=\"user-content-margo\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#margo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    ><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings\
    \ to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\"\
    \ rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\n\
    library optimized for use in HPC environments.  Its native API presents a\ncallback-oriented\
    \ interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\"\
    \ rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n\
    <p>Margo combines Mercury and Argobots to simplify development of distributed\n\
    services.  Mercury operations are presented as conventional blocking\noperations,\
    \ and RPC handlers are presented as sequential threads.  This\nconfiguration enables\
    \ high degree of concurrency while hiding the\ncomplexity associated with asynchronous\
    \ communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends\
    \ callers after issuing a Mercury operation, and\nautomatically resumes them when\
    \ the operation completes.  This allows\nother concurrent user-level threads to\
    \ make progress while Mercury\noperations are in flight without consuming operating\
    \ system threads.\nThe goal of this design is to combine the performance advantages\
    \ of\nMercury's native event-driven execution model with the progamming\nsimplicity\
    \ of a multi-threaded execution model.</p>\n<p>A companion library called abt-io\
    \ provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\"\
    >https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should\
    \ be compatible with any Mercury network\ntransport (NA plugin).  The documentation\
    \ assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury\
    \ for\nsimplicity.  This plugin is only valid for communication between\nprocesses\
    \ on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\"\
    >Using Margo with other Mercury NA\nplugins</a> for information\non other configuration\
    \ options.</p>\n<h2><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing\
    \ the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"\
    nofollow\">https://spack.io/</a>).</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury\
    \  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\"\
    >https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone\
    \ <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n\
    </ul>\n<h3><a id=\"user-content-recommended-mercury-build-options\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#recommended-mercury-build-options\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury build options</h3>\n\
    <ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable\
    \ the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should be compiled\
    \ with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path\
    \ for cases in which a Mercury service is linked into the same\nexecutable as\
    \ the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir\
    \ build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON\
    \ -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install\
    \ \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n\
    <h2><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n\
    <p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install\
    \ \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"\
    -g -Wall\"\n</code></pre>\n<h2><a id=\"user-content-running-examples\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#running-examples\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The\
    \ examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example\
    \ client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]:\
    \ an example RPC definition</li>\n</ul>\n<p>The following example shows how to\
    \ execute them.  Note that when the server starts it will display the address\
    \ that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server\
    \ na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with\
    \ input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val:\
    \ 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client\
    \ na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3]\
    \ running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\n\
    Got response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n\
    <p>The client will issue 4 concurrent RPCs to the server and wait for them to\n\
    complete.</p>\n<h2><a id=\"user-content-running-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#running-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running tests</h2>\n<p><code>make check</code></p>\n<h2><a id=\"user-content-using-margo-with-the-other-na-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-margo-with-the-other-na-plugins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Margo\
    \ with the other NA plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\"\
    \ rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible\
    \ with any Mercury transport and uses the same address\nformat.</p>\n<h2><a id=\"\
    user-content-instrumentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#instrumentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Instrumentation</h2>\n\
    <p>See the <a href=\"doc/instrumentation.md\">Instrumentation documentation</a>\
    \ for\ninformation on how to extract diagnostic instrumentation from Margo.</p>\n\
    <h2><a id=\"user-content-debugging\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #debugging\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Debugging</h2>\n\
    <p>See the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo\
    \ debugging\nfeatures and strategies.</p>\n<h2><a id=\"user-content-design-details\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#design-details\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Design details</h2>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"doc/fig/margo-diagram.png\"><img src=\"\
    doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>Margo provides Argobots-aware wrappers to common Mercury library\
    \ functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The\
    \ wrappers\nhave the same arguments as their native Mercury counterparts except\
    \ that no\ncallback function is specified.  Each function blocks until the operation\n\
    is complete.  The above diagram illustrates a typical control flow.</p>\n<p>Margo\
    \ launches a long-running user-level thread internally to drive\nprogress on Mercury\
    \ and execute Mercury callback functions (labeled\n<code>__margo_progress()</code>\
    \ above).  This thread can be assigned to a\ndedicated Argobots execution stream\
    \ (i.e., an operating system thread)\nto drive network progress with a dedicated\
    \ core.  Otherwise it will be\nautomatically scheduled when the caller's execution\
    \ stream is blocked\nwaiting for network events as shown in the above diagram.</p>\n\
    <p>Argobots eventual constructs are used to suspend and resume user-level\nthreads\
    \ while Mercury operations are in flight.</p>\n<p>Margo allows several different\
    \ threading/multicore configurations:</p>\n<ul>\n<li>The progress loop can run\
    \ on a dedicated operating system thread or not</li>\n<li>Multiple Margo instances\
    \ (and thus progress loops) can be\nexecuted on different operating system threads</li>\n\
    <li>(for servers) a single Margo instance can launch RPC handlers\non different\
    \ operating system threads</li>\n</ul>\n"
  stargazers_count: 15
  subscribers_count: 9
  topics: []
  updated_at: 1666595727.0
mochi-hpc/mochi-poesie:
  data_format: 2
  description: POESIE is a Mochi microservice designed to run interpreters of various
    scripting languages (currently Lua and Python) and make them accessible remotely.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-poesie
  latest_release: v0.2
  readme: "<h1><a id=\"user-content-poesie-embedding-scripting-languages-for-mochi-services\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#poesie-embedding-scripting-languages-for-mochi-services\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>POESIE:\
    \ Embedding Scripting Languages for Mochi Services</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>POESIE\
    \ can easily be installed using Spack:</p>\n<p><code>spack install mochi-poesie</code></p>\n\
    <p>This will install POESIE (and any required dependencies) with both\nPython\
    \ and Lua backends. Disabling one or the other can be done by\nappending <code>~lua</code>\
    \ or <code>~python</code>, for example:</p>\n<p><code>spack install poesie~lua</code></p>\n\
    <h2><a id=\"user-content-architecture\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#architecture\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Architecture</h2>\n<p>Like most mochi services, POESIE relies on a\
    \ client/provider architecture.\nA provider, identified by its <em>address</em>\
    \ and <em>provider id</em>, manages one or more\ninterpreters (called <em>virtual\
    \ machines</em>, or <em>VMs</em>), referenced externally\nby either their name\
    \ or their VM id.</p>\n<h2><a id=\"user-content-starting-a-daemon-using-bedrock\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#starting-a-daemon-using-bedrock\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting\
    \ a daemon using Bedrock</h2>\n<p>By installing POESIE with the <code>+bedrock</code>\
    \ variant, one can deploy a daemon\nby providing a JSON configuration like the\
    \ following to Bedrock.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\
    \    <span class=\"pl-ent\">\"libraries\"</span>: [\n        <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>libpoesie-bedrock-module.so<span class=\"pl-pds\"\
    >\"</span></span>\n    ],\n    <span class=\"pl-ent\">\"providers\"</span>: [\n\
    \        {\n            <span class=\"pl-ent\">\"name\"</span>: <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>my_poesie_provider<span class=\"pl-pds\"\
    >\"</span></span>,\n            <span class=\"pl-ent\">\"provider_id\"</span>:\
    \ <span class=\"pl-c1\">0</span>,\n            <span class=\"pl-ent\">\"config\"\
    </span>: {\n                <span class=\"pl-ent\">\"vms\"</span>: {\n       \
    \             <span class=\"pl-ent\">\"my_vm\"</span>: {\n                   \
    \     <span class=\"pl-ent\">\"language\"</span>: <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>python<span class=\"pl-pds\">\"</span></span>\n            \
    \        }\n                }\n            }\n        }\n    ]\n}</pre></div>\n\
    <h2><a id=\"user-content-client-api\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #client-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client\
    \ API</h2>\n<p>The client API is available in <em>poesie-client.h</em>.\nThe codes\
    \ in the <em>test</em> folder illustrate how to use it.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975197.0
mochi-hpc/mochi-ssg:
  data_format: 2
  description: Scalable Service Groups (SSG), a group membership service for Mochi
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-ssg
  latest_release: v0.5.3
  readme: '<h1><a id="user-content-ssg-scalable-service-groups" class="anchor" aria-hidden="true"
    href="#ssg-scalable-service-groups"><span aria-hidden="true" class="octicon octicon-link"></span></a>SSG
    (Scalable Service Groups)</h1>

    <p>SSG is a group membership microservice based on the Mercury RPC system.

    It provides mechanisms for bootstrapping sets of Mercury processes into

    logical groups and for managing the membership of these process groups

    over time. At a high-level, each group collectively maintains a <em>group view</em>,

    which is just a mapping from group member identifiers to Mercury address

    information. The inital group membership view is specified completely

    when the group is bootstrapped (created). Currently, SSG offers the

    following group bootstrapping methods:</p>

    <ul>

    <li>MPI communicator-based bootstrap</li>

    <li>config file-based bootstrap</li>

    <li>generic bootstrap method using an array of Mercury address strings</li>

    </ul>

    <p>Process groups are referenced using unique group identifiers

    which encode Mercury address information that can be used to connect

    with a representative member of the group. These identifiers may be

    transmitted to other processes so they can join the group or attach to

    the group (<em>attachment</em> provides non-group members a way to access a

    group''s view).</p>

    <p>Optionally, SSG can be configured to use the <a href="http://www.cs.cornell.edu/~asdas/research/dsn02-SWIM.pdf"
    rel="nofollow">SWIM failure detection and

    group membership protocol</a>

    internally to detect and respond to group member failures. SWIM uses a

    randomized probing mechanism to detect faulty group members and uses an

    efficient gossip protocol to dissmeninate group membership changes to other

    group members. SSG propagates group membership view updates back to the SSG

    user using a callback interface.</p>

    <p><strong>NOTE</strong>: SSG does not currently support group members dynamically
    leaving

    or joining a group, though this should be supported in the near future.

    This means that, for now, SSG groups are immutable after creation.

    When using SWIM, this means members can be marked as faulty, but they

    cannot be fully evicted from the group view yet.</p>

    <p><strong>NOTE</strong>: SSG does not currently allow for user-specified group
    member

    identifiers, and instead assigns identifiers as dense ranks into the

    list of address strings specified at group creation time. That is,

    the group member with the first address string in the list is rank 0,

    and so on.</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <ul>

    <li>mercury (git clone --recurse-submodules <a href="https://github.com/mercury-hpc/mercury.git">https://github.com/mercury-hpc/mercury.git</a>)</li>

    <li>argobots (git clone <a href="https://github.com/pmodels/argobots.git">https://github.com/pmodels/argobots.git</a>)</li>

    <li>margo (git clone <a href="https://xgitlab.cels.anl.gov/sds/margo.git" rel="nofollow">https://xgitlab.cels.anl.gov/sds/margo.git</a>)</li>

    <li>libev (e.g libev-dev package on Ubuntu or Debian)</li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>(if configuring for the first time)

    ./prepare.sh</p>

    <p>./configure [standard options] PKG_CONFIG_PATH=/path/to/pkgconfig/files</p>

    <p>make</p>

    <p>make install</p>

    <p>MPI support is by default optionally included. If you wish to compile with
    MPI

    support, set CC=mpicc (or equivalent) in configure. If you wish to disable MPI

    entirely, use --disable-mpi (you can also force MPI inclusion through

    --enable-mpi).</p>

    '
  stargazers_count: 1
  subscribers_count: 6
  topics: []
  updated_at: 1641352657.0
mochi-hpc/mochi-thallium:
  data_format: 2
  description: Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and
    providing an object-oriented way to use these libraries.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-thallium
  latest_release: v0.10.1
  readme: '<h1><a id="user-content-thallium" class="anchor" aria-hidden="true" href="#thallium"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Thallium</h1>

    <p>Thallium is a C++ interface to <a href="https://github.com/mochi-hpc/mochi-margo/">Margo</a>.

    It offers a modern, object-oriented way of developing HPC data services. More

    information can be found on <a href="https://mochi.readthedocs.io/en/latest/"
    rel="nofollow">Mochi''s readthedocs</a>

    website.</p>

    '
  stargazers_count: 7
  subscribers_count: 4
  topics: []
  updated_at: 1666172632.0
mochi-hpc/mochi-yokan:
  data_format: 2
  description: Remote Key/Value storage service for Mochi
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-yokan
  latest_release: v0.2.10
  readme: '<h1><a id="user-content-yokan---mochis-keyvalue-and-more-storage-service"
    class="anchor" aria-hidden="true" href="#yokan---mochis-keyvalue-and-more-storage-service"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Yokan - Mochi''s Key/Value
    (and more) storage service</h1>

    <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"><img
    src="https://github.com/mochi-hpc/mochi-yokan/actions/workflows/test.yml/badge.svg?branch=main"
    alt="" style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/mochi-hpc/mochi-yokan" rel="nofollow"><img src="https://camo.githubusercontent.com/fc95c801bafa29b49219f4727f651b97e7385800c8dc4a4757a1dccadefe6611/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d796f6b616e2f6272616e63682f6d61696e2f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/mochi-hpc/mochi-yokan/branch/main/graph/badge.svg"
    style="max-width: 100%;"></a></p>

    <p>Please see documentation <a href="https://mochi.readthedocs.io/en/latest/yokan.html"
    rel="nofollow">here</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641326484.0
mochi-hpc/py-mochi-margo:
  data_format: 2
  description: Python wrapper for Margo. Can be used to prototype Margo services in
    Python.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-margo
  latest_release: v0.5.1
  readme: "<h1><a id=\"user-content-py-margo\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#py-margo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Py-Margo</h1>\n<p>Py-Margo provides a Python wrapper on top of <a\
    \ href=\"https://xgitlab.cels.anl.gov/sds/margo\" rel=\"nofollow\">Margo</a>.\n\
    It enables one to develop Margo-based service in Python.</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>margo\
    \ (and its dependencies)</li>\n<li>python</li>\n<li>pybind11</li>\n<li>py-pkgconfig</li>\n\
    </ul>\n<h2><a id=\"user-content-installing\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installing</h2>\n<p>The easiest way to install Py-Margo is to use\
    \ <a href=\"https://spack.io/\" rel=\"nofollow\">spack</a>.\nFollow the instructions\
    \ <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">here</a>\n\
    to add the <code>sds</code> namespace and its packages (instal spack first, if\
    \ needed).\nThen type:</p>\n<pre><code>spack install py-margo\n</code></pre>\n\
    <p>Once installed, you need the py-margo package (and its dependencies) to\nbe\
    \ loaded to use it.</p>\n<h2><a id=\"user-content-examples\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#examples\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<h3><a id=\"user-content-basic-example\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#basic-example\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Basic example</h3>\n<p>The following\
    \ is an example of provider programmed in Python.\nLet's put is in a file <code>server.py</code>.\n\
    The provider listens to an address on a given multiple id (here 42).\nWhenever\
    \ it receives an RPC, it prints \"Hello from\" and the name sent\nby the client,\
    \ then sends the \"Hi \"+name+\"!\" string back to the client,\nand finally terminates.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">pymargo</span>.<span class=\"pl-s1\">core</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-v\">Engine</span>, <span class=\"pl-v\">Provider</span>\n\
    \n<span class=\"pl-k\">class</span> <span class=\"pl-v\">HelloProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>(<span class=\"pl-s1\">engine</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\"\
    >register</span>(<span class=\"pl-s\">\"say_hello\"</span>, <span class=\"pl-s\"\
    >\"hello\"</span>)\n\n\t<span class=\"pl-k\">def</span> <span class=\"pl-en\"\
    >hello</span>(<span class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>,\
    \ <span class=\"pl-s1\">name</span>):\n\t\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Hello from \"</span><span class=\"pl-c1\">+</span><span class=\"\
    pl-s1\">name</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"pl-s\"\
    >\"RPC id is \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">handle</span>.<span class=\"pl-en\">get_id</span>()))\n\t\t\
    <span class=\"pl-s1\">handle</span>.<span class=\"pl-en\">respond</span>(<span\
    \ class=\"pl-s\">\"Hi \"</span><span class=\"pl-c1\">+</span><span class=\"pl-s1\"\
    >name</span><span class=\"pl-c1\">+</span><span class=\"pl-s\">\"!\"</span>)\n\
    \t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\">get_engine</span>().<span\
    \ class=\"pl-en\">finalize</span>()\n\n<span class=\"pl-k\">def</span> <span class=\"\
    pl-v\">WhenFinalize</span>():\n\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Finalize was called\"</span>)\n\n<span class=\"pl-s1\">engine</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Engine</span>(<span class=\"\
    pl-s\">'tcp'</span>)\n<span class=\"pl-s1\">provider_id</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Server running at address \"</span> <span class=\"pl-c1\">+</span>\
    \ <span class=\"pl-en\">str</span>(<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">addr</span>()) <span class=\"pl-c1\">+</span> <span class=\"pl-s\">\"\
    \ with provider_id \"</span> <span class=\"pl-c1\">+</span> <span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">provider_id</span>))\n\n<span class=\"pl-s1\"\
    >engine</span>.<span class=\"pl-en\">on_finalize</span>(<span class=\"pl-v\">WhenFinalize</span>)\n\
    <span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">HelloProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>The following code is the corresponding\
    \ client code (<code>client.py</code>).</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">sys</span>\n<span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">pymargo</span>\n<span class=\"\
    pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"pl-s1\"\
    >core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">name</span>):\n\t<span class=\"pl-s1\">addr</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">lookup</span>(<span\
    \ class=\"pl-s1\">addr_str</span>)\n\t<span class=\"pl-s1\">handle</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">create_handle</span>(<span class=\"pl-s1\">addr</span>, <span class=\"\
    pl-s1\">rpc_id</span>)\n\t<span class=\"pl-k\">return</span> <span class=\"pl-s1\"\
    >handle</span>.<span class=\"pl-en\">forward</span>(<span class=\"pl-s1\">provider_id</span>,\
    \ <span class=\"pl-s1\">name</span>)\n\n<span class=\"pl-k\">with</span> <span\
    \ class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span class=\"\
    pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span> <span class=\"\
    pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">register</span>(<span\
    \ class=\"pl-s\">\"say_hello\"</span>)\n\t<span class=\"pl-s1\">ret</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"\
    pl-c1\">3</span>]))\n\t<span class=\"pl-en\">print</span>(<span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n<p>First, run the\
    \ server on a new terminal:</p>\n<pre><code>python server.py\n</code></pre>\n\
    <p>This will output something like</p>\n<pre><code>Server running at address ofi+sockets://10.0.2.15:39151\
    \ with provider_id=42\n</code></pre>\n<p>Then run the client on a new terminal:</p>\n\
    <pre><code>python client.py ofi+sockets://10.0.2.15:39151 42 Matthieu\n</code></pre>\n\
    <h3><a id=\"user-content-sendingreceiving-python-objects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#sendingreceiving-python-objects\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Sending/receiving Python objects</h3>\n<p>The\
    \ example above shows the basic principles of Py-Margo.\nPy-Margo's RPC always\
    \ use a string as input and respond with a string.\nYet this is sufficient to\
    \ cover any use-cases you may have: Python\nindeed comes with a serialization\
    \ package, <code>pickle</code>, that can take\ncare of converting almost any Python\
    \ object from/to a string.</p>\n<p>Let us assume we have a file named <code>mymaths.py</code>\
    \ which contains the\nfollowing definition of a point in 3D.</p>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span\
    \ class=\"pl-v\">Point</span>():\n\t<span class=\"pl-k\">def</span> <span class=\"\
    pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>,<span class=\"pl-s1\"\
    >x</span>,<span class=\"pl-s1\">y</span>,<span class=\"pl-s1\">z</span>):\n\t\t\
    <span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">x</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">x</span>\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">y</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\"\
    >y</span>\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">z</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">z</span>\n\t<span class=\"\
    pl-k\">def</span> <span class=\"pl-en\">__str__</span>(<span class=\"pl-s1\">self</span>):\n\
    \t\t<span class=\"pl-k\">return</span> <span class=\"pl-s\">'Point ('</span><span\
    \ class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\"\
    >self</span>.<span class=\"pl-s1\">x</span>)<span class=\"pl-c1\">+</span><span\
    \ class=\"pl-s\">','</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">y</span>)<span\
    \ class=\"pl-c1\">+</span><span class=\"pl-s\">','</span><span class=\"pl-c1\"\
    >+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">z</span>)<span class=\"pl-c1\">+</span><span class=\"pl-s\"\
    >')'</span></pre></div>\n<p>Then here is a server that can compute a cross product\
    \ on two points sent by\na client.</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Engine</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Provider</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\"\
    >mymaths</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n\
    <span class=\"pl-k\">import</span> <span class=\"pl-s1\">pickle</span>\n\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-v\">VectorMathProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>().<span class=\"pl-en\">__init__</span>(<span class=\"pl-s1\"\
    >engine</span>, <span class=\"pl-s1\">provider_id</span>)\n\t\t<span class=\"\
    pl-s1\">self</span>.<span class=\"pl-en\">register</span>(<span class=\"pl-s\"\
    >\"cross_product\"</span>, <span class=\"pl-s\">\"cross_product\"</span>)\n\n\t\
    <span class=\"pl-k\">def</span> <span class=\"pl-en\">cross_product</span>(<span\
    \ class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>, <span class=\"\
    pl-s1\">args</span>):\n\t\t<span class=\"pl-s1\">points</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">loads</span>(<span\
    \ class=\"pl-s1\">args</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Received: \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">points</span>))\n\t\t<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span> <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">0</span>].<span class=\"pl-s1\">z</span><span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span\
    \ class=\"pl-s1\">y</span>\n\t\t<span class=\"pl-s1\">y</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">z</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">x</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span>\n\t\t<span class=\"pl-s1\">z</span> <span class=\"pl-c1\">=</span>\
    \ <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span class=\"\
    pl-s1\">x</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">1</span>].<span class=\"pl-s1\">y</span> <span class=\"pl-c1\"\
    >-</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\n\
    \t\t<span class=\"pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Point</span>(<span class=\"pl-s1\">x</span>,<span class=\"pl-s1\">y</span>,<span\
    \ class=\"pl-s1\">z</span>)\n\t\t<span class=\"pl-s1\">handle</span>.<span class=\"\
    pl-en\">respond</span>(<span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >dumps</span>(<span class=\"pl-s1\">res</span>))\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-en\">get_engine</span>().<span class=\"pl-en\">finalize</span>()\n\
    \n<span class=\"pl-s1\">engine</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>)\n<span class=\"pl-s1\"\
    >provider_id</span> <span class=\"pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n\
    <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Server running at address\
    \ \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">mid</span>.<span class=\"pl-en\">addr</span>())<span class=\"\
    pl-c1\">+</span><span class=\"pl-s\">\"with provider_id=\"</span><span class=\"\
    pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">provider_id</span>))\n\
    \n<span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">VectorMathProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>And here is a client.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">import</span> <span class=\"\
    pl-s1\">pymargo</span>\n<span class=\"pl-k\">import</span> <span class=\"pl-s1\"\
    >pickle</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">mymaths</span>\
    \ <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n<span\
    \ class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"\
    pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">p1</span>, <span class=\"pl-s1\">p2</span>):\n\t<span class=\"pl-s1\"\
    >addr</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span\
    \ class=\"pl-en\">lookup</span>(<span class=\"pl-s1\">addr_str</span>)\n\t<span\
    \ class=\"pl-s1\">handle</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">engine</span>.<span class=\"pl-en\">create_handle</span>(<span class=\"\
    pl-s1\">addr</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t<span class=\"pl-s1\">args</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">dumps</span>([<span\
    \ class=\"pl-s1\">p1</span>,<span class=\"pl-s1\">p2</span>])\n\t<span class=\"\
    pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">handle</span>.<span\
    \ class=\"pl-en\">forward</span>(<span class=\"pl-s1\">args</span>)\n\t<span class=\"\
    pl-k\">return</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >loads</span>(<span class=\"pl-s1\">res</span>)\n\n<span class=\"pl-k\">with</span>\
    \ <span class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span\
    \ class=\"pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\"\
    >pymargo</span>.<span class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span>\
    \ <span class=\"pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">mid</span>.<span class=\"\
    pl-en\">register</span>(<span class=\"pl-s\">\"cross_product\"</span>)\n\t<span\
    \ class=\"pl-s1\">p1</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >Point</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span\
    \ class=\"pl-c1\">3</span>)\n\t<span class=\"pl-s1\">p2</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-v\">Point</span>(<span class=\"pl-c1\">4</span>,<span\
    \ class=\"pl-c1\">5</span>,<span class=\"pl-c1\">6</span>)\n\t<span class=\"pl-s1\"\
    >ret</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">mid</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-s1\">p1</span>,\
    \ <span class=\"pl-s1\">p2</span>)\n\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-en\">str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n"
  stargazers_count: 1
  subscribers_count: 5
  topics: []
  updated_at: 1664973466.0
mochi-hpc/py-mochi-s4m:
  data_format: 2
  description: Python library using Mochi to broadcast data
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-s4m
  latest_release: null
  readme: '<h1><a id="user-content-mochi-s4m-share-for-me" class="anchor" aria-hidden="true"
    href="#mochi-s4m-share-for-me"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    S4M (Share for Me)</h1>

    <p>This service provides a simple non-blocking broadcast/receive

    mechanism based on Mochi.</p>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <p>Make sure you have <a href="https://spack.io/" rel="nofollow">spack</a> installed
    and setup.

    If needed, install it and set it up as follows:</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>You then need to clone the <code>mochi-spack-packages</code> repository

    and make it available to spack:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Finally, you can install S4M as follows:</p>

    <pre><code>$ spack install py-mochi-s4m

    </code></pre>

    <h2><a id="user-content-using" class="anchor" aria-hidden="true" href="#using"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using</h2>

    <p>S4M has a very simple API consisting of an <code>S4MService</code> class with

    two functions: <code>broadcast</code>, and <code>receive</code>. It requires mpi4py
    to

    bootstrap the set of processes. The <a href="test/test.py">test.py</a> file

    provides a comprehensive use case.</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1663070268.0
mochi-hpc/ycsb-cpp-interface:
  data_format: 2
  description: Mochi-based DB backends for the YCSB benchmark
  filenames:
  - spack.yaml
  full_name: mochi-hpc/ycsb-cpp-interface
  latest_release: null
  readme: "<h1><a id=\"user-content-ycsb-c-interface\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#ycsb-c-interface\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>YCSB C++ Interface</h1>\n<p><a href=\"https://github.com/brianfrankcooper/YCSB\"\
    >YCSB</a> is one of the most popular Cloud\nstorage benchmark. However it is written\
    \ in Java, forcing databases implemented\nin other languages to provide a Java\
    \ wrapper. While <a href=\"https://github.com/ls4154/YCSB-cpp\">YCSC-cpp</a>\n\
    provides a reimplementation of YCSB in C++, to date it only supports three backends,\
    \ as\nopposed to 45 for the original YCSB.</p>\n<p><a href=\"https://github.com/mochi-hpc/ycsb-cpp-interface\"\
    >ycsb-cpp-interface</a>\ntakes a different approach from YCSB-cpp, providing a\
    \ Java/C++ library\nthat enables the use of C++ to write DB backends for YCSB.</p>\n\
    <p>ycsb-cpp-inteface works in a modular way, dynamically loading your C++ database\n\
    implementation from a library using a factory pattern.</p>\n<h2><a id=\"user-content-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n<h3><a id=\"\
    user-content-building-manually\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building-manually\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Building manually</h3>\n<p>To build this repository from source, you\
    \ will first need to have\nits dependencies installed and findable by CMake. These\
    \ dependencies\ninclude:</p>\n<ul>\n<li>Java Development Kit (e.g., OpenJDK)</li>\n\
    <li>YCSB</li>\n<li>cmake</li>\n</ul>\n<p>Make sure to set the <code>JAVA_HOME</code>\
    \ environment variable\nto point to where your JDK is installed so that CMake\
    \ can find it.\nIt is recommended to install a distribution of YCSB, rather than\n\
    the source.</p>\n<p>You can then build the source contained in this repository\
    \ as follows.</p>\n<pre><code>$ mkdir build\n$ cd build\n$ cmake .. -DYCSB_ROOT=&lt;path/to/where/ycsb/is/installed&gt;\
    \ \\\n           -DCMAKE_INSTALL_PREFIX=&lt;install/prefix&gt;\n$ make\n</code></pre>\n\
    <h3><a id=\"user-content-installing-using-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#installing-using-spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Installing using Spack</h3>\n<p>You can install this\
    \ library using <a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a>.\nThe\
    \ <code>ycsb-cpp-interface</code> Spack package is available via the\n<a href=\"\
    https://github.com/mochi-hpc/mochi-spack-packages\">Mochi repository</a>,\nwhich\
    \ can be added to Spack as follows.</p>\n<pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git\n\
    $ spack repo add mochi-spack-packages\n</code></pre>\n<p>Once the <code>mochi-spack-packages</code>\
    \ repository has been made available to Spack,\nyou can install <code>ycsb-cpp-interface</code>\
    \ as follows.</p>\n<pre><code>$ spack install ycsb-cpp-interface\n</code></pre>\n\
    <h2><a id=\"user-content-testing\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #testing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Testing</h2>\n\
    <p>If you have installed ycsb-cpp-interface with Spack, make sure that\nthe package\
    \ is loaded (<code>spack load ycsb-cpp-interface</code>), then you\ncan start\
    \ the CLI for testing, as follows.</p>\n<pre><code>ycsb-cpp-cli\n</code></pre>\n\
    <p>When building from source, the CLI is located in the <code>bin</code> subdirectory\n\
    of your build folder.</p>\n<p>You will end up in YCBS's CLI, with the YcsbDBClient\
    \ loaded as the\nDB backend, itself using a test implementation of an in-memory\
    \ database\nwith which you can interact (type <code>help</code> to see a list\
    \ of available commands).</p>\n<h2><a id=\"user-content-writing-your-own-c-db-backend\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#writing-your-own-c-db-backend\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Writing\
    \ your own C++ DB backend</h2>\n<p>ycsb-cpp-interface provides a header file,\
    \ <code>YCSBCppInterface.hpp</code>, with\na <code>ycsb::DB</code> abstract class.\
    \ To implement your own C++ backend database,\nyou simply need to implement a\
    \ child class of the <code>ycsb::DB</code> class that\nimplements the required\
    \ virtual functions. You may look at <a href=\"src/TestDB.cpp\"></a>\nas an example\
    \ of such an implementation. Note the use of the\n<code>YCSB_CPP_REGISTER_DB_TYPE</code>\
    \ macro after the class definition. This macro\nmust be called in a .cpp file\
    \ to associate the name of your backend\n(e.g. <code>myawesomedb</code>) with\
    \ the class name to use (e.g., <code>MyAwesomeDB</code>).</p>\n<p>Once your database\
    \ class is ready, compile it into a shared library\n(e.g., <code>libmyawesomedb.so</code>).\
    \ Make sure the <code>LD_LIBRARY_PATH</code> environment\nvariable contains the\
    \ path to your dynamic library. You may then test\nyour backend with the CLI as\
    \ follows.</p>\n<pre><code>$ ycsb-cpp-cli -p ycsb.cpp.library=libmyawesomedb.so\
    \ -p ycsb.cpp.backend=myawesomedb\n</code></pre>\n<p>The <code>ycsb.cpp.library</code>\
    \ and <code>ycsb.cpp.backend</code> properties are the only properties\nneeded\
    \ by ycsb-cpp-interface. Any other properties provided will be propagated\nto\
    \ your database implementation in the form of an <code>std::unordered_map&lt;std::string,\
    \ std::string&gt;</code>.\nNote that <code>ycsb.cpp.library</code> may accept\
    \ a full path to your dynamic library,\nif you don't want to change the <code>LD_LIBRARY_PATH</code>\
    \ environment variable.</p>\n<h2><a id=\"user-content-running-ycsb-with-your-c-db-backend\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-ycsb-with-your-c-db-backend\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ YCSB with your C++ DB backend</h2>\n<p>ycsb-cpp-interface provides a convenience\
    \ script, <code>ycsb-cpp</code>, to run YCSB\nwith your own backend. It can be\
    \ used in a way similar to the original ycsb script,\nas follows.</p>\n<pre><code>$\
    \ ycsb-cpp load -p ycsb.cpp.library=libmyawesomedb.so -p ycsb.cpp.backend=myawesomedb\
    \ -P workloadfile\n$ ycsb-cpp run -p ycsb.cpp.library=libmyawesomedb.so -p ycsb.cpp.backend=myawesomedb\
    \ -P workloadfile\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1661162651.0
nantes-m2-rps-exp/qqbar2mumu-2022:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: nantes-m2-rps-exp/qqbar2mumu-2022
  latest_release: null
  readme: "<h1><a id=\"user-content-projet-exp\xE9rimental---production-de-quarkonia\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#projet-exp\xE9rimental---production-de-quarkonia\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Projet exp\xE9\
    rimental - Production de quarkonia</h1>\n<blockquote>\n<p>Ce d\xE9pot git h\xE9\
    berge les fichiers n\xE9cessaires pour d\xE9marrer le projet \"Production de quarkonia\"\
    \ du Master 2 RPS de l'Universit\xE9 de Nantes. Il est principalement \xE0 destination\
    \ des \xE9tudiants qui r\xE9alisent ce projet. Le \"vous\" ci-dessous s'adresse\
    \ donc \xE0 ces \xE9tudiants.</p>\n</blockquote>\n<p>Pour ce projet le language\
    \ de programmation choisi est Python. Nous recommandons de l'utiliser par le biais\
    \ de <a href=\"https://jupyter.org\" rel=\"nofollow\">\"Notebooks Jupyter\"</a>\
    \ qui permettent de m\xE9langer le code, la documentation et les r\xE9sultats\
    \ de l'ex\xE9cution du code.</p>\n<p>Jupyter est un outil commun dans le domaine\
    \ de la science des donn\xE9es. Il y a bien des fa\xE7ons d'utiliser Jupyter et\
    \ de nombreux tutoriels sont disponibles en ligne pour aller plus loin, mais vous\
    \ trouverez ci-dessous trois m\xE9thodes pour d\xE9marrer :</p>\n<ol>\n<li>une\
    \ <a href=\"conda/README.md\">m\xE9thode locale bas\xE9e sur conda</a>\n</li>\n\
    <li>une <a href=\"cloud/README.md\">m\xE9thode cloud</a>\n</li>\n<li>une <a href=\"\
    multipass/README.md\">m\xE9thode locale bas\xE9e sur multipass</a>\n</li>\n</ol>\n\
    <p>A noter que seule la troisi\xE8me m\xE9thode permet, a priori, de r\xE9aliser\
    \ toutes les t\xE2ches n\xE9cessaires \xE0 ce projet, car elle offre des interfaces\
    \ Python de paquets C++ d\xE9velopp\xE9s sp\xE9cifiquement pour ce projet, alors\
    \ que les deux premi\xE8res ne permettent d'acc\xE9der qu'\xE0 des paquets Python\
    \ \"g\xE9n\xE9riques\". Les deux premi\xE8res m\xE9thodes permettent n\xE9anmoins\
    \ de d\xE9marrer assez rapidement.</p>\n<p>Pour ce projet, vous utiliserez \xE9\
    galement <a href=\"https://git.com\" rel=\"nofollow\">Git</a> et <a href=\"https://github.com\"\
    >GitHub</a>. Si ce n'est pas d\xE9j\xE0 le cas, il vous faudra <a href=\"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\"\
    \ rel=\"nofollow\">installer git sur votre machine</a> et vous <a href=\"https://fr.wikihow.com/cr%C3%A9er-un-compte-sur-GitHub\"\
    \ rel=\"nofollow\">cr\xE9\xE9r un compte GitHub</a>.</p>\n<p>Comme pour Jupyter,\
    \ un nombre important de ressources documentaires et tutoriels sont disponibles\
    \ sur le net pour commencer avec git si c'est votre premi\xE8re approche ou encore\
    \ pour approfondir votre ma\xEEtrise de cet outil si vous le connaissez d\xE9\
    j\xE0 un peu.</p>\n<p>Vous trouverez dans le <a href=\"git/README.md\">document\
    \ <code>git/README.md</code></a> les commandes de base pour d\xE9marrer avec ce\
    \ d\xE9p\xF4t git en particulier.</p>\n<p>Une fois la premi\xE8re installation\
    \ r\xE9alis\xE9e, commencez par vous familiariser avec Jupyter en utilisant le\
    \ <a href=\"notebooks/muon-eta-distribution.ipynb\">notebook d'exemple</a></p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1667463557.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - linux-centos7-broadwell/or-slurm/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_env/index.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2><a id="user-content-purpose" class="anchor" aria-hidden="true" href="#purpose"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 1
  subscribers_count: 18
  topics: []
  updated_at: 1662034991.0
openPMD/openPMD-api:
  data_format: 2
  description: ':floppy_disk: C++ & Python API for Scientific I/O'
  filenames:
  - .github/ci/spack-envs/clang14_py311_nompi_h5_ad1_ad2/spack.yaml
  full_name: openPMD/openPMD-api
  latest_release: 0.14.5
  readme: "<h1><a id=\"user-content-c--python-api-for-scientific-io-with-openpmd\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#c--python-api-for-scientific-io-with-openpmd\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ &amp;\
    \ Python API for Scientific I/O with openPMD</h1>\n<p><a href=\"https://github.com/openPMD/openPMD-standard/releases\"\
    ><img src=\"https://camo.githubusercontent.com/5957dc11cb68f6705ef9ef6683152c6c4fcc057a24dff340e1e8bada1bee0d01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\"\
    \ alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d54fa5adcf7ca50d2cdb45823be5064379b613d526fa06f6e193ba2ce616318/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/f551141eea2176c34aa163092549d6fdde9a220d605d6efe9128b024c6e5932b/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\"\
    \ alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"\
    https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"\
    max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4fc8091716dbd967fa2a82eef3d29227110e5081f3128aaa38663e547c24f812/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/104f6901ae04bff8385acc8273bb276ab84656a927a418108b940d09fd6e5d7c/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0d568047fbbd300af56b766d9a4235a20534485f5827194e859d4f5c20e58334/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\"\
    \ alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/context:cpp\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/63a7f9e783999e3afc03ef38ee82e2048017e4e6d279ff4120ad8b8718480ccd/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f6370702f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\"\
    \ alt=\"LGTM: C/C++\" data-canonical-src=\"https://img.shields.io/lgtm/grade/cpp/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/context:python\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5046bf66a4612476a030d38de817c23fa03990183d2d74fa92c5f1379feb5d09/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\"\
    \ alt=\"LGTM: Python\" data-canonical-src=\"https://img.shields.io/lgtm/grade/python/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/alerts/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/85e32deb8face392eea9bfa2be4da4c11ca7c0f834fa069223fbc63758b68c4f/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\"\
    \ alt=\"LGTM: Total alerts\" data-canonical-src=\"https://img.shields.io/lgtm/alerts/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f0487a8fc14d269210ae8ce80b556d4afcd93684f02e61386d2d02daa4423cbd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f438ca4eaa308f982d0a28c48f05bf63ca1a86e52c3d2817f6d7559d1dee68e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8278d89e3634e25a818a2d673fe997c2aa5a09fd5995f716aeffa743388030ee/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\"\
    \ alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/30679331f3c6a5ae54970eda85f36a30347dee8a9111448d7aa48587fd524a1d/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\"\
    \ alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\
    ><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\"\
    \ alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fc9c860bb1fc8e7e145ea9dd6723b9ac6ac2743c195e5e899f6cfa3d38a5a69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\"\
    \ alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0b068d7b5718aafccb46e2ee35f8249938ef189a36ba353c15222ed5e6f65e49/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\"\
    \ alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD is an open meta-data schema\
    \ that provides meaning and self-description for data sets in science and engineering.\n\
    See <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a>\
    \ for details of this schema.</p>\n<p>This library provides a reference API for\
    \ openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable,\
    \ hierarchical file formats, this library implements various backends such as\
    \ HDF5, ADIOS1, ADIOS2 and JSON.\nWriting &amp; reading through those backends\
    \ and their associated files are supported for serial and <a href=\"https://www.mpi-forum.org/docs/\"\
    \ rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<h3><a id=\"user-content-c\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#c\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>C++</h3>\n<p><a href=\"https://isocpp.org/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d47ea5fd5ff323ff5c76593ea37f2340533c73de5e6e37a2b27d7dc28070cd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\"\
    \ alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span>\
    \ s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span\
    \ class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"\
    pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>\
    \ &amp; [step, it] : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span>\
    \ &lt;&lt; step &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span\
    \ class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\"\
    >const</span> &amp; [name, mesh] : it.<span class=\"pl-smi\">meshes</span> ) {\n\
    \        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\
    \  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; name &lt;&lt; <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\"\
    >\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\"\
    >for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp;\
    \ val : mesh.<span class=\"pl-c1\">attributes</span>() )\n            std::cout\
    \ &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"\
    pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\
    \    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span>\
    \ <span class=\"pl-k\">const</span> &amp; [name, species] : it.<span class=\"\
    pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"\
    </span></span> &lt;&lt; name &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\"\
    >auto</span> <span class=\"pl-k\">const</span>&amp; val : species.<span class=\"\
    pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt;\
    \ val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n\
    <h3><a id=\"user-content-python\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #python\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Python</h3>\n\
    <p><a href=\"https://www.python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\"\
    \ alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span>\
    \ <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"\
    pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span\
    \ class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\"\
    >io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\
    \n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"\
    pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span\
    \ class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n  \
    \  <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\
    \n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span\
    \ class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n\
    \        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}'\
    \ attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\"\
    >k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"\
    pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span\
    \ class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span\
    \ class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"\
    pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"\
    pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n  \
    \          <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n\
    <h3><a id=\"user-content-more\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #more\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>More!</h3>\n\
    <p>Curious?\nOur manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\"\
    \ rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n\
    <h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Dependencies</h2>\n<p>Required:</p>\n<ul>\n<li>CMake 3.15.0+</li>\n\
    <li>C++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx</li>\n\
    </ul>\n<p>Shipped internally in <code>share/openPMD/thirdParty/</code>:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> 2.13.9+\
    \ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\">BSL-1.0</a>)</li>\n\
    <li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> 2.10.1+ (<a\
    \ href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)</li>\n\
    <li>\n<a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a> 3.9.1+ (<a\
    \ href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\">MIT</a>)</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> 3.7.1+ (<a href=\"\
    https://github.com/ToruNiina/toml11/blob/master/LICENSE\">MIT</a>)</li>\n</ul>\n\
    <p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\"\
    \ rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\"\
    \ rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://www.olcf.ornl.gov/center-projects/adios\"\
    \ rel=\"nofollow\">ADIOS1</a> 1.13.1+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either\
    \ with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n\
    </ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python\
    \ 3.7 - 3.11</li>\n<li>pybind11 2.10.1+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py\
    \ 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n\
    <li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n<li>CUDA C++\
    \ (optional, currently used only in tests)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"\
    https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/580cdb6331254f66680bd967326d9630f5124291efd5ace18549fbb93cbae6db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3c3728308a9e416589fa8b3b8168967287c515037bfbd4b40f1b14f266de56fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/92b7b7bb69b2b17d1981ae5fdcdb32f971ee57f54a98ea4804e93fd0a2eb58ef/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4eeb2c48c0e554ea8dbe8e90f73a6f2d217e775e0bd5e5cb90ddf4619ef3a6a0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/2babf79954ea524c24f2f9b1cfa05728fdaccbe0a80c2da6a7a7595cc131894c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\"\
    \ alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our community loves to help each other.\n\
    Please <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\"\
    >report installation problems</a> in case you should get stuck.</p>\n<p>Choose\
    \ <em>one</em> of the install methods below to get started:</p>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://spack.io\"\
    \ rel=\"nofollow\">Spack</a></h3>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/becffbecb6a50502286f02ec86c4e62f239f3671148d11341152e0dc695a2fc9/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\"\
    \ alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b29fc54abf92a2a6d1d2c70159eb276df53b67a1294ae3f82b1b0bf22a3c586b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\"\
    \ alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \    +python +adios1 -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack\
    \ load openpmd-api</pre></div>\n<h3><a id=\"user-content-conda\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#conda\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a></h3>\n\
    <p><a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img\
    \ src=\"https://camo.githubusercontent.com/3ad2b345bb3589aa2d733ca20df72938ed54a48342b69f7cbe9eacab43d84549/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a51d3cd2bfa3c6b01bd0f2e36abc206fb9db5700105fac2acd2c2105fced2ec4/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \           OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\n\
    conda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n\
    <h3><a id=\"user-content-brew\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #brew\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://brew.sh\" rel=\"nofollow\">Brew</a></h3>\n<p><a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/d873c8c473fece8abf1c34a8299a50b7ee0da9772eb50cce8649e7ca32468a6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\"\
    \ alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/7b767b67facc26db7d850ae5c3155fa949048991dde7a0f5471c1e6862f0a586/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\"\
    \ alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<h3><a id=\"\
    user-content-pypi\" class=\"anchor\" aria-hidden=\"true\" href=\"#pypi\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://pypi.org\"\
    \ rel=\"nofollow\">PyPI</a></h3>\n<p><a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fc28bd368523d0b8adab5f4b414aebb304743130eef42bca203f4e9eed428ae7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\"\
    \ alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7cef25e887c028f65d5d7e20f3e7abe394ab328ecb499e34e47460afd2c78558/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\"\
    \ alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82acdd95515851a5ba4a3006871151f76cfe4d6583f6c24e80bd0fd29d391845/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\"\
    \ alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9)\
    \ or on exotic processor architectures, this install method <em>compiles from\
    \ source</em> against the found installations of HDF5, ADIOS1, ADIOS2, and/or\
    \ MPI (in system paths, from other package managers, or loaded via a module system,\
    \ ...).</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                   --user</span>\n\
    python3 -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n\
    <p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional:                                    --user</span>\npython3\
    \ -m pip install -U pip setuptools wheel\npython3 -m pip install -U cmake\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                 \
    \                                                  --user</span>\nopenPMD_USE_MPI=ON\
    \ python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n<p>For\
    \ some exotic architectures and compilers, you might need to disable a compiler\
    \ feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\"\
    \ rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter\
    \ linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                               \
    \                 --user</span>\npython3 -m pip install openpmd-api --no-binary\
    \ openpmd-api</pre></div>\n<p>Additional CMake options can be passed via individual\
    \ environment variables, which need to be prefixed with <code>openPMD_CMAKE_</code>.</p>\n\
    <h3><a id=\"user-content-from-source\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #from-source\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>From\
    \ Source</h3>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0a40953107090abff3b564ec3436668756b873cd4d9e021738a046781a5a0e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\"\
    \ alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD-api can also be built and installed\
    \ from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\
    \nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests,\
    \ with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which\
    \ python3)</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\"\
    >.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\n\
    ctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required\
    \ for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target\
    \ install</pre></div>\n<p>The following options can be added to the <code>cmake</code>\
    \ call to control features.\nCMake controls options with prefixed <code>-D</code>,\
    \ e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n\
    <td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_ADIOS1</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS1 backend (<code>.bp</code> files up to version BP3)</td>\n</tr>\n<tr>\n\
    <td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n\
    <td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code\
    \ <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro\
    \ independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_INSTALL_RPATH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Add RPATHs to installed binaries</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n\
    <td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n\
    </table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n\
    <sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without\
    \ specific cause is highly discouraged</em></p>\n<p>Additionally, the following\
    \ libraries are shipped internally.\nThe following options allow to switch to\
    \ external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n\
    <th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.9+</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>pybind11</td>\n<td>2.10.1+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_TOML11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>toml11</td>\n<td>3.7.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this\
    \ will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and\
    \ installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code>\
    \ to the <code>cmake</code> command.\nYou can only build a static or a shared\
    \ library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\n\
    In order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code>\
    \ to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and\
    \ command line tools are built.\nIn order to skip building those, pass <code>OFF</code>\
    \ to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_CUDA_EXAMPLES</code></td>\n<td>ON/<strong>OFF</strong>\n\
    </td>\n<td>Use CUDA in examples</td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-linking-to-your-project\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #linking-to-your-project\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Linking to your project</h2>\n<p>The install will contain header files\
    \ and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n\
    <h3><a id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CMake</h3>\n\
    <p>If your project is using CMake for its build, one can conveniently use our\
    \ provided <code>openPMDConfig.cmake</code> package which is installed alongside\
    \ the library.</p>\n<p>First set the following environment hint if openPMD-api\
    \ was <em>not</em> installed in a system path:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed\
    \ if installed outside of system paths</span>\n<span class=\"pl-k\">export</span>\
    \ CMAKE_PREFIX_PATH=<span class=\"pl-smi\">$HOME</span>/somepath:<span class=\"\
    pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n<p>Use the following lines in\
    \ your project's <code>CMakeLists.txt</code>:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> supports:           \
    \            COMPONENTS MPI NOMPI HDF5 ADIOS1 ADIOS2</span>\n<span class=\"pl-c1\"\
    >find_package</span>(openPMD 0.9.0 <span class=\"pl-k\">CONFIG</span>)\n\n<span\
    \ class=\"pl-k\">if</span>(openPMD_FOUND)\n    <span class=\"pl-c1\">target_link_libraries</span>(YourTarget\
    \ <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)\n<span class=\"pl-k\"\
    >endif</span>()</pre></div>\n<p><em>Alternatively</em>, add the openPMD-api repository\
    \ source directly to your project and use it via:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">add_subdirectory</span>(<span\
    \ class=\"pl-s\">\"path/to/source/of/openPMD-api\"</span>)\n\n<span class=\"pl-c1\"\
    >target_link_libraries</span>(YourTarget <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n\
    <p>For development workflows, you can even automatically download and build openPMD-api\
    \ from within a depending CMake project.\nJust replace the <code>add_subdirectory</code>\
    \ call with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"\
    pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077\
    \ <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_SHARED_LIBS\
    \ <span class=\"pl-k\">OFF</span>)  <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> precedence over BUILD_SHARED_LIBS if needed</span>\n<span class=\"pl-c1\"\
    >set</span>(openPMD_INSTALL <span class=\"pl-k\">OFF</span>)            <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> or instead use:</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> set(openPMD_INSTALL ${BUILD_SHARED_LIBS})\
    \  # only install if used as a shared library</span>\n<span class=\"pl-c1\">set</span>(openPMD_USE_PYTHON\
    \ <span class=\"pl-k\">OFF</span>)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY\
    \ <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"</span>\n\
    \  GIT_TAG        <span class=\"pl-s\">\"dev\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n\
    <h3><a id=\"user-content-manually\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #manually\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manually</h3>\n\
    <p>If your (Linux/OSX) project is build by calling the compiler directly or uses\
    \ a manually written <code>Makefile</code>, consider using our <code>openPMD.pc</code>\
    \ helper file for <code>pkg-config</code> which are installed alongside the library.</p>\n\
    <p>First set the following environment hint if openPMD-api was <em>not</em> installed\
    \ in a system path:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed if installed\
    \ outside of system paths</span>\n<span class=\"pl-k\">export</span> PKG_CONFIG_PATH=<span\
    \ class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span class=\"pl-smi\"\
    >$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and compiler flags\
    \ for your project are available via:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> switch to check if openPMD-api\
    \ was build as static library</span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> (via BUILD_SHARED_LIBS=OFF) or as shared library (default)</span>\n\
    <span class=\"pl-k\">if</span> [ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config --variable=static\
    \ openPMD<span class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\
    \ <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>true<span class=\"pl-pds\">\"</span></span> ]\n<span class=\"pl-k\">then</span>\n\
    \    pkg-config --libs --static openPMD\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so\
    \ /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config\
    \ --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib\
    \ -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n\
    <h2><a id=\"user-content-author-contributions\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#author-contributions\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Author Contributions</h2>\n<p>openPMD-api is developed\
    \ by many people.\nIt was initially started by the <a href=\"https://hzdr.de/crp\"\
    \ rel=\"nofollow\">Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\
    >libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\"\
    \ rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"\
    https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe\
    \ following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\
    >contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\"\
    >Axel Huebl (HZDR, now LBNL)</a>:\nproject lead, releases, documentation, automated\
    \ CI/CD, Python bindings, Dask, installation &amp; packaging, prior reference\
    \ implementations</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\">Franz\
    \ Poeschel (CASUS)</a>:\nJSON &amp; ADIOS2 backend, data staging/streaming, reworked\
    \ class design</li>\n<li>\n<a href=\"https://github.com/C0nsultant\">Fabian Koller\
    \ (HZDR)</a>:\ninitial library design and implementation with HDF5 &amp; ADIOS1\
    \ backend</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu (LBNL)</a>:\n\
    non-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n</ul>\n\
    <p>Further thanks go to improvements and contributions from:</p>\n<ul>\n<li>\n\
    <a href=\"https://github.com/CFGrote\">Carsten Fortmann-Grote (EU XFEL GmbH, now\
    \ MPI-EvolBio)</a>:\ndraft of our Python unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\"\
    >Dominik Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n\
    <li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\n\
    support on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\"\
    >James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"\
    https://github.com/psychocoderHPC\">Ren\xE9 Widera (HZDR)</a>:\ndesign improvements\
    \ for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\"\
    >Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n\
    <a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation\
    \ improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\xE9\
    mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n\
    <a href=\"https://github.com/LDAmorim\">L\xEDgia Diana Amorim (LBNL)</a>:\npackage\
    \ integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\"\
    >Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"\
    https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing,\
    \ documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\"\
    >Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"\
    https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask prototyping\
    \ &amp; ADIOS2 benchmarking</li>\n<li>\n<a href=\"https://github.com/jakirkham\"\
    >John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n<li>\n<a href=\"\
    https://github.com/eschnett\">Erik Schnetter (PITP)</a>:\nC++ API bug fixes</li>\n\
    <li>\n<a href=\"https://github.com/jeanbez\">Jean Luca Bez (LBNL)</a>:\nHDF5 performance\
    \ tuning</li>\n</ul>\n<h3><a id=\"user-content-grants\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#grants\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Grants</h3>\n<p>The openPMD-api authors acknowledge support via the\
    \ following programs.\nThis project has received funding from the European Unions\
    \ Horizon 2020 research and innovation programme under grant agreement No 654220.\n\
    Supported by the Consortium for Advanced Modeling of Particles Accelerators (CAMPA),\
    \ funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\n\
    Supported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort\
    \ of two U.S. Department of Energy organizations (Office of Science and the National\
    \ Nuclear Security Administration).\nThis work was partially funded by the Center\
    \ of Advanced Systems Understanding (CASUS), which is financed by Germany's Federal\
    \ Ministry of Education and Research (BMBF) and by the Saxon Ministry for Science,\
    \ Culture and Tourism (SMWK) with tax funds on the basis of the budget approved\
    \ by the Saxon State Parliament.</p>\n<h3><a id=\"user-content-transitive-contributions\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#transitive-contributions\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Transitive Contributions</h3>\n\
    <p>openPMD-api stands on the shoulders of giants and we are grateful for the following\
    \ projects included as direct dependencies:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS\"\
    >ADIOS1</a> and <a href=\"https://github.com/ornladios/ADIOS2\">ADIOS2</a> by\
    \ <a href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky (ORNL), team,\
    \ collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"\
    https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\xFD</a> and <a href=\"\
    https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n\
    <li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a>\
    \ and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a>\
    \ by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"\
    https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> by <a href=\"\
    https://github.com/ToruNiina\">Toru Niina</a> and <a href=\"https://github.com/ToruNiina/toml11#Contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\"\
    >pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a>\
    \ and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n\
    </li>\n<li>all contributors to the evolution of modern C++ and early library preview\
    \ developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n\
    </li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a>\
    \ and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n\
    </li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"\
    nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\
    \ and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among\
    \ others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\"\
    >openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR,\
    \ now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\
    >contributors</a>\n</li>\n</ul>\n"
  stargazers_count: 91
  subscribers_count: 10
  topics:
  - openpmd
  - openscience
  - hdf5
  - adios
  - mpi
  - hpc
  - research
  - file-handling
  - python3
  - opendata
  - cpp14
  - metadata
  updated_at: 1667524944.0
pdidev/test_env:
  data_format: 2
  description: Testing environment for PDI
  filenames:
  - spack/1b-spack/spack.yaml
  full_name: pdidev/test_env
  latest_release: null
  readme: '<h1><a id="user-content-docker-images" class="anchor" aria-hidden="true"
    href="#docker-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Docker
    images:</h1>

    <p>A set of related Docker images to build and test PDI.</p>

    <p>We provide images based on:</p>

    <ul>

    <li>Dask recipes,</li>

    <li>Binary packages.</li>

    </ul>

    <h2><a id="user-content-dask-based-images" class="anchor" aria-hidden="true" href="#dask-based-images"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dask-based images</h2>

    <p>These images are based on a minimal Ubuntu 18.08, with spack and all dependencies
    installed through

    spack.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/spack/${deps_version}/${compiler}/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>deps_version</code>:

    <ul>

    <li>

    <code>oldest</code>: dependencies use the oldest versions supported by PDI,</li>

    <li>

    <code>latest</code>: dependencies use the latest versions available in spack at
    the time of generation,</li>

    </ul>

    </li>

    <li>

    <code>compiler</code>:

    <ul>

    <li>

    <code>gcc</code>:   using GCC compiler,</li>

    <li>

    <code>clang</code>: using clang for C/C++ and gfortran for Fortran,</li>

    </ul>

    </li>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image.</li>

    </ul>

    </li>

    </ul>

    <h2><a id="user-content-binary-package-based-images" class="anchor" aria-hidden="true"
    href="#binary-package-based-images"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binary
    package based images</h2>

    <p>These images are based on Ubuntu 18.08, with all dependencies installed through
    packages.</p>

    <p>The images are named as: <code>ghcr.io/pdidev/ubuntu/bionic/${mpi}/${level}</code>

    With the following parameters:</p>

    <ul>

    <li>

    <code>mpi</code>:

    <ul>

    <li>

    <code>mpich</code>: using mpich implementation of MPI,</li>

    <li>

    <code>openmpi</code>: using openmpi implementation of MPI,</li>

    </ul>

    </li>

    <li>

    <code>level</code>:

    <ul>

    <li>

    <code>mini</code>: dependencies "vendored" in PDI are not included in the image,</li>

    <li>

    <code>all</code>: dependencies "vendored" in PDI are included in the image,</li>

    <li>

    <code>pdi</code>: PDI is included in the image.</li>

    </ul>

    </li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1641653805.0
psakievich/Driver-Cylinder:
  data_format: 2
  description: Test problem for the Exawind-Driver designed for demo's and debugging
  filenames:
  - spack.yaml
  - spack_e4s.yaml
  full_name: psakievich/Driver-Cylinder
  latest_release: null
  readme: '<h1><a id="user-content-exawind-demo-problem" class="anchor" aria-hidden="true"
    href="#exawind-demo-problem"><span aria-hidden="true" class="octicon octicon-link"></span></a>Exawind
    Demo Problem</h1>

    <p>Rotating laminar cyinder in a cross flow with nested refinement

    Eventually this should be turbulent/turn on turbulence models to test the same
    code paths used for turbine runs</p>

    <p>Nearbody meshes:</p>

    <ul>

    <li>cylinder3d_nearbody_2k.g (no refinement, what we have in the regression suite)</li>

    <li>cylinder3d_nearbody_18k.g (1 level of refinement)</li>

    <li>cylinder3d_nearbody_146k.g (2 level of refinement)</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1665545780.0
range3/chfs-containers:
  data_format: 2
  description: null
  filenames:
  - spack/envs/chfs/spack.yaml
  full_name: range3/chfs-containers
  latest_release: null
  readme: '<h1><a id="user-content-chfs-containers" class="anchor" aria-hidden="true"
    href="#chfs-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>chfs-containers</h1>

    <h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>example</h2>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    explicitly pull the latest chfs image </span>

    docker pull range3/chfs:master


    git clone https://github.com/range3/chfs-containers

    <span class="pl-c1">cd</span> chfs-containers


    <span class="pl-c"><span class="pl-c">#</span> start servers</span>

    docker-compose up -d


    <span class="pl-c"><span class="pl-c">#</span> start another container for client</span>

    docker run -it --rm --network chfs_net --privileged range3/chfs:master bash

    <span class="pl-c"><span class="pl-c">#</span> set CHFS_SERVER env</span>

    <span class="pl-k">export</span> CHFS_SERVER=<span class="pl-s"><span class="pl-pds">$(</span>chlist
    -c -s ofi+sockets://172.30.0.3:50000<span class="pl-pds">)</span></span>


    <span class="pl-c"><span class="pl-c">#</span> list chfs servers</span>

    chlist


    <span class="pl-c"><span class="pl-c">#</span> mount chfs via FUSE</span>

    mkdir /tmp/m

    chmkdir /tmp/m

    chfuse -o direct_io,modules=subdir,subdir=<span class="pl-s"><span class="pl-pds">"</span>/tmp/m<span
    class="pl-pds">"</span></span> /tmp/m


    <span class="pl-c"><span class="pl-c">#</span> &lt;ctrl-D&gt;</span>

    <span class="pl-c"><span class="pl-c">#</span> the client container is removed</span>


    <span class="pl-c"><span class="pl-c">#</span> stop and remove server containers</span>

    docker-compose down</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652094301.0
range3/fio-practice:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/fio-practice
  latest_release: null
  readme: '<h1><a id="user-content-fio-practice" class="anchor" aria-hidden="true"
    href="#fio-practice"><span aria-hidden="true" class="octicon octicon-link"></span></a>fio-practice</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1665547201.0
range3/kvs-evaluation:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/kvs-evaluation
  latest_release: null
  readme: "<h1><a id=\"user-content-kvs-evaluation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#kvs-evaluation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>kvs-evaluation</h1>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> external/YCSB-C\n\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> sudo\u3092\u4F7F\u3063\u3066libhiredis.so\u304C\
    /usr/local/lib\u306B\u30A4\u30F3\u30B9\u30C8\u30FC\u30EB\u3055\u308C\u308B</span>\n\
    make\n<span class=\"pl-k\">export</span> LD_LIBRARY_PATH=/usr/local/lib\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> \u52D5\u4F5C\u78BA\u8A8D</span>\n\
    ./ycsbc -db basic -threads 1 -P workloads/workloada.spec</pre></div>\n<h1><a id=\"\
    user-content-ycsb-c\" class=\"anchor\" aria-hidden=\"true\" href=\"#ycsb-c\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>YCSB-C</h1>\n\
    <h2><a id=\"user-content-workload\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #workload\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>workload</h2>\n\
    <table>\n<thead>\n<tr>\n<th align=\"left\">workload</th>\n<th align=\"left\">description</th>\n\
    <th align=\"right\">read</th>\n<th align=\"right\">insert</th>\n<th align=\"right\"\
    >update</th>\n<th align=\"right\">scan</th>\n<th align=\"right\">R-M-W</th>\n\
    <th align=\"center\">distribution</th>\n<th align=\"center\">remarks</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td align=\"left\">A</td>\n<td align=\"left\">Update\
    \ heavy</td>\n<td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >B</td>\n<td align=\"left\">Read mostly</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">zipfian</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">C</td>\n<td align=\"left\">Read\
    \ only</td>\n<td align=\"right\">1</td>\n<td align=\"right\"></td>\n<td align=\"\
    right\"></td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"\
    >D</td>\n<td align=\"left\">Read latest</td>\n<td align=\"right\">0.95</td>\n\
    <td align=\"right\">0.05</td>\n<td align=\"right\"></td>\n<td align=\"right\"\
    ></td>\n<td align=\"right\"></td>\n<td align=\"center\">latest</td>\n<td align=\"\
    center\"></td>\n</tr>\n<tr>\n<td align=\"left\">E</td>\n<td align=\"left\">Short\
    \ ranges</td>\n<td align=\"right\"></td>\n<td align=\"right\">0.05</td>\n<td align=\"\
    right\"></td>\n<td align=\"right\">0.95</td>\n<td align=\"right\"></td>\n<td align=\"\
    center\">zipfian</td>\n<td align=\"center\">maxscanlength=100 random(uniform)</td>\n\
    </tr>\n<tr>\n<td align=\"left\">F</td>\n<td align=\"left\">Read-modify-write</td>\n\
    <td align=\"right\">0.5</td>\n<td align=\"right\"></td>\n<td align=\"right\"></td>\n\
    <td align=\"right\"></td>\n<td align=\"right\">0.5</td>\n<td align=\"center\"\
    >zipfian</td>\n<td align=\"center\"></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-class-diagram-subset\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #class-diagram-subset\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>class diagram (subset)</h2>\n<pre lang=\"mermaid\"><code>classDiagram\n\
    class DBFactory\nclass DB\n&lt;&lt;interface&gt;&gt; DB\nclass HashtableDB\n&lt;&lt;abstruct&gt;&gt;\
    \ HashtableDB\nclass LockStlDB\nclass StringHashtable~V~\n&lt;&lt;interface&gt;&gt;\
    \ StringHashtable\nclass KeyHashtable\n&lt;&lt;interface&gt;&gt; KeyHashtable\n\
    class FieldHashtable\n&lt;&lt;interface&gt;&gt; FieldHashtable\nclass StlHashTable~V~\n\
    class StlHashTableKey {\n  std::unorderd_map~String,FieldHashtable*~\n}\nclass\
    \ StlHashTableField {\n  std::unorderd_map~String,const char*~\n}\nclass LockStlHashtable~T~\n\
    class LockStlHashtableKey {\n  std::mutex\n}\nclass LockStlHashtableField {\n\
    \  std::mutex\n}\n\nDBFactory ..&gt; LockStlDB : create\nLockStlDB *-- LockStlHashtableKey\n\
    LockStlHashtableKey o-- LockStlHashtableField\nLockStlDB ..&gt; LockStlHashtableField\
    \ : create\n\nDB &lt;|.. HashtableDB\nHashtableDB &lt;|.. LockStlDB\nStringHashtable\
    \ &lt;|.. StlHashTable\nStlHashTable &lt;|--LockStlHashtable\n\nStringHashtable\
    \ .. FieldHashtable : instantiation\nStringHashtable .. KeyHashtable : instantiation\n\
    StlHashTable .. StlHashTableKey : instantiation\nStlHashTable .. StlHashTableField\
    \ : instantiation\nLockStlHashtable .. LockStlHashtableKey : instantiation\nLockStlHashtable\
    \ .. LockStlHashtableField : instantiation\n\nStlHashTableKey  &lt;|-- LockStlHashtableKey\n\
    StlHashTableField  &lt;|-- LockStlHashtableField\nKeyHashtable &lt;|.. StlHashTableKey\n\
    FieldHashtable &lt;|.. StlHashTableField\n\nHashtableDB ..&gt; KeyHashtable :\
    \ use\nHashtableDB ..&gt; FieldHashtable : use\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667533964.0
range3/ucx_practice:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/ucx_practice
  latest_release: null
  readme: '<h1><a id="user-content-ucx_practice" class="anchor" aria-hidden="true"
    href="#ucx_practice"><span aria-hidden="true" class="octicon octicon-link"></span></a>ucx_practice</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666601300.0
ravisiv/PhishingEmailDetection:
  data_format: 2
  description: null
  filenames:
  - src/spack/capstone/spack.yaml
  - src_simple/spack/capstone/spack.yaml
  full_name: ravisiv/PhishingEmailDetection
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/67842939/190537013-b30595b5-fb57-4246-adf1-c96ec88a805c.png"><img
    width="857" alt="image" src="https://user-images.githubusercontent.com/67842939/190537013-b30595b5-fb57-4246-adf1-c96ec88a805c.png"
    style="max-width: 100%;"></a></p>

    <p><strong>Abstract.</strong> Phishing emails are a primary mode of entry for
    attackers

    into an organization. A successful phishing attempt leads to

    unauthorized access to sensitive information and systems. However,

    automatically identifying phishing emails is often difficult since many

    phishing emails have composite features such as body text and metadata

    that are nearly indistinguishable from valid emails. This paper presents

    a novel machine learning-based framework, the DARTH framework, that

    characterizes and combines multiple models, with one model for each

    individual composite feature, that enables the accurate identification

    of phishing emails. The framework analyses each composite feature

    independently utilizing a multi-faceted approach using Natural Language

    Processing (NLP) and neural network-based techniques and combines the

    results of these analysis to classify the emails as malicious or

    legitimate. Utilizing the framework on more than 150,000 emails and

    training data from multiple sources including the authors'' personal

    emails and phishtank.com resulted in the precision (correct

    identification of malicious observations to the total prediction of

    malicious observations) of 99.97% with an f-score of 99.98% and

    accurately identifying phishing emails 99.98% of the time. Utilizing

    multiple machine learning techniques combined in an ensemble approach

    across a range of composite features yields highly accurate

    identification of phishing emails.</p>

    <p>Download the full <a href="https://github.com/ravisiv/PhishingEmailDetection/raw/main/Phishing%20Detection%20using%20ML%20and%20NLP.docx">paper</a>.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1658945123.0
robertu94/poorjit:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/poorjit
  latest_release: null
  readme: '<h1><a id="user-content-poorjit" class="anchor" aria-hidden="true" href="#poorjit"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>poorjit</h1>

    <p>A poor man''s jit for C++ for when you want to instantiate and call templates
    at

    runtime. Is there a more efficient way to do this? sure, but this is ~100 lines

    of code I wrote in less than an afternoon. Almost certainly only works on Linux

    and with either clang or g++.</p>

    <p>See <code>test</code> for a usage example.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1668235142.0
robertu94/sz-zfp-zchecker:
  data_format: 2
  description: container for the ISC/SC compression tutorial
  filenames:
  - spack.yaml
  full_name: robertu94/sz-zfp-zchecker
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1652997619.0
salotz/scoot:
  data_format: 2
  description: Boost/STL for Scopes
  filenames:
  - spack.yaml
  full_name: salotz/scoot
  latest_release: null
  readme: "<h1><a id=\"user-content-scoot\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#scoot\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>scoot</h1>\n\
    <h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>The module is under <code>src/scoot</code>.\
    \ You can copy this subtree into your\nproject and then add it to the <code>package.path</code>\
    \ in your Scopes\n<code>_project.sc</code> file.</p>\n<h3><a id=\"user-content-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#with-spack\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>With Spack</h3>\n<p>This module\
    \ is available as the <code>scoot</code> package in the\n<a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> repository. This will pull in the necessary dependencies\nincluding\
    \ Scopes.</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spack install\
    \ scoot</pre></div>\n<p>See the <a href=\"https://github.com/salotz/snailpacks\"\
    >snailpacks</a> documentation for more best practices of installing.</p>\n<h2><a\
    \ id=\"user-content-development-environment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development-environment\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Development Environment</h2>\n<p>We use <a href=\"\
    https://spack.io/\" rel=\"nofollow\">Spack</a> to install dependencies. First\
    \ install Spack.</p>\n<p>Then you'll need our custom repo of build recipes:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  mkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">`</span>/.spack/repos</span>\n<span class=\"pl-s\"\
    >  git clone git@github.com:salotz/snailpacks.git <span class=\"pl-pds\">`</span></span>/.spack/repos/snailpacks\n\
    \  spack repo add <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc., this will create this and\ninstall the packages:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  make init</pre></div>\n\
    <p>Then you can activate the environment to get started:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  spacktivate <span class=\"pl-c1\">.</span></pre></div>\n\
    <p>Run some commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> run the sanity entrypoint</span>\n\
    make sanity\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> run the tests</span>\n\
    make <span class=\"pl-c1\">test</span></pre></div>\n<p>To exit the environment\
    \ (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1661112922.0
salotz/scopes-demos:
  data_format: 2
  description: null
  filenames:
  - 002_pong/spack.yaml
  - template/{{name}}/spack.yaml
  - 001_chipmunk2d-hello-world/spack.yaml
  full_name: salotz/scopes-demos
  latest_release: null
  readme: "<h2><a id=\"user-content-running-the-demos\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#running-the-demos\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Running the Demos</h2>\n<p>You will need Spack installed\
    \ as well as the <a href=\"\">snailpacks</a> repo. The\nquick bootstrap script\
    \ should be enough to get going if you don't have\nthis installed already:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>curl --proto <span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>=https<span class=\"pl-pds\">'</span></span>\
    \ --tlsv1.2 -sSf https://raw.githubusercontent.com/salotz/snailpacks/master/bootstrap.sh\
    \ <span class=\"pl-k\">|</span> sh</pre></div>\n<p>Then for each demo you can\
    \ build the environment, activate it, and run\nthem.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  <span class=\"pl-c1\">cd</span> XXX_demo-name\n\
    \  make env\n  spacktivate <span class=\"pl-c1\">.</span>\n  make run</pre></div>\n\
    <h2><a id=\"user-content-creating-a-new-demo\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#creating-a-new-demo\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Creating a New Demo</h2>\n<p>You can use the template\
    \ for a quick start (requires <code>copier</code> &gt; 6):</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>copier template</pre></div>\n<p>To update\
    \ the</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657842137.0
salotz/scopes-lib_copier-template:
  data_format: 2
  description: Copier template for a Scopes library
  filenames:
  - template/spack.yaml
  full_name: salotz/scopes-lib_copier-template
  latest_release: null
  readme: "<h1><a id=\"user-content-project-template-for-a-scopes-lang-library\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#project-template-for-a-scopes-lang-library\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Project\
    \ Template for a Scopes Lang Library</h1>\n<p>This is a project template generator\
    \ and updater using the\n<a href=\"https://github.com/copier-org/copier/\">copier</a>\
    \ tool for creating libraries for the <a href=\"http://scopes.rocks\" rel=\"nofollow\"\
    >Scopes</a> programming language.</p>\n<p>Please install from the latest copier\
    \ for this to work, not the latest\nstable release. Currently I am using\n<a href=\"\
    https://github.com/pypa/pipx\">pipx</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pipx install copier</pre></div>\n<h2><a id=\"user-content-generating-and-updating-a-project\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#generating-and-updating-a-project\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Generating\
    \ and Updating a Project</h2>\n<p>Then you can generate your project:</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>copier <span class=\"pl-s\"\
    ><span class=\"pl-pds\">'</span>gh:salotz/scopes-lib_copier-template<span class=\"\
    pl-pds\">'</span></span> name-of-folder</pre></div>\n<p>This should generate something\
    \ like the following (<code>repo_name = my-lib</code>):</p>\n<pre><code>name-of-folder\n\
    \u251C\u2500\u2500 __env.sc\n\u251C\u2500\u2500 Makefile\n\u251C\u2500\u2500 README.md\n\
    \u251C\u2500\u2500 spack.yaml\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500\
    \ my-lib\n        \u251C\u2500\u2500 init.sc\n        \u2514\u2500\u2500 ...\n\
    </code></pre>\n<p>You can update the project with:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> name-of-folder\n\
    copier update</pre></div>\n<p>See documentation of copier for more details.</p>\n\
    <h2><a id=\"user-content-development-environment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development-environment\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Development Environment</h2>\n<p>See the docs in <code>template/README.md.jinja</code>\
    \ that will be generated for\neach project.</p>\n<h2><a id=\"user-content-libraries-using-this-template\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#libraries-using-this-template\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Libraries\
    \ Using this Template</h2>\n<ul>\n<li><a href=\"https://github.com/salotz/raylib-scopes\"\
    >scopes-raylib</a></li>\n<li><a href=\"https://github.com/salotz/scopes-chipmunk2d\"\
    >scopes-chipmunk2d</a></li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - copier-template
  - scopes-lang
  updated_at: 1648781021.0
salotz/snailpacks:
  data_format: 2
  description: Spack repo for multimedia development
  filenames:
  - examples/c-meson/spack.yaml
  - examples/c-wgpu/spack.yaml
  full_name: salotz/snailpacks
  latest_release: null
  stargazers_count: 1
  subscribers_count: 1
  topics:
  - spack
  - spack-repo
  - scopes-lang
  - multimedia
  - game-development
  - package-manager
  - development-environment
  updated_at: 1648089720.0
sayefsakin/auto_profiler:
  data_format: 2
  description: null
  filenames:
  - py_src/spack.yaml
  full_name: sayefsakin/auto_profiler
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1659512207.0
simonpintarelli/acclapack-tests:
  data_format: 2
  description: null
  filenames:
  - spack-envs/cuda/spack.yaml
  - spack-envs/rocm/spack.yaml
  full_name: simonpintarelli/acclapack-tests
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667393188.0
simonpintarelli/nlcglib:
  data_format: 2
  description: Nonlinear CG methods for wave-function optimization in DFT
  filenames:
  - spack-envs/q-e-sirius-lumi/spack.yaml
  full_name: simonpintarelli/nlcglib
  latest_release: v0.9.1
  stargazers_count: 5
  subscribers_count: 2
  topics: []
  updated_at: 1657259472.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-22.05/spack.yaml
  - NERSC/perlmutter/e4s-21.11/ci/spack.yaml
  - NERSC/perlmutter/e4s-21.11/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 43
  subscribers_count: 24
  topics: []
  updated_at: 1663345202.0
srini009/serviz:
  data_format: 2
  description: Ascent visualization microservice built using the Mochi software stack
  filenames:
  - spack_laptop.yaml
  - spack.yaml
  full_name: srini009/serviz
  latest_release: v0.1.0
  readme: '<h1><a id="user-content-serviz-a-shared-in-situ-visualization-service"
    class="anchor" aria-hidden="true" href="#serviz-a-shared-in-situ-visualization-service"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SERVIZ: A Shared In
    Situ Visualization Service</h1>

    <p>This is an experimental repo implementing a distributed Ascent visualization
    microservice.</p>

    <p>Inline and in transit visualization have arisen as popular models of in situ
    visualization for high performance computing (HPC) applications. Inline visualization
    is invoked through a library call on the HPC application (simulation code), while
    in transit methods involve the invocation of the visualization module on in transit
    resources. Compared to inline methods, in transit methods have the flexibility
    to run at a lower level of concurrency than the simulation code, allowing them
    to offer better efficiency for the visualization operation. The state-of-the-art
    in transit schemes are limited to employing a dedicated in transit resource for
    every HPC application.

    This results in significant idle time on the in transit resource and severely
    limits the cost savings that can be achieved over the inline model.

    This research proposes that a single, in transit visualization service be shared
    amongst multiple HPC applications to make efficient use of the in transit resources
    by reducing the idle time. We realize this idea through SERVIZ, a shared in transit
    visualization service. SERVIZ achieves cost savings of up to 40% over inline (at
    scale) and up to 4x reduction in idle time compared to a dedicated in transit
    implementation.

    In all, the results from this work identify that a shared in transit resource
    is an attractive approach for cost efficiency.</p>

    <p>SERVIZ is a hybrid MPI + RPC visualization program that can be partitioned
    into multiple "instances" that are each capable

    of serving multiple clients simultaneously. RPC is used to transfer simulation
    data to the SERVIZ instance, and MPI is subsequently used to

    parallelize the visualization operation.

    <a target="_blank" rel="noopener noreferrer" href="SERVIZ.svg"><img src="SERVIZ.svg"
    alt="SERVIZ" style="max-width: 100%;"></a></p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1649894816.0
srini009/symbiomon:
  data_format: 2
  description: SYMBIOMON Monitoring Microservice
  filenames:
  - spack.yaml
  full_name: srini009/symbiomon
  latest_release: null
  readme: '<p>SYMBIOMON is a prototype distributed, metric monitoring service designed

    for use on HPC systems. Internally, SYMBIOMON employs a time-series

    data model and is composed of three microservice components:</p>

    <ol>

    <li>COLLECTOR: Exposes the main metric API.</li>

    <li>AGGREGATOR: Distributed microservice component that stores aggregated (reduced)
    time-series data.</li>

    <li>REDUCER: Distributed microservice component that performs a global reduction
    on partially aggregated time-series data.

    Additionally, it makes this globally reducted value available for use in adapting
    distributed components.</li>

    </ol>

    <p>An illustration of the SYMBIOMON design is presented below:

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/10570459/144708286-da263116-a128-47d6-9102-800bcd2838c4.png"><img
    src="https://user-images.githubusercontent.com/10570459/144708286-da263116-a128-47d6-9102-800bcd2838c4.png"
    alt="SYMBIOMON_Conceptual_Illustration(7)" style="max-width: 100%;"></a></p>

    <p>Further detailed information can be found here: <a href="https://docs.google.com/presentation/d/1SNAM1QaeQYSoRwDJfTa7bCO2IvcppCzPPFDCAUdALlU/edit?usp=sharing"
    rel="nofollow">https://docs.google.com/presentation/d/1SNAM1QaeQYSoRwDJfTa7bCO2IvcppCzPPFDCAUdALlU/edit?usp=sharing</a></p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1653524013.0
supercontainers/sc-tutorials:
  data_format: 2
  description: SC Tutorials
  filenames:
  - exercises/spack_containerize/spack.yaml
  full_name: supercontainers/sc-tutorials
  latest_release: null
  readme: '<h1><a id="user-content-getting-started-with-containers-on-hpc" class="anchor"
    aria-hidden="true" href="#getting-started-with-containers-on-hpc"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Getting Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/sc-tutorials/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2><a id="user-content-hpc-containers-tutorial-session" class="anchor" aria-hidden="true"
    href="#hpc-containers-tutorial-session"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>HPC Containers Tutorial Session</h2>

    <p><a target="_blank" rel="noopener noreferrer" href="fig/ecp.jpg"><img src="fig/ecp.jpg"
    width="200" style="max-width: 100%;"></a><a target="_blank" rel="noopener noreferrer"
    href="fig/pawsey.png"><img src="fig/pawsey.png" width="200" style="max-width:
    100%;"></a><a target="_blank" rel="noopener noreferrer" href="fig/redhat.png"><img
    src="fig/redhat.png" width="200" style="max-width: 100%;"></a></p>

    <h2><a id="user-content-details" class="anchor" aria-hidden="true" href="#details"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Full-day Tutorial Session</p>

    <p>Venue: Supercomputing Conference (SC 22)</p>

    <p>Date: Sunday November 13, 2022 8:30am - 5pm Central Standard Time (GMT -6)</p>

    <p>Location: Dallas TX, USA</p>

    <p>Link: <a href="https://sc22.supercomputing.org/presentation/?id=tut111&amp;sess=sess201"
    rel="nofollow">SC 2022 Tutorial Details</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2><a id="user-content-abstract" class="anchor" aria-hidden="true" href="#abstract"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Within just the past few years, the use of containers has revolutionized the
    way in which industries and enterprises have developed and deployed computational
    software and distributed systems. The containerization model has gained traction
    within the HPC community as well with the promise of improved reliability, reproducibility,
    portability, and levels of customization that were previously not possible on
    supercomputers. This adoption has been enabled by a number of HPC Container runtimes
    that have emerged including Singularity, Shifter, Enroot, Charliecloud and others.</p>

    <p>This hands-on tutorial looks to train users on the usability of containers
    on HPC resources. We will provide a detailed background on Linux containers, along
    with introductory hands-on experience building a container image, sharing the
    container and running it on a HPC cluster. Furthermore, the tutorial will provide
    more advanced information on how to run MPI-based and GPU-enabled HPC applications,
    how to optimize I/O intensive workflows, and how to setup GUI enabled interactive
    sessions. Cutting-edge examples will include machine learning and bioinformatics.
    Users will leave the tutorial with a solid foundational understanding of how to
    utilize containers with HPC resources through Shifter and Singularity, as well
    as an in-depth knowledge to deploy custom containers on their own resources.</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>Please consult the website for prerequisites and recommended setup steps.</p>

    <h2><a id="user-content-questions" class="anchor" aria-hidden="true" href="#questions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-schedule---autogenerated-from-the-metadata" class="anchor"
    aria-hidden="true" href="#schedule---autogenerated-from-the-metadata"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Schedule - Autogenerated from the metadata</h2>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics: []
  updated_at: 1649669614.0
sxs-collaboration/spectre:
  data_format: 2
  description: SpECTRE is a code for multi-scale, multi-physics problems in astrophysics
    and gravitational physics.
  filenames:
  - support/DevEnvironments/spack.yaml
  full_name: sxs-collaboration/spectre
  latest_release: v2022.10.04
  readme: "<p><a href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\
    ><img src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\"\
    \ alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\"\
    \ alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/actions\"\
    ><img src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/sxs-collaboration/spectre\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2022.10.04\"\
    ><img src=\"https://camo.githubusercontent.com/1f64d620eabc0c26a3b41afd2ba166ec866b80a724fba4a41ee37f84b639988e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032322e31302e30342d696e666f726d6174696f6e616c\"\
    \ alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2022.10.04-informational\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.7144771\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/291c336afca1c9cbf95471dfe4f3061dafc01fbe244d6a814df8a0b0cde4ea02/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e373134343737312e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.7144771.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-what-is-spectre\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#what-is-spectre\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>What is SpECTRE?</h2>\n<p>SpECTRE\
    \ is an open-source code for multi-scale, multi-physics problems\nin astrophysics\
    \ and gravitational physics. In the future, we hope that\nit can be applied to\
    \ problems across discipline boundaries in fluid\ndynamics, geoscience, plasma\
    \ physics, nuclear physics, and\nengineering. It runs at petascale and is designed\
    \ for future exascale\ncomputers.</p>\n<p>SpECTRE is being developed in support\
    \ of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into\
    \ the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae,\
    \ and\ngamma-ray bursts.</p>\n<h2><a id=\"user-content-citing-spectre\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#citing-spectre\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Citing SpECTRE</h2>\n<p>Please cite\
    \ SpECTRE in any publications that make use of its code or data. Cite\nthe latest\
    \ version that you use in your publication. The DOI for this version\nis:</p>\n\
    <ul>\n<li>DOI: <a href=\"https://doi.org/10.5281/zenodo.7144771\" rel=\"nofollow\"\
    >10.5281/zenodo.7144771</a>\n</li>\n</ul>\n<p>You can cite this BibTeX entry in\
    \ your publication:</p>\n\n\n<div class=\"highlight highlight-text-bibtex\"><pre><span\
    \ class=\"pl-k\">@software</span>{<span class=\"pl-en\">spectrecode</span>,\n\
    \    <span class=\"pl-s\">author</span> = <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Deppe, Nils and Throwe, William and Kidder, Lawrence E. and\
    \ Vu,</span>\n<span class=\"pl-s\">Nils L. and H\\'ebert, Fran\\c{c}ois and Moxon,\
    \ Jordan and Armaza, Crist\\'obal and</span>\n<span class=\"pl-s\">Bonilla, Gabriel\
    \ S. and Kim, Yoonsoo and Kumar, Prayush and Lovelace, Geoffrey</span>\n<span\
    \ class=\"pl-s\">and Macedo, Alexandra and Nelli, Kyle C. and O'Shea, Eamonn and\
    \ Pfeiffer, Harald</span>\n<span class=\"pl-s\">P. and Scheel, Mark A. and Teukolsky,\
    \ Saul A. and Wittek, Nikolas A. and</span>\n<span class=\"pl-s\">others<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">title</span> =\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\\texttt{SpECTRE v2022.10.04}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">version</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2022.10.04<span class=\"\
    pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">publisher</span> = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>Zenodo<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">doi</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>10.5281/zenodo.7144771<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">url</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>https://spectre-code.org<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">howpublished</span> =\n<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>\\href{https://doi.org/10.5281/zenodo.7144771}{10.5281/zenodo.7144771}<span\
    \ class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-s\">license</span>\
    \ = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MIT<span class=\"pl-pds\"\
    >\"</span></span>,\n    <span class=\"pl-s\">year</span> = <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>2022<span class=\"pl-pds\">\"</span></span>,\n\
    \    <span class=\"pl-s\">month</span> = <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>10<span class=\"pl-pds\">\"</span></span>\n}</pre></div>\n\n<p>To aid\
    \ reproducibility of your scientific results with SpECTRE, we recommend you\n\
    keep track of the version(s) you used and report this information in your\npublication.\
    \ We also recommend you supply the YAML input files and, if\nappropriate, any\
    \ additional C++ code you wrote to compile SpECTRE executables as\nsupplemental\
    \ material to the publication.</p>\n<p>See our <a href=\"https://spectre-code.org/publication_policies.html\"\
    \ rel=\"nofollow\">publication policy</a>\nfor more information.</p>\n<h2><a id=\"\
    user-content-viewing-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #viewing-documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Viewing Documentation</h2>\n<p>The documentation can be viewed at\
    \ <a href=\"https://spectre-code.org/\" rel=\"nofollow\">https://spectre-code.org/</a>.</p>\n"
  stargazers_count: 117
  subscribers_count: 14
  topics: []
  updated_at: 1668095778.0
tgamblin/cali-container:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: tgamblin/cali-container
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667175253.0
trilinos/ForTrilinos:
  data_format: 2
  description: ForTrilinos provides portable object-oriented Fortran interfaces to
    Trilinos C++ packages.
  filenames:
  - scripts/spack.yaml
  full_name: trilinos/ForTrilinos
  latest_release: v2.1.0
  readme: '<h1><a id="user-content-fortrilinos" class="anchor" aria-hidden="true"
    href="#fortrilinos"><span aria-hidden="true" class="octicon octicon-link"></span></a>ForTrilinos</h1>

    <p><a href="https://cloud.cees.ornl.gov/jenkins-ci/job/ForTrilinos-master-continuous"
    rel="nofollow"><img src="https://camo.githubusercontent.com/857fffb6b672ed62abe998b01a81c3932111fcba10541918cb2f938f414440e6/68747470733a2f2f636c6f75642e636565732e6f726e6c2e676f762f6a656e6b696e732d63692f6275696c645374617475732f69636f6e3f6a6f623d466f725472696c696e6f732d6d61737465722d636f6e74696e756f7573"
    alt="Build Status" data-canonical-src="https://cloud.cees.ornl.gov/jenkins-ci/buildStatus/icon?job=ForTrilinos-master-continuous"
    style="max-width: 100%;"></a>

    <a href="http://fortrilinos.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/e261f09cffcfcbf7e647f541614bf7912e3018ccd3a085f035a1219a854f5867/687474703a2f2f72656164746865646f63732e6f72672f70726f6a656374732f666f727472696c696e6f732f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="http://readthedocs.org/projects/fortrilinos/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/trilinos/ForTrilinos/branch/develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/fbeea009914f87218441791dba76a1a512b7c287749f94ff47d7b76f49902d23/68747470733a2f2f636f6465636f762e696f2f67682f7472696c696e6f732f466f725472696c696e6f732f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/trilinos/ForTrilinos/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a></p>

    <p><a href="http://trilinos.org/packages/fortrilinos" rel="nofollow">ForTrilinos</a>
    is a part of the <a href="http://trilinos.org" rel="nofollow">Trilinos</a> project
    and provides object-oriented Fortran interfaces to Trilinos C++ packages.</p>

    <p>This is the new effort to provide Fortran interfaces to Trilinos through

    automatic code generation using SWIG. The previous effort (ca. 2008-2012) can

    be obtained by downloading Trilinos releases prior to 12.12. See <a href="https://fortrilinos.readthedocs.io/en/latest/install.html#version-compatibility"
    rel="nofollow">the

    documentation</a> for details on version compatibility.</p>

    <h2><a id="user-content-provided-functionality" class="anchor" aria-hidden="true"
    href="#provided-functionality"><span aria-hidden="true" class="octicon octicon-link"></span></a>Provided
    functionality</h2>

    <p>ForTrilinos provides Fortran interfaces for the following capabilities:</p>

    <ul>

    <li>Parameter lists and XML parsers (through Teuchos);</li>

    <li>Distributed linear algebra object including sparse graphs, sparse matrices,
    and dense vectors (through Tpetra);</li>

    <li>Linear solvers and preconditioners (through Stratimikos, Ifpack2, Belos, MueLu);</li>

    <li>Eigen solvers (through Anasazi).</li>

    </ul>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <ul>

    <li>

    <p><a href="https://fortrilinos.readthedocs.org" rel="nofollow">Documentation</a></p>

    </li>

    <li>

    <p><a href="https://trilinos.github.io/ForTrilinos/" rel="nofollow">Summary</a></p>

    </li>

    </ul>

    <h2><a id="user-content-installing-fortrilinos" class="anchor" aria-hidden="true"
    href="#installing-fortrilinos"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing
    ForTrilinos</h2>

    <p>Please consult the documentation available <a href="https://fortrilinos.readthedocs.io/en/latest/install.html"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-questions-bug-reporting-and-issue-tracking" class="anchor"
    aria-hidden="true" href="#questions-bug-reporting-and-issue-tracking"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Questions, Bug Reporting, and Issue Tracking</h2>

    <p>Questions, bug reporting and issue tracking are provided by GitHub. Please

    report all bugs by creating a new issue with the bug tag. You can ask

    questions by creating a new issue with the question tag.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>We encourage you to contribute to ForTrilinos! Please check out the

    <a href="CONTRIBUTING.md">guidelines</a> about how to proceed.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>ForTrilinos is licensed under a BSD license.</p>

    '
  stargazers_count: 24
  subscribers_count: 10
  topics:
  - trilinos
  - fortran
  - swig
  - scientific-computing
  updated_at: 1654781824.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/r-stack/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<h1><a id="user-content-spack--uc-davis" class="anchor" aria-hidden="true"
    href="#spack--uc-davis"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    @ UC Davis</h1>

    <h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters" class="anchor"
    aria-hidden="true" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack repos and configs
    for UC Davis HPCCF Clusters</h2>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666297706.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - spack-environments/csd3-skylake/compute-node/spack.yaml
  - spack-environments/csd3-icelake/compute-node/spack.yaml
  - spack-environments/archer2/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1><a id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#excalibur-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks and regression tests\
    \ for the ExCALIBUR project.</p>\n<p>These benchmarks are based on a similar project\
    \ by\n<a href=\"https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2><a\
    \ id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h2>\n\
    <h3><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><em><strong>Note</strong>: in some HPC facilities there may be already a central\
    \ Spack\ninstallation available.  In principle you should be able to use that\
    \ one (you\nonly need to have <code>spack</code> in the <code>PATH</code>), but\
    \ you may need an up-to-date version\nof Spack in order to install some packages.\
    \  Instructions below show you how to\ninstall Spack locally.</em></p>\n<p><a\
    \ href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager specifically\
    \ designed for HPC\nfacilities.  Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall the latest version of\
    \ Spack.</p>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable.  This\
    \ can be achieved for instance by running\nthe commands to get shell support described\
    \ in Spack documentation, which you\ncan also add to your shell init script to\
    \ do it automatically in every session.\nFor example, if you use a shell of the\
    \ family bash/zsh/sh you can add to your\ninit script:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRac projects.  If\
    \ you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system, if known, otherwise it will automatically\ncreate a very basic environment.</p>\n\
    <h3><a id=\"user-content-reframe\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #reframe\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ReFrame</h3>\n\
    <p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\" rel=\"nofollow\"\
    >ReFrame</a> is a high-level\nframework for writing regression tests for HPC systems.\
    \  For our tests we\nrequire ReFrame 3.11.0.  Follow the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall this package.  Note\
    \ that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a\
    \ specific module to have this version of Python available.</p>\n<p>We provide\
    \ a ReFrame configuration file with the settings of some systems that\nare part\
    \ of the ExCALIBUR project.  You can point ReFrame to this file by\nsetting the\n\
    <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILE</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILE=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${PWD}</span>/reframe_config.py<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>If you want to use a different ReFrame configuration file, for example because\n\
    you use a different system, you can set this environment variable to the path\
    \ of\nthat file.</p>\n<p><strong>Note</strong>: in order to use the Spack build\
    \ system in ReFrame, the <code>spack</code>\nexecutable must be in the <code>PATH</code>,\
    \ also on the computing nodes of a cluster, if\nyou want to run your benchmarks\
    \ on them.  Note that by default ReFrame uses</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a>, which would not load\nthe user's init script.  If you have added\
    \ Spack to your <code>PATH</code> within your init\nscript, you may want to set\
    \ the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ in order to make ReFrame use</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash\
    \ -l</span></pre></div>\n<p>as shebang line, instead.</p>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<p>Once you have set up\
    \ Spack and ReFrame, you can execute a benchmark with</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/BENCH_NAME -r --performance-report</pre></div>\n\
    <p>where <code>apps/BENCH_NAME</code> is the directory where the benchmark is.\
    \  The command\nabove supposes you have the program <code>reframe</code> in your\
    \ PATH, if it is not the\ncase you can also call <code>reframe</code> with its\
    \ relative or absolute path.  For\nexample, to run the Sombrero benchmark in the\
    \ <code>apps/sombrero</code> directory you can\nuse</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>reframe -c apps/sombrero -r --performance-report</pre></div>\n\
    <p>For benchmark using the Spack build system, the tests define a default Spack\
    \ specification\nto be installed in the environment, but users can change it when\
    \ invoking ReFrame on the\ncommand line with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c apps/sombrero -r --performance-report -S\
    \ spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<p>Note that the <code>-S</code>\
    \ option can be used to set from the command line on a per-job\nbasis the built-in\
    \ fields of ReFrame regressions classes, e.g.\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.variables\"\
    \ rel=\"nofollow\"><code>variables</code></a>,\nwhich controls the environment\
    \ variables used in a job.  For example</p>\n<pre><code>reframe -c apps/sombrero\
    \ -r --performance-report -S variables=OMP_PLACES:threads\n</code></pre>\n<p>runs\
    \ the <code>apps/sombrero</code> benchmark setting the environment variable <code>OMP_PLACES</code>\n\
    to <code>threads</code>.</p>\n<h3><a id=\"user-content-selecting-system-and-queue-access-options\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#selecting-system-and-queue-access-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  You can always use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3><a id=\"user-content-unsupported-systems\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#unsupported-systems\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Unsupported systems</h3>\n<p>The\
    \ configuration provided in <a href=\"./reframe_config.py\"><code>reframe_config.py</code></a>\
    \ lets you run the\nbenchmarks on systems for which the configuration has been\
    \ already contributed.  However you\ncan still use this framework on any system\
    \ by choosing the \"generic\" system with <code>--system generic</code>, or using\
    \ your own ReFrame configuration.  Note, however, that if you use the\n\"generic\"\
    \ system, ReFrame will not know anything about the queue manager of your system,\
    \ if\nany, or the MPI launcher.  For the benchmarks using the Spack build system,\
    \ if you choose\nthe \"generic\" system, a new empty Spack environment will be\
    \ automatically created in\n<code>spack-environments/generic</code>.  In any case,\
    \ you can always make the benchmarks use a\ndifferent Spack environment by setting\
    \ the environment variable <code>EXCALIBUR_SPACK_ENV</code>\ndescribed above.</p>\n\
    <h2><a id=\"user-content-contributing-new-systems-or-benchmarks\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#contributing-new-systems-or-benchmarks\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\n\
    <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 5
  subscribers_count: 7
  topics: []
  updated_at: 1667839527.0
uturuncoglu/testing:
  data_format: 2
  description: It is used for component testing and GitHub Action implementation
  filenames:
  - spack.yaml
  full_name: uturuncoglu/testing
  latest_release: null
  readme: '<h1><a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>testing</h1>

    <p>It is used for component testing and GitHub Action implementation</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657212117.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/lassen/spack.yaml
  - platformFiles/polaris/gcc-11.2.0/spack.yaml
  - platformFiles/crusher/PrgEnv-cray/spack.yaml
  - platformFiles/crusher/PrgEnv-gnu/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1><a id="user-content-useful-supplementary-materials-for-installing-the-xsdk"
    class="anchor" aria-hidden="true" href="#useful-supplementary-materials-for-installing-the-xsdk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful supplementary
    materials for installing the xSDK</h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 4
  subscribers_count: 8
  topics: []
  updated_at: 1637108321.0
