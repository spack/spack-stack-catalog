AMReX-Codes/pyamrex:
  data_format: 2
  description: '[Experimental] AMReX Python Bindings'
  filenames:
  - spack.yaml
  full_name: AMReX-Codes/pyamrex
  latest_release: null
  readme: '<h1><a id="user-content-pyamrex" class="anchor" aria-hidden="true" href="#pyamrex"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>pyAMReX</h1>

    <p><a href="https://www.python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e"
    alt="Python3" title="Python3 API" data-canonical-src="https://img.shields.io/badge/language-Python3-yellowgreen"
    style="max-width: 100%;"></a> <a target="_blank" rel="noopener noreferrer nofollow"
    href="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"><img
    src="https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e"
    alt="Python3 API: Pre-Alpha" title="Status: Pre-Alpha" data-canonical-src="https://img.shields.io/badge/phase-pre--alpha-yellowgreen"
    style="max-width: 100%;"></a>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License AMReX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a><br>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development"
    alt="linux" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development"
    alt="macos" style="max-width: 100%;"></a>

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"><img
    src="https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development"
    alt="windows" style="max-width: 100%;"></a></p>

    <p>The Python binding pyAMReX bridges the worlds between block-structured codes
    and data science: it provides zero-copy application GPU data access for AI/ML,
    in situ analysis, application coupling and enables rapid, massively parallel prototyping.</p>

    <p>pyAMReX is part of AMReX.

    Due to its <strong>highly experimental</strong> nature, we develop it currently
    in a separate respository.</p>

    <p>We will add further information here once first development versions are ready
    for testing.</p>

    <h2><a id="user-content-users" class="anchor" aria-hidden="true" href="#users"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Users</h2>

    <p><em>to do</em></p>

    <ul>

    <li>pip/pypa</li>

    <li>conda-forge</li>

    <li>spack</li>

    <li>brew</li>

    <li>...</li>

    </ul>

    <h3><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h3>

    <p><em>to do</em></p>

    <div class="highlight highlight-source-python"><pre><span class="pl-k">import</span>
    <span class="pl-s1">amrex</span>


    <span class="pl-s1">small_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>()

    <span class="pl-s1">big_end</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Int_Vect</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>,
    <span class="pl-c1">4</span>)


    <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">amrex</span>.<span
    class="pl-v">Box</span>(<span class="pl-s1">small_end</span>, <span class="pl-s1">big_end</span>)

    <span class="pl-en">print</span>(<span class="pl-s1">b</span>)


    <span class="pl-c"># ...</span></pre></div>

    <h2><a id="user-content-developers" class="anchor" aria-hidden="true" href="#developers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Developers</h2>

    <p>If you are new to CMake, <a href="https://hsf-training.github.io/hsf-training-cmake-webpage/"
    rel="nofollow">this short tutorial</a> from the HEP Software foundation is the
    perfect place to get started with it.</p>

    <p>If you just want to use CMake to build the project, jump into sections <em>1.
    Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>

    <h3><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

    <p>pyAMReX depends on the following popular third party software.</p>

    <ul>

    <li>a mature <a href="https://en.wikipedia.org/wiki/C%2B%2B17" rel="nofollow">C++17</a>
    compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer</li>

    <li><a href="https://cmake.org" rel="nofollow">CMake 3.20.0+</a></li>

    <li>

    <a href="https://amrex-codes.github.io" rel="nofollow">AMReX <em>development</em></a>:
    we automatically download and compile a copy of AMReX</li>

    <li>

    <a href="https://github.com/pybind/pybind11/">pybind11</a> 2.10.1+: we automatically
    download and compile a copy of pybind11 (<a href="https://github.com/pybind/pybind11/blob/master/LICENSE">new
    BSD</a>)

    <ul>

    <li>

    <a href="https://python.org" rel="nofollow">Python</a> 3.7+</li>

    <li>

    <a href="https://numpy.org" rel="nofollow">Numpy</a> 1.15+</li>

    </ul>

    </li>

    </ul>

    <p>Optional dependencies include:</p>

    <ul>

    <li>

    <a href="https://www.openmp.org" rel="nofollow">mpi4py</a> 2.1+: for multi-node
    and/or multi-GPU execution</li>

    <li>

    <a href="https://ccache.dev" rel="nofollow">CCache</a>: to speed up rebuilds (for
    CUDA support, needs 3.7.9+ and 4.2+ is recommended)</li>

    <li>further <a href="https://github.com/AMReX-Codes/amrex/">optional dependencies
    of AMReX</a>

    </li>

    <li>

    <a href="https://docs.pytest.org/en/stable/" rel="nofollow">pytest</a> 6.2+: for
    running unit tests</li>

    </ul>

    <p>Optional CUDA-capable dependencies for tests include:</p>

    <ul>

    <li>

    <a href="https://github.com/cupy/cupy#installation">cupy</a> 11.2+</li>

    <li>

    <a href="https://numba.readthedocs.io/en/stable/user/installing.html" rel="nofollow">numba</a>
    0.56+</li>

    <li>

    <a href="https://pytorch.org/get-started/locally/" rel="nofollow">torch</a> 1.12+</li>

    </ul>

    <h3><a id="user-content-install-dependencies" class="anchor" aria-hidden="true"
    href="#install-dependencies"><span aria-hidden="true" class="octicon octicon-link"></span></a>Install
    Dependencies</h3>

    <p>macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate -d <span
    class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span> optional:</span>

    <span class="pl-c"><span class="pl-c">#</span> spack add cuda</span>

    spack install</pre></div>

    <p>(in new terminals, re-activate the environment with <code>spack env activate
    -d .</code> again)</p>

    <p>or macOS/Linux:</p>

    <div class="highlight highlight-source-shell"><pre>brew update

    brew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>

    <p>Now, <code>cmake --version</code> should be at version 3.20.0 or newer.</p>

    <p>Or go:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional:                                    --user</span>

    python3 -m pip install -U pip setuptools wheel

    python3 -m pip install -U cmake</pre></div>

    <p>If you wish to run unit tests, then please install <code>pytest</code></p>

    <div class="highlight highlight-source-shell"><pre>python3 -m pip install -U pytest</pre></div>

    <h3><a id="user-content-configure-your-compiler" class="anchor" aria-hidden="true"
    href="#configure-your-compiler"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configure
    your compiler</h3>

    <p>For example, using the Clang compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CC=<span class="pl-s"><span class="pl-pds">$(</span>which clang<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <p>If you also want to select a CUDA compiler:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CUDACXX=<span class="pl-s"><span class="pl-pds">$(</span>which nvcc<span class="pl-pds">)</span></span>

    <span class="pl-k">export</span> CUDAHOSTCXX=<span class="pl-s"><span class="pl-pds">$(</span>which
    clang++<span class="pl-pds">)</span></span></pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>From the base of the pyAMReX source directory, execute:</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    optional controls (example):</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SPACEDIM=3</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_MPI=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_OMP=ON</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_GPU_BACKEND=CUDA</span>

    <span class="pl-c"><span class="pl-c">#</span>export AMREX_SRC=$PWD/../amrex</span>

    <span class="pl-c"><span class="pl-c">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>


    python3 -m pip install -U -r requirements.txt

    python3 -m pip install -v --force-reinstall --no-deps <span class="pl-c1">.</span></pre></div>

    <p>If you are iterating on builds, it will faster to rely on <code>ccache</code>
    and to let CMake call the <code>pip</code> install logic:</p>

    <div class="highlight highlight-source-shell"><pre>cmake -S <span class="pl-c1">.</span>
    -B build

    cmake --build build --target pip_install -j 8</pre></div>

    <h3><a id="user-content-test" class="anchor" aria-hidden="true" href="#test"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Test</h3>

    <p>After successful installation, you can run the unit tests (assuming <code>pytest</code>
    is

    installed). If <code>AMREX_MPI=ON</code>, then please prepend the following commands
    with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Run all tests</span>

    python3 -m pytest tests/


    <span class="pl-c"><span class="pl-c">#</span> Run tests from a single file</span>

    python3 -m pytest tests/test_intvect.py


    <span class="pl-c"><span class="pl-c">#</span> Run a single test (useful during
    debugging)</span>

    python3 -m pytest tests/test_intvect.py::test_iv_conversions


    <span class="pl-c"><span class="pl-c">#</span> Run all tests, do not capture "print"
    output and be verbose</span>

    python3 -m pytest -s -vvvv tests/</pre></div>

    <h3><a id="user-content-build-options" class="anchor" aria-hidden="true" href="#build-options"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build Options</h3>

    <p>If you are using the pip-driven install, selected <a href="https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake"
    rel="nofollow">AMReX CMake options</a> can be controlled with environment variables:</p>

    <table>

    <thead>

    <tr>

    <th>Environment Variable</th>

    <th>Default &amp; Values</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>AMREX_OMP</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable OpenMP</td>

    </tr>

    <tr>

    <td><code>AMREX_GPU_BACKEND</code></td>

    <td>

    <strong>NONE</strong>/SYCL/CUDA/HIP</td>

    <td>On-node, accelerated GPU backend</td>

    </tr>

    <tr>

    <td><code>AMREX_MPI</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Enable MPI</td>

    </tr>

    <tr>

    <td><code>AMREX_PRECISION</code></td>

    <td>SINGLE/<strong>DOUBLE</strong>

    </td>

    <td>Precision of AMReX Real type</td>

    </tr>

    <tr>

    <td><code>AMREX_SPACEDIM</code></td>

    <td>1/2/<strong>3</strong>

    </td>

    <td>Dimension of AMReX</td>

    </tr>

    <tr>

    <td><code>AMREX_BUILD_SHARED_LIBS</code></td>

    <td>ON/<strong>OFF</strong>

    </td>

    <td>Build the core AMReX library as shared library</td>

    </tr>

    <tr>

    <td><code>AMREX_SRC</code></td>

    <td><em>None</em></td>

    <td>Absolute path to AMReX source directory (preferred if set)</td>

    </tr>

    <tr>

    <td><code>AMREX_REPO</code></td>

    <td><code>https://github.com/AMReX-Codes/amrex.git</code></td>

    <td>Repository URI to pull and build AMReX from</td>

    </tr>

    <tr>

    <td><code>AMREX_BRANCH</code></td>

    <td><code>development</code></td>

    <td>Repository branch for <code>AMREX_REPO</code>

    </td>

    </tr>

    <tr>

    <td><code>AMREX_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed AMReX library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>PYBIND11_INTERNAL</code></td>

    <td>

    <strong>ON</strong>/OFF</td>

    <td>Needs a pre-installed pybind11 library if set to <code>OFF</code>

    </td>

    </tr>

    <tr>

    <td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>

    <td>2</td>

    <td>Number of parallel build threads</td>

    </tr>

    <tr>

    <td><code>PYAMREX_LIBDIR</code></td>

    <td><em>None</em></td>

    <td>If set, search for pre-built a pyAMReX library</td>

    </tr>

    <tr>

    <td><code>PYINSTALLOPTIONS</code></td>

    <td><em>None</em></td>

    <td>Additional options for <code>pip install</code>, e.g., <code>-v --user</code>

    </td>

    </tr>

    </tbody>

    </table>

    <p>For example, one can also build against a local AMReX copy.

    Assuming AMReX'' source is located in <code>$HOME/src/amrex</code>, then <code>export
    AMREX_SRC=$HOME/src/amrex</code>.</p>

    <p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>

    <div class="highlight highlight-source-shell"><pre>AMREX_SRC=<span class="pl-smi">$PWD</span>/../amrex
    python3 -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>Note that you need to use absolute paths for external source trees, because
    pip builds in a temporary directory.</p>

    <p>Or build against an AMReX feature branch of a colleague.

    Assuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code>
    in a branch <code>new-feature</code> then</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">unset</span>
    AMREX_SRC  <span class="pl-c"><span class="pl-c">#</span> preferred if set</span>

    AMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3
    -m pip install -v --force-reinstall <span class="pl-c1">.</span></pre></div>

    <p>You can speed up the install further if you pre-install AMReX, e.g. with a
    package manager.

    Set <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the
    environment variable <a href="https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html"
    rel="nofollow">CMAKE_PREFIX_PATH</a>.

    Please see the <a href="#Developers">short CMake tutorial that we linked above</a>
    if this sounds new to you.</p>

    <h2><a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgements</h2>

    <p>This work was supported by the Laboratory Directed Research and Development
    Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy
    Contract No. DE-AC02-05CH11231.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>pyAMReX Copyright (c) 2021-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for pyamrex can be found at <a href="LICENSE">LICENSE</a>.</p>

    '
  stargazers_count: 18
  subscribers_count: 15
  topics:
  - amrex
  - python
  updated_at: 1681177984.0
AlexanderRichert-NOAA/CItest:
  data_format: 2
  description: Set up a simplified test case based on spack/HDF5 build fail due to
    /usr/local contents
  filenames:
  - spack.yaml
  full_name: AlexanderRichert-NOAA/CItest
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1671482597.0
Alpine-DAV/spack_configs:
  data_format: 2
  description: spack envs
  filenames:
  - _experimental/envs/olcf/summit/spack.yaml
  - _experimental/envs/alpinedav/ubuntu_18_cuda_10.1_devel/spack.yaml
  - _experimental/envs/llnl/quartz/spack.yaml
  - _experimental/envs/llnl/pascal-cuda/spack.yaml
  full_name: Alpine-DAV/spack_configs
  latest_release: null
  readme: '<h1><a id="user-content-spack_configs" class="anchor" aria-hidden="true"
    href="#spack_configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack_configs</h1>

    <p>shared spack configs repo</p>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1639176281.0
ArjunaCluster/spack:
  data_format: 2
  description: Spack Repos and Configuration Files
  filenames:
  - environments/bootstrap/spack.yaml
  - environments/common/spack.yaml
  - environments/slurm/spack.yaml
  full_name: ArjunaCluster/spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1637623732.0
CINECA-HPC/container_bioinfo_bismark_ubuntu2004_x86_64:
  data_format: 2
  description: null
  filenames:
  - spack_bismark_docker_ubuntu2004_x86_64.yaml
  full_name: CINECA-HPC/container_bioinfo_bismark_ubuntu2004_x86_64
  latest_release: null
  readme: '<h1><a id="user-content-container_bioinfo_bismark_ubuntu2004_x86_64" class="anchor"
    aria-hidden="true" href="#container_bioinfo_bismark_ubuntu2004_x86_64"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>container_bioinfo_bismark_ubuntu2004_x86_64</h1>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1606916803.0
CINECA-HPC/container_bioinfo_bwa_ubuntu2004_x86_64:
  data_format: 2
  description: null
  filenames:
  - spack_bwa_docker_ubuntu2004_x86_64.yaml
  full_name: CINECA-HPC/container_bioinfo_bwa_ubuntu2004_x86_64
  latest_release: null
  readme: '<h1><a id="user-content-container_bioinfo_bwa_ubuntu2004_x86_64" class="anchor"
    aria-hidden="true" href="#container_bioinfo_bwa_ubuntu2004_x86_64"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>container_bioinfo_bwa_ubuntu2004_x86_64</h1>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1612456323.0
CINECA-HPC/container_spack_centos_x86_64:
  data_format: 2
  description: Containers for arch x86_64 based on Centos 7 and 8 with GNU 7 and 8
    compiler and different versions of Spack 0.15.4 and 0.16.0
  filenames:
  - spack_openmpi_strip_centos8.yaml
  full_name: CINECA-HPC/container_spack_centos_x86_64
  latest_release: null
  readme: '<h1><a id="user-content-container_spack_centos_x86_64" class="anchor" aria-hidden="true"
    href="#container_spack_centos_x86_64"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>container_spack_centos_x86_64</h1>

    <p>Containers for arch x86_64 based on Centos 7 with GNU 7 compiler and different
    versions of Spack</p>

    <ul>

    <li>15.4</li>

    <li>16.0</li>

    </ul>

    <p>IMPORTANT (NOT NECESSARY IF YOU START FROM A DOCKER IMAGE): When you are going
    to work inside the container remember to source these 2 file in order to set the
    proper module environment with spack and Lmod</p>

    <ul>

    <li>source /opt/spack/share/spack/setup-env.sh</li>

    <li>source /usr/share/lmod/8.2.7/init/sh</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics:
  - spack
  updated_at: 1614178565.0
CINECA-HPC/container_spack_ubuntu2004_x86_64:
  data_format: 2
  description: null
  filenames:
  - spack_openmpi_strip_ubuntu2004.yaml
  full_name: CINECA-HPC/container_spack_ubuntu2004_x86_64
  latest_release: null
  readme: '<h1><a id="user-content-container_spack_ubuntu2004_x86_64" class="anchor"
    aria-hidden="true" href="#container_spack_ubuntu2004_x86_64"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>container_spack_ubuntu2004_x86_64</h1>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1613997573.0
CODARcode/z-checker-installer:
  data_format: 2
  description: one-key installation to install gnuplot, sz, zfp, and z-checker, and
    complete the configuration automatically for the testing.
  filenames:
  - libpressio-opt/spack.yaml
  full_name: CODARcode/z-checker-installer
  latest_release: 0.8.0
  readme: '<h1><a id="user-content-z-checker-installer" class="anchor" aria-hidden="true"
    href="#z-checker-installer"><span aria-hidden="true" class="octicon octicon-link"></span></a>Z-checker
    installer</h1>

    <p>(C) 2017-2021 by Mathematics and Computer Science (MCS), Argonne National Laboratory.</p>

    <p>See COPYRIGHT in top-level directory.</p>

    <p>Major authors: Sheng Di, Dingwen Tao, Hanqi Guo

    Other contributors: Robert Underwood, Hengzhi Chen</p>

    <h2><a id="user-content-3rd-party-librariestools" class="anchor" aria-hidden="true"
    href="#3rd-party-librariestools"><span aria-hidden="true" class="octicon octicon-link"></span></a>3rd
    party libraries/tools</h2>

    <ul>

    <li>cmake (version: 3.13+)</li>

    <li>gcc (version: 7.3+)</li>

    <li>g++</li>

    <li>git</li>

    <li>curl</li>

    <li>texlive (e.g., execute ''sudo yum install texlive-*'' on linux)</li>

    <li>ghostscript(gsview) (z-checker-install.sh can install it automatically if
    missing)</li>

    <li>latexmk (z-checker-install.sh will install latexmk automatically if missing)</li>

    <li>gnuplot (z-checker-install.sh will install gnuplot automatically if missing)</li>

    <li>perl (used by only web-visualization support)</li>

    </ul>

    <p>Note: if you install only texlive (e.g., sudo yum install texlive), then you
    also need to install latex packages ''comment.sty'', ''subfigure.sty'', ''nopageno.sty''
    and ''morefloats.sty'' by running ''sudo yum -y install "tex(${latexpkg})"'' (e.g.,
    sudo yum -y install "tex(comment.sty)")</p>

    <p>The following libraries - libpng, tif22pnm and sam2p are used to convert slice
    image png files to eps. If plotSliceImag option is disabled (in zc.config), these
    three libraries are not needed.</p>

    <ul>

    <li>libpng (z-checker-install.sh will install tif22pnm automatically if missing;
    in fact, libpng can be installed using system installation command such as ''yum
    install libpng-devel'' on linux.)</li>

    <li>tif22pnm (z-checker-install.sh will install tif22pnm automatically if missing)</li>

    <li>sam2p (z-checker-install.sh will install sam2p automatically if missing)</li>

    </ul>

    <p>For simplicity,

    the Fedora users need to run the following command for installation:</p>

    <div class="highlight highlight-source-shell"><pre>sudo dnf install -y gcc gcc-c++
    git cmake zlib-devel libzstd-devel gfortran which xorg-x11-server-Xorg gnuplot
    libpng-devel findutils unzip latexmk texlive-<span class="pl-k">*</span>

    <span class="pl-k">&lt;</span><span class="pl-k">!</span>-- required texlive package:
    <span class="pl-s"><span class="pl-pds">"</span>tex(comment.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(pifont.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(natbib.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(amsmath.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(morefloats.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(geometry.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(nopageno.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(subfigure.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(enumitem.sty)<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>tex(morefloats.sty)<span class="pl-pds">"</span></span>--<span
    class="pl-k">&gt;</span>

    git clone http://github.com/CODARcode/z-checker-installer

    <span class="pl-c1">cd</span> z-checker-installer

    ./z-checker-install.sh</pre></div>

    <p>the Ubuntu users need to run the following command for installation:</p>

    <div class="highlight highlight-source-shell"><pre>sudo sudo apt-get install -y
    gcc g++ git cmake zlib-devel gfortran gnuplot libpng-devel xorg openbox findutils
    unzip latexmk texlive-full texlive-fonts-recommends --no-install-recommends

    git clone http://github.com/CODARcode/z-checker-installer

    <span class="pl-c1">cd</span> z-checker-installer

    ./z-checker-install.sh</pre></div>

    <h2><a id="user-content-testinginstallation-method" class="anchor" aria-hidden="true"
    href="#testinginstallation-method"><span aria-hidden="true" class="octicon octicon-link"></span></a>Testing/Installation
    method</h2>

    <p>z-checker-install.sh will download latexmk, gnuplot, Z-checker, ZFP, and SZ
    and install them one by one automatically, and then add the patches to let ZFP
    and SZ fit for Z-checker.</p>

    <p>After installation, please download the two testing data sets, CESM-ATM and
    MD-simulation (exaalt). The two data sets are available only for the purpose of
    research of compression. Please ask for the data by contacting <a href="">sdi1@anl.gov</a>
    if interested.</p>

    <p>LibpressioOPT is a library that is able to search for the appropriate error
    bound setting based on user-sepcified metric values such as compression ratio
    and PSNR. Z-checker itself has some simple built-in algorithms to do this work,
    which may not be as accurate as LibpressioOPT. To this end, you also need to install
    spack and use spack to install some preliminary libraries. For more details, please
    read the z-checker-installer-instruction.pdf in the ./doc/ directory. If you don''t
    need LibpressioOPT, you just need to run ''./z-checker-installer.sh'' to install
    everything.</p>

    <h3><a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Quick Start</h3>

    <p>Then, you are ready to conduct the compression checking.

    You can generate compression results with SZ and ZFP using the following simple
    steps:

    (Note: you have to run z-checker-install.sh to install the software before doing
    the following tests)</p>

    <ol>

    <li>

    <p>Configure the error bound setting and comparison cases in errBounds.cfg.</p>

    </li>

    <li>

    <p>Create a new test-case, by executing "createZCCase.sh [test-case-name]". You
    need to replace [test-case-name] by a meaningful name.

    For example:

    [user@localhost z-checker-installer] ./createZCCase.sh CESM-ATM-tylor-data</p>

    </li>

    <li>

    <p>Perform the checking by running the command "runZCCase.sh": runZCCase.sh [data_type]
    [error-bound-mode] [test-case-name] [data dir] [extension] [dimensions....].

    Example:

    [user@localhost z-checker-installer] ./runZCCase.sh -f REL CESM-ATM-tylor-data
    /home/shdi/CESM-testdata/1800x3600 dat 3600 1800</p>

    </li>

    </ol>

    <p>Then, you can find the report generated in z-checker-installer/Z-checker/[test-case-name]/report.</p>

    <h3><a id="user-content-step-by-step-checking" class="anchor" aria-hidden="true"
    href="#step-by-step-checking"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step-by-step
    Checking</h3>

    <p>Unlike the above one-command checking, the following steps present the generation
    of compression results step by step.</p>

    <ol>

    <li>

    <p>Go to zfp/utils/, and then execute "zfp-zc-ratedistortion.sh [data directory]
    [dimension sizes....]". The compression results are stored in the compressionResults/
    directory.

    For example, suppose the directory of CESM-ATM data set is here: /home/shdi/CESM-testdata/1800x3600,
    then the command is "zfp-zc-ratedistortion.sh /home/shdi/CESM-testdata/1800x3600
    3600 1800". Note: the data files stored in the directory are also ending with
    .dat and the dimension sizes are the same (1800x3600) in this test-case.</p>

    </li>

    <li>

    <p>Similarly, go to SZ/example/, and then generate compression results by SZ compressor
    as follows: "sz-zc-ratedistortion.sh [data directory] [dimension sizes....]".
    The compression results are stored in the compressionResults/ directory.

    As for the example CESM-ATM, the test command is "sz-zc-ratedistortion.sh /home/shdi/CESM-testdata/1800x3600
    3600 1800".</p>

    </li>

    <li>

    <p>Then, go to Z-checker/examples/ directory, and run the command "./analyzeDataProperty.sh
    [data directory] [dimension sizes....]" to generate the data properties based
    on the data sets. This step has nothing to do with the compressors. The data analysis
    results are stored in the dataProperties/ directory.</p>

    </li>

    <li>

    <p>Generate the figure files: run the command "./generateReport.sh" simply. The
    results of comparing different compressors (such as sz and zfp in this test-case)
    are stored in the directory called compareCompressors/.</p>

    </li>

    </ol>

    <h3><a id="user-content-create-a-new-case" class="anchor" aria-hidden="true" href="#create-a-new-case"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Create a new case</h3>

    <p>"createZCCase.sh [test-case-name]" allows you to create a new test-case.  This
    command will create a new workspace directory in Z-checker, SZ, and zfp respectively.
    The compression results will be put in those workspace directories to avoid bing
    messed with other test-cases.</p>

    <p>For example, if you run the generateReport.sh in the directory ./Z-checker/examples,
    it is actually one test case, where the compression results and data analysis
    results will be put in the dataProperty/ and compressionResults/ under it.

    For another test case with another set of data or application, you can create
    a new workspace directory by the script createZCCase.sh (which calls ./Z-checker/createNewCase.sh).</p>

    <h3><a id="user-content-z-checker-updatesh" class="anchor" aria-hidden="true"
    href="#z-checker-updatesh"><span aria-hidden="true" class="octicon octicon-link"></span></a>z-checker-update.sh</h3>

    <p>z-checker-update.sh can be used to update the repository (pull the new update
    from the server), so that you don''t have to perform the update manually.</p>

    <h3><a id="user-content-web-installation" class="anchor" aria-hidden="true" href="#web-installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>web installation</h3>

    <p>Web installation allows to install a web server on the local machine, such
    that you can visualize the data through a local webpage and other people can view
    the data/results via that page if public ip is provided.

    z-checker-web-install.sh</p>

    <h3><a id="user-content-add-a-new-compressor" class="anchor" aria-hidden="true"
    href="#add-a-new-compressor"><span aria-hidden="true" class="octicon octicon-link"></span></a>Add
    a new compressor</h3>

    <ol>

    <li>Make a monitoring program (e.g., called testfloat_CompDecomp.c) for your compressor.
    An example can be found in SZ/example/testfloat_CompDecomp.c, which is used for
    SZ compressor.)</li>

    <li>Modify the manageCompressor.cfg based on the workspaceDir on your computer
    and directory containing the compiled executable monitoring program.</li>

    <li>Suppose the new compressor''s name is zz and the compression mode is called
    ''best''; then, run the following command to add the new compressor:

    ./manageCompressor -a zz -m best -c manageCompressor.cfg</li>

    <li>Then, open errBounds.cfg to modify the error bounds for the new compressor;
    and also modify the comparison cases as follows (the compressor name ''zz_b''
    was set in manageCompressor.cfg):

    comparisonCases="sz_f(1E-1),sz_d(1E-1),zfp(1E-1) sz_f(1E-2),sz_d(1E-2),zfp(1E-2)"
    --&gt; comparisonCases="sz_f(1E-1),sz_d(1E-1),zfp(1E-1),zz_b(1E-2) sz_f(1E-2),sz_d(1E-2),zfp(1E-2),zz_b(1E-2)"</li>

    <li>Finally, create a test case like this: ./createZCCase.sh case_name</li>

    <li>Perform the assessment by runZCCase.sh.</li>

    </ol>

    <h3><a id="user-content-remove-a-compressor" class="anchor" aria-hidden="true"
    href="#remove-a-compressor"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remove
    a compressor</h3>

    <p>Remove sz_f (sz fast mode):

    $ manageCompressor -d sz -m fast -c manageCompressor-sz-f.cfg

    Remove sz_d (sz fast mode):

    $ manageCompressor -d sz -m deft -c manageCompressor-sz-d.cfg

    Remove zfp:

    $ manageCompressor -d zfp -c manageCompressor-zfp.cfg</p>

    <h3><a id="user-content-generate-z-checker-report-based-on-hdf5-files" class="anchor"
    aria-hidden="true" href="#generate-z-checker-report-based-on-hdf5-files"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Generate Z-checker
    report based on HDF5 files</h3>

    <p>You can generate Z-checker report directly based on an HDF5 file.

    To this end, you need to install HDF5 library before hand, and then compile the
    Z-checker/HDF5Reader as follows:</p>

    <p>You need to modify Makefile.linux2 by replacing "HDF5PATH = /home/sdi/Install/hdf5-1.10.1-install"
    by your HDF5 installation path.

    Then:

    make -f Makefile.linux2</p>

    <p>You will find the executable ''testHDF5_CompDecomp'' generated on Z-checker/HDF5Reader/test/
    directory.

    You can use this command to read HDF5 file and generate analysis results.</p>

    <p>After that, you can use ''installHDF5Reader.sh'' and ''runZCCase_hdf5.sh''
    to generate the .pdf report.

    More details can be found in testHDF5/README.txt</p>

    <h3><a id="user-content-generate-z-checker-report-based-on-adios2-files" class="anchor"
    aria-hidden="true" href="#generate-z-checker-report-based-on-adios2-files"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Generate Z-checker
    report based on ADIOS2 files</h3>

    <p>Go to the directory ADIOS2Header, and then do the following steps:</p>

    <ol>

    <li>Modify the ADIOS2''s installation path in Makefile</li>

    <li>make</li>

    <li>execute ''testAdios2''</li>

    </ol>

    <p>Example:

    testAdios2 -i myVector_cpp.bp -n 2 -v bpFloats bpInts -o [target output directory]</p>

    <p>The generated binary data files will be put in the target output directory.
    A meta file called ''varInfo.txt'' contains the extracted variables'' information
    and it will be put in the target output directory as well.

    varInfo.txt and the binary files can be processed by runZCCase.sh</p>

    '
  stargazers_count: 5
  subscribers_count: 7
  topics: []
  updated_at: 1658448853.0
CUP-ECS/ExaCLAMR:
  data_format: 2
  description: null
  filenames:
  - etc/spack.yaml
  - spack.yaml
  full_name: CUP-ECS/ExaCLAMR
  latest_release: null
  readme: '<h1><a id="user-content-exaclamr" class="anchor" aria-hidden="true" href="#exaclamr"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ExaCLAMR</h1>

    <p>Re-Implementation of the Shallow Water Solver LANL/CLAMR using Kokkos, Cabana,
    and Cajita.</p>

    <h2><a id="user-content-current-status" class="anchor" aria-hidden="true" href="#current-status"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Current Status</h2>

    <ul>

    <li>Properly functions using

    <ul>

    <li>Serial</li>

    <li>OpenMP</li>

    <li>Cuda</li>

    <li>Serial + MPI</li>

    <li>OpenMP + MPI</li>

    <li>Cuda + MPI</li>

    </ul>

    </li>

    <li>Able to write to Silo files using PMPIO (Tested on Mac in Serial, OpenMP,
    Serial + MPI, OpenMP + MPI)</li>

    <li>Can Visualize results using VisIt</li>

    </ul>

    <h2><a id="user-content-future-directions-and-tasks" class="anchor" aria-hidden="true"
    href="#future-directions-and-tasks"><span aria-hidden="true" class="octicon octicon-link"></span></a>Future
    Directions and Tasks</h2>

    <ul>

    <li>[x] Fix Cuda MPI issue in use of Cajita Halo gather (currently functioning
    with a work around using CudaUVM and a custom halo exchange). It might be an issue
    with how ExaCLAMR is using the Cajita gather?</li>

    <li>[x] Get Silo to build on Wheeler and Xena and get it working with the CudaUVM
    case</li>

    <li>[x] Template the mesh and problem manager classes for regular grids, AMR grids</li>

    <li>[ ] Investigate using Cabana AoSoA</li>

    <li>[ ] Add particle physics</li>

    </ul>

    <h2><a id="user-content-building-exaclamr" class="anchor" aria-hidden="true" href="#building-exaclamr"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building ExaCLAMR</h2>

    <p>ExaCLAKMR is built and installed using cmake, and relies on variety of packages
    and

    libraries:</p>

    <ul>

    <li>Kokkos - Programming system for accelerated and threaded architectures</li>

    <li>Cabana/Cajita - Framework for regular mesh and particle oprogramming in Kokkos</li>

    <li>Silo - Parallel I/O library for reading in restarts and writing output for

    visualization using VisIt or Paraview</li>

    <li>HeFFTE - GPU-accelerated high-speed fast fourier transform library (Note:
    not

    needed by ExaCLAMR but we''ll want it for the z-model implementation)</li>

    </ul>

    <h3><a id="user-content-building-with-a-spack-environment" class="anchor" aria-hidden="true"
    href="#building-with-a-spack-environment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Building with a Spack environment</h3>

    <p>Generally, the easiest way to build ExaCLAMR is to use <a href="http://spack.io"
    rel="nofollow">Spack</a> to

    either install and load the prerequisites or to create a dedicated environment

    for building and running AppName. The spack specification (etc/spack.yaml) is

    included to create a spack environment in which the build and run AppName. Note,
    however

    //that there are important caveats at the top of this file you''ll ened to pay
    attention to

    to use it//. In particular, to use it to build a CUDA environment you''ll need
    to patch your

    cabana/packages.py spec and set teh cuda architecture kokkos uses. Alternatively,
    you

    can just remove the cuda specifiers from the spack.yaml file.</p>

    <p>To create a spack environment for compiling and running ExaCLAMR in a build
    directory:</p>

    <pre><code>prompt&gt; mkdir build; cd build

    prompt&gt; spack env create -d . /path/to/ExaCLAMR/etc/spack.yaml

    prompt&gt; spack env activate .

    prompt&gt; spack concretize

    prompt&gt; spack install

    </code></pre>

    <p>Once all ExaCLAMR dependencies are installed either manually or via a

    Spack environment, use cmake to build it from the chosen build

    directory:</p>

    <pre><code>cmake /path/to/ExaCLAMR

    </code></pre>

    <h3><a id="user-content-building-on-unm-carc-wheeler" class="anchor" aria-hidden="true"
    href="#building-on-unm-carc-wheeler"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    on UNM CARC Wheeler</h3>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/CUP-ECS/ExaCLAMR.git

    <span class="pl-c1">cd</span> ExaCLAMR

    bash scripts/build_wheeler.sh -a

    mkdir -p data

    mkdir -p data/raw</pre></div>

    <h3><a id="user-content-running-on-unm-carc-wheeler---example-on-2-ranks-serial-mpiopenmp"
    class="anchor" aria-hidden="true" href="#running-on-unm-carc-wheeler---example-on-2-ranks-serial-mpiopenmp"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running on UNM CARC
    Wheeler - Example on 2 Ranks (Serial, MPI+OpenMP)</h3>

    <div class="highlight highlight-source-shell"><pre>module load cmake-3.15.4-gcc-8.3.0-rmxifnl

    module load openmpi-3.1.4-gcc-8.3.0-w3pkrvv

    module load gcc-8.3.0-gcc-4.8.5-wwpinbr

    module load hypre-2.14.0-gcc-7.3.0-openmpi-mkl-zndhsgh

    mpirun -np 2 --display-map --map-by ppr:1:node --bind-to none -machinefile <span
    class="pl-smi">$PBS_NODEFILE</span> -x PATH -x LD_LIBRARY_PATH ./build/examples/DamBreak

    mpirun -np 2 --display-map --map-by ppr:1:node --bind-to none -machinefile <span
    class="pl-smi">$PBS_NODEFILE</span> -x PATH -x LD_LIBRARY_PATH ./build/examples/DamBreak
    -mopenmp</pre></div>

    <h3><a id="user-content-building-on-unm-carc-xena" class="anchor" aria-hidden="true"
    href="#building-on-unm-carc-xena"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    on UNM CARC Xena</h3>

    <ul>

    <li>Note: You have to build on a compute node with a GPU</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/CUP-ECS/ExaCLAMR.git

    <span class="pl-c1">cd</span> ExaCLAMR

    bash scripts/build_xena.sh -a

    mkdir -p data

    mkdir -p data/raw</pre></div>

    <h3><a id="user-content-running-on-unm-carc-xena" class="anchor" aria-hidden="true"
    href="#running-on-unm-carc-xena"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    on UNM CARC Xena</h3>

    <div class="highlight highlight-source-shell"><pre>sbatch scripts/xena_run.sh</pre></div>

    <h2><a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Performance</h2>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1632120250.0
CUP-ECS/cajitafluids:
  data_format: 2
  description: A simple poisson finite difference fluid solver in Cajita/Kokkos for
    testing MPI communication abstractions and their performance
  filenames:
  - configs/generic/spack-cuda-wrapper.yaml
  - configs/generic/spack-cuda-clang.yaml
  - configs/github/spack.yaml
  - configs/llnl-lassen/spack.yaml
  - configs/tutorial-uao-cuda/spack.yaml
  full_name: CUP-ECS/cajitafluids
  latest_release: null
  readme: '<h1><a id="user-content-poisson-mpi-benchmark" class="anchor" aria-hidden="true"
    href="#poisson-mpi-benchmark"><span aria-hidden="true" class="octicon octicon-link"></span></a>Poisson
    MPI Benchmark</h1>

    <p>This directory contains code for a relatively simple finite difference

    fluid advection solver for exploring communication issues on modern architectures

    (particularly GPUs). The main goal is to look at different neighbor collective

    and GPU communication approaches.</p>

    <p>Computationally, the benchmark advects a material feature (that doesn''t otherwise
    effect

    fluid flow, e.g. by changing pressite) using the incompressible Euler fluid flow
    equations.

    Consider, for example, something like a dye being carried through a tank of water
    or a

    fragrance wafting across a room.</p>

    <p>The main elements of the benchmark are:</p>

    <ul>

    <li>Solution of the pressure gradient at each timestep to maintain

    incompressibility. The benchmark has two initial implementations:

    (1) Calling a matrix-free solver in HYPRE to solve the problem or (2)

    running a local matrix-free preconditioned CG solver, in which different

    MPI approaches for the halo exchange are explored.</li>

    <li>Interpolation (either cubic splines or linear) for semi-Lagrangian

    advection of the material being advected across timesteps.</li>

    <li>3rd-order Runge Kutta for time integration</li>

    </ul>

    <p>Sources:</p>

    <ul>

    <li>Fluid Simulation for Comptuer Graphics by Bridson</li>

    <li>Incremental Fluids in Kokkos (<a href="mailto:git@github.com">git@github.com</a>:pkestene/incremental-fluids-kokkos.git)</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1654983605.0
CreRecombinase/ptb_workflowr:
  data_format: 2
  description: preterm birth project workflowr
  filenames:
  - workflow/ldsc_spack.yaml
  full_name: CreRecombinase/ptb_workflowr
  latest_release: null
  readme: '<h1><a id="user-content-ptb" class="anchor" aria-hidden="true" href="#ptb"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ptb</h1>

    <p>A <a href="https://github.com/jdblischak/workflowr">workflowr</a> project about
    pre-term birth, epigenetics and GWAS.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1588962297.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/22.11/rocm-x86_64/spack.yaml
  - environments/21.08/spack.yaml
  - environments/22.05/oneapi.spack.yaml
  - environments/21.11/spack-x86_64.yaml
  - environments/22.02/spack-x86_64.yaml
  - environments/22.11/oneapi-x86_64/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: null
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#e4s\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n<ul>\n<li>User\
    \ Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\">https://e4s.readthedocs.io</a>\n\
    </li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\
    >https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub: <a href=\"https://github.com/E4S-Project/\"\
    >https://github.com/E4S-Project/</a>\n</li>\n<li>E4S Slack Channel: <a href=\"\
    https://e4s-project.slack.com\" rel=\"nofollow\">https://e4s-project.slack.com</a>\n\
    </li>\n<li>Slack Channel Invitation: <a href=\"https://communityinviter.com/apps/e4s-project/e4s\"\
    \ rel=\"nofollow\">https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n\
    <li>E4S Dashboard: <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\
    >E4S-Project/E4S-Project.github.io</a> - E4S Documentation repo that is hosted\
    \ on <a href=\"https://e4s-project.github.io/\" rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>E4S is released\
    \ as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 16
  subscribers_count: 10
  topics: []
  updated_at: 1680351263.0
ECP-CANDLE/Supervisor:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: ECP-CANDLE/Supervisor
  latest_release: null
  stargazers_count: 6
  subscribers_count: 10
  topics:
  - nci-doe-collaboration-capability
  updated_at: 1627991581.0
ECP-WarpX/WarpX:
  data_format: 2
  description: WarpX is an advanced, time-based electromagnetic & electrostatic Particle-In-Cell
    code.
  filenames:
  - Tools/machines/desktop/spack-macos-openmp.yaml
  - Tools/machines/desktop/spack-ubuntu-cuda.yaml
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: ECP-WarpX/WarpX
  latest_release: '23.04'
  readme: '<h1><a id="user-content-warpx" class="anchor" aria-hidden="true" href="#warpx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WarpX</h1>

    <p><a href="https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development"
    rel="nofollow"><img src="https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74"
    alt="Code Status development" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2" rel="nofollow"><img
    src="https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573"
    alt="Nightly Installation Tests" data-canonical-src="https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages"
    style="max-width: 100%;"></a>

    <a href="https://warpx.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/warpx/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://spack.readthedocs.io/en/latest/package_list.html#warpx" rel="nofollow"><img
    src="https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078"
    alt="Spack Version" data-canonical-src="https://img.shields.io/spack/v/warpx"
    style="max-width: 100%;"></a>

    <a href="https://anaconda.org/conda-forge/warpx" rel="nofollow"><img src="https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078"
    alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/warpx"
    style="max-width: 100%;"></a>

    <a href="https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667"
    alt="Gitter" data-canonical-src="https://badges.gitter.im/ECP-WarpX/community.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://warpx.readthedocs.io/en/latest/install/users.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565"
    alt="Supported Platforms" data-canonical-src="https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue"
    style="max-width: 100%;"></a>

    <a href="https://github.com/ECP-WarpX/WarpX/compare/development"><img src="https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667"
    alt="GitHub commits since last release" data-canonical-src="https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg"
    style="max-width: 100%;"></a>

    <a href="https://www.exascaleproject.org/research/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765"
    alt="Exascale Computing Project" data-canonical-src="https://img.shields.io/badge/supported%20by-ECP-orange"
    style="max-width: 100%;"></a>

    <a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667"
    alt="Language: C++17" data-canonical-src="https://img.shields.io/badge/language-C%2B%2B17-orange.svg"
    style="max-width: 100%;"></a>

    <a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667"
    alt="Language: Python" data-canonical-src="https://img.shields.io/badge/language-Python-orange.svg"
    style="max-width: 100%;"></a><br>

    <a href="https://spdx.org/licenses/BSD-3-Clause-LBNL.html" rel="nofollow"><img
    src="https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667"
    alt="License WarpX" data-canonical-src="https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.5281/zenodo.4571577" rel="nofollow"><img src="https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667"
    alt="DOI (source)" data-canonical-src="https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://doi.org/10.1109/SC41404.2022.00008" rel="nofollow"><img src="https://camo.githubusercontent.com/2be0ab9ceaff22581aac9ee5d5eac9cc73cae7e4bad2c69bcf0ffd6713337293/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667"
    alt="DOI (paper)" data-canonical-src="https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg"
    style="max-width: 100%;"></a></p>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>WarpX is an advanced <strong>electromagnetic &amp; electrostatic Particle-In-Cell</strong>
    code.

    It supports many features including Perfectly-Matched Layers (PML), mesh refinement,
    and the boosted-frame technique.</p>

    <p>WarpX is a <em>highly-parallel and highly-optimized code</em>, which can run
    on GPUs and multi-core CPUs, and includes load balancing capabilities.

    WarpX scales to the world''s largest supercomputers and was awarded the <a href="https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/"
    rel="nofollow">2022 ACM Gordon Bell Prize</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://warpx.readthedocs.io" rel="nofollow">https://warpx.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo, or visit
    our Gitter room at <a href="https://gitter.im/ECP-WarpX/community" rel="nofollow">https://gitter.im/ECP-WarpX/community</a></p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2023, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 183
  subscribers_count: 15
  topics:
  - laser
  - plasma
  - physics
  - gpu
  - simulation
  - particle-in-cell
  - pic
  - research
  updated_at: 1681889461.0
ECP-WarpX/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Docs/spack.yaml
  full_name: ECP-WarpX/artemis
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" href="#artemis"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a development
    fork of WarpX for modeling micromagnetics and electrodynamic waves in next-generation
    microelectornics.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p><a href="https://picmi-standard.github.io" rel="nofollow"><img src="https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICMI" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.openPMD.org" rel="nofollow"><img src="https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://yt-project.org" rel="nofollow"><img src="https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="yt-project" data-canonical-src="https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>In order to learn how to install and run the code, please see the online documentation:

    <a href="https://artemis-em.readthedocs.io" rel="nofollow">https://artemis-em.readthedocs.io</a></p>

    <p>To contact the developers, feel free to open an issue on this repo.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p><a href="https://amrex-codes.github.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="AMReX" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://picsar.net" rel="nofollow"><img src="https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="PICSAR" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://openpmd-api.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="openPMD-api" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://csmd.ornl.gov/adios" rel="nofollow"><img src="https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="ADIOS" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://www.hdfgroup.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="HDF5" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="http://www.ascent-dav.org" rel="nofollow"><img src="https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="Ascent" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a>

    <a href="https://sensei-insitu.org" rel="nofollow"><img src="https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232"
    alt="SENSEI" data-canonical-src="https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22"
    style="max-width: 100%;"></a></p>

    <p>Our workflow is described in <a href="CONTRIBUTING.rst">CONTRIBUTING.rst</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>WarpX Copyright (c) 2018-2022, The Regents of the University of California,

    through Lawrence Berkeley National Laboratory (subject to receipt of any

    required approvals from the U.S. Dept. of Energy).  All rights reserved.</p>

    <p>If you have questions about your rights to use or distribute this software,

    please contact Berkeley Lab''s Innovation &amp; Partnerships Office at

    <a href="mailto:IPO@lbl.gov">IPO@lbl.gov</a>.</p>

    <p>NOTICE.  This Software was developed under funding from the U.S. Department

    of Energy and the U.S. Government consequently retains certain rights. As

    such, the U.S. Government has been granted for itself and others acting on

    its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the

    Software to reproduce, distribute copies to the public, prepare derivative

    works, and perform publicly and display publicly, and to permit other to do

    so.</p>

    <p>License for WarpX can be found at <a href="LICENSE.txt">LICENSE.txt</a>.</p>

    '
  stargazers_count: 7
  subscribers_count: 5
  topics: []
  updated_at: 1674918589.0
Exawind/exawind-builder:
  data_format: 2
  description: Scripts to help building Exawind codes on various systems
  filenames:
  - etc/spack/spack/spack.yaml
  full_name: Exawind/exawind-builder
  latest_release: v0.1.0
  readme: '<h1><a id="user-content-exawind-code-builder" class="anchor" aria-hidden="true"
    href="#exawind-code-builder"><span aria-hidden="true" class="octicon octicon-link"></span></a>ExaWind
    Code Builder</h1>

    <p><a href="https://exawind.github.io/exawind-builder" rel="nofollow">Documentation</a></p>

    <p>ExaWind Builder is a collection of bash scripts to configure and compile the

    codes used within the <a href="https://github.com/exawind">ExaWind</a> project
    on various

    high-performance computing (HPC) systems. The builder provides the following</p>

    <ul>

    <li>

    <p><strong>Platform configuration</strong>: Provides the minimal set of modules
    that must be

    loaded when compiling with different compilers and MPI libraries on different

    HPC systems.</p>

    </li>

    <li>

    <p><strong>Software configuration</strong>: Provides baseline CMake configuration
    that can be

    used to configure the various options when building a <em>project</em>, e.g.,

    enable/disable optional modules, automate specification of paths to various

    libraries, configure release vs. debug builds.</p>

    </li>

    <li>

    <p><strong>Build script generation</strong>: Generates an executable end-user
    script for a

    combination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>

    </li>

    <li>

    <p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific

    script that allows the user to recreate the exact environment used to build

    the codes during runtime.</p>

    </li>

    </ul>

    <p>The build scripts are intended for developers who might want to compile the

    codes with different configuration options, build different branches during

    their development cycle, or link to a different development version of a library

    that is currently not available in the standard installation on the system. Please
    see the

    <a href="https://exawind.github.io/exawind-builder" rel="nofollow">documentation</a>
    for

    details on how to use this to build ExaWind software.</p>

    <h2><a id="user-content-installation-and-usage" class="anchor" aria-hidden="true"
    href="#installation-and-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation
    and usage</h2>

    <h3><a id="user-content-using-exawind-builder-with-pre-installed-exawind-environment"
    class="anchor" aria-hidden="true" href="#using-exawind-builder-with-pre-installed-exawind-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using exawind-builder
    with pre-installed ExaWind environment</h3>

    <p>ExaWind Builder is already installed and setup on OLCF Summit, NREL

    Eagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly

    to using build scripts from the central installation. Please consult <a href="https://exawind.github.io/exawind-builder/basic.html#basic-usage"
    rel="nofollow">user

    manual</a> to

    learn how to use the scripts.</p>

    <h3><a id="user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions"
    class="anchor" aria-hidden="true" href="#bootstrapping-exawind-builder-with-pre-configured-system-definitions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Bootstrapping exawind-builder
    with pre-configured system definitions</h3>

    <p>ExaWind builder has <a href="https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems"
    rel="nofollow">pre-built

    configurations</a>

    for several systems. On these systems you can use the <code>bootstrap</code> script
    to

    quickly get up and running. Please consult <a href="https://exawind.github.io/exawind-builder/installation.html"
    rel="nofollow">installation

    manual</a>. The

    relevant steps are shown below.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    Download bootstrap script</span>

    curl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Make it executable</span>

    chmod a+x bootstrap.sh


    <span class="pl-c"><span class="pl-c">#</span> Execute bootstrap and provide system/compiler
    combination</span>

    ./bootstrap.sh -s [SYSTEM] -c [COMPILER]


    <span class="pl-c"><span class="pl-c">#</span> Examples</span>

    ./bootstrap.sh -s spack -c clang       <span class="pl-c"><span class="pl-c">#</span>
    On MacOS with homebrew</span>

    ./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system

    ./bootstrap.sh -s eagle -c gcc         <span class="pl-c"><span class="pl-c">#</span>
    NREL Eagle</span>

    ./bootstrap.sh -s cori -c intel        <span class="pl-c"><span class="pl-c">#</span>
    NERSC Cori</span>

    ./bootstrap.sh -s snl-ascicgpu -c gcc  <span class="pl-c"><span class="pl-c">#</span>
    SNL GPU development machine</span></pre></div>

    <h3><a id="user-content-creating-new-system-configuration" class="anchor" aria-hidden="true"
    href="#creating-new-system-configuration"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Creating new system configuration</h3>

    <p>You can add new system definitions to exawind-builder for use on new systems

    that are not used by ExaWind team. Please see <a href="https://exawind.github.io/exawind-builder/advanced.html"
    rel="nofollow">manual

    installation</a> and

    <a href="https://exawind.github.io/exawind-builder/newsys.html" rel="nofollow">adding
    a new system</a>

    sections in the user manual.</p>

    <h2><a id="user-content-links" class="anchor" aria-hidden="true" href="#links"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Links</h2>

    <ul>

    <li><a href="https://www.exawind.org" rel="nofollow">ExaWind</a></li>

    <li><a href="https://github.com/exawind">ExaWind GitHub Organization</a></li>

    <li><a href="https://a2e.energy.gov/about/hfm" rel="nofollow">A2e HFM</a></li>

    </ul>

    '
  stargazers_count: 3
  subscribers_count: 5
  topics:
  - cmake
  - build
  - exawind
  - hpc
  - exawind-builder
  updated_at: 1643028069.0
HEPonHPC/hepnos_eventselection:
  data_format: 2
  description: null
  filenames:
  - docker/hepnos/spack.yaml
  full_name: HEPonHPC/hepnos_eventselection
  latest_release: null
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1658856345.0
JuliaParallel/MPI.jl:
  data_format: 2
  description: MPI wrappers for Julia
  filenames:
  - .ci/mvapich/spack.yaml
  full_name: JuliaParallel/MPI.jl
  latest_release: v0.20.8
  readme: '<h1><a id="user-content-mpi-interface-for-the-julia-language" class="anchor"
    aria-hidden="true" href="#mpi-interface-for-the-julia-language"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>MPI interface for the Julia language</h1>

    <p><a href="https://juliaparallel.github.io/MPI.jl/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667"
    alt="Docs latest" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667"
    alt="Docs stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml"><img
    src="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml/badge.svg"
    alt="Unit Tests" style="max-width: 100%;"></a>

    <a href="https://buildkite.com/julialang/mpi-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/87debbd756a8b45df7ac1f25dc034436051f7ccfe155df49f1ec1f6209e51caf/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65643831336263346437396635353761646264623832316231633863386465393839393936383665363937646634613337332e7376673f6272616e63683d6d6173746572"
    alt="GPU tests" data-canonical-src="https://badge.buildkite.com/ed813bc4d79f557adbdb821b1c8c8de98999686e697df4a373.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00ad86424fd334dccd9dde2876e4f3e82b84ad4219e5c1661d6a06b63f46f516/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f4d50492e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572"
    alt="codecov.io" data-canonical-src="https://codecov.io/github/JuliaParallel/MPI.jl/coverage.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://coveralls.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/4d989c928ad758732dcf79e5d1a0b592a1765763c2237af784955ed806e37ef1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f4d50492e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaParallel/MPI.jl/badge.svg?branch=master&amp;service=github"
    style="max-width: 100%;"></a></p>

    <p>This provides <a href="http://julialang.org/" rel="nofollow">Julia</a> interface
    to the Message Passing Interface (<a href="http://www.mpi-forum.org/" rel="nofollow">MPI</a>),
    roughly inspired by <a href="https://github.com/mpi4py/mpi4py/">mpi4py</a>.</p>

    <p>Please see the <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow">documentation</a>
    for instructions on <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/"
    rel="nofollow">configuration</a> and <a href="https://juliaparallel.github.io/MPI.jl/stable/usage/"
    rel="nofollow">usage</a>.</p>

    <p><strong>Breaking changes with v0.20:</strong> The way how MPI.jl is configured
    to use

    different MPI implementations has changed from v0.19 to v0.20 in a

    <em>non-backward-compatible</em> manner.

    Specifically, most <code>JULIA_MPI_XXX</code> variables do not have an effect
    anymore.

    Please refer to the

    <a href="https://juliaparallel.org/MPI.jl/stable/configuration/#Migration-from-MPI.jl-v0.19-or-earlier"
    rel="nofollow">docs</a>

    for information on how to migrate your existing configuration.</p>

    <h1><a id="user-content-help-and-discussion" class="anchor" aria-hidden="true"
    href="#help-and-discussion"><span aria-hidden="true" class="octicon octicon-link"></span></a>Help
    and discussion</h1>

    <p>For help and discussion, we suggest asking on the following venues:</p>

    <ul>

    <li><a href="https://discourse.julialang.org/c/domain/parallel/34" rel="nofollow">"Julia
    at Scale" topic on the Julia Discourse</a></li>

    <li>#distributed channel on the <a href="https://julialang.slack.com/" rel="nofollow">Julia
    Slack</a> (visit <a href="https://julialang.org/slack/" rel="nofollow">https://julialang.org/slack/</a>
    to join).</li>

    </ul>

    <h1><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h1>

    <p>Contributions are encouraged. In particular, MPI provides several hundred functions,
    only a small number of which are currently exposed. If there are additional functions
    you would like to use, please open an <a href="https://github.com/JuliaParallel/MPI.jl/issues">issue</a>
    or <a href="https://github.com/JuliaParallel/MPI.jl/pulls">pull request</a>.</p>

    <p>Additional examples and documentation improvements are also very welcome.</p>

    <h1><a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citation</h1>

    <p>If you use MPI.jl in your work, please cite the following paper:</p>

    <blockquote>

    <p>Simon Byrne, Lucas C. Wilcox, and Valentin Churavy (2021) "MPI.jl: Julia bindings
    for the Message Passing Interface". <em>JuliaCon Proceedings</em>, 1(1), 68, doi:
    <a href="https://doi.org/10.21105/jcon.00068" rel="nofollow">10.21105/jcon.00068</a></p>

    </blockquote>

    '
  stargazers_count: 319
  subscribers_count: 21
  topics:
  - mpi
  - julia
  - hpc
  - julia-language
  - mpich
  - openmpi
  - microsoft-mpi
  updated_at: 1680005017.0
L-LYR/playground:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: L-LYR/playground
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676371970.0
LLNL/Umpire:
  data_format: 2
  description: An application-focused API for memory management on NUMA & GPU architectures
  filenames:
  - .spack_env/darwin/spack.yaml
  - .spack_env/llnl/spack.yaml
  full_name: LLNL/Umpire
  latest_release: v2022.10.0
  readme: '<h1><a id="user-content---umpire-v2022100" class="anchor" aria-hidden="true"
    href="#--umpire-v2022100"><span aria-hidden="true" class="octicon octicon-link"></span></a>

    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/81bd6212d0dd884f5a1d99f54f5b792596f42ad2d6643791a885b7ff42aad41e/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"><img
    src="https://camo.githubusercontent.com/81bd6212d0dd884f5a1d99f54f5b792596f42ad2d6643791a885b7ff42aad41e/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67"
    width="128" valign="middle" alt="Umpire" data-canonical-src="https://cdn.rawgit.com/LLNL/Umpire/develop/share/umpire/logo/umpire-logo.png"
    style="max-width: 100%;"></a>  Umpire v2022.10.0</h1>

    <p><a href="https://travis-ci.com/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/36f0f474aacbade149e980682a28b1b97aa3ea7737006edce896fa4ebbc9ffa7/68747470733a2f2f7472617669732d63692e636f6d2f4c4c4e4c2f556d706972652e7376673f6272616e63683d646576656c6f70"
    alt="Travis Build Status" data-canonical-src="https://travis-ci.com/LLNL/Umpire.svg?branch=develop"
    style="max-width: 100%;"></a>

    <a href="https://dev.azure.com/davidbeckingsale/Umpire/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/615ebc663bd8e7bce0a236693071d360c1f3d4b04bfabb454ba50068b0bac3c0/68747470733a2f2f6465762e617a7572652e636f6d2f64617669646265636b696e6773616c652f556d706972652f5f617069732f6275696c642f7374617475732f4c4c4e4c2e556d706972653f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/davidbeckingsale/Umpire/_apis/build/status/LLNL.Umpire?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://umpire.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/7fd7eef5a102528cae391ff45e9ae1026690d979c1413498b1604b23febeffaf/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756d706972652f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/umpire/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/Umpire" rel="nofollow"><img src="https://camo.githubusercontent.com/d567cb288d0416a63a2faa83e8b2d5265860c1a3e9af604f4b6730340fa830c7/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f556d706972652f6272616e63682f646576656c6f702f67726170682f62616467652e737667"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/Umpire/branch/develop/graph/badge.svg"
    style="max-width: 100%;"></a> <a href="https://gitter.im/LLNL/Umpire?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"
    rel="nofollow"><img src="https://camo.githubusercontent.com/d812b594e8c008b20bc4b4e508035cb3ffd814a168debe18107da92e6c7e5f88/68747470733a2f2f6261646765732e6769747465722e696d2f4c4c4e4c2f556d706972652e737667"
    alt="Join the chat at https://gitter.im/LLNL/Umpire" data-canonical-src="https://badges.gitter.im/LLNL/Umpire.svg"
    style="max-width: 100%;"></a></p>

    <p>Umpire is a resource management library that allows the discovery, provision,

    and management of memory on machines with multiple memory devices like NUMA and
    GPUs.</p>

    <p>Umpire uses CMake and BLT to handle builds. Since BLT is included as a

    submodule, first make sure you run:</p>

    <pre><code>$ git submodule init &amp;&amp; git submodule update

    </code></pre>

    <p>Then, make sure that you have a modern compiler loaded, and the configuration
    is as

    simple as:</p>

    <pre><code>$ mkdir build &amp;&amp; cd build

    $ cmake ..

    </code></pre>

    <p>CMake will provide output about which compiler is being used. Once CMake has

    completed, Umpire can be built with Make:</p>

    <pre><code>$ make

    </code></pre>

    <p>For more advanced configuration you can use standard CMake variables.</p>

    <h1><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>Both user and code documentation is available <a href="http://umpire.readthedocs.io/"
    rel="nofollow">here</a>.</p>

    <p>The Umpire <a href="https://umpire.readthedocs.io/en/develop/sphinx/tutorial.html"
    rel="nofollow">tutorial</a> provides a step by step introduction to Umpire features.</p>

    <p>If you have build problems, we have comprehensive <a href="https://umpire.readthedocs.io/en/develop/sphinx/advanced_configuration.html"
    rel="nofollow">build system documentation</a> too!</p>

    <h1><a id="user-content-getting-involved" class="anchor" aria-hidden="true" href="#getting-involved"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Involved</h1>

    <p>Umpire is an open-source project, and we welcome contributions from the community.</p>

    <h2><a id="user-content-mailing-list" class="anchor" aria-hidden="true" href="#mailing-list"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Mailing List</h2>

    <p>The Umpire mailing list is hosted on Google Groups, and is a great place to
    ask questions:</p>

    <ul>

    <li><a href="https://groups.google.com/forum/#!forum/umpire-users" rel="nofollow">Umpire
    Users Google Group</a></li>

    </ul>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" href="#contributions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits; it''s all great!</p>

    <p>To contribute, make a <a href="https://github.com/LLNL/Umpire/compare">pull
    request</a>, with <code>develop</code> as the destination branch.

    We use Travis to run CI tests, and your branch must pass these tests before being
    merged.</p>

    <p>For more information, see the <a href="https://github.com/LLNL/Umpire/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h1><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h1>

    <p>Thanks to all of Umpire''s

    <a href="https://github.com/LLNL/Umpire/graphs/contributors">contributors</a>.</p>

    <p>Umpire was created by David Beckingsale (<a href="mailto:david@llnl.gov">david@llnl.gov</a>).</p>

    <h2><a id="user-content-citing-umpire" class="anchor" aria-hidden="true" href="#citing-umpire"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citing Umpire</h2>

    <p>If you are referencing Umpire in a publication, please use the following citation:</p>

    <ul>

    <li>D. Beckingsale, M. Mcfadden, J. Dahm, R. Pankajakshan and R. Hornung, <a href="https://ieeexplore.ieee.org/document/8907404"
    rel="nofollow">"Umpire: Application-Focused Management and Coordination of Complex
    Hierarchical Memory,"</a> in IBM Journal of Research and Development. 2019. doi:
    10.1147/JRD.2019.2954403</li>

    </ul>

    <h1><a id="user-content-release" class="anchor" aria-hidden="true" href="#release"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Release</h1>

    <p>Umpire is released under an MIT license. For more details, please see the

    <a href="./LICENSE">LICENSE</a> and <a href="./RELEASE">RELEASE</a> files.</p>

    <p><code>LLNL-CODE-747640</code>

    <code>OCEC-18-031</code></p>

    '
  stargazers_count: 250
  subscribers_count: 16
  topics:
  - hpc
  - memory-management
  - gpu
  - blt
  - portability
  - radiuss
  - cpp
  updated_at: 1681418644.0
LLNL/conduit:
  data_format: 2
  description: Simplified Data Exchange for HPC Simulations
  filenames:
  - scripts/uberenv_configs/old_configs/spack_envs/llnl/quartz/spack.yaml
  full_name: LLNL/conduit
  latest_release: v0.8.7
  readme: '<h1><a id="user-content-conduit" class="anchor" aria-hidden="true" href="#conduit"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Conduit</h1>

    <p><strong>Conduit: Simplified Data Exchange for HPC Simulations</strong></p>

    <p>Conduit is an open source project from Lawrence Livermore National Laboratory
    that provides an intuitive model for describing hierarchical scientific data in
    C++, C, Fortran, and Python. It is used for data coupling between packages in-core,
    serialization, and I/O tasks.</p>

    <p><a href="https://travis-ci.org/LLNL/conduit" rel="nofollow"><img src="https://camo.githubusercontent.com/478365930966f70f879ae04d59ea3f5c5888bee7d2a50e7e281dc1da3cf9aff1/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67"
    alt="Travis CI Build Status" data-canonical-src="https://travis-ci.org/LLNL/conduit.png"
    style="max-width: 100%;"></a>

    <a href="https://ci.appveyor.com/project/cyrush/conduit" rel="nofollow"><img src="https://camo.githubusercontent.com/a0839e4a484ebb633a1c2ebcd90e345a176f5edc60e42f32636eefa9c3c79fad/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565"
    alt="Appveyor Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop&amp;svg=true"
    style="max-width: 100%;"></a>

    <a href="https://coveralls.io/github/LLNL/conduit?branch=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/50b12c605f0f4bcc64b6db415dddf2de99c5e19a526d7bc53e45db45c95b2931/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop"
    style="max-width: 100%;"></a>

    <a href="https://scan.coverity.com/projects/llnl-conduit" rel="nofollow"><img
    src="https://camo.githubusercontent.com/d4b204e42fe1ef30b166cdfd7cba043d5d74600b343aedd5e094a810b4c5c727/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31"
    alt="Static Analysis Status" data-canonical-src="https://scan.coverity.com/projects/8426/badge.svg?flat=1"
    style="max-width: 100%;"></a></p>

    <h1><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h1>

    <p>To get started building and using Conduit, check out the full documentation:</p>

    <p><a href="http://llnl-conduit.readthedocs.io/" rel="nofollow">http://llnl-conduit.readthedocs.io/</a></p>

    <h1><a id="user-content-source-repo" class="anchor" aria-hidden="true" href="#source-repo"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Repo</h1>

    <p>Conduit''s source is hosted on GitHub:</p>

    <p><a href="https://github.com/llnl/conduit">https://github.com/llnl/conduit</a></p>

    <h1><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h1>

    <p>Conduit is released under a BSD-style license - for detailed license info,
    refer to:</p>

    <p><a href="https://llnl-conduit.readthedocs.io/en/latest/licenses.html" rel="nofollow">https://llnl-conduit.readthedocs.io/en/latest/licenses.html</a></p>

    <p>or the following files in the Conduit source tree:</p>

    <ul>

    <li><a href="/LICENSE">LICENSE</a></li>

    <li><a href="/thirdparty_licenses.md">thirdparty_licenses.md</a></li>

    </ul>

    <h1><a id="user-content-changelog" class="anchor" aria-hidden="true" href="#changelog"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Changelog</h1>

    <ul>

    <li><a href="/CHANGELOG.md">Changelog</a></li>

    </ul>

    '
  stargazers_count: 148
  subscribers_count: 21
  topics:
  - hpc
  - scientific-computing
  - cpp
  - fortran
  - python
  - llnl
  - json
  - yaml
  - hdf5
  - radiuss
  - data-management
  updated_at: 1680637492.0
LLNL/radiuss-spack-testing:
  data_format: 2
  description: Gitlab CI automation of Spack testing with RADIUSS projects builds.
  filenames:
  - spack-environments/raja-suite/spack.yaml
  - spack-environments/radiuss/spack.yaml
  full_name: LLNL/radiuss-spack-testing
  latest_release: null
  readme: '<h1><a id="user-content-radiuss-spack-testing" class="anchor" aria-hidden="true"
    href="#radiuss-spack-testing"><span aria-hidden="true" class="octicon octicon-link"></span></a>RADIUSS
    Spack Testing</h1>

    <p>The RADIUSS project promotes and supports key High Performance Computing (HPC)
    open-source software developed at the LLNL. These tools and libraries cover a
    wide range of features a team would need to develop a modern simulation code targeting
    HPC plaftorms.</p>

    <p>RADIUSS Spack Testing is a sub-project from the RADIUSS initiative providing
    a

    testing infrastructure to test Spack Packages automatically in GitLab while

    tracking changes in Spack.</p>

    <p>Access the <a href="https://radiuss-spack-testing.readthedocs.io/" rel="nofollow">documentation</a>.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Started</h2>

    <p>The primary goal of this repo is to be used in Gitlab. The Gitlab CI configuration
    is such that it will use Spack pipeline feature to generate and run a pipeline
    that builds one of the environments in the <code>spack-environments</code> directory.</p>

    <p>The specific environment to be built is controlled by the CI variable <code>ENV_NAME</code>.</p>

    <h3><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>This project requires no installation.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Please read <a href="https://github.com/LLNL/radiuss-spack-testing/CONTRIBUTING.md">CONTRIBUTING.md</a>
    for details on our code of conduct, and the process for submitting pull requests
    to us.</p>

    <h2><a id="user-content-versioning" class="anchor" aria-hidden="true" href="#versioning"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Versioning</h2>

    <p>version: 1.0.0</p>

    <p>TODO: Not even sure how to handle versioning here.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Adrien M Bernede</p>

    <p>See also the list of <a href="https://github.com/LLNL/radiuss-spack-testing/contributors">contributors</a>
    who participated in this project.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a>
    file for details</p>

    <p>All new contributions must be made under the MIT License.</p>

    <p>See <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (MIT)</p>

    <p>LLNL-CODE-793462</p>

    <h2><a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgments</h2>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics:
  - radiuss
  updated_at: 1679009672.0
LLNL/radiuss-stack:
  data_format: 2
  description: A spack stack with radiuss (some) radiuss packages
  filenames:
  - spack.yaml
  full_name: LLNL/radiuss-stack
  latest_release: null
  readme: '<h1><a id="user-content-radiuss-stack" class="anchor" aria-hidden="true"
    href="#radiuss-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>RADIUSS
    Stack</h1>

    <p>The RADIUSS project promotes and supports key High Performance Computing (HPC)
    open-source software developed at the LLNL. These tools and libraries cover a
    wide range of features a team would need to develop a modern simulation code targeting
    HPC plaftorms.</p>

    <p>RADIUSS Stack project aims at creating a spack stack (environment) for RADIUSS
    projects, and test it with CI.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Started</h2>

    <p>This project is standalone and mainly consist of configuarion files for spack.</p>

    <h3><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h3>

    <p>This project introduces a radiuss stack described in <code>spack.yaml</code>.</p>

    <h3><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>This project requires no installation. Installing RADIUSS stack simply requires
    to run spack install in this directory.</p>

    <p>This has only be tested on Livermore Computing quartz. The goal being both
    to extend the number of machines it can be used on and complete the list of packages
    in the stack.</p>

    <h2><a id="user-content-running-the-tests" class="anchor" aria-hidden="true" href="#running-the-tests"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running the tests</h2>

    <p>Testing consists in building the stack on LC Gitlab CI.</p>

    <p>TODO: automate the update of spack.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Please read <a href="https://github.com/LLNL/radiuss-ci/CONTRIBUTING.md">CONTRIBUTING.md</a>
    for details on our code of conduct, and the process for submitting pull requests
    to us.</p>

    <h2><a id="user-content-versioning" class="anchor" aria-hidden="true" href="#versioning"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Versioning</h2>

    <p>version: 1.0.0</p>

    <p>TODO: Not even sure how to handle versioning here.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Adrien M Bernede</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a>
    file for details</p>

    <p>All new contributions must be made under the MIT License.</p>

    <p>See <a href="https://github.com/LLNL/radiuss-stack/blob/master/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/radiuss-stack/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/radiuss-stack/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (MIT)</p>

    <p>LLNL-CODE-793462</p>

    <h2><a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgments</h2>

    '
  stargazers_count: 1
  subscribers_count: 5
  topics: []
  updated_at: 1614636168.0
LLNL/serac:
  data_format: 2
  description: Serac is a high order nonlinear thermomechanical simulation code
  filenames:
  - scripts/spack/configs/toss_3_x86_64_ib/spack.yaml
  - scripts/spack/devtools_configs/toss_3_x86_64_ib/spack.yaml
  full_name: LLNL/serac
  latest_release: null
  readme: '<h1><a id="" class="anchor" aria-hidden="true" href="#"><span aria-hidden="true"
    class="octicon octicon-link"></span></a><a target="_blank" rel="noopener noreferrer"
    href="/share/serac/logo/serac-logo-blue.png?raw=true"><img src="/share/serac/logo/serac-logo-blue.png?raw=true"
    width="150" alt="Serac" style="max-width: 100%;"></a></h1>

    <p><a href="https://dev.azure.com/llnl-serac/serac/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/32116a71164a7fb6a2fcfe0a7c886af91fec3370119490e45e69481936df0830/68747470733a2f2f6465762e617a7572652e636f6d2f6c6c6e6c2d73657261632f73657261632f5f617069732f6275696c642f7374617475732f4c4c4e4c2e73657261633f6272616e63684e616d653d646576656c6f70"
    alt="Build Status" data-canonical-src="https://dev.azure.com/llnl-serac/serac/_apis/build/status/LLNL.serac?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://serac.readthedocs.io/en/latest/?badge=latest" rel="nofollow"><img
    src="https://camo.githubusercontent.com/b98a52491f8df53cc2e655f7f1ad48d32a2e3ccca2c3eee393b16cd34e237c5e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73657261632f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/serac/badge/?version=latest"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/gh/LLNL/serac" rel="nofollow"><img src="https://camo.githubusercontent.com/e6930e8581d65cfcd5b1d2a091d1260ffd65fbd0a61235d5eac8bc8914abbb09/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f73657261632f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d444f344b464d504e4d30"
    alt="codecov" data-canonical-src="https://codecov.io/gh/LLNL/serac/branch/develop/graph/badge.svg?token=DO4KFMPNM0"
    style="max-width: 100%;"></a>

    <a href="./LICENSE"><img src="https://camo.githubusercontent.com/3d6a8874ec039bb1f4d9ab5f71e22b2cbd98b9005f413da1066664ef444ec780/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/license-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a></p>

    <p>Serac is a 3D implicit nonlinear thermal-structural simulation code. Its primary
    purpose is to investigate multiphysics

    abstraction strategies and implicit finite element-based algorithm development
    for emerging computing architectures.

    It also serves as a proxy-app for LLNL''s Smith code and heavily leverages the
    <a href="https://mfem.org/" rel="nofollow">MFEM finite element library</a>.</p>

    <blockquote>

    <p>This project is under heavy development and is currently a pre-alpha release.
    Functionality and interfaces may change rapidly

    as development progresses.</p>

    </blockquote>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Build, run, and design documentation can be found at <a href="https://serac.readthedocs.io"
    rel="nofollow">readthedocs</a>.</p>

    <p>Source documentation can be found <a href="https://serac.readthedocs.io/en/latest/doxygen/html/index.html"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" href="#contributions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, and documentation
    edits.</p>

    <p>For more information, see the <a href="./CONTRIBUTING.md">contributing guide</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Copyright (c) 2019-2023, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Serac project are retained by contributors.

    No copyright assignment is required to contribute to Serac.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution<br>

    <code>LLNL-CODE-805541</code></p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" href="#spdx-usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SPDX usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" href="#external-packages"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>External Packages</h2>

    <p>Serac bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: Axom<br>

    PackageHomePage: <a href="https://github.com/LLNL/axom">https://github.com/LLNL/axom</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: MFEM<br>

    PackageHomePage: <a href="https://github.com/mfem/mfem">https://github.com/mfem/mfem</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 108
  subscribers_count: 12
  topics:
  - math-physics
  - finite-elements
  - proxy-application
  - simulation
  - cpp
  updated_at: 1681857744.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/e4s-quarterly/int64-double/spack.yaml
  - docker/sundials-ci/e4s-quarterly/int32-double/spack.yaml
  - docker/sundials-ci/spack-nightly/int32-double/spack.yaml
  - docker/sundials-ci/spack-nightly/int64-double/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.5.1
  readme: '<h1><a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" aria-hidden="true" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SUNDIALS: SUite of
    Nonlinear and DIfferential/ALgebraic equation Solvers</h1>

    <h3><a id="user-content-version-651-mar-2023" class="anchor" aria-hidden="true"
    href="#version-651-mar-2023"><span aria-hidden="true" class="octicon octicon-link"></span></a>Version
    6.5.1 (Mar 2023)</h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form

    $$M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form

    $$y'' = f(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form

    $$y'' = f(t,y,p), \quad y(t_0) = y_0(p)$$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form

    $$F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0''$$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form

    $$F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p)$$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form

    $$F(u) = 0 \quad \text{or} \quad G(u) = u$$</p>

    </li>

    </ul>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" href="#support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2><a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Slaven Peles, Cosmin Petra, H. Hunter Schwartz, Jean M. Sexton,

    Dan Shumaker, Steve G. Smith, Allan G. Taylor, Hilari C. Tiedeman, Chris White,

    Ting Yan, and Ulrike M. Yang.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 347
  subscribers_count: 35
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1681859646.0
LLNL/uberenv:
  data_format: 2
  description: Automates using spack to build and deploy software
  filenames:
  - .ci/test-project/spack_configs/darwin/spack.yaml
  - .ci/test-project/spack_configs/linux_ubuntu_22/spack.yaml
  full_name: LLNL/uberenv
  latest_release: v1.0.0
  readme: '<h1><a id="user-content-uberenv" class="anchor" aria-hidden="true" href="#uberenv"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>uberenv</h1>

    <p>Automates using a package manager to build and deploy software.</p>

    <p><a href="https://uberenv.readthedocs.io" rel="nofollow"><img src="https://camo.githubusercontent.com/02247bd3961daeb4d17d6d1d8f821df0c991efeb0c5f0411fed0a94bd9fa3ebe/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f75626572656e762f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Read the Docs" data-canonical-src="https://readthedocs.org/projects/uberenv/badge/?version=latest"
    style="max-width: 100%;"></a></p>

    <p>Uberenv is a python script that helps automate building

    third-party dependencies for development and deployment.</p>

    <p>Uberenv uses Spack (<a href="https://www.spack.io/" rel="nofollow">https://www.spack.io/</a>)
    on Unix-based systems (e.g. Linux and macOS)

    and Vcpkg (<a href="https://github.com/microsoft/vcpkg">https://github.com/microsoft/vcpkg</a>)
    on Windows systems.</p>

    <p>Uberenv was released as part of the Conduit project (<a href="https://github.com/LLNL/conduit/">https://github.com/LLNL/conduit/</a>).

    It is included in-source in several projects, this repo is used to hold the latest
    reference version.</p>

    <p>For more details, see Uberenv''s documention:</p>

    <p><a href="https://uberenv.readthedocs.io" rel="nofollow">https://uberenv.readthedocs.io</a></p>

    <p>You can also find details about how it is used in Conduit''s documentation:</p>

    <p><a href="https://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies"
    rel="nofollow">https://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies</a></p>

    <p>Conduit''s source repo also serves as an example for uberenv and spack configuration
    files, etc:</p>

    <p><a href="https://github.com/LLNL/conduit/tree/master/scripts/uberenv">https://github.com/LLNL/conduit/tree/master/scripts/uberenv</a></p>

    '
  stargazers_count: 20
  subscribers_count: 9
  topics:
  - shell
  - build-tools
  updated_at: 1676463765.0
LuisSalbey/environment_containers:
  data_format: 2
  description: null
  filenames:
  - dockerfile_intel_env/spack.yaml
  - dockerfile_gcc_env/spack.yaml
  full_name: LuisSalbey/environment_containers
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1635344357.0
Lumi-supercomputer/lumi-spack-settings:
  data_format: 2
  description: Spack configuration files for LUMI
  filenames:
  - 22.08/0.19.0/spack.yaml
  - 22.08/0.18.1/spack.yaml
  - 23.03/0.19.2/spack.yaml
  full_name: Lumi-supercomputer/lumi-spack-settings
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-for-lumi" class="anchor"
    aria-hidden="true" href="#spack-configuration-files-for-lumi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Spack configuration files for LUMI</h1>

    <p>Repository containing configuration files for the Spack instances installed
    in <code>/appl/lumi/spack</code> on LUMI for public use. The files in this repository
    can be found in <code>/appl/lumi/spack/etc/</code> on LUMI. The folder hierarchy
    is determined by the Cray Programming Environment (CPE) version and Spack release
    version. For example, the directory</p>

    <pre><code>22.08/0.18.1/

    22.08/0.18.1-user/

    </code></pre>

    <p>contains the configuration files for Spack version 0.18.1 configured to use
    CPE 22.08. The first instance <code>0.18.1</code> is the upstream instance, which
    is maintained by the LUMI Support Team. The second instance <code>0.18.1-user</code>
    is a separate instance configured to install packages in a user-defined directory
    in e.g. <code>/project/</code>. It is chained to the upstream instance, so that
    already installed packages can be reused.</p>

    <p>If you are user of LUMI, and want to set up your own instance, you can copy
    the <code>compilers.yaml</code>and  <code>packages.yaml</code> files to your instance.
    The <code>config.yaml</code> needs to be modified if you want to use that one.</p>

    '
  stargazers_count: 0
  subscribers_count: 12
  topics: []
  updated_at: 1675956191.0
MichaelBrim/unify-olcf-scripts:
  data_format: 2
  description: null
  filenames:
  - crusher/spack-env/spack.yaml
  - summit/spack-env/spack.yaml
  full_name: MichaelBrim/unify-olcf-scripts
  latest_release: null
  readme: '<h1><a id="user-content-unify-olcf-scripts" class="anchor" aria-hidden="true"
    href="#unify-olcf-scripts"><span aria-hidden="true" class="octicon octicon-link"></span></a>unify-olcf-scripts</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649778838.0
MiddelkoopT/spack-tutorial:
  data_format: 2
  description: Spack tutorial
  filenames:
  - spack.yaml
  full_name: MiddelkoopT/spack-tutorial
  latest_release: null
  stargazers_count: 3
  subscribers_count: 2
  topics: []
  updated_at: 1636098474.0
MuonColliderSoft/mucoll-spack:
  data_format: 2
  description: Muon Collider software repository for Spack
  filenames:
  - environments/mucoll-common/spack.yaml
  - environments/mucoll-release/spack.yaml
  full_name: MuonColliderSoft/mucoll-spack
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-package-repository-for-muon-collider-software-stack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#spack-package-repository-for-muon-collider-software-stack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>\n<a href=\"\
    https://github.com/spack/spack\">Spack</a> package repository for Muon Collider\
    \ software stack</h1>\n<p>This repository holds a set of Spack recipes for Muon\
    \ Collider software (under namespace <code>mucoll</code>) based on <a href=\"\
    https://key4hep.github.io/key4hep-doc/\" rel=\"nofollow\">Key4hep</a> stack. It\
    \ extends the corresponding <a href=\"https://github.com/key4hep/key4hep-spack\"\
    >key4hep-stack</a> repository, which is required for installation, overriding\
    \ several packages by the ones customised for Muon Collider simulation studies.</p>\n\
    <p>After installing <a href=\"https://github.com/key4hep/spack\">Spack</a> and\
    \ downloading the <a href=\"https://github.com/key4hep/key4hep-spack\">key4hep-spack</a>\
    \ and <a href=\"https://github.com/MuonColliderSoft/mucoll-spack\">mucoll-spack</a>\
    \ repositories, the whole software stack can be installed using the following\
    \ commands:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Add repositories</span>\nspack repo add ./key4hep-spack\n\
    spack repo add ./mucoll-spack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a Spack environment</span>\nspack env create sim\nspack env activate\
    \ sim\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy package configurations</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Install the software stack</span>\nspack add mucoll-stack\nspack\
    \ concretize --reuse\nspack install --fail-fast\n\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Load the Muon Collider environment</span>\n<span class=\"\
    pl-c1\">source</span> <span class=\"pl-smi\">$MUCOLL_STACK</span></pre></div>\n\
    <h2><a id=\"user-content-setting-up-the-environment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setting-up-the-environment\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Setting up the environment</h2>\n<p>When signing\
    \ in to a machine with the installed sofware stack (VM or Docker container), it\
    \ has to be loaded into the environment:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack env activate sim\n<span class=\"pl-c1\">source</span> <span class=\"\
    pl-smi\">$MUCOLL_STACK</span></pre></div>\n<h2><a id=\"user-content-package-versioning\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#package-versioning\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Package versioning</h2>\n<p>Preferred\
    \ convention for version names in Spack is numbers separated by dots, without\
    \ leading zeros, e.g. <code>1.2.13</code>.\nConversion to tag names in <code>mucoll</code>\
    \ packages is provided by <code>MCIlcsoftpackage</code> class defined in <code>packages/mucoll-stack/mucoll_utils.py</code>,\
    \ e.g. for <a href=\"https://github.com/MuonColliderSoft/lcgeo/releases/tag/v00-17-MC\"\
    ><code>lcgeo</code></a> package version <code>0.17</code> corresponds to tag name\
    \ <code>v00-17-MC</code>.</p>\n<h2><a id=\"user-content-adding-new-versions-for-individual-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-versions-for-individual-packages\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new\
    \ versions for individual packages</h2>\n<p>After a new tag for the package is\
    \ created, e.g. <code>v00-17-MC</code> in <code>lcgeo</code> repository, it can\
    \ be added to this Spack repository in two steps:</p>\n<ol>\n<li>Get the archive\
    \ checksum for the new tag</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack checksum lcgeo 0.17\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Validates archive URL and returns the checksum</span>\n    version(<span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>0.17<span class=\"pl-pds\">'</span></span>,\
    \ sha256=<span class=\"pl-s\"><span class=\"pl-pds\">'</span>5ab33aaf5bc37deba82c2dde78cdce6c0041257222ed7ea052ecdd388a41cf9b<span\
    \ class=\"pl-pds\">'</span></span>)</pre></div>\n<ol start=\"2\">\n<li>Add the\
    \ returned version definition to the corresponding package file: <a href=\"packages/lcgeo/package.py\"\
    ><code>packages/lcgeo/package.py</code></a>\n</li>\n</ol>\n<blockquote>\n<p>NOTE:\
    \ This repository only contains packages maintained by the Muon Collider collaboration.\n\
    If the version of interest is missing from Spack for some other package, the line\
    \ with a new version definition should be added to the package file in the corresponding\
    \ repository.<br>\nTo see locations of other repositories: <code>spack repo list</code></p>\n\
    </blockquote>\n<h2><a id=\"user-content-creating-a-new-stack-release\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#creating-a-new-stack-release\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Creating a new stack release</h2>\n\
    <p>To introduce a new release version for the whole software stack, update the\
    \ version number in <a href=\"packages/mucoll-stack/package.py\"><code>packages/mucoll-stack/package.py</code></a>\
    \ and then update versions of all the relevant packages in [environments/mucoll-release/packages.yaml].<br>\n\
    Test this new configuration in a fresh environment:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Create a development environment</span>\nspack env create dev\nspack env activate\
    \ dev\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Copy the package configuration</span>\n\
    cp ./mucoll-spack/environments/mucoll-release/<span class=\"pl-k\">*</span>.yaml\
    \ <span class=\"pl-smi\">$SPACK_ENV</span>/\n\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Add stack with updated version to the environment</span>\nspack\
    \ add mucoll-stack\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Check\
    \ which packages would be installed</span>\nspack spec --reuse -NIt</pre></div>\n\
    <p>Packages that are already installed in the <code>sim</code> environment are\
    \ known to Spack and will be reused, providing a clear indication of which part\
    \ of the dependency tree will be modified by the new release.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1679435634.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/cori-e4s-21.02/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/gerty/spack.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/cce/spack.yaml
  - docs/spack.yaml
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/perlmutter-user-spack/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The spack infrastructure\
    \ repository contains spack configuration in the form of <code>spack.yaml</code>\
    \ required to build spack stacks on Cori and Perlmutter system. We leverage gitlab\
    \ to automate software stack deployment which is configured using the <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> file. The documentation is available at\
    \ <a href=\"https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <h2><a id=\"user-content-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-configuration\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack Configuration</h2>\n<p>The spack configuration\
    \ can be found in <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\"\
    \ rel=\"nofollow\">spack-configs</a> directory with subdirectory for each deployment.\n\
    Each pipeline can be run if one sets the variable <code>PIPELINE_NAME</code> to\
    \ a unique value in order to run a pipeline. You can check the <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\"\
    \ rel=\"nofollow\">.gitlab-ci.yml</a> for the gitlab configuration. The pipeline\
    \ can be run via <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web interface</a>, if you chose this route, you must set <code>PIPELINE_NAME</code>\
    \ to the appropriate value.</p>\n<p>If you want to trigger pipeline via <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"\
    nofollow\">web-interface</a> you will need to define PIPELINE_NAME variable to\
    \ trigger the appropriate pipeline.</p>\n<h2><a id=\"user-content-running-ci-pipelines\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-ci-pipelines\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running CI Pipelines</h2>\n<p>This\
    \ project is configured with several <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\"\
    \ rel=\"nofollow\">scheduled pipelines</a> that will run at different times.</p>\n\
    <p>Currently, we have a shell runner installed on Perlmutter using <code>e4s</code>\
    \ account which is configured with following settings. You can find list of runners\
    \ and their runner status under <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\"\
    \ rel=\"nofollow\">Settings &gt; CI/CD &gt; Runners</a>. Please make sure you\
    \ login to the appropriate hostname when starting the gitlab runner.</p>\n<table>\n\
    <thead>\n<tr>\n<th>System</th>\n<th>Runner Name</th>\n<th>Hostname</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>perlmutter</td>\n<td><code>perlmutter-e4s</code></td>\n\
    <td><code>login27</code></td>\n</tr>\n<tr>\n<td>cori</td>\n<td><code>cori-e4s</code></td>\n\
    <td><code>cori02</code></td>\n</tr>\n<tr>\n<td>muller</td>\n<td><code>muller-e4s</code></td>\n\
    <td><code>login02</code></td>\n</tr>\n<tr>\n<td>gerty</td>\n<td><code>gerty-e4s</code></td>\n\
    <td><code>gert01</code></td>\n</tr>\n</tbody>\n</table>\n<p>The runner configuration\
    \ files are located in <code>~/.gitlab-runner</code> for user <strong>e4s</strong>.</p>\n\
    <p>The production pipelines are triggered via web-interface which requires approval\
    \ from a project maintainer. Production pipelines should be run when we need to\
    \ do full redeployment of stack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#current-challenges\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Current Challenges</h2>\n<p>There\
    \ are several challenges with building spack stack at NERSC which can be summarized\
    \ as follows</p>\n<ul>\n<li>\n<p><strong>System OS + Cray Programming Environment\
    \ (CPE) changes</strong>: A system upgrade such as change to <code>glibc</code>\
    \ or upgrades in CPE can lead to full software stack rebuild, especially if you\
    \ have external packages set for packages like <code>cray-mpich</code>, <code>cray-libsci</code>\
    \ which generally change between versions</p>\n</li>\n<li>\n<p><strong>Incompatibile\
    \ compilers</strong>: Some packages can't be built with certain compilers (<code>nvhpc</code>,\
    \ <code>aocc</code>) which could be due to several factors.</p>\n<ul>\n<li>An\
    \ application doesn't have support though it was be added in newer version but\
    \ you don't have it in your spack release used for deployment</li>\n<li>Lack of\
    \ support in spack package recipe or spack-core base including spack-cray detection.\
    \ This may require getting fix and cherry-pick commit or waiting for new version</li>\n\
    <li>Spack Cray detection is an important part in build errors including how one\
    \ specifies externals via <code>modules</code> vs <code>prefix</code> both could\
    \ be provided and it requires experimentation. An example of this is trying to\
    \ get <code>cray-mpich</code> external one could set something like this with\
    \ modules or prefix</li>\n</ul>\n<div class=\"highlight highlight-source-yaml\"\
    ><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n    <span class=\"pl-ent\"\
    >buildable</span>: <span class=\"pl-c1\">false</span>\n    <span class=\"pl-ent\"\
    >externals</span>:\n    - <span class=\"pl-ent\">spec</span>: <span class=\"pl-s\"\
    >cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"pl-ent\">prefix</span>:\
    \ <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n      <span\
    \ class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contact</h2>\n\
    <p>If you need elevated privledge or assistance with this project please contact\
    \ one of the maintainers:</p>\n<ul>\n<li><strong>Shahzeb Siddiqui (<a href=\"\
    mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>)</strong></li>\n\
    <li><strong>Erik Palmer (<a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>)</strong></li>\n\
    <li><strong>Justin Cook (<a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>)</strong></li>\n\
    <li>E4S Team: <strong>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</strong>, <strong>Christopher Peyralans (<a href=\"\
    mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>)</strong>, <strong>Wyatt\
    \ Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>)</strong>,\
    \ <strong>Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</strong>\n\
    </li>\n</ul>\n"
  stargazers_count: 8
  subscribers_count: 14
  topics: []
  updated_at: 1673545287.0
NOAA-EMC/GSI-Monitor:
  data_format: 2
  description: GSI Monitoring Tools
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-Monitor
  latest_release: null
  readme: "<h1><a id=\"user-content-gsi-monitor\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#gsi-monitor\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>GSI-Monitor</h1>\n<p>GSI Monitoring Tools</p>\n<p>These tools monitor\
    \ the Gridpoint Statsical Interpolation (GSI) package's data assimiliation, detecting\n\
    and reporting missing data sources, low obervational counts, and high penalty\
    \ values.</p>\n<p>Suite includes:</p>\n<pre><code>  ConMon   Conventional Monitor\
    \     \n  MinMon   GSI Minimization Monitor \n  OznMon   Ozone Monitor       \
    \     \n  RadMon   Radiance Monitor         \n</code></pre>\n<p>PoC:  <a href=\"\
    mailto:edward.safford@noaa.gov\">edward.safford@noaa.gov</a></p>\n"
  stargazers_count: 2
  subscribers_count: 0
  topics: []
  updated_at: 1680132912.0
NOAA-EMC/GSI-utils:
  data_format: 2
  description: GSI related utilities
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI-utils
  latest_release: null
  readme: '<h1><a id="user-content-gsi-utils" class="anchor" aria-hidden="true" href="#gsi-utils"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GSI-Utils</h1>

    <p>GSI Utility Tools</p>

    <p>These are GSI utilities for various functions.</p>

    <p>For installation instruction see <a href="./INSTALL.md">here</a></p>

    '
  stargazers_count: 2
  subscribers_count: 8
  topics: []
  updated_at: 1675565618.0
NOAA-EMC/NCEPLIBS-grib_util:
  data_format: 2
  description: This is a collection of NCEP GRIB related utilities.
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/NCEPLIBS-grib_util
  latest_release: v1.2.4
  readme: '<h1><a id="user-content-nceplibs-grib_util" class="anchor" aria-hidden="true"
    href="#nceplibs-grib_util"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCEPLIBS-grib_util</h1>

    <p>This is a collection of NCEP GRIB related utilities. This is related

    to the <a href="https://github.com/NOAA-EMC/NCEPLIBS">NCEPLIBS</a> project.</p>

    <p>For complete documentation see

    <a href="https://noaa-emc.github.io/NCEPLIBS-grib_util/" rel="nofollow">https://noaa-emc.github.io/NCEPLIBS-grib_util/</a>.
    For the NCEP WMO GRIB2

    Documentation see

    <a href="https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/" rel="nofollow">https://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc/</a>.</p>

    <h2><a id="user-content-related-nceplibs-projects" class="anchor" aria-hidden="true"
    href="#related-nceplibs-projects"><span aria-hidden="true" class="octicon octicon-link"></span></a>Related
    NCEPLIBS Projects</h2>

    <table>

    <thead>

    <tr>

    <th>Repository</th>

    <th>Notes</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2c">NCEPLIBS-g2c</a></td>

    <td>C implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></td>

    <td>Fortran implementation of the GRIB 2 functions</td>

    </tr>

    <tr>

    <td><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></td>

    <td>Utilities for GRIB2 templates</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <table>

    <thead>

    <tr>

    <th>Utility</th>

    <th>Author(s)</th>

    <th>User(s)</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>cnvgrib</td>

    <td>Stephen Gilbert, Gordon, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>copygb</td>

    <td>Mark Iredell, Stephen Gilbert, Trojan, Boi Vuong</td>

    <td>UFS_UTILS</td>

    </tr>

    <tr>

    <td>copygb2</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>degrib2</td>

    <td>Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grb2index</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong</td>

    <td>???</td>

    </tr>

    <tr>

    <td>grbindex</td>

    <td>Mark Iredell, Stephen Gilbert, Boi Vuong, W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    <tr>

    <td>tocgrib</td>

    <td>Stephen Gilbert, Boi Vuong, Farley, R. E. Jones</td>

    <td>RAP for FAA</td>

    </tr>

    <tr>

    <td>tocgrib2</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>tocgrib2super</td>

    <td>Stephen Gilbert, Boi Vuong</td>

    <td>(GFS, NAM, SMOKE, RAP, HRRR, NWPS, etc.) in production for AWIPS  and NDFD</td>

    </tr>

    <tr>

    <td>wgrib</td>

    <td>W. Ebisuzaki</td>

    <td>FAA and AWIPS (CONUS grid id 211)</td>

    </tr>

    </tbody>

    </table>

    <p>Code Manager : Hang Lei, Edward Hartnett</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This package requires the following third party libraries:</p>

    <ul>

    <li><a href="http://www.ece.uvic.ca/~mdadams/jasper/" rel="nofollow">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="http://www.gzip.org/zlib/" rel="nofollow">libz</a></li>

    </ul>

    <p>This package requires the folling NCEPLIBS libraries:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a> (before
    version 1.3.0)</li>

    <li>

    <a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a> (starting
    version 1.3.0)</li>

    </ul>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <pre><code>mkdir build

    cd build

    cmake -DCMAKE_INSTALL_PREFIX=/path/to/install -DCMAKE_PREFIX_PATH=/path/to/dependencies
    ..

    make -j4

    make install

    </code></pre>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 7
  subscribers_count: 3
  topics: []
  updated_at: 1680626680.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: upp-srw-v2.1.0
  readme: '<h1><a id="user-content-unified-post-processing-upp" class="anchor" aria-hidden="true"
    href="#unified-post-processing-upp"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unified
    Post-Processing (UPP)</h1>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecasting System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Application

    Forecasting System (HAFS), and the Medium Range Weather (MRW) and Short

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model

    derived brightness temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages, or for

    further downstream post-processing, e.g. statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <h2><a id="user-content-user-support" class="anchor" aria-hidden="true" href="#user-support"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>User Support</h2>

    <p>Support for the UFS UPP is provided through <a href="https://github.com/NOAA-EMC/UPP/discussions">GitHub
    Discussions</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>User Guide for latest public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <h2><a id="user-content-developer-information" class="anchor" aria-hidden="true"
    href="#developer-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>Developer
    Information</h2>

    <p>Please see review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Kate Fossell</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>The UPP requires certain NCEPLIB packages to be installed via

    the HPC-Stack project.</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3nco">NCEPLIBS-w3nco</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-gfsio">NCEPLIBS-gfsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">libz</a></li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for Regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 25
  subscribers_count: 16
  topics: []
  updated_at: 1680455964.0
NOAA-EMC/spack-stack:
  data_format: 2
  description: null
  filenames:
  - configs/templates/skylab-no-python-dev/spack.yaml
  full_name: NOAA-EMC/spack-stack
  latest_release: 1.3.0
  readme: '<h1><a id="user-content-spack-stack" class="anchor" aria-hidden="true"
    href="#spack-stack"><span aria-hidden="true" class="octicon octicon-link"></span></a>spack-stack</h1>

    <p>Spack-stack enables the installation of software required

    for HPC system deployments of NOAA''s Unified Forecast System (UFS) and

    other weather and climate models, including components of the Joint

    Effort for Data assimilation Integration (JEDI).</p>

    <p>Spack-stack is a collaborative effort between:</p>

    <ul>

    <li><a href="https://www.emc.ncep.noaa.gov/emc_new.php" rel="nofollow">NOAA Environmental
    Modeling Center (EMC)</a></li>

    <li><a href="https://www.jcsda.org/" rel="nofollow">UCAR Joint Center for Satellite
    Data Assimilation (JCSDA)</a></li>

    <li>

    <a href="https://epic.noaa.gov/" rel="nofollow">Earth Prediction Innovation Center
    (EPIC)</a>.</li>

    </ul>

    <p>Spack-stack is a thin layer around a fork of the

    <a href="https://github.com/spack/spack">spack</a> repository. Spack is a

    community-supported, multi-platform, Python-based package manager

    originally developed by the Lawrence Livermore National Laboratory

    (LLNL). Spack is provided as a submodule to spack-stack so that a

    stable version can be referenced. For more information about spack see

    the <a href="https://computing.llnl.gov/projects/spack-hpc-package-manager" rel="nofollow">LLNL
    project page for

    spack</a>

    and the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack

    documentation</a>.</p>

    <p>The stack can be installed on a range of platforms, from Linux and

    macOS laptops to HPC systems, and comes pre-configured for many

    systems. Users can install the necessary packages for a particular

    application and later add the missing packages for another application

    without having to rebuild the entire stack.</p>

    <p>spack-stack is mainly a collection of Spack configuration files, but

    provides a Spack extension to simplify the installation process:</p>

    <ul>

    <li>

    <p><code>spack stack create</code> is provided to copy common, site-specific,
    and

    application-specific configuration files into a coherent Spack

    environment and to create container recipes</p>

    </li>

    <li>

    <p><code>spack stack setup-meta-modules</code> creates compiler, MPI and Python

    meta-modules for a convenient setup of a user environment using

    modules (lua and tcl)</p>

    </li>

    </ul>

    <p>Documentation for installing and using spack-stack can be found here:

    <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a></p>

    <p>spack-stack is maintained by:</p>

    <ul>

    <li>

    <p><a href="https://www.github.com/AlexanderRichert-NOAA">Alex Richert</a>, <a
    href="https://www.github.com/Hang-Lei-NOAA">Hang

    Lei</a>, <a href="https://www.github.com/edwardhartnett">Ed

    Hartnett</a> NOAA-EMC</p>

    </li>

    <li>

    <p><a href="https://www.github.com/climbfuji">Dom Heinzeller</a>, JCSDA</p>

    </li>

    </ul>

    <p>For more information about the organization of the spack-stack

    project, see the <a href="project_charter.md">Project Charter</a>.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    '
  stargazers_count: 16
  subscribers_count: 7
  topics: []
  updated_at: 1680703509.0
NOAA-GFDL/AM4:
  data_format: 2
  description: null
  filenames:
  - container/spack_intel_gfdl_model.yaml
  full_name: NOAA-GFDL/AM4
  latest_release: highres_aquaplanet_2022
  readme: '<h1><a id="user-content-gfdl-am4-model" class="anchor" aria-hidden="true"
    href="#gfdl-am4-model"><span aria-hidden="true" class="octicon octicon-link"></span></a>GFDL
    AM4 Model</h1>

    <p><a href="https://zenodo.org/badge/latestdoi/102487636" rel="nofollow"><img
    src="https://camo.githubusercontent.com/878db836b9000fd7d9ff531257cade7343f3a3fdf8f764b5a7f1e8ef6ccc6abe/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3130323438373633362e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/102487636.svg" style="max-width:
    100%;"></a></p>

    <p>This repository includes the public release of the GFDL AM4 model

    code.  The AM4 model is described in the

    <a href="https://doi.org/10.1002/2017MS001208" rel="nofollow">two</a>

    <a href="https://doi.org/10.1002/2017MS001209" rel="nofollow">articles</a> published
    in the

    <a href="https://agupubs.onlinelibrary.wiley.com/journal/19422466" rel="nofollow">Journal
    of Advances in Modeling Earth Systems

    (JAMES)</a>.

    More information on the model and access to the output is available on

    the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">AM4
    data and code

    site</a> at the

    <a href="https://www.gfdl.noaa.gov" rel="nofollow">Geophysical Fluid Dynamics
    Laboratory

    (GFDL)</a>.</p>

    <p>The layout of this package includes the following directories:</p>

    <ul>

    <li>src - The source code for the AM4 model</li>

    <li>exec - The build directory with Makefiles for building the AM4 model executable</li>

    <li>idealized_exec - The build directory with Makefiles for building the aquaplanet

    and doubly periodic executable</li>

    <li>run - Sample run script and updated files needed for running</li>

    <li>analysis - Sample analysis scripts</li>

    </ul>

    <h2><a id="user-content-cloning-instructions" class="anchor" aria-hidden="true"
    href="#cloning-instructions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cloning
    Instructions</h2>

    <p>This repository uses <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"
    rel="nofollow">git

    submodules</a> to

    point to other repositories.  Thus, care should be taken when cloning,

    and updating the source to ensure all source.  To obtain all source,

    use the following git command</p>

    <pre><code>git clone --recursive https://github.com/NOAA-GFDL/AM4.git

    </code></pre>

    <p>The <code>--recursive</code> option to <code>git clone</code> instructs git
    to recursively

    clone all submodules.  In the event the repository was not cloned

    using the <code>--recursive</code> option, the following step must be taken to

    obtain all sources:</p>

    <pre><code># From within the AM4 parent directory

    git submodule update --init --recursive

    </code></pre>

    <h2><a id="user-content-source-code" class="anchor" aria-hidden="true" href="#source-code"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Code</h2>

    <p>All model source is contained in the <a href="src">src</a> directory.  GFDL

    tracks code using the git version control system.  This package

    includes a single version of the following GFDL model components.  The

    git hash listed corresponds to the commit hash in the internal GFDL

    git repository.</p>

    <table>

    <thead>

    <tr>

    <th>Component</th>

    <th>Commit Hash</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>atmos_drivers</td>

    <td>5ee95d6abf0879594551dd7e6635dff4004c4010</td>

    </tr>

    <tr>

    <td>atmos_param</td>

    <td>2e94acfd8621e85216bf822c395a8c3f15a511a5</td>

    </tr>

    <tr>

    <td>atmos_shared</td>

    <td>a557d4d7bab033ef1ad1d400a62fe07a97ccb477</td>

    </tr>

    <tr>

    <td>ice_param</td>

    <td>1553c8bc4f9a66791c89367b6f327147523155ed</td>

    </tr>

    <tr>

    <td>ice_sis</td>

    <td>ccc7328dcd79706dd5c17c8bab660222886fc80b</td>

    </tr>

    <tr>

    <td>land_lad2</td>

    <td>a220288ecb289bf9d793d051fc5076072874ce07</td>

    </tr>

    </tbody>

    </table>

    <p>The following components are available in the

    <a href="https://github.com/NOAA-GFDL">NOAA-GFDL</a> github organization:</p>

    <ul>

    <li><a href="https://github.com/NOAA-GFDL/MOM6">MOM6</a></li>

    <li><a href="https://github.com/NOAA-GFDL/coupler">coupler</a></li>

    <li>

    <a href="https://github.com/NOAA-GFDL/FMS">FMS</a> (as <a href="src/shared">shared</a>)</li>

    <li>

    <a href="https://github.com/NOAA-GFDL/GFDL_atmos_cubed_sphere">GFDL_atmos_cubed_sphere
    (tag AM4.0)</a> (as <a href="src/atmos_cubed_sphere">atmos_cubed_sphere</a>)</li>

    </ul>

    <h2><a id="user-content-building-am4" class="anchor" aria-hidden="true" href="#building-am4"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building AM4</h2>

    <p>###Containers

    The <a href="container">container folder</a> provides example Dockerfiles and
    Signularity

    definition files to use to build AM4 containers using either GCC/GFORTAN or

    Intel oneAPI. There is a script that can be used to build the intel

    singularity containers, and the first step of this script can be used with the

    other GFDL climate models.</p>

    <h3><a id="user-content-from-source" class="anchor" aria-hidden="true" href="#from-source"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>From source</h3>

    <p>The <a href="exec">exec</a> directory contains Makefiles that can be used to

    build the AM4 executable.  These Makefiles were generated using the

    <a href="https://github.com/NOAA-GFDL/mkmf">Make Makefile (mkmf)</a> program.

    Included in the exec direcgtory is a sample make template file for the

    Intel compilers (<a href="exec/templates/intel.mk">intel.mk</a>).  This make

    template can be used on any system with a relatively recent version of

    the Intel compilers, the netCDF 4 library and the MPICH2 MPI library.

    Included in the <a href="exec/templates/intel.mk">intel.mk</a> file are

    additional settings that can be modified during the build.</p>

    <p>To run the default build (-O3 -msse2), go to the exec directory and

    enter the command</p>

    <pre><code>make

    </code></pre>

    <p>If you would like to change some of the compiler options, there are several
    different

    options to add to the make command.  For example</p>

    <pre><code>make ISA=-xhost BLD_TYPE=REPRO

    </code></pre>

    <p>will replace -msse with -xhost and -O3 with -O2.  The three options for

    <code>BLD_TYPE</code> are<br>

    <code>PROD</code> (-O3)<br>

    <code>REPRO</code> (-O2)<br>

    <code>DEBUG</code> (-O0 and other traps)<br>

    All of the make line options can be

    found in the <a href="exec/templates/intel.mk">intel.mk</a> file.</p>

    <h2><a id="user-content-obtaining-the-input-data" class="anchor" aria-hidden="true"
    href="#obtaining-the-input-data"><span aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining
    the input data</h2>

    <p>The input data required for running the AM4 model can be found on

    <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">GFDL''s
    data

    portal</a> .</p>

    <p>The file <code>AM4.tar.gz</code> contains a configured run directory to run
    a

    sample experiment of the AM4 model.  Included in the tar file is a

    README.AM4_run with more instructions on how to configure the AM4 run

    directory.</p>

    <p>On Linux systems, the <code>wget</code> command is usually sufficient to download
    the data

    file:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz

    </code></pre>

    <p>To ensure the file downloaded is complete and not corrupted, download one of
    the two files:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sha256

    wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sig

    </code></pre>

    <p>and run the following command that corresponds to the signature file downloaded:</p>

    <pre><code>sha256sum -c AM4_run.tar.gz.sha256

    </code></pre>

    <pre><code>gpg --verify AM4_run.tar.gz.sig

    </code></pre>

    <h2><a id="user-content-running-am4" class="anchor" aria-hidden="true" href="#running-am4"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running AM4</h2>

    <p>Included in the run directory is a sample run script for reference.

    To run the AM4 sample experiment, first download the data file

    mentioned in <a href="#obtaining-the-input-data">Obtaining the Input data</a>

    section.  Replace diag_table and input.nml in the top level of the

    untar''d directory with the corresponding files in the run directory

    of this repository. Modify the variables in the configuration section

    in the sample run script, and then run the script.</p>

    <p>The sample data and run script are configured to run on 216

    processors.  To run on a different number of processors, or modify the

    experiment, refer to the <code>README.AM4_run</code> file included in the AM4

    data tarball.</p>

    <p>Note: The <code>input.nml</code> file (found in the AM4 data tarball) contains

    Fortran namelists and namelist variables that modify, at run time, the

    model.  To learn more about the settings in the <code>input.nml</code> file,

    please refer to source code where the namelist/variable are defined.</p>

    <h2><a id="user-content-analysis-scripts" class="anchor" aria-hidden="true" href="#analysis-scripts"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Analysis Scripts</h2>

    <p>Some of the climate analysis scripts run at NOAA GFDL and used in the

    AM4 documentation papers are located in the analysis directory.

    Within each analysis suite, is a <a href="https://jupyter-notebook.readthedocs.io/en/stable/"
    rel="nofollow">jupyter

    notebook</a>, both

    readable and runnable from your local jupyter environment, provided

    all dependencies are installed.</p>

    <p>E.g.</p>

    <ul>

    <li><a href="analysis/cjs1/radiation_atmos_av_mon/radiation_atmos_av_mon.ipynb">Radiation
    processor</a></li>

    <li><a href="analysis/bw/bw_atmos_cru_ts_a1r/bw_atmos_monthly_cru_ts.1980-2014.ipynb">Long-term
    DJF seasonal mean</a></li>

    <li><a href="analysis/bw/bw_atmos_zm_atl_pac_a1r/bw_atmos_atl_pac.1980-2014.ipynb">Zonal_mean_zonal_wind_stress</a></li>

    <li><a href="analysis/pcmdimetrics/portraitPlot-AM4.AMIP.ipynb">PCMDI Metrics
    Portrait Plot</a></li>

    </ul>

    <h2><a id="user-content-model-output-and-other-references" class="anchor" aria-hidden="true"
    href="#model-output-and-other-references"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Model output and Other References</h2>

    <p>Please refer to the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/"
    rel="nofollow">AM4 data and code

    site</a> for details

    about where to find model and OBS data used in the papers.</p>

    <p>For all analysis figures and pertaining data, please use the AM4

    documentation papers as the original reference.</p>

    <p>Please direct your questions and feedback to

    <a href="mailto:gfdl.climate.model.info@noaa.gov">gfdl.climate.model.info@noaa.gov</a></p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an ''as is'' basis and the user assumes responsibility for

    its use.  DOC has relinquished control of the information and no

    longer has responsibility to protect the integrity, confidentiality,

    or availability of the information.  Any claims against the Department

    of Commerce stemming from the use of its GitHub project will be

    governed by all applicable Federal law.  Any reference to specific

    commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply

    their endorsement, recommendation or favoring by the Department of

    Commerce.  The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <p>This project code is made available through GitHub but is managed by

    NOAA-GFDL at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 11
  subscribers_count: 7
  topics:
  - fortran
  - jupyter-notebook
  - shell-script
  - ncl
  updated_at: 1645229928.0
NOAA-GFDL/ESM4:
  data_format: 2
  description: null
  filenames:
  - container/spack_intel_gfdl_model.yaml
  full_name: NOAA-GFDL/ESM4
  latest_release: '2021.03'
  readme: '<h1><a id="user-content-earth-system-model-4" class="anchor" aria-hidden="true"
    href="#earth-system-model-4"><span aria-hidden="true" class="octicon octicon-link"></span></a>Earth
    System Model 4</h1>

    <h2><a id="user-content-what-is-included" class="anchor" aria-hidden="true" href="#what-is-included"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>What Is Included</h2>

    <ul>

    <li>[src]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/src">https://github.com/NOAA-GFDL/ESM4/tree/master/src</a>)
    source code for the ESM4 model (all code is in submodules)</li>

    <li>[exec]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/exec">https://github.com/NOAA-GFDL/ESM4/tree/master/exec</a>)
    Makefiles to compile the code</li>

    <li>[run]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/run">https://github.com/NOAA-GFDL/ESM4/tree/master/run</a>)
    Simple run script</li>

    </ul>

    <h2><a id="user-content-cloning" class="anchor" aria-hidden="true" href="#cloning"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Cloning</h2>

    <p>To clone the ESM4 model please use the recursive option</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive git@github.com:NOAA-GFDL/ESM4.git
    </pre></div>

    <p>or</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/NOAA-GFDL/ESM4.git</pre></div>

    <h2><a id="user-content-compiling" class="anchor" aria-hidden="true" href="#compiling"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compiling</h2>

    <h3><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    href="#building-the-container"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>The <a href="container">container folder</a> provides example Dockerfiles and
    Signularity

    definition files to use to build AM4 containers using either GCC/GFORTAN or

    Intel oneAPI. There is a script that can be used to build the intel

    singularity containers, and the first step of this script can be used with the

    other GFDL climate models.</p>

    <h3><a id="user-content-building-from-source" class="anchor" aria-hidden="true"
    href="#building-from-source"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    from source</h3>

    <p>This model was originally compiled and run with the intel16 compiler.

    It is recommended that you compile with an intel compiler.</p>

    <p>Compiling assumes that you have an intel compiler, MPI (impi, mpich,

    openmpi, etc), netcdf, and hdf5 in your LD_LIBRARY_PATH and LIBRARY_PATH.

    It is also assumed that nf-config and nc-config are in your path.

    If you work on a machine with modules, you may need to load these

    packages into your environment.</p>

    <p>Makefiles have been included in the

    <a href="https://github.com/NOAA-GFDL/ESM4/tree/master/exec">exec/</a> folder.

    There are several option for compiling, which can be found in the

    <a href="https://github.com/NOAA-GFDL/ESM4/blob/master/exec/templates/intel.mk">template/intel.mk</a>.<br>

    You may need to edit the template/intel.mk to update the compiler names

    or add any CPPDEF options specific for your system.

    The most common compile with optimizations on and with openmp would be</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    <span class="pl-c1">exec</span>

    make OPENMP=on</pre></div>

    <p>If you would like to compile with <em>-O2</em> instead of <em>-O3</em> do</p>

    <div class="highlight highlight-source-shell"><pre>make REPRO=on OPENMP=on</pre></div>

    <p>To compile with <em>-O0</em> and debug flags do</p>

    <div class="highlight highlight-source-shell"><pre>make BLD_TYPE=DEBUG OPENMP=on</pre></div>

    <p>Compiling with openMP is optional.</p>

    <p>Here are examples of how to compile the model on various systems:</p>

    <p>gaea (NOAA RDHPCS cray system)</p>

    <div class="highlight highlight-source-shell"><pre>module load intel

    module load cray-netcdf

    module load cray-hdf5

    git clone --recursive git@github.com:NOAA-GFDL/ESM4.git

    <span class="pl-c1">cd</span> ESM4/exec

    make MKL_LIBS=<span class="pl-s"><span class="pl-pds">"</span>none<span class="pl-pds">"</span></span>
    OPENMP=y</pre></div>

    <p>Compiling on orion (MSU)</p>

    <div class="highlight highlight-source-shell"><pre>module load intel impi netcdf
    hdf5

    <span class="pl-k">export</span> LIBRARY_PATH=<span class="pl-smi">${LIBRARY_PATH}</span>:<span
    class="pl-smi">${LD_LIBRARY_PATH}</span>

    git clone --recursive git@github.com:NOAA-GFDL/ESM4.git

    <span class="pl-c1">cd</span> ESM4/exec

    make OPENMP=on</pre></div>

    <h2><a id="user-content-model-running" class="anchor" aria-hidden="true" href="#model-running"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Model running</h2>

    <p>A work directory needed for running the model can be obtained from

    ftp://data1.gfdl.noaa.gov/users/ESM4/ESM4Documentation/GFDL-ESM4/inputData/ESM4_rundir.tar.gz</p>

    <p>The directory contains input.nml as the namelist, various input tables needed

    for running the model, and model input files in a folder called INPUT/.  There

    is also a directory named RESTART/ that should be empty at the beginning of

    each run.</p>

    <p>There is a skeleton of a run script named <a href="https://github.com/NOAA-GFDL/ESM4/blob/master/run/ESM4_run.sh">run/ESM4_run.sh</a>.  You
    must update this

    script to run the model.  Include a path to the work directory and the executable.

    You should also update the program you need to run the model on your system.  The

    default for this script is <code>srun</code>.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    '
  stargazers_count: 6
  subscribers_count: 6
  topics:
  - gfdl
  - ems
  - ems4
  - fms
  - climate
  - model
  - fortran
  updated_at: 1668092261.0
NOAA-GFDL/HPC-ME:
  data_format: 2
  description: null
  filenames:
  - spack_intel_ubuntu20.04_e4s.yaml
  - apps/spack_intel_ufs_model.yaml
  - apps/spack_intel_gfdl_model.yaml
  full_name: NOAA-GFDL/HPC-ME
  latest_release: null
  readme: '<h1><a id="user-content-hpc-me-hpc-portable-containers-for-model-environments"
    class="anchor" aria-hidden="true" href="#hpc-me-hpc-portable-containers-for-model-environments"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPC-ME: HPC Portable
    Containers for Model Environments</h1>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contents</h2>

    <ul>

    <li><a href="#what-is-hpc-me">What is HPC-ME</a></li>

    <li><a href="#list-of-current-compilers">List of current compilers/MPI/OS</a></li>

    <li><a href="#list-of-current-libraries">List of current libraries</a></li>

    <li><a href="#how-to-build">How to build</a></li>

    <li><a href="#how-to-use">How to use</a></li>

    <li><a href="#gfdl-example">GFDL example</a></li>

    <li><a href="#planned-improvements">Planned improvements</a></li>

    </ul>

    <h2><a id="user-content-what-is-hpc-me" class="anchor" aria-hidden="true" href="#what-is-hpc-me"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>What is HPC-ME</h2>

    <p>HPC Portable Container - Model Environments is a set of Dockerfiles, Singularity
    Definition files, and containers to provide portable model environments for scientific
    applications that require the same set of libraries.  The ultimate goal is to
    have a community-based list of libraries that are needed for compiling, executing,
    and post-processing earth science models.  We all use many of the same underlying
    libraries, and by working together we can agree upon a community-based approach
    to making container usage as standardized as possible.</p>

    <h2><a id="user-content-list-of-current-compilersmpios" class="anchor" aria-hidden="true"
    href="#list-of-current-compilersmpios"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>List of current compilers/MPI/OS</h2>

    <p>For each container, there is a full version that contains the programming environment
    and a smaller runtime environment that can be used to run compiled executables.
    (The runtime container definition files will be added soon.)

    #- <a href="Dockerfile_gnu_ubuntu20.04">gcc 8/mpich/ubuntu 20.04</a></p>

    <ul>

    <li><a href="Dockerfile_gnu_rhel8">gcc 8/mpich/RHEL8</a></li>

    <li>

    <a href="Dockerfile_intel_ubuntu18.04">intel oneAPI 2022.1/mpich(impi)/ubuntu
    18.04</a>

    #- <a href="Dockerfile_intel_centos8">intel oneAPI 2021.4/mpich(impi)/centos 8</a>

    </li>

    </ul>

    <h2><a id="user-content-list-of-current-libraries" class="anchor" aria-hidden="true"
    href="#list-of-current-libraries"><span aria-hidden="true" class="octicon octicon-link"></span></a>List
    of current libraries</h2>

    <p>This is the current list of most of the libraries used in the HPC-ME containers
    (We are trying to keep this up-to-date).

    The complete lit should be found in the respective YAML file.</p>

    <ul>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#automake"
    rel="nofollow">automake@1.16.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bacio" rel="nofollow">bacio@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#berkeley-db"
    rel="nofollow">berkeley-db@18.1.40</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bison" rel="nofollow">bison@3.7.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#bzip2" rel="nofollow">bzip2@1.0.8</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cmake" rel="nofollow">cmake@3.21.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#crtm" rel="nofollow">crtm@2.3.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#curl" rel="nofollow">curl@7.78.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#diffutils"
    rel="nofollow">diffutils@3.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#esmf" rel="nofollow">esmf@8.1.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#expat" rel="nofollow">expat@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2" rel="nofollow">g2@3.4.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#g2tmpl"
    rel="nofollow">g2tmpl@1.10.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gdbm" rel="nofollow">gdbm@1.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#gsl" rel="nofollow">gsl@2.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#hdf5" rel="nofollow">hdf5@1.10.7</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#intel-mpi"
    rel="nofollow">intel-mpi@2019.10.317</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip" rel="nofollow">ip@3.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ip2" rel="nofollow">ip2@1.1.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#jasper"
    rel="nofollow">jasper@2.0.32</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libbsd"
    rel="nofollow">libbsd@0.11.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libiconv"
    rel="nofollow">libiconv@1.16</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libjpeg-turbo"
    rel="nofollow">libjpeg-turbo@2.1.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libmd" rel="nofollow">libmd@1.0.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libpng"
    rel="nofollow">libpng@1.6.37</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libsigsegv"
    rel="nofollow">libsigsegv@2.13</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libxml2"
    rel="nofollow">libxml2@2.9.12</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#libyaml"
    rel="nofollow">libyaml@0.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#m4" rel="nofollow">m4@1.4.19</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nasm" rel="nofollow">nasm@2.15.05</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#ncurses"
    rel="nofollow">ncurses@6.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nemsio"
    rel="nofollow">nemsio@2.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-c"
    rel="nofollow">netcdf-c@4.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#netcdf-fortran"
    rel="nofollow">netcdf-fortran@4.5.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#numactl"
    rel="nofollow">numactl@2.0.14</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#openssl"
    rel="nofollow">openssl@1.1.1l</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#parallel-netcdf"
    rel="nofollow">parallel-netcdf@1.12.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#perl" rel="nofollow">perl@5.34.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#pkgconf"
    rel="nofollow">pkgconf@1.8.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#readline"
    rel="nofollow">readline@8.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sfcio" rel="nofollow">sfcio@1.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sigio" rel="nofollow">sigio@2.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#sp" rel="nofollow">sp@2.3.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#udunits"
    rel="nofollow">udunits@2.2.28</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3emc" rel="nofollow">w3emc@2.9.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#w3nco" rel="nofollow">w3nco@2.4.1</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#wrf-io"
    rel="nofollow">wrf-io@1.2.0</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xerces-c"
    rel="nofollow">xerces-c@3.2.3</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#xz" rel="nofollow">xz@5.2.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#zlib" rel="nofollow">zlib@1.2.11</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#lmod" rel="nofollow">lmod@8.5.6</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nccmp" rel="nofollow">nccmp@1.8.6.5</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#nco" rel="nofollow">nco@4.7.9</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-netcdf"
    rel="nofollow">cray-netcdf@4.6.3.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#cray-hdf5"
    rel="nofollow">cray-hdf5@1.10.5.2</a></li>

    <li><a href="https://spack.readthedocs.io/en/latest/package_list.html#uberftp"
    rel="nofollow">uberftp</a></li>

    </ul>

    <h2><a id="user-content-how-to-build" class="anchor" aria-hidden="true" href="#how-to-build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to build</h2>

    <p><strong>We plan to make this step optional soon.</strong> In order to build
    the Docker images, you will need access to a computer with root-like access, and
    either docker or singularity installed. If you do not have root-like access to
    a suitable machine, you can still run images that were already created (e.g. on
    Docker hub), and we plan on hosting runnable Docker images along with the Dockerfiles
    in this repository soon. If you have root-like access and docker, start by choosing
    one of the currently supported model environments from the list above. Then build
    the Docker container from the Dockerfile using docker build; for example, to build
    the gcc8/mpich/ubuntu18 container:</p>

    <pre><code>docker build --file Dockerfile_gnu_ubuntu20.04 . --tag hpc-me.ubuntu.gnu

    </code></pre>

    <p>The build process takes approximately 2-3 hours, as the packages are downloaded
    and compiled using Spack. After a successful build, you will see that the image
    was built and tagged successfully:</p>

    <pre><code>Successfully built 90a878af77b4

    Successfully tagged hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>Then, you may run the container using docker or singularity on the same host.
    To run the image on a different machine, pushing the image to Docker Hub is recommended.
    Note that you will need a DockerHub account to do this (replace USER with your
    Docker user ID in the examples below). For example:</p>

    <pre><code>docker tag hpc-me.rhel8.gnu USER/hpc-me.rhel8.gnu

    docker login

    docker push USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <h2><a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>How to use</h2>

    <p>We plan to make improvements on this process. Also, while we plan on making
    Docker images available on the GitHub container registry, currently you must build
    the images yourself. Please start with the <a href="#how-to-build">Build instructions</a>
    to generate a Docker image with your desired OS/compiler HPC-ME environment. Then
    you may run the container using docker or singularity; singularity is more likely
    than docker to be available on HPC environments.</p>

    <p>The usage documentation consists of some general notes on serial/parallel usage,
    files inside and outside the container, downloading the containers, and then specific
    usage scenarios:</p>

    <ul>

    <li><a href="#serial-applications-using-docker">Serial applications using docker</a></li>

    <li><a href="#serial-applications-using-singularity">Serial applications using
    singularity</a></li>

    <li><a href="#parallel-applications-using-singularity">Parallel applications using
    singularity</a></li>

    </ul>

    <h3><a id="user-content-serial-and-parallel-usage" class="anchor" aria-hidden="true"
    href="#serial-and-parallel-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Serial
    and parallel usage</h3>

    <p>HPC-ME containers are intended for both serial and parallel applications. Serial
    applications include compiling model executables, generating input grids, and
    post-processing model output. Earth system, climate, and weather models require
    parallelism to run efficiently, and use one of the Message Passage Interface (MPI)
    implementations OpenMPI, Intel MPI, or mpich. GCC-based HPC-ME containers use
    the mpich-based MPI library, which is widely available on most HPC sites, and
    the Intel-based containers contain both mpich and Intel MPI.</p>

    <h3><a id="user-content-notes-on-filesystems-and-writing-files" class="anchor"
    aria-hidden="true" href="#notes-on-filesystems-and-writing-files"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Notes on filesystems and writing files</h3>

    <p>We recommend not saving or modifying files within the environment container,
    and instead create and modify files on your regular filesystem. To do this, you
    will need to connect your filesystem to your container using bind mounts.</p>

    <h3><a id="user-content-downloading-containers-and-managing-images-on-the-filesystem"
    class="anchor" aria-hidden="true" href="#downloading-containers-and-managing-images-on-the-filesystem"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Downloading containers
    and managing images on the filesystem</h3>

    <p>Once you have pushed your images to DockerHub, you will need to download them
    before using. In the examples below, replace USER with your Docker Hub ID. If
    using docker,</p>

    <pre><code>docker pull USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity,</p>

    <pre><code>singularity pull docker://USER/hpc-me.rhel8.gnu:latest

    </code></pre>

    <p>If using singularity, the image file (SIF format) is saved to the current working
    directory</p>

    <pre><code>&gt; ls *.sif

    -rwxr-xr-x 532M Dec 10 16:09 hpc-me.rhel8.gnu_latest.sif*

    </code></pre>

    <p>If using docker, the downloaded image is handled by the central docker service.</p>

    <h3><a id="user-content-serial-applications-using-docker" class="anchor" aria-hidden="true"
    href="#serial-applications-using-docker"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Serial applications using docker</h3>

    <p>You may activate an interactive shell within the desired HPC-ME container using
    docker. After running the container, the compilers and tools available within
    the container will be accessible in your PATH; e.g.</p>

    <pre><code>&gt; docker run -it hpc-me.rhel8.gnu:latest


    [root@0d2cf64e1175 /]# which nf-config

    /opt/view/bin/nf-config


    [root@0d2cf64e1175 /]# nf-config --version

    netCDF-Fortran 4.5.3


    [root@0d2cf64e1175 /]# nf-config --cflags

    -I/opt/software/linux-rhel8-x86_64/gcc-8.4.1/netcdf-fortran-4.5.3-g5qfkdlp36unt2s4j4wyrc6heh2sa64n/include

    </code></pre>

    <h3><a id="user-content-serial-applications-using-singularity" class="anchor"
    aria-hidden="true" href="#serial-applications-using-singularity"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Serial applications using singularity</h3>

    <p>Singularity can run Docker images and is more likely to be available on HPC
    environments. As with docker run, the HPC-ME tools and compilers are available
    in the shell, somewhat similar to loading a set of Environment Modules prepared
    by site administrators.</p>

    <pre><code>&gt;singularity run hpc-me.rhel8.gnu_latest.sif


    Singularity&gt; which nf-config

    /opt/view/bin/nf-config


    Singularity&gt; nf-config --version

    netCDF-Fortran 4.5.3

    </code></pre>

    <h3><a id="user-content-parallel-applications-using-singularity" class="anchor"
    aria-hidden="true" href="#parallel-applications-using-singularity"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Parallel applications using singularity</h3>

    <p>HPC-ME containers can provide the runtime environment for MPI applications.
    For instance, one could compile an MPI application using the instructions above
    using one of the HPC-ME development containers; and then run the application using
    the corresponding runtime HPC-ME container.</p>

    <p>Please note that we are continuing to improve the usability of HPC-ME containers
    as well as provide more usage examples.</p>

    <p>Usually, GFDL climate models are run on gaea by submitting a runscript to the
    Slurm scheduler. The runscript loads needed runtime Environment Modules, prepares
    input directories and files, and executes the MPI executable using srun. The HPC-ME
    containers provide the necessary runtime environment, obviating the need for loading
    Environment Modules. Currently, our approach for using the HPC-ME containers is
    as follows:</p>

    <ol>

    <li>Create a new container, starting with the desired HPC-ME runtime container</li>

    <li>Add the MPI-compiled executable to the container filesystem</li>

    <li>Set the MPI-compiled executable to as the container''s command (so that when
    the container is run the MPI executable within the container runs)</li>

    <li>Run the singularity container SIF file using srun within the runscript, replacing
    the traditional MPI executable.</li>

    </ol>

    <ul>

    <li>Replace "srun executable.x" with "srun singularity run container.SIF"</li>

    <li>Add --mpi=pmi2 to the srun call, which connects the system MPI to the container
    MPI to the singularity run call</li>

    <li>Bind the working directory so that the container has access to the input files
    and can write output files (singularity run -B=/path/to/workdir)</li>

    </ul>

    <ol start="5">

    <li>Submit the modified runscript to the scheduler</li>

    </ol>

    <p>We plan to provide more examples and usage scenarios, such as using the HPC-ME
    containers as-is (i.e. not creating a new container as described above)</p>

    <h2><a id="user-content-gfdl-example" class="anchor" aria-hidden="true" href="#gfdl-example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL example</h2>

    <p>An example of using an HPC-ME container with the GFDL FRE workflow can be found
    <a href="GFDL_EXAMPLE.md">here</a></p>

    <h2><a id="user-content-planned-improvements" class="anchor" aria-hidden="true"
    href="#planned-improvements"><span aria-hidden="true" class="octicon octicon-link"></span></a>Planned
    improvements</h2>

    <p>HPC-ME is a work in progress under active development, so please check back
    or follow the repository for more updates.</p>

    <h3><a id="user-content-build-cache" class="anchor" aria-hidden="true" href="#build-cache"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build cache</h3>

    <p>We are working to create a build cache for the libraries listed so that building
    the containers is quick and easy.</p>

    <h3><a id="user-content-github-container-registry" class="anchor" aria-hidden="true"
    href="#github-container-registry"><span aria-hidden="true" class="octicon octicon-link"></span></a>Github
    container registry</h3>

    <p>We are working to add CI capability to this repository, so that the containers
    will be automatically built and stored in the github container registry. This
    will make building unnecessary for most cases, though users may build the containers
    themselves if they wish (e.g. for custom modifications).</p>

    <h3><a id="user-content-more-usage-examples-and-documentation-especially-for-mpi-applications"
    class="anchor" aria-hidden="true" href="#more-usage-examples-and-documentation-especially-for-mpi-applications"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>More usage examples
    and documentation, especially for MPI applications</h3>

    <p>We are still learning how to best use the HPC-ME containers with MPI appliations,
    so please check back.</p>

    <h3><a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h3>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    <p>This project code is made available through GitHub but is managed by NOAA-GFDL

    at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1650907447.0
PawseySC/hpc-container-training:
  data_format: 2
  description: 'Training material on using containers in an HPC setting. '
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/hpc-container-training
  latest_release: null
  readme: '<h1><a id="user-content-readme" class="anchor" aria-hidden="true" href="#readme"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Readme</h1>

    '
  stargazers_count: 1
  subscribers_count: 5
  topics:
  - docker
  - singularity
  - hpc
  - pawsey
  - training-materials
  updated_at: 1650946836.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Configuration files for Spack at Pawsey
  filenames:
  - systems/setonix/environments/env_bench/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-pawsey-spack-configuration" class="anchor" aria-hidden="true"
    href="#pawsey-spack-configuration"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pawsey
    Spack Configuration</h1>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_DAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <h3><a id="user-content-singularity" class="anchor" aria-hidden="true" href="#singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h3>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <h3><a id="user-content-software-stack-modulefile" class="anchor" aria-hidden="true"
    href="#software-stack-modulefile"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    stack modulefile</h3>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <h2><a id="user-content-repository-structure" class="anchor" aria-hidden="true"
    href="#repository-structure"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    structure</h2>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <h2><a id="user-content-the-scripts-directory" class="anchor" aria-hidden="true"
    href="#the-scripts-directory"><span aria-hidden="true" class="octicon octicon-link"></span></a>The
    <code>scripts</code> directory</h2>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <h2><a id="user-content-the-systemssystem-directory" class="anchor" aria-hidden="true"
    href="#the-systemssystem-directory"><span aria-hidden="true" class="octicon octicon-link"></span></a>The
    <code>systems/&lt;system&gt;</code> directory</h2>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <h2><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h2>

    <h3><a id="user-content-module-categories-in-use" class="anchor" aria-hidden="true"
    href="#module-categories-in-use"><span aria-hidden="true" class="octicon octicon-link"></span></a>Module
    categories in use</h3>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <h3><a id="user-content-testing-modules" class="anchor" aria-hidden="true" href="#testing-modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Testing Modules</h3>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1641801068.0
PawseySC/performance-modelling-tools:
  data_format: 2
  description: This repository hosts configuration files for HPC Toolkit, ROCprof,
    NVprof and ERT, and scripts to help us create roofline and instruction based roofline
    diagrams (performance models) for applications
  filenames:
  - spack/mulan/spack.yaml
  full_name: PawseySC/performance-modelling-tools
  latest_release: null
  readme: '<h1><a id="user-content-performance-modeling-tools" class="anchor" aria-hidden="true"
    href="#performance-modeling-tools"><span aria-hidden="true" class="octicon octicon-link"></span></a>Performance
    Modeling Tools</h1>

    <p>This repository hosts configuration files and scripts to support performance
    modeling of research application on Pawsey Supercomputing Centre systems.</p>

    <p>We have provided</p>

    <ul>

    <li>

    <a href="./spack">Spack environments</a> that provide performance modeling toolchains
    for Pawsey systems</li>

    <li>

    <a href="./examples/">Examples</a> that illustrate how to use this repository
    for active research projects</li>

    <li>

    <a href="./bin/">Scripts</a> for processing profiler data to create graphics and
    other post-processed data to support performance modeling</li>

    </ul>

    <h2><a id="user-content-about-this-repository" class="anchor" aria-hidden="true"
    href="#about-this-repository"><span aria-hidden="true" class="octicon octicon-link"></span></a>About
    this Repository</h2>

    <h3><a id="user-content-scaffolding" class="anchor" aria-hidden="true" href="#scaffolding"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Scaffolding</h3>

    <p>This repository is organized with the following top-level directories</p>

    <ul>

    <li>

    <code>bin/</code> : Contains scripts for post-processing profiler data</li>

    <li>

    <code>docs/</code> : Contains mkdocs documentation</li>

    <li>

    <code>examples/</code> : Contains example configurations for creating profile
    data and processing output with the tools in this repository.</li>

    <li>

    <code>spack/</code> : Contains spack environments for various Pawsey systems that
    provide hpc-toolkit and other useful tools.</li>

    <li>

    <code>tests/</code>: Contains some simple tests for exploring device offloading
    with HIP, CUDA, OpenMP. Currently has a single test, <code>warmup/</code>

    </li>

    </ul>

    <h2><a id="user-content-getting-help" class="anchor" aria-hidden="true" href="#getting-help"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Help</h2>

    <p>Currently, you can request help by <a href="https://github.com/PawseySC/performance-modelling-tools/issues">submitting
    an issue</a></p>

    '
  stargazers_count: 1
  subscribers_count: 8
  topics: []
  updated_at: 1664518211.0
PawseySC/singularity-containers:
  data_format: 2
  description: Webinars&Tutorial on Containers on HPC and Cloud with Singularity
  filenames:
  - demos/spack_blast/spack.yaml
  full_name: PawseySC/singularity-containers
  latest_release: null
  readme: '<h1><a id="user-content-readme" class="anchor" aria-hidden="true" href="#readme"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Readme</h1>

    '
  stargazers_count: 22
  subscribers_count: 11
  topics: []
  updated_at: 1676043785.0
RMeli/HPCpp:
  data_format: 2
  description: 'Experiments with C++ for HPC and collection of C++ benchmarks. '
  filenames:
  - cpp/libint-hf/spack.yaml
  full_name: RMeli/HPCpp
  latest_release: null
  readme: '<h1><a id="user-content-hpc-experiments-and-notes-for-high-performance-c"
    class="anchor" aria-hidden="true" href="#hpc-experiments-and-notes-for-high-performance-c"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>HPC++: Experiments
    and Notes for High-Performance C++</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664828168.0
RMeli/my-spack:
  data_format: 2
  description: Spack environments
  filenames:
  - envs/local/cp2k/spack.yaml
  full_name: RMeli/my-spack
  latest_release: null
  readme: '<h1><a id="user-content-my-spack" class="anchor" aria-hidden="true" href="#my-spack"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>My Spack</h1>

    <p>Spack-related stuff for @RMeli.</p>

    <h2><a id="user-content-package-repository" class="anchor" aria-hidden="true"
    href="#package-repository"><span aria-hidden="true" class="octicon octicon-link"></span></a>Package
    Repository</h2>

    <p><a href="https://spack.readthedocs.io/en/latest/repositories.html" rel="nofollow">Spack
    Package Repositories</a></p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679671251.0
RemoteConnectionManager/CINECA_RCM_deployments:
  data_format: 2
  description: null
  filenames:
  - environments/production/rcm/spack.yaml
  - environments/production/base/spack.yaml
  full_name: RemoteConnectionManager/CINECA_RCM_deployments
  latest_release: null
  readme: '<h1><a id="user-content-here-we-collect-recipes-for-rcm-deploy-on-cineca-clusters"
    class="anchor" aria-hidden="true" href="#here-we-collect-recipes-for-rcm-deploy-on-cineca-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Here we collect recipes
    for RCM deploy on CINECA clusters</h1>

    <p>download:</p>

    <pre><code>git clone --recursive  --branch master https://github.com/RemoteConnectionManager/CINECA_RCM_deployments.git

    cd CINECA_RCM_deployments

    </code></pre>

    <p>If plan to develop, align all submodules to their branches specified in .gitsubmodules</p>

    <pre><code>git submodule foreach -q --recursive ''branch="$(git config -f $toplevel/.gitmodules
    submodule.$name.branch)"; git checkout $branch''

    </code></pre>

    <p>update the repo and submodules from origin:

    git pull

    git submodule update --recursive</p>

    <ul>

    <li><a href="GIT_HINTS.md">Other hints on git operations</a></li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1581939434.0
RemoteConnectionManager/RCM_spack_deploy:
  data_format: 2
  description: Deploy components and scripts for RCM
  filenames:
  - deploy/environments/rcm/spack.yaml
  - deploy/base_spack_devel/environments/base/spack.yaml
  full_name: RemoteConnectionManager/RCM_spack_deploy
  latest_release: null
  readme: "<h1><a id=\"user-content-rcm_spack_deploy\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#rcm_spack_deploy\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>RCM_spack_deploy</h1>\n<p>deploy components and scripts for RCM</p>\n\
    <p>First step: clone this repo:</p>\n<pre><code>git clone  https://github.com/RemoteConnectionManager/RCM_spack_deploy.git\
    \ &lt;folder name&gt;\n</code></pre>\n<p>Short story:</p>\n<pre><code>cd &lt;folder\
    \ name&gt;\nbin/spack-deploy   --workdir deploy/base_spack_devel/ gitmanager deploy\
    \ \nbin/spack-deploy   --workdir deploy/base_spack_devel/ spackmanager config_setup\n\
    </code></pre>\n<p>More info can be found in:</p>\n<pre><code>recipes/hosts/&lt;host&gt;/README.md\n\
    </code></pre>\n<ul>\n<li><a href=\"https://github.com/RemoteConnectionManager/RCM_spack_deploy/blob/master/GIT_HINTS.md\"\
    >Git hints</a></li>\n<li><a href=\"https://github.com/RemoteConnectionManager/RCM_spack_deploy/blob/master/DEPLOY_HINTS.md\"\
    >Deployment hints</a></li>\n<li><a href=\"https://github.com/RemoteConnectionManager/RCM_spack_deploy/blob/master/old_stuff/README.md\"\
    >Old README</a></li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1570732892.0
ResearchIT/isu-spack:
  data_format: 2
  description: Spec files for research software library installed at Iowa State University
    via Spack
  filenames:
  - 2-mpis/spack.yaml
  - 3-packages/spack.yaml
  full_name: ResearchIT/isu-spack
  latest_release: null
  stargazers_count: 1
  subscribers_count: 6
  topics: []
  updated_at: 1589495508.0
SCOREC/centos7-spack-config:
  data_format: 2
  description: spack config for erp cluster
  filenames:
  - openFoam24/spack.yaml
  full_name: SCOREC/centos7-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-centos7-spack-config" class="anchor" aria-hidden="true"
    href="#centos7-spack-config"><span aria-hidden="true" class="octicon octicon-link"></span></a>centos7-spack-config</h1>

    <p>centos7 spack configuration and scripts</p>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list

    config.yaml - global config

    install.sh - package installation commands

    modules.yaml - hierarchical layout for lua modules

    packages.yaml - system installed packages

    README.md - this file

    setupSpack.sh - env needed for executing spack commands</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1649267705.0
SCOREC/dcs-spack-config:
  data_format: 2
  description: Spack config for CCI DCS (AiMOS) system
  filenames:
  - v0133gcc/spack.yaml
  - v0162gccSpectrum/spack.yaml
  - rhel8NvhpcWdmapp/spack.yaml
  - v0133gccSpectrum/spack.yaml
  - v0160gcc/spack.yaml
  - spack.yaml
  full_name: SCOREC/dcs-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-dcs-spack-config" class="anchor" aria-hidden="true"
    href="#dcs-spack-config"><span aria-hidden="true" class="octicon octicon-link"></span></a>dcs-spack-config</h1>

    <p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies

    with the IBM XL compilers and Spectrum-MPI.</p>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list</p>

    <p>config.yaml - global config</p>

    <p>install.sh - package installation commands</p>

    <p>modules.yaml - hierarchical layout for lua modules</p>

    <p>packages.yaml - system installed packages</p>

    <p>README.md - this file</p>

    <p>setupSpack.sh - env needed for executing spack commands</p>

    <p>spack.yaml - list of packages to install</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>setup</h2>

    <pre><code>git clone git@github.com:spack/spack.git spack

    cd !$

    git checkout v0.13.3

    # add the simmetrix-simmodsuite package from the develop branch

    git cherry-pick 5ddf5e2

    # create the environment

    spack env create v0133

    spack env activate v0133

    # copy the yaml files into the v0133

    cp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.

    # copy the compiler yaml file into the spack etc dir

    cp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.

    </code></pre>

    <h2><a id="user-content-install-cmake" class="anchor" aria-hidden="true" href="#install-cmake"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>install cmake</h2>

    <p>The bootstrap step of the cmake install fails with the XL compilers.  I

    installed it manually outside of the environment with spack and gcc4.8.5</p>

    <pre><code>spack install cmake%gcc@4.8.5_rhel7

    </code></pre>

    <p>Then added the path to <code>packages.yaml</code>.</p>

    <h2><a id="user-content-resuming-work-in-an-environment" class="anchor" aria-hidden="true"
    href="#resuming-work-in-an-environment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>resuming work in an environment</h2>

    <pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh

    spack env activate v0133

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633029356.0
SCOREC/rhel7-spack-config:
  data_format: 2
  description: rhel7 spack configuration and scripts
  filenames:
  - v0.18.1/spack.yaml
  - v0.15.4/spack.yaml
  full_name: SCOREC/rhel7-spack-config
  latest_release: null
  readme: "<h1><a id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#setup-on-scorec\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\n\
    source setupSpack.sh\n</code></pre>\n<h1><a id=\"user-content-rhel7-spack-config\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#rhel7-spack-config\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7\
    \ spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained\
    \ in this repo is for documentation purposes (e.g., in case we had to reinstall\
    \ the entire stack from scratch) and should not be executed as it will not use\
    \ all of our existing package installs.  More discussion of package installation\
    \ is below.</p>\n<h2><a id=\"user-content-useful-commands\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#useful-commands\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack\
    \ module lmod refresh\n</code></pre>\n<h2><a id=\"user-content-installing-new-packages\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-new-packages\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new\
    \ packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack\
    \ package updates could result in additional installation of packages with little\
    \ or no package source code changes.  These additional installs can be avoided\
    \ when installing new packages by first examining the output of the <code>spack\
    \ spec -I</code> command.  If a utility/infrastructure level package, such as\
    \ cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column\
    \ then it means that the existing install will be used.  If spack does not default\
    \ to using the existing install you can append the hash of the package to the\
    \ spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi\
    \ install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\n\
    Input spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\n\
    Concretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo\
    \ ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]     \
    \ ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64\
    \ \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64\
    \ \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]  \
    \        ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]  \
    \            ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp\
    \ +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0\
    \ patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2\
    \ arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]\
    \              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]       \
    \       ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e\
    \ +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\
    </code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change\
    \ to the new mpich version yet.  So, we will get the hash of the existing mpich\
    \ 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed\
    \ package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\n\
    niuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n\
    <p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code>\
    \ syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\
    \ ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\
    [+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\
    \ arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n\
    \ -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none\
    \ ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt\
    \ arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib\
    \ arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64\
    \ \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64\
    \ \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac\
    \ +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared\
    \ arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra\
    \ netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And\
    \ see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n\
    <h2><a id=\"user-content-contents\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #contents\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n\
    <p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package\
    \ installation commands\nmodules.yaml - hierarchical layout for lua modules\n\
    packages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh\
    \ - env needed for executing spack commands</p>\n"
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1643231013.0
SouthernMethodistUniversity/mp_testing:
  data_format: 2
  description: null
  filenames:
  - mp/testing/05_openmm/spack.yaml
  - mp/testing/01_spack/spack_nvhpc.yaml
  - mp/testing/01_spack/spack_lammps.yaml
  full_name: SouthernMethodistUniversity/mp_testing
  latest_release: null
  readme: '<h1><a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h1>

    <p><strong>All code in this repo is for testing. The code may not work and may
    change. Pull requests and issues welcome.</strong></p>

    <p>See <a href="quick_start_notes.md">Quick Start Notes</a> for a short overview
    of MP usage.</p>

    <h2><a id="user-content-usage-example" class="anchor" aria-hidden="true" href="#usage-example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage Example</h2>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/SouthernMethodistUniversity/mp_testing.git

    <span class="pl-c1">cd</span> mp_testing/demos/00_nemo

    ./submit_jobs.sh</pre></div>

    <h2><a id="user-content-applications" class="anchor" aria-hidden="true" href="#applications"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Applications</h2>

    <ul>

    <li>LAMMPS (NGC)</li>

    <li>AMBER</li>

    <li>NAMD (NGC)</li>

    <li>OpenMM</li>

    <li>Gaussian</li>

    <li>VASP</li>

    <li>CRYSTAL</li>

    <li>Q-Chem</li>

    <li>Quantum Espresso</li>

    </ul>

    <h2><a id="user-content-analysis-tools" class="anchor" aria-hidden="true" href="#analysis-tools"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Analysis Tools</h2>

    <ul>

    <li>Memory profiling</li>

    <li>Performance profiling</li>

    </ul>

    <h2><a id="user-content-librariesapis" class="anchor" aria-hidden="true" href="#librariesapis"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Libraries/APIs</h2>

    <ul>

    <li>Raja</li>

    <li>Magma</li>

    <li>heFFTe</li>

    <li>Pandas</li>

    <li>NumPy</li>

    <li>TensorFlow</li>

    <li>PyTorch</li>

    <li>DALI</li>

    </ul>

    <h2><a id="user-content-languages" class="anchor" aria-hidden="true" href="#languages"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Languages</h2>

    <ul>

    <li>C</li>

    <li>C++</li>

    <li>Python</li>

    <li>Some custom layer in C++/CUDA</li>

    <li>Fortran</li>

    <li>CUDA Fortran</li>

    <li>Julia</li>

    </ul>

    <h2><a id="user-content-molecular-dynamics" class="anchor" aria-hidden="true"
    href="#molecular-dynamics"><span aria-hidden="true" class="octicon octicon-link"></span></a>Molecular
    Dynamics</h2>

    <ul>

    <li>OpenMM</li>

    <li>AMBER</li>

    <li>Desmond</li>

    <li>GROMACS</li>

    <li>Mentioned MIC modes?</li>

    <li>NGC for Keras/TF and Pytorch</li>

    </ul>

    <h2><a id="user-content-issues" class="anchor" aria-hidden="true" href="#issues"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Issues</h2>

    <ul>

    <li>Can''t run enroot images directly via <code>enroot start hello_world.sqsh</code>.
    The OS

    needs squashfuse and fuse-overlayfs installed. I installed these on Easley and

    it works.</li>

    <li>Custom build and final images for containerized Spack environments fails due

    to apparently assuming that Spack already exists. See: <code>01_spack/spack_nvhpc.yaml</code>.</li>

    <li>Spack-blessed NVIDIA container fails to build due to public key error. See:
    <code>01_spack/spack_lammps.yaml</code>.</li>

    <li>

    <code>export ENROOT_MOUNT_HOME=1</code> to bind $HOME.</li>

    <li>Default flags and <code>target=zen2</code> gave LAMMPS run times of 4:44,
    while <code>target=zen2 cppflags=-O3</code>

    </li>

    <li>Running containers or non-hpc-x MPI produces warnings about <code>Unknown
    interface name</code> /

    <code>An invalid value was given for btl_tcp_if_include</code>. It appears not
    to see the Mellanox / IB correctly?</li>

    </ul>

    <h2><a id="user-content-maybe-useful" class="anchor" aria-hidden="true" href="#maybe-useful"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Maybe Useful</h2>

    <ul>

    <li><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/gpu-applications-catalog.pdf"
    rel="nofollow">https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/gpu-applications-catalog.pdf</a></li>

    <li><a href="https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html"
    rel="nofollow">https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html</a></li>

    <li><a href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html"
    rel="nofollow">https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html</a></li>

    <li><a href="https://secure.cci.rpi.edu/wiki/" rel="nofollow">https://secure.cci.rpi.edu/wiki/</a></li>

    </ul>

    <h2><a id="user-content-things-we-need-to-plan-for" class="anchor" aria-hidden="true"
    href="#things-we-need-to-plan-for"><span aria-hidden="true" class="octicon octicon-link"></span></a>Things
    we need to plan for</h2>

    <ul>

    <li>How and when do we decide we''re updating Nvidia Drivers / Cuda. I think we
    need to be very clear about this if we''re not going to maintain the latest and
    greatest. (we''re currently on 11.4, but 11.7 and associated drivers are available)</li>

    </ul>

    '
  stargazers_count: 2
  subscribers_count: 2
  topics: []
  updated_at: 1674857302.0
TurbulentDynamics/tdLBCpp:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: TurbulentDynamics/tdLBCpp
  latest_release: null
  readme: "<h1><a id=\"user-content-turbulent-dynamics-lattice-boltzmann-c\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#turbulent-dynamics-lattice-boltzmann-c\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Turbulent\
    \ Dynamics Lattice Boltzmann (C++)</h1>\n<p>This is a basic version of the multi-node\
    \ heterogeneous HPC code to run simulation with hundreds of billions of cells.</p>\n\
    <h2><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\">#Generate\
    \ an input file</span>\n<span class=\"pl-s1\">python3</span> <span class=\"pl-s1\"\
    >generate_stirred_tank_input</span>.<span class=\"pl-s1\">py</span> <span class=\"\
    pl-c1\">-</span><span class=\"pl-s1\">x</span> <span class=\"pl-c1\">100</span>\
    \ <span class=\"pl-c1\">-</span><span class=\"pl-s1\">f</span> <span class=\"\
    pl-s1\">input_debug_gridx100_numSteps20</span>.<span class=\"pl-s1\">json</span>\n\
    .<span class=\"pl-c1\">/</span><span class=\"pl-s1\">tdlbcpp</span> <span class=\"\
    pl-c1\">-</span><span class=\"pl-c1\">-</span><span class=\"pl-s1\">input_file</span>\
    \ <span class=\"pl-s1\">input_debug_gridx100_numSteps20</span>.<span class=\"\
    pl-s1\">json</span>\n\n<span class=\"pl-c\">#Load from checkpoint dir</span>\n\
    .<span class=\"pl-c1\">/</span><span class=\"pl-s1\">tdlbcpp</span> <span class=\"\
    pl-c1\">-</span><span class=\"pl-c1\">-</span><span class=\"pl-s1\">checkpoint_dir</span>\
    \ <span class=\"pl-s1\">checkpoint_2021_9_21__jd7aflakjd</span></pre></div>\n\
    <h2><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n\
    <p>###\_Dependencies</p>\n<pre><code>sudo apt install bazel\ncp /location/to/cuda-samples/Common/{helper_*,exception.h}\
    \ tdlbcpp/src\n</code></pre>\n<h3><a id=\"user-content-generic-build\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#generic-build\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Generic build</h3>\n<pre><code>bazel\
    \ build //tdlbcpp/src:tdlbcpp --verbose_failures -s\n\n\n</code></pre>\n<h3><a\
    \ id=\"user-content-gpu-build\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #gpu-build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>GPU\
    \ build</h3>\n<p>uses <code>nvcc</code> compiler for cuda files and main.cpp and\
    \ sets WITH_GPU | WITH_GPU_MEMSHARED define</p>\n<pre><code>bazel build --config\
    \ gpu //tdlbcpp/src:tdlbcpp\nbazel build --config gpu_shared //tdlbcpp/src:tdlbcpp\n\
    </code></pre>\n<p>For debug build add -c dbg switch:</p>\n<pre><code>bazel build\
    \ -c dbg --config gpu //tdlbcpp/src:tdlbcpp\n</code></pre>\n<p>Specify capabilities\
    \ and custom cuda path using the following switches:</p>\n<p><code>--@rules_cuda//cuda:cuda_targets=sm_XY</code>\n\
    <code>--repo_env=CUDA_PATH=/usr/local/cuda-ZZZ</code></p>\n<pre><code>bazel build\
    \ -c dbg --config gpu --@rules_cuda//cuda:cuda_targets=sm_75 --repo_env=CUDA_PATH=/usr/local/cuda-11.5\
    \ //tdlbcpp/src:tdlbcpp\n</code></pre>\n<h2><a id=\"user-content-tests\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#tests\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Tests</h2>\n<pre><code>bazel test //tdlbcpp/tests/Params:tests\n\
    </code></pre>\n<h2><a id=\"user-content-package-structure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#package-structure\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Package Structure</h2>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"docs/Package-Structure.jpeg\"><img src=\"docs/Package-Structure.jpeg\"\
    \ alt=\"Package Structure\" style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"\
    user-content-vector-identification-see-headerh\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#vector-identification-see-headerh\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Vector Identification (see <a href=\"\
    tdlbcpp/src/Header.h\">Header.h</a>)</h2>\n<p><a target=\"_blank\" rel=\"noopener\
    \ noreferrer\" href=\"docs/D2Q9-D3Q19.jpeg\"><img src=\"docs/D2Q9-D3Q19.jpeg\"\
    \ alt=\"D2Q9 and D3Q19\" style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 1
  subscribers_count: 4
  topics: []
  updated_at: 1640518096.0
UNM-CARC/docker_base:
  data_format: 2
  description: Base Docker Image for CDSE containers running at CARC
  filenames:
  - spack.yaml
  full_name: UNM-CARC/docker_base
  latest_release: null
  readme: '<h1><a id="user-content-docker_basemaster" class="anchor" aria-hidden="true"
    href="#docker_basemaster"><span aria-hidden="true" class="octicon octicon-link"></span></a>docker_base:master</h1>

    <p>Base Docker Image for CDSE containers. Master container is generic openmpi

    and x86_64.</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1573079460.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - spack-sdk-environments/e4s_ecosystem/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 20
  subscribers_count: 6
  topics: []
  updated_at: 1673374590.0
actions-marketplace-validations/haampie-spack_setup-spack:
  data_format: 2
  description: null
  filenames:
  - example-environment/spack.yaml
  full_name: actions-marketplace-validations/haampie-spack_setup-spack
  latest_release: null
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1669840356.0
acwen11/cactusamrex_copy:
  data_format: 2
  description: null
  filenames:
  - utils/Docker/cpu/make-image/spack.yaml
  - utils/Docker/gpu/make-image-gpu/spack.yaml
  full_name: acwen11/cactusamrex_copy
  latest_release: null
  readme: '<h1><a id="user-content-cactusamrex" class="anchor" aria-hidden="true"
    href="#cactusamrex"><span aria-hidden="true" class="octicon octicon-link"></span></a><a
    href="https://bitbucket.org/eschnett/cactusamrex" rel="nofollow">CactusAMReX</a></h1>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/carpetx.png"><img
    src="figures/carpetx.png" alt="CarpetX logo" style="max-width: 100%;"></a></p>

    <p><strong>CarpetX</strong> is a <a href="https://cactuscode.org/" rel="nofollow">Cactus</a>
    driver based on <a href="https://amrex-codes.github.io" rel="nofollow">AMReX</a>,
    a software framework for block-structured AMR (adaptive mesh refinement). CarpetX
    is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>.</p>

    <ul>

    <li>

    <a href="https://bitbucket.org/eschnett/cactusamrex" rel="nofollow">Bitbucket</a>:
    Source code repository</li>

    <li>

    <a href="https://dev.azure.com/schnetter/CactusAMReX/_build" rel="nofollow">Azure   Pipelines</a>:
    Build Status <a href="https://dev.azure.com/schnetter/CactusAMReX/_build/latest?definitionId=6&amp;branchName=master"
    rel="nofollow"><img src="https://camo.githubusercontent.com/c376f6da8aa212a12313b10b09f29b30a096a8f4bc59b67c7baf9a5aaa2ad8a1/68747470733a2f2f6465762e617a7572652e636f6d2f7363686e65747465722f436163747573414d5265582f5f617069732f6275696c642f7374617475732f436163747573414d5265582d43493f6272616e63684e616d653d6d6173746572"
    alt="Build Status" data-canonical-src="https://dev.azure.com/schnetter/CactusAMReX/_apis/build/status/CactusAMReX-CI?branchName=master"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <p>CarpetX is almost ready for production. (The only missing feature is

    checkpointing/recovery.) You are welcome to give it a try, to look at

    what changes your code might need to benefit from CarpetX''s new

    features, and to give us feedback.</p>

    <p>The recorded talk <a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html"
    rel="nofollow">"Using CarpetX: A Guide for Early

    Adopters"</a>.

    This presentation provides an overview of the current capabilities of

    CarpetX and showcases how to write Cactus code using it.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>Here are instructions for downloading the Einstein Toolkit including

    CarpetX, building, and running an example.</p>

    <h3><a id="user-content-download-and-setup" class="anchor" aria-hidden="true"
    href="#download-and-setup"><span aria-hidden="true" class="octicon octicon-link"></span></a>Download
    and Setup</h3>

    <p>Download the Einstein Toolkit, including CarpetX. This will create a

    new directory <code>Cactus</code> that will contain the code:</p>

    <div class="highlight highlight-source-shell"><pre>curl -kLO https://raw.githubusercontent.com/gridaphobe/CRL/master/GetComponents

    perl GetComponents --parallel https://bitbucket.org/eschnett/cactusamrex/raw/master/manifest/einsteintoolkit-carpetx.th

    <span class="pl-c1">cd</span> Cactus</pre></div>

    <p>We''re using a Docker image to provide dependencies (including AMReX)

    to simplify installation. However, the Einstein Toolkit source code

    does not reside in that image; it resides in the <code>Cactus</code> directory

    which you just created. This leads to the following workflow:</p>

    <ul>

    <li>To download, look at, edit, git add/commit/pull/push etc. the code,

    you use the regular tools you already have installed on your system.

    Docker is not involved in this in any way.</li>

    <li>To build and run, you create an emphemeral (stateless) Docker

    container running Bash, with our Docker image mounted. For

    convenience, there is a shell script for this:</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>./repos/cactusamrex/utils/Docker/cpu/run-container</pre></div>

    <p>The first time you run this script, Docker will download the Docker

    image with the dependencies, which might take a few minutes.</p>

    <p>Inside this container, the hostname is <code>carpetx-docker-cpu</code>, so
    that

    you know you''re inside the container. (You exit the container by

    exiting the shell, e.g. with the <code>exit</code> command.)</p>

    <p>Note: While the container (running the Bash shell) is thrown away

    after each use, the changes to the file system you make persist, since

    your home directory is mounted and thus available in the container.</p>

    <p>As usual, the first time you use the Einstein Toolkit, you have to

    configure Simfactory for your local machine:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim setup</pre></div>

    <h3><a id="user-content-build" class="anchor" aria-hidden="true" href="#build"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h3>

    <p>Let''s build the toolkit with CarpetX.</p>

    <p>The default option list doesn''t point to AMReX nor some other

    dependencies. We thus specify our own. (I assume this could be fixed

    in the thorns handling these external dependencies.)</p>

    <p>The default thorn list would build the regular Einstein Toolkit

    without CarpetX; we need to specify a particular thorn list which

    includes all CarpetX thorns. This thorn list also disables those

    thorns that do not yet work with CarpetX.</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim build
    --optionlist=repos/cactusamrex/utils/Docker/cpu/carpetx.cfg --thornlist=repos/cactusamrex/utils/Docker/cpu/carpetx.th</pre></div>

    <p>Of course, once you created your configuration with the command above,

    to re-build after changing some code, the command is simply</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim build</pre></div>

    <p>as usual.</p>

    <h3><a id="user-content-run" class="anchor" aria-hidden="true" href="#run"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run</h3>

    <p>Let''s run some examples!</p>

    <p>Starting slowly, here is a scalar wave:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim submit
    planewave --parfile=arrangements/CarpetX/WaveToyCPU/par/planewave.par --procs=8
    --num-threads=8</pre></div>

    <p>You want to adapt the number of cores (<code>--procs</code>) and threads

    (<code>--num-threads</code>) to your system.</p>

    <p>It seems that the default Simfactory setup that was created above

    buffers the output, so that there might be long periords of time where

    the simulation appears to hang. Use <code>top</code> to see whether it is still

    running, and check the output directory to see whether it is still

    producing output.</p>

    <p>We can also run a binary black hole merger:</p>

    <div class="highlight highlight-source-shell"><pre>./simfactory/bin/sim submit
    planewave --parfile=arrangements/CarpetX/Z4c/par/qc0.rpar --procs=40 --num-threads=10</pre></div>

    <p>This setup requires more memory and time. I''m running it with about

    200 GByte of memory on 40 cores for 24 hours.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1680546511.0
akhilred36/gameOfLifeKokkos:
  data_format: 2
  description: Game of Life implementation in Kokkos.
  filenames:
  - spack.yaml
  full_name: akhilred36/gameOfLifeKokkos
  latest_release: null
  readme: '<h1><a id="user-content-gameoflifekokkos" class="anchor" aria-hidden="true"
    href="#gameoflifekokkos"><span aria-hidden="true" class="octicon octicon-link"></span></a>gameOfLifeKokkos</h1>

    <p>Game of Life implementation in Kokkos with MPI.</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <ul>

    <li>GCC&gt;=7.5.0</li>

    <li>CUDA&gt;=11.2.0</li>

    <li>Kokkos&gt;=3.5.00 with cuda and nvcc_wrapper</li>

    <li>OpenMPI&gt;=4.1.2 with cuda</li>

    <li>CMake&gt;=3.10</li>

    </ul>

    <h2><a id="user-content-install-prerequisites-into-a-spack-environment" class="anchor"
    aria-hidden="true" href="#install-prerequisites-into-a-spack-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Install prerequisites
    into a spack environment:</h2>

    <div class="highlight highlight-source-shell"><pre>spack env create <span class="pl-k">&lt;</span>name<span
    class="pl-k">&gt;</span> spack.yaml</pre></div>

    <div class="highlight highlight-source-shell"><pre>spack env activate <span class="pl-k">&lt;</span>name<span
    class="pl-k">&gt;</span></pre></div>

    <div class="highlight highlight-source-shell"><pre>spack install</pre></div>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <h3><a id="user-content-initial-setup" class="anchor" aria-hidden="true" href="#initial-setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Initial setup:</h3>

    <div class="highlight highlight-source-shell"><pre>mkdir build <span class="pl-k">&amp;&amp;</span>
    mkdir data</pre></div>

    <h3><a id="user-content-compile" class="anchor" aria-hidden="true" href="#compile"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compile:</h3>

    <div class="highlight highlight-source-shell"><pre>make clean <span class="pl-k">&amp;&amp;</span>
    make</pre></div>

    <h3><a id="user-content-clean-generated-log-files" class="anchor" aria-hidden="true"
    href="#clean-generated-log-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Clean
    generated log files:</h3>

    <div class="highlight highlight-source-shell"><pre>make cleandata</pre></div>

    <h2><a id="user-content-running" class="anchor" aria-hidden="true" href="#running"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running</h2>

    <p>Run the following in the build directory:</p>

    <h3><a id="user-content-format" class="anchor" aria-hidden="true" href="#format"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Format:</h3>

    <div class="highlight highlight-source-shell"><pre>mpirun -n <span class="pl-k">&lt;</span>numTasks<span
    class="pl-k">&gt;</span> ./gol <span class="pl-k">&lt;</span>meshSize<span class="pl-k">&gt;</span>
    <span class="pl-k">&lt;</span>numIterations<span class="pl-k">&gt;</span> <span
    class="pl-k">&lt;</span>coord1X coord1Y<span class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>coord2X
    coord2Y<span class="pl-k">&gt;</span> .... <span class="pl-k">&lt;</span>coordNX
    coordNY<span class="pl-k">&gt;</span> <span class="pl-k">&lt;</span>print<span
    class="pl-k">&gt;</span></pre></div>

    <h3><a id="user-content-example-runs" class="anchor" aria-hidden="true" href="#example-runs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example runs:</h3>

    <p>4 tasks, mesh size 32, 100 iterations, (10, 10) (10, 11) (10, 13) as active
    cells, and log enabled:</p>

    <div class="highlight highlight-source-shell"><pre>mpirun -n 4 ./gol 32 100 10
    10 10 11 10 13 1</pre></div>

    <p>4 tasks, mesh size 32, 100 iterations, (10, 10) (10, 11) (10, 13) as active
    cells, and log disabled:</p>

    <div class="highlight highlight-source-shell"><pre>mpirun -n 4 ./gol 32 100 10
    10 10 11 10 13 0</pre></div>

    <h2><a id="user-content-interpreting-logs" class="anchor" aria-hidden="true" href="#interpreting-logs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Interpreting logs:</h2>

    <p>The logs are written into the directory data/. The naming convention used is
    <code>&lt;rank&gt;_&lt;iter&gt;</code>. For example, to view the state of a mesh
    of rank 0 and iteration 12, run:</p>

    <div class="highlight highlight-source-shell"><pre>cat 0_12</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1649796861.0
alexpacheco/spackenv:
  data_format: 2
  description: 'Spack Environments '
  filenames:
  - cent7/libs_old/spack.yaml
  - cent8/envs/x86_64/spack.yaml
  - cent8/envs/avx/python/spack.yaml
  - cent8/envs/avx2/python/spack.yaml
  - cent7/ece_hpc/spack.yaml
  - cent8/envs/avx512/python/spack.yaml
  - cent7/bioinformatics/spack.yaml
  - cent7/py_376/spack.yaml
  - cent8/envs/avx/rproject/spack.yaml
  full_name: alexpacheco/spackenv
  latest_release: null
  readme: '<h1><a id="user-content-spack-environments" class="anchor" aria-hidden="true"
    href="#spack-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPACK
    Environments</h1>

    <p>This repo contains the environment definitions to deploy site-software on Lehigh
    University''s Research Computing resources via SPACK environments.</p>

    <h2><a id="user-content-software-deployment-for-centos-8x" class="anchor" aria-hidden="true"
    href="#software-deployment-for-centos-8x"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Software deployment for CentOS 8.x</h2>

    <p>Software is deployed using two Spack installations.</p>

    <ol>

    <li>For compilers and module environments</li>

    <li>Site software for general use</li>

    </ol>

    <h3><a id="user-content-compilers" class="anchor" aria-hidden="true" href="#compilers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilers</h3>

    <p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod
    software for module management. In the future, this installation will also provide
    intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were
    installed in /share/Apps/intel with older intel compilers. This installation should
    not be used for deploying site software nor should the software provided be made
    available using the module environment.</p>

    <p>To reproduce installation</p>

    <pre><code>git clone https://github.com/alexpacheco/spackenv.git

    cd spackenv/compilers/envs/compilers

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch
    between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>

    <h3><a id="user-content-lu-software" class="anchor" aria-hidden="true" href="#lu-software"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LU Software</h3>

    <p>This spack installation provides the deployed site-software on Sol and Hawk.</p>

    <p>To reproduce this installation, you need to first copy the site configuration
    files from <code>etc/spack</code> to your spack install tree. This assumes that
    SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code>
    file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel,
    cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of
    the lubio repository and should be changed to your location. The directory <code>templates</code>
    contains the template lua file for a few modules as defined in the <code>modules.yaml</code>
    file  and should be copied to the <code>etc</code> directory in your spack installation
    tree.</p>

    <p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>

    <h4><a id="user-content-available-environments" class="anchor" aria-hidden="true"
    href="#available-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    Environments</h4>

    <h5><a id="user-content-solhawk" class="anchor" aria-hidden="true" href="#solhawk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>solhawk</h5>

    <p>This environment builds the entire software except the various python and r
    packages for ivybridge, haswell and skylake_avx512 architectures. This environment
    also builds the tcl environment modules that is not currently used. This should
    be build first and any new packages should be added to this environment.</p>

    <pre><code>cd spackenv/cent8/envs/solhawk

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-avxavx2avx512" class="anchor" aria-hidden="true" href="#avxavx2avx512"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>avx/avx2/avx512</h4>

    <p>These environment builds the software stack except the various python and r
    packages for ivybridge/haswell/skylake_avx512 architectures. If software in the
    <code>solhawk</code> environment is already built, then these environments are
    only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>.
    The only reason these environments exist is due to SPACK''s inability to built
    a architecture based LMOD module tree similar to the TCL module tree.

    <em>Note</em>: If you change the path of the installation root, make sure that
    you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx2/lusoft

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-python-and-r-packages" class="anchor" aria-hidden="true"
    href="#python-and-r-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>Python
    and R packages</h4>

    <p>Rather than building module files for various python and r packages, a single
    module is created for a filesystem view of all python and r packages respectively.
    The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any
    application such as <code>trinity</code> that requires many R packages only need
    to load the r module. If new packages added to the above environments require
    a dependent R package, then that dependency should be added to the rpoject environment
    and concretized. The python environment uses a <code>concretization: together</code>
    and may not provide the same python package as the above software environments.
    The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code>
    and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>

    <pre><code>cd spackenv/cent8/envs/avx/python

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <pre><code>cd spackenv/cent8/envs/avx512/rproject

    spack env activate -d .

    spack concretize -f # optional

    spack install

    </code></pre>

    <h4><a id="user-content-x86_64" class="anchor" aria-hidden="true" href="#x86_64"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>x86_64</h4>

    <p>This environment builds unoptimized software such as anaconda python, gnu parallel,
    scree, tmux, etc for generic x86_64 processor.</p>

    <h2><a id="user-content-centos-7x-software" class="anchor" aria-hidden="true"
    href="#centos-7x-software"><span aria-hidden="true" class="octicon octicon-link"></span></a>CentOS
    7.x software</h2>

    <p>This just collects the various environments for building software before the
    CentOS 8.x upgrade.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657632897.0
aminaramoon/config:
  data_format: 2
  description: null
  filenames:
  - packages/spack.yaml
  full_name: aminaramoon/config
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1673135222.0
apt-sim/AdePT:
  data_format: 2
  description: Accelerated demonstrator of electromagnetic Particle Transport
  filenames:
  - scripts/spack.yaml
  full_name: apt-sim/AdePT
  latest_release: null
  readme: '

    <h1><a id="user-content-adept" class="anchor" aria-hidden="true" href="#adept"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>AdePT</h1>

    <p>Accelerated demonstrator of electromagnetic Particle Transport</p>

    <h2><a id="user-content-build-requirements" class="anchor" aria-hidden="true"
    href="#build-requirements"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Requirements</h2>

    <p>The following packages are a required to build and run:</p>

    <ul>

    <li>CMake &gt;= 3.18</li>

    <li>C/C++ Compiler with C++14 support</li>

    <li>CUDA Toolkit (tested 10.1, min version TBD)</li>

    <li>VecCore <a href="https://github.com/root-project/veccore">library</a> 0.7.0
    (recommended, but older versions &gt;= 0.5.0 also work)</li>

    <li>VecGeom <a href="https://gitlab.cern.ch/VecGeom/VecGeom" rel="nofollow">library</a>
    &gt;= 1.1.20</li>

    </ul>

    <p>A suitable environment may be set up either from CVMFS (requires the sft.cern.ch
    and projects.cern.ch repos

    to be available on the local system):</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c1">source</span> /cvmfs/sft.cern.ch/lcg/views/devAdePT/latest/x86_64-centos7-gcc11-opt/setup.sh</span></pre></div>

    <p>or from the supplied <a href="https://spack.io" rel="nofollow">spack</a> environment
    file:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">spack
    env create adept-spack ./scripts/spack.yaml</span>

    $ <span class="pl-s1">spack -e adept-spack concretize -f</span>

    $ <span class="pl-s1">spack -e adept-spack install</span>

    <span class="pl-c1">...</span>

    $ <span class="pl-s1">spack env activate -p adept-spack</span></pre></div>

    <p>Note that the above assumes your spack configuration defaults to use a suitable
    C++ compiler and has

    <code>cuda_arch</code> set appropriately for the hardware you will be running
    on.</p>

    <p>You can also build the packages manually as follows. To configure and build
    VecCore, simply run:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    -S. -B./veccore-build -DCMAKE_INSTALL_PREFIX=<span class="pl-s"><span class="pl-pds">"</span>&lt;path_to_veccore_installation&gt;<span
    class="pl-pds">"</span></span></span>

    $ <span class="pl-s1">cmake --build ./veccore-build --target install</span></pre></div>

    <p>Add your CUDA installation to the PATH and LD_LIBRARY_PATH environment variables,
    as in:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-k">export</span> PATH=<span class="pl-smi">${PATH}</span>:/usr/local/cuda/bin</span>

    $ <span class="pl-s1"><span class="pl-k">export</span> LD_LIBRARY_PATH=<span class="pl-smi">${LD_LIBRARY_PATH}</span>:/usr/local/cuda/lib64</span></pre></div>

    <p>Find the CUDA architecture for the target GPU. If you installed the CUDA demo
    suite, the fastest way is to use the deviceQuery executable from <code>extras/demo_suite</code>.
    This lists the CUDA capability for all installed GPUs, remember the value for
    your target:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">/usr/local/cuda/extras/demo_suite/deviceQuery</span>

    <span class="pl-c1">Device 0: "GeForce RTX 2080 SUPER"</span>

    <span class="pl-c1">  CUDA Capability Major/Minor version number:    7.5 (cuda_architecture=75)</span>

    <span class="pl-c1">...</span>

    <span class="pl-c1">Device 1: "Quadro K4200"</span>

    <span class="pl-c1">  CUDA Capability Major/Minor version number:    3.0 (cuda_architecture=30)</span></pre></div>

    <p>To configure and build VecGeom, use the configuration options below, using
    as &lt;cuda_architecture&gt; the value from the step above:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    -S. -B./vecgeom-build \</span>

    <span class="pl-c1">  -DCMAKE_INSTALL_PREFIX="&lt;path_to_vecgeom_installation&gt;"
    \</span>

    <span class="pl-c1">  -DCMAKE_PREFIX_PATH="&lt;path_to_veccore_installation&gt;"
    \</span>

    <span class="pl-c1">  -DVECGEOM_ENABLE_CUDA=ON \</span>

    <span class="pl-c1">  -DVECGEOM_GDML=ON \</span>

    <span class="pl-c1">  -DBACKEND=Scalar \</span>

    <span class="pl-c1">  -DCMAKE_CUDA_ARCHITECTURES=&lt;cuda_architecture&gt; \</span>

    <span class="pl-c1">  -DVECGEOM_USE_NAVINDEX=ON \</span>

    <span class="pl-c1">  -DCMAKE_BUILD_TYPE=Release</span>

    $ <span class="pl-s1">cmake --build ./vecgeom-build --target install -- -j6 <span
    class="pl-c"><span class="pl-c">#</span>## build using 6 threads and install</span></span></pre></div>

    <p>To configure AdePT, simply run:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    -S. -B./adept-build <span class="pl-k">&lt;</span>otherargs<span class="pl-k">&gt;</span></span></pre></div>

    <p>As  one needs to provide the paths to the dependence libraries VecCore and
    VecGeom, and optionally the path to the Alpaka installation (in case you want
    to build FisherPrice_Alpaka)</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">   -DCMAKE_PREFIX_PATH="&lt;path_to_veccore_installation&gt;;&lt;path_to_vecgeom_installation&gt;;[&lt;alpakaInstallDir&gt;]"
    \</span>

    <span class="pl-c1">   -DCMAKE_CUDA_ARCHITECTURES=&lt;cuda_architecture&gt; \</span>

    <span class="pl-c1">   -DCMAKE_BUILD_TYPE=Release</span></pre></div>

    <p>To build, run:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">cmake
    --build ./adept-build -- -j6 <span class="pl-c"><span class="pl-c">#</span>##
    build using 6 threads</span></span></pre></div>

    <p>The provided examples and tests can be run from the build directory:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c1">cd</span> adept-build</span>

    $ <span class="pl-s1">CUDA_VISIBLE_DEVICES=0 BuildProducts/bin/<span class="pl-k">&lt;</span>executable<span
    class="pl-k">&gt;</span>   <span class="pl-c"><span class="pl-c">#</span>## use
    the device number matching the selected &lt;cuda_architecture&gt;</span></span></pre></div>

    <h2><a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Copyright</h2>

    <p>AdePT code is Copyright (C) CERN, 2020, for the benefit of the AdePT project.

    Any other code in the project has (C) and license terms clearly indicated.</p>

    <p>Contributions of all authors to AdePT and their institutes are acknowledged
    in

    the <code>AUTHORS.md</code> file.</p>

    '
  stargazers_count: 14
  subscribers_count: 9
  topics: []
  updated_at: 1678241719.0
ashermancinelli/oci-builder:
  data_format: 2
  description: Repo to use free github actions to build my docker containers in kaniko
  filenames:
  - spack.yaml
  full_name: ashermancinelli/oci-builder
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1630966496.0
ashermancinelli/vimconfig:
  data_format: 2
  description: null
  filenames:
  - spack/envs/triage/spack.yaml
  full_name: ashermancinelli/vimconfig
  latest_release: null
  readme: "<h1><a id=\"user-content-vimconfig\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#vimconfig\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>vimconfig</h1>\n<p>Lots and lots of different configurations for various\
    \ programs all wrapped up into one repo. Under heavy development so tread with\
    \ some caution :)</p>\n<h2><a id=\"user-content-how-to-use\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#how-to-use\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>How to use</h2>\n<p>The top directory has a\
    \ script to deal with installation - you should pretty much only interact with\
    \ the repo through that script.\nThe help message is quite descriptive:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>$ ./configure --h\n\n  Usage:\n\
    \n  -p <span class=\"pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>  \
    \         Sets install prefix. Default: /people/manc568/.local\n  -r <span class=\"\
    pl-k\">&lt;</span>path<span class=\"pl-k\">&gt;</span>           Path to RC file\
    \ <span class=\"pl-k\">for</span> given shell. Default: /qfs/people/manc568/.bashrc\n\
    \  -d                  Default installation. Installs ctags, vim, and bash\n \
    \ -s <span class=\"pl-k\">&lt;</span>pkg<span class=\"pl-k\">&gt;</span>     \
    \       Show installation script <span class=\"pl-k\">for</span> pacakge\n  -i\
    \                  One or more of the following list, separated by commas with\
    \ no spaces:\n\n       zsh\n       bash\n       ctags\n       vim\n       tmux\n\
    \       emacs\n       profiles\n       modules\n       rice\n       rice.sh\n\
    \       fresh</pre></div>\n<h2><a id=\"user-content-examples\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#examples\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<p>For example, to just install\
    \ my vim configuration, you'd do:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>$ ./configure -i vim</pre></div>\n<p>Or to install configs for multiple\
    \ programs:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ ./configure\
    \ -i vim,ctags,tmux,emacs,bash</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1681145022.0
bfovet/config:
  data_format: 2
  description: My personal configuration files
  filenames:
  - spack-env/linux-ubuntu22.04-skylake/spack.yaml
  full_name: bfovet/config
  latest_release: null
  readme: '<h1><a id="user-content-config" class="anchor" aria-hidden="true" href="#config"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>config</h1>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1658465316.0
bsurc/BSU-software-configs:
  data_format: 2
  description: null
  filenames:
  - borah/environments/_netcdf+hdf5+fftw/_spack.yaml
  - borah/environments/libraries/netcdf/_spack.yaml
  - falcon/environments/applications/lammps/_spack.yaml
  - falcon/environments/applications/vacuumms/_spack.yaml
  - falcon/environments/applications/gromacs/_spack.yaml
  - falcon/environments/applications/vasp/_spack.yaml
  - falcon/environments/libraries/netcdf/_spack.yaml
  - falcon/environments/applications/ncl/_spack.yaml
  - borah/environments/libraries/hdf5/_spack.yaml
  - falcon/environments/libraries/hdf5/_spack.yaml
  - falcon/environments/compilers/_spack.yaml
  - falcon/environments/applications/quantum-espresso/_spack.yaml
  - falcon/environments/applications/wps/_spack.yaml
  - falcon/environments/Core/_spack.yaml
  - falcon/environments/applications/openfoam/_spack.yaml
  - borah/environments/compilers/_spack.yaml
  - falcon/environments/base/_spack.yaml
  - falcon/environments/applications/namd/_spack.yaml
  - falcon/environments/applications/ncview/_spack.yaml
  full_name: bsurc/BSU-software-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configurations-used-to-stand-up-stacks-at-boise-state-university"
    class="anchor" aria-hidden="true" href="#spack-configurations-used-to-stand-up-stacks-at-boise-state-university"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configurations
    used to stand up stacks at Boise State University</h1>

    <p>(C) 2022 Frank Willmore, et. al. Boise State Univesity Reseach Computing

    <a href="mailto:frankwillmore@boisestate.edu">frankwillmore@boisestate.edu</a></p>

    <p>Note that the environment (spack.yaml) files as checked in are named _spack.yaml,
    since spack rewrites and reorders spack.yaml as it digests the environment. _spack.yaml
    can be regarded as the master, and copied to spack.yaml when processing an environment.
    There is a .gitignore under BOISESTATE set to ignore spack.yaml''s under this
    tree.</p>

    <p>Base configurations provided gcc and oneapi compilers, cuda built with these
    compilers, mpich, openmpi, and intel-oneapi-mpi MPI stacks built with these compilers,
    and modules that will load the correct cuda build and compiler when loading the
    MPI.</p>

    <p>Copies of modules are checked in as well, as these needed to be modified considerably
    from the original generated modules.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1676657373.0
bsurc/spack-configs:
  data_format: 2
  description: spack configuration settings used at BSU research computing
  filenames:
  - BOISESTATE/borah/environments/b4s/_spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.08/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/prod/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.08/prod/spack.yaml
  - NERSC/cori/e4s-21.02/prod/spack.yaml
  - NERSC/cori/e4s-stacks/knl/spack.yaml
  - BOISESTATE/falcon/environments/libraries/hdf5/_spack.yaml
  - BOISESTATE/borah/environments/netcdf+hdf5+fftw/_spack.yaml
  - NERSC/cori/e4s-21.02/spack.yaml
  - NERSC/cori/e4s-20.10/spack.yaml
  - OLCF/e4s-stacks/etc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - BOISESTATE/falcon/environments/Core/_spack.yaml
  - BOISESTATE/borah/applications/gromacs/_spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/prod/spack.yaml
  full_name: bsurc/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1660257692.0
buildsi/splice-experiment:
  data_format: 2
  description: Preparing for the splice experiment (notes are currently here)
  filenames:
  - manual/ref/e4s/spack.yaml
  full_name: buildsi/splice-experiment
  latest_release: null
  readme: '<h1><a id="user-content-splice-experiment" class="anchor" aria-hidden="true"
    href="#splice-experiment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Splice
    Experiment</h1>

    <p>This is planning for the <a href="https://github.com/buildsi/spliced">spliced</a>
    experiment

    that we plan to run for the BUILDSI project. We will use a container base to the
    largest extent possible.

    To see our original manual setup, you can look in <a href="manual">manual</a>,
    or to read the original

    experiment plan and design, see <a href="plan.md">plan.md</a>. Note that although
    the original plan was to run this on HPC, the file-system had significant issues
    and it was entirely run in GitHub actions. For the interested user,

    examples of running scripts are provided for Singularity, Podman, and Docker,
    in the case you want to do this manually. The actual running of experiments happened
    in <a href="https://github.com/buildsi/splice-experiment-runs">this repository</a>.</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <h3><a id="user-content-1-experiment-derivation" class="anchor" aria-hidden="true"
    href="#1-experiment-derivation"><span aria-hidden="true" class="octicon octicon-link"></span></a>1.
    Experiment Derivation</h3>

    <p><em>data from this step is provided here</em></p>

    <p>To see our first experiment attempt setup, see <a href="attempts.md">attemps.md</a>
    where we tried using tests in spack for a ground truth. Ultimately we decided
    this was not good enough and we would use a set of known libraries with ABI issues
    (manually defined) in <a href="diffs">diffs</a>.</p>

    <h3><a id="user-content-2-running-experiments" class="anchor" aria-hidden="true"
    href="#2-running-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.
    Running Experiments</h3>

    <p>Running experiments is easy, and automated! We use the container build alongside
    this repostiory with a Github workflow in a separate repository and then can programatically
    get results. Simply:</p>

    <ol>

    <li>Ensure this repository is pushed (up to date), as the diffs/splices come from
    here.</li>

    <li>Go to <a href="https://github.com/buildsi/splice-experiment-runs/actions">buildsi/splice-experiment-runs
    Actions</a>

    </li>

    <li>Click on the "Spliced Analysis" workflow, and then "Run Workflow"</li>

    <li>The name in the box should correspond to the main package and dependency folder
    to run.</li>

    </ol>

    <p>When you are done, you can clone the <a href="https://github.com/buildsi/splice-experiment-artifacts">artifacts
    repository</a> to manually update artifacts, or just wait for it to update overnight.
    The full analysis (with the artifacts as a git submodule) is in <a href="https://github.com/buildsi/splice-experiment-results">buildsi/splice-experiment-results</a>.</p>

    <h2><a id="user-content-changelog" class="anchor" aria-hidden="true" href="#changelog"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Changelog:</h2>

    <ul>

    <li>version 0.0.1: original version with some tweaks</li>

    <li>version 0.0.11: updating cle from its master to resolve dependency install
    bugs <a href="https://github.com/vsoch/cle/commit/b631940d5598e457533866cbc7284123c2c08ef1">commit</a>

    </li>

    <li>version 0.0.12: refactor of spliced to include diff functionality</li>

    </ul>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1670462783.0
buildtesters/buildtest:
  data_format: 2
  description: HPC System and Software Testing Framework
  filenames:
  - examples/spack/example/spack.yaml
  full_name: buildtesters/buildtest
  latest_release: v1.3
  stargazers_count: 60
  subscribers_count: 5
  topics:
  - test-automation
  - testing-framework
  - yaml
  - system-testing
  - hpc
  - json-schema
  - buildtest
  updated_at: 1676973368.0
bvanessen/lbann_distconv:
  data_format: 2
  description: null
  filenames:
  - spack_environments/users/llnl_lc/x86_64_cuda/spack.yaml
  - spack_environments/users/llnl_lc/ppc64le_cuda/spack.yaml
  full_name: bvanessen/lbann_distconv
  latest_release: null
  readme: "<h1><a id=\"user-content-lbann-livermore-big-artificial-neural-network-toolkit\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#lbann-livermore-big-artificial-neural-network-toolkit\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>LBANN: Livermore\
    \ Big Artificial Neural Network Toolkit</h1>\n<p>The Livermore Big Artificial\
    \ Neural Network toolkit (LBANN) is an\nopen-source, HPC-centric, deep learning\
    \ training framework that is\noptimized to compose multiple levels of parallelism.</p>\n\
    <p>LBANN provides model-parallel acceleration through domain\ndecomposition to\
    \ optimize for strong scaling of network training.  It\nalso allows for composition\
    \ of model-parallelism with both data\nparallelism and ensemble training methods\
    \ for training large neural\nnetworks with massive amounts of data.  LBANN is\
    \ able to advantage of\ntightly-coupled accelerators, low-latency high-bandwidth\
    \ networking,\nand high-bandwidth parallel file systems.</p>\n<p>LBANN supports\
    \ state-of-the-art training algorithms such as\nunsupervised, self-supervised,\
    \ and adversarial (GAN) training methods\nin addition to traditional supervised\
    \ learning.  It also supports\nrecurrent neural networks via back propagation\
    \ through time (BPTT)\ntraining, transfer learning, and multi-model and ensemble\
    \ training\nmethods.</p>\n<h2><a id=\"user-content-building-lbann\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#building-lbann\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Building LBANN</h2>\n<p>The preferred method\
    \ for LBANN users to install LBANN is to use\n<a href=\"https://github.com/llnl/spack\"\
    >Spack</a>. After some system\nconfiguration, this should be as straightforward\
    \ as</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack install lbann</pre></div>\n\
    <p>More detailed instructions for building and installing LBANN are\navailable\
    \ at the <a href=\"https://lbann.readthedocs.io/en/latest/index.html\" rel=\"\
    nofollow\">main LBANN\ndocumentation</a>.</p>\n<h2><a id=\"user-content-running-lbann\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-lbann\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running LBANN</h2>\n<p>The basic\
    \ template for running LBANN is</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-k\">&lt;</span>mpi-launcher<span class=\"pl-k\">&gt;</span>\
    \ <span class=\"pl-k\">&lt;</span>mpi-options<span class=\"pl-k\">&gt;</span>\
    \ \\\n    lbann <span class=\"pl-k\">&lt;</span>lbann-options<span class=\"pl-k\"\
    >&gt;</span> \\\n    --model=model.prototext \\\n    --optimizer=opt.prototext\
    \ \\\n    --reader=data_reader.prototext</pre></div>\n<p>When using GPGPU accelerators,\
    \ users should be aware that LBANN is\noptimized for the case in which one assigns\
    \ one GPU per MPI\n<em>rank</em>. This should be borne in mind when choosing the\
    \ parameters for\nthe MPI launcher.</p>\n<p>More details about running LBANN are\
    \ documented\n<a href=\"https://lbann.readthedocs.io/en/latest/running_lbann.html\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h2><a id=\"user-content-publications\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#publications\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Publications</h2>\n<p>A list of publications,\
    \ presentations and posters are shown\n<a href=\"https://lbann.readthedocs.io/en/latest/publications.html\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h2><a id=\"user-content-reporting-issues\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reporting-issues\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Reporting issues</h2>\n<p>Issues,\
    \ questions, and bugs can be raised on the <a href=\"https://github.com/llnl/lbann/issues\"\
    >Github issue\ntracker</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1570946110.0
camierjs/mfem-asan:
  data_format: 2
  description: null
  filenames:
  - config/docker/spack.yaml
  full_name: camierjs/mfem-asan
  latest_release: null
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed under the terms\
    \ of the BSD-3 license. All new contributions\nmust be made under this license.\
    \ See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a> for\n\
    details.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release Number:\
    \ LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1680543921.0
charmoniumQ/astrophysics-project:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: charmoniumQ/astrophysics-project
  latest_release: null
  readme: '<h1><a id="user-content-neural-network-superresolving-for-cosmological-simulations"
    class="anchor" aria-hidden="true" href="#neural-network-superresolving-for-cosmological-simulations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Neural Network Superresolving
    for Cosmological Simulations</h1>

    <p>In this repository, I attempt to reproduce the analysis of <a href="https://arxiv.org/pdf/2111.06393.pdf"
    rel="nofollow">Schaurecker et

    al. 2021</a> on Enzo data (they use Illustris).</p>

    <h1><a id="user-content-to-reproduce" class="anchor" aria-hidden="true" href="#to-reproduce"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>To reproduce</h1>

    <p>The code <code>main.py</code> is intended to be run locally. It sends commands
    to the

    remote. You will need to modify this with your site-specific parameters. It

    should be the only file you need to modify.</p>

    <p>To set up the remote machine (should be capable of Slurm):</p>

    <div class="highlight highlight-source-shell"><pre>remote$ <span class="pl-c"><span
    class="pl-c">#</span> Install Spack on the remote</span>

    remote$ <span class="pl-c"><span class="pl-c">#</span> See my notes in reports/spack_on_cc.md
    for details on the UIUC Campus Cluster.</span>

    remote$ git clone -c feature.manyFiles=true https://github.com/spack/spack.git


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy spack.lock to the
    remote</span>

    remote$ spack/bin/spack environment create main4 spack.lock

    remote$ spack/bin/spack environment activate main4

    remote$ spack/bin/spack concretize

    remote$ spack/bin/spack install


    remote$ <span class="pl-c"><span class="pl-c">#</span> Copy envirment.yaml ot
    the remote</span>

    remote$ spack/bin/spack activate main4

    remote$ conda install --name main3 --file environment,yaml


    remote$ <span class="pl-c"><span class="pl-c">#</span> Ensure that Slurm works</span>

    remote$ sbatch --help</pre></div>

    <p>To set up the local machine:</p>

    <div class="highlight highlight-source-shell"><pre>locla$ <span class="pl-c"><span
    class="pl-c">#</span> Install conda</span>

    locla$ <span class="pl-c"><span class="pl-c">#</span> Install conda environment</span>

    local$ conda install --name main3 --file environment,yaml</pre></div>

    <p>You will need to configure SSH keys to the remote.</p>

    <p>Then you should be to run <code>main.py</code>. <code>main.py</code> runs the
    entire workflow. It is

    smart about not running a certain step if the data already exists. It also

    hashes the input parameters in the filename of the data, so it is unlikely to

    return stale data.</p>

    <p>The end result will end up in <code>output</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1650312591.0
cinemascienceworkflows/2021-05_ExaWind-AMRWind:
  data_format: 2
  description: null
  filenames:
  - inputs/spack/spack.yaml
  full_name: cinemascienceworkflows/2021-05_ExaWind-AMRWind
  latest_release: null
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1627931117.0
class4kayaker/GPGPU_self_study:
  data_format: 2
  description: Minor work intended to do self study on GPGPU programming.
  filenames:
  - 1D_advection_FCT/kokkos/spack.yaml
  full_name: class4kayaker/GPGPU_self_study
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1616469892.0
d-SEAMS/seams-core:
  data_format: 2
  description: The d-SEAMS C++ core engine
  filenames:
  - spack.yaml
  full_name: d-SEAMS/seams-core
  latest_release: v1.0.1
  readme: "<h1><a id=\"user-content-d-seams\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#d-seams\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>d-SEAMS</h1>\n<p><strong>Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations</strong></p>\n<p><a href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\
    ><img src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://builtwithnix.org\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82b492dd4f94cd6fe1783f1065487d3dbc0602c2a65b1717a5613df3b6e8f65f/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\"\
    \ alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<ul>\n<li>Check our build status <a href=\"\
    https://github.com/d-SEAMS/seams-core/actions/workflows/\">here</a>.</li>\n<li>The\
    \ docs themselves are <a href=\"https://docs.dseams.info\" rel=\"nofollow\">here</a>\
    \ and development is\nongoing <a href=\"https://github.com/d-SEAMS/seams-core\"\
    >on GitHub</a>\n</li>\n<li>We also have <a href=\"https://zenodo.org/communities/d-seams/\"\
    \ rel=\"nofollow\">a Zenodo community</a> for user-contributions like reviews,\
    \ testimonials\nand tutorials</li>\n<li>Trajectories are hosted <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">on\nfigshare</a>.</li>\n<li>Our <a href=\"https://wiki.dseams.info\"\
    \ rel=\"nofollow\">wiki is here</a>\n</li>\n</ul>\n<p>\\brief The C++ core of\
    \ d-SEAMS, a molecular dynamics trajectory analysis engine.</p>\n<p>\\note The\
    \ <a href=\"pages.html\">related pages</a> describe the examples and how to obtain\n\
    the data-sets (trajectories) <a href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\"\
    \ rel=\"nofollow\">from figshare</a>.</p>\n<p>\\warning <strong>If</strong> you\
    \ are unwilling to use the <code>nix</code> build system, then <strong>please\
    \ note</strong> that you must manage the dependencies MANUALLY, including the\
    \ compiler versions. Optionally, use the provided <code>conda</code> environment.</p>\n\
    <h1><a id=\"user-content-citation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #citation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citation</h1>\n\
    <ul>\n<li>\n<p>This has been published at the <a href=\"https://doi.org/10.1021/acs.jcim.0c00031\"\
    \ rel=\"nofollow\">Journal of Chemical Information and Modeling\n(JCIM)</a></p>\n\
    </li>\n<li>\n<p>You may also read <a href=\"https://arxiv.org/abs/1909.09830\"\
    \ rel=\"nofollow\">the preprint on arXiv</a></p>\n</li>\n</ul>\n<p>If you use\
    \ this software please cite the following:</p>\n<pre><code>Goswami, R., Goswami,\
    \ A., &amp; Singh, J. K. (2020). d-SEAMS: Deferred Structural Elucidation Analysis\
    \ for Molecular Simulations. Journal of Chemical Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n\
    </code></pre>\n<p>The corresponding <code>bibtex</code> entry is:</p>\n<pre><code>@Article{Goswami2020,\n\
    author={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS:\
    \ Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal\
    \ of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\n\
    publisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\n\
    url={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n</code></pre>\n<h1><a id=\"\
    user-content-compilation\" class=\"anchor\" aria-hidden=\"true\" href=\"#compilation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compilation</h1>\n\
    <p>We use a deterministic build system to generate both bug reports and uniform\n\
    usage statistics. This also handles the <code>lua</code> scripting engine.</p>\n\
    <p>\\note The lua functions are documented on the <a href=\"https://docs.dseams.info/md_markdown_luafunctions\"\
    \ rel=\"nofollow\">on the API Docs</a></p>\n<p>We also provide a <code>conda</code>\
    \ environment as a fallback, which is also recommended for MacOS users.</p>\n\
    <h2><a id=\"user-content-build\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #build\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build</h2>\n\
    <h3><a id=\"user-content-conda-working-now\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#conda-working-now\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Conda (working now)</h3>\n<p>Although we strongly suggest using <code>nix</code>,\
    \ for MacOS systems, the following\ninstructions may be more suitable. We will\
    \ assume the presence of <a href=\"https://mamba.readthedocs.io/en/latest/installation.html\"\
    \ rel=\"nofollow\">micromamba</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-k\">~</span>/seams-core\n\
    micromamba create -f environment.yml\nmicromamba activate dseams\nluarocks install\
    \ luafilesystem</pre></div>\n<p>Now the installation can proceed.</p>\n<p>\\note\
    \ we do not install <code>lua-luafilesystem</code> within the <code>conda</code>\
    \ environment because it is outdated on <code>osx</code></p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>mkdir build\n<span class=\"pl-c1\">cd</span> build\n\
    cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=<span\
    \ class=\"pl-smi\">$CONDA_PREFIX</span> ../\nmake -j<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">$(</span>nproc<span class=\"pl-pds\">)</span></span>\nmake\
    \ install\n<span class=\"pl-smi\">$CONDA_PREFIX</span>/bin/yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>We have opted to install into the <code>conda</code> environment, if this is\
    \ not the\nintended behavior, use <code>/usr/local</code> instead.</p>\n<h3><a\
    \ id=\"user-content-spack-not-working-at-the-moment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-not-working-at-the-moment\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Spack (not working at the moment)</h3>\n<p>Manually\
    \ this can be done in a painful way as follows:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>spack install eigen@3.3.9 lua@5.2\nspack install catch2 fmt yaml-cpp openblas\
    \ boost cmake ninja meson\nspack load catch2 fmt yaml-cpp openblas boost cmake\
    \ ninja meson eigen@3.3.9 lua@5.2\nluarocks install luafilesystem</pre></div>\n\
    <p>Or better:</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack\
    \ env activate <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pwd<span class=\"\
    pl-pds\">)</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> After\
    \ loading the packages</span>\nluarocks install luafilesystem</pre></div>\n<p>Now\
    \ we can build and install as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>cmake -S <span class=\"pl-c1\">.</span> -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=<span\
    \ class=\"pl-smi\">$HOME</span>/.local \\\n -DCMAKE_CXX_FLAGS=<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>-pg -fsanitize=address <span class=\"pl-pds\"\
    >\"</span></span> \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\
    \ \\\n -DBUILD_TESTING=NO\ncmake --build build</pre></div>\n<p>Or more reasonably:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ INST_DIR=<span class=\"pl-smi\">$HOME</span>/.local\n<span class=\"pl-c1\">cd</span>\
    \ src\nmeson setup bbdir --prefix <span class=\"pl-smi\">$INST_DIR</span>\nmeson\
    \ compile -C bbdir\nmeson install -C bbdir\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> if not done</span>\n<span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-smi\">$PATH</span>:<span class=\"pl-smi\">$INST_DIR</span>/bin\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:<span\
    \ class=\"pl-smi\">$INST_DIR</span>/lib\n<span class=\"pl-c1\">cd</span> ../\n\
    yodaStruct -c lua_inputs/config.yml</pre></div>\n<h3><a id=\"user-content-nix-not-working-at-the-moment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#nix-not-working-at-the-moment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Nix (not\
    \ working at the moment)</h3>\n<p>Since this project is built with <code>nix</code>,\
    \ we can simply do the following from the\nroot directory (longer method):</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Make sure there are no artifacts</span>\nrm -rf build\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This will take a long time\
    \ the first time as it builds the dependencies</span>\nnix-build <span class=\"\
    pl-c1\">.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>A faster method of building the software is by using the <a href=\"https://dseams.cachix.org/\"\
    \ rel=\"nofollow\">cachix binary cache</a> as shown:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Install cachix</span>\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Use the binary cache</span>\n\
    cachix use dseams\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Faster with\
    \ the cache than building from scratch</span>\nnix-build <span class=\"pl-c1\"\
    >.</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Optional</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Install into your path</span>\n\
    nix-env -if <span class=\"pl-c1\">.</span> <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Required</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ Run the command anywhere</span>\nyodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <h3><a id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h3>\n\
    <p>Having installed the <code>yodaStruct</code> binary and library, we can now\
    \ use it.</p>\n<div class=\"highlight highlight-source-shell\"><pre>yodaStruct\
    \ -c lua_inputs/config.yml</pre></div>\n<p>\\note The paths in the <code>.yml</code>\
    \ should be <strong>relative to the folder from which the binary is called</strong>.</p>\n\
    <p>If you're confused about how to handle the relative paths, run the command\
    \ <code>yodaStruct -c lua_inputs/config.yml</code> in the top-level directory,\
    \ and set the paths relative to the top-level directory. This is the convention\
    \ used in the examples as well.</p>\n<h3><a id=\"user-content-language-server-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#language-server-support\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Language Server\
    \ Support</h3>\n<p>To generate a <code>compile_commands.json</code> file for working\
    \ with a language server\nlike <a href=\"https://github.com/MaskRay/ccls\">ccls</a>\
    \ use the following commands:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Pure environment</span>\n\
    nix-shell --pure\nmkdir -p build <span class=\"pl-k\">&amp;&amp;</span> <span\
    \ class=\"pl-c1\">cd</span> build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES\
    \ ../\ncp compile_commands.json ../</pre></div>\n<p>Note that there is no need\
    \ to actually compile the project if you simply need to\nget the compiler database\
    \ for the language server.</p>\n<p><strong>Do Not</strong> commit the <code>.json</code>\
    \ file.</p>\n<h2><a id=\"user-content-development\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Development</h2>\n<p>We can simply use the <code>nix</code> environment:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> From the project root</span>\nnix-shell --pure</pre></div>\n\
    <h1><a id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n\
    <p>This is built completely with nix:</p>\n<pre lang=\"{bash}\"><code># Install\
    \ systemwide\nnix-env -if .\n</code></pre>\n<p>To run the sample inputs, simply\
    \ install the software, and ensure that <code>input/</code> is a child directory.</p>\n\
    <pre lang=\"{bash}\"><code># Assuming you are in the src directory\n# Check help\
    \ with -h\nyodaStruct -c lua_inputs/config.yml\n</code></pre>\n<h2><a id=\"user-content-tests\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#tests\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Tests</h2>\n<p>Apart from the <a href=\"\
    https://docs.dseams.info/pages.html\" rel=\"nofollow\">examples</a>, the test-suite\n\
    can be run with the <code>yodaStruct_test</code> binary, which will drop into\
    \ the\n<code>nix</code> environment before building and executing <code>gdb</code>:</p>\n\
    <pre lang=\"{bash}\"><code># Just run this\n./testBuild.sh\n# At this point the\
    \ binary and library are copied into the root\n# One might, in a foolhardy attempt,\
    \ use gdb at this point\n# Here be dragons :)\n# USE NIX\n# Anyway\ngdb --args\
    \ ./yodaStruct -c lua_inputs/config.yml\n# quit gdb with quit\n# Go run the test\
    \ binary\ncd shellBuild\n./yodaStruct_test\n</code></pre>\n<p>Do note that the\
    \ regular installation via <code>nix-env</code> runs the tests before the installation</p>\n\
    <h1><a id=\"user-content-developer-documentation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#developer-documentation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Developer Documentation</h1>\n\n<p>While developing,\
    \ it is sometimes expedient to update the packages used. It is\nthen useful to\
    \ note that we use <a href=\"https://github.com/nmattia/niv/\">niv</a> to handle\
    \ our pinned packages (apart from\nthe ones built from Github). Thus, one might\
    \ need, say:</p>\n<div class=\"highlight highlight-source-shell\"><pre>niv update\
    \ nixpkgs -b nixpkgs-unstable</pre></div>\n<p>Test the build with nix:</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>nix-build <span class=\"pl-c1\"\
    >.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Outputs are in ./result</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> If you get a CMake error</span>\n\
    rm -rf build\nnix-store --delete /nix/store/<span class=\"pl-smi\">$whatever</span>\
    \ <span class=\"pl-c\"><span class=\"pl-c\">#</span> $whatever is the derivation\
    \ complaining</span>\nnix-collect-garbage <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> then try again [worst case scenario]</span></pre></div>\n<h2><a\
    \ id=\"user-content-leaks-and-performance\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#leaks-and-performance\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Leaks and performance</h2>\n<p>While testing for leaks, use <code>clang</code>\
    \ (for\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\"\
    >AddressSanitizer</a>\nand\n<a href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\
    >LeakSanitizer</a>)\nand the following:</p>\n<pre lang=\"{bash}\"><code># From\
    \ the developer shell\nexport CXX=/usr/bin/clang++ &amp;&amp; export CC=/usr/bin/clang\n\
    cmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg\
    \ -DCMAKE_SHARED_LINKER_FLAGS=-pg\n</code></pre>\n<h1><a id=\"user-content-overview\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Overview</h1>\n<p>As of Mon Jan\
    \ 20 15:57:18 2020, the lines of code calculated by\n<a href=\"http://cloc.sourceforge.net/\"\
    \ rel=\"nofollow\">cloc</a> are as follows:</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"><img src=\"images/cloc-2020-01-20_15-56.png\"\
    \ alt=\"Cloc Lines\" style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-contributing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Contributing</h1>\n<p>Please\
    \ ensure that all contributions are formatted according to the\n<a href=\"./clang-format\"\
    >clang-format</a> configuration file.</p>\n<p>Specifically, consider using the\
    \ following:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/rosshemsley/SublimeClangFormat\"\
    >Sublime Plugin</a> for users\nof Sublime Text</p>\n</li>\n<li>\n<p><a href=\"\
    https://github.com/lassik/emacs-format-all-the-code\">format-all</a> for Emacs</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/rhysd/vim-clang-format\">vim-clang-format</a>\
    \ for Vim</p>\n</li>\n<li>\n<p>Visual Studio: <a href=\"http://llvm.org/builds/\"\
    \ rel=\"nofollow\">http://llvm.org/builds/</a>, or use the <a href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\"\
    \ rel=\"nofollow\">integrated support in Visual Studio 2017</a></p>\n</li>\n<li>\n\
    <p>Xcode: <a href=\"https://github.com/travisjeffery/ClangFormat-Xcode\">https://github.com/travisjeffery/ClangFormat-Xcode</a></p>\n\
    </li>\n</ul>\n<p>Where some of the above suggestions are derived from <a href=\"\
    https://github.com/andrewseidl/githook-clang-format\">this depreciated githook</a>.</p>\n\
    <p>Also, do note that we have a <code>CONTRIBUTING</code> file you <strong>need\
    \ to read</strong> to\ncontribute, for certain reasons, like, common sense.</p>\n\
    <h2><a id=\"user-content-commit-hook\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #commit-hook\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Commit\
    \ Hook</h2>\n<p>Note that we expect compliance with the <code>clang-format</code>\
    \ as mentioned above, and this may be enforced by using the provided scripts for\
    \ a pre-commit hook:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./scripts/git-pre-commit-format\
    \ install</pre></div>\n<p>This will ensure that new commits are in accordance\
    \ to the <code>clang-format</code> file.</p>\n<h2><a id=\"user-content-development-builds\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development-builds\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Development Builds</h2>\n<p>The\
    \ general idea is to drop into an interactive shell with the dependencies and\
    \ then use <code>cmake</code> as usual.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>nix-shell --pure --run bash --show-trace --verbose\n<span class=\"pl-c1\"\
    >cd</span> build\ncmake .. -DCMAKE_BUILD_TYPE=Debug -DNO_WARN=TRUE \\\n -DFIND_EIGEN=TRUE\
    \ \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n -G <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>Ninja<span class=\"pl-pds\">\"</span></span>\nninja\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> Test</span>\n<span class=\"pl-c1\">cd</span>\
    \ ../\nyodaStruct -c lua_inputs/config.yml\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> Debug</span>\ngdb --args yodaStruct -c lua_inputs/config.yml</pre></div>\n\
    <p>To load debugging symbols from the shared library, when you are inside <code>gdb</code>\
    \ (from the top-level directory, for instance), use the following command:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>add-symbol-file build/libyodaLib.so</pre></div>\n\
    <p>Then you can set breakpoints in the C++ code; for instance:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>b seams_input.cpp:408</pre></div>\n<h1><a\
    \ id=\"user-content-acknowledgements\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #acknowledgements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Acknowledgements</h1>\n<p>The following tools are used in this project:</p>\n\
    <ul>\n<li>\n<a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a> for compilation\
    \ (<a href=\"https://github.com/cginternals/cmake-init\">cmake-init</a> was used\
    \ as a reference)</li>\n<li>\n<a href=\"https://clang.llvm.org/\" rel=\"nofollow\"\
    >Clang</a> because it is more descriptive with better tools</li>\n<li>\n<a href=\"\
    https://www.doxygen.org\" rel=\"nofollow\">Doxygen</a> for the developer API</li>\n\
    <li>\n<a href=\"https://clang.llvm.org/docs/ClangFormat.html\" rel=\"nofollow\"\
    >clang-format</a> for code formatting\n<ul>\n<li>\n<a href=\"https://github.com/barisione/clang-format-hooks\"\
    >clang-format-hooks</a> for <code>git</code> hooks to enforce formatting</li>\n\
    </ul>\n</li>\n<li>\n<a href=\"https://www.lua.org\" rel=\"nofollow\">lua</a> for\
    \ the scripting engine</li>\n<li>\n<a href=\"http://yaml.org/\" rel=\"nofollow\"\
    >yaml</a> for the configuration</li>\n</ul>\n<h2><a id=\"user-content-third-party-libraries\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#third-party-libraries\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Third Party Libraries</h2>\n\
    <p>The libraries used are:</p>\n<ul>\n<li>\n<a href=\"https://github.com/bombela/backward-cpp\"\
    >backward-cpp</a> for better stacktraces without <code>gdb</code>\n</li>\n<li>\n\
    <a href=\"https://github.com/jarro2783/cxxopts\">cxxopts</a> for parsing command\
    \ line options</li>\n<li>\n<a href=\"https://github.com/agauniyal/rang\">rang</a>\
    \ for terminal styles (ANSI)</li>\n<li>\n<a href=\"https://github.com/ThePhD/sol2\"\
    >sol2</a> for interfacing with lua</li>\n<li>\n<a href=\"https://github.com/jbeder/yaml-cpp\"\
    >yaml-cpp</a> for working with <code>yaml</code>\n</li>\n<li>\n<a href=\"https://github.com/fmtlib/fmt\"\
    >fmt</a> for safe and fast formatting</li>\n<li><a href=\"http://www.netlib.org/lapack/\"\
    \ rel=\"nofollow\">Linear Algebra PACKage (LAPACK)</a></li>\n<li><a href=\"http://www.netlib.org/blas/\"\
    \ rel=\"nofollow\">Basic Linear Algebra Subprograms (BLAS)</a></li>\n<li><a href=\"\
    https://github.com/yixuan/spectra/\">Spectra</a></li>\n<li>\n<a href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\"\
    \ rel=\"nofollow\">Boost Geometry</a> for working with different coordinates</li>\n\
    <li>\n<a href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\
    >Boost Math</a> for spherical harmonics</li>\n<li>\n<a href=\"https://bitbucket.org/blaze-lib/blaze/\"\
    \ rel=\"nofollow\">Blaze</a> for very fast modern linear algebra</li>\n<li>\n\
    <a href=\"https://github.com/jlblancoc/nanoflann\">nanoflann</a> to calculate\
    \ nearest neighbors</li>\n<li>\n<a href=\"https://github.com/renatoGarcia/icecream-cpp\"\
    >icecream-cpp</a> for pretty-printing and debugging</li>\n</ul>\n"
  stargazers_count: 29
  subscribers_count: 5
  topics:
  - molecular-dynamics-simulation
  - molecular-dynamics
  - trajectory-analysis
  - lua
  - nix
  - d-seams
  - analysis-framework
  - trajectories
  updated_at: 1679913310.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - hpcg-amd/spack.yaml
  - gromacs-amd/spack.yaml
  - nwchem-amd/spack.yaml
  - wrf-amd/spack.yaml
  - quantum-espresso-amd/spack.yaml
  - namd-amd/spack.yaml
  - lammps-amd/spack.yaml
  - hmmer-amd/spack.yaml
  - openfoam-amd/spack.yaml
  - hpl-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<h1><a id="user-content-benchmark-containers" class="anchor" aria-hidden="true"
    href="#benchmark-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Benchmark
    Containers</h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
deephyper/deephyper-platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running DeepHyper experiments on various platforms.
  filenames:
  - ANL/Polaris/spack.yaml
  - ANL/Swing/spack.yaml
  full_name: deephyper/deephyper-platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-deephyper-platform-configurations" class="anchor"
    aria-hidden="true" href="#deephyper-platform-configurations"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>DeepHyper Platform Configurations</h1>

    <p>This repository provides a set of configuration files and example scripts for
    running DeepHyper experiments on various platforms.</p>

    <p>The <code>generic</code> subdirectory contains a minimal DeepHyper environment
    example that can be used as a starting point for systems for which there is no
    existing recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which DeepHyper packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <div class="highlight highlight-source-shell"><pre>git clone -c feature.manyFiles=true
    https://github.com/spack/spack.git

    <span class="pl-c1">.</span> spack/share/spack/setup-env.sh</pre></div>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>deephyper-spack-packages</code>, which contains
    the DeepHyper packages.</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-spack-packages.git

    spack repo add deephyper-spack-packages</pre></div>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <div class="highlight highlight-source-shell"><pre>git clone https://github.com/deephyper/deephyper-platform-configurations.git

    <span class="pl-c1">cd</span> deephyper-platform-configurations/ANL/Polaris</pre></div>

    <p>Edit the path to <code>deephyper-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <div class="highlight highlight-source-shell"><pre>spack env create myenv spack.yaml</pre></div>

    <p>Change to a directory outside of the <code>deephyper-platform-configurations</code>
    folders

    and activate the environment as follows.</p>

    <div class="highlight highlight-source-shell"><pre>spack env activate myenv</pre></div>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <div class="highlight highlight-source-shell"><pre>spack install</pre></div>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-acknowledgment" class="anchor" aria-hidden="true" href="#acknowledgment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgment</h2>

    <p>This repository was created by following the example of the <a href="https://github.com/mochi-hpc-experiments/platform-configurations">Mochi
    Project</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1675421226.0
eflows4hpc/workflow-registry:
  data_format: 2
  description: Registry to store workflow descriptions
  filenames:
  - Pillar_II/esm/spack.yaml
  - minimal_workflow/wordcount/spack.yaml
  - rom_pillar_I/reduce_order_model/spack.yaml
  full_name: eflows4hpc/workflow-registry
  latest_release: 2nd_stack_release
  readme: "<h1><a id=\"user-content-workflow-registry\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#workflow-registry\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Workflow Registry</h1>\n<p>This is a repository to\
    \ store the Workflow descriptions using the eFlows4HPC methodology. This description\
    \ consist of at least the TOSCA description of the worklfow, the code of the their\
    \ different steps and their required software per step.</p>\n<h2><a id=\"user-content-repository-structure\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#repository-structure\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Repository structure</h2>\n<p>Workflow\
    \ descriptions have to be included inside this repository according to the following\
    \ structure.</p>\n<pre><code>workflow-registry\n  |- workflow_1\n  |    |- tosca\n\
    \  |    |    |- types.yml               TOSCA description of the different components\
    \ involved in the workflow\n  |    |       ... \n  |    |- step_1\n  |    |  \
    \  |- spack.yml               Sofware requirements for this workflow step as a\
    \ Spack environment specification \n  |    |    |- src                     PyCOMPSs\
    \ code of the workflow step\n  |    |       ...\n  |    |- step_2\n  |       \
    \  ....\n  |- workflow_2                                \n  |\t...\n\n</code></pre>\n\
    <h2><a id=\"user-content-including-new-workflows\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#including-new-workflows\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Including new Workflows</h2>\n<p>To include new workflows\
    \ in the repository, first create a new fork of the repository and  include a\
    \ new folder for the workflow with a subfolder for the TOSCA description and the\
    \ different workflow steps. Finally, create a pull request with the new workflow\
    \ description. This pull request will be reviewed and included in the repository.</p>\n"
  stargazers_count: 2
  subscribers_count: 8
  topics: []
  updated_at: 1675113861.0
epfl-radio-astro/ska-spack-env:
  data_format: 2
  description: SKA Spack environments related files
  filenames:
  - bipp-jed-gcc/spack.yaml
  - env-bipp-izar/spack.yaml
  - bipp-izar-gcc/spack.yaml
  full_name: epfl-radio-astro/ska-spack-env
  latest_release: null
  readme: '<h1><a id="user-content-ska-spack-env" class="anchor" aria-hidden="true"
    href="#ska-spack-env"><span aria-hidden="true" class="octicon octicon-link"></span></a>ska-spack-env</h1>

    <p>SKA Spack environments related files</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674857920.0
esm-tools/esm_tools:
  data_format: 2
  description: Simple Infrastructure for Earth System Simulations
  filenames:
  - configs/spack_envs/albedo-spack.yaml
  full_name: esm-tools/esm_tools
  latest_release: v6.0.0
  stargazers_count: 20
  subscribers_count: 9
  topics: []
  updated_at: 1671059683.0
eth-cscs/spack-batteries-included:
  data_format: 2
  description: Installing spack without system dependencies
  filenames:
  - build/6_spack/spack.yaml
  full_name: eth-cscs/spack-batteries-included
  latest_release: develop
  readme: "<p><a href=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml\"\
    ><img src=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\"\
    \ alt=\"Update spack develop version\" style=\"max-width: 100%;\"></a></p>\n<h1><a\
    \ id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#-spack-with-batteries-included-linuxx86_64\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><g-emoji class=\"\
    g-emoji\" alias=\"battery\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png\"\
    >\U0001F50B</g-emoji> Spack with batteries included (linux/x86_64)</h1>\n<p><a\
    \ href=\"https://github.com/spack/spack\">Spack</a> is a package manager, and\
    \ package managers should be trivial to install.</p>\n<p>This repo offers a single,\
    \ static executable for Spack:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">wget -qO spack.x https://github.com/eth-cscs/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n\
    $ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x\
    \ install curl tls=mbedtls</span></pre></div>\n<h2><a id=\"user-content-what-version-of-spack-is-shipped\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#what-version-of-spack-is-shipped\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What version\
    \ of Spack is shipped?</h2>\n<p>The URL above gives you a rolling release of Spack's\
    \ develop branch, which is updated\nhourly. The exact commit SHA is included as\
    \ a file and can be retrieved like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"\
    pl-k\">&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints\
    \ the Spack commit sha]</span></pre></div>\n<h2><a id=\"user-content-supported-platforms\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#supported-platforms\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Supported platforms</h2>\n<ul>\n\
    <li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n<li>Debian 8 and\
    \ above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and above</li>\n\
    <li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for Linux 2 with any\
    \ of the above distro's.</li>\n</ul>\n<p>The system dependencies are <code>glibc\
    \ 2.17</code> and above and optionally the <code>fusermount</code>\nexecutable.\
    \ If your system supports rootless containers it likely has <code>fusermount</code>\n\
    installed already!</p>\n<h2><a id=\"user-content-how-does-it-work\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#how-does-it-work\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>How does it work?</h2>\n<p><code>spack.x</code>\
    \ consists of a modified version of the AppImage runtime concatenated\nwith a\
    \ big squashfs file which includes <code>binutils</code>, <code>bzip2</code>,\
    \ <code>clingo</code>, <code>curl</code>,\n<code>file</code>, <code>git</code>,\
    \ <code>gmake</code>, <code>gpg</code>, <code>gzip</code>, <code>openssl</code>,\
    \ <code>patch</code>, <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>,\
    \ <code>tar</code>, <code>unzip</code>, <code>xz</code>, <code>zstd</code> and\
    \ their dependencies.</p>\n<p>When you run <code>spack.x [args]</code> it will\
    \ use <code>fusermount</code> to\nmount this squashfs file in a temporary directory,\
    \ and then execute the\nentrypoint executable <a href=\"build/6_spack/spack\"\
    >spack</a>.</p>\n<p>The <code>spack</code> executable sets some environment variables\
    \ like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code> to the bin and lib\
    \ folders of the squashfs file, and then it\nexecutes <code>python3 spack_src/bin/spack\
    \ [args]</code>.</p>\n<p>When the command is done running, the runtime unmounts\
    \ the squashfs file again.</p>\n<h2><a id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>My system\
    \ doesn't allow me to use <code>fusermount</code>, what now?</h2>\n<p><code>fusermount</code>\
    \ is used to mount a squashfs file included in the binary. If you\ndon't want\
    \ that, you can just extract it:</p>\n<pre><code>$ spack.x --squashfs-extract\n\
    $ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\
    </code></pre>\n<p>but working with the extracted <code>spack</code> folder can\
    \ come with a performance\npenalty on shared filesystems in HPC centers.</p>\n\
    <h2><a id=\"user-content-differences-and-improvements-over-appimage-runtime\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#differences-and-improvements-over-appimage-runtime\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Differences\
    \ and improvements over AppImage runtime</h2>\n<ul>\n<li>spack.x uses <code>zstd</code>\
    \ for faster decompression;</li>\n<li>spack.x itself is an entirely static binary;</li>\n\
    <li>spack.x does not need to dlopen libfuse.so.</li>\n</ul>\n<h2><a id=\"user-content-troubleshooting\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#troubleshooting\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Troubleshooting</h2>\n<p><strong>immutability</strong>\
    \ The squashfs mountpoint is a readonly folder, meaning that\nspack can't write\
    \ to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard\
    \ directories, see <code>spack.x config blame config</code> for details.</p>\n\
    <p>Note, spack.x applies <a href=\"https://github.com/spack/spack/pull/20158/\"\
    >this patch</a>\nto ensure that log files are written to the <code>config:misc_cache</code>\
    \ folder.</p>\n<p><strong>openssl</strong>: By default spack.x uses <code>ca-certificates-mozilla</code>\
    \ for downloading\npackage sources over https. If you somehow need to use system\
    \ certificates,\nset <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAINFO</code>\
    \ or <code>SSL_CERT_FILE</code> and <code>GIT_SSL_CERT</code>.</p>\n<h2><a id=\"\
    user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#can-i-run-spackx-inside-a-container\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Can I run spack.x inside a container?</h2>\n\
    <p>Yes, but please don't! Since <code>fusermount</code> is a setuid binary, you\
    \ will need to\nrun a privileged container, which is never a good idea.</p>\n\
    <p>The recommended way to run spack.x inside a container is to just extract it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >spack.x --squashfs-extract</span>\n$ <span class=\"pl-s1\">./spack/spack --version</span></pre></div>\n\
    <p>If you insist on running spack.x in Docker, this is one way to do it:</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"\
    >sudo docker run --privileged --device /dev/fuse -it -v <span class=\"pl-smi\"\
    >$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n# <span class=\"pl-s1\"\
    >apt update <span class=\"pl-k\">&amp;&amp;</span> apt install fuse <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n# <span\
    \ class=\"pl-s1\">spack.x --version</span></pre></div>\n<h2><a id=\"user-content-running-an-executable-shipped-with-spackx-directly\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-an-executable-shipped-with-spackx-directly\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ an executable shipped with spack.x directly</h2>\n<p>If you want to run an executable\
    \ shipped with <code>spack.x</code> directly instead\nof invoking spack (the default\
    \ entrypoint), try this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x which python</span>\n<span\
    \ class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n\
    <hr>\n<h2><a id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#how-do-i-build-spackx-myself\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How do I build spack.x myself?</h2>\n\
    <p>Initially you may need docker to get a rootfs filesystem for centos 7.</p>\n\
    <p>Building goes like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-c1\">make rootfs-with-spack</span>\n<span class=\"pl-c1\"\
    >make</span></pre></div>\n<p>You'll find the output in</p>\n<pre><code>build/output\n\
    </code></pre>\n"
  stargazers_count: 23
  subscribers_count: 2
  topics:
  - spack
  - squashfs
  - libfuse
  updated_at: 1677258315.0
eugeneswalker/noaa:
  data_format: 2
  description: null
  filenames:
  - oneapi/spack.yaml
  - gnu/failures/spack.yaml
  - clang/spack.yaml
  - clang/failures/spack.yaml
  - nvhpc/failures/spack.yaml
  - oneapi/failures/spack.yaml
  - nvhpc/spack.yaml
  - gnu/spack.yaml
  full_name: eugeneswalker/noaa
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675202595.0
eugeneswalker/pantheon-containers:
  data_format: 2
  description: Pantheon Container Recipes
  filenames:
  - spack_env/spack.yaml
  full_name: eugeneswalker/pantheon-containers
  latest_release: null
  readme: '<h1><a id="user-content-pantheon-base" class="anchor" aria-hidden="true"
    href="#pantheon-base"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pantheon-base</h1>

    <p>In order to build this image, execute the <code>./build.sh</code> script.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1606954524.0
eugeneswalker/qmcpack-ci-container:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  - docker-images/spack.yaml
  full_name: eugeneswalker/qmcpack-ci-container
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678143972.0
felixthieme/2020_ASPECT_IGG:
  data_format: 2
  description: null
  filenames:
  - contrib/spack/spack.yaml
  full_name: felixthieme/2020_ASPECT_IGG
  latest_release: null
  readme: "<p>(Cloned from ASPECT by Felix Thieme (Idaho Geodynamics Group) on 5/27/2020)</p>\n\
    <h1><a id=\"user-content-aspect---advanced-solver-for-problems-in-earths-convection\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#aspect---advanced-solver-for-problems-in-earths-convection\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ASPECT -\
    \ Advanced Solver for Problems in Earth's ConvecTion</h1>\n<p><a href=\"https://github.com/geodynamics/aspect/blob/master/LICENSE\"\
    ><img src=\"https://camo.githubusercontent.com/6bdbfedce993ff7baeecb8c93e87eeebe79d7ae3d19002c54f87e301ec0e7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6372616e2f6c2f646576746f6f6c732e737667\"\
    \ alt=\"License GPL2:\" data-canonical-src=\"https://img.shields.io/cran/l/devtools.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.2653531\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/91da28a81e083b7f3b47a26fd70f2dfcf0a87a9306f2b6f0d457a65ebe089752/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e323635333533312e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.2653531.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.6084/m9.figshare.4865333\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7f17ee0a3d31869d37f8d1b1f43540d6fb99d9a8c72bcf879977682693cbe1a7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6765742d5044462d677265656e2e737667\"\
    \ alt=\"pdf manual\" data-canonical-src=\"https://img.shields.io/badge/get-PDF-green.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-about\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#about\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>About</h2>\n<p>ASPECT is a code to simulate\
    \ convection in Earth's mantle and elsewhere.\nIt has grown from a pure mantle-convection\
    \ code into a tool for many\ngeodynamic applications including applications for\
    \ inner core convection,\nlithospheric scale deformation, two-phase flow, and\
    \ numerical methods development.\nThe project is supported by CIG (<a href=\"\
    http://geodynamics.org\" rel=\"nofollow\">http://geodynamics.org</a>).</p>\n<h2><a\
    \ id=\"user-content-installation-instructions\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#installation-instructions\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Installation instructions</h2>\n<p>The steps\
    \ to install the necessary dependencies and ASPECT itself are described\nin the\
    \ Installation instructions section of the ASPECT\n<a href=\"http://www.math.clemson.edu/~heister/manual.pdf\"\
    \ rel=\"nofollow\">manual</a>. If you encounter\nproblems during the installation,\
    \ please consult our\n<a href=\"https://github.com/geodynamics/aspect/wiki\">wiki</a>\
    \ for typical installation\nproblems or specific instructions for MacOS users,\
    \ before asking your question\non the mailing list.</p>\n<h2><a id=\"user-content-running-and-extending-aspect\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-and-extending-aspect\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running\
    \ and extending ASPECT</h2>\n<p>Instructions on how to run and extend, as well\
    \ as on how to interpret the\noutput of ASPECT can also be found in the ASPECT\n\
    <a href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\">manual</a>.\
    \ This manual also\ndiscusses the structure of the source code.</p>\n<p>For getting\
    \ started, you can also watch our online\n<a href=\"https://geodynamics.org/cig/events/calendar/2016-cig-all-hands-meeting/aspect-tutorial/tutorial/\"\
    \ rel=\"nofollow\">tutorial</a>.</p>\n<h2><a id=\"user-content-contributing-to-aspect\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing-to-aspect\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ to ASPECT</h2>\n<p>ASPECT is a community project that lives by the participation\
    \ of its\nmembers \u2014 i.e., including you! It is our goal to build an inclusive\n\
    and participatory community so we are happy that you are interested in\nparticipating!\
    \ We have collected a set of guidelines and advice on how\nto get involved in\
    \ the community and keep them in the\n<a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a>\n\
    file in ASPECT's repository.</p>\n<h2><a id=\"user-content-more-information\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#more-information\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>More information</h2>\n<p>For\
    \ more information see:</p>\n<ul>\n<li>\n<p>The official website at <a href=\"\
    https://aspect.geodynamics.org\" rel=\"nofollow\">https://aspect.geodynamics.org</a></p>\n\
    </li>\n<li>\n<p>The current <a href=\"http://www.math.clemson.edu/~heister/manual.pdf\"\
    \ rel=\"nofollow\">manual</a></p>\n</li>\n<li>\n<p><a href=\"https://aspect.geodynamics.org/cite.html\"\
    \ rel=\"nofollow\">How to cite ASPECT</a></p>\n</li>\n<li>\n<p>For questions on\
    \ the source code of ASPECT, portability, installation, new or existing features,\
    \ etc., use the <a href=\"https://community.geodynamics.org/c/aspect\" rel=\"\
    nofollow\">ASPECT forum</a>. This forum is where the ASPECT users and developers\
    \ all hang out. Archived discussions from the inactive aspect-devel mailing list\
    \ can be downloaded at <a href=\"http://lists.geodynamics.org/pipermail/aspect-devel\"\
    \ rel=\"nofollow\">aspect-devel archives</a>.</p>\n</li>\n<li>\n<p>ASPECT is primarily\
    \ based on the deal.II library. If you have particular questions about deal.II,\
    \ contact the <a href=\"https://www.dealii.org/mail.html\" rel=\"nofollow\">deal.II\
    \ discussion groups</a>.</p>\n</li>\n<li>\n<p>In case of more general questions\
    \ about mantle convection, you can contact the <a href=\"http://lists.geodynamics.org/cgi-bin/mailman/listinfo/cig-MC\"\
    \ rel=\"nofollow\">CIG mantle convection mailing lists</a>.</p>\n</li>\n<li>\n\
    <p>ASPECT is being developed by a large, collaborative, and inclusive community.\
    \ It is currently maintained by the following people:</p>\n<ul>\n<li>Wolfgang\
    \ Bangerth: <a href=\"mailto:bangerth@math.colostate.edu\">bangerth@math.colostate.edu</a>\n\
    </li>\n<li>Juliane Dannberg: <a href=\"mailto:judannberg@gmail.com\">judannberg@gmail.com</a>\n\
    </li>\n<li>Rene Gassmoeller: <a href=\"mailto:rene.gassmoeller@mailbox.org\">rene.gassmoeller@mailbox.org</a>\n\
    </li>\n<li>Timo Heister: <a href=\"mailto:heister@clemson.edu\">heister@clemson.edu</a>\n\
    </li>\n</ul>\n</li>\n<li>\n<p>The following people have significantly contributed\
    \ and furthered ASPECT's goals and are therefore Principal Developers:</p>\n<ul>\n\
    <li>Jacky Austermann</li>\n<li>Wolfgang Bangerth</li>\n<li>Juliane Dannberg</li>\n\
    <li>Menno Fraters</li>\n<li>Rene Gassmoeller</li>\n<li>Anne Glerum</li>\n<li>Timo\
    \ Heister</li>\n<li>John Naliboff</li>\n</ul>\n</li>\n<li>\n<p>A complete and\
    \ growing list of the many authors that have contributed over the years can be\
    \ found at <a href=\"https://github.com/geodynamics/aspect/graphs/contributors\"\
    >github</a></p>\n</li>\n<li>\n<p>If you have specific questions about ASPECT that\
    \ are not suitable for public and archived mailing lists, feel free to contact\
    \ the maintainers or principal developers.</p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>ASPECT is published\
    \ under <a href=\"LICENSE\">GPL v2 or newer</a>.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1590610476.0
floquet/builds:
  data_format: 2
  description: Notes and scripts for building applications on HPCs
  filenames:
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-01-31_21,26/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/Macmini8,1-(xiuhcoatl)/linux/amzn-2.0.20220316.0/amzn-2.0.20220316.0-dantopa-docker-spack/2022-04-07_21,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-amzn2-haswell/Macmini8,1-(xiuhcoatl)/linux/amazonlinux-2/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-07_16,22/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/linux-ubuntu22.04-haswell/MacBookPro16,1-(ehecoatl)/linux/ubuntu-22.04/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/darwin-monterey-skylake/Macmini8,1 (xiuhcoatl)/darwin 21.2.0/Monterey-12.1/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-01-31_21,28/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-03-04_09,42/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(quaxolotl)/darwin 21.2.0/Monterey-12.1/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-tlaloc-spack/2022-03-07_16,30/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/Macmini8,1 (xiuhcoatl)/darwin 21.2.0/Monterey-12.1/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-03_10,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(quaxolotl)/darwin 21.2.0/Monterey-12.1/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-03_10,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.2.0/Monterey-12.1/ehecoatl-internal-spack/2022-02-19_22,36/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_07,27/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_07,27/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-01-31_21,26/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-07_16,22/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/amzn-2022/amzn-2022-dantopa-docker-spack/2022-03-08_16,11/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/dantopa/2022-04-20_09,09/yamls/spacktivity/mageia-8-dantopa-docker-spack/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_09,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-SpWx-docker-spack/2022-01-17_21,00/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_09,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-amzn2-haswell/Macmini8,1-(xiuhcoatl)/linux/amazonlinux-2/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(quaxolotl)/darwin 21.2.0/Monterey-12.1/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-SpWx-docker-spack/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/MagneticFields/2022-03-03_20,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/dantopa/2022-04-20_09,09/yamls/spacktivity/mageia-8-dantopa-docker-spack/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-07_16,22/yamls/share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-SpWx-docker-spack/2022-01-17_21,00/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-01-31_21,28/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/shell-scripts/2022-02-19_21,55/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-SpWx-docker-spack/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/reaper/2022-01-19_18,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/Macmini8,1 (xiuhcoatl)/darwin 21.2.0/Monterey-12.1/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/darwin-monterey-skylake/MacBookPro16,1-(ehecoatl)/darwin-21.3.0/Monterey-12.2.1/ehecoatl-internal-spack/2022-03-07_16,29/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/dantopa/2022-04-20_09,09/yamls/spacktivity/mageia-8-dantopa-docker-spack/share/spack/gitlab/cloud_pipelines/stacks/e4s-mac/spack.yaml
  - results-spack/linux-amzn2-haswell/Macmini8,1-(xiuhcoatl)/linux/amazonlinux-2/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_09,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-SpWx-docker-spack/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/Macmini8,1-(xiuhcoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-03-03_10,10/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(quaxolotl)/linux/centos-7.9.2009/centos-7.9.2009-SpWx-docker-spack/2022-01-17_21,00/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/reaper/2022-02-17_14,48/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  - results-spack/echo/MacBookPro16,1-(quaxolotl)/darwin-21.4.0/Monterey-12.3/spack-quaxolotl-darwin/2022-04-26_17,02/yamls/share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml
  - results-spack/echo/MacBookPro16,1-(ehecoatl)/linux/debian-bookworm/mageia-8-dantopa-docker-spack/2022-04-20_07,27/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/reaper/2022-02-17_14,48/yamls/share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml
  - results-spack/linux-centos7-haswell/MacBookPro16,1-(ehecoatl)/linux/centos-7.9.2009/centos-7.9.2009-dantopa-docker-spack/2022-02-02_18,34/yamls/share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml
  full_name: floquet/builds
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1641760136.0
flux-framework/flux-research-artifacts:
  data_format: 2
  description: Collection of Research Artifacts from Papers Involving Flux
  filenames:
  - 2021-IJHPCA/spack-env/spack.yaml
  full_name: flux-framework/flux-research-artifacts
  latest_release: v0.2
  readme: '<h1><a id="user-content-flux-research-artifacts" class="anchor" aria-hidden="true"
    href="#flux-research-artifacts"><span aria-hidden="true" class="octicon octicon-link"></span></a>flux-research-artifacts</h1>

    <p>Collection of Research Artifacts from Papers Involving Flux</p>

    '
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1628308190.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - ubuntu-gcc/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1><a id="user-content-synergia2-containers" class="anchor" aria-hidden="true"
    href="#synergia2-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1678463172.0
frankwillmore/alcf-stacks:
  data_format: 2
  description: null
  filenames:
  - openmpi-all-tgpu/spack.yaml
  full_name: frankwillmore/alcf-stacks
  latest_release: null
  readme: '<p>These are environments, to build on top of base layers as

    enumerated in:</p>

    <p><a href="http://github.com/frankwillmore/derkommissar">http://github.com/frankwillmore/derkommissar</a></p>

    '
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1626474269.0
frankwillmore/deployment:
  data_format: 2
  description: null
  filenames:
  - arcticus/e4s-21.05/spack.yaml
  full_name: frankwillmore/deployment
  latest_release: null
  readme: '<h1><a id="user-content-deployment" class="anchor" aria-hidden="true" href="#deployment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>deployment</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1628112357.0
frankwillmore/derkommissar:
  data_format: 2
  description: null
  filenames:
  - jlse/spack.yaml
  full_name: frankwillmore/derkommissar
  latest_release: null
  readme: '<h1><a id="user-content-der-kommissar" class="anchor" aria-hidden="true"
    href="#der-kommissar"><span aria-hidden="true" class="octicon octicon-link"></span></a>Der
    Kommissar</h1>

    <p><i>Kommissar - a representative of the supreme authority in an area.</i></p>

    <p>Der Kommissar is a spack environment (or set of known good environments) which
    will provide a set of packages, typically provided via the OS package manager,
    but built using spack with ''together'' concretization and intended for consumption
    by spack as a localization platform on which to build a dependent environment
    (e.g. e4s) for a target system.</p>

    <p>Building this environment generates the packages in the versions needed, and
    the script provided  will generate a packages.yaml formatted file, to be included
    in downstream environments.</p>

    <p>None of the packages contained herein should be built when the dependent environment
    is built. Furthermore, this environment should be built only with GCC, and at
    the GCC version level of the compiler used to build the dependent environment.
    In some cases, it may be possible to build these packages with llvm compilers
    instead of gcc compilers, but that is up to the discretion of the deployer.</p>

    <p>Standardizing on the set of packages and concretizing together insures that
    they are as compatible as possible with one another, and also reduces the number
    of redundant (and sometimes failing) builds.</p>

    <p>For LMOD installations, these packages are built with and made available through
    the Core compiler.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1627944419.0
frankwillmore/e4s-21.08-isolated-settings:
  data_format: 2
  description: null
  filenames:
  - prod/spack.yaml
  - _spack.yaml
  - spack.yaml
  full_name: frankwillmore/e4s-21.08-isolated-settings
  latest_release: null
  readme: '<h1><a id="user-content-e4s-2105" class="anchor" aria-hidden="true" href="#e4s-2105"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>e4s 21.05</h1>

    <p>The e4s 21.05 stack is based on <a href="https://github.com/E4S-Project/e4s">E4S-Project/e4s</a>
    using <a href="https://github.com/E4S-Project/e4s/blob/v21.05/spack.yaml">spack.yaml</a>
    provided in the 21.05 tag release which is tuned for Arcticus nodes in the ANL
    JLSE. Shown below are the relevant files:</p>

    <ul>

    <li>[spack.yaml]: The spack.yaml in top-level folder is used for building E4S
    to populate the buildcache in the named mirror.</li>

    <li>[prod/spack.yaml]: This is the spack.yaml used for deployment of E4S from
    the generated buildcache to the desired location.</li>

    <li>[.gitlab-ci.yml]: Gitlab CI file to automate deployment using Gitlab</li>

    <li>[site_config]: spack configuration at <em>site</em> scope that overrides default.
    This helps ensure user can get necessary defaults when they use this spack instance</li>

    </ul>

    <h2><a id="user-content-project-variables" class="anchor" aria-hidden="true" href="#project-variables"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Project Variables</h2>

    <p>The following variables are defined for consumption by the Gitlab project which
    used to install and populate the buildcache, and can be used to alter the behavior
    of the CI job.</p>

    <ul>

    <li>

    <code>BUILD_E4S</code>: Used for building E4S stack and pushing to buildcache.
    <code>Default: True</code>

    </li>

    <li>

    <code>DEPLOY_E4S</code>: Used for running the deployment job (<code>Default: False</code>)</li>

    <li>

    <code>REMOVE_BUILDCACHE</code>: Used for removing the buildcache directory in
    order to rebuild E4S from source. <code>Default: False</code>

    </li>

    <li>

    <code>SPACK_CDASH_AUTH_TOKEN</code>: Token used for pushing spack builds to <a
    href="https://cdash.spack.io" rel="nofollow">https://cdash.spack.io</a>

    </li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1636391708.0
giltirn/mochi-margo:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: giltirn/mochi-margo
  latest_release: null
  readme: "<h1><a id=\"user-content-margo\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#margo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    ><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\"\
    \ alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings\
    \ to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\"\
    \ rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\n\
    library optimized for use in HPC environments.  Its native API presents a\ncallback-oriented\
    \ interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\"\
    \ rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n\
    <p>Margo combines Mercury and Argobots to simplify development of distributed\n\
    services.  Mercury operations are presented as conventional blocking\noperations,\
    \ and RPC handlers are presented as sequential threads.  This\nconfiguration enables\
    \ high degree of concurrency while hiding the\ncomplexity associated with asynchronous\
    \ communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends\
    \ callers after issuing a Mercury operation, and\nautomatically resumes them when\
    \ the operation completes.  This allows\nother concurrent user-level threads to\
    \ make progress while Mercury\noperations are in flight without consuming operating\
    \ system threads.\nThe goal of this design is to combine the performance advantages\
    \ of\nMercury's native event-driven execution model with the progamming\nsimplicity\
    \ of a multi-threaded execution model.</p>\n<p>A companion library called abt-io\
    \ provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\"\
    >https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should\
    \ be compatible with any Mercury network\ntransport (NA plugin).  The documentation\
    \ assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury\
    \ for\nsimplicity.  This plugin is only valid for communication between\nprocesses\
    \ on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\"\
    >Using Margo with other Mercury NA\nplugins</a> for information\non other configuration\
    \ options.</p>\n<h2><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing\
    \ the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"\
    nofollow\">https://spack.io/</a>).</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury\
    \  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\"\
    >https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone\
    \ <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n\
    </ul>\n<h3><a id=\"user-content-recommended-mercury-build-options\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#recommended-mercury-build-options\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury build options</h3>\n\
    <ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable\
    \ the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should be compiled\
    \ with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path\
    \ for cases in which a Mercury service is linked into the same\nexecutable as\
    \ the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir\
    \ build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON\
    \ -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install\
    \ \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n\
    <h2><a id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #building\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n\
    <p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install\
    \ \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"\
    -g -Wall\"\n</code></pre>\n<h2><a id=\"user-content-running-examples\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#running-examples\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The\
    \ examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example\
    \ client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]:\
    \ an example RPC definition</li>\n</ul>\n<p>The following example shows how to\
    \ execute them.  Note that when the server starts it will display the address\
    \ that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server\
    \ na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with\
    \ input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val:\
    \ 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client\
    \ na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3]\
    \ running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\n\
    Got response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n\
    <p>The client will issue 4 concurrent RPCs to the server and wait for them to\n\
    complete.</p>\n<h2><a id=\"user-content-running-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#running-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running tests</h2>\n<p><code>make check</code></p>\n<h2><a id=\"user-content-using-margo-with-the-other-na-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-margo-with-the-other-na-plugins\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Margo\
    \ with the other NA plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\"\
    \ rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible\
    \ with any Mercury transport and uses the same address\nformat.</p>\n<h2><a id=\"\
    user-content-instrumentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#instrumentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Instrumentation</h2>\n\
    <p>See the <a href=\"doc/instrumentation.md\">Instrumentation documentation</a>\
    \ for\ninformation on how to extract diagnostic instrumentation from Margo.</p>\n\
    <h2><a id=\"user-content-debugging\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #debugging\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Debugging</h2>\n\
    <p>See the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo\
    \ debugging\nfeatures and strategies.</p>\n<h2><a id=\"user-content-design-details\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#design-details\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Design details</h2>\n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer\" href=\"doc/fig/margo-diagram.png\"><img src=\"\
    doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width: 100%;\"\
    ></a></p>\n<p>Margo provides Argobots-aware wrappers to common Mercury library\
    \ functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The\
    \ wrappers\nhave the same arguments as their native Mercury counterparts except\
    \ that no\ncallback function is specified.  Each function blocks until the operation\n\
    is complete.  The above diagram illustrates a typical control flow.</p>\n<p>Margo\
    \ launches a long-running user-level thread internally to drive\nprogress on Mercury\
    \ and execute Mercury callback functions (labeled\n<code>__margo_progress()</code>\
    \ above).  This thread can be assigned to a\ndedicated Argobots execution stream\
    \ (i.e., an operating system thread)\nto drive network progress with a dedicated\
    \ core.  Otherwise it will be\nautomatically scheduled when the caller's execution\
    \ stream is blocked\nwaiting for network events as shown in the above diagram.</p>\n\
    <p>Argobots eventual constructs are used to suspend and resume user-level\nthreads\
    \ while Mercury operations are in flight.</p>\n<p>Margo allows several different\
    \ threading/multicore configurations:</p>\n<ul>\n<li>The progress loop can run\
    \ on a dedicated operating system thread or not</li>\n<li>Multiple Margo instances\
    \ (and thus progress loops) can be\nexecuted on different operating system threads</li>\n\
    <li>(for servers) a single Margo instance can launch RPC handlers\non different\
    \ operating system threads</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1654705049.0
giordano/julia-on-fugaku:
  data_format: 2
  description: null
  filenames:
  - benchmarks/blas-axpy/spack-env/spack.yaml
  full_name: giordano/julia-on-fugaku
  latest_release: null
  readme: "<h1><a id=\"user-content-julia-on-fugaku-2022-07-23\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#julia-on-fugaku-2022-07-23\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Julia on Fugaku (2022-07-23)</h1>\n\
    <p><em>Note: many links refer to internal documentation which is accessible only\
    \ to Fugaku users.</em></p>\n<h2><a id=\"user-content-read-the-paper\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#read-the-paper\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Read the paper</h2>\n<p>Benchmarks\
    \ present in this repository have been published in the paper <a href=\"https://doi.org/10.1109/CLUSTER51413.2022.00072\"\
    \ rel=\"nofollow\">Productivity meets\nPerformance: Julia on A64FX</a>, presented\
    \ at\nthe 2022 IEEE International Conference on Cluster Computing (CLUSTER22),\
    \ as part of the\n<a href=\"https://arm-hpc-user-group.github.io/eahpc-2022/\"\
    \ rel=\"nofollow\">Embracing Arm for High Performance Computing\nWorkshop</a>\
    \ (pre-print available on arXiv:\n<a href=\"https://arxiv.org/abs/2207.12762\"\
    \ rel=\"nofollow\"><code>2207.12762</code></a>).  See the <a href=\"./CITATION.bib\"\
    ><code>CITATION.bib</code></a>\nfile for a BibTeX entry to cite the paper.</p>\n\
    <h2><a id=\"user-content-storage\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #storage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Storage</h2>\n\
    <p>Before doing anything on Fugaku, be aware that there are <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20220408_01\"\
    \ rel=\"nofollow\">tight\nlimits</a> on the size of (20 GiB)\nand the number of\
    \ inodes in (200k) your home directory.  If you use many Julia Pkg\nartifacts,\
    \ it's very likely you'll hit these limits.  You'll notice that you hit the limit\n\
    because any disk I/O operation will result in a <code>Disk quota exceeded</code>\
    \ error like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-e\">[user@fn01sv03 ~]</span>$ <span class=\"pl-s1\">touch\
    \ foo</span>\n<span class=\"pl-c1\">touch: cannot touch 'foo': Disk quota exceeded</span></pre></div>\n\
    <p>You can check the quota of your home directory with <code>accountd</code> for\
    \ the size, and <code>accountd -i</code> for the number of inodes.</p>\n<h3><a\
    \ id=\"user-content-using-the-data-directory\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#using-the-data-directory\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Using the data directory</h3>\n<p>In order to\
    \ avoid clogging up the home directory you may want to move the Julia depot to\
    \ the\ndata directory:</p>\n<div class=\"highlight highlight-source-shell\"><pre>DATADIR=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/data/&lt;YOUR GROUP&gt;/<span\
    \ class=\"pl-smi\">${USER}</span><span class=\"pl-pds\">\"</span></span>\n<span\
    \ class=\"pl-k\">export</span> JULIA_DEPOT_PATH=<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span><span class=\"pl-smi\">${DATADIR}</span>/julia-depot<span class=\"\
    pl-pds\">\"</span></span></pre></div>\n<h2><a id=\"user-content-interactive-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#interactive-usage\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Interactive usage</h2>\n<p>The\
    \ login nodes you access via <code>login.fugaku.r-ccs.riken.jp</code> (<a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/AccessToTheSystem/LoggingInToTheFugakuComputerWithLocalAccount.html\"\
    \ rel=\"nofollow\">connection\ninstructions</a>)\nhave Cascade Lake CPUs, so they\
    \ aren't much useful if you want to run an aarch64 Julia.</p>\n<p>You can <a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/Overview.html\"\
    \ rel=\"nofollow\">submit jobs to the\nqueue</a>\nto run Julia code on the A64FX\
    \ compute nodes, but this can be cumbersone if you need quick\nfeedback during\
    \ development or debugging.  You can also request an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/InteractiveJob.html\"\
    \ rel=\"nofollow\">interactive\nnode</a>,\nfor example with:</p>\n<pre><code>pjsub\
    \ --interact -L \"node=1\" -L \"rscgrp=int\" -L \"elapse=30:00\" --sparam \"wait-time=600\"\
    \ --mpi \"max-proc-per-node=4\"\n</code></pre>\n<h2><a id=\"user-content-available-software\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#available-software\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Available software</h2>\n<p>Fugaku\
    \ uses the <a href=\"https://spack.io/\" rel=\"nofollow\">Spack package manager</a>.\
    \  For more information about how\nto use it, see the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/FugakuSpackGuide/\"\
    \ rel=\"nofollow\">Fugaku Spack User\nGuide</a>.</p>\n<p>Note that Spack is installed\
    \ in <code>/vol0004</code>, this means that if your home directory isn't\nmounted\
    \ on this volume you will have to <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20211130_02\"\
    \ rel=\"nofollow\">explicitly request the\npartition</a> in your submission\n\
    job scripts or commands, for example by adding <code>-x PJM_LLIO_GFSCACHE=/vol0004</code>\
    \ to the\n<code>pjsub</code> command, or the line</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>PJM\
    \ -x PJM_LLIO_GFSCACHE=/vol0004</span></pre></div>\n<p>in a job script.</p>\n\
    <h2><a id=\"user-content-using-julia-on-the-compute-nodes\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#using-julia-on-the-compute-nodes\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Using Julia on the compute nodes</h2>\n<p>There\
    \ is a Julia module built with Spack <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/UsingOSS/oss_e.html#packages-installed-on-the-compute-nodes\"\
    \ rel=\"nofollow\">available on the compute\nnodes</a>,\nbut as of this writing\
    \ (2022-07-23) the version of Julia provided is 1.6.3, so you may want\nto download\
    \ a more recent version from the <a href=\"https://julialang.org/downloads/\"\
    \ rel=\"nofollow\">official\nwebsite</a>.  Use the <code>aarch64</code> builds\
    \ for Glibc Linux,\npreferably <a href=\"https://julialang.org/downloads/#current_stable_release\"\
    \ rel=\"nofollow\">latest stable</a> or even\nthe <a href=\"https://julialang.org/downloads/nightlies/\"\
    \ rel=\"nofollow\">nightly build</a> if you feel confident.</p>\n<p>To enable\
    \ full vectorisation you may need to set the environment variable\n<code>JULIA_LLVM_ARGS=\"\
    -aarch64-sve-vector-bits-min=512\"</code>.  Example:\n<a href=\"https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\"\
    >https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623</a>. \
    \ However, note that\nare a couple of severe bugs when using 512-bit vectors:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/JuliaLang/julia/issues/44401\">https://github.com/JuliaLang/julia/issues/44401</a>\
    \ (may be an upstream LLVM bug:\n<a href=\"https://github.com/llvm/llvm-project/issues/53331\"\
    >https://github.com/llvm/llvm-project/issues/53331</a>)</li>\n<li>\n<a href=\"\
    https://github.com/JuliaLang/julia/issues/44263\">https://github.com/JuliaLang/julia/issues/44263</a>\
    \ (only in Julia v1.8+)</li>\n</ul>\n<p><em><strong>Note</strong></em>: Julia\
    \ v1.9, which is based on <a href=\"https://community.arm.com/arm-community-blogs/b/tools-software-ides-blog/posts/llvm-14\"\
    \ rel=\"nofollow\">LLVM\n14</a>,\nis able to natively autovectorise code for A64FX\
    \ <em>without</em> having to set\n<code>JULIA_LLVM_ARGS</code>, side stepping\
    \ the issues above altogether.</p>\n<h2><a id=\"user-content-mpijl\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#mpijl\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>MPI.jl</h2>\n<p><a href=\"https://github.com/JuliaParallel/MPI.jl\"\
    ><code>MPI.jl</code></a> with default JLL-provided MPICH works\nout of the box!\
    \  In order to\n<a href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\"\
    \ rel=\"nofollow\">configure</a> <code>MPI.jl</code> v0.19 to\nuse system-provided\
    \ Fujitsu MPI (based on OpenMPI) you have to specify the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/CompileCommands.html\"\
    \ rel=\"nofollow\">MPI C\ncompiler</a>\nfor A64FX with</p>\n<pre><code>julia --project\
    \ -e 'ENV[\"JULIA_MPI_BINARY\"]=\"system\"; ENV[\"JULIA_MPICC\"]=\"mpifcc\"; using\
    \ Pkg; Pkg.build(\"MPI\"; verbose=true)'\n</code></pre>\n<p><em><strong>Note #1</strong></em>:\
    \ <code>mpifcc</code> is available only on the compute nodes.  On the login nodes\
    \ that would be\n<code>mpifccpx</code>, but this is the cross compiler running\
    \ on Intel architecture, it's unlikely\nyou'll run an <code>aarch64</code> Julia\
    \ on there.  <a href=\"https://github.com/JuliaParallel/MPI.jl/issues/539\">Preliminary\n\
    tests</a> show that <code>MPI.jl</code> should work\nmostly fine with Fujitsu\
    \ MPI, but custom error handlers may not be available (read: trying\nto use them\
    \ causes segmentation faults).</p>\n<p><em><strong>Note #2</strong></em>: in <code>MPI.jl</code>\
    \ v0.20 Fujitsu MPI is a known ABI (it's the same as OpenMPI) and\nthere is nothing\
    \ special to do to configure it apart from <a href=\"https://juliaparallel.org/MPI.jl/dev/configuration/#Configuration-2\"\
    \ rel=\"nofollow\">choosing the system\nbinaries</a>.</p>\n<p><em><strong>Note\
    \ #3</strong></em>: we recommend using <code>MPI.jl</code>'s wrapper of <code>mpiexec</code>\
    \ to run MPI applications\nwith Julia:\n<a href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Julia-wrapper-for-mpiexec\"\
    \ rel=\"nofollow\"><code>mpiexecjl</code></a>.</p>\n<h3><a id=\"user-content-file-system-latency\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#file-system-latency\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>File system latency</h3>\n<p>Fugaku\
    \ has an advanced system to handle <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/index.html\"\
    \ rel=\"nofollow\">parallel file system\nlatency</a>.\nIn order.  In order to\
    \ speed up parallel applications run through MPI you may want to\ndistribute it\
    \ to the cache area of the second-layer storage on the first-layer storage using\n\
    <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/TheSecondLayerStrage.html#common-file-distribution-function-llio-transfer\"\
    \ rel=\"nofollow\"><code>llio_transfer</code></a>.\nIn particular, if you're using\
    \ Julia, you likely want to distribute the <code>julia</code> executable\nitself\
    \ together with its installation bundle.</p>\n<p>For example, assuming that you\
    \ are using the official binaries from the website, instead of\nthe Julia module\
    \ provided by Spack, you can do the following:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Directory for log of\
    \ `llio_transfer` and its wrapper `dir_transfer`</span>\nLOGDIR=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${TMPDIR}</span>/log<span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Create the log directory if necessary</span>\nmkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Get directory where Julia is placed</span>\nJL_BUNDLE=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>dirname <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>julia --startup-file=no\
    \ -O0 --compile=min -e <span class=\"pl-s\"><span class=\"pl-pds\">'</span>print(Sys.BINDIR)<span\
    \ class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span><span\
    \ class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Move Julia installation to\
    \ fast LLIO directory</span>\n/home/system/tool/dir_transfer -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Do not write\
    \ empty stdout/stderr files for MPI processes.</span>\n<span class=\"pl-k\">export</span>\
    \ PLE_MPI_STD_EMPTYFILE=off\n\nmpiexecjl --project=. -np ... julia ...\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Remove Julia installation directory\
    \ from the cache.</span>\n/home/system/tool/dir_transfer -p -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span></pre></div>\n<h2><a id=\"user-content-reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reverse\
    \ engineering Fujitsu compiler using LLVM output</h2>\n<p>The Fujitsu compiler\
    \ has <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/C/modeTradAndClangC.html\"\
    \ rel=\"nofollow\">two operation\nmodes</a>:\n\"trad\" (for \"traditional\") and\
    \ \"clang\" (enabled by the flag <code>-Nclang</code>).  In clang mode it's\n\
    based on LLVM (version 7 at the moment).  This means you can get it to emit LLVM\
    \ IR with\n<code>-emit-llvm</code>.  For example, with</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\"\
    >echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>int main(){}<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> fcc -Nclang -x\
    \ c - -S -emit-llvm -o -</span></pre></div>\n<p>you get</p>\n<div class=\"highlight\
    \ highlight-source-llvm\"><pre><span class=\"pl-c\">; ModuleID = '-'</span>\n\
    source_filename = <span class=\"pl-s\">\"-\"</span>\n<span class=\"pl-k\">target</span>\
    \ <span class=\"pl-k\">datalayout</span> = <span class=\"pl-s\">\"e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128\"\
    </span>\n<span class=\"pl-k\">target</span> <span class=\"pl-k\">triple</span>\
    \ = <span class=\"pl-s\">\"aarch64-unknown-linux-gnu\"</span>\n\n<span class=\"\
    pl-c\">; Function Attrs: norecurse nounwind readnone uwtable</span>\n<span class=\"\
    pl-k\">define</span> dso_local <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">@main</span>() <span class=\"pl-k\">local_unnamed_addr</span> #<span class=\"\
    pl-c1\">0</span> <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!8</span>\
    \ {\n  <span class=\"pl-k\">ret</span> <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!11</span>\n\
    }\n\n<span class=\"pl-k\">attributes</span> #<span class=\"pl-c1\">0</span> =\
    \ { <span class=\"pl-k\">norecurse</span> <span class=\"pl-k\">nounwind</span>\
    \ <span class=\"pl-k\">readnone</span> <span class=\"pl-k\">uwtable</span> <span\
    \ class=\"pl-s\">\"correctly-rounded-divide-sqrt-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"disable-tail-calls\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"less-precise-fpmad\"\
    </span>=<span class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim\"\
    </span>=<span class=\"pl-s\">\"true\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim-non-leaf\"\
    </span> <span class=\"pl-s\">\"no-infs-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"no-jump-tables\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> <span class=\"pl-s\">\"no-nans-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-signed-zeros-fp-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-trapping-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"stack-protector-buffer-size\"\
    </span>=<span class=\"pl-s\">\"8\"</span> <span class=\"pl-s\">\"target-cpu\"\
    </span>=<span class=\"pl-s\">\"a64fx\"</span> <span class=\"pl-s\">\"target-features\"\
    </span>=<span class=\"pl-s\">\"+crc,+crypto,+fp-armv8,+lse,+neon,+ras,+rdm,+sve,+v8.2a\"\
    </span> <span class=\"pl-s\">\"unsafe-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"use-soft-float\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> }\n\n<span class=\"pl-v\">!llvm.dbg.cu</span> = !{<span class=\"\
    pl-v\">!0</span>}\n<span class=\"pl-v\">!llvm.module.flags</span> = !{<span class=\"\
    pl-v\">!3</span>, <span class=\"pl-v\">!4</span>, <span class=\"pl-v\">!5</span>}\n\
    <span class=\"pl-v\">!llvm.ident</span> = !{<span class=\"pl-v\">!6</span>}\n\
    <span class=\"pl-v\">!llvm.compinfo</span> = !{<span class=\"pl-v\">!7</span>}\n\
    \n<span class=\"pl-v\">!0</span> = distinct <span class=\"pl-v\">!DICompileUnit</span>(language:\
    \ DW_LANG_C99, file: <span class=\"pl-v\">!1</span>, producer: <span class=\"\
    pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on\
    \ LLVM 7.1.0)\"</span>, isOptimized: <span class=\"pl-k\">true</span>, runtimeVersion:\
    \ <span class=\"pl-c1\">0</span>, emissionKind: LineTablesOnly, enums: <span class=\"\
    pl-v\">!2</span>)\n<span class=\"pl-v\">!1</span> = <span class=\"pl-v\">!DIFile</span>(filename:\
    \ <span class=\"pl-s\">\"-\"</span>, directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"\
    </span>)\n<span class=\"pl-v\">!2</span> = !{}\n<span class=\"pl-v\">!3</span>\
    \ = !{<span class=\"pl-k\">i32</span> <span class=\"pl-c1\">2</span>, !<span class=\"\
    pl-s\">\"Dwarf Version\"</span>, <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">4</span>}\n<span class=\"pl-v\">!4</span> = !{<span class=\"pl-k\">i32</span>\
    \ <span class=\"pl-c1\">2</span>, !<span class=\"pl-s\">\"Debug Info Version\"\
    </span>, <span class=\"pl-k\">i32</span> <span class=\"pl-c1\">3</span>}\n<span\
    \ class=\"pl-v\">!5</span> = !{<span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">1</span>, !<span class=\"pl-s\">\"wchar_size\"</span>, <span class=\"\
    pl-k\">i32</span> <span class=\"pl-c1\">4</span>}\n<span class=\"pl-v\">!6</span>\
    \ = !{!<span class=\"pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021\
    \ 10:55:52) (based on LLVM 7.1.0)\"</span>}\n<span class=\"pl-v\">!7</span> =\
    \ !{!<span class=\"pl-s\">\"C::clang\"</span>}\n<span class=\"pl-v\">!8</span>\
    \ = distinct <span class=\"pl-v\">!DISubprogram</span>(name: <span class=\"pl-s\"\
    >\"main\"</span>, scope: <span class=\"pl-v\">!9</span>, file: <span class=\"\
    pl-v\">!9</span>, line: <span class=\"pl-c1\">1</span>, type: <span class=\"pl-v\"\
    >!10</span>, isLocal: <span class=\"pl-k\">false</span>, isDefinition: <span class=\"\
    pl-k\">true</span>, scopeLine: <span class=\"pl-c1\">1</span>, isOptimized: <span\
    \ class=\"pl-k\">true</span>, unit: <span class=\"pl-v\">!0</span>, retainedNodes:\
    \ <span class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!9</span> = <span class=\"\
    pl-v\">!DIFile</span>(filename: <span class=\"pl-s\">\"&lt;stdin&gt;\"</span>,\
    \ directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"</span>)\n<span class=\"\
    pl-v\">!10</span> = <span class=\"pl-v\">!DISubroutineType</span>(types: <span\
    \ class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!11</span> = <span class=\"\
    pl-v\">!DILocation</span>(line: <span class=\"pl-c1\">1</span>, column: <span\
    \ class=\"pl-c1\">12</span>, scope: <span class=\"pl-v\">!8</span>)</pre></div>\n\
    <h2><a id=\"user-content-systembenchmarksjl\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#systembenchmarksjl\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>SystemBenchmarks.jl</h2>\n<p>I ran <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl\"\
    ><code>SystemBenchmarks.jl</code></a> on a\ncompute node.  Here are the results:\n\
    <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\"\
    >https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968</a>.</p>\n\
    <h2><a id=\"user-content-blas\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #blas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>BLAS</h2>\n\
    <p>OpenBLAS seems to have poor performance:</p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">2.589865257047898e10</span></pre></div>\n\
    <p>Up to v1.7, Julia uses OpenBLAS v0.3.17, which actually doesn't support A64FX\
    \ at all, so\nit's probably using the generic kernels.\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.19\"\
    ><code>v0.3.19</code></a> and\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.20\"\
    ><code>v0.3.20</code></a> improved support for\nthis chip, you can find a build\
    \ of 0.3.20 at\n<a href=\"https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\"\
    >https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz</a>,\n\
    but sadly there isn't a great performance improvement:</p>\n<div class=\"highlight\
    \ highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">lbt_forward</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>lib/libopenblas64_.so<span class=\"pl-pds\"\
    >\"</span></span>)\n<span class=\"pl-c1\">4856</span>\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.6362952057793587e10</span></pre></div>\n\
    <p>There is an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/Library/BLASLAPACKScaLAPACKLibrary.html#how-to-dynamically-load-and-use-blas-lapack-and-scalapack\"\
    \ rel=\"nofollow\">optimised\nBLAS</a>\nprovided by Fujitsu, with support for\
    \ SVE (with both LP64 and ILP64).  In order to use it,\ninstall <a href=\"https://github.com/giordano/FujitsuBLAS.jl\"\
    ><code>FujitsuBLAS.jl</code></a></p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ FujitsuBLAS, LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">get_config</span>()\nLinearAlgebra<span\
    \ class=\"pl-k\">.</span>BLAS<span class=\"pl-k\">.</span>LBTConfig\nLibraries<span\
    \ class=\"pl-k\">:</span>\n\u2514 [ILP64] libfjlapackexsve_ilp64<span class=\"\
    pl-k\">.</span>so\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">4.801227630694119e10</span></pre></div>\n\
    <p>The package <a href=\"https://github.com/carstenbauer/BLISBLAS.jl\"><code>BLISBLAS.jl</code></a>\
    \ similarly forwards\nBLAS calls to the <a href=\"https://github.com/flame/blis\"\
    >blis</a> library, which has optimised kernels\nfor A64FX.</p>\n<h2><a id=\"user-content-building-julia-from-source\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#building-julia-from-source\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building Julia\
    \ from source</h2>\n<h3><a id=\"user-content-with-gcc\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#with-gcc\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>with GCC</h3>\n<p>Building Julia from source with GCC (which is the\
    \ default if you don't set <code>CC</code> and <code>CXX</code>)\nworks fine,\
    \ it's just <em>slow</em>:</p>\n<pre><code>[...]\n    JULIA usr/lib/julia/corecompiler.ji\n\
    Core.Compiler \u2500\u2500\u2500\u2500 903.661 seconds\n[...]\nBase  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500271.257337 seconds\n\
    ArgTools  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 50.348227 seconds\n\
    Artifacts  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.193792 seconds\n\
    Base64  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.057241\
    \ seconds\nCRC32c  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.097865 seconds\nFileWatching  \u2500\u2500\u2500\u2500\u2500  1.169747\
    \ seconds\nLibdl  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.026215 seconds\nLogging  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  0.411966 seconds\nMmap  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.972844 seconds\nNetworkOptions \
    \ \u2500\u2500\u2500  1.159094 seconds\nSHA  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.067851 seconds\nSerialization\
    \  \u2500\u2500\u2500\u2500  2.942512 seconds\nSockets  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.568797 seconds\nUnicode  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.814165 seconds\nDelimitedFiles \
    \ \u2500\u2500\u2500  1.121546 seconds\nLinearAlgebra  \u2500\u2500\u2500\u2500\
    109.560774 seconds\nMarkdown  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  7.977584 seconds\nPrintf  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500  1.635409 seconds\nRandom  \u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 13.843395 seconds\nTar  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.146368 seconds\n\
    Dates  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 16.694863 seconds\nDistributed  \u2500\u2500\u2500\u2500\u2500\u2500  8.163152\
    \ seconds\nFuture  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.060472 seconds\nInteractiveUtils  \u2500  5.245523 seconds\nLibGit2\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 15.469061 seconds\n\
    Profile  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  5.399918\
    \ seconds\nSparseArrays  \u2500\u2500\u2500\u2500\u2500 42.660136 seconds\nUUIDs\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.165799\
    \ seconds\nREPL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500 40.149298 seconds\nSharedArrays  \u2500\u2500\u2500\u2500\u2500 \
    \ 5.476926 seconds\nStatistics  \u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.130843\
    \ seconds\nSuiteSparse  \u2500\u2500\u2500\u2500\u2500\u2500 16.849304 seconds\n\
    TOML  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  0.714203 seconds\nTest  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500  3.538098 seconds\nLibCURL  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.547585 seconds\nDownloads  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  3.657012 seconds\nPkg  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 54.053634 seconds\n\
    LazyArtifacts  \u2500\u2500\u2500\u2500  0.019103 seconds\nStdlibs total  \u2500\
    \u2500\u2500\u2500427.178257 seconds\nSysimage built. Summary:\nTotal \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500 698.447219 seconds\nBase: \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500 271.257337 seconds 38.8372%\nStdlibs: \u2500\u2500\u2500\u2500\
    \ 427.178257 seconds 61.1611%\n[...]\nPrecompilation complete. Summary:\nTotal\
    \ \u2500\u2500\u2500\u2500\u2500\u2500\u2500 1274.714700 seconds\nGeneration \u2500\
    \u2500 886.445205 seconds 69.5407%\nExecution \u2500\u2500\u2500 388.269495 seconds\
    \ 30.4593%\n</code></pre>\n<h3><a id=\"user-content-with-fujitsu-compiler\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#with-fujitsu-compiler\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>With Fujitsu compiler</h3>\n\
    <p><em>For reference, the version used for the last build I attempted was\n<a\
    \ href=\"https://github.com/JuliaLang/julia/commit/1ad2396f05fa63a71e5842c814791cd7c7715100\"\
    ><code>1ad2396f</code></a></em></p>\n<p>Compiling Julia from source with the Fujitsu\
    \ compiler is complicated.  In particular, it's\nan absolute pain to use the Fujitsu\
    \ compiler in trad mode.  You can have some more luck with\nclang mode.</p>\n\
    <p>Preparation.  Create the <code>Make.user</code> file with this content (I'm\
    \ not sure this file is\nactually necessary when using Clang mode, but it definitely\
    \ is with trad mode):</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-k\">override</span> <span class=\"pl-smi\">ARCH</span>\
    \ := aarch64\n<span class=\"pl-k\">override</span> <span class=\"pl-smi\">BUILD_MACHINE</span>\
    \ := aarch64-unknown-linux-gnu</pre></div>\n<p>Then you can compile with (<code>-Nclang</code>\
    \ is to select clang mode)</p>\n<pre><code>make -j50 CC=\"fcc -Nclang\" CFLAGS=\"\
    -Kopenmp\" CXX=\"FCC -Nclang\" CXXFLAGS=\"-Kopenmp\"\n</code></pre>\n<p>The compiler\
    \ in trad mode doesn't define the macro <code>__SIZEOF_POINTER__</code>, so compilation\n\
    would fail in\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115</a>.\n\
    The solution is to set the macro <code>-D__SIZEOF_POINTER__=8</code> in the <code>CFLAGS</code>\
    \ (or just not use\ntrad mode).  Then, you may get errors like</p>\n<pre><code>/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2000:13:\
    \ error: initializer element is not a compile-time constant\n            jl_typename_type,\n\
    \            ^~~~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    /vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2025:43: error: initializer\
    \ element is not a compile-time constant\n    jl_typename_type-&gt;types = jl_svec(13,\
    \ jl_symbol_type, jl_any_type /*jl_module_type*/,\n                          \
    \                ^~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    </code></pre>\n<p>This is the compiler's fault, which is supposed to be able to\
    \ handle this, but you can just\ndelete the assertions at lines\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446</a>.</p>\n\
    <p>If you're lucky enough, with all these changes, you may be able to build <code>usr/bin/julia</code>.\n\
    Unfortunately, last time I tried, run this executable causes a segmentation fault\
    \ in\n<code>dl_init</code>:</p>\n<pre><code>(gdb) run\nStarting program: /vol0003/ra000019/a04463/repo/julia/julia\n\
    Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-151.el8.aarch64\n\
    [Thread debugging using libthread_db enabled]\nUsing host libthread_db library\
    \ \"/lib64/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation\
    \ fault.\n0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\n\
    Missing separate debuginfos, use: yum debuginfo-install FJSVxoslibmpg-2.0.0-25.14.1.el8.aarch64\
    \ elfutils-libelf-0.182-3.el8.aarch64\n(gdb) bt\n#0  0x000040000000def4 in _dl_init\
    \ () from /lib/ld-linux-aarch64.so.1\n#1  0x000040000020adb0 in _dl_catch_exception\
    \ () from /lib64/libc.so.6\n#2  0x00004000000125e4 in dl_open_worker () from /lib/ld-linux-aarch64.so.1\n\
    #3  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#4  0x0000400000011aa8\
    \ in _dl_open () from /lib/ld-linux-aarch64.so.1\n#5  0x0000400000091094 in dlopen_doit\
    \ () from /lib64/libdl.so.2\n#6  0x000040000020ad54 in _dl_catch_exception ()\
    \ from /lib64/libc.so.6\n#7  0x000040000020ae20 in _dl_catch_error () from /lib64/libc.so.6\n\
    #8  0x00004000000917f0 in _dlerror_run () from /lib64/libdl.so.2\n#9  0x0000400000091134\
    \ in dlopen@@GLIBC_2.17 () from /lib64/libdl.so.2\n#10 0x0000400000291f34 in load_library\
    \ (rel_path=0x400001e900c6 &lt;dep_libs+30&gt; \"libjulia-internal.so.1\", src_dir=&lt;optimized\
    \ out&gt;, err=1) at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:65\n\
    #11 0x0000400000291c78 in jl_load_libjulia_internal () at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:200\n\
    #12 0x000040000000de04 in call_init.part () from /lib/ld-linux-aarch64.so.1\n\
    #13 0x000040000000df08 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#14 0x0000400000001044\
    \ in _dl_start_user () from /lib/ld-linux-aarch64.so.1\nBacktrace stopped: previous\
    \ frame identical to this frame (corrupt stack?)\n</code></pre>\n"
  stargazers_count: 6
  subscribers_count: 2
  topics: []
  updated_at: 1670626282.0
goma/goma:
  data_format: 2
  description: A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport
  filenames:
  - spack.yaml
  full_name: goma/goma
  latest_release: v7.4.4
  readme: '<h1><a id="user-content-goma" class="anchor" aria-hidden="true" href="#goma"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Goma</h1>

    <p>A Full-Newton Finite Element Program for Free and Moving Boundary Problems
    with Coupled Fluid/Solid Momentum, Energy, Mass, and Chemical Species Transport</p>

    <p>For more information see the <a href="https://www.gomafem.com" rel="nofollow">Goma
    website</a></p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Most of the documentation can be found at <a href="https://www.gomafem.com/documentation.html"
    rel="nofollow">https://www.gomafem.com/documentation.html</a></p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>See <a href="LICENSE">LICENSE</a> file. Some cmake modules under <code>cmake/</code>
    were modified from the Eigen library

    and are noted at the top of the cmake file.</p>

    <h2><a id="user-content-major-changes" class="anchor" aria-hidden="true" href="#major-changes"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Major Changes</h2>

    <p>See <a href="CHANGES.md">CHANGES.md</a></p>

    <h2><a id="user-content-build-instructions" class="anchor" aria-hidden="true"
    href="#build-instructions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Instructions</h2>

    <p>See <a href="BUILD.md">BUILD.md</a></p>

    <h2><a id="user-content-spack-package" class="anchor" aria-hidden="true" href="#spack-package"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack package</h2>

    <p>The Spack package manager <a href="https://spack.io/" rel="nofollow">https://spack.io</a>
    can be used to install

    Goma and all of Goma''s third party libraries</p>

    <p>Currently available on the <code>develop</code> branch of spack.</p>

    <p>Example for a bash-like shell:</p>

    <pre><code>git clone https://github.com/spack/spack.git

    . spack/share/spack/setup-env.sh

    spack install goma

    </code></pre>

    <p>For more information on build options see:</p>

    <pre><code>spack info goma

    </code></pre>

    <p>For more information on using spack see the <a href="https://spack.readthedocs.io/en/latest/"
    rel="nofollow">spack documentation</a>.</p>

    <h2><a id="user-content-third-party-libraries" class="anchor" aria-hidden="true"
    href="#third-party-libraries"><span aria-hidden="true" class="octicon octicon-link"></span></a>Third
    party libraries</h2>

    <ul>

    <li>Metis 5.1.0 (Optional)</li>

    <li>SEACAS 2022-01-27 (Required: Exodus and Aprepro)</li>

    <li>BLAS/LAPACK (Configured through Trilinos)</li>

    <li>Trilinos matrix solvers 13.0.1 and up (Required: AztecOO, Amesos, Epetra,
    TPL LAPACK; Optional: Stratimikos [with Teko, Ifpack, Belos, Tpetra])</li>

    <li>PETSc matrix solvers (KSP, PC)</li>

    <li>MUMPS 5.4.0 (through Trilinos or PETSc only)</li>

    <li>Superlu_dist 7.2.0 (through Trilinos or PETSc only, Trilinos requires parmetis
    build)</li>

    <li>UMFPACK, SuiteSparse 5.10.1 (Optional)</li>

    <li>ARPACK/arpack-ng 3.8.0 (Optional)</li>

    <li>sparse 1.4b (Optional)</li>

    <li>Catch2 (Optional testing)</li>

    </ul>

    <h3><a id="user-content-run-the-tutorial" class="anchor" aria-hidden="true" href="#run-the-tutorial"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run the tutorial</h3>

    <p>To get started with Goma, use the following:</p>

    <ul>

    <li><a href="https://docs.gomafem.com/files/goma-beginners-tutorial.pdf" rel="nofollow">Tutorial
    instructions</a></li>

    <li><a href="https://docs.gomafem.com/files/goma_beginners_tutorial.tar.gz" rel="nofollow">Tutorial
    files tarball</a></li>

    </ul>

    '
  stargazers_count: 94
  subscribers_count: 25
  topics:
  - finite-elements
  - finite-element-analysis
  - simulation
  - parallel
  - multiphysics
  - fem
  - snl-applications
  updated_at: 1681224746.0
haampie-spack/ci-example-appimage:
  data_format: 2
  description: trying to use spack in gh actions without docker images
  filenames:
  - ci/spack.yaml
  full_name: haampie-spack/ci-example-appimage
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1625582986.0
haampie-spack/ci-example-gha:
  data_format: 2
  description: Use setup-spack GitHub Action
  filenames:
  - ci/spack.yaml
  full_name: haampie-spack/ci-example-gha
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1626953351.0
haampie-spack/setup-spack:
  data_format: 2
  description: null
  filenames:
  - example-environment/spack.yaml
  full_name: haampie-spack/setup-spack
  latest_release: v1.2.1
  stargazers_count: 3
  subscribers_count: 2
  topics: []
  updated_at: 1643842993.0
haampie-throwaway/spack-status-code:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: haampie-throwaway/spack-status-code
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1611744607.0
haampie/sirius-appimage:
  data_format: 2
  description: SIRIUS AppImage (using just the bare minimum)
  filenames:
  - sirius/spack.yaml
  full_name: haampie/sirius-appimage
  latest_release: null
  readme: "<h1><a id=\"user-content-creating-an-appimage-from-a-spack-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#creating-an-appimage-from-a-spack-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating\
    \ an AppImage from a spack environment</h1>\n<p>HPC container runtimes often use\
    \ squashfs as an archive to store an image, which is then mounted on compute nodes\
    \ and made writeable using overlayfs where the top layer is a ramfs. This trick\
    \ gives good performance particularly on shared filesystems, since the squashfs\
    \ file is a single blob on the disk and has good caching behavior.</p>\n<p>However,\
    \ perfect isolation from the host system is not always possible, in particular\
    \ when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into\
    \ the container, and the question is what the point of containers really is if\
    \ they still depend on the host system.</p>\n<p>Instead of using containers, one\
    \ can still deploy applications as a single self-contained blob on the filesystem\
    \ by using the AppImage runtime. The basic idea is to create an executable which\
    \ unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo\
    \ shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\"\
    >SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a>\
    \ and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\"\
    >AppImage runtime</a>.</p>\n<h2><a id=\"user-content-building\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#building\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Building</h2>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">./build.sh</span></pre></div>\n<h2><a id=\"user-content-running\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n\
    <span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git\
    \ hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    <span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\"\
    >build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time\
    \     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI\
    \ ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                 \
    \     : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\
    \n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n\
    <span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\
    \n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"\
    pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n\
    <span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"\
    pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"\
    pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n\
    <span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in\
    \ Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=\
    \   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double}\
    \ default value for APW linearization energies</span>\n<span class=\"pl-c1\">\
    \  --auto_enu allow search of APW linearization energies</span>\n<span class=\"\
    pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\"\
    >  --rel      use scalar-relativistic solver</span></pre></div>\n<h2><a id=\"\
    user-content-running-on-piz-daint\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #running-on-piz-daint\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Running on piz daint</h2>\n<p>For Piz Daint I've modified the <code>sirius/spack.yaml</code>\
    \ a bit so that it links against system libmpi.so (<code>^cray-mpich</code> that\
    \ is):</p>\n<pre><code>daint103 $ ./build.sh\n...\n\ndaint103 $ du -sh sirius.app\
    \ # binary size (includes compressed squashfs)\n26M\tsirius.app\n\ndaint103 $\
    \ ./sirius.app --appimage-extract # runtime allows you to extract\nsquashfs-root/AppRun\n\
    squashfs-root/usr\nsquashfs-root/usr/bin\nsquashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\n\
    squashfs-root/usr/lib\nsquashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\n\
    squashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n\
    ...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\
    \ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf\
    \ # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\n\
    srun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\n\
    input file does not exist\n===========================================================================================================\n\
    \                            #         Total          %   Parent %        Median\
    \           Min           Max\n-----------------------------------------------------------------------------------------------------------\n\
    sirius                      1       2.30 ms     100.00     100.00       2.30 ms\
    \       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms   \
    \   60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize\
    \        1     333.28 us      14.52      14.52     333.28 us     333.28 us   \
    \  333.28 us\n\n===========================================================================================================\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1616508538.0
haampie/spack-docker-bootstrap:
  data_format: 2
  description: Build optimized docker images for Spack
  filenames:
  - spack.yaml
  full_name: haampie/spack-docker-bootstrap
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-in-docker-with-buildcache\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#spack-in-docker-with-buildcache\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Spack in Docker with buildcache</h1>\n\
    <p>This bootstraps Spack's own, optimized dependencies, as well as the\ncompiler\
    \ toolchain of the distro, so that in the end we just depend\non system libc.</p>\n\
    <p>See <a href=\"spack.yaml\">spack.yaml</a> for things that are built by Spack,\
    \ and\n<a href=\"Makefile\">Makefile</a> and <a href=\"Dockerfile\">Dockerfile</a>\
    \ for how it's built.</p>\n<p>Docker buildkit is required.</p>\n<p>Build with:</p>\n\
    <pre><code>DOCKER_BUILDKIT=1 docker build -f linux-ubuntu22.04-x86_64_v2/Dockerfile\
    \ -t spack-optimized --progress=plain .\n</code></pre>\n<p>Since this uses Python\
    \ 3.11 and clingo with some optimizations, it should\ngenerally be faster:</p>\n\
    <pre><code>Benchmark 1: docker run --rm spack-optimized spack spec hdf5\n  Time\
    \ (mean \xB1 \u03C3):      8.494 s \xB1  0.401 s    [User: 0.015 s, System: 0.008\
    \ s]\n  Range (min \u2026 max):    8.034 s \u2026  8.763 s    3 runs\n\nBenchmark\
    \ 2: docker run --rm spack/ubuntu-focal spec hdf5\n  Time (mean \xB1 \u03C3):\
    \     10.795 s \xB1  0.382 s    [User: 0.013 s, System: 0.009 s]\n  Range (min\
    \ \u2026 max):   10.355 s \u2026 11.030 s    3 runs\n\nSummary\n  'docker run\
    \ --rm spack-optimized spack spec hdf5' ran\n    1.27 \xB1 0.07 times faster than\
    \ 'docker run --rm spack/ubuntu-focal spec hdf5'\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1674134786.0
hariharan-devarajan/emacs:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: hariharan-devarajan/emacs
  latest_release: null
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1620404607.0
hariharan-devarajan/unifyfs-bug:
  data_format: 2
  description: null
  filenames:
  - dependency/spack.yaml
  full_name: hariharan-devarajan/unifyfs-bug
  latest_release: null
  readme: "<h1><a id=\"user-content-unifyfs-bug\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#unifyfs-bug\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>unifyfs-bug</h1>\n<h2><a id=\"user-content-the-bug-comes-in-multi-node-case-only\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#the-bug-comes-in-multi-node-case-only\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The bug\
    \ comes in multi-node case only.</h2>\n<h2><a id=\"user-content-instructions\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#instructions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Instructions</h2>\n<ul>\n<li>update\
    \ path of unifyfs on dependency/spack.yaml packages</li>\n<li>activate dependency\
    \ spack folder\n<div class=\"highlight highlight-source-shell\"><pre>spack activate\
    \ -p dependency\nspack install</pre></div>\n</li>\n<li>update path of unifyfs\
    \ install on line 3 of CMakeLists</li>\n<li>build code.\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>cmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_C_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/gcc\
    \ -DCMAKE_CXX_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/g++ -G <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>CodeBlocks - Unix Makefiles<span class=\"\
    pl-pds\">\"</span></span> /g/g92/haridev/temp/unifyfs-bug\ncmake --build /g/g92/haridev/temp/unifyfs-bug/cmake-build-debug\
    \ --target all -- -j 128</pre></div>\n</li>\n<li>Run Unifyfs server\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> unifyfs-bug\n\
    <span class=\"pl-k\">export</span> UNIFYFS_LOG_VERBOSITY=3\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> SET ME</span>\n<span class=\"pl-k\">export</span>\
    \ UNIFYFS_ROOT_DIR=/usr/workspace/iopp/software/tailorfs/dependency/.spack-env/view\
    \  \n<span class=\"pl-k\">export</span> UNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >${HOME}</span>/unifyfs/logs\n<span class=\"pl-k\">export</span> pfs=/p/gpfs1/iopp\n\
    <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-smi\">${PWD}</span>/dependency/.spack-env/view/lib:<span\
    \ class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/lib\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> ACTUAL RUN</span>\nUNIFYFS_LOG_DIR=<span class=\"pl-smi\"\
    >$UNIFYFS_LOG_DIR</span> UNIFYFS_SERVER_CORES=8 <span class=\"pl-smi\">${UNIFYFS_ROOT_DIR}</span>/bin/unifyfs\
    \ start --share-dir=<span class=\"pl-smi\">${pfs}</span>/unifyfs/share-dir -d</pre></div>\n\
    </li>\n<li>Run code\n<h2><a id=\"user-content-bug-1\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#bug-1\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Bug 1</h2>\n<div class=\"highlight highlight-source-shell\"><pre>jsrun\
    \ -r 1 -a 1 -c 1  -d packed <span class=\"pl-smi\">$PWD</span>/cmake-build-debug/unifyfs-bug\
    \ 1</pre></div>\nOutput\n<div class=\"highlight highlight-source-shell\"><pre>Running\
    \ transfer\n2023-03-27T09:36:22 tid=30501 @ <span class=\"pl-en\">forward_to_server</span>()\
    \ [margo_client.c:233] <span class=\"pl-en\">margo_forward_timed</span>() failed\
    \ - HG_TIMEOUT\n2023-03-27T09:36:22 tid=30501 @ <span class=\"pl-en\">invoke_client_transfer_rpc</span>()\
    \ [margo_client.c:614] forward of transfer rpc to server failed\nunifyfs-bug:\
    \ /g/g92/haridev/project/unifyfs-bug/bug.cpp:137: int main(int, char<span class=\"\
    pl-k\">**</span>): Assertion <span class=\"pl-s\"><span class=\"pl-pds\">`</span>rc\
    \ == UNIFYFS_SUCCESS<span class=\"pl-s\"><span class=\"pl-pds\">'</span> failed.</span></span>\n\
    <span class=\"pl-s\"><span class=\"pl-s\">[lassen1:30501] *** Process received\
    \ signal ***</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\">[lassen1:30501]\
    \ Signal: Aborted (6)</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\"\
    >[lassen1:30501] Signal code:  (-6)</span></span></pre></div>\n</li>\n</ul>\n\
    <pre><code>  ## Bug 2\n\n  ```bash\n  jsrun -r 1 -a 1 -c 1  -d packed $PWD/cmake-build-debug/unifyfs-bug\
    \ 2\n</code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1675706965.0
hepnos/HEPnOS-ICARUS-Benchmark:
  data_format: 2
  description: A HEPnOS benchmark aimed at investigating performance issues with the
    ICARUS application access pattern.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-ICARUS-Benchmark
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1659444215.0
hepnos/HEPnOS-PEP-Benchmark:
  data_format: 2
  description: Benchmark exercizing the ParallelEventProcessor feature of HEPnOS.
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-PEP-Benchmark
  latest_release: v0.6
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1643644897.0
hepnos/HEPnOS-Wizard:
  data_format: 2
  description: Python utilities to generate HEPnOS configurations
  filenames:
  - spack.yaml
  full_name: hepnos/HEPnOS-Wizard
  latest_release: v0.0.2
  readme: '<h1><a id="user-content-hepnos-wizard" class="anchor" aria-hidden="true"
    href="#hepnos-wizard"><span aria-hidden="true" class="octicon octicon-link"></span></a>HEPnOS-Wizard</h1>

    <p>This package contains scripts to help setup valid configurations

    for the HEPnOS storage service.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1641579766.0
j-woz/SV-CP-2022-11-23:
  data_format: 2
  description: null
  filenames:
  - spack/spack.yaml
  full_name: j-woz/SV-CP-2022-11-23
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669233200.0
jacobmerson/vector-correlation:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: jacobmerson/vector-correlation
  latest_release: null
  readme: '<h1><a id="user-content-vector-correlation" class="anchor" aria-hidden="true"
    href="#vector-correlation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Vector
    Correlation</h1>

    <p>This code is intended to reproduce the vector correlation technique discussed
    in

    "Vector correlation technique for pixel-wise detection of collagen fiber realignment

    during injurous tensile loading", Quinn et al.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1634889026.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-github/GPU/spack.yaml
  - Docs/compile-notes/frontera-bitbucket/GPU/spack.yaml
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  - Docs/compile-notes/frontera-bitbucket/CPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/8257fa34c1c5b6c660b31bf16a6196859c354c9c503b7742e1cdee871fbb96c8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/b768fc44ae95216e4b53ff734978771466ba222596e760da27e9e60a0d47d6f7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <h2><a id="user-content-available-modules" class="anchor" aria-hidden="true" href="#available-modules"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Available modules</h2>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>TOVSolver</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    '
  stargazers_count: 8
  subscribers_count: 8
  topics: []
  updated_at: 1679282900.0
jaykalinani/AsterX-Docs:
  data_format: 2
  description: 'AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes'
  filenames:
  - compile-notes/frontera-bitbucket/GPU/spack.yaml
  - compile-notes/frontera-github/CPU/spack.yaml
  - compile-notes/frontera-github/GPU/spack.yaml
  - compile-notes/frontera-bitbucket/CPU/spack.yaml
  full_name: jaykalinani/AsterX-Docs
  latest_release: null
  readme: '<h1><a id="user-content-asterx" class="anchor" aria-hidden="true" href="#asterx"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>AsterX</h1>

    <p>AsterX: a new open-source GPU-accelerated GRMHD code for dynamical spacetimes</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1677876939.0
jedwards4b/spackenvironments:
  data_format: 2
  description: my spack environments for software builds
  filenames:
  - esmfbld/spack.yaml
  - paralleliobld/spack.yaml
  full_name: jedwards4b/spackenvironments
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1664981968.0
jeffersonscientific/seissol_compile:
  data_format: 2
  description: Compile (and similar) script for SeisSol
  filenames:
  - ss_spack_env_template.yaml
  full_name: jeffersonscientific/seissol_compile
  latest_release: null
  readme: '<h1><a id="user-content-seissol_compile" class="anchor" aria-hidden="true"
    href="#seissol_compile"><span aria-hidden="true" class="octicon octicon-link"></span></a>seissol_compile</h1>

    <p>Compile (and similar) script for SeisSol</p>

    <h1></h1>

    <p>To date, these scripts can be used to install SeisSol on Stanford Research
    Computing''s Sherlock HPC. The <code>compile_seissol_spack.sh</code> script primarily
    uses a <code>spack</code> built environment, and so can be adapted to another
    HPC relatively easily.</p>

    <p>The <code>compile_seissol_sherlock.sh</code> script might be refrenced as a
    template -- the idea being to use pre-built SW modules to build SeisSol, but it
    ultimately crashes and burns prety spetacularly. One issue is that the various
    components may have differend dependencies. Namely, some packages are built from
    a <code>gcc/10.1.0</code> toolchain and another from <code>gcc/12.1.0</code>.</p>

    <p>Files:</p>

    <ul>

    <li>

    <code>build_spack_env.sh</code>: a generic batchable bash script to build a spack
    environment.</li>

    <li>

    <code>ss_env.yaml</code>: Should be the einvironment file we use to define the
    <code>seissol</code> spack environment. Note that the environment includes some
    external package definitions and Sherlock''s built in <code>gcc</code> compilers,
    including the primary <code>gcc@12.1.0</code>. These will need to be modified
    to deploy on a different HPC. Compilers can be built natively in Spack, then automagically
    discovered and added, but ultimately it will still likely be neessary to modify
    their definition in the environment file.</li>

    <li>

    <code>compile_seissol_spack.sh</code>: Working (on Sherlock HPC) compile script.
    will build all the non-Spack components</li>

    <li>

    <code>compile_seissol_cees_sherlock</code>: An older compile script that attempts
    to use Sherlock''s standard SW to compile. It ultimately crashes and burns, but
    might be referenced as a template.</li>

    <li>

    <code>install_ss_spack.sh</code>: An early template to build the Spack environment
    from scratch, including building, and <code>find</code>ing compilers in Spack.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666893798.0
jkbk2004/src:
  data_format: 2
  description: null
  filenames:
  - src/UPP/ci/spack.yaml
  full_name: jkbk2004/src
  latest_release: null
  readme: "<h1><a id=\"user-content-ufs-short-range-weather-application\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#ufs-short-range-weather-application\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UFS Short-Range\
    \ Weather Application</h1>\n<p>The Unified Forecast System (UFS) is a community-based,\
    \ coupled, comprehensive Earth modeling system. It is designed to be the source\
    \ system for NOAA\u2019s operational numerical weather prediction applications\
    \ while enabling research, development, and contribution opportunities for the\
    \ broader weather enterprise. For more information about the UFS, visit the UFS\
    \ Portal at <a href=\"https://ufscommunity.org/\" rel=\"nofollow\">https://ufscommunity.org/</a>.</p>\n\
    <p>The UFS includes multiple applications (see a complete list at <a href=\"https://ufscommunity.org/science/aboutapps/\"\
    \ rel=\"nofollow\">https://ufscommunity.org/science/aboutapps/</a>) that support\
    \ different forecast durations and spatial domains. This documentation describes\
    \ the development branch of the UFS Short-Range Weather (SRW) Application, which\
    \ targets predictions of atmospheric behavior on a limited spatial domain and\
    \ on time scales from minutes to several days. The development branch of the application\
    \ is continually evolving as the system undergoes open development. The latest\
    \ SRW App release (v2.0.0) represents a snapshot of this continuously evolving\
    \ system.</p>\n<p>The UFS SRW App User's Guide associated with the development\
    \ branch is at: <a href=\"https://ufs-srweather-app.readthedocs.io/en/develop/\"\
    \ rel=\"nofollow\">https://ufs-srweather-app.readthedocs.io/en/develop/</a>, while\
    \ the guide specific to the SRW App v2.0.0 release can be found at: <a href=\"\
    https://ufs-srweather-app.readthedocs.io/en/release-public-v2/\" rel=\"nofollow\"\
    >https://ufs-srweather-app.readthedocs.io/en/release-public-v2/</a>. The repository\
    \ is at: <a href=\"https://github.com/ufs-community/ufs-srweather-app\">https://github.com/ufs-community/ufs-srweather-app</a>.</p>\n\
    <p>For instructions on how to clone the repository, build the code, and run the\
    \ workflow, see:\n<a href=\"https://github.com/ufs-community/ufs-srweather-app/wiki/Getting-Started\"\
    >https://github.com/ufs-community/ufs-srweather-app/wiki/Getting-Started</a></p>\n\
    <p>UFS Development Team. (2022, June 23). Unified Forecast System (UFS) Short-Range\
    \ Weather (SRW) Application (Version v2.0.0). Zenodo. <a href=\"https://doi.org/10.5281/zenodo.6505854\"\
    \ rel=\"nofollow\">https://doi.org/10.5281/zenodo.6505854</a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1661692471.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - anl/polaris/polaris.spack.yaml
  - ornl/summit/summit.spack.yaml
  - ornl/crusher/crusher.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
jotsap/msds_hpc_project:
  data_format: 2
  description: null
  filenames:
  - bin/spack_r_final.yaml
  full_name: jotsap/msds_hpc_project
  latest_release: null
  readme: '<h1><a id="user-content-msds-hpc-and-ds-final-project" class="anchor" aria-hidden="true"
    href="#msds-hpc-and-ds-final-project"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>MSDS HPC and DS Final Project</h1>

    <p>The goal of semester project is to produce a single-submit, end-to-end,

    performant pipeline for a complex and computationally intensive data analysis

    workflow.</p>

    <h2><a id="user-content-semester-project-details" class="anchor" aria-hidden="true"
    href="#semester-project-details"><span aria-hidden="true" class="octicon octicon-link"></span></a>Semester
    Project Details</h2>

    <ul>

    <li>The analysis and dataset, possibly generative, needs to be

    sufficiently computationally intensive such that a reasonable

    performance analysis can be conducted.</li>

    <li>The specific dataset, analysis, and performance analysis will be

    agreed to at various stages during the semester.</li>

    <li>The pipeline should be single-submit, meaning that a single job is

    submitted to the queue system and then entire pipeline is run with

    each stage run on appropriate hardware with appropriately optimized

    software stacks.</li>

    <li>The deliverable will be a ready to present slide deck in your GitHub

    repo, <em>i.e.</em> a job will be submitted on an SMU HPC cluster and then,

    sometime later with zero human interaction, a PDF presentation will

    appear in your GitHub repo.</li>

    <li>The presentation should discuss both the dataset analysis and

    performance analysis.</li>

    <li>Specific compute resources will be reserved for final testing and

    the production run.</li>

    </ul>

    <h2><a id="user-content-repository-structure" class="anchor" aria-hidden="true"
    href="#repository-structure"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Structure</h2>

    <ul>

    <li>

    <code>bin</code>, Executable scripts.</li>

    <li>

    <code>src</code>, Non-directly executable source code.</li>

    <li>

    <code>data</code>, Datasets, where appropriate, and parameter files</li>

    <li>

    <code>docs</code>, Workflow documentation and location of the final deliverable</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1659416600.0
jrood-nrel/spack-configs:
  data_format: 2
  description: Spack configuration files and scripts for use on machines at NREL
  filenames:
  - envs/exawind/spack.yaml
  full_name: jrood-nrel/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"
    class="anchor" aria-hidden="true" href="#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack configuration
    files and scripts for use on machines at NREL</h1>

    <p>These software installations are maintained by Jon Rood for the HPACF group
    at NREL and are tailored to the applications our group develops. The list of available
    modules can be seen in <a href="modules.txt">modules.txt</a>. They are open to
    anyone to use on our machines. The software installations are organized by date
    snapshots. The binaries, compilers, and utilties are not updated as often as the
    software modules, so dated symlinks might point to older dates for those. However,
    each date snapshot of the modules should be able to stand on its own so that older
    snapshots can be purged safely over time.</p>

    <ul>

    <li>"base" is just a newer version of GCC to replace the system GCC 4.8.5 which
    is far too old to build many recent projects.</li>

    <li>"binaries" are generally the binary downloads of Paraview and Visit.</li>

    <li>"compilers" are the latest set of compilers built using the base GCC.</li>

    <li>"utilities" are the latest set of utility programs that don''t rely on MPI
    and are built using the base GCC.</li>

    <li>"software" are the latest set of generally larger programs and dependencies
    that rely on MPI. Each date corresponds to a single MPI implementation so there
    is no confusion as to which MPI was used for the applications. These modules are
    built using a farily recent GCC, Clang, or Intel compiler provided from the "compilers"
    modules, using the highest optimization flags specific to the machine architecture.</li>

    </ul>

    <p>The Spack hierarchy is linked in the following manner where each installation
    is based on other upstream Spack installations. "software" depends on "utilities",
    which both depend on "compilers". This hierarchy allows Spack to point to packages
    it needs which are already built upstream. The "compilers" installation exposes
    only the modules for compilers, while the "utilities" modules inherit modules
    from itself as well as the dependency packages in the "compilers" installation
    except the compiler modules themselves.</p>

    <p>Currently there is no perfect way to advertise deprecation or addition, and
    evolution of these modules. I have an MOTD you can cat in your login script to
    see updates. Generally the latest 4 sets of modules will likely be kept and new
    sets have been showing up around every 3 to 6 months.</p>

    <p>To use these modules you can add the following to your <code>~/.bashrc</code>
    for example and choose the module set (date) you prefer, and the GCC or Intel
    compiled software modules:</p>

    <pre><code>#------------------------------------------


    #MPT 2.22

    #MODULES=modules-2020-07

    #COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3.1

    #MODULES=modules-2019-10-08

    #COMPILER=gcc-7.4.0

    #COMPILER=clang-7.0.1

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-23

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-05-08

    #COMPILER=gcc-7.4.0

    #COMPILER=intel-18.0.4


    #MPICH 3.3

    #MODULES=modules-2019-01-10

    #COMPILER=gcc-7.3.0

    #COMPILER=intel-18.0.4


    #Recommended default according to where "modules" is currently symlinked

    MODULES=modules

    COMPILER=gcc-8.4.0

    #COMPILER=clang-10.0.0

    #COMPILER=intel-18.0.4


    module purge

    module unuse ${MODULEPATH}

    module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}

    module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}

    module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}

    module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

    module load gcc

    module load git

    module load python

    #etc...


    #------------------------------------------

    </code></pre>

    <p>If <code>module avail</code> does not show the modules on Eagle, try removing
    the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>

    <p>Also included in this directory is a recommended Spack configurations you can
    use to build your own packages on the machines supported at NREL. Once you have
    <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code>
    which should copy the yaml files into your instance of Spack. Or you can copy
    the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack
    compilers</code> should then show you many available compilers. Source your Spack''s
    <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code>
    in your <code>.bashrc</code> so that your Spack instance will add its own module
    path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack
    compilers</code> doesn''t show you the updated list of compilers. The <code>~/.spack</code>
    directory takes highest precendence in the Spack configuration.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1666717629.0
js947/spack-docker-test:
  data_format: 2
  description: testing spack's containerize command
  filenames:
  - spack.yaml
  full_name: js947/spack-docker-test
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"><img
    src="https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg"
    alt="Build container" style="max-width: 100%;"></a></p>

    <h1><a id="user-content-spack-docker-test" class="anchor" aria-hidden="true" href="#spack-docker-test"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-docker-test</h1>

    <p>testing spack''s containerize command</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1606954982.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-release-user/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software. It grew
    out of <a href="https://github.com/HSF/hep-spack">https://github.com/HSF/hep-spack</a>,
    and many recipes habe been included in the upstream spack repostiory.</p>

    <p>Consult the <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack
    documentation</a> and the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep
    documentation website</a> for more details.</p>

    <h3><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    href="#repository-contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>Repository
    Contents</h3>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the repository contains some <code>scripts</code> used for publishing on cvmfs,
    and <code>config</code> files for spack.</p>

    <h3><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    href="#central-installations"><span aria-hidden="true" class="octicon octicon-link"></span></a>Central
    Installations</h3>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>,
    see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 8
  subscribers_count: 10
  topics: []
  updated_at: 1680637567.0
lanl/SICM:
  data_format: 2
  description: Simplified Interface to Complex Memory
  filenames:
  - spack.yaml
  full_name: lanl/SICM
  latest_release: null
  readme: '<h1><a id="user-content-sicm" class="anchor" aria-hidden="true" href="#sicm"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SICM</h1>

    <p>Simplified Interface to Complex Memory</p>

    <p><a href="https://github.com/lanl/SICM/actions"><img src="https://github.com/lanl/SICM/actions/workflows/sicm.yml/badge.svg"
    alt="GitHub Actions" style="max-width: 100%;"></a></p>

    <h2><a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

    <p>This project is split into two interfaces: <code>low</code> and <code>high</code>.</p>

    <p>The <code>low</code> interface provides a minimal interface for application
    wanting to

    manage their own memory on heterogeneous memory tiers. It also provides an

    arena allocator that application developers can use to create <code>jemalloc</code>
    arenas

    on different memory tiers and allocate to those tiers.</p>

    <p>The <code>high</code> interface attempts to automatically manage the memory
    tiers for the

    application. It provides an LLVM compiler pass (and compiler wrappers) to

    automatically transform applications to make the appropriate <code>high</code>
    interface

    calls, as well as a runtime library which provides profiling for the

    application.  The profiling is currently meant to be used offline; that is,

    after enabling the profiling for an application run, the results are printed

    out at the end of the run, and that information must be fed into a second run

    to make use of it. An online approach is planned.</p>

    <h2><a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

    <p>The only dependencies that you will need for the low-level interface

    are <code>libnuma</code> and <code>jemalloc</code>. We require that <code>jemalloc</code>
    be

    configured with the <code>je_</code> prefix (using the <code>--with-jemalloc-prefix</code>
    flag).

    <code>CMake</code> will use <code>pkg-config</code> to find <code>jemalloc</code>.</p>

    <p>For the high-level interface, you need an installation of LLVM. LLVM 4.0 and

    later have been tested, although 3.9 may possibly work. For the profiling, you

    will also need an installation of <code>libpfm</code>, which is a small helper
    library for

    <code>perf</code> that is available on most distributions.</p>

    <p>Additionally, several other packages are required, and can be installed through
    a package manager:</p>

    <h3><a id="user-content-binaries" class="anchor" aria-hidden="true" href="#binaries"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Binaries</h3>

    <ul>

    <li>A modern C compiler</li>

    <li>A modern C++ compiler</li>

    <li>A modern Fortran compiler</li>

    <li>CMake 3.0+</li>

    <li>Make</li>

    <li>numactl</li>

    <li>automake + friends (if jemalloc needs to be built)</li>

    </ul>

    <h3><a id="user-content-development-libraries" class="anchor" aria-hidden="true"
    href="#development-libraries"><span aria-hidden="true" class="octicon octicon-link"></span></a>Development
    Libraries</h3>

    <p>These packages are usually named <code>lib*-dev</code> or <code>lib*-devel</code>:</p>

    <ul>

    <li>numa</li>

    </ul>

    <p>Additional packages are required for the high level interface:</p>

    <ul>

    <li>hwloc</li>

    <li>llvm</li>

    <li>omp (if OpenMP is not available by default on your compilers)</li>

    <li>pfm4</li>

    </ul>

    <h2><a id="user-content-compilation" class="anchor" aria-hidden="true" href="#compilation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compilation</h2>

    <pre><code>export PKG_CONFIG_PATH=&lt;jemalloc prefix&gt;/lib/pkgconfig:$PKG_CONFIG_PATH

    mkdir build

    cd build

    cmake .. -DCMAKE_INSTALL_PREFIX=&lt;prefix&gt;

    make

    make install

    </code></pre>

    <h2><a id="user-content-low-level-api" class="anchor" aria-hidden="true" href="#low-level-api"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Low-Level API</h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_init</code></td>

    <td>Detects all memory devices on system, returns a list of them.</td>

    </tr>

    <tr>

    <td><code>sicm_fini</code></td>

    <td>Frees up a device list and associated SICM data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_find_device</code></td>

    <td>Return the first device that matches a given type and page size.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc</code></td>

    <td>Allocates to a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_free</code></td>

    <td>Frees memory on a device.</td>

    </tr>

    <tr>

    <td><code>sicm_can_place_exact</code></td>

    <td>Returns whether or not a device supports exact placement.</td>

    </tr>

    <tr>

    <td><code>sicm_device_alloc_exact</code></td>

    <td>Allocate memory on a device with an exact base address.</td>

    </tr>

    <tr>

    <td><code>sicm_numa_id</code></td>

    <td>Returns the NUMA ID that a device is on.</td>

    </tr>

    <tr>

    <td><code>sicm_device_page_size</code></td>

    <td>Returns the page size of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_device_eq</code></td>

    <td>Returns if two devices are equal or not.</td>

    </tr>

    <tr>

    <td><code>sicm_move</code></td>

    <td>Moves memory from one device to another.</td>

    </tr>

    <tr>

    <td><code>sicm_pin</code></td>

    <td>Pin the current process to a device''s memory.</td>

    </tr>

    <tr>

    <td><code>sicm_capacity</code></td>

    <td>Returns the capacity of a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_avail</code></td>

    <td>Returns the amount of memory available on a given device.</td>

    </tr>

    <tr>

    <td><code>sicm_model_distance</code></td>

    <td>Returns the distance of a given memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_is_near</code></td>

    <td>Returns whether or not a given memory device is nearby the current NUMA node.</td>

    </tr>

    <tr>

    <td><code>sicm_latency</code></td>

    <td>Measures the latency of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear2</code></td>

    <td>Measures a memory device''s linear access bandwidth.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random2</code></td>

    <td>Measures random access bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_linear3</code></td>

    <td>Measures the linear bandwidth of a memory device.</td>

    </tr>

    <tr>

    <td><code>sicm_bandwidth_random3</code></td>

    <td>Measures the random access bandwidth of a memory device.</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-arena-allocator-api" class="anchor" aria-hidden="true"
    href="#arena-allocator-api"><span aria-hidden="true" class="octicon octicon-link"></span></a>Arena
    Allocator API</h2>

    <table>

    <thead>

    <tr>

    <th>Function Name</th>

    <th>Description</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sicm_arenas_list</code></td>

    <td>List all arenas created in the arena allocator.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_create</code></td>

    <td>Create a new arena on the given device.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_destroy</code></td>

    <td>Frees up an arena, deleting all associated data structures.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_default</code></td>

    <td>Sets an arena as the default for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_default</code></td>

    <td>Gets the default arena for the current thread.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_get_device</code></td>

    <td>Gets the device for a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_set_device</code></td>

    <td>Sets the memory device for a given arena. Moves all allocated memory already
    allocated to the arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_size</code></td>

    <td>Gets the size of memory allocated to the given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc</code></td>

    <td>Allocate to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_alloc_aligned</code></td>

    <td>Allocate aligned memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_realloc</code></td>

    <td>Resize allocated memory to a given arena.</td>

    </tr>

    <tr>

    <td><code>sicm_arena_lookup</code></td>

    <td>Returns which arena a given pointer belongs to.</td>

    </tr>

    </tbody>

    </table>

    <h2><a id="user-content-high-level-interface" class="anchor" aria-hidden="true"
    href="#high-level-interface"><span aria-hidden="true" class="octicon octicon-link"></span></a>High-Level
    Interface</h2>

    <p>The high-level interface is normally used with the compiler wrappers located
    in

    <code>bin/</code>. Users should use these wrappers to compile their applications,
    and a

    compiler pass will automatically transform the code so that it calls the

    high-level interface with the appropriate arguments, including initialization,

    destruction, and the proper allocation functions. Assuming the high-level

    interface is linked to the application as a shared library, it automatically

    initializes itself.  All heap allocation routines are replaced by calls to

    <code>void* sh_alloc(int id, size_t sz)</code>, which associates an ID with a
    given

    allocation and allocates the memory into an arena with other allocations of

    that ID.</p>

    <h2><a id="user-content-programming-practices" class="anchor" aria-hidden="true"
    href="#programming-practices"><span aria-hidden="true" class="octicon octicon-link"></span></a>Programming
    Practices</h2>

    <ol>

    <li>All blocks use curly braces

    <ul>

    <li>Even one-line blocks</li>

    </ul>

    </li>

    <li>Constants on the left side of <code>==</code>

    <ul>

    <li><code>if(NULL == foo) { ...</code></li>

    </ul>

    </li>

    <li>Functions with no arguments are <code>(void)</code>

    </li>

    <li>No C++-style comments in C code</li>

    <li>No GCC extensions except in GCC-only code</li>

    <li>No C++ code in libraries

    <ul>

    <li>Discouraged in components</li>

    </ul>

    </li>

    <li>Always define preprocessor macros

    <ul>

    <li>Define logicals to 0 or 1 (vs. define or not define)</li>

    <li>Use <code>#if FOO</code>, not <code>#ifdef FOO</code>

    </li>

    </ul>

    </li>

    </ol>

    '
  stargazers_count: 22
  subscribers_count: 20
  topics: []
  updated_at: 1681283454.0
lanl/cellar-gtest-mpi:
  data_format: 2
  description: null
  filenames:
  - spack/agaspar/spack.yaml
  full_name: lanl/cellar-gtest-mpi
  latest_release: null
  readme: "<h1><a id=\"user-content-google-test-for-mpi-gtest-mpi\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#google-test-for-mpi-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Google Test for MPI (gtest-mpi)</h1>\n\
    <p>This is a support library that helps users write Google Test unit tests that\n\
    rely on MPI.</p>\n<h2><a id=\"user-content-features\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#features\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Features</h2>\n<ul>\n<li>Serialized and rank-tagged Google Test output.</li>\n\
    <li>Rank-tagged failure reports.</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p><a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> is the easiest way\
    \ to install gtest-mpi. The gtest-mpi\npackage is available in\n<a href=\"https://gitlab.lanl.gov/agaspar/spack-repo\"\
    \ rel=\"nofollow\">agaspar/spack-repo</a>. Follow the\nREADME there to use that\
    \ spack repo. Once the agaspar-spack-repo repo is\ninstalled, installing gtest-mpi\
    \ is as simple as running:</p>\n<pre><code>spack install gtest-mpi\n</code></pre>\n\
    <p>When you want to use gtest-mpi, run <code>spack load gtest-mpi</code> to load\
    \ it into your\ncurrent environment.</p>\n<h3><a id=\"user-content-cmake\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#cmake\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>CMake</h3>\n<p>If you don't want to use spack,\
    \ you can install gtest-mpi directly using CMake.\ngtest-mpi uses CMake, so all\
    \ of your knowledge of CMake applies. gtest-mpi\nhas a dependency on Google Test,\
    \ and uses\n<a href=\"https://cmake.org/cmake/help/latest/module/FindGTest.html\"\
    \ rel=\"nofollow\">FindGTest.cmake</a> to\nfind it. Therefore, in order to install\
    \ gtest-mpi, you must first have a\nworking installation of <a href=\"https://github.com/google/googletest/\"\
    >Google Test</a>.</p>\n<p>Once you've installed Google Test, building and installing\
    \ gtest-mpi is just\nlike any other modern CMake package.</p>\n<pre><code>git\
    \ clone git@gitlab.lanl.gov:agaspar/gtest-mpi.git\ncd gtest-mpi\nmkdir build &amp;&amp;\
    \ cd build\ncmake ..\nmake install\n</code></pre>\n<h2><a id=\"user-content-using-gtest-mpi\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-gtest-mpi\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using gtest-mpi</h2>\n<h3><a\
    \ id=\"user-content-with-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #with-cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>With\
    \ CMake</h3>\n<p>If you don't need any custom startup logic, using gtest-mpi in\
    \ your own CMake\nproject is simple:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">find_package</span>(gtest-mpi 0.1 <span class=\"pl-k\"\
    >REQUIRED</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> gtest-mpi-main\
    \ provides a main function for you</span>\n<span class=\"pl-c1\">add_executable</span>(my-test\
    \ mytest.cpp)\n<span class=\"pl-c1\">target_link_libraries</span>(my-test gtest-mpi-main)</pre></div>\n\
    <p>Then you can write a Google Test just like you normally would:</p>\n<div class=\"\
    highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> mytest.cpp</span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-en\"\
    >TEST</span>(GTestMPI, Basic) {\n    <span class=\"pl-k\">int</span> rank;\n \
    \   <span class=\"pl-c1\">MPI_Comm_rank</span>(MPI_COMM_WORLD, &amp;rank);\n\n\
    \    <span class=\"pl-k\">bool</span> is_root = rank == <span class=\"pl-c1\"\
    >0</span>;\n\n    <span class=\"pl-k\">bool</span> is_anyone_root = <span class=\"\
    pl-c1\">false</span>;\n    <span class=\"pl-c1\">MPI_Allreduce</span>(\n     \
    \   &amp;is_root, &amp;is_anyone_root, <span class=\"pl-c1\">1</span>, MPI_CXX_BOOL,\
    \ MPI_LOR, MPI_COMM_WORLD);\n\n    <span class=\"pl-c1\">ASSERT_TRUE</span>(is_anyone_root);\n\
    }</pre></div>\n<p>If you need to write your own main function, that's also fairly\
    \ straighforward.\nIn your CMake project, you link against <code>gtest-mpi-lib</code>\
    \ instead of\n<code>gtest-mpi-main</code>. Then you must provide your own main\
    \ function:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> main.cpp</span>\n#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest-mpi/init.hpp<span\
    \ class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>gtest/gtest.h<span class=\"\
    pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"\
    pl-s\"><span class=\"pl-pds\">&lt;</span>mpi.h<span class=\"pl-pds\">&gt;</span></span>\n\
    \n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span> **argv) {\n    <span\
    \ class=\"pl-c1\">testing::InitGoogleTest</span>(&amp;argc, argv);\n    <span\
    \ class=\"pl-c1\">MPI_Init</span>(&amp;argc, &amp;argv);\n    <span class=\"pl-c1\"\
    >gtest_mpi::init</span>(&amp;argc, &amp;argv);\n\n    <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Your custom init logic goes here</span>\n\n    <span\
    \ class=\"pl-k\">int</span> exit_code = <span class=\"pl-c1\">RUN_ALL_TESTS</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Your custom finalize\
    \ logic goes here</span>\n\n    <span class=\"pl-c1\">gtest_mpi::finalize</span>();\n\
    \    <span class=\"pl-c1\">MPI_Finalize</span>();\n\n    <span class=\"pl-k\"\
    >return</span> exit_code;\n}</pre></div>\n<h3><a id=\"user-content-without-cmake\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#without-cmake\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Without CMake</h3>\n<p>CMake\
    \ is not required to use gtest-mpi, but it is recommended. If you wish to\nuse\
    \ a different build system, then adding <code>-lgtest-mpi-lib</code> and (optionally)\n\
    <code>-lgtest-mpi-main</code> to your link line will work.</p>\n<h2><a id=\"user-content-ctest\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#ctest\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>CTest</h2>\n<p>Here's an example of\
    \ adding a CTest using gtest-mpi to your CMake file:</p>\n<div class=\"highlight\
    \ highlight-source-cmake\"><pre><span class=\"pl-c1\">enable_testing</span>()\n\
    \n<span class=\"pl-c1\">add_test</span>(\n    <span class=\"pl-k\">NAME</span>\
    \ my-test\n    <span class=\"pl-k\">COMMAND</span>\n        <span class=\"pl-smi\"\
    >${MPIEXEC}</span> <span class=\"pl-smi\">${MPIEXEC_NUMPROC_FLAG}</span> 4 <span\
    \ class=\"pl-smi\">${MPIEXEC_PREFLAGS}</span>\n            $&lt;<span class=\"\
    pl-k\">TARGET_FILE</span>:my-test&gt; <span class=\"pl-smi\">${MPIEXEC_POSTFLAGS}</span>)</pre></div>\n\
    <p>These tests can be run using <code>ctest</code>.</p>\n"
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1668046366.0
le-raffael/AdaptiveTimeSteppingSEAS:
  data_format: 2
  description: null
  filenames:
  - tandem/submodules/yateto/tests/spack.yaml
  full_name: le-raffael/AdaptiveTimeSteppingSEAS
  latest_release: null
  readme: '<h1><a id="user-content-adaptivetimesteppingseas" class="anchor" aria-hidden="true"
    href="#adaptivetimesteppingseas"><span aria-hidden="true" class="octicon octicon-link"></span></a>AdaptiveTimeSteppingSEAS</h1>

    <p>The main implementation of this thesis is located in the folder "tandem"

    To compile and run the simulation:</p>

    <ul>

    <li>cd tandem</li>

    <li>mkdir build</li>

    <li>ccmake ..       # to specify domain dimension, quadrature order ...</li>

    <li>cmake -DALIGNMENT=16 -DPETSC_MEMALIGN=16 -DCMAKE_PREFIX_PATH=/path/to/petsc
    -DLUA_INCLUDE_DIR=/path/to/lua ..</li>

    <li>make tandem</li>

    <li>./app/tandem ../examples/tandem/2d/bp1_sym.toml --petsc -ts_monitor</li>

    </ul>

    <p>The simulation settings can be changed in tandem/examples/tandem/2d/bp1_sym.toml,
    tandem/examples/tandem/3d/bp5.toml or any other .toml file</p>

    <p>There is also an option to calculate the residual of the Newton iteration and
    Broyden iteration on the 1st order ODE formulation (works only in 2D)</p>

    <ul>

    <li>make testJacobian</li>

    <li>./app/testJacobian ../examples/tandem/2d/bp1_sym.toml</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1623696683.0
lfortran/lfortran:
  data_format: 2
  description: Official main repository for LFortran
  filenames:
  - spack.yaml
  full_name: lfortran/lfortran
  latest_release: null
  readme: "<h1><a id=\"user-content-lfortran\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#lfortran\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>LFortran</h1>\n<p><a href=\"https://lfortran.zulipchat.com/\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>LFortran is a modern open-source (BSD\
    \ licensed) interactive Fortran compiler\nbuilt on top of LLVM. It can execute\
    \ user's code interactively to allow\nexploratory work (much like Python, MATLAB\
    \ or Julia) as well as compile to\nbinaries with the goal to run user's code on\
    \ modern architectures such as\nmulti-core CPUs and GPUs.</p>\n<p>Website: <a\
    \ href=\"https://lfortran.org/\" rel=\"nofollow\">https://lfortran.org/</a></p>\n\
    <p>Try online: <a href=\"https://dev.lfortran.org/\" rel=\"nofollow\">https://dev.lfortran.org/</a></p>\n\
    <h1><a id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#documentation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Documentation</h1>\n<p>All documentation, installation instructions,\
    \ motivation, design, ... is\navailable at:</p>\n<p><a href=\"https://docs.lfortran.org/\"\
    \ rel=\"nofollow\">https://docs.lfortran.org/</a></p>\n<p>Which is generated using\
    \ the files in the <code>doc</code> directory.</p>\n<h1><a id=\"user-content-development\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Development</h1>\n<p>We welcome\
    \ all contributions.\nThe main development repository is at GitHub:</p>\n<p><a\
    \ href=\"https://github.com/lfortran/lfortran\">https://github.com/lfortran/lfortran</a></p>\n\
    <p>Please send Pull Requests (PRs) and open issues there.</p>\n<p>See the <a href=\"\
    CONTRIBUTING.md\">CONTRIBUTING</a> document for more information.</p>\n<p>Main\
    \ mailinglist:</p>\n<p><a href=\"https://groups.io/g/lfortran\" rel=\"nofollow\"\
    >https://groups.io/g/lfortran</a></p>\n<p>You can also chat with us on Zulip (<a\
    \ href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/11e6556bfe778e7cf7331cac9c44bd0616062722036cc0d9bb0b7909aaae8779/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\"\
    \ alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\"\
    \ style=\"max-width: 100%;\"></a>).</p>\n<p>Note: We moved to the above GitHub\
    \ repository from GitLab on July 18, 2022.</p>\n<h1><a id=\"user-content-donations\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#donations\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Donations</h1>\n<p>You can support\
    \ LFortran's development by donating to NumFOCUS or Open\nCollective as well as\
    \ GitHub Sponsors:</p>\n<ul>\n<li><a href=\"https://numfocus.org/donate-to-lfortran\"\
    \ rel=\"nofollow\">https://numfocus.org/donate-to-lfortran</a></li>\n<li><a href=\"\
    https://opencollective.com/lfortran\" rel=\"nofollow\">https://opencollective.com/lfortran</a></li>\n\
    <li><a href=\"https://github.com/sponsors/lfortran\">https://github.com/sponsors/lfortran</a></li>\n\
    </ul>\n<p>All donations will be used strictly to fund LFortran development, by\
    \ supporting\ntasks such as paying developers to implement features, sprints,\
    \ improved\ndocumentation, fixing bugs, etc.</p>\n<p>The donations to LFortran\
    \ are managed by the NumFOCUS foundation. NumFOCUS is a\n501(c)3 non-profit foundation,\
    \ so if you are subject to US Tax law, your\ncontributions will be tax-deductible.</p>\n\
    <p>If you want to discuss another way to fund or help with the development, feel\n\
    free to contact Ond\u0159ej \u010Cert\xEDk (<a href=\"mailto:ondrej@certik.us\"\
    >ondrej@certik.us</a>).</p>\n<h1><a id=\"user-content-star-history\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#star-history\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Star History</h1>\n<p><a href=\"https://star-history.com/#lfortran/lfortran&amp;Date\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7e19634671b985a40376628d5d76d76ef6baf79368e0c4b6a409523464e705b7/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c666f727472616e2f6c666f727472616e26747970653d44617465\"\
    \ alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=lfortran/lfortran&amp;type=Date\"\
    \ style=\"max-width: 100%;\"></a></p>\n"
  stargazers_count: 585
  subscribers_count: 18
  topics:
  - fortran
  - interactive
  - compiler
  - library
  - repl
  - jupyter
  - jupyter-notebook
  - jupyter-kernels
  updated_at: 1681822643.0
ma595/fenics-csd3-spack:
  data_format: 2
  description: Set up fenics spack on csd3
  filenames:
  - spack-icelake.yaml
  full_name: ma595/fenics-csd3-spack
  latest_release: null
  readme: '<h1><a id="user-content-fenics-csd3-spack" class="anchor" aria-hidden="true"
    href="#fenics-csd3-spack"><span aria-hidden="true" class="octicon octicon-link"></span></a>fenics-csd3-spack</h1>

    <p>Follow instructions in icelake-spack-env.sh</p>

    <p>Or, copy existing <code>spack.yaml</code> files into cloned Spack repo. It
    is necessary to <code>module purge</code> environment first, otherwise the prepend
    path inside <code>spack.yaml</code> will lead to duplications.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1667830944.0
mayrmt/spack_environments:
  data_format: 2
  description: A set of spack environemts for some of my projects
  filenames:
  - env_4c/spack.yaml
  - env_baci/spack.yaml
  - env_trilinos/spack.yaml
  full_name: mayrmt/spack_environments
  latest_release: null
  readme: '<h1><a id="user-content-a-set-of-spack-environemts" class="anchor" aria-hidden="true"
    href="#a-set-of-spack-environemts"><span aria-hidden="true" class="octicon octicon-link"></span></a>A
    set of spack environemts</h1>

    <h2><a id="user-content-purpose-and-intention" class="anchor" aria-hidden="true"
    href="#purpose-and-intention"><span aria-hidden="true" class="octicon octicon-link"></span></a>Purpose
    and intention</h2>

    <p>While this collection of <code>spack.yaml</code> files is mainly inteded for
    my personal use

    to setup <code>spack</code> environments for the development of various software
    projects,

    some of them might actually useful for my colleages or even a broader community.</p>

    <h2><a id="user-content-using-this-repository-to-setup-spack-environment" class="anchor"
    aria-hidden="true" href="#using-this-repository-to-setup-spack-environment"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using this repository
    to setup <code>spack</code> environment</h2>

    <p>In order to create a named environment <code>&lt;myEnv&gt;</code> based on
    a give <code>spack.yaml</code> file

    located at <code>&lt;path/to/environment/spack.yaml&gt;</code>, perform the following
    steps:</p>

    <ol>

    <li>Clone the <a href="https://github.com/spack/spack"><code>spack</code> repository</a>:
    <code>git clone git@github.com:spack/spack.git</code>

    </li>

    <li>Clone this repository: <code>git clone git@github.com:mayrmt/spack_environments.git</code>

    </li>

    <li>Activate spack in your terminal</li>

    <li>Create a named environment: <code>spack env create &lt;myEnv&gt; &lt;path/to/environment/spack.yaml&gt;</code>

    </li>

    </ol>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Feedback and contributions are welcome!

    Just open an <a href="https://github.com/mayrmt/spack_environments/issues">issue</a>

    or <a href="https://github.com/mayrmt/spack_environments/pulls">pull request</a>

    in the <a href="https://github.com/mayrmt/spack_environments">GitHub repository</a>.

    Thank you!</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1634191144.0
mochi-hpc-experiments/colza-experiments:
  data_format: 2
  description: Experiments using Colza for In Situ Analysis
  filenames:
  - ubuntu/amr-wind/spack.yaml
  full_name: mochi-hpc-experiments/colza-experiments
  latest_release: ipdps2022
  readme: '<h1><a id="user-content-colza-experiments" class="anchor" aria-hidden="true"
    href="#colza-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Colza
    Experiments</h1>

    <p>This repository contains scripts to reproduce experiments

    related to the Colza elastic in situ analysis framework.

    These experiments were run on the Cori supercomputer.</p>

    <p>Each subfolder contains a README file explaining what the

    experiment in the subfolder does, how to install its

    dependencies, and how to run it.</p>

    <p>The ubuntu folder contains scripts that allow reproducing

    the most experiments on a single Linux workstation or a

    cluster of Linux machines.</p>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1655200495.0
mochi-hpc-experiments/mochi-xfer-benchmark:
  data_format: 2
  description: Mochi transfer benchmark
  filenames:
  - spack.yaml
  full_name: mochi-hpc-experiments/mochi-xfer-benchmark
  latest_release: null
  readme: '<h1><a id="user-content-mochi-xfer-benchmark" class="anchor" aria-hidden="true"
    href="#mochi-xfer-benchmark"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    Xfer Benchmark</h1>

    <p>This benchmark is specifically designed to answer one question:

    what is the best way to transfer N bytes from a client to a server

    in Mochi, on a given platform? Its tests includes relying on RPC

    arguments, registering a different buffer at every operation for

    RDMA, or re-using a preregistered buffer (which for clients

    means copying the payload to it).</p>

    <h2><a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h2>

    <p>This program can be installed using spack, provided that you have

    the <a href="https://github.com/mochi-hpc/mochi-spack-packages">Mochi repository</a>

    added to your spack installation.</p>

    <pre><code>$ spack install mochi-xfer-benchmark

    </code></pre>

    <h2><a id="user-content-using-the-benchmark" class="anchor" aria-hidden="true"
    href="#using-the-benchmark"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    the benchmark</h2>

    <p>Once installed, the <code>mochi-xfer-benchmark</code> can be used as a two-process

    MPI program. It provides the following options:</p>

    <ul>

    <li>

    <code>-p/--protocol</code> (required): protocol to use (<code>na+sm</code>, <code>ofi+tcp</code>,
    etc.).</li>

    <li>

    <code>-o/--output</code> (required): name of the output CSV file.</li>

    <li>

    <code>-i/--iterations</code>: number of repetitions of each operation.</li>

    <li>

    <code>-c/--client-protocol</code>: protocol for the client to use, if different

    from that of the server.</li>

    <li>

    <code>-v/--verbose</code>: logging level (trace, debug, info, warning, error,
    critical, off).</li>

    <li>

    <code>--client-use-progress-thread</code>: if provided, the client will use a
    dedicated

    progress thread.</li>

    <li>

    <code>--server-use-progress-thread</code>: if provided, the server will use a
    dedicated

    progress thread.</li>

    <li>

    <code>--server-num-handler-threads</code>: number of handler threads (0, 1, or
    -1).

    With 0, RPCs will execute in the primary ES. With 1, they will execute in

    a dedicated ES. With -1, they will execute in the ES in which the progress

    loop runs.</li>

    <li>The remaining, non-labelled arguments forms the list of transfer sizes.</li>

    </ul>

    <p>The benchmark will output a CSV file containing the results of the following

    operations. "Send" and "Receive" are understood from the point of view of the

    server (e.g. <code>recv-args</code> means that the server will receive the payload
    via

    RPC arguments).</p>

    <h3><a id="user-content-recv-args" class="anchor" aria-hidden="true" href="#recv-args"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>recv-args</h3>

    <p>The client sends the payload as an RPC argument.</p>

    <h3><a id="user-content-recv-rdma-xy" class="anchor" aria-hidden="true" href="#recv-rdma-xy"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>recv-rdma-(x,y)</h3>

    <p>The server uses RDMA PULL to get the payload from the client.</p>

    <p><code>x</code> may be <code>new</code> (new registration) or <code>pre</code>
    (pre-registered bulk).

    In the former case, the client creates a bulk handle to expose its

    payload at every iteration. In the latter case, the client uses a

    pre-allocated buffer and pre-registered bulk handle, and does a

    <code>memcpy</code> of its payload in this buffer prior to sending the RPC.</p>

    <p>Similarly <code>y</code> may be <code>new</code> or <code>pre</code>. In the
    former case, at every

    operation the server will allocate a new buffer and register it

    before doing a PULL. In the latter case, the server will rely on

    a pre-allocated buffer and a corresponding pre-registered bulk

    handle. No memcpy is performed in this case.</p>

    <h3><a id="user-content-send-resp" class="anchor" aria-hidden="true" href="#send-resp"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>send-resp</h3>

    <p>The server sends its payload as an RPC response.</p>

    <h3><a id="user-content-send-rdma-xy" class="anchor" aria-hidden="true" href="#send-rdma-xy"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>send-rdma-(x,y)</h3>

    <p>The server uses RDMA PUSH to send its payload to the client.</p>

    <p><code>x</code> may be <code>new</code> or <code>pre</code>. In the former case,
    the client creates

    a bulk handle to expose the buffer in which it wants the data to

    be placed. In the latter case, it relies on a pre-allocated buffer

    and associated pre-registered bulk handle, and does a memcpy once

    the data has arrived.</p>

    <p>Similarly, <code>y</code> may be <code>new</code> or <code>pre</code>. In the
    former case, at every

    operation the server allocates a new buffer and registers it

    before doing a PUSH. In the latter case, the server will rely on

    a pre-allocated buffer and a corresponding pre-registered bulk

    handle.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1637930437.0
mochi-hpc-experiments/mona-benchmarking:
  data_format: 2
  description: Mona benchmarking
  filenames:
  - bebop/spack.yaml
  full_name: mochi-hpc-experiments/mona-benchmarking
  latest_release: null
  readme: '<h1><a id="user-content-mona-benchmarking" class="anchor" aria-hidden="true"
    href="#mona-benchmarking"><span aria-hidden="true" class="octicon octicon-link"></span></a>MoNA
    benchmarking</h1>

    <p>This repository contains scripts to run the MoNA benchmarks on various

    supercomputing platforms.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1629225591.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - ORNL/Crusher/spack.yaml
  - generic/spack.yaml
  - ANL/JLSE/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" href="#platform-configurations-for-mochi"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Platform configurations for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    href="#using-spackyaml-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    href="#contributing-to-this-repository"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1677790084.0
mochi-hpc/flamestore:
  data_format: 2
  description: Storage system for Deep Learning models designed using the Mochi components.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/flamestore
  latest_release: null
  readme: '<h1><a id="user-content-what-is-flamestore" class="anchor" aria-hidden="true"
    href="#what-is-flamestore"><span aria-hidden="true" class="octicon octicon-link"></span></a>What
    is FlameStore?</h1>

    <p>FlameStore is a Mochi component to access Keras deep learning models

    and store them in various backends (right now: in memory, on a local

    file system, or on a composition of SDSKV and BAKE providers).</p>

    <p>FlameStore is developped by Matthieu Dorier (<a href="mailto:mdorier@anl.gov">mdorier@anl.gov</a>).

    More information on how to install and use is available

    <a href="https://xgitlab.cels.anl.gov/sds/flamestore/wikis/home" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 1
  subscribers_count: 4
  topics: []
  updated_at: 1633975412.0
mochi-hpc/mochi-bake:
  data_format: 2
  description: A microservice (i.e., Mochi provider) for high performance bulk storage
    of raw data regions
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-bake
  latest_release: v0.6.4
  readme: "<h1><a id=\"user-content-bake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #bake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bake</h1>\n\
    <p>Bake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage\
    \ of raw data regions.  Bake uses modular backends to store data\non persistent\
    \ memory, conventional file systems, or other storage media.</p>\n<p>See <a href=\"\
    https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a>\
    \ and\n<a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a>\
    \ for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively\
    \ to data storage.  Capabilities such as\nindexing, name spaces, and sharding\
    \ must be provided by other microservice\ncomponents.</p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The easiest\
    \ way to install Bake is through spack:</p>\n<p><code>spack install bake</code></p>\n\
    <p>This will install BAKE and its dependencies.  Please refer to the end of the\n\
    document for manual compilation instructions.</p>\n<h2><a id=\"user-content-architecture\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#architecture\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>Like most\
    \ Mochi services, BAKE relies on a client/provider architecture.\nA provider,\
    \ identified by its <em>address</em> and <em>multiplex id</em>, manages one or\
    \ more\n<em>BAKE targets</em>, referenced externally by their <em>target id</em>.</p>\n\
    <p>A target can be thought of as a storage device.  This may be (for example)\
    \ a\nPMDK volume or a local file system.</p>\n<h2><a id=\"user-content-setting-up-a-bake-target\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-a-bake-target\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up a\
    \ BAKE target</h2>\n<p>BAKE requires the backend storage file to be created beforehand\
    \ using\n<code>bake-mkpool</code>. For instance:</p>\n<p><code>bake-mkpool -s\
    \ 500M /dev/shm/foo.dat</code></p>\n<p>creates a 500 MB file at <em>/dev/shm/foo.dat</em>\
    \ to be used by BAKE as a target.\nBake will use the <code>pmem</code> (persistent\
    \ memory) backend by default, which means\nthat the underlying file will memory\
    \ mapped for access usign the PMDK\nlibrary.  You can also providie an explicit\
    \ prefix (such as <code>file:</code> for the\nconventional file backend or <code>pmem:</code>\
    \ for the persistent memory backend) to\ndictate a specific target type.</p>\n\
    <h2><a id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#starting-a-daemon\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Starting a daemon</h2>\n<p>BAKE ships with a default daemon program\
    \ that can setup providers and attach\nto storage targets. This daemon can be\
    \ started as follows:</p>\n<p><code>bake-server-daemon [options] &lt;listen_address&gt;\
    \ &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n<p>The program takes\
    \ a set of options followed by an address at which to listen for\nincoming RPCs,\
    \ and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n\
    <p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234\
    \ /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n\
    <ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the\
    \ address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em>\
    \ or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates\
    \ that, if multiple BAKE targets are used (as above),\nthese targets should be\
    \ managed by multiple providers, accessible through\ndifferent multiplex ids 1,\
    \ 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage.\
    \ The <em>targets</em> mode indicates that a single provider should be used to\n\
    manage all the storage targets.</p>\n<h2><a id=\"user-content-integrating-bake-into-a-larger-service\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#integrating-bake-into-a-larger-service\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Integrating\
    \ Bake into a larger service</h2>\n<p>Bake is not intended to be a standalone\
    \ user-facing service.  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\"\
    \ rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for\
    \ guidance on how to\nintegrate it with other providers using Mochi's Bedrock\
    \ capability.</p>\n<h2><a id=\"user-content-client-api-example\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#client-api-example\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Client API example</h2>\n<p>Data is\
    \ stored in <code>regions</code> within a <code>target</code> using explicit create,\n\
    write, and persist operations.  The caller cannot dictate the region id\nthat\
    \ will be used to reference a region; this identifier is generated\nby Bake at\
    \ creation time.  The region size must be specified at creation\ntime as well;\
    \ there is no mechanism for extending the size of an existing\nregion.</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>bake-client.h<span class=\"\
    pl-pds\">&gt;</span></span>\n\n<span class=\"pl-k\">int</span> <span class=\"\
    pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\"\
    >char</span> **argv)\n{\n    <span class=\"pl-k\">char</span> *svr_addr_str; <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> string address of the BAKE server</span>\n\
    \    <span class=\"pl-c1\">hg_addr_t</span> svr_addr; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> Mercury address of the BAKE server</span>\n    margo_instance_id\
    \ mid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> Margo instance id</span>\n\
    \    <span class=\"pl-c1\">bake_client_t</span> bcl; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> BAKE client</span>\n    <span class=\"pl-c1\">bake_provider_handle_t</span>\
    \ bph; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE handle to provider</span>\n\
    \    <span class=\"pl-c1\">uint8_t</span> mplex_id; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> multiplex id of the provider</span>\n    <span class=\"\
    pl-c1\">uint32_t</span> target_number; <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> target to use</span>\n    <span class=\"pl-c1\">bake_region_id_t</span>\
    \ rid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE region id handle</span>\n\
    \t<span class=\"pl-c1\">bake_target_id_t</span>* bti; <span class=\"pl-c\"><span\
    \ class=\"pl-c\">//</span> array of target ids</span>\n\n\t<span class=\"pl-c\"\
    ><span class=\"pl-c\">/*</span> ... setup variables ... <span class=\"pl-c\">*/</span></span>\n\
    \n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Initialize Margo <span\
    \ class=\"pl-c\">*/</span></span>\n\tmid = <span class=\"pl-c1\">margo_init</span>(...,\
    \ MARGO_CLIENT_MODE, <span class=\"pl-c1\">0</span>, -<span class=\"pl-c1\">1</span>);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Lookup the server <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_lookup</span>(mid,\
    \ svr_addr_str, &amp;svr_addr);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span>\
    \ Creates the BAKE client <span class=\"pl-c\">*/</span></span>\n\t<span class=\"\
    pl-c1\">bake_client_init</span>(mid, &amp;bcl);\n\t<span class=\"pl-c\"><span\
    \ class=\"pl-c\">/*</span> Creates the provider handle <span class=\"pl-c\">*/</span></span>\n\
    \t<span class=\"pl-c1\">bake_provider_handle_create</span>(bcl, svr_addr, mplex_id,\
    \ &amp;bph);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Asks the provider\
    \ for up to target_number target ids <span class=\"pl-c\">*/</span></span>\n\t\
    <span class=\"pl-c1\">uint32_t</span> num_targets = <span class=\"pl-c1\">0</span>;\n\
    \tbti = <span class=\"pl-c1\">calloc</span>(num_targets, <span class=\"pl-k\"\
    >sizeof</span>(*bti));\n\t<span class=\"pl-c1\">bake_probe</span>(bph, target_number,\
    \ bti, &amp;num_targets);\n\t<span class=\"pl-k\">if</span>(num_targets &lt; target_number)\
    \ {\n\t\t<span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>Error: provider has only <span class=\"pl-c1\">%d</span>\
    \ storage targets<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>,\
    \ num_targets);\n\t}\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Create\
    \ a region <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">size_t</span>\
    \ size = ...; <span class=\"pl-c\"><span class=\"pl-c\">//</span> size of the\
    \ region to create</span>\n\t<span class=\"pl-c1\">bake_create</span>(bph, bti[target_number-<span\
    \ class=\"pl-c1\">1</span>], size, &amp;rid);\n\t<span class=\"pl-c\"><span class=\"\
    pl-c\">/*</span> Write data into the region at offset 0 <span class=\"pl-c\">*/</span></span>\n\
    \t<span class=\"pl-k\">char</span>* buf = ...;\n\t<span class=\"pl-c1\">bake_write</span>(bph,\
    \ rid, <span class=\"pl-c1\">0</span>, buf, size);\n\t<span class=\"pl-c\"><span\
    \ class=\"pl-c\">/*</span> Make all modifications persistent <span class=\"pl-c\"\
    >*/</span></span>\n\t<span class=\"pl-c1\">bake_persist</span>(bph, rid);\n\t\
    <span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release provider handle <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_provider_handle_release</span>(bph);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release BAKE client <span\
    \ class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_client_finalize</span>(bcl);\n\
    \t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Cleanup Margo resources\
    \ <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_free</span>(mid,\
    \ svr_addr);\n\t<span class=\"pl-c1\">margo_finalize</span>(mid);\n\t<span class=\"\
    pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n<p>Note that\
    \ a <code>bake_region_id_t</code> object is persistent.  It can be written\n(into\
    \ a file or a socket) and stored or sent to another program. These\nregion ids\
    \ are what uniquely reference a region within a given target.</p>\n<p>The rest\
    \ of the client-side API can be found in <code>bake-client.h</code>.</p>\n<h2><a\
    \ id=\"user-content-provider-api\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #provider-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider\
    \ API</h2>\n<p>The bake-server-daemon source is a good example of how to create\
    \ providers and\nattach storage targets to them. The provider-side API is located\
    \ in\n<em>bake-server.h</em>, and consists of mainly two functions:</p>\n<div\
    \ class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">bake_provider_register</span>(margo_instance_id      \
    \               mid,\n                           <span class=\"pl-c1\">uint16_t</span>\
    \                              provider_id,\n                           <span\
    \ class=\"pl-k\">const</span> <span class=\"pl-k\">struct</span> bake_provider_init_info*\
    \ args,\n                           <span class=\"pl-c1\">bake_provider_t</span>*\
    \                      provider);</pre></div>\n<p>This creates a provider at the\
    \ given provider id using the specified margo\ninstance.  The <code>args</code>\
    \ parameter can be used to modify default settings,\nincluding passing in a fully\
    \ specified json configuration block.  See\n<code>bake-server.h</code> for details.</p>\n\
    <div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span>\
    \ <span class=\"pl-en\">bake_provider_attach_target</span>(<span class=\"pl-c1\"\
    >bake_provider_t</span>   provider,\n                                <span class=\"\
    pl-k\">const</span> <span class=\"pl-k\">char</span>*       target_name,\n   \
    \                             <span class=\"pl-c1\">bake_target_id_t</span>* target_id);</pre></div>\n\
    <p>This makes the provider manage the given storage target.</p>\n<p>Other functions\
    \ are available to create and detach targets from a provider.</p>\n<h2><a id=\"\
    user-content-generic-bake-benchmark\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #generic-bake-benchmark\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Generic Bake benchmark</h2>\n<p>By using <code>--enable-benchmark</code>\
    \ when compiling Bake (or <code>+benchmark</code> when using Spack),\nyou will\
    \ build a <code>bake-benchmark</code> program that can be used as a configurable\
    \ benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure\
    \ Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n<p>The benchmark\
    \ is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a\
    \ server, while non-zero ranks act as clients. The server will not create\na Bake\
    \ target. The Bake target needs to be created (with <code>bake-makepool</code>)\
    \ beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing\
    \ the sequence\nof benchmarks to execute. An example of such a file is located\
    \ in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code>\
    \ array corresponds to a benchmark. The <code>type</code> field indicates\nthe\
    \ type of benchmark to execute. The <code>repetitions</code> field indicates how\
    \ many times the\nbenchmark should be repeated.</p>\n<p>The following table describes\
    \ each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n\
    <th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n\
    </tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or\
    \ range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n\
    <tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to\
    \ the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n\
    <td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions\
    \ after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n\
    <td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number\
    \ of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n\
    <td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for\
    \ each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n\
    <td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n\
    <td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's\
    \ buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n\
    <td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n\
    <td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n\
    <td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions,\
    \ or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n\
    <td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n\
    </tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether\
    \ to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n\
    <td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n\
    </tbody>\n</table>\n<h2><a id=\"user-content-manual-installation\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#manual-installation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Manual installation</h2>\n<p>BAKE\
    \ depends on the following libraries:</p>\n<ul>\n<li>uuid (install uuid-dev package\
    \ on ubuntu)</li>\n<li>PMDK (see instructions below)</li>\n<li>json-c</li>\n<li>mochi-abt-io</li>\n\
    <li>mochi-margo</li>\n</ul>\n<p>Bake will automatically identify these dependencies\
    \ at configure time using\npkg-config. To compile BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n\
    <li><code>mkdir build</code></li>\n<li><code>cd build</code></li>\n<li><code>../configure\
    \ --prefix=/home/carns/working/install</code></li>\n<li><code>make</code></li>\n\
    </ul>\n<p>If any dependencies are installed in a nonstandard location, then\n\
    modify the configure step listed above to include the following argument:</p>\n\
    <ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n\
    </ul>\n"
  stargazers_count: 0
  subscribers_count: 7
  topics: []
  updated_at: 1633975151.0
mochi-hpc/mochi-doc:
  data_format: 2
  description: Documentations and tutorials for Margo, Thallium, Argobots, Mercury,
    and other Mochi libraries.
  filenames:
  - code/spack.yaml
  full_name: mochi-hpc/mochi-doc
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"><img
    src="https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg"
    alt="build" style="max-width: 100%;"></a></p>

    <h1><a id="user-content-mochi-documentation" class="anchor" aria-hidden="true"
    href="#mochi-documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi
    documentation</h1>

    <p>This repository contains a Sphinx-based documentation

    for the Mochi libraries: Margo, Thallium, Argobots, Mercury,

    ABT-IO, and SSG, as well as corresponding code examples.</p>

    <h2><a id="user-content-building-the-documentation" class="anchor" aria-hidden="true"
    href="#building-the-documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the documentation</h2>

    <p>To build and/or contribute to this documentation, you must have a Sphinx and

    a few related extensions installed.  These can be installed as follows using

    Python''s <code>pip</code>.</p>

    <pre><code>pip install sphinx

    pip install sphinx_rtd_theme

    pip install sphinx_copybutton

    pip install recommonmark

    pip install breathe

    </code></pre>

    <p>You must also install the <code>doxygen</code> documentation system.  This
    is likely

    available in your platform''s primary package manager.  For example on Ubuntu:</p>

    <pre><code>sudo apt install doxygen

    </code></pre>

    <p>Once you have these dependencies installed, clone this

    repository and cd into it. You can change the documentation

    by editing the files in the source subdirectory (these files

    use the .rst format). You can build the documentation

    using the following command.</p>

    <pre><code>cd docs

    make html

    </code></pre>

    <p>And check the result by opening the <code>build/html/index.html</code> page

    that has been created in the docs directory.</p>

    <h2><a id="user-content-building-the-code-examples" class="anchor" aria-hidden="true"
    href="#building-the-code-examples"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the code examples</h2>

    <p>To build the code, you will need spack and the

    <a href="https://github.com/mochi-hpc/mochi-spack-packages">mochi repo</a> setup.</p>

    <pre><code>cd code

    spack env create mochi-doc-env spack.yaml

    spack env activate mochi-doc-env

    spack install

    mkdir build

    cd build

    cmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc

    make

    </code></pre>

    '
  stargazers_count: 4
  subscribers_count: 4
  topics: []
  updated_at: 1668505847.0
mochi-hpc/mochi-mona:
  data_format: 2
  description: Mochi messaging over NA
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-mona
  latest_release: v0.2.3
  readme: '<h1><a id="user-content-mona---messaging-over-na" class="anchor" aria-hidden="true"
    href="#mona---messaging-over-na"><span aria-hidden="true" class="octicon octicon-link"></span></a>MoNA
    - Messaging over NA</h1>

    <p>MoNA is a Mochi library combining the NA layer of Mercury with

    the Argobots threading library, in a way similar to how Margo

    combines Mercury with Argobots. It provides a low-level messaging

    interface and hides the NA progress loop into Argobots ULTs.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633974549.0
mochi-hpc/mochi-poesie:
  data_format: 2
  description: POESIE is a Mochi microservice designed to run interpreters of various
    scripting languages (currently Lua and Python) and make them accessible remotely.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-poesie
  latest_release: v0.2
  readme: "<h1><a id=\"user-content-poesie-embedding-scripting-languages-for-mochi-services\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#poesie-embedding-scripting-languages-for-mochi-services\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>POESIE:\
    \ Embedding Scripting Languages for Mochi Services</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>POESIE\
    \ can easily be installed using Spack:</p>\n<p><code>spack install mochi-poesie</code></p>\n\
    <p>This will install POESIE (and any required dependencies) with both\nPython\
    \ and Lua backends. Disabling one or the other can be done by\nappending <code>~lua</code>\
    \ or <code>~python</code>, for example:</p>\n<p><code>spack install poesie~lua</code></p>\n\
    <h2><a id=\"user-content-architecture\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#architecture\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Architecture</h2>\n<p>Like most mochi services, POESIE relies on a\
    \ client/provider architecture.\nA provider, identified by its <em>address</em>\
    \ and <em>provider id</em>, manages one or more\ninterpreters (called <em>virtual\
    \ machines</em>, or <em>VMs</em>), referenced externally\nby either their name\
    \ or their VM id.</p>\n<h2><a id=\"user-content-starting-a-daemon-using-bedrock\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#starting-a-daemon-using-bedrock\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting\
    \ a daemon using Bedrock</h2>\n<p>By installing POESIE with the <code>+bedrock</code>\
    \ variant, one can deploy a daemon\nby providing a JSON configuration like the\
    \ following to Bedrock.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\
    \    <span class=\"pl-ent\">\"libraries\"</span>: [\n        <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>libpoesie-bedrock-module.so<span class=\"pl-pds\"\
    >\"</span></span>\n    ],\n    <span class=\"pl-ent\">\"providers\"</span>: [\n\
    \        {\n            <span class=\"pl-ent\">\"name\"</span>: <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>my_poesie_provider<span class=\"pl-pds\"\
    >\"</span></span>,\n            <span class=\"pl-ent\">\"provider_id\"</span>:\
    \ <span class=\"pl-c1\">0</span>,\n            <span class=\"pl-ent\">\"config\"\
    </span>: {\n                <span class=\"pl-ent\">\"vms\"</span>: {\n       \
    \             <span class=\"pl-ent\">\"my_vm\"</span>: {\n                   \
    \     <span class=\"pl-ent\">\"language\"</span>: <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>python<span class=\"pl-pds\">\"</span></span>\n            \
    \        }\n                }\n            }\n        }\n    ]\n}</pre></div>\n\
    <h2><a id=\"user-content-client-api\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #client-api\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client\
    \ API</h2>\n<p>The client API is available in <em>poesie-client.h</em>.\nThe codes\
    \ in the <em>test</em> folder illustrate how to use it.</p>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975197.0
mochi-hpc/mochi-thallium:
  data_format: 2
  description: Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and
    providing an object-oriented way to use these libraries.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/mochi-thallium
  latest_release: v0.11.1
  readme: '<h1><a id="user-content-thallium" class="anchor" aria-hidden="true" href="#thallium"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Thallium</h1>

    <p>Thallium is a C++ interface to <a href="https://github.com/mochi-hpc/mochi-margo/">Margo</a>.

    It offers a modern, object-oriented way of developing HPC data services. More

    information can be found on <a href="https://mochi.readthedocs.io/en/latest/"
    rel="nofollow">Mochi''s readthedocs</a>

    website.</p>

    '
  stargazers_count: 9
  subscribers_count: 4
  topics: []
  updated_at: 1675839350.0
mochi-hpc/py-mochi-bedrock:
  data_format: 2
  description: Python interface for Mochi's Bedrock service.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-bedrock
  latest_release: v0.2
  readme: '<h1><a id="user-content-py-bedrock" class="anchor" aria-hidden="true" href="#py-bedrock"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Py-Bedrock</h1>

    <p>Py-Bedrock providers Python utilities to configure and deploy Mochi-based

    services using Python.</p>

    <h2><a id="user-content-running-the-jupyter-demo" class="anchor" aria-hidden="true"
    href="#running-the-jupyter-demo"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Jupyter demo</h2>

    <p>Create a spack environment and add the required packages in it.</p>

    <pre><code>spack env create py-bedrock-demo

    spack env activate py-bedrock-demo

    spack add py-mochi-bedrock

    spack add py-jupyterlab-server

    spack install

    </code></pre>

    <p>Deactivate and re-activate the environment for the PYTHONPATH variable to

    be updated.</p>

    <pre><code>spack env deactivate

    spack env activate py-bedrock-demo

    </code></pre>

    <p>Run the Jupyter server.</p>

    <pre><code>jupyter notebook --ip 0.0.0.0 --port 8888

    </code></pre>

    <p>Then from your browser, open the <code>notebooks/Demo.ipynb</code> notebook,

    and start playing!</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1641579587.0
mochi-hpc/py-mochi-margo:
  data_format: 2
  description: Python wrapper for Margo. Can be used to prototype Margo services in
    Python.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-margo
  latest_release: v0.5.2
  readme: "<h1><a id=\"user-content-py-margo\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#py-margo\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Py-Margo</h1>\n<p>Py-Margo provides a Python wrapper on top of <a\
    \ href=\"https://xgitlab.cels.anl.gov/sds/margo\" rel=\"nofollow\">Margo</a>.\n\
    It enables one to develop Margo-based service in Python.</p>\n<h2><a id=\"user-content-dependencies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>margo\
    \ (and its dependencies)</li>\n<li>python</li>\n<li>pybind11</li>\n<li>py-pkgconfig</li>\n\
    </ul>\n<h2><a id=\"user-content-installing\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#installing\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installing</h2>\n<p>The easiest way to install Py-Margo is to use\
    \ <a href=\"https://spack.io/\" rel=\"nofollow\">spack</a>.\nFollow the instructions\
    \ <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">here</a>\n\
    to add the <code>sds</code> namespace and its packages (instal spack first, if\
    \ needed).\nThen type:</p>\n<pre><code>spack install py-margo\n</code></pre>\n\
    <p>Once installed, you need the py-margo package (and its dependencies) to\nbe\
    \ loaded to use it.</p>\n<h2><a id=\"user-content-examples\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#examples\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Examples</h2>\n<h3><a id=\"user-content-basic-example\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#basic-example\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Basic example</h3>\n<p>The following\
    \ is an example of provider programmed in Python.\nLet's put is in a file <code>server.py</code>.\n\
    The provider listens to an address on a given multiple id (here 42).\nWhenever\
    \ it receives an RPC, it prints \"Hello from\" and the name sent\nby the client,\
    \ then sends the \"Hi \"+name+\"!\" string back to the client,\nand finally terminates.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">pymargo</span>.<span class=\"pl-s1\">core</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-v\">Engine</span>, <span class=\"pl-v\">Provider</span>\n\
    \n<span class=\"pl-k\">class</span> <span class=\"pl-v\">HelloProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>(<span class=\"pl-s1\">engine</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\"\
    >register</span>(<span class=\"pl-s\">\"say_hello\"</span>, <span class=\"pl-s\"\
    >\"hello\"</span>)\n\n\t<span class=\"pl-k\">def</span> <span class=\"pl-en\"\
    >hello</span>(<span class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>,\
    \ <span class=\"pl-s1\">name</span>):\n\t\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Hello from \"</span><span class=\"pl-c1\">+</span><span class=\"\
    pl-s1\">name</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"pl-s\"\
    >\"RPC id is \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">handle</span>.<span class=\"pl-en\">get_id</span>()))\n\t\t\
    <span class=\"pl-s1\">handle</span>.<span class=\"pl-en\">respond</span>(<span\
    \ class=\"pl-s\">\"Hi \"</span><span class=\"pl-c1\">+</span><span class=\"pl-s1\"\
    >name</span><span class=\"pl-c1\">+</span><span class=\"pl-s\">\"!\"</span>)\n\
    \t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-en\">get_engine</span>().<span\
    \ class=\"pl-en\">finalize</span>()\n\n<span class=\"pl-k\">def</span> <span class=\"\
    pl-v\">WhenFinalize</span>():\n\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Finalize was called\"</span>)\n\n<span class=\"pl-s1\">engine</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Engine</span>(<span class=\"\
    pl-s\">'tcp'</span>)\n<span class=\"pl-s1\">provider_id</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"Server running at address \"</span> <span class=\"pl-c1\">+</span>\
    \ <span class=\"pl-en\">str</span>(<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">addr</span>()) <span class=\"pl-c1\">+</span> <span class=\"pl-s\">\"\
    \ with provider_id \"</span> <span class=\"pl-c1\">+</span> <span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">provider_id</span>))\n\n<span class=\"pl-s1\"\
    >engine</span>.<span class=\"pl-en\">on_finalize</span>(<span class=\"pl-v\">WhenFinalize</span>)\n\
    <span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">HelloProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>The following code is the corresponding\
    \ client code (<code>client.py</code>).</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">sys</span>\n<span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">pymargo</span>\n<span class=\"\
    pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"pl-s1\"\
    >core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">name</span>):\n\t<span class=\"pl-s1\">addr</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">lookup</span>(<span\
    \ class=\"pl-s1\">addr_str</span>)\n\t<span class=\"pl-s1\">handle</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">create_handle</span>(<span class=\"pl-s1\">addr</span>, <span class=\"\
    pl-s1\">rpc_id</span>)\n\t<span class=\"pl-k\">return</span> <span class=\"pl-s1\"\
    >handle</span>.<span class=\"pl-en\">forward</span>(<span class=\"pl-s1\">provider_id</span>,\
    \ <span class=\"pl-s1\">name</span>)\n\n<span class=\"pl-k\">with</span> <span\
    \ class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span class=\"\
    pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span> <span class=\"\
    pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">engine</span>.<span class=\"pl-en\">register</span>(<span\
    \ class=\"pl-s\">\"say_hello\"</span>)\n\t<span class=\"pl-s1\">ret</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"\
    pl-c1\">3</span>]))\n\t<span class=\"pl-en\">print</span>(<span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n<p>First, run the\
    \ server on a new terminal:</p>\n<pre><code>python server.py\n</code></pre>\n\
    <p>This will output something like</p>\n<pre><code>Server running at address ofi+sockets://10.0.2.15:39151\
    \ with provider_id=42\n</code></pre>\n<p>Then run the client on a new terminal:</p>\n\
    <pre><code>python client.py ofi+sockets://10.0.2.15:39151 42 Matthieu\n</code></pre>\n\
    <h3><a id=\"user-content-sendingreceiving-python-objects\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#sendingreceiving-python-objects\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Sending/receiving Python objects</h3>\n<p>The\
    \ example above shows the basic principles of Py-Margo.\nPy-Margo's RPC always\
    \ use a string as input and respond with a string.\nYet this is sufficient to\
    \ cover any use-cases you may have: Python\nindeed comes with a serialization\
    \ package, <code>pickle</code>, that can take\ncare of converting almost any Python\
    \ object from/to a string.</p>\n<p>Let us assume we have a file named <code>mymaths.py</code>\
    \ which contains the\nfollowing definition of a point in 3D.</p>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span\
    \ class=\"pl-v\">Point</span>():\n\t<span class=\"pl-k\">def</span> <span class=\"\
    pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>,<span class=\"pl-s1\"\
    >x</span>,<span class=\"pl-s1\">y</span>,<span class=\"pl-s1\">z</span>):\n\t\t\
    <span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">x</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">x</span>\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">y</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\"\
    >y</span>\n\t\t<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">z</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">z</span>\n\t<span class=\"\
    pl-k\">def</span> <span class=\"pl-en\">__str__</span>(<span class=\"pl-s1\">self</span>):\n\
    \t\t<span class=\"pl-k\">return</span> <span class=\"pl-s\">'Point ('</span><span\
    \ class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\"\
    >self</span>.<span class=\"pl-s1\">x</span>)<span class=\"pl-c1\">+</span><span\
    \ class=\"pl-s\">','</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">self</span>.<span class=\"pl-s1\">y</span>)<span\
    \ class=\"pl-c1\">+</span><span class=\"pl-s\">','</span><span class=\"pl-c1\"\
    >+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-s1\">z</span>)<span class=\"pl-c1\">+</span><span class=\"pl-s\"\
    >')'</span></pre></div>\n<p>Then here is a server that can compute a cross product\
    \ on two points sent by\na client.</p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Engine</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span\
    \ class=\"pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"\
    pl-v\">Provider</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\"\
    >mymaths</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n\
    <span class=\"pl-k\">import</span> <span class=\"pl-s1\">pickle</span>\n\n<span\
    \ class=\"pl-k\">class</span> <span class=\"pl-v\">VectorMathProvider</span>(<span\
    \ class=\"pl-v\">Provider</span>):\n\n\t<span class=\"pl-k\">def</span> <span\
    \ class=\"pl-en\">__init__</span>(<span class=\"pl-s1\">self</span>, <span class=\"\
    pl-s1\">engine</span>, <span class=\"pl-s1\">provider_id</span>):\n\t\t<span class=\"\
    pl-en\">super</span>().<span class=\"pl-en\">__init__</span>(<span class=\"pl-s1\"\
    >engine</span>, <span class=\"pl-s1\">provider_id</span>)\n\t\t<span class=\"\
    pl-s1\">self</span>.<span class=\"pl-en\">register</span>(<span class=\"pl-s\"\
    >\"cross_product\"</span>, <span class=\"pl-s\">\"cross_product\"</span>)\n\n\t\
    <span class=\"pl-k\">def</span> <span class=\"pl-en\">cross_product</span>(<span\
    \ class=\"pl-s1\">self</span>, <span class=\"pl-s1\">handle</span>, <span class=\"\
    pl-s1\">args</span>):\n\t\t<span class=\"pl-s1\">points</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">loads</span>(<span\
    \ class=\"pl-s1\">args</span>)\n\t\t<span class=\"pl-en\">print</span>(<span class=\"\
    pl-s\">\"Received: \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\"\
    >str</span>(<span class=\"pl-s1\">points</span>))\n\t\t<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span> <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">0</span>].<span class=\"pl-s1\">z</span><span class=\"pl-c1\"\
    >*</span><span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span\
    \ class=\"pl-s1\">y</span>\n\t\t<span class=\"pl-s1\">y</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">z</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\
    \ <span class=\"pl-c1\">-</span> <span class=\"pl-s1\">points</span>[<span class=\"\
    pl-c1\">0</span>].<span class=\"pl-s1\">x</span><span class=\"pl-c1\">*</span><span\
    \ class=\"pl-s1\">points</span>[<span class=\"pl-c1\">1</span>].<span class=\"\
    pl-s1\">z</span>\n\t\t<span class=\"pl-s1\">z</span> <span class=\"pl-c1\">=</span>\
    \ <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span class=\"\
    pl-s1\">x</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\">points</span>[<span\
    \ class=\"pl-c1\">1</span>].<span class=\"pl-s1\">y</span> <span class=\"pl-c1\"\
    >-</span> <span class=\"pl-s1\">points</span>[<span class=\"pl-c1\">0</span>].<span\
    \ class=\"pl-s1\">y</span><span class=\"pl-c1\">*</span><span class=\"pl-s1\"\
    >points</span>[<span class=\"pl-c1\">1</span>].<span class=\"pl-s1\">x</span>\n\
    \t\t<span class=\"pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Point</span>(<span class=\"pl-s1\">x</span>,<span class=\"pl-s1\">y</span>,<span\
    \ class=\"pl-s1\">z</span>)\n\t\t<span class=\"pl-s1\">handle</span>.<span class=\"\
    pl-en\">respond</span>(<span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >dumps</span>(<span class=\"pl-s1\">res</span>))\n\t\t<span class=\"pl-s1\">self</span>.<span\
    \ class=\"pl-en\">get_engine</span>().<span class=\"pl-en\">finalize</span>()\n\
    \n<span class=\"pl-s1\">engine</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>)\n<span class=\"pl-s1\"\
    >provider_id</span> <span class=\"pl-c1\">=</span> <span class=\"pl-c1\">42</span>\n\
    <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Server running at address\
    \ \"</span><span class=\"pl-c1\">+</span><span class=\"pl-en\">str</span>(<span\
    \ class=\"pl-s1\">mid</span>.<span class=\"pl-en\">addr</span>())<span class=\"\
    pl-c1\">+</span><span class=\"pl-s\">\"with provider_id=\"</span><span class=\"\
    pl-c1\">+</span><span class=\"pl-en\">str</span>(<span class=\"pl-s1\">provider_id</span>))\n\
    \n<span class=\"pl-s1\">provider</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-v\">VectorMathProvider</span>(<span class=\"pl-s1\">engine</span>, <span class=\"\
    pl-s1\">provider_id</span>)\n\n<span class=\"pl-s1\">engine</span>.<span class=\"\
    pl-en\">wait_for_finalize</span>()</pre></div>\n<p>And here is a client.</p>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span>\
    \ <span class=\"pl-s1\">sys</span>\n<span class=\"pl-k\">import</span> <span class=\"\
    pl-s1\">pymargo</span>\n<span class=\"pl-k\">import</span> <span class=\"pl-s1\"\
    >pickle</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-s1\">mymaths</span>\
    \ <span class=\"pl-k\">import</span> <span class=\"pl-v\">Point</span>\n<span\
    \ class=\"pl-k\">from</span> <span class=\"pl-s1\">pymargo</span>.<span class=\"\
    pl-s1\">core</span> <span class=\"pl-k\">import</span> <span class=\"pl-v\">Engine</span>\n\
    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">engine</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">addr_str</span>, <span class=\"pl-s1\">provider_id</span>, <span class=\"\
    pl-s1\">p1</span>, <span class=\"pl-s1\">p2</span>):\n\t<span class=\"pl-s1\"\
    >addr</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">engine</span>.<span\
    \ class=\"pl-en\">lookup</span>(<span class=\"pl-s1\">addr_str</span>)\n\t<span\
    \ class=\"pl-s1\">handle</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">engine</span>.<span class=\"pl-en\">create_handle</span>(<span class=\"\
    pl-s1\">addr</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"pl-s1\"\
    >provider_id</span>)\n\t<span class=\"pl-s1\">args</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\">dumps</span>([<span\
    \ class=\"pl-s1\">p1</span>,<span class=\"pl-s1\">p2</span>])\n\t<span class=\"\
    pl-s1\">res</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">handle</span>.<span\
    \ class=\"pl-en\">forward</span>(<span class=\"pl-s1\">args</span>)\n\t<span class=\"\
    pl-k\">return</span> <span class=\"pl-s1\">pickle</span>.<span class=\"pl-en\"\
    >loads</span>(<span class=\"pl-s1\">res</span>)\n\n<span class=\"pl-k\">with</span>\
    \ <span class=\"pl-v\">Engine</span>(<span class=\"pl-s\">'tcp'</span>, <span\
    \ class=\"pl-s1\">mode</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\"\
    >pymargo</span>.<span class=\"pl-s1\">client</span>) <span class=\"pl-k\">as</span>\
    \ <span class=\"pl-s1\">engine</span>:\n\t<span class=\"pl-s1\">rpc_id</span>\
    \ <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">mid</span>.<span class=\"\
    pl-en\">register</span>(<span class=\"pl-s\">\"cross_product\"</span>)\n\t<span\
    \ class=\"pl-s1\">p1</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >Point</span>(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span\
    \ class=\"pl-c1\">3</span>)\n\t<span class=\"pl-s1\">p2</span> <span class=\"\
    pl-c1\">=</span> <span class=\"pl-v\">Point</span>(<span class=\"pl-c1\">4</span>,<span\
    \ class=\"pl-c1\">5</span>,<span class=\"pl-c1\">6</span>)\n\t<span class=\"pl-s1\"\
    >ret</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">call_rpc_on</span>(<span\
    \ class=\"pl-s1\">mid</span>, <span class=\"pl-s1\">rpc_id</span>, <span class=\"\
    pl-s1\">sys</span>.<span class=\"pl-s1\">argv</span>[<span class=\"pl-c1\">1</span>],\
    \ <span class=\"pl-en\">int</span>(<span class=\"pl-s1\">sys</span>.<span class=\"\
    pl-s1\">argv</span>[<span class=\"pl-c1\">2</span>]), <span class=\"pl-s1\">p1</span>,\
    \ <span class=\"pl-s1\">p2</span>)\n\t<span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-en\">str</span>(<span class=\"pl-s1\">ret</span>))</pre></div>\n"
  stargazers_count: 2
  subscribers_count: 5
  topics: []
  updated_at: 1675190754.0
mochi-hpc/py-mochi-sonata:
  data_format: 2
  description: Python binding to the Mochi Sonata microservice.
  filenames:
  - spack.yaml
  full_name: mochi-hpc/py-mochi-sonata
  latest_release: null
  readme: '<p>Py-Sonata is a Python interface for the <a href="https://github.com/mochi-hpc/mochi-sonata">Sonata
    Mochi microservice</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633975502.0
mpbelhorn/olcf-spack-environments:
  data_format: 2
  description: Spack environments for OLCF resources.
  filenames:
  - hosts/frontier/envs/base/spack.yaml
  - hosts/afw/envs/base/spack.yaml
  - hosts/andes/envs/base/spack.yaml
  full_name: mpbelhorn/olcf-spack-environments
  latest_release: null
  readme: '<h1><a id="user-content-olcf-spack-environments" class="anchor" aria-hidden="true"
    href="#olcf-spack-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>OLCF
    Spack Environments</h1>

    <p>This repo contains the infrastructure and environment definitions to deploy

    site-provided software on OLCF resources via Spack environments.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting Started</h2>

    <p>Clone this repo and it''s facility-modified spack fork somewhere on an OLCF

    filesystem:</p>

    <pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git

    </code></pre>

    <p>or</p>

    <pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments

    </code></pre>

    <p>Next, initialize spack and the build environment. This is done by calling</p>

    <pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base
    . ./init-facility-spack.sh

    </code></pre>

    <p>This will configure the spack build- and run-time environment build and install

    the facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this
    repo for the

    current machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both
    of these

    variables are optional. If omitted, each variable will take on their default

    values:</p>

    <pre><code>FACSPACK_MY_ENVS="/sw/${_THIS_HOST}/spack-envs"

    FACSPACK_ENV_NAME="base"

    </code></pre>

    <p>such that sourcing this script by itself</p>

    <pre><code>. ./init-facility-spack.sh

    </code></pre>

    <p>will setup the runtime shell environment to manipulate the production spack

    environment on the current system.</p>

    <p>This repo will always track at least one spack environment per machine named

    <code>base</code> which is the complete standard software environment used in
    production

    for that machine. Furthermore, only the user account with owner permissions on

    the production environment may be used to manipulate it in the default

    <code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent
    multiple

    users from concurrently modifying the production environment. Users may set an

    alternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using
    any

    tracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file
    in this repo.</p>

    <p>From these variables, a unique path per each environment name will be

    constructed:</p>

    <pre><code>FACSPACK_ENV="${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}"

    </code></pre>

    <p>The value of <code>${_THIS_HOST}</code> is determined automatically from the
    hostname on

    which the init script is being run. For each system and environment tracked in

    this repo that you wish to work on, ensure that the final expanded value of

    <code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>

    <p>Configuration paths in our <code>spack.yaml</code> environments that are not
    fixed to

    universal values are expressed in terms of relative paths to either the spack

    instance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.

    These paths are referenced in the <code>spack.yaml</code> files via environment
    variables

    set by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code>
    environment files to

    define portable and relocatable spack environments which can be re-deployed in

    arbitrary private locations by any users without needing to modify the

    environment file.</p>

    <p>The following variables are exported in Spack''s runtime environment by

    <code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code>
    the enviornment

    files tracked in this repo.</p>

    <ul>

    <li>

    <code>${FACSPACK_ENV}</code>:

    Path to where spack environment will be installed. Contains subdirs <code>opt</code>

    and <code>modules</code>.</li>

    <li>

    <code>${FACSPACK_ENV_MODULEROOT}</code>:

    Shortcut to <code>${FACSPACK_ENV}/modules</code> under which static and

    spack-generated modules are generated. Contains subdirectories <code>spack</code>,

    <code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static
    modulefiles

    respectively.</li>

    <li>

    <code>${FACSPACK_CONF_COMMON}</code>:

    Path to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>

    <li>

    <code>${FACSPACK_CONF_HOST}</code>:

    Path to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>

    </li>

    </ul>

    <p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>

    files which cannot de-reference environment variables. These affect</p>

    <ul>

    <li>Mirrors</li>

    <li>Extensions</li>

    </ul>

    <p>Spack does not internally expand environment variables in the configuration
    of

    these items so they must be expressed as hard-coded full path strings. The

    default values in this repo should point to permanent world-readable paths on

    the OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>

    <h2><a id="user-content-spack-fork" class="anchor" aria-hidden="true" href="#spack-fork"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack Fork</h2>

    <p>The upstream development branch of spack is not used directly. Instead, the
    OLCF

    has implemented some customizations that are tracked in the "olcf-X.Y.Z"

    branches of a <a href="https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0">facility
    fork of spack</a>

    where <code>X.Y.Z</code> refers to the tagged release of upstream spack from which
    the

    OLCF-modified branch is forked.</p>

    '
  stargazers_count: 4
  subscribers_count: 2
  topics: []
  updated_at: 1662572646.0
nantes-m2-rps-exp/qqbar2mumu-2022:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: nantes-m2-rps-exp/qqbar2mumu-2022
  latest_release: null
  readme: "<h1><a id=\"user-content-projet-exp\xE9rimental---production-de-quarkonia\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#projet-exp\xE9rimental---production-de-quarkonia\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Projet exp\xE9\
    rimental - Production de quarkonia</h1>\n<blockquote>\n<p>Ce d\xE9pot git h\xE9\
    berge les fichiers n\xE9cessaires pour d\xE9marrer le projet \"Production de quarkonia\"\
    \ du Master 2 RPS de l'Universit\xE9 de Nantes. Il est principalement \xE0 destination\
    \ des \xE9tudiants qui r\xE9alisent ce projet. Le \"vous\" ci-dessous s'adresse\
    \ donc \xE0 ces \xE9tudiants.</p>\n</blockquote>\n<p>Pour ce projet le language\
    \ de programmation choisi est Python. Nous recommandons de l'utiliser par le biais\
    \ de <a href=\"https://jupyter.org\" rel=\"nofollow\">\"Notebooks Jupyter\"</a>\
    \ qui permettent de m\xE9langer le code, la documentation et les r\xE9sultats\
    \ de l'ex\xE9cution du code.</p>\n<p>Jupyter est un outil commun dans le domaine\
    \ de la science des donn\xE9es. Il y a bien des fa\xE7ons d'utiliser Jupyter et\
    \ de nombreux tutoriels sont disponibles en ligne pour aller plus loin, mais vous\
    \ trouverez ci-dessous trois m\xE9thodes pour d\xE9marrer :</p>\n<ol>\n<li>une\
    \ <a href=\"conda/README.md\">m\xE9thode locale bas\xE9e sur conda</a>\n</li>\n\
    <li>une <a href=\"cloud/README.md\">m\xE9thode cloud</a>\n</li>\n<li>une <a href=\"\
    multipass/README.md\">m\xE9thode locale bas\xE9e sur multipass</a>\n</li>\n</ol>\n\
    <p>A noter que seule la troisi\xE8me m\xE9thode permet, a priori, de r\xE9aliser\
    \ toutes les t\xE2ches n\xE9cessaires \xE0 ce projet, car elle offre des interfaces\
    \ Python de paquets C++ d\xE9velopp\xE9s sp\xE9cifiquement pour ce projet, alors\
    \ que les deux premi\xE8res ne permettent d'acc\xE9der qu'\xE0 des paquets Python\
    \ \"g\xE9n\xE9riques\". Les deux premi\xE8res m\xE9thodes permettent n\xE9anmoins\
    \ de d\xE9marrer assez rapidement.</p>\n<p>Pour ce projet, vous utiliserez \xE9\
    galement <a href=\"https://git.com\" rel=\"nofollow\">Git</a> et <a href=\"https://github.com\"\
    >GitHub</a>. Si ce n'est pas d\xE9j\xE0 le cas, il vous faudra <a href=\"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\"\
    \ rel=\"nofollow\">installer git sur votre machine</a> et vous <a href=\"https://fr.wikihow.com/cr%C3%A9er-un-compte-sur-GitHub\"\
    \ rel=\"nofollow\">cr\xE9\xE9r un compte GitHub</a>.</p>\n<p>Comme pour Jupyter,\
    \ un nombre important de ressources documentaires et tutoriels sont disponibles\
    \ sur le net pour commencer avec git si c'est votre premi\xE8re approche ou encore\
    \ pour approfondir votre ma\xEEtrise de cet outil si vous le connaissez d\xE9\
    j\xE0 un peu.</p>\n<p>Vous trouverez dans le <a href=\"git/README.md\">document\
    \ <code>git/README.md</code></a> les commandes de base pour d\xE9marrer avec ce\
    \ d\xE9p\xF4t git en particulier.</p>\n<p>Une fois la premi\xE8re installation\
    \ r\xE9alis\xE9e, commencez par vous familiariser avec Jupyter en utilisant le\
    \ <a href=\"notebooks/muon-eta-distribution.ipynb\">notebook d'exemple</a></p>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1667463557.0
nickrobison-usds/mobility-cpp:
  data_format: 2
  description: CPP port of mobility analysis project
  filenames:
  - spack.yaml
  full_name: nickrobison-usds/mobility-cpp
  latest_release: null
  readme: '<h1><a id="user-content-make-mobility-fast" class="anchor" aria-hidden="true"
    href="#make-mobility-fast"><span aria-hidden="true" class="octicon octicon-link"></span></a>Make
    Mobility Fast</h1>

    <p>Try to fix some issues with our python analysis and make it more performant.</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Setup</h2>

    <p>git submodule update --init --recursive

    vcpkg install geos tbb arrow range-v3 gdal</p>

    <h3><a id="user-content-cluster" class="anchor" aria-hidden="true" href="#cluster"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Cluster</h3>

    <h4><a id="user-content-cades" class="anchor" aria-hidden="true" href="#cades"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CADES</h4>

    <div class="highlight highlight-source-shell"><pre>module load PE-gnu/4.0

    spack env activate <span class="pl-c1">.</span>

    spack install

    cmake -B build/</pre></div>

    <h4><a id="user-content-cori" class="anchor" aria-hidden="true" href="#cori"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>CORI</h4>

    <div class="highlight highlight-source-shell"><pre>module swap PrgEnv-intel PrgEnv-cray

    spack env activate <span class="pl-c1">.</span>

    spack install

    cmake -DCMAKE_TOOLCHAIN_FILE=cmake/toolchains/Cori.cmake -B build/</pre></div>

    <h4><a id="user-content-theta" class="anchor" aria-hidden="true" href="#theta"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Theta</h4>

    <blockquote>

    <p>Note: We don''t currently support building with static linking (which is the
    default on Theta).</p>

    </blockquote>

    <div class="highlight highlight-source-shell"><pre><span class="pl-k">export</span>
    CRAYPE_LINK_TYPE=dynamic

    module swap craype-mic-knl craype-haswell

    module swap PrgEnv-intel PrgEnv-gnu

    spack env activate <span class="pl-c1">.</span>

    spack install

    module load cmake cray-jemalloc

    cmake -DCMAKE_TOOLCHAIN_FILE=cmake/toolchains/Theta.cmake -B build/ </pre></div>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    <span class="pl-k">~</span>/mobility-cpp

    <span class="pl-c1">.</span> /gpfs/mira-home/nickrobison/spack/share/spack/setup-env.sh

    spack env activate <span class="pl-c1">.</span></pre></div>

    <h3><a id="user-content-python" class="anchor" aria-hidden="true" href="#python"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Python</h3>

    <p>This repo contains a couple of helper Jupyter notebooks for testing ideas and
    building datasets.</p>

    <p>Setup is based on <code>virtualenv</code>, but Conda could be used just as
    easily.</p>

    <div class="highlight highlight-source-shell"><pre>pip3 install virtualenv

    virtualenv venv

    <span class="pl-c1">source</span> venv/bin/activate

    pip3 install -r requirements.txt</pre></div>

    <p>Start the notebook: <code>jupyter notebook python/</code></p>

    <p>Some of the notebooks are described here:</p>

    <h4><a id="user-content-join-locations" class="anchor" aria-hidden="true" href="#join-locations"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Join locations</h4>

    <p>This notebook builds the <code>Joined_POI.parquet</code> file which is used
    by some of the analysis applications.

    It requires the <code>core_poi.csv</code> files from Safegraph and the combined
    <code>block_groups.shp</code> file, which is built by combining all of the block
    group files from the Census bureau into a single file.</p>

    <p>The output should be placed in the <code>${DATA_DIR}/reference</code> directory.</p>

    <h4><a id="user-content-output-inspection" class="anchor" aria-hidden="true" href="#output-inspection"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Output Inspection</h4>

    <p>This notebook contains some helper cells for inspecting the output of the various
    analysis tools.</p>

    <h2><a id="user-content-reference-datasets" class="anchor" aria-hidden="true"
    href="#reference-datasets"><span aria-hidden="true" class="octicon octicon-link"></span></a>Reference
    datasets</h2>

    <p>The application makes use of a couple of reference datasets that need to be
    built, prior to launch.</p>

    <h3><a id="user-content-unified-census-block-file" class="anchor" aria-hidden="true"
    href="#unified-census-block-file"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unified
    Census Block file</h3>

    <h3><a id="user-content-joined_poi" class="anchor" aria-hidden="true" href="#joined_poi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Joined_POI</h3>

    <p>We need to join the Safegraph Core_POI dataset with unified Census Block file
    generated in the previous step.</p>

    <ol>

    <li>Download the entirety of the POI catalog from the</li>

    <li>Unzip and un-gzip the poi files.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>find <span class="pl-c1">.</span>
    -name <span class="pl-s"><span class="pl-pds">''</span>*.zip<span class="pl-pds">''</span></span>
    -exec sh -c <span class="pl-s"><span class="pl-pds">''</span>unzip -o -d "${0%.*}"
    "$0"<span class="pl-pds">''</span></span> <span class="pl-s"><span class="pl-pds">''</span>{}<span
    class="pl-pds">''</span></span> <span class="pl-s"><span class="pl-pds">''</span>;<span
    class="pl-pds">''</span></span>

    gunzip -r <span class="pl-c1">.</span></pre></div>

    <ol start="3">

    <li>Join them all together into a single, massive set of Parquet files.</li>

    </ol>

    '
  stargazers_count: 2
  subscribers_count: 2
  topics: []
  updated_at: 1605197303.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - cray-sles15-zen3/crusher/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_env/index.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2><a id="user-content-purpose" class="anchor" aria-hidden="true" href="#purpose"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 4
  subscribers_count: 19
  topics: []
  updated_at: 1670008521.0
onkarbpatil/IPDPS2020-benchmarks:
  data_format: 2
  description: null
  filenames:
  - SICM/spack.yaml
  full_name: onkarbpatil/IPDPS2020-benchmarks
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1591368300.0
onkarbpatil/sc20-benchmarks:
  data_format: 2
  description: All the codes and scripts are available in this repository.
  filenames:
  - SICM/spack.yaml
  full_name: onkarbpatil/sc20-benchmarks
  latest_release: sc2020v1.1
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1590882033.0
openPMD/openPMD-api:
  data_format: 2
  description: ':floppy_disk: C++ & Python API for Scientific I/O'
  filenames:
  - spack.yaml
  - .github/ci/spack-envs/clang7_nopy_nompi_h5_libcpp/spack.yaml
  full_name: openPMD/openPMD-api
  latest_release: 0.15.1
  readme: "<h1><a id=\"user-content-c--python-api-for-scientific-io-with-openpmd\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#c--python-api-for-scientific-io-with-openpmd\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ &amp;\
    \ Python API for Scientific I/O with openPMD</h1>\n<p><a href=\"https://github.com/openPMD/openPMD-standard/releases\"\
    ><img src=\"https://camo.githubusercontent.com/5957dc11cb68f6705ef9ef6683152c6c4fcc057a24dff340e1e8bada1bee0d01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\"\
    \ alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d54fa5adcf7ca50d2cdb45823be5064379b613d526fa06f6e193ba2ce616318/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\"\
    \ alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/f551141eea2176c34aa163092549d6fdde9a220d605d6efe9128b024c6e5932b/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\"\
    \ alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    ><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"\
    https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"\
    max-width: 100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4fc8091716dbd967fa2a82eef3d29227110e5081f3128aaa38663e547c24f812/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/104f6901ae04bff8385acc8273bb276ab84656a927a418108b940d09fd6e5d7c/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\"\
    \ alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0d568047fbbd300af56b766d9a4235a20534485f5827194e859d4f5c20e58334/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\"\
    \ alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f0487a8fc14d269210ae8ce80b556d4afcd93684f02e61386d2d02daa4423cbd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\"\
    \ alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\"\
    \ style=\"max-width: 100%;\"></a><br>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f438ca4eaa308f982d0a28c48f05bf63ca1a86e52c3d2817f6d7559d1dee68e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8278d89e3634e25a818a2d673fe997c2aa5a09fd5995f716aeffa743388030ee/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\"\
    \ alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/30679331f3c6a5ae54970eda85f36a30347dee8a9111448d7aa48587fd524a1d/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\"\
    \ alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\
    ><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\"\
    \ alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fc9c860bb1fc8e7e145ea9dd6723b9ac6ac2743c195e5e899f6cfa3d38a5a69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\"\
    \ alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0b068d7b5718aafccb46e2ee35f8249938ef189a36ba353c15222ed5e6f65e49/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\"\
    \ alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD is an open meta-data schema\
    \ that provides meaning and self-description for data sets in science and engineering.\n\
    See <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a>\
    \ for details of this schema.</p>\n<p>This library provides a reference API for\
    \ openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable,\
    \ hierarchical file formats, this library implements various backends such as\
    \ HDF5, ADIOS2 and JSON.\nWriting &amp; reading through those backends and their\
    \ associated files are supported for serial and <a href=\"https://www.mpi-forum.org/docs/\"\
    \ rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<h2><a id=\"user-content-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<h3><a id=\"user-content-c\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#c\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>C++</h3>\n<p><a href=\"https://isocpp.org/\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8d47ea5fd5ff323ff5c76593ea37f2340533c73de5e6e37a2b27d7dc28070cd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\"\
    \ alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"\
    ><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"\
    pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n\
    #<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span>\
    \ s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span\
    \ class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"\
    pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>\
    \ &amp; [step, it] : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span>\
    \ &lt;&lt; step &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span\
    \ class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\"\
    >const</span> &amp; [name, mesh] : it.<span class=\"pl-smi\">meshes</span> ) {\n\
    \        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>\
    \  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; name &lt;&lt; <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\"\
    >\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\"\
    >for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp;\
    \ val : mesh.<span class=\"pl-c1\">attributes</span>() )\n            std::cout\
    \ &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"\
    pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\
    \    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span>\
    \ <span class=\"pl-k\">const</span> &amp; [name, species] : it.<span class=\"\
    pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"\
    </span></span> &lt;&lt; name &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\"\
    >\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\"\
    >auto</span> <span class=\"pl-k\">const</span>&amp; val : species.<span class=\"\
    pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt;\
    \ val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"\
    pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n\
    <h3><a id=\"user-content-python\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #python\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Python</h3>\n\
    <p><a href=\"https://www.python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\"\
    \ alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a> <a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    ><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\
    \ alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"\
    ><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span>\
    \ <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"\
    pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\"\
    >=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span\
    \ class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\"\
    >io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\
    \n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"\
    pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span\
    \ class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n  \
    \  <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\
    \n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span\
    \ class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\"\
    >i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n\
    \        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}'\
    \ attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\"\
    >k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span>\
    \ <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"\
    pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span\
    \ class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"\
    pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span\
    \ class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span\
    \ class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"\
    pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"\
    pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span>\
    \ <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n  \
    \          <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"\
    </span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n\
    <h3><a id=\"user-content-more\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #more\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>More!</h3>\n\
    <p>Curious?\nOur manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\"\
    \ rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n\
    <h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#dependencies\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Dependencies</h2>\n<p>Required:</p>\n<ul>\n<li>CMake 3.15.0+</li>\n\
    <li>C++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx</li>\n\
    </ul>\n<p>Shipped internally in <code>share/openPMD/thirdParty/</code>:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> 2.13.10+\
    \ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\">BSL-1.0</a>)</li>\n\
    <li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> 2.10.1+ (<a\
    \ href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)</li>\n\
    <li>\n<a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a> 3.9.1+ (<a\
    \ href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\">MIT</a>)</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> 3.7.1+ (<a href=\"\
    https://github.com/ToruNiina/toml11/blob/master/LICENSE\">MIT</a>)</li>\n</ul>\n\
    <p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\"\
    \ rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\"\
    \ rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either\
    \ with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n\
    </ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python\
    \ 3.7 - 3.11</li>\n<li>pybind11 2.10.1+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py\
    \ 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n\
    <li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n<li>CUDA C++\
    \ (optional, currently used only in tests)</li>\n</ul>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"\
    https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"\
    nofollow\"><img src=\"https://camo.githubusercontent.com/580cdb6331254f66680bd967326d9630f5124291efd5ace18549fbb93cbae6db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3c3728308a9e416589fa8b3b8168967287c515037bfbd4b40f1b14f266de56fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/92b7b7bb69b2b17d1981ae5fdcdb32f971ee57f54a98ea4804e93fd0a2eb58ef/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4eeb2c48c0e554ea8dbe8e90f73a6f2d217e775e0bd5e5cb90ddf4619ef3a6a0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\"\
    \ alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/2babf79954ea524c24f2f9b1cfa05728fdaccbe0a80c2da6a7a7595cc131894c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\"\
    \ alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>Our community loves to help each other.\n\
    Please <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\"\
    >report installation problems</a> in case you should get stuck.</p>\n<p>Choose\
    \ <em>one</em> of the install methods below to get started:</p>\n<h3><a id=\"\
    user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://spack.io\"\
    \ rel=\"nofollow\">Spack</a></h3>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/becffbecb6a50502286f02ec86c4e62f239f3671148d11341152e0dc695a2fc9/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\"\
    \ alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b29fc54abf92a2a6d1d2c70159eb276df53b67a1294ae3f82b1b0bf22a3c586b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\"\
    \ alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \    +python -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack load\
    \ openpmd-api</pre></div>\n<h3><a id=\"user-content-conda\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#conda\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a></h3>\n<p><a\
    \ href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img\
    \ src=\"https://camo.githubusercontent.com/3ad2b345bb3589aa2d733ca20df72938ed54a48342b69f7cbe9eacab43d84549/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a51d3cd2bfa3c6b01bd0f2e36abc206fb9db5700105fac2acd2c2105fced2ec4/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:           \
    \           OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\n\
    conda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n\
    <h3><a id=\"user-content-brew\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #brew\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"https://brew.sh\" rel=\"nofollow\">Brew</a></h3>\n<p><a href=\"https://github.com/openPMD/homebrew-openPMD\"\
    ><img src=\"https://camo.githubusercontent.com/d873c8c473fece8abf1c34a8299a50b7ee0da9772eb50cce8649e7ca32468a6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\"\
    \ alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\"\
    \ alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/7b767b67facc26db7d850ae5c3155fa949048991dde7a0f5471c1e6862f0a586/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\"\
    \ alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<h3><a id=\"\
    user-content-pypi\" class=\"anchor\" aria-hidden=\"true\" href=\"#pypi\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://pypi.org\"\
    \ rel=\"nofollow\">PyPI</a></h3>\n<p><a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fc28bd368523d0b8adab5f4b414aebb304743130eef42bca203f4e9eed428ae7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\"\
    \ alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\
    \ alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\"\
    \ alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7cef25e887c028f65d5d7e20f3e7abe394ab328ecb499e34e47460afd2c78558/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\"\
    \ alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82acdd95515851a5ba4a3006871151f76cfe4d6583f6c24e80bd0fd29d391845/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\"\
    \ alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9)\
    \ or on exotic processor architectures, this install method <em>compiles from\
    \ source</em> against the found installations of HDF5, ADIOS2, and/or MPI (in\
    \ system paths, from other package managers, or loaded via a module system, ...).</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"pl-c\"\
    ><span class=\"pl-c\">#</span> optional:                   --user</span>\npython3\
    \ -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n\
    <p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> optional:                                    --user</span>\npython3\
    \ -m pip install -U pip setuptools wheel\npython3 -m pip install -U cmake\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                 \
    \                                                  --user</span>\nopenPMD_USE_MPI=ON\
    \ python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n<p>For\
    \ some exotic architectures and compilers, you might need to disable a compiler\
    \ feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\"\
    \ rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter\
    \ linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> optional:                               \
    \                 --user</span>\npython3 -m pip install openpmd-api --no-binary\
    \ openpmd-api</pre></div>\n<p>Additional CMake options can be passed via individual\
    \ environment variables, which need to be prefixed with <code>openPMD_CMAKE_</code>.</p>\n\
    <h3><a id=\"user-content-from-source\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #from-source\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>From\
    \ Source</h3>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0a40953107090abff3b564ec3436668756b873cd4d9e021738a046781a5a0e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\"\
    \ alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p>openPMD-api can also be built and installed\
    \ from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\
    \nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests,\
    \ with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which\
    \ python3)</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\"\
    >.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\n\
    ctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required\
    \ for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target\
    \ install</pre></div>\n<p>The following options can be added to the <code>cmake</code>\
    \ call to control features.\nCMake controls options with prefixed <code>-D</code>,\
    \ e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n\
    <td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n\
    <td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n\
    <td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code\
    \ <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro\
    \ independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_INSTALL_RPATH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Add RPATHs to installed binaries</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n\
    <td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n\
    </table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n\
    <sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without\
    \ specific cause is highly discouraged</em></p>\n<p>Additionally, the following\
    \ libraries are shipped internally.\nThe following options allow to switch to\
    \ external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n\
    <th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.10+</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>pybind11</td>\n<td>2.10.1+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n\
    </tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_TOML11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>toml11</td>\n<td>3.7.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this\
    \ will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and\
    \ installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code>\
    \ to the <code>cmake</code> command.\nYou can only build a static or a shared\
    \ library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\n\
    In order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code>\
    \ to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and\
    \ command line tools are built.\nIn order to skip building those, pass <code>OFF</code>\
    \ to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake\
    \ Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n\
    <td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n\
    <td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n\
    <tr>\n<td><code>openPMD_USE_CUDA_EXAMPLES</code></td>\n<td>ON/<strong>OFF</strong>\n\
    </td>\n<td>Use CUDA in examples</td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-linking-to-your-project\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #linking-to-your-project\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Linking to your project</h2>\n<p>The install will contain header files\
    \ and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n\
    <h3><a id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #cmake\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CMake</h3>\n\
    <p>If your project is using CMake for its build, one can conveniently use our\
    \ provided <code>openPMDConfig.cmake</code> package which is installed alongside\
    \ the library.</p>\n<p>First set the following environment hint if openPMD-api\
    \ was <em>not</em> installed in a system path:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed\
    \ if installed outside of system paths</span>\n<span class=\"pl-k\">export</span>\
    \ CMAKE_PREFIX_PATH=<span class=\"pl-smi\">$HOME</span>/somepath:<span class=\"\
    pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n<p>Use the following lines in\
    \ your project's <code>CMakeLists.txt</code>:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> supports:           \
    \            COMPONENTS MPI NOMPI HDF5 ADIOS2</span>\n<span class=\"pl-c1\">find_package</span>(openPMD\
    \ 0.9.0 <span class=\"pl-k\">CONFIG</span>)\n\n<span class=\"pl-k\">if</span>(openPMD_FOUND)\n\
    \    <span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span class=\"\
    pl-k\">PRIVATE</span> openPMD::openPMD)\n<span class=\"pl-k\">endif</span>()</pre></div>\n\
    <p><em>Alternatively</em>, add the openPMD-api repository source directly to your\
    \ project and use it via:</p>\n<div class=\"highlight highlight-source-cmake\"\
    ><pre><span class=\"pl-c1\">add_subdirectory</span>(<span class=\"pl-s\">\"path/to/source/of/openPMD-api\"\
    </span>)\n\n<span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span\
    \ class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n<p>For development\
    \ workflows, you can even automatically download and build openPMD-api from within\
    \ a depending CMake project.\nJust replace the <code>add_subdirectory</code> call\
    \ with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"\
    pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077\
    \ <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING\
    \ <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_SHARED_LIBS\
    \ <span class=\"pl-k\">OFF</span>)  <span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> precedence over BUILD_SHARED_LIBS if needed</span>\n<span class=\"pl-c1\"\
    >set</span>(openPMD_INSTALL <span class=\"pl-k\">OFF</span>)            <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> or instead use:</span>\n<span class=\"\
    pl-c\"><span class=\"pl-c\">#</span> set(openPMD_INSTALL ${BUILD_SHARED_LIBS})\
    \  # only install if used as a shared library</span>\n<span class=\"pl-c1\">set</span>(openPMD_USE_PYTHON\
    \ <span class=\"pl-k\">OFF</span>)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY\
    \ <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"</span>\n\
    \  GIT_TAG        <span class=\"pl-s\">\"dev\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n\
    <h3><a id=\"user-content-manually\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #manually\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manually</h3>\n\
    <p>If your (Linux/OSX) project is build by calling the compiler directly or uses\
    \ a manually written <code>Makefile</code>, consider using our <code>openPMD.pc</code>\
    \ helper file for <code>pkg-config</code> which are installed alongside the library.</p>\n\
    <p>First set the following environment hint if openPMD-api was <em>not</em> installed\
    \ in a system path:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed if installed\
    \ outside of system paths</span>\n<span class=\"pl-k\">export</span> PKG_CONFIG_PATH=<span\
    \ class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span class=\"pl-smi\"\
    >$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and compiler flags\
    \ for your project are available via:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> switch to check if openPMD-api\
    \ was build as static library</span>\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> (via BUILD_SHARED_LIBS=OFF) or as shared library (default)</span>\n\
    <span class=\"pl-k\">if</span> [ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config --variable=static\
    \ openPMD<span class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\
    \ <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>true<span class=\"pl-pds\">\"</span></span> ]\n<span class=\"pl-k\">then</span>\n\
    \    pkg-config --libs --static openPMD\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so\
    \ /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so\
    \ -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so\
    \ /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config\
    \ --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib\
    \ -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n\
    <h2><a id=\"user-content-author-contributions\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#author-contributions\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Author Contributions</h2>\n<p>openPMD-api is developed\
    \ by many people.\nIt was initially started by the <a href=\"https://hzdr.de/crp\"\
    \ rel=\"nofollow\">Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\"\
    \ rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\
    >libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\"\
    \ rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"\
    https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe\
    \ following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\
    >contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\"\
    >Axel Huebl (HZDR, now LBNL)</a>:\nproject lead, releases, documentation, automated\
    \ CI/CD, Python bindings, Dask, installation &amp; packaging, prior reference\
    \ implementations</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\">Franz\
    \ Poeschel (CASUS)</a>:\nJSON &amp; ADIOS2 backend, data staging/streaming, reworked\
    \ class design</li>\n<li>\n<a href=\"https://github.com/C0nsultant\">Fabian Koller\
    \ (HZDR)</a>:\ninitial library design and implementation with HDF5 &amp; ADIOS1\
    \ backend</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu (LBNL)</a>:\n\
    non-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n</ul>\n\
    <p>Further thanks go to improvements and contributions from:</p>\n<ul>\n<li>\n\
    <a href=\"https://github.com/CFGrote\">Carsten Fortmann-Grote (EU XFEL GmbH, now\
    \ MPI-EvolBio)</a>:\ndraft of our Python unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\"\
    >Dominik Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n\
    <li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\n\
    support on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\"\
    >James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"\
    https://github.com/psychocoderHPC\">Ren\xE9 Widera (HZDR)</a>:\ndesign improvements\
    \ for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\"\
    >Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n\
    <a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation\
    \ improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\xE9\
    mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n\
    <a href=\"https://github.com/LDAmorim\">L\xEDgia Diana Amorim (LBNL)</a>:\npackage\
    \ integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\"\
    >Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"\
    https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing,\
    \ documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\"\
    >Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"\
    https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask prototyping\
    \ &amp; ADIOS2 benchmarking</li>\n<li>\n<a href=\"https://github.com/jakirkham\"\
    >John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n<li>\n<a href=\"\
    https://github.com/eschnett\">Erik Schnetter (PITP)</a>:\nC++ API bug fixes</li>\n\
    <li>\n<a href=\"https://github.com/jeanbez\">Jean Luca Bez (LBNL)</a>:\nHDF5 performance\
    \ tuning</li>\n<li>\n<a href=\"https://github.com/bernhardmgruber\">Bernhard Manfred\
    \ Gruber (CERN)</a>:\nCMake fix for parallel HDF5</li>\n<li>\n<a href=\"https://github.com/DerNils-git\"\
    >Nils Schild (IPP)</a>:\nCMake improvements for subprojects</li>\n</ul>\n<h3><a\
    \ id=\"user-content-grants\" class=\"anchor\" aria-hidden=\"true\" href=\"#grants\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Grants</h3>\n\
    <p>The openPMD-api authors acknowledge support via the following programs.\nSupported\
    \ by the CAMPA collaboration, a project of the U.S. Department of Energy, Office\
    \ of Science, Office of Advanced Scientific Computing Research and Office of High\
    \ Energy Physics, Scientific Discovery through Advanced Computing (SciDAC) program.\n\
    Previously supported by the Consortium for Advanced Modeling of Particles Accelerators\
    \ (CAMPA), funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\n\
    Supported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort\
    \ of two U.S. Department of Energy organizations (Office of Science and the National\
    \ Nuclear Security Administration).\nThis project has received funding from the\
    \ European Unions Horizon 2020 research and innovation programme under grant agreement\
    \ No 654220.\nThis work was partially funded by the Center of Advanced Systems\
    \ Understanding (CASUS), which is financed by Germany's Federal Ministry of Education\
    \ and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism\
    \ (SMWK) with tax funds on the basis of the budget approved by the Saxon State\
    \ Parliament.</p>\n<h3><a id=\"user-content-transitive-contributions\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#transitive-contributions\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Transitive Contributions</h3>\n\
    <p>openPMD-api stands on the shoulders of giants and we are grateful for the following\
    \ projects included as direct dependencies:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\"\
    >ADIOS2</a> by <a href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky,\
    \ N. Podhorszki, W.F. Godoy (ORNL), team, collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\"\
    >Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"\
    https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\xFD</a> and <a href=\"\
    https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n\
    <li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a>\
    \ and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a>\
    \ by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"\
    https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n\
    <li>\n<a href=\"https://github.com/ToruNiina/toml11\">toml11</a> by <a href=\"\
    https://github.com/ToruNiina\">Toru Niina</a> and <a href=\"https://github.com/ToruNiina/toml11#Contributors\"\
    >contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\"\
    >pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a>\
    \ and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n\
    </li>\n<li>all contributors to the evolution of modern C++ and early library preview\
    \ developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n\
    </li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a>\
    \ and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n\
    </li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"\
    nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\
    \ and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among\
    \ others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\"\
    >openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR,\
    \ now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\
    >contributors</a>\n</li>\n</ul>\n"
  stargazers_count: 103
  subscribers_count: 10
  topics:
  - openpmd
  - openscience
  - hdf5
  - adios
  - mpi
  - hpc
  - research
  - file-handling
  - python3
  - opendata
  - cpp14
  - metadata
  updated_at: 1680167205.0
pace-gt/PACE-ProvBench:
  data_format: 2
  description: Provenance based Benchmark suite
  filenames:
  - Utilities/spack-config/var/spack/environments/base_gcc_apps/spack.yaml
  - Utilities/spack-config/var/spack/environments/bench_intel_openmpi/spack.yaml
  - Utilities/spack-config/var/spack/environments/bench_intel_mvapich/spack.yaml
  - Utilities/spack-config/var/spack/environments/bench_intel19_mv2_external_apps/spack.yaml
  - Utilities/spack-config/var/spack/environments/base_gcc/spack.yaml
  full_name: pace-gt/PACE-ProvBench
  latest_release: v1.0.0
  readme: "<h1><a id=\"user-content-pace-provbench\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#pace-provbench\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>PACE-ProvBench</h1>\n<p>PACE-ProvBench is a Platform independent tool\
    \ to quickly setup test suite/environment for usability and performance test on\
    \ any new machines,\nand it provides an easy way to compare the performance across\
    \ multiple systems. When tests are running, all runtime\ninformation including\
    \ software, hardware, environment settings are recorded in the database, those\
    \ data can be compared\nafterwards. This project uses object oriented design to\
    \ encapsulate the information relating to benchmark testing, and\npresents a clearer\
    \ high-level representation, which aims to make the benchmark testing easier to\
    \ extend and maintain,\nmeantime the testing provenance is captured.</p>\n<p>Reach\
    \ to Fang (Cherry) Liu (<a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a>)\
    \ if you have any questions.</p>\n<h1><a id=\"user-content-repo-structure\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#repo-structure\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Repo Structure</h1>\n<pre><code>&lt;PACE-ProvBench\
    \ Root Dir&gt; \n  | - Application  (includes all application related data, build\
    \ scripts, input data, recipe and module files/installation placeholder)\n  |\
    \ - Utitilies (include all automation bash scripts, either is used in python code,\
    \ or for building Spack software tool chaim, or used as bootstraping)\n  | - SRC\
    \ (The main source code for ProvBench, all python codes)\n  | - UnitTest (Test\
    \ and query interface for users to invoking the tests and query the results)\n\
    \  | - Test (Default test output place holder)\n  | - SC20Test (includes all automation\
    \ test scripts which generates the test result for the paper) \n  | - Images (stores\
    \ all images used in this documentation)\n  | - Design (includes the design documentation)\n\
    </code></pre>\n<p>Please check the detailed repo structure at <a href=\"repo_directory_struc.md\"\
    >repo_directory_struc</a></p>\n<h2><a id=\"user-content-checkout-the-repository\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#checkout-the-repository\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Checkout the\
    \ repository</h2>\n<p><code>git clone https://github.com/pace-gt/PACE-ProvBench.git</code></p>\n\
    <p>Due to SPACK has some filesystem requirement, the current test needs to be\
    \ done on a physical RHEL7 node\nwith local filesystem.</p>\n<h2><a id=\"user-content-few-terminologies\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#few-terminologies\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Few Terminologies</h2>\n<p>Experiment\
    \ \u2013 each test run, usually one application with multiple runs</p>\n<p>ROLEs\
    \ \u2013 person who interacts with the framework</p>\n<ul>\n<li>Developer: develops\
    \ and extends the framework in functionalities and design</li>\n<li>Contributor:\
    \ builds the test suite and adds new applications</li>\n<li>User: run the tests\
    \ and analyzes the data collected by the framework</li>\n</ul>\n<p>RECIPE \u2013\
    \ defines how the application is run from command line</p>\n<h2><a id=\"user-content-system-requirements\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#system-requirements\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>System Requirements</h2>\n<ul>\n\
    <li>\n<p>Easy to rebuild the software in a short time span with as little as possible\
    \ manual steps:</p>\n<p>-- Use LLNL SPACK tool to build the underline compilers\
    \ and libraries, using SPACK ENV to ensure automation and reproducibility (this\
    \ is an optional step, Contributor can build software manually as needed)</p>\n\
    <p>-- Provide the template build scripts and module files for Contributor to build\
    \ the test suite on existing applications</p>\n<p>-- Allow easily to add new applications</p>\n\
    </li>\n<li>\n<p>Information collected are permanently stored</p>\n<p>-- includes\
    \ all software, hardware, running environment</p>\n<p>-- information can be used\
    \ to rebuild the tests</p>\n</li>\n<li>\n<p>Framework should be easy to extend</p>\n\
    <p>-- Object-oriented programming style is adopted</p>\n</li>\n</ul>\n<h2><a id=\"\
    user-content-high-level-objects-design-and-workflow\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#high-level-objects-design-and-workflow\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>High Level Objects Design and workflow</h2>\n\
    <p>This is for developer only, PACE-ProvBench has 7 main objects all under python\
    \ package <code>&lt;repo root&gt;/SRC/pace/provbench</code>:</p>\n<ul>\n<li>Application\
    \ : represents all information and functionalities for one application in test\
    \ suite</li>\n<li>Runtime : provides the information related to each Experiment\
    \ run</li>\n<li>System : captures hareware information for each individual host</li>\n\
    <li>Result: processes the performance result, e.g. average/mean/max/min time</li>\n\
    <li>Database: interacts with database, construct the insert/update/select queries</li>\n\
    <li>Command: encapsultes the command line invokation for each application</li>\n\
    <li>Experiment: includes all above objects, serves as the entry point for user\
    \ interaction</li>\n</ul>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\"\
    \ href=\"Images/objectflow.png\"><img src=\"Images/objectflow.png\" alt=\"PACE-ProvBench\
    \ Object and Data flow\" width=\"55%\" style=\"max-width: 100%;\"></a></p>\n<h2><a\
    \ id=\"user-content-repository-directory-structure\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#repository-directory-structure\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Repository Directory Structure</h2>\n<p>Please\
    \ check <a href=\"repo_directory_struc.md\">repository directory structure</a>\
    \ for details.\nIt gives the detailed description on how each directory is for,\
    \ and naming convention on how to put the new information in.</p>\n<h2><a id=\"\
    user-content-building-the-initial-test-suite\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#building-the-initial-test-suite\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Building the initial test suite</h2>\n<p>Please\
    \ check <a href=\"build_testsuite.md\">Build Initial Test Suite</a> for how to\
    \ establish the initial benchmark suite with\none application (leslie-spec), this\
    \ initial test suite should allow user to experience the PACE-ProvBench framework\n\
    in terms of functionalities.</p>\n<h2><a id=\"user-content-run-tests-as-a-user\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#run-tests-as-a-user\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Run tests as a user</h2>\n<p>Please\
    \ check <a href=\"run_test.md\">User run test</a> for how to run a test.</p>\n\
    <p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"Images/runtest.png\"\
    ><img src=\"Images/runtest.png\" alt=\"Run test as a user\" width=\"55%\" style=\"\
    max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-adding-new-application-to-pace-provbench\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-application-to-pace-provbench\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new\
    \ application to PACE-ProvBench</h2>\n<p>The general steps are as follows, please\
    \ check <a href=\"add_new_application.md\">add new application</a> session for\
    \ details.</p>\n<pre><code>* build the application using the pace_build.sh from\
    \ $PACEPROVBENCH/Application/Source\n* add new module file under $PACEPROVBENCH/Application/Module/&lt;appname&gt;/&lt;version&gt;.lua\n\
    * add new recipe file under $PACEPROVBENCH/Application/Recipe/&lt;appname&gt;.inp\n\
    * follow the step on how to run a test \n</code></pre>\n<p><a target=\"_blank\"\
    \ rel=\"noopener noreferrer\" href=\"Images/newappflow.png\"><img src=\"Images/newappflow.png\"\
    \ alt=\"Add New Application\" width=\"55%\" style=\"max-width: 100%;\"></a></p>\n\
    <h2><a id=\"user-content-query-the-database\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#query-the-database\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Query the database</h2>\n<p>User can access PACE-ProvBench\
    \ database to gather performance data from the runs they had through the query\
    \ interface.\nPlease see <a href=\"query_database.md\">how to query the database</a>\
    \ session for more details.</p>\n<h2><a id=\"user-content-summary\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#summary\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Summary</h2>\n<ul>\n<li>\n<p>Current PACE-ProvBench\
    \ provides:</p>\n<p>-- A way to build the test suite</p>\n<p>-- A way to integrate\
    \ new test application</p>\n<p>-- A way to capture the provenance information\
    \ and store permanently</p>\n<p>-- A way to easy query the provenance information\
    \ with given criteria</p>\n<p>-- A way to easy extend the framework</p>\n</li>\n\
    <li>\n<p>Future work</p>\n<p>-- More test and validation need to be done</p>\n\
    <p>-- More applications need to be added to test suite</p>\n<p>-- Extend the framework\
    \ to handle more data analytics to answer HPC data center\u2019 questions</p>\n\
    <p>-- Publish the work in paper and github</p>\n</li>\n</ul>\n<p>Contributed by\
    \ Fang (Cherry) Liu <a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a></p>\n"
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1614293355.0
player1537-playground/decaf-superbuild:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: player1537-playground/decaf-superbuild
  latest_release: null
  readme: '<h1><a id="user-content-decaf--henson-superbuild" class="anchor" aria-hidden="true"
    href="#decaf--henson-superbuild"><span aria-hidden="true" class="octicon octicon-link"></span></a>Decaf
    / Henson Superbuild</h1>

    <p>This repository makes use of CMake features to enable easier integration and

    use of Decaf and/or Henson for scientific workflows. In essence, external

    low-level dependencies (boost, cmake, mpich, diy, and python) are installed

    using Spack, Python dependencies (networkx, scipy, numpy, matplotlib) are

    installed within a Python virtual environment, and higher-level dependencies

    (decaf, diy, qhull, tess, and henson) are built from source using CMake''s

    ExternalProject library.</p>

    <p>The dependencies that are built by CMake also put their source code in a local

    directory for easier modification and development. For example, after changing

    Henson code manually, the entire set of dependencies are re-built with the same

    basic build command.</p>

    <h2><a id="user-content-usage-gosh" class="anchor" aria-hidden="true" href="#usage-gosh"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage ("go.sh")</h2>

    <p>There is a helper script at the root of this repository that helps automate

    many of the commands. It can be used for every step of the process and is short

    and easy to read if modifications are needed.</p>

    <p><strong>Spack Dependencies</strong> are defined in the <code>spack.yaml</code>
    file.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c"><span class="pl-c">#</span> Load the Spack environment defined by
    the spack.yaml file</span></span>

    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span>   (Run this
    every time you load the project)</span></span>

    $ <span class="pl-s1"><span class="pl-c1">eval</span> <span class="pl-s"><span
    class="pl-pds">$(</span>./go.sh spack env activate --sh .<span class="pl-pds">)</span></span></span>


    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span> Install the
    dependencies</span></span>

    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span>   (Run this
    once)</span></span>

    $ <span class="pl-s1">./go.sh spack install</span></pre></div>

    <p><strong>Python Dependencies</strong> are defined in the <code>requirments.txt</code>
    file.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c"><span class="pl-c">#</span> Setup and install the Python dependencies</span></span>

    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span>  (Run this
    once)</span></span>

    $ <span class="pl-s1">./go.sh venv</span>


    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span> Load the
    Python environment</span></span>

    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span>  (Run this
    every time you load the project)</span></span>

    $ <span class="pl-s1"><span class="pl-c1">source</span> venv/bin/activate</span></pre></div>

    <p><strong>Source Dependencies</strong> are defined the in root <code>CMakeLists.txt</code>
    file and the <code>cmake/Find&lt;Package&gt;.cmake</code> files.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c"><span class="pl-c">#</span> Setup the build directory</span></span>

    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span>  (Run this
    every time you change the CMakeLists.txt file)</span></span>

    $ <span class="pl-s1">./go.sh cmake</span>


    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span> Build the
    source dependencies and main project</span></span>

    $ <span class="pl-s1"><span class="pl-c"><span class="pl-c">#</span>  (Run this
    every time you change the code)</span></span>

    $ <span class="pl-s1">./go.sh make</span></pre></div>

    <p><strong>Running the Code</strong> requires setting up the <code>LD_LIBRARY_PATH</code>
    environment variable.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c"><span class="pl-c">#</span> Run the built code with the correct environment</span></span>

    $ <span class="pl-s1">./go.sh <span class="pl-c1">exec</span> build/my_executable</span></pre></div>

    <h2><a id="user-content-simplest-usage-copy-paste" class="anchor" aria-hidden="true"
    href="#simplest-usage-copy-paste"><span aria-hidden="true" class="octicon octicon-link"></span></a>Simplest
    Usage (copy-paste)</h2>

    <p>Run these once to setup the project.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c1">eval</span> <span class="pl-s"><span class="pl-pds">$(</span>./go.sh
    spack env activate --sh .<span class="pl-pds">)</span></span></span>

    $ <span class="pl-s1">./go.sh spack install</span>

    $ <span class="pl-s1">./go.sh venv</span>

    $ <span class="pl-s1"><span class="pl-c1">source</span> venv/bin/activate</span>

    $ <span class="pl-s1">./go.sh cmake</span>

    $ <span class="pl-s1">./go.sh make</span></pre></div>

    <p>Run these when starting to work on this project again.</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1"><span
    class="pl-c1">eval</span> <span class="pl-s"><span class="pl-pds">$(</span>./go.sh
    spack env activate --sh .<span class="pl-pds">)</span></span></span>

    $ <span class="pl-s1"><span class="pl-c1">source</span> venv/bin/activate</span>

    $ <span class="pl-s1">./go.sh cmake</span>

    $ <span class="pl-s1">./go.sh make</span></pre></div>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1609796820.0
psakievich/Driver-Cylinder:
  data_format: 2
  description: Test problem for the Exawind-Driver designed for demo's and debugging
  filenames:
  - spack_e4s.yaml
  - spack.yaml
  full_name: psakievich/Driver-Cylinder
  latest_release: null
  readme: '<h1><a id="user-content-exawind-demo-problem" class="anchor" aria-hidden="true"
    href="#exawind-demo-problem"><span aria-hidden="true" class="octicon octicon-link"></span></a>Exawind
    Demo Problem</h1>

    <p>Rotating laminar cyinder in a cross flow with nested refinement

    Eventually this should be turbulent/turn on turbulence models to test the same
    code paths used for turbine runs</p>

    <p>Nearbody meshes:</p>

    <ul>

    <li>cylinder3d_nearbody_2k.g (no refinement, what we have in the regression suite)</li>

    <li>cylinder3d_nearbody_18k.g (1 level of refinement)</li>

    <li>cylinder3d_nearbody_146k.g (2 level of refinement)</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1665545780.0
range3/chfs-containers:
  data_format: 2
  description: null
  filenames:
  - spack/envs/chfs-master/spack.yaml
  - spack/envs/chfs/spack.yaml
  full_name: range3/chfs-containers
  latest_release: null
  readme: '<h1><a id="user-content-chfs-containers" class="anchor" aria-hidden="true"
    href="#chfs-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>chfs-containers</h1>

    <h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>example</h2>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    explicitly pull the latest chfs image </span>

    docker pull range3/chfs:master


    git clone https://github.com/range3/chfs-containers

    <span class="pl-c1">cd</span> chfs-containers


    <span class="pl-c"><span class="pl-c">#</span> start servers</span>

    docker-compose up -d


    <span class="pl-c"><span class="pl-c">#</span> start another container for client</span>

    docker run -it --rm --network chfs_net --privileged range3/chfs:master bash

    <span class="pl-c"><span class="pl-c">#</span> set CHFS_SERVER env</span>

    <span class="pl-k">export</span> CHFS_SERVER=<span class="pl-s"><span class="pl-pds">$(</span>chlist
    -c -s ofi+sockets://172.30.0.3:50000<span class="pl-pds">)</span></span>


    <span class="pl-c"><span class="pl-c">#</span> list chfs servers</span>

    chlist


    <span class="pl-c"><span class="pl-c">#</span> mount chfs via FUSE</span>

    mkdir /tmp/m

    chmkdir /tmp/m

    chfuse -o direct_io,modules=subdir,subdir=<span class="pl-s"><span class="pl-pds">"</span>/tmp/m<span
    class="pl-pds">"</span></span> /tmp/m


    <span class="pl-c"><span class="pl-c">#</span> &lt;ctrl-D&gt;</span>

    <span class="pl-c"><span class="pl-c">#</span> the client container is removed</span>


    <span class="pl-c"><span class="pl-c">#</span> stop and remove server containers</span>

    docker-compose down</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652094301.0
range3/fio-practice:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/fio-practice
  latest_release: null
  readme: '<h1><a id="user-content-fio-practice" class="anchor" aria-hidden="true"
    href="#fio-practice"><span aria-hidden="true" class="octicon octicon-link"></span></a>fio-practice</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1665547201.0
range3/spack-playground:
  data_format: 2
  description: null
  filenames:
  - spack/envs/broken-verbs-chris8x/spack.yaml
  - spack/envs/chris8x/spack.yaml
  - spack/envs/dev/spack.yaml
  - spack/envs/cygnus/spack.yaml
  full_name: range3/spack-playground
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-playground\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack-playground\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>spack-playground</h1>\n<h2><a id=\"user-content-development\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#development\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Development</h2>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> /workspaces/spack-playground\n\
    spack env activate -d spack/envs/dev\nspack install --keep-stage</pre></div>\n\
    <h2><a id=\"user-content-activate-intellisense-provided-by-clangd\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#activate-intellisense-provided-by-clangd\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>activate IntelliSense\
    \ provided by clangd</h2>\n<ul>\n<li>the vsode extensions are already installed\
    \ in the dev container.</li>\n<li>open vscode command palette\n<ul>\n<li><code>&gt;\
    \ clangd: Download language server</code></li>\n<li><code>&gt; Developper: Reload\
    \ Window</code></li>\n</ul>\n</li>\n</ul>\n<h2><a id=\"user-content-create-new-spack-env-if-you-want\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#create-new-spack-env-if-you-want\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Create new\
    \ spack env if you want</h2>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c1\">cd</span> /workspaces/spack-playground\nspack env\
    \ create -d spack/envs/dev2\nspack env activate -d spack/envs/dev2\nspack compiler\
    \ find\nspack external find\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>\
    \ edit spack/envs/dev2/spack.yaml</span>\n<span class=\"pl-c\"><span class=\"\
    pl-c\">#</span># suggestion: remove openssl and python from external packages</span>\n\
    spack concretize -f\nspack install --keep-stage</pre></div>\n<h2><a id=\"user-content-3rd-party-library-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#3rd-party-library-license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>3rd Party Library\
    \ License</h2>\n<h3><a id=\"user-content-akka-httpsgithubcomakkaakka\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#akka-httpsgithubcomakkaakka\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Akka (<a href=\"https://github.com/akka/akka\"\
    >https://github.com/akka/akka</a>)</h3>\n<details><summary>Apache 2 license</summary>\n\
    <pre><code>This software is licensed under the Apache 2 license, quoted below.\n\
    \nCopyright 2009-2018 Lightbend Inc. &lt;https://www.lightbend.com&gt;\n\nLicensed\
    \ under the Apache License, Version 2.0 (the \"License\"); you may not\nuse this\
    \ file except in compliance with the License. You may obtain a copy of\nthe License\
    \ at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable\
    \ law or agreed to in writing, software\ndistributed under the License is distributed\
    \ on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either\
    \ express or implied. See the\nLicense for the specific language governing permissions\
    \ and limitations under\nthe License.\n</code></pre>\n</details>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1639559107.0
range3/ucx_practice:
  data_format: 2
  description: null
  filenames:
  - spack/envs/dev/spack.yaml
  full_name: range3/ucx_practice
  latest_release: null
  readme: '<h1><a id="user-content-ucx_practice" class="anchor" aria-hidden="true"
    href="#ucx_practice"><span aria-hidden="true" class="octicon octicon-link"></span></a>ucx_practice</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1666601300.0
ravisiv/PhishingEmailDetection:
  data_format: 2
  description: null
  filenames:
  - src_simple/spack/capstone/spack.yaml
  - src/spack/capstone/spack.yaml
  full_name: ravisiv/PhishingEmailDetection
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/67842939/190537013-b30595b5-fb57-4246-adf1-c96ec88a805c.png"><img
    width="857" alt="image" src="https://user-images.githubusercontent.com/67842939/190537013-b30595b5-fb57-4246-adf1-c96ec88a805c.png"
    style="max-width: 100%;"></a></p>

    <p><strong>Abstract.</strong> Phishing emails are a primary mode of entry for
    attackers

    into an organization. A successful phishing attempt leads to

    unauthorized access to sensitive information and systems. However,

    automatically identifying phishing emails is often difficult since many

    phishing emails have composite features such as body text and metadata

    that are nearly indistinguishable from valid emails. This paper presents

    a novel machine learning-based framework, the DARTH framework, that

    characterizes and combines multiple models, with one model for each

    individual composite feature, that enables the accurate identification

    of phishing emails. The framework analyses each composite feature

    independently utilizing a multi-faceted approach using Natural Language

    Processing (NLP) and neural network-based techniques and combines the

    results of these analysis to classify the emails as malicious or

    legitimate. Utilizing the framework on more than 150,000 emails and

    training data from multiple sources including the authors'' personal

    emails and phishtank.com resulted in the precision (correct

    identification of malicious observations to the total prediction of

    malicious observations) of 99.97% with an f-score of 99.98% and

    accurately identifying phishing emails 99.98% of the time. Utilizing

    multiple machine learning techniques combined in an ensemble approach

    across a range of composite features yields highly accurate

    identification of phishing emails.</p>

    <p>Download the full <a href="https://github.com/ravisiv/PhishingEmailDetection/raw/main/Phishing%20Detection%20using%20ML%20and%20NLP.docx">paper</a>.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1658945123.0
rngoodner/fiesta-helpers:
  data_format: 2
  description: null
  filenames:
  - spack-environments/openmpi-lassen/spack.yaml
  - spack-environments/mvapich2-lassen/spack.yaml
  full_name: rngoodner/fiesta-helpers
  latest_release: null
  readme: '<h1><a id="user-content-fiesta-helpers" class="anchor" aria-hidden="true"
    href="#fiesta-helpers"><span aria-hidden="true" class="octicon octicon-link"></span></a>fiesta-helpers</h1>

    <p>Convenience scripts for building and running FIESTA. These are the scripts
    I have been using to help build/run FIESTA on Xena to test run-times after source
    modifications and with different implementations of MPI.</p>

    <h1><a id="user-content-build-script" class="anchor" aria-hidden="true" href="#build-script"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build script</h1>

    <p>The build script will set up an environment with Spack and then build fiesta
    into a directory named <code>build-&lt;env&gt;-&lt;commit-hash&gt;</code>.</p>

    <h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h2>

    <p><code>./build.sh &lt;path-to-fiesta-clone&gt; &lt;commit-hash&gt; &lt;env-file-to-source&gt;</code></p>

    <p>Evironment files can be found in <code>env-files/</code>.</p>

    <h2><a id="user-content-example" class="anchor" aria-hidden="true" href="#example"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example</h2>

    <p><code>./build.sh ../cup-ecs-fiesta ./env-files/openmpi</code></p>

    <h1><a id="user-content-run-script" class="anchor" aria-hidden="true" href="#run-script"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Run script</h1>

    <p>The run script will load the spack environment and the run a specified test
    a specified number of times.</p>

    <h2><a id="user-content-usage-1" class="anchor" aria-hidden="true" href="#usage-1"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h2>

    <p><code>./run.sh &lt;path-to-fiesta-binary&gt; &lt;path-to-test-dir&gt; &lt;env-file-to-source&gt;
    &lt;scheduler command&gt; &lt;gpus-per-node&gt; &lt;number-of-runs&gt;</code></p>

    <h2><a id="user-content-example-1" class="anchor" aria-hidden="true" href="#example-1"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example</h2>

    <p><code>./run.sh ../cup-ecs-fiesta/build-mvapich2-lassen-d8f360b/fiesta ./idexp3dterrain-gpu-type
    ./env-files/mvapich2-lassen "lrun -N4 -T1" 1 25</code></p>

    <h1><a id="user-content-get-run-times" class="anchor" aria-hidden="true" href="#get-run-times"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Get run times</h1>

    <p><code>parse.awk</code> can be used to extract run-times from a slurm output
    consisting of many runs.

    The output is formatted as a python list so results can be easily plotted.</p>

    <h2><a id="user-content-example-2" class="anchor" aria-hidden="true" href="#example-2"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example</h2>

    <pre><code>rgoodner@xena host-mod]$ ./parse.awk fiesta-host-mod.32325.out

    Found [1]: Total Time:                              6.71e+02

    Found [2]: Total Time:                              6.77e+02

    Found [3]: Total Time:                              6.73e+02

    Found [4]: Total Time:                              6.74e+02

    Found [5]: Total Time:                              6.80e+02

    Found [6]: Total Time:                              6.72e+02

    Found [7]: Total Time:                              6.74e+02

    Found [8]: Total Time:                              6.72e+02

    Found [9]: Total Time:                              6.72e+02

    Found [10]: Total Time:                              6.79e+02

    Found [11]: Total Time:                              6.78e+02

    Found [12]: Total Time:                              6.77e+02

    Found [13]: Total Time:                              6.76e+02

    Found [14]: Total Time:                              6.74e+02

    Found [15]: Total Time:                              6.77e+02

    Found [16]: Total Time:                              6.79e+02

    Found [17]: Total Time:                              6.78e+02

    Found [18]: Total Time:                              6.73e+02

    Found [19]: Total Time:                              6.73e+02

    Found [20]: Total Time:                              6.75e+02

    Found [21]: Total Time:                              6.81e+02

    Found [22]: Total Time:                              6.76e+02

    Found [23]: Total Time:                              6.75e+02

    Found [24]: Total Time:                              6.76e+02

    Found [25]: Total Time:                              6.74e+02

    [6.71e+02, 6.77e+02, 6.73e+02, 6.74e+02, 6.80e+02, 6.72e+02, 6.74e+02, 6.72e+02,
    6.72e+02, 6.79e+02, 6.78e+02, 6.77e+02, 6.76e+02, 6.74e+02, 6.77e+02, 6.79e+02,
    6.78e+02, 6.73e+02, 6.73e+02, 6.75e+02, 6.81e+02, 6.76e+02, 6.75e+02, 6.76e+02,
    6.74e+02]

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1625505905.0
robertu94/libpressio:
  data_format: 2
  description: A library to abstract between different lossless and lossy compressors
  filenames:
  - docker/spack.yaml
  full_name: robertu94/libpressio
  latest_release: 0.70.0
  readme: "<h1><a id=\"user-content-libpressio\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#libpressio\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>LibPressio</h1>\n<p><em>the stable version of this code is found at\
    \ <a href=\"https://github.com/CODARcode/libpressio\">at the CODARCode organization</a>\
    \ it is updated about anually</em></p>\n<p>Pressio is latin for compression. \
    \ LibPressio is a C++ library with C compatible bindings to abstract between different\
    \ lossless and lossy compressors and their configurations.  It solves the problem\
    \ of having to having to write separate application level code for each lossy\
    \ compressor that is developed.  Instead, users write application level code using\
    \ LibPressio, and the library will make the correct underlying calls to the compressors.\
    \  It provides interfaces to represent data, compressors settings, and compressors.</p>\n\
    <p>Documentation for the <code>master</code> branch can be <a href=\"https://robertu94.github.io/libpressio/\"\
    \ rel=\"nofollow\">found here</a></p>\n<h1><a id=\"user-content-using-libpressio\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#using-libpressio\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using LibPressio</h1>\n<p>Example\
    \ using the CLI from <a href=\"https://github.com/robertu94/pressio-tools\"><code>pressio-tools</code></a>\n\
    We also have C, C++, Rust, Julia, and Python bindings.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pressio -i <span class=\"pl-k\">~</span>/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32\
    \ \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m <span class=\"pl-k\"\
    >time</span> -m size -m error_stat -M all \\\n    -w /path/to/output.dec</pre></div>\n\
    <p>The reccomended way to learn LibPressio is with self-pased <a href=\"https://github.com/robertu94/libpressio_tutorial\"\
    >LibPressio Tutorial</a>.\nHere you will find examples of how to use LibPressio\
    \ in a series of lessons for several common languages.</p>\n<p>You can also find\
    \ a <a href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\">recording of the\
    \ tutorial on YouTube</a>.</p>\n<h2><a id=\"user-content-getting-started\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#getting-started\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>After skimming\
    \ the example, LibPressio has 6 major headers that you will need to use:</p>\n\
    <table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Use</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>pressio.h</code></td>\n<td>Error reporting and aquiring handles\
    \ to compressors</td>\n</tr>\n<tr>\n<td><code>pressio_compressor.h</code></td>\n\
    <td>Used to compress and decompress data, provided by plugins</td>\n</tr>\n<tr>\n\
    <td><code>pressio_data.h</code></td>\n<td>Represents data and associated metadata\
    \ (size, type, dimentionality, memory ownership)</td>\n</tr>\n<tr>\n<td><code>pressio_options.h</code></td>\n\
    <td>Maps between names and values, used for options for compressors and metrics\
    \ results</td>\n</tr>\n<tr>\n<td><code>pressio_metrics.h</code></td>\n<td>A set\
    \ of metrics to run while compressors run</td>\n</tr>\n<tr>\n<td><code>pressio_io.h</code></td>\n\
    <td>An extension header that provides methods to load or store data from/to persistent\
    \ storage</td>\n</tr>\n</tbody>\n</table>\n<p>All of these are included by the\
    \ convience header <code>libpressio.h</code>.</p>\n<p>You can pick up the more\
    \ advanced features as you need them.</p>\n<p>You can also find more examples\
    \ in <code>test/</code> or in the <a href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\
    >LibPressio intresting scripts collection</a> which catalogs intresting higher-level\
    \ use cases.</p>\n<h2><a id=\"user-content-supported-compressors-and-metrics\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#supported-compressors-and-metrics\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported\
    \ Compressors and Metrics</h2>\n<p>Libpressio provides a number of builtin compressor\
    \ and metrics modules.\nAll of these are <strong>disabled by default</strong>.\n\
    They can be enabled by passing the corresponding <code>LIBPRESSIO_HAS_*</code>\
    \ variable to CMake.</p>\n<p>Additionally, Libpressio is extensible.\nFor information\
    \ on writing a compressor plugin see [Writing a Compressor Plugin](@ref writingacompressor)\n\
    For information on writing a metrics plugin see [Writing a Metrics Plugin](@ref\
    \ writingametric)</p>\n<h3><a id=\"user-content-compressor-plugins\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#compressor-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Compressor Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\
    >src/plugins/compressors</a></p>\n<p>See the [compressor settings page](@ref compressors)\
    \ for information on how to configure them.</p>\n<h3><a id=\"user-content-metrics-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#metrics-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Metrics Plugins</h3>\n<p>1st\
    \ party compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\
    >src/plugins/metrics</a></p>\n<p>See the [metrics results page](@ref metrics)\
    \ for information on what they produce</p>\n<h3><a id=\"user-content-io-plugins\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#io-plugins\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>IO Plugins</h3>\n<p>1st party\
    \ compressors plugins can be found in <a href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\
    >src/plugins/io</a></p>\n<p>See the [io settings page](@ref io) for information\
    \ on how to configure them</p>\n<h1><a id=\"user-content-installation\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Installation</h1>\n<h2><a id=\"user-content-installing-libpressio-using-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing-libpressio-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ LibPressio using Spack</h2>\n<p>LibPressio can be built using <a href=\"https://github.com/spack/spack/\"\
    >spack</a>.  This example will install libpressio with only the SZ3 plugin.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/spack/spack\n\
    <span class=\"pl-c1\">source</span> ./spack/share/spack/setup-env.sh\nspack install\
    \ libpressio+sz3</pre></div>\n<p>More information on spack can be found in the\
    \ <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a>\
    \ or <a href=\"https://robertu94.github.io/guides\" rel=\"nofollow\">my quick\
    \ start guides for systems that I use</a></p>\n<p>You can see the other available\
    \ versions and compilation options by calling <code>spack info libpressio</code></p>\n\
    <p>The following language bindings are in this repository.</p>\n<ul>\n<li>\n<code>C</code>\
    \ -- (default) if you need a stable interface</li>\n<li>\n<code>C++</code> --\
    \ (default) if you want a more productive interface, or want to extend LibPressio</li>\n\
    <li>\n<code>Python</code> -- (<code>+python</code>; BUILD_PYTHON_WRAPPER) if you\
    \ know or want to intergate Python</li>\n<li>\n<code>HDF5</code> -- (<code>+hdf5+json</code>;\
    \ LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5</li>\n</ul>\n\
    <p>The following bindings must be installed seperately:</p>\n<ul>\n<li>\n<code>R</code>\
    \ -- <a href=\"https://github.com/robertu94/libpressio-r\">r-libpressio</a> if\
    \ you know or want to integrate with R</li>\n<li>\n<code>Bash/CLI</code> -- <a\
    \ href=\"https://github.com/robertu94/pressio-tools\">libpressio-tools</a>  if\
    \ you want to quickly prototype from the CLI</li>\n</ul>\n<p>The following bindings\
    \ are experimental and can be installed manually:</p>\n<ul>\n<li>\n<code>Julia</code>\
    \ -- <a href=\"https://github.com/robertu94/LibPressio.jl\">libpressio-jl</a>\
    \ if you know or want to integrate with Julia</li>\n<li>\n<code>Rust</code> --\
    \ <a href=\"https://github.com/robertu94/libpressio-rs\">libpressio-rs</a> if\
    \ you know or want to integrate with Rust</li>\n</ul>\n<h2><a id=\"user-content-doing-a-development-build-with-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#doing-a-development-build-with-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Doing a\
    \ development build with spack</h2>\n<p>The easiest way to do a development build\
    \ of libpressio is to use Spack envionments.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> one time setup: create\
    \ an envionment</span>\nspack env create -d mydevenviroment\nspack env activate\
    \ mydevenvionment\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one time\
    \ setup: install libpressio-tools and checkout </span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> libpressio for development</span>\nspack add libpressio-tools\n\
    spack develop libpressio@git.master\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> compile and install (repeat as needed)</span>\nspack install </pre></div>\n\
    <h2><a id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#manual-installation\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Manual Installation</h2>\n<p>Libpressio unconditionally\
    \ requires:</p>\n<ul>\n<li><code>cmake</code></li>\n<li><code>pkg-config</code></li>\n\
    <li><a href=\"https://github.com/robertu94/std_compat\"><code>std_compat</code></a></li>\n\
    <li>either:\n<ul>\n<li>\n<code>gcc-4.8.5</code> or later</li>\n<li>\n<code>clang-7.0.0</code>\
    \ or later using either <code>libc++</code> or <code>libstdc++</code>.  Beware\
    \ that system libraries may need to be recompiled with <code>libc++</code> if\
    \ using <code>libc++</code>\n</li>\n</ul>\n</li>\n</ul>\n<p>Dependency versions\
    \ and optional dependencies are documented <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >in the spack package</a>.</p>\n<h2><a id=\"user-content-configuring-libpressio-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-libpressio-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuring\
    \ LibPressio Manually</h2>\n<p>LibPressio uses a fairly standard CMake buildsystem.\n\
    For more information on <a href=\"https://robertu94.github.io/learning/cmake\"\
    \ rel=\"nofollow\">CMake refer to these docs</a></p>\n<p>The set of configuration\
    \ options for LibPressio can be found using <code>cmake -L $BUILD_DIR</code>.\n\
    For information on what these settings do, see the <a href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\
    >spack package</a></p>\n<h1><a id=\"user-content-api-stability\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#api-stability\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>API Stability</h1>\n<p>Please refer to <a href=\"\
    docs/stability.md\">docs/stability.md</a>.</p>\n<h1><a id=\"user-content-how-to-contribute\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-contribute\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to Contribute</h1>\n<p>Please\
    \ refer to <a href=\"CONTRIBUTORS.md\">CONTRIBUTORS.md</a> for a list of contributors,\
    \ sponsors, and contribution guidelines.</p>\n<h1><a id=\"user-content-bug-reports\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#bug-reports\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Bug Reports</h1>\n<p>Please files\
    \ bugs to the Github Issues page on the CODARCode libpressio repository.</p>\n\
    <p>Please read this post on <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\"\
    \ rel=\"nofollow\">how to file a good bug report</a>.\_ After reading this post,\
    \ please provide the following information specific to libpressio:</p>\n<ul>\n\
    <li>Your OS version and distribution information, usually this can be found in\
    \ <code>/etc/os-release</code>\n</li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n\
    </li>\n<li>the version of each of libpressio's dependencies listed in the README\
    \ that you have installed. Where possible, please provide the commit hashes.</li>\n\
    </ul>\n<h1><a id=\"user-content-citing-libpressio\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#citing-libpressio\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Citing LibPressio</h1>\n<p>If you find LibPressio\
    \ useful, please cite this paper:</p>\n<pre><code>@inproceedings{underwood2021productive,\n\
    \  title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n\
    \  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di,\
    \ Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on\
    \ Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n\
    \  year={2021},\n  organization={IEEE}\n}\n</code></pre>\n"
  stargazers_count: 16
  subscribers_count: 5
  topics: []
  updated_at: 1673367032.0
robertu94/libpressio-sperr:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/libpressio-sperr
  latest_release: null
  readme: '<h1><a id="user-content-libpressio-sperr" class="anchor" aria-hidden="true"
    href="#libpressio-sperr"><span aria-hidden="true" class="octicon octicon-link"></span></a>LibPressio-SPERR</h1>

    <p>A LibPressio compressor plugin for SPERR. Packaged seperately because of GPL
    Licensing</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Via Spack</p>

    <pre><code>git clone https://github.com/robertu94/spack_packages robertu94_packages

    spack repo add ./robertu94_packages


    spack install libpressio-sperr

    </code></pre>

    <p>Manually Via CMake</p>

    <pre><code># install cmake, sperr, libpressio and dependencies first


    cmake -S . -B build -DCMAKE_INSTALL_PREFIX

    cmake --build build

    cmake --install

    </code></pre>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1658183703.0
robertu94/roibin-sz3-experiments:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: robertu94/roibin-sz3-experiments
  latest_release: null
  readme: '<h1><a id="user-content-roibin-sz-experiments" class="anchor" aria-hidden="true"
    href="#roibin-sz-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>ROIBIN-SZ
    Experiments</h1>

    <h2><a id="user-content-system-information" class="anchor" aria-hidden="true"
    href="#system-information"><span aria-hidden="true" class="octicon octicon-link"></span></a>System
    Information</h2>

    <p>The hardware and software versions used for the performance evaluations can
    be found in Table I in the paper. These nodes come from Clemson University''s
    Palmetto Cluster.</p>

    <p>The quality assessment was done on the PSANA system at SLAC national accelerator
    laboratory using PSOCAKE, PHENIX, and CCP4.</p>

    <h2><a id="user-content-where-is-the-implementation-of-roibin-sz3" class="anchor"
    aria-hidden="true" href="#where-is-the-implementation-of-roibin-sz3"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Where is the implementation of ROIBIN-SZ3?</h2>

    <p>This repository contains only our experimental codes and configuration files.</p>

    <p>We contributed the composed building blocks for ROIBIN-SZ3 into the <a href="https://github.com/robertu94/libpressio">libpressio</a>
    repository specifically <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc"><code>binning.cc</code></a>,  <a
    href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc"><code>roibin.cc</code></a>
    and <a href="https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h"><code>roibin_impl.h</code></a>
    in the <code>src/plugins/compressors</code> subdirectory.  The automated tuning
    implementation was used directly from <a href="https://github.com/robertu94/libpressio_opt">OptZConfig/LibPressioOpt</a>.</p>

    <p>See <a href="#obtaining-data">Obtaining Data</a> to request the dataset used.</p>

    <p>The quality assessment software was not designed in this paper.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Getting started</h2>

    <p>For ease of evaluation, we provide a docker container to evaluate our performance
    results.</p>

    <p>There are several key steps:</p>

    <ol>

    <li>Obtaining Data</li>

    <li>Installing the software (either in a container or on the host system)</li>

    <li>Running the experiments</li>

    </ol>

    <h3><a id="user-content-obtaining-data" class="anchor" aria-hidden="true" href="#obtaining-data"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining Data</h3>

    <p>The data for these experiments are extremely large (6+TB for one complete dataset
    used in the quality assessment). The full Se-SAD dataset is publicly available
    here <a href="https://cxidb.org/id-54.html" rel="nofollow">https://cxidb.org/id-54.html</a>,
    but require some domain knowledge to process the entire dataset. We include a
    subset of the data for testing roibin-sz3. For more information about CXI files
    used for this paper, contact the authors.</p>

    <p>To run in the container, you may need to set the files to world readable <code>chmod
    a+r</code> to be read inside the container depending on your container manager.</p>

    <h3><a id="user-content-quality-assessment" class="anchor" aria-hidden="true"
    href="#quality-assessment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Quality
    Assessment</h3>

    <p>The quality analysis results (Figures 1,4-8 and Table 3)  were produced using
    <a href="https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial"
    rel="nofollow">PSOCAKE</a>, <a href="https://phenix-online.org" rel="nofollow">PHENIX</a>,
    and <a href="https://www.ccp4.ac.uk" rel="nofollow">CCP4</a>.

    Correct use of this tool requires experience and expertise in serial

    crystallography and is outside the scope of this document.</p>

    <p>Where decompressed outputs were needed for inputs for these tools, they were
    outputted from the Performance Assessment codes.</p>

    <h3><a id="user-content-container-install-for-ease-of-setup" class="anchor" aria-hidden="true"
    href="#container-install-for-ease-of-setup"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Container Install (for ease of setup)</h3>

    <p>We provide a container for <code>x86_64</code> image for ease of installation.</p>

    <p>This container differs from our experimental setup in 2 ways:</p>

    <ol>

    <li>The production build used <code>-march=native -mtune=native</code> for architecture
    optimized builds where as the container does not use these flags to maximize compatablity
    across <code>x86_64</code> hardware.</li>

    <li>We use MPICH in the container rather than the OpenMPI because we found MPICH
    more reliably ran in the container during testing while OpenMPI was the system
    MPI.</li>

    </ol>

    <p>NOTE this file is &gt;= 6 GB (without datasets; see above), download with caution.</p>

    <h4><a id="user-content-singularity" class="anchor" aria-hidden="true" href="#singularity"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h4>

    <p>You can install and start the container on many super computers using singularity.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    this first commmand may issue a ton of warnings regarding xattrs depending on
    your filesystem on your container host; these were benign in our testing.</span>

    singularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> -c enables additional confinement
    than singularity uses by default to prevent polution from /home</span>

    <span class="pl-c"><span class="pl-c">#</span> -B bind mounts in the data directory
    containing your CXI files.</span>

    singularity run -c -B path/to/datadir:/data:ro roibin.sif bash</pre></div>

    <h4><a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h4>

    <p>You can run an example code on a small dataset by running with the following
    container and requesting a dataset.</p>

    <div class="highlight highlight-source-shell"><pre>docker pull ghcr.io/robertu94/roibin:latest

    <span class="pl-c"><span class="pl-c">#</span>most systems</span>

    docker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest


    <span class="pl-c"><span class="pl-c">#</span> if running on a SeLinux enforcing
    system</span>

    docker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin</pre></div>

    <h3><a id="user-content-building-the-container" class="anchor" aria-hidden="true"
    href="#building-the-container"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    the container</h3>

    <p>You can build the container yourself as follows:

    NOTE this process takes 3+ hours on a modern laptop, and most clusters do not

    provide sufficient permissions to run container builds on the cluster.</p>

    <p>Additional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to
    build.</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>
    install/module load git-lfs, needed to download example_data for building the
    container</span>

    sudo dnf install git-lfs <span class="pl-c"><span class="pl-c">#</span>Fedora/CentOS
    Stream 8</span>

    sudo apt-get install git-lfs <span class="pl-c"><span class="pl-c">#</span> Ubuntu</span>

    spack install git-lfs<span class="pl-k">;</span> spack load git-lfs <span class="pl-c"><span
    class="pl-c">#</span> using spack</span>


    <span class="pl-c"><span class="pl-c">#</span> clone this repository</span>

    git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    <span class="pl-c1">cd</span> roibin-sz3-experiments

    docker build <span class="pl-c1">.</span> -t roibin</pre></div>

    <p>If you forgot to install <code>git-lfs</code> before and have an empty <code>example_data</code>
    folder, you should install <code>git-lfs</code>

    and then run the following:</p>

    <pre><code>git lfs fetch

    git lfs checkout

    </code></pre>

    <h3><a id="user-content-manual-install-for-scale" class="anchor" aria-hidden="true"
    href="#manual-install-for-scale"><span aria-hidden="true" class="octicon octicon-link"></span></a>Manual
    Install (for scale)</h3>

    <p>The easiest way to install this manually is with <code>spack</code></p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/robertu94/roibin-sz3-experiments

    git clone https://github.com/spack/spack

    <span class="pl-c1">source</span> ./spack/share/spack/setup-env.sh

    spack compiler find


    spack env activate <span class="pl-c1">.</span>

    <span class="pl-c"><span class="pl-c">#</span>see note about MPI below</span>

    spack install


    mkdir build

    <span class="pl-c1">cd</span> build

    cmake ..</pre></div>

    <p>This software is not compatible with Windows, and hasn''t been tested on MacOS.</p>

    <p>Please note all functionality will not work on Debian/Ubuntu (due to known
    bug in LibPressio we hope to resolve soon).

    Please use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL,
    ...).

    Additionally some of this code requires a newer compiler and may not compile on
    older versions of CentOS.</p>

    <p>You may wish to configure the build to use your local version of MPI.

    Please see <a href="https://spack.readthedocs.io/en/latest/build_settings.html#external-packages"
    rel="nofollow">the spack guide</a> for how to do this.</p>

    <h2><a id="user-content-running-the-experiments" class="anchor" aria-hidden="true"
    href="#running-the-experiments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    the Experiments</h2>

    <p>Once the container is installed, you can run our testing commmands.</p>

    <div class="highlight highlight-source-shell"><pre>mpiexec -np <span class="pl-smi">$procs</span>
    /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json</pre></div>

    <p>where <code>-f</code> is the input data file, and <code>-p</code> is the configuration
    to use <code>-c</code> is the chunk size.</p>

    <p>Please see <code>run_all.sh</code> for our production configurations.</p>

    <h3><a id="user-content-example-output" class="anchor" aria-hidden="true" href="#example-output"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Example Output</h3>

    <p>NOTE results below from a laptop, not the server grade hardware from the paper

    and in the container with the differences noted above so bandwidth will differ.

    Additionally, this files results were only reported in aggregate in the paper

    and may not represent the entire 6TB dataset.  It was selected as one of the smaller

    files from the data-set to ease reproduce-ability.</p>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-e">[demo@620bb069495a
    app]</span>$ <span class="pl-s1"><span class="pl-c1">cd</span> /app</span>

    <span class="pl-e">[demo@620bb069495a app]</span>$ <span class="pl-s1">mpiexec
    -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json
    -c 32</span>

    <span class="pl-c1">/pressio/composite/time:time:metric &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/composite:composite:names &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/composite:composite:plugins &lt;char*[]&gt; = {size,
    time, }</span>

    <span class="pl-c1">/pressio/composite:composite:scripts &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite/time:time:metric
    &lt;char*&gt; = "noop"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:names
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:plugins
    &lt;char*[]&gt; = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz/composite:composite:scripts
    &lt;char*[]&gt; = {}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:metrics:errors_fatal
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:lossless &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:pw_rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:abs_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:app &lt;char*&gt;
    = "SZ"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_file &lt;char*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:config_struct &lt;void*&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:data_type &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str
    &lt;char*&gt; = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:bin_size &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peak_size
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs
    &lt;data&gt; = data{ type=byte dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim &lt;uint32&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:exafel:tolerance
    &lt;double&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:gzip_mode &lt;int32&gt;
    = 3</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:lossless_compressor
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:max_quant_intervals
    &lt;uint32&gt; = 65536</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pred_threshold &lt;float&gt;
    = 0.99</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:prediction_mode &lt;int32&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:protect_value_range
    &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:psnr_err_bound &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound
    &lt;double&gt; = 0.001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:quantization_intervals
    &lt;uint32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:rel_err_bound &lt;double&gt;
    = 0.0001</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sample_distance &lt;int32&gt;
    = 100</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:segment_size &lt;int32&gt;
    = 36</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step
    &lt;int32&gt; = 5</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sol_id &lt;int32&gt;
    = 101</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:sz_mode &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio/sz:sz:user_params &lt;void*&gt;
    = 0</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:abs &lt;double&gt;
    = 90</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:compressor &lt;char*&gt;
    = "sz"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:metric &lt;char*&gt;
    = "composite"</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:rel &lt;double&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background/pressio:pressio:reset_mode &lt;bool&gt;
    = &lt;empty&gt;</span>

    <span class="pl-c1">/pressio/roibin/background:binning:compressor &lt;char*&gt;
    = "pressio"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/background:binning:nthreads &lt;uint32&gt;
    = 4</span>

    <span class="pl-c1">/pressio/roibin/background:binning:shape &lt;data&gt; = data{
    type=double dims={3, } has_data=[2, 2, 1, ]}</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:copy_compressor_results
    &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/background:metrics:errors_fatal &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/background:pressio:metric &lt;char*&gt; =
    "composite"</span>

    <span class="pl-c1">/pressio/roibin/composite/time:time:metric &lt;char*&gt; =
    "noop"</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite/time:time:metric &lt;char*&gt;
    = "noop"</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:names &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:plugins &lt;char*[]&gt;
    = {size, time, }</span>

    <span class="pl-c1">/pressio/roibin/roi/composite:composite:scripts &lt;char*[]&gt;
    = {}</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:has_header &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin/roi:fpzip:prec &lt;int32&gt; = 0</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin/roi:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:metrics:copy_compressor_results &lt;int32&gt;
    = 1</span>

    <span class="pl-c1">/pressio/roibin:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:background &lt;char*&gt; = "binning"</span>

    <span class="pl-c1">/pressio/roibin:roibin:centers &lt;data&gt; = data{ type=byte
    dims={} has_data=false}</span>

    <span class="pl-c1">/pressio/roibin:roibin:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio/roibin:roibin:nthreads &lt;uint32&gt; = 1</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi &lt;char*&gt; = "fpzip"</span>

    <span class="pl-c1">/pressio/roibin:roibin:roi_size &lt;data&gt; = data{ type=double
    dims={3, } has_data=[8, 8, 0, ]}</span>

    <span class="pl-c1">/pressio:metrics:copy_compressor_results &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:metrics:errors_fatal &lt;int32&gt; = 1</span>

    <span class="pl-c1">/pressio:pressio:compressor &lt;char*&gt; = "roibin"</span>

    <span class="pl-c1">/pressio:pressio:metric &lt;char*&gt; = "composite"</span>

    <span class="pl-c1">/pressio:pressio:reset_mode &lt;bool&gt; = &lt;empty&gt;</span>


    <span class="pl-c1">processing 0 256</span>

    <span class="pl-c1">global_cr=51.805</span>

    <span class="pl-c1">wallclock_ms=2811</span>

    <span class="pl-c1">compress_ms=1098</span>

    <span class="pl-c1">compress_bandwidth_GBps=1.08781</span>

    <span class="pl-c1">wallclock_bandwidth_GBps=0.424909</span></pre></div>

    <p>In this output, the lines beginning with <code>/pressio</code> are the represent
    the configuration used for the experiment.

    All of the configurations we used can be found in the <code>/app/share</code>
    directory.

    More details on the meanings of these options by calling <code>pressio -a help
    &lt;compressor_id&gt;</code> where the compressor id is one of <code>binning</code>,
    <code>roi</code>, <code>opt</code>, <code>fpzip</code>, <code>sz</code>, <code>sz3</code>,
    <code>zfp</code>, <code>mgard</code>, <code>blosc</code>, etc...</p>

    <p>The <code>-o</code> flag provided in some of our run codes outputs the decompressed
    dataset.

    There is also a <code>-d</code> and <code>-D</code> which together output fine
    grained metrics on individual events.</p>

    <p>the lines <code>processing &lt;start&gt; &lt;end&gt;</code> show the progress
    of each stage of the compression.

    For example <code>processing 0 256</code> means that the first 256 events are
    being processed.</p>

    <p><code>global_cr</code> is the compression ratio across all events.

    <code>wallclock_ms</code> is the wall clock time including IO from the CXI file.  In
    the real system, there would not be the IO from the CXI files.

    <code>compress_ms</code> is the compression clock time.

    <code>compress_bandwidth_GBps</code> is the compression bandwidth in GB/s.

    <code>wallclock_bandwidth_GBps</code> is the wallclock bandwidth in GB/s</p>

    <h2><a id="user-content-results-for-figures" class="anchor" aria-hidden="true"
    href="#results-for-figures"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results
    for Figures</h2>

    <p>The script <code>run_all.sh</code> contains configurations for all runs for
    all results in the paper.  Each specific configuration corresponds to a configuration
    file in the <code>share</code> directory.  We would comment and uncomment specific
    sections to run various sub experiments. All results output metrics files (not
    the decompressed data) are also included from all past runs.</p>

    <p>The results for table 2 are in from the lines in the sectoin labeled "full_table2".

    The results for table 3 come from the section labeled "full scale" with cxi_file
    set to the appropriate dataset.

    The results for table 4 come from the section labeled "tune"

    The results for table 5 come from the section labeled "scalability"

    The results for table 6 come from the section labeled "overview"</p>

    <p>Many of the visualizations come from the section labeled "full scale"</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1648861627.0
roblatham00/cashersize:
  data_format: 2
  description: Exercise caching in the mochi context
  filenames:
  - spack.yaml
  full_name: roblatham00/cashersize
  latest_release: null
  readme: '<p>Your project "cachersize" has been setup!

    Enjoy programming with Mochi!</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1652377734.0
salotz/raylib-scopes:
  data_format: 2
  description: Raylib wrapper for the Scopes language
  filenames:
  - spack.yaml
  full_name: salotz/raylib-scopes
  latest_release: null
  readme: "<h1><a id=\"user-content-scopes-raylib\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#scopes-raylib\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>scopes-raylib</h1>\n<p>Bindings of <a href=\"https://github.com/raysan5/raylib\"\
    >Raylib</a> for the\n<a href=\"https://scopes.rocks\" rel=\"nofollow\">Scopes</a>\
    \ programming language.</p>\n<p>This is an incredibly thin wrapper as such and\
    \ you can basically use\nthe Raylib C-API with Scopes notation. Some of the naming\
    \ prefixes\nhave been scrubbed to make calling things less verbose.</p>\n<p>There\
    \ are a few macros added for \"begin-end\" type constructs that you\ncan see in\
    \ use in the examples, but you don't need to use them.</p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The module\
    \ is under <code>src/raylib</code>. You can copy this subtree into your\nproject\
    \ and then add it to the <code>package.path</code> in your Scopes\n<code>_project.sc</code>\
    \ file.</p>\n<h3><a id=\"user-content-with-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#with-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>With Spack</h3>\n<p>This module is available as the <code>scopes-raylib</code>\
    \ package in the\n<a href=\"https://github.com/salotz/snailpacks\">snailpacks</a>\
    \ repository. This will pull in the necessary dependencies\nincluding Scopes.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  spack install scopes-raylib</pre></div>\n\
    <p>See the <a href=\"https://github.com/salotz/snailpacks\">snailpacks</a> documentation\
    \ for more best practices of installing.</p>\n<h2><a id=\"user-content-development-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development-environment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development Environment</h2>\n\
    <p>We use <a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> to install\
    \ dependencies. First install Spack.</p>\n<p>Then you'll need our custom repo\
    \ of build recipes:</p>\n<div class=\"highlight highlight-source-shell\"><pre>\
    \  mkdir -p <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/.spack/repos</span>\n\
    <span class=\"pl-s\">  git clone git@github.com:salotz/snailpacks.git <span class=\"\
    pl-pds\">`</span></span>/.spack/repos/snailpacks\n  spack repo add <span class=\"\
    pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  spack env create -d <span class=\"pl-c1\">.</span></pre></div>\n<p>Activate\
    \ the environment (i.e. set the environment variables\nappropriately) and install\
    \ the packages:</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spacktivate\
    \ <span class=\"pl-c1\">.</span>\n  spack install</pre></div>\n<p>To exit the\
    \ environment (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics:
  - raylib
  - scopes-lang
  updated_at: 1648089749.0
salotz/scopes-chipmunk2d:
  data_format: 2
  description: Scopes language wrapper of Chipmunk2D
  filenames:
  - spack.yaml
  full_name: salotz/scopes-chipmunk2d
  latest_release: null
  readme: "<h1><a id=\"user-content-scopes-chipmunk2d\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#scopes-chipmunk2d\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>scopes-chipmunk2d</h1>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The module\
    \ is under <code>src/chipmunk2d</code>. You can copy this subtree into your\n\
    project and then add it to the <code>package.path</code> in your Scopes\n<code>_project.sc</code>\
    \ file.</p>\n<h3><a id=\"user-content-with-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#with-spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>With Spack</h3>\n<p>This module is available as the <code>scopes-chipmunk2d</code>\
    \ package in the\n<a href=\"https://github.com/salotz/snailpacks\">snailpacks</a>\
    \ repository. This will pull in the necessary dependencies\nincluding Scopes.</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>  spack install scopes-chipmunk2d</pre></div>\n\
    <p>See the <a href=\"https://github.com/salotz/snailpacks\">snailpacks</a> documentation\
    \ for more best practices of installing.</p>\n<h2><a id=\"user-content-development-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#development-environment\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development Environment</h2>\n\
    <p>We use <a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> to install\
    \ dependencies. First install Spack.</p>\n<p>Then you'll need our custom repo\
    \ of build recipes:</p>\n<div class=\"highlight highlight-source-shell\"><pre>\
    \  mkdir -p <span class=\"pl-s\"><span class=\"pl-pds\">`</span>/.spack/repos</span>\n\
    <span class=\"pl-s\">  git clone git@github.com:salotz/snailpacks.git <span class=\"\
    pl-pds\">`</span></span>/.spack/repos/snailpacks\n  spack repo add <span class=\"\
    pl-s\"><span class=\"pl-pds\">`</span>/resources/spack-repos/snailpacks</span></pre></div>\n\
    <p>Then you need to create an environment in this folder that will\ncontain the\
    \ headers and libraries etc.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  spack env create -d <span class=\"pl-c1\">.</span></pre></div>\n<p>Activate\
    \ the environment (i.e. set the environment variables\nappropriately) and install\
    \ the packages:</p>\n<div class=\"highlight highlight-source-shell\"><pre>  spacktivate\
    \ <span class=\"pl-c1\">.</span>\n  spack install</pre></div>\n<p>To exit the\
    \ environment (i.e. unset the env variables):</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>  despacktivate</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - scopes-lang
  - chipmunk2d
  updated_at: 1648788744.0
salotz/scopes-demos:
  data_format: 2
  description: null
  filenames:
  - 003_python-embed/spack.yaml
  - template/{{name}}/spack.yaml
  - 001_chipmunk2d-hello-world/spack.yaml
  - 002_pong/spack.yaml
  full_name: salotz/scopes-demos
  latest_release: null
  readme: "<h2><a id=\"user-content-running-the-demos\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#running-the-demos\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Running the Demos</h2>\n<p>You will need Spack installed\
    \ as well as the <a href=\"\">snailpacks</a> repo. The\nquick bootstrap script\
    \ should be enough to get going if you don't have\nthis installed already:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>curl --proto <span class=\"\
    pl-s\"><span class=\"pl-pds\">'</span>=https<span class=\"pl-pds\">'</span></span>\
    \ --tlsv1.2 -sSf https://raw.githubusercontent.com/salotz/snailpacks/master/bootstrap.sh\
    \ <span class=\"pl-k\">|</span> sh</pre></div>\n<p>Then for each demo you can\
    \ build the environment, activate it, and run\nthem.</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  <span class=\"pl-c1\">cd</span> XXX_demo-name\n\
    \  make env\n  spacktivate <span class=\"pl-c1\">.</span>\n  make run</pre></div>\n\
    <h2><a id=\"user-content-creating-a-new-demo\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#creating-a-new-demo\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Creating a New Demo</h2>\n<p>You can use the template\
    \ for a quick start (requires <code>copier</code> &gt; 6):</p>\n<div class=\"\
    highlight highlight-source-shell\"><pre>copier template</pre></div>\n<p>To update\
    \ the</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1657842137.0
salotz/scopes-lib_copier-template:
  data_format: 2
  description: Copier template for a Scopes library
  filenames:
  - template/spack.yaml
  full_name: salotz/scopes-lib_copier-template
  latest_release: null
  readme: "<h1><a id=\"user-content-project-template-for-a-scopes-lang-library\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#project-template-for-a-scopes-lang-library\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Project\
    \ Template for a Scopes Lang Library</h1>\n<p>This is a project template generator\
    \ and updater using the\n<a href=\"https://github.com/copier-org/copier/\">copier</a>\
    \ tool for creating libraries for the <a href=\"http://scopes.rocks\" rel=\"nofollow\"\
    >Scopes</a> programming language.</p>\n<p>Please install from the latest copier\
    \ for this to work, not the latest\nstable release. Currently I am using\n<a href=\"\
    https://github.com/pypa/pipx\">pipx</a>:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pipx install copier</pre></div>\n<h2><a id=\"user-content-generating-and-updating-a-project\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#generating-and-updating-a-project\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Generating\
    \ and Updating a Project</h2>\n<p>Then you can generate your project:</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>copier <span class=\"pl-s\"\
    ><span class=\"pl-pds\">'</span>gh:salotz/scopes-lib_copier-template<span class=\"\
    pl-pds\">'</span></span> name-of-folder</pre></div>\n<p>This should generate something\
    \ like the following (<code>repo_name = my-lib</code>):</p>\n<pre><code>name-of-folder\n\
    \u251C\u2500\u2500 __env.sc\n\u251C\u2500\u2500 Makefile\n\u251C\u2500\u2500 README.md\n\
    \u251C\u2500\u2500 spack.yaml\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500\
    \ my-lib\n        \u251C\u2500\u2500 init.sc\n        \u2514\u2500\u2500 ...\n\
    </code></pre>\n<p>You can update the project with:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> name-of-folder\n\
    copier update</pre></div>\n<p>See documentation of copier for more details.</p>\n\
    <h2><a id=\"user-content-development-environment\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#development-environment\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Development Environment</h2>\n<p>See the docs in <code>template/README.md.jinja</code>\
    \ that will be generated for\neach project.</p>\n<h2><a id=\"user-content-libraries-using-this-template\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#libraries-using-this-template\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Libraries\
    \ Using this Template</h2>\n<ul>\n<li><a href=\"https://github.com/salotz/raylib-scopes\"\
    >scopes-raylib</a></li>\n<li><a href=\"https://github.com/salotz/scopes-chipmunk2d\"\
    >scopes-chipmunk2d</a></li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - copier-template
  - scopes-lang
  updated_at: 1648781021.0
sayefsakin/auto_profiler:
  data_format: 2
  description: null
  filenames:
  - py_src/spack.yaml
  full_name: sayefsakin/auto_profiler
  latest_release: null
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1659512207.0
scifihpc/scibuilder:
  data_format: 2
  description: New build system for building scientific software.
  filenames:
  - test/appl_test/spack.yaml
  full_name: scifihpc/scibuilder
  latest_release: null
  readme: "<h1><a id=\"user-content-scibuilder\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#scibuilder\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Scibuilder</h1>\n<p>Scibuilder is a tool for helping with automated\
    \ builds</p>\n<h2><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Installation</h2>\n<p>Scibuilder is a Python module and it needs an\
    \ environment with various packages.</p>\n<p>We recommend using <code>mamba</code>\
    \ for faster installation.\n<a href=\"https://github.com/conda-forge/miniforge#install\"\
    >Mambaforge</a> is an excellent way\nof getting <code>mamba</code>.</p>\n<p>Creating\
    \ environment:</p>\n<div class=\"highlight highlight-source-shell\"><pre>mamba\
    \ env create --file environment.yml\n<span class=\"pl-c1\">source</span> activate\
    \ scibuilder</pre></div>\n<h2><a id=\"user-content-running-scibuilder-example\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#running-scibuilder-example\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running scibuilder\
    \ example</h2>\n<h3><a id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Spack</h3>\n<p>This example build works on Ubuntu 22.04. It installs\
    \ cmake as an example.</p>\n<div class=\"highlight highlight-source-shell\"><pre>git\
    \ clone https://github.com/spack/spack.git\n<span class=\"pl-c1\">.</span> spack/share/spack/setup-env.sh\n\
    python -m scibuilder spack build examples/without-image/spackbuilder_example.yml</pre></div>\n\
    <h3><a id=\"user-content-mamba\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #mamba\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mamba</h3>\n\
    <p>This example build will work on any linux system. It creates two conda environments:\n\
    one with gpu-enabled packgages and one without.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python -m scibuilder mamba build examples/without-image/mambabuilder_example.yml</pre></div>\n\
    <h2><a id=\"user-content-scibuilder-build-image\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#scibuilder-build-image\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>scibuilder-build-image</h2>\n<p>Scibuilder can be\
    \ run in a docker/podman images.</p>\n<p>See image <a href=\"dockerfiles/scibuilder-build-image/README.md\"\
    >README.md</a> for more information.</p>\n<h2><a id=\"user-content-configuring-builds\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-builds\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Configuring builds</h2>\n<h3><a\
    \ id=\"user-content-spack-1\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-1\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>Spack builds are configured by creating a YAML-file that describes what environments\
    \ we\nwant to build and the compilers we want to use for building them.</p>\n\
    <p>Let's look at <a href=\"examples/without-image/spackbuilder_example.yml\">examples/without-image/spackbuilder_example.yml</a>:</p>\n\
    <div class=\"highlight highlight-source-yaml\"><pre><span class=\"pl-ent\">environments</span>:\n\
    \  - <span class=\"pl-ent\">name</span>: <span class=\"pl-s\">spack_example</span>\n\
    \    <span class=\"pl-ent\">tags</span>:\n      - <span class=\"pl-s\">spack</span>\n\
    \      - <span class=\"pl-s\">main</span>\n    <span class=\"pl-ent\">environment_file</span>:\
    \ <span class=\"pl-s\">examples/without-image/spack_example_ubuntu22.04/spack.yaml</span>\n\
    \    <span class=\"pl-ent\">system_compiler</span>: <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>gcc@11.3.0<span class=\"pl-pds\">\"</span></span>\n\
    \    <span class=\"pl-ent\">compilers</span>:\n      - <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>gcc@11.3.0<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>The list <code>environments</code> consist of multiple independent build with\
    \ the following\nattributes:</p>\n<ul>\n<li>\n<code>name</code> - Name of the\
    \ environment</li>\n<li>\n<code>tags</code> - List of arbitrary tags that can\
    \ be used to limit the builder to only these\nbuilds via the <code>--tags=TAGS</code>-parameter.</li>\n\
    <li>\n<code>environmnet_file</code> - A spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">environement file</a>\nthat contains information on what packages\
    \ we want to install and where we want to install them.</li>\n<li>\n<code>system_compiler</code>\
    \ - A compiler present in the system that the builder will try to locate for\n\
    spack to use as an initial compiler.</li>\n<li>\n<code>compilers</code>: List\
    \ of compilers that spack will try to locate and build with the system compiler\n\
    before building the environment in full.</li>\n</ul>\n"
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1678697646.0
scs-lab/ChronoLog:
  data_format: 2
  description: 'ChronoLog: A High-Performance Storage Infrastructure for Activity
    and Log Workloads'
  filenames:
  - spack.yaml
  - CI/enviroment/spack.yaml
  full_name: scs-lab/ChronoLog
  latest_release: null
  readme: '<h1><a id="user-content-chronolog" class="anchor" aria-hidden="true" href="#chronolog"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ChronoLog</h1>

    <p>ChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads
    (NSF CSSI 2104013)</p>

    <h2><a id="user-content-chronolog-project-synopsis" class="anchor" aria-hidden="true"
    href="#chronolog-project-synopsis"><span aria-hidden="true" class="octicon octicon-link"></span></a>ChronoLog
    Project Synopsis</h2>

    <p>This project will design and implement ChronoLog, a distributed and tiered
    shared log storage ecosystem. ChronoLog uses physical time to distribute log entries
    while providing total log ordering. It also utilizes multiple storage tiers to
    elastically scale the log capacity (i.e., auto-tiering). ChronoLog will serve
    as a foundation for developing scalable new plugins, including a SQL-like query
    engine for log data, a streaming processor leveraging the time-based data distribution,
    a log-based key-value store, and a log-based TensorFlow module.</p>

    <h2><a id="user-content-workloads-and-applications" class="anchor" aria-hidden="true"
    href="#workloads-and-applications"><span aria-hidden="true" class="octicon octicon-link"></span></a>Workloads
    and Applications</h2>

    <p>Modern applications spanning from Edge to High Performance Computing (HPC)
    systems, produce and process log data and create a plethora of workload characteristics
    that rely on a common storage model: <strong>the distributed shared log</strong>.</p>

    <p><a target="_blank" rel="noopener noreferrer" href="/doc/images/log_centric_paradigm.svg"><img
    src="/doc/images/log_centric_paradigm.svg" alt="Log centric paradigm" style="max-width:
    100%;"></a></p>

    <h2><a id="user-content-features" class="anchor" aria-hidden="true" href="#features"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Features</h2>

    <p><a target="_blank" rel="noopener noreferrer" href="/doc/images/feature-matrix.png"><img
    src="/doc/images/feature-matrix.png" alt="Feature matrix" style="max-width: 100%;"></a></p>

    <h2><a id="user-content-checkout-chronolog" class="anchor" aria-hidden="true"
    href="#checkout-chronolog"><span aria-hidden="true" class="octicon octicon-link"></span></a>Checkout
    ChronoLog</h2>

    <p>ChronoLog uses HCL internally. It is added to this repository as a submodule.
    Thus, you need to clone the submodules as well. You can do it using <code>git
    clone --recursive git@github.com:scs-lab/ChronoLog.git</code> to clone ChronoLog.
    Or you can run <code>git submodule update --init --recursive</code> once in <code>ChronoLog</code>
    directory after you clone the repository without <code>--recursive</code>. For
    following pulls, you can update the submodule using command <code>git pull --recurse-submodules</code>.</p>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" href="#building"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>ChronoLog has a list of dependencies which can be solved by Spack packages.
    Thus, Spack needs to be installed and configured as the first step to build ChronoLog.</p>

    <h3><a id="user-content-install-spack" class="anchor" aria-hidden="true" href="#install-spack"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Install Spack</h3>

    <p>Spack can be checked out with <code>git clone https://github.com/spack/spack.git</code>.
    It is assumed that Spack is stored at <code>~/Spack</code> for the following step.
    Spack needs to activated by running <code>source ~/Spack/spack/share/spack/setup-env.sh</code>.</p>

    <h3><a id="user-content-install-chronolog-dependencies" class="anchor" aria-hidden="true"
    href="#install-chronolog-dependencies"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Install ChronoLog dependencies</h3>

    <p>Currently, most of the dependencies are listed in <code>spack.yaml</code> and
    can be installed via Spack.</p>

    <p>A Spack environment needs to be created and activated using the following commands.
    When the environment is activated, a shell prompt <code>[ChronoLog]</code> will
    pop up.</p>

    <pre><code>cd ChronoLog

    git switch develop

    spack env create -d .

    spack env activate -p .

    spack install -v

    </code></pre>

    <p>The installation may take some time (&gt; 30 minutes) to finish.</p>

    <p>Additionally, <code>rapidjson</code> is needed to parse the JSON configuration
    file. You can install it using command <code>sudo apt install rapidjson-dev</code>
    in Ubuntu.</p>

    <h3><a id="user-content-build-chronolog" class="anchor" aria-hidden="true" href="#build-chronolog"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build ChronoLog</h3>

    <p><strong>Please make sure all the building is carried out in the activated Spack
    environment.</strong> Otherwise, CMake will not able to find the dependencies.</p>

    <p>Three tests can be built for not to have a mini testbed. <code>chronovisor_server_test</code>
    is for the ChronoVisor. <code>chronolog_client_lib_connect_rpc_test</code> and
    <code>chronolog_client_lib_metadata_rpc_test</code> are two client apps to test
    the connection/disconnection and metadata operations (e.g., Chronicle and Story
    management) functionalities, respectively.</p>

    <pre><code>cd ChronoLog

    git switch develop

    mkdir build

    cd build

    cmake ..

    make chronovisor_server_test chronolog_client_lib_connect_rpc_test chronolog_client_lib_metadata_rpc_test

    </code></pre>

    <h3><a id="user-content-configuration-files" class="anchor" aria-hidden="true"
    href="#configuration-files"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configuration
    files</h3>

    <p>All ChronoLog executables share one unified configuration file. The template
    file can be found in <code>test/default_conf.json.in</code>. You can modify it
    for your own preferences. By default, all existing mini tests expect a configuration
    file <code>default_conf.json</code> in the same directory it launches. The default
    building process will copy and rename <code>test/default_conf.json.in</code> to
    achieve that. If you want to change the default configurations, you can edit the
    template file and rebuild the targets, or directly edit the file in the target
    directory.</p>

    <p>ChronoLog will support sockets/TCP/verbs protocols using ofi transport. You
    can run command <code>margo-info</code> to check which transports and protocols
    are supported on your system.</p>

    <hr>

    <h1><a id="user-content-coming-soon-" class="anchor" aria-hidden="true" href="#coming-soon-"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Coming soon ...</h1>

    <p>For more details about the ChronoLog project, please visit our website <a href="http://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html"
    rel="nofollow">http://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1675193782.0
smutch/regrider:
  data_format: 2
  description: Downsample gbpTrees and VELOCIraptor cartesian grids using FFTW
  filenames:
  - spack.yaml
  full_name: smutch/regrider
  latest_release: null
  readme: '<h1><a id="user-content-regrider" class="anchor" aria-hidden="true" href="#regrider"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Regrider</h1>

    <p>Downsample 3D cartesian grids using FFTW.</p>

    <p>Natively handles gbpTrees and VELOCIraptor files.</p>

    <h2><a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>TODO</h2>

    <ul>

    <li>[X] Malloc orig using FFTW (with inplace padding)</li>

    <li>[X] Do an inplace FFT</li>

    <li>[X] Convolution</li>

    <li>[X] Inverse FFTW</li>

    <li>[X] Reshuffle data inplace</li>

    <li>[X] Write the data back out</li>

    <li>[X] Get rid of choice of grid and convert all grids</li>

    <li>[X] Documentation</li>

    <li>[X] Do an implementation for VELOCIraptor</li>

    <li>[ ] Proper tests for known solutions</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1627973220.0
spack/gitlab-runners:
  data_format: 2
  description: Images used to run Gitlab pipelines in the cloud
  filenames:
  - spack.yaml
  full_name: spack/gitlab-runners
  latest_release: v2023-03-09
  readme: '<p>This repository contains images that are used to run Gitlab pipelines
    to validate PRs in Spack.</p>

    <p>The recipes have been modified from ones in: <a href="https://github.com/UO-OACISS/e4s">https://github.com/UO-OACISS/e4s</a></p>

    '
  stargazers_count: 1
  subscribers_count: 10
  topics: []
  updated_at: 1675192423.0
spack/spack-ci-containers:
  data_format: 2
  description: Container recipes used by Spack for test purposes
  filenames:
  - clingo/spack.yaml
  full_name: spack/spack-ci-containers
  latest_release: null
  readme: '<h1><a id="user-content-spack-ci-containers" class="anchor" aria-hidden="true"
    href="#spack-ci-containers"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    CI containers</h1>

    <p>This repository contains recipes for containers that are

    used to test Spack under CI.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-ci-containers/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-ci-containers/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1621989328.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-22.11/prod/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.08/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.08/prod/spack.yaml
  - NERSC/cori/e4s-20.10/prod/spack.yaml
  - OLCF/spock/spack.yaml
  - NERSC/perlmutter/e4s-22.05/gcc/spack.yaml
  - NERSC/perlmutter/e4s-22.11/prod/cce/spack.yaml
  - NERSC/cori/e4s-20.10/spack.yaml
  - OLCF/andes/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/cuda/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.08/spack.yaml
  - OLCF/frontier/spack.yaml
  - NERSC/cori/e4s-21.02/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/nvhpc/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/cce/spack.yaml
  - NERSC/perlmutter/e4s-21.11/ci/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/prod/spack.yaml
  - NERSC/perlmutter/e4s-22.11/prod/cuda/spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/gcc/spack.yaml
  - OLCF/crusher/spack.yaml
  - NERSC/perlmutter/e4s-22.11/prod/nvhpc/spack.yaml
  - OLCF/e4s-stacks/etc/spack.yaml
  - BOISESTATE/borah/applications/gromacs/_spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 49
  subscribers_count: 26
  topics: []
  updated_at: 1680649792.0
spack/spack-cscs2019:
  data_format: 2
  description: Slides for the "Software Management Course" at CSCS (May, 14th 2019)
  filenames:
  - docker/spack.yaml
  full_name: spack/spack-cscs2019
  latest_release: null
  readme: '<p>"Software Development and Deployment with Spack"</p>

    <p>Slides for the "Software Management Course" at CSCS (May 14th, 2019) in Lugano,
    based on the awesome <a href="https://github.com/hakimel/reveal.js">reveal.js</a></p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" href="#license"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>MIT licensed</p>

    <p>Copyright (C) 2019 Hakim El Hattab, Massimiliano Culpo</p>

    '
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1621966087.0
supercontainers/isc-tutorial:
  data_format: 2
  description: ISC 2022 -- Getting Started with Containers on HPC
  filenames:
  - files/spack_contenerize/spack.yaml
  - exercises/spack_contenerize/spack.yaml
  full_name: supercontainers/isc-tutorial
  latest_release: null
  readme: '<h1><a id="user-content-getting-started-with-containers-on-hpc" class="anchor"
    aria-hidden="true" href="#getting-started-with-containers-on-hpc"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Getting Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/isc-tutorial/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2><a id="user-content-ecp-supercontainers-tutorial-session" class="anchor" aria-hidden="true"
    href="#ecp-supercontainers-tutorial-session"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>ECP Supercontainers Tutorial Session</h2>

    <p><a target="_blank" rel="noopener noreferrer" href="fig/ecp.jpg"><img src="fig/ecp.jpg"
    width="250" style="max-width: 100%;"></a><a target="_blank" rel="noopener noreferrer"
    href="fig/pawsey.jpeg"><img src="fig/pawsey.jpeg" width="250" style="max-width:
    100%;"></a></p>

    <h2><a id="user-content-details" class="anchor" aria-hidden="true" href="#details"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Half-day Tutorial Session</p>

    <p>Venue: International Supercomputing Conference (ISC 2022)</p>

    <p>Date: 29 May 2022 2:00pm - 6:00pm, Central European Summer Time CEST (GMT+2)</p>

    <p>Location: Hamburg, Germany</p>

    <p>Link: <a href="https://app.swapcard.com/widget/event/isc-high-performance-2022/planning/UGxhbm5pbmdfODYxMTU3"
    rel="nofollow">ISC 2022 Schedule</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2><a id="user-content-ec2-login" class="anchor" aria-hidden="true" href="#ec2-login"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>EC2 Login</h2>

    <p>These will be provided the day of the tutorial.</p>

    <h2><a id="user-content-abstract" class="anchor" aria-hidden="true" href="#abstract"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Container computing has revolutionized the way applications are developed and
    delivered.  It offers opportunities that never existed before for significantly
    improving efficiency of scientific workflows and easily moving these workflows
    from the laptop to the supercomputer.  Tools like Docker, Shifter, Singularity,
    Charliecloud and Podman enable a new paradigm for scientific and technical computing.  However,
    to fully unlock its potential, users and administrators need to understand how
    to utilize these new approaches.  This tutorial will introduce attendees to the
    basics of creating container images, explain best practices, and cover more advanced
    topics such as creating images to be run on HPC platforms using various container
    runtimes.  The tutorial will also explain how research scientists can utilize
    container-based computing to accelerate their research and how these tools can
    boost the impact of their research by enabling better reproducibility and sharing
    of their scientific process without compromising security.</p>

    <p>This is an updated version of the highly successful tutorial presented at SC16-21
    and ISC19-21.</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>This is a hands-on tutorial.  Participants should bring a laptop and load or
    pre-install a terminal and/or ssh client in advance to make best use of time during
    the tutorial.  We will be providing training user accounts to both pre-configured
    EC2 instances.</p>

    <div><a target="_blank" rel="noopener noreferrer" href="fig/AWS_logo.png"><img
    src="fig/AWS_logo.png" width="250" style="max-width: 100%;"></a></div>

    <p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards.  EC2
    images and temporary login credentials will be distributed onsite at the tutorial.</p>

    <p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2
    to run through the tutorial again. We recommend you use your own EC2 key and change
    the password.</p>

    <p>US-West-Oregon: ami-0fe12765123c6a840</p>

    <h3><a id="user-content-optional-prerequisites" class="anchor" aria-hidden="true"
    href="#optional-prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optional
    Prerequisites</h3>

    <p>Users can also install Docker and Singularity prior to attending the tutorial
    session.  Here, it may be beneficial to create Docker and Sylabs (Singularity)
    accounts in advance at <a href="https://cloud.docker.com/" rel="nofollow">https://cloud.docker.com/</a>
    and <a href="https://cloud.sylabs.io/" rel="nofollow">https://cloud.sylabs.io/</a>.  These
    accounts will be needed to create images on Docker Cloud/Dockerhub and Sylabs
    Cloud.</p>

    <p><a href="https://sylabs.io/guides/3.7/user-guide/" rel="nofollow">Install Singularity
    on Linux</a></p>

    <p><a href="https://repo.sylabs.io/desktop/" rel="nofollow">Install Singularity
    on Mac</a> (Alpha)</p>

    <p><a href="https://www.docker.com/products/docker-desktop" rel="nofollow">Install
    Docker for Desktop</a></p>

    <h2><a id="user-content-questions" class="anchor" aria-hidden="true" href="#questions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-schedule-see-the-git-pages-site-for-the-autogenerated-version"
    class="anchor" aria-hidden="true" href="#schedule-see-the-git-pages-site-for-the-autogenerated-version"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Schedule (See the git
    pages site for the autogenerated version)</h2>

    <p>14:00 - 14:15 Introduction to containers in HPC (Shane)<br>

    Including defining jargon (containers, images, registries/repos,..)</p>

    <p>14:15 - 14:55 Build and run your first container (Eduardo)<br>

    Basic of containers and understanding the OCI Image Spec</p>

    <p>14:55 - 15:30 Deploy containers on a supercomputer (Alexis)</p>

    <p>15:30 - 16:00 High-performance containers (Alexis)</p>

    <p>16:00 - 16:30 BREAK</p>

    <p>16:30 - 17:05 Best practices (Shane)</p>

    <p>17:05 - 17:35 E4S containers initiative (Sameer)</p>

    <p>17:35 - 17:55 Advanced container builds (Eduardo)</p>

    <p>17:55 - 18:00 Wrap-up and final Q&amp;A</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics:
  - hpc
  - containers
  - singularity-container
  - singularity
  - shifter
  - docker
  - tutorial
  - supercomputer
  updated_at: 1659454820.0
supercontainers/sc-tutorials:
  data_format: 2
  description: SC Tutorials
  filenames:
  - exercises/spack_containerize/spack.yaml
  full_name: supercontainers/sc-tutorials
  latest_release: null
  readme: '<h1><a id="user-content-getting-started-with-containers-on-hpc" class="anchor"
    aria-hidden="true" href="#getting-started-with-containers-on-hpc"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Getting Started with Containers on HPC</h1>

    <p>View this on the <a href="https://supercontainers.github.io/sc-tutorials/"
    rel="nofollow">Tutorial Homepage</a>.</p>

    <h2><a id="user-content-hpc-containers-tutorial-session" class="anchor" aria-hidden="true"
    href="#hpc-containers-tutorial-session"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>HPC Containers Tutorial Session</h2>

    <p><a target="_blank" rel="noopener noreferrer" href="fig/ecp.jpg"><img src="fig/ecp.jpg"
    width="200" style="max-width: 100%;"></a><a target="_blank" rel="noopener noreferrer"
    href="fig/pawsey.png"><img src="fig/pawsey.png" width="200" style="max-width:
    100%;"></a><a target="_blank" rel="noopener noreferrer" href="fig/redhat.png"><img
    src="fig/redhat.png" width="200" style="max-width: 100%;"></a></p>

    <h2><a id="user-content-details" class="anchor" aria-hidden="true" href="#details"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Details</h2>

    <p>Full-day Tutorial Session</p>

    <p>Venue: Supercomputing Conference (SC 22)</p>

    <p>Date: Sunday November 13, 2022 8:30am - 5pm Central Standard Time (GMT -6)</p>

    <p>Location: Dallas TX, USA</p>

    <p>Link: <a href="https://sc22.supercomputing.org/presentation/?id=tut111&amp;sess=sess201"
    rel="nofollow">SC 2022 Tutorial Details</a></p>

    <p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific
    Software Development, DevOps</p>

    <h2><a id="user-content-abstract" class="anchor" aria-hidden="true" href="#abstract"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

    <p>Within just the past few years, the use of containers has revolutionized the
    way in which industries and enterprises have developed and deployed computational
    software and distributed systems. The containerization model has gained traction
    within the HPC community as well with the promise of improved reliability, reproducibility,
    portability, and levels of customization that were previously not possible on
    supercomputers. This adoption has been enabled by a number of HPC Container runtimes
    that have emerged including Singularity, Shifter, Enroot, Charliecloud and others.</p>

    <p>This hands-on tutorial looks to train users on the usability of containers
    on HPC resources. We will provide a detailed background on Linux containers, along
    with introductory hands-on experience building a container image, sharing the
    container and running it on a HPC cluster. Furthermore, the tutorial will provide
    more advanced information on how to run MPI-based and GPU-enabled HPC applications,
    how to optimize I/O intensive workflows, and how to setup GUI enabled interactive
    sessions. Cutting-edge examples will include machine learning and bioinformatics.
    Users will leave the tutorial with a solid foundational understanding of how to
    utilize containers with HPC resources through Shifter and Singularity, as well
    as an in-depth knowledge to deploy custom containers on their own resources.</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>Please consult the website for prerequisites and recommended setup steps.</p>

    <h2><a id="user-content-questions" class="anchor" aria-hidden="true" href="#questions"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Questions</h2>

    <p>You can ask questions verbally or with this <a href="https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing"
    rel="nofollow">Google Doc</a>.

    Please append your question below the others in the document.</p>

    <p>We have also created a Slack Team for this.  The invitation link is <a href="https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY"
    rel="nofollow">here</a>.</p>

    <h2><a id="user-content-schedule---autogenerated-from-the-metadata" class="anchor"
    aria-hidden="true" href="#schedule---autogenerated-from-the-metadata"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Schedule - Autogenerated from the metadata</h2>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics: []
  updated_at: 1649669614.0
tgamblin/cali-container:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: tgamblin/cali-container
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1667175253.0
thomas-bouvier/spack-envs:
  data_format: 2
  description: My Spack environments
  filenames:
  - thetagpu/spack.yaml
  - chifflot/v100/spack.yaml
  - cooley/spack.yaml
  - gemini/spack.yaml
  - chifflot/p100/spack.yaml
  - local/spack.yaml
  full_name: thomas-bouvier/spack-envs
  latest_release: null
  readme: '<h1><a id="user-content-spack-envs" class="anchor" aria-hidden="true" href="#spack-envs"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>spack-envs</h1>

    <pre><code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git
    ~/spack

    git clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages

    git clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs

    </code></pre>

    <h2><a id="user-content-locally" class="anchor" aria-hidden="true" href="#locally"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Locally</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: $spack/opt/spack</span>

    <span class="pl-c1">build_stage: $user_cache_path/stage</span>


    <span class="pl-c1">spack env activate ~/Dev/spack-envs/local</span>

    <span class="pl-c1">spack install</span></pre></div>

    <h2><a id="user-content-g5k" class="anchor" aria-hidden="true" href="#g5k"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>G5k</h2>

    <div class="highlight highlight-text-shell-session"><pre><span class="pl-c1">spack
    config --scope defaults edit config</span>

    <span class="pl-c1">install_tree: /mnt/spack</span>

    <span class="pl-c1">build_stage: /tmp/spack-stage</span></pre></div>

    <h2><a id="user-content-anl" class="anchor" aria-hidden="true" href="#anl"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ANL</h2>

    <h3><a id="user-content-cooley" class="anchor" aria-hidden="true" href="#cooley"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Cooley</h3>

    <p>Before using Spack to compile stuff on Cooley, we recommend to run <code>use_build_cooley</code>
    to get access to newer gcc, cmake, and mvapich versions.</p>

    <h3><a id="user-content-thetagpu" class="anchor" aria-hidden="true" href="#thetagpu"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ThetaGPU</h3>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1678891926.0
thomas-robinson/centos7-netcdff:
  data_format: 2
  description: Container files for building centos7 with netcdf fortran
  filenames:
  - spack.yaml
  full_name: thomas-robinson/centos7-netcdff
  latest_release: null
  readme: '<h1><a id="user-content-centos7-netcdff" class="anchor" aria-hidden="true"
    href="#centos7-netcdff"><span aria-hidden="true" class="octicon octicon-link"></span></a>centos7-netcdff</h1>

    <p>Container files for building centos7 with netcdf fortran</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1615473800.0
toxa81/se:
  data_format: 2
  description: Software environments
  filenames:
  - catalog-config/core/spack.yaml
  - catalog-config/libxc-5.2.3/spack.yaml
  full_name: toxa81/se
  latest_release: null
  readme: '<h1><a id="user-content-software-environments" class="anchor" aria-hidden="true"
    href="#software-environments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Software
    environments</h1>

    <p>Deployment steps</p>

    <ul>

    <li>clone spack <code>git clone https://github.com/spack/spack.git</code>

    </li>

    <li>enable spack <code>source enable-spack</code>

    </li>

    <li>srun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16</li>

    <li>install gcc-11.3.0 view <code>spack -e  ./env-spec/gcc-11.3.0/ install</code>

    </li>

    <li>install nvhpc-22.9 <code>srun -N1 --partition=nvgpu spack -e . install -j64</code>

    </li>

    </ul>

    <p>spack compiler find $(spack find --format {prefix.bin} gcc@11)</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1669195550.0
tpeterka/mpas-o-workflow:
  data_format: 2
  description: null
  filenames:
  - mpas_spack.yaml
  full_name: tpeterka/mpas-o-workflow
  latest_release: null
  readme: "<h1><a id=\"user-content-instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Instructions\
    \ for Building MPAS-Ocean to Run in a Wilkins Workflow</h1>\n<p>Installation is\
    \ done through Spack. If you don't have Spack installed or if Spack is new to\
    \ you, go <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\
    >here</a> first.</p>\n<p>Clone this repository and cd into it. These instructions\
    \ assume there is a top-level directory called climate.</p>\n<pre><code>mkdir\
    \ ~/climate\ncd ~/climate\ngit clone https://github.com/tpeterka/mpas-o-workflow\n\
    cd mpas-o-workflow\n</code></pre>\n<hr>\n<h2><a id=\"user-content-setting-up-spack-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-spack-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting\
    \ up Spack environment</h2>\n<h3><a id=\"user-content-first-time-create-and-load-the-spack-environment-for-mpas-ocean\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-and-load-the-spack-environment-for-mpas-ocean\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>First time:\
    \ create and load the Spack environment for MPAS-Ocean</h3>\n<pre><code>cd ~/climate/mpas-o-workflow\n\
    source ./create-mpas.sh     # requires being in the same directory to work properly\n\
    </code></pre>\n<h3><a id=\"user-content-subsequent-times-load-the-spack-environment-for-mpas-ocean\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#subsequent-times-load-the-spack-environment-for-mpas-ocean\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Subsequent\
    \ times: load the Spack environment for MPAS-Ocean</h3>\n<pre><code>source ~/climate/mpas-o-workflow/load-mpas.sh\n\
    </code></pre>\n<hr>\n<h2><a id=\"user-content-building-mpas-ocean\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#building-mpas-ocean\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Building MPAS-Ocean</h2>\n<h3><a id=\"\
    user-content-first-time-clone-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#first-time-clone-mpas-ocean\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>First time: clone MPAS-Ocean</h3>\n<pre><code>cd ~/climate\n\
    git clone https://github.com/E3SM-Project/E3SM\ncd E3SM\ngit submodule update\
    \ --init --recursive\n</code></pre>\n<h2><a id=\"user-content-first-time-modify-mpas-ocean-makefiles-to-link-to-henson\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-modify-mpas-ocean-makefiles-to-link-to-henson\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>First time:\
    \ modify MPAS-Ocean makefiles to link to Henson</h2>\n<p>Edit ~climate/E3SM/components/mpas-ocean/Makefile:</p>\n\
    <p>Insert at line 596:\n<code>LIBS += -L $(HENSON)/lib -lhenson</code></p>\n<p>Insert\
    \ at line 732:\n<code>LDFLAGS += -shared</code></p>\n<p>Edit line 1002 to add\
    \ .so to executable name: <code>$(EXE_NAME).so</code></p>\n<h3><a id=\"user-content-build-mpas-ocean\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#build-mpas-ocean\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Build MPAS-Ocean</h3>\n<pre><code>cd\
    \ ~/climate/E3SM/components/mpas-ocean\nmake clean              # if dirty\nmake\
    \ -j gfortran\n</code></pre>\n<p>This will take ~ 5 minutes to compile.</p>\n\
    <h3><a id=\"user-content-create-a-run-script-for-mpas-ocean\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#create-a-run-script-for-mpas-ocean\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Create a run script for MPAS-Ocean</h3>\n\
    <p>Edit (create) <code>~/climate/E3SM/components/mpas-ocean/ocean_model</code>:</p>\n\
    <p><code>python3 ~/climate/mpas-o-workflow/mpas-henson.py</code></p>\n<p>Set permissions\
    \ of <code>ocean_model</code> to executable:</p>\n<p><code>chmod 755 ~/climate/E3SM/components/mpas-ocean/ocean_model</code></p>\n\
    <hr>\n<h2><a id=\"user-content-setting-up-a-test-case-to-execute\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#setting-up-a-test-case-to-execute\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Setting up a test case to execute</h2>\n\
    <p>Compass is an E3SM system for generating and running test cases for MPAS-Ocean,\
    \ and relies on conda environments. The instructions below assume you have conda\
    \ or miniconda already installed. If not, go <a href=\"https://docs.conda.io/en/latest/miniconda.html\"\
    \ rel=\"nofollow\">here</a> first.</p>\n<h3><a id=\"user-content-first-time-install-compass-and-create-compass-environment\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-install-compass-and-create-compass-environment\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>First time:\
    \ install Compass and create Compass environment</h3>\n<pre><code>cd ~\ngit clone\
    \ https://github.com/MPAS-Dev/compass.git compass-env-only\ncd ~/compass-env-only\n\
    git submodule update --init --recursive\n./conda/configure_compass_env.py --conda\
    \ ~/miniconda3 --env_only\nsource load_dev_compass_1.2.0-alpha.4.sh        # load_dev_compass-1.2.0-alpha.4.sh\
    \ is the script created by the previous command\n</code></pre>\n<h3><a id=\"user-content-first-time-create-a-compass-configuration-file-for-a-new-machine\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-a-compass-configuration-file-for-a-new-machine\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>First time:\
    \ create a compass configuration file for a new machine</h3>\n<p>Assumes the config\
    \ file is named ~/compass-env-only/compass.cfg and has these contents, or similar\
    \ (yours may vary)</p>\n<pre><code># This file contains some common config options\
    \ you might want to set\n\n# The paths section describes paths to databases and\
    \ shared compass environments\n[paths]\n\n# A root directory where MPAS standalone\
    \ data can be found\ndatabase_root = /home/tpeterka/compass/mpas_standalonedata\n\
    \n# The parallel section describes options related to running tests in parallel\n\
    [parallel]\n\n# parallel system of execution: slurm or single_node\nsystem = single_node\n\
    \n# whether to use mpirun or srun to run the model\nparallel_executable = mpiexec\n\
    \n# cores per node on the machine, detected automatically by default\n# cores_per_node\
    \ = 4\n</code></pre>\n<h3><a id=\"user-content-first-time-create-test-case-for-the-executable\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-test-case-for-the-executable\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>First time:\
    \ create test case for the executable</h3>\n<p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code>\
    \ is the name of the conda environment load script created initially</p>\n<pre><code>source\
    \ ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh\ncompass setup -t ocean/baroclinic_channel/10km/default\
    \ -w ~/spack-baroclinic-test -p ~/climate/E3SM/components/mpas-ocean -f ~/compass-env-only/compass.cfg\n\
    </code></pre>\n<p>Set the output file type for the test case:</p>\n<p>Edit <code>~/spack-baroclinic-test/ocean/baroclinic_channel/10km/default/forward/streams.ocean</code>.</p>\n\
    <p>Add <code>io_type=\"netcdf4\"&gt;</code> to the <code>&lt;stream name=\"output\"\
    </code> section of the file. E.g.,</p>\n<pre><code>&lt;stream name=\"output\"\n\
    \        type=\"output\"\n        filename_template=\"output.nc\"\n        filename_interval=\"\
    01-00-00_00:00:00\"\n        reference_time=\"0001-01-01_00:00:00\"\n        clobber_mode=\"\
    truncate\"\n        precision=\"double\"\n        output_interval=\"0000_00:00:01\"\
    \n        io_type=\"netcdf4\"&gt;\n\n    &lt;var_struct name=\"tracers\"/&gt;\n\
    \    &lt;var name=\"xtime\"/&gt;\n    &lt;var name=\"normalVelocity\"/&gt;\n \
    \   &lt;var name=\"layerThickness\"/&gt;\n&lt;/stream&gt;\n</code></pre>\n<h3><a\
    \ id=\"user-content-run-the-test-case\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#run-the-test-case\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Run the test case</h3>\n<p>Assumes that <code>load_dev_compass_1.2.0-alpha.4.sh</code>\
    \ is the name of the conda environment load script created initially</p>\n<pre><code>source\
    \ ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh\nsource ~/climate/mpas-o-workflow/load-mpas.sh\n\
    cd ~/spack-baroclinic-test/ocean/baroclinic_channel/10km/default\ncompass run\n\
    </code></pre>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1679076329.0
tvandera/spack-repos:
  data_format: 2
  description: null
  filenames:
  - var/spack/environments/intelmpi/bpmf-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/karolina/bpmf-ompss-cluster/spack.yaml
  - var/spack/environments/karolina/bpmf-gpi/spack.yaml
  - var/spack/environments/karolina/bpmf-mpi_isend/spack.yaml
  - var/spack/environments/karolina/bpmf-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-mpi_isend/spack.yaml
  - var/spack/environments/intelmpi/bpmf-gpi/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-argo/spack.yaml
  - var/spack/environments/intelmpi/bpmf-ompss-cluster/spack.yaml
  full_name: tvandera/spack-repos
  latest_release: null
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1635166163.0
ucdavis/spack-ucdavis:
  data_format: 2
  description: null
  filenames:
  - environments/hpccf/farm/libs/spack.yaml
  - environments/hpccf/franklin/cluster-core/spack.yaml
  full_name: ucdavis/spack-ucdavis
  latest_release: null
  readme: '<h1><a id="user-content-spack--uc-davis" class="anchor" aria-hidden="true"
    href="#spack--uc-davis"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    @ UC Davis</h1>

    <h2><a id="user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters" class="anchor"
    aria-hidden="true" href="#spack-repos-and-configs-for-uc-davis-hpccf-clusters"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Spack repos and configs
    for UC Davis HPCCF Clusters</h2>

    <p>This repo contains package specs, configurations, and utility scripts for

    <a href="https://spack.readthedocs.io/en/latest/index.html" rel="nofollow">spack</a>
    deployments on

    clusters managed by the UC Davis High Performance Computing Core Facility.</p>

    <p>The structure of this repo is as follows:</p>

    <ul>

    <li>

    <code>repos/hpccf</code>: Our spack package specifications. This includes both
    overrides

    of <code>builtin</code> and from-scratch specs. The packages are namespaced under
    <code>ucdavis.hpccf</code>.</li>

    <li>

    <code>templates/hpccf</code>: Template extensions for module management.</li>

    <li>

    <code>config/hpccf/[SITE]</code>: Site-specific configuration files. <code>[SITE]</code>
    directories

    correspond to cluster names. These are linked to <code>${SPACK_ROOT}/etc/spack/</code>
    when deployed.</li>

    <li>

    <code>bin</code>: Utility scripts.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1676322811.0
ucsd-galaxy-lab/agora-gizmo-runs:
  data_format: 2
  description: null
  filenames:
  - env/spack.yaml
  full_name: ucsd-galaxy-lab/agora-gizmo-runs
  latest_release: null
  readme: '<h1><a id="user-content-agora-gizmo-runs" class="anchor" aria-hidden="true"
    href="#agora-gizmo-runs"><span aria-hidden="true" class="octicon octicon-link"></span></a>AGORA
    GIZMO Runs</h1>

    <p>This repository contains data and notes needed to reproduce several GIZMO runs
    for the AGORA project.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1609960274.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - benchmarks/spack/dial3/compute-node/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1><a id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#excalibur-tests\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks and regression tests\
    \ for the ExCALIBUR project.</p>\n<p>These benchmarks are based on a similar project\
    \ by\n<a href=\"https://github.com/stackhpc/hpc-tests\">StackHPC</a>.</p>\n<p><em><strong>Note</strong>:\
    \ at the moment the ExCALIBUR benchmarks are a work-in-progress.</em></p>\n<h2><a\
    \ id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"\
    #installation\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>It is recommended to install the <strong>excalibur-tests</strong> package with\
    \ <code>pip</code> by</p>\n<div class=\"highlight highlight-source-shell\"><pre>pip\
    \ install <span class=\"pl-c1\">.</span></pre></div>\n<p>On most systems, it is\
    \ recommended to install the package in a virtual environment.\nFor example, using\
    \ the python3 <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow\"\
    >built-in virtual environment tool <code>venv</code></a>,\ncreate an environment\
    \ called <code>my_environment</code> with</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python3 -m venv ./my_environment</pre></div>\n<p>and activate it with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">source</span>\
    \ ./my_environment/bin/activate</pre></div>\n<p>For <a href=\"https://setuptools.pypa.io/en/latest/userguide/development_mode.html\"\
    \ rel=\"nofollow\">development</a>,\npass the <code>-e/--editable</code> flag\
    \ to <code>pip</code> to link the installed package to the files in the local\n\
    directory, instead of copying, to be able to make changes to the installed package.</p>\n\
    <h2><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\"\
    \ href=\"#requirements\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Requirements</h2>\n<p>The pip install will install a compatible version\
    \ of <strong>ReFrame</strong> from\n<a href=\"https://pypi.org/project/ReFrame-HPC/\"\
    \ rel=\"nofollow\">PyPi</a>. However, you will have to\nmanually provide an installation\
    \ of <strong>Spack</strong>.</p>\n<h3><a id=\"user-content-spack\" class=\"anchor\"\
    \ aria-hidden=\"true\" href=\"#spack\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Spack</h3>\n<p><a href=\"https://spack.io/\" rel=\"\
    nofollow\">Spack</a> is a package manager specifically designed for HPC\nfacilities.\
    \ In some HPC facilities there may be already a central Spack installation available.\n\
    However, the version installed is most likely too old to support all the features\n\
    used by this package. Therefore we recommend you install the latest version locally,\n\
    following the instructions below.</p>\n<p><em><strong>Note</strong>: if you have\
    \ already installed spack locally and you want to upgrade to\na newer version,\
    \ you might first have to clear the cache to avoid conflicts:\n<code>spack clean\
    \ -m</code></em></p>\n<p>Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official instructions</a>\nto install the latest version of\
    \ Spack (summarised here for convenience, but not guaranteed to be\nup-to-date):</p>\n\
    <ul>\n<li>git clone spack:\n<code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code>\n\
    </li>\n<li>run spack setup script: <code>source ./spack/share/spack/setup-env.sh</code>\n\
    </li>\n<li>check spack is in <code>$PATH</code>, for example <code>spack --version</code>\n\
    </li>\n</ul>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable. This\
    \ is taken care of by the <code>setup-env.sh</code>\nscript as above, and you\
    \ can have your shell init script (e.g. <code>.bashrc</code>)\ndo that automatically\
    \ in every session, by adding the following lines to it:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame also requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRAC projects in\n\
    <a href=\"https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack\"\
    >https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack/</a>.\n\
    If you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system if known, otherwise it will automatically\ncreate a very basic environment\
    \ (see \"Usage on unsupported systems\" section below).</p>\n<h3><a id=\"user-content-reframe\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#reframe\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>ReFrame</h3>\n<p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\"\
    \ rel=\"nofollow\">ReFrame</a> is a high-level\nframework for writing regression\
    \ tests for HPC systems.  For our tests we\nrequire ReFrame v4.1.3.</p>\n<p>If\
    \ you need to manually install ReFrame, follow the <a href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\"\
    \ rel=\"nofollow\">official\ninstructions</a> to\ninstall this package.  Note\
    \ that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a\
    \ specific module to have this version of Python available.</p>\n<p>We provide\
    \ a ReFrame configuration file with the settings of some systems that\nare part\
    \ of the ExCALIBUR or DiRAC projects.  You can point ReFrame to this file by\n\
    setting the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILE</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILE=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${PWD}</span>/benchmarks/reframe_config.py<span class=\"pl-pds\">\"</span></span></pre></div>\n\
    <p>If you want to use a different ReFrame configuration file, for example because\n\
    you use a different system, you can set this environment variable to the path\
    \ of\nthat file.</p>\n<p><strong>Note</strong>: in order to use the Spack build\
    \ system in ReFrame, the <code>spack</code>\nexecutable must be in the <code>PATH</code>\
    \ also on the compute nodes of a cluster, if\nyou want to run your benchmarks\
    \ on them. This is taken care of by adding it\nto your init file (see spack section\
    \ above).</p>\n<p>However, you will also need to set the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ (<code>export RFM_USE_LOGIN_SHELL=\"Yes\"</code>) in order to make ReFrame use</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">!</span><span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash -l</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a> line, which would load\nthe user's init script.</p>\n<h2><a id=\"\
    user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <p>Once you have set up Spack and ReFrame, you can execute a benchmark with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/BENCH_NAME\
    \ -r --performance-report</pre></div>\n<p>where <code>benchmarks/apps/BENCH_NAME</code>\
    \ is the directory where the benchmark is.  The command\nabove assumes you have\
    \ the program <code>reframe</code> in your PATH.  If you have followed the instructions\n\
    to install using <code>pip</code> into the default directory, it should have been\
    \ automatically added.\nIf it is not the case, call <code>reframe</code> with\
    \ its relative or absolute path.</p>\n<p>For example, to run the Sombrero benchmark\
    \ in the <code>benchmarks/apps/sombrero</code> directory you can\nuse</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/sombrero\
    \ -r --performance-report</pre></div>\n<p>For benchmarks that use the Spack build\
    \ system, the tests define a default Spack specification\nto be installed in the\
    \ environment, but users can change it when invoking ReFrame on the\ncommand line\
    \ with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3><a id=\"user-content-setting-environment-variables\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#setting-environment-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting\
    \ environment variables</h3>\n<p>All the built-in fields of ReFrame regression\
    \ classes can be set on a per-job basis using the\n<code>-S</code> command-line\
    \ option. One useful such field is\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.env_vars\"\
    \ rel=\"nofollow\"><code>env_vars</code></a>,\nwhich controls the environment\
    \ variables used in a job.\nThe syntax to set dictionary items, like for <code>env_vars</code>,\
    \ is a comma-separated list of <code>key:value</code> pairs: <code>-S dict=key_1:value_1,key_2:value_2</code>.\n\
    For example</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S env_vars=OMP_PLACES:threads\n</code></pre>\n<p>runs the <code>benchmarks/apps/sombrero</code>\
    \ benchmark setting the environment variable <code>OMP_PLACES</code>\nto <code>threads</code>.</p>\n\
    <h3><a id=\"user-content-selecting-system-and-queue-access-options\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#selecting-system-and-queue-access-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  To avoid this, you can use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3><a id=\"user-content-usage-on-unsupported-systems\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#usage-on-unsupported-systems\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage on\
    \ unsupported systems</h3>\n<p>The configuration provided in <a href=\"./reframe_config.py\"\
    ><code>reframe_config.py</code></a> lets you run the\nbenchmarks on pre-configured\
    \ HPC systems.  However you\ncan use this framework on any system by choosing\
    \ the \"generic\" system with <code>--system generic</code>, or by using your\
    \ own ReFrame configuration.  You can use the \"generic\" system to run\nbenchmarks\
    \ in ReFrame without using a queue manager or an MPI launcher (e.g. on a personal\
    \ workstation).</p>\n<p>If you choose the \"generic\" system and a benchmark using\
    \ the Spack build system,\na new empty Spack environment will be automatically\
    \ created in\n<code>spack-environments/generic</code> when ReFrame is launched\
    \ for the first time.\nYou should populate the environment with the packages already\
    \ installed on your system\nbefore running Spack to avoid excessively rebuilding\
    \ system packages. See the\n<em>Spack configuration</em> section of <a href=\"\
    ./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on how\n\
    to set up a Spack environment.\nIn particular, make sure that at least a compiler\
    \ and an MPI library are added into the environment.\nAfter the Spack environment\
    \ is set up, tell ReFrame to use it by setting the environment\nvariable <code>EXCALIBUR_SPACK_ENV</code>,\
    \ as described above.</p>\n<h3><a id=\"user-content-system-specific-flags\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#system-specific-flags\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>System-specific flags</h3>\n\
    <p>While the aim is to automate as much system-specific configuration as possible,\
    \ there are some options that have to be provided by the user, such as accounting\
    \ details, and unfortunately the syntax can vary.\nThe file <a href=\"./SYSTEMS.md\"\
    ><code>SYSTEMS.md</code></a> contains information about the use of this framework\
    \ on specific systems.</p>\n<h2><a id=\"user-content-contributing-new-systems-or-benchmarks\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#contributing-new-systems-or-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\
    \ <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 8
  subscribers_count: 7
  topics: []
  updated_at: 1680953656.0
uturuncoglu/testing:
  data_format: 2
  description: It is used for component testing and GitHub Action implementation
  filenames:
  - spack.yaml
  full_name: uturuncoglu/testing
  latest_release: null
  readme: '<h1><a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>testing</h1>

    <p>It is used for component testing and GitHub Action implementation</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1657212117.0
vanderwb/spack-crayenv:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: vanderwb/spack-crayenv
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon octicon-link"></span></a>NCAR
    Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>crayenv</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Fri Jun 17 18:21:49 MDT 2022</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>24319d896f9bd0d58f5327fd89f251d80b844198</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>22.02</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td>v0.18.0</td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/scratch/vanderwb/spack-tests/crayenv/22.02</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/scratch/vanderwb/spack-tests/crayenv/22.02/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1655513096.0
veit/jupyter-tutorial:
  data_format: 2
  description: 'Training materials for setting up and using a research infrastructure
    based on Jupyter notebooks: https://cusy.io/en/seminars'
  filenames:
  - spackenvs/python-38/spack.yaml
  - spackenvs/python-374/spack.yaml
  full_name: veit/jupyter-tutorial
  latest_release: 0.8.0
  stargazers_count: 19
  subscribers_count: 5
  topics:
  - jupyter
  - jupyter-notebooks
  - jupyter-kernels
  - ipython
  - ipywidgets
  - ipython-widget
  - spack
  - pipenv
  - dvc
  - data-science
  - pandas
  updated_at: 1678958728.0
wangzhezhe/mona-vtk:
  data_format: 2
  description: null
  filenames:
  - spack.yaml
  full_name: wangzhezhe/mona-vtk
  latest_release: null
  readme: "<h1><a id=\"user-content-mona-vtk-examples\" class=\"anchor\" aria-hidden=\"\
    true\" href=\"#mona-vtk-examples\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>MoNA-VTK examples</h1>\n<p>This repo shows how to\
    \ implement the MonaController and use it for Paraview Catalyst to do the in-situ\
    \ data analytics. The <code>src</code> folder contains the implementation details\
    \ of the MonaController based on the MonaCommunicator which is implemented based\
    \ on <a href=\"https://github.com/mochi-hpc/mochi-mona\">mochi-mona</a>.</p>\n\
    <p>There are several examples in the <code>example</code> folder:</p>\n<ul>\n\
    <li>\n<p>basic: This example shows that how the MonaController can be used to\
    \ execute the basic vtk parallel operations such as send and recv vtk object.</p>\n\
    </li>\n<li>\n<p>icetExample: This exmaple shows that how the mochi-mona can be\
    \ used to execute the iceT test cases based on the iceT wrapper for the mochi-mona.</p>\n\
    </li>\n<li>\n<p>MandelbulbCatalystExample: This example shows how the MonaController\
    \ can be used to execute the tightly coupled in-situ analytics in distributed\
    \ way.</p>\n</li>\n<li>\n<p>MandelbulbColza: This example shows how the MonaController\
    \ can be used to execute the loosely coupled in-situ analytics in distributed\
    \ way, the <a href=\"https://github.com/mochi-hpc/mochi-colza\">mochi-colza</a>\
    \ is used as the data staging service for this example.</p>\n</li>\n<li>\n<p>GrayScottColza:\
    \ This example is similar with the MandelbulbColza case but the simulation data\
    \ is generated by Gray-Scott simulation.</p>\n</li>\n</ul>\n<h2><a id=\"user-content-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#installing\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n<p>We assume\
    \ there is a new account on cori system, and we need following operations to install\
    \ necessary depedencies</p>\n<p><strong>Spack configuration</strong></p>\n<p>There\
    \ are two ways to use the Spack to install the software packages, the first one\
    \ is to init the package.yaml file and the second one is to use the spack env.</p>\n\
    <p>For example, we use <code>spack arch -p</code> to check the current architecture.\
    \ If the architecture is the cray, the <code>package.yaml</code> file should locate\
    \ at the <code>~/.spack/cray/</code>. And we update the <code>package.yaml</code>\
    \ file as needed for installing the mochi-software stacks. One sample <code>package.yaml</code>\
    \ for cori system is located in <code>./config/cori/packages.yaml</code>.</p>\n\
    <p>The repo of the spack used by the mochi project: <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo.git\"\
    \ rel=\"nofollow\">https://xgitlab.cels.anl.gov/sds/sds-repo.git</a>, we need\
    \ to add this repo into the spack system by executing <code>spack repo add sds-repo</code>\
    \ at the current direactly.</p>\n<p><strong>Building ParaView patch version</strong></p>\n\
    <p>The source code of ParaView patch is located at this repo: <a href=\"https://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration\"\
    \ rel=\"nofollow\">https://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration</a>.</p>\n\
    <pre><code>git clone https://gitlab.kitware.com/mdorier/paraview.git\ncd paraview\n\
    git checkout ecb0a075f459c9db78bdd57bf83d715a99f0fe55\ngit submodule update --init\
    \ --recursive\n</code></pre>\n<p>The ParaView needs the osmesa to support the\
    \ capability of in-situ rendering. We use the osmesa installed by the spack on\
    \ the cori system:</p>\n<pre><code>module load spack\nspack load -r mesa/qozjngg\n\
    PATH=\"/global/common/cori/software/altd/2.0/bin:$PATH\"\n</code></pre>\n<p>We\
    \ also need to set the compiler on the cori before building the ParaView</p>\n\
    <pre><code># for compiling vtk on cori\nexport CRAYPE_LINK_TYPE=dynamic\n\n# let\
    \ cc and CC to be the gnu compier\nmodule swap PrgEnv-intel PrgEnv-gnu\n\nmodule\
    \ swap gcc/8.3.0 gcc/9.3.0\n</code></pre>\n<p>At the build direactory of the ParaView,\
    \ we use cmake commands as follows (if we assume the source direactory is <code>~/cworkspace/src/ParaView_patch/paraview</code>):</p>\n\
    <pre><code>cmake ~/cworkspace/src/ParaView_patch/paraview -DPARAVIEW_USE_QT=OFF\
    \ -DPARAVIEW_USE_PYTHON=ON -DPARAVIEW_USE_MPI=ON -DVTK_OPENGL_HAS_OSMESA:BOOL=TRUE\
    \ -DVTK_USE_X:BOOL=FALSE -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_PYTHON_OPTIONAL_LINK=OFF\
    \ -DCMAKE_BUILD_TYPE=Release\n</code></pre>\n<p>with the gcc and openmpi</p>\n\
    <pre><code>module unload cray-mpich/7.7.10\nmodule load cgpu cuda openmpi\n\n\
    cmake ~/cworkspace/src/ParaView_matthieu/paraview/ -DPARAVIEW_USE_QT=OFF -DPARAVIEW_USE_PYTHON=ON\
    \ -DPARAVIEW_USE_MPI=ON -DVTK_OPENGL_HAS_OSMESA:BOOL=TRUE -DVTK_USE_X:BOOL=FALSE\
    \ -DCMAKE_CXX_COMPILER=g++ -DCMAKE_C_COMPILER=gcc -DVTK_PYTHON_OPTIONAL_LINK=OFF\
    \ -DCMAKE_BUILD_TYPE=Release\n</code></pre>\n<p><strong>Building and installing\
    \ Colza</strong></p>\n<p>This command will install the mochi-colza and other related\
    \ mochi softwares</p>\n<pre><code>spack install mochi-colza@main+drc+examples%gcc@9.3.0\n\
    </code></pre>\n<p><strong>Building all examples</strong></p>\n<p>We can load these\
    \ depedencies if all packages are installed successfully. The sample commands\
    \ are located in <code>config/cori/monavtkEnv.sh</code>. We execute these commands\
    \ before building the mona-vtk examples.</p>\n<p>Then we can build the mona-vtk\
    \ the cmake command like this:</p>\n<pre><code>cmake ~/cworkspace/src/mona-vtk/\
    \ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=$SCRATCH/build_paraview_matthieu_release/\
    \ -DENABLE_EXAMPLE=ON -DParaView_DIR=$SCRATCH/build_paraview_matthieu_release/\
    \ -DBUILD_SHARED_LIBS=ON \n</code></pre>\n<h2><a id=\"user-content-running\" class=\"\
    anchor\" aria-hidden=\"true\" href=\"#running\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Running</h2>\n<p>The scripts for scale evaluation\
    \ are located at the <code>example/MandelbulbColza/testScripts</code> and <code>./example/GrayScottColza/testScripts</code>\
    \ separately.</p>\n<p>For example, we can set the build and src dir properly at\
    \ the beginning of the scripts, such as</p>\n<pre><code>BUILDDIR=/global/cscratch1/sd/zw241/build_monavtk\n\
    SRCDIR=/global/homes/z/zw241/cworkspace/src/mona-vtk\n</code></pre>\n<p>and then\
    \ use sbatch to submit jobs with specific node configurations as needed:</p>\n\
    <pre><code>sbatch ~/cworkspace/src/mona-vtk/example/MandelbulbColza/testScripts/strongscale/cori_strongscale_mona_4.scripts\n\
    </code></pre>\n<p>or</p>\n<pre><code>sbatch ~/cworkspace/src/mona-vtk/example/GrayScottColza/testScripts/strongscale/cori_gsstrongscale_mona_128_512.scripts\n\
    </code></pre>\n<p>We can check the corresponding server and log file to get the\
    \ particular data put and analysing time.</p>\n<p>For example, the <code>mbclient_mona_4_512.log</code>\
    \ records the client information when there are 4 staging processes and 512 client\
    \ pracesses.</p>\n<p>For the <code>MandelbulbColza</code> example, we can set\
    \ the size of the data block by updating the <code>BLOCKLENW</code>, <code>BLOCKLENH</code>\
    \ and <code>BLOCKLEND</code> in the associated script.</p>\n<p>For the <code>GrayScottColza</code>\
    \ example, we can set the size of the data block by updating the <code>L</code>\
    \ value at the client configuration file. For example, at the <code>client_settings_monaback_408.json</code>,\
    \ we set the <code>L</code> as 408, which means there are <code>408*408*408</code>\
    \ cells for each data block.</p>\n<h2><a id=\"user-content-other-potential-issues\"\
    \ class=\"anchor\" aria-hidden=\"true\" href=\"#other-potential-issues\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other potential\
    \ issues</h2>\n<p>We could also try to install osmesa by spack manaully:</p>\n\
    <pre><code>spack install mesa+osmesa~llvm swr=none\n</code></pre>\n<p><a href=\"\
    https://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5\" rel=\"\
    nofollow\">https://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5</a></p>\n\
    <pre><code>/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so:\
    \ undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023'\n</code></pre>\n\
    <p>try this:</p>\n<p>SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")</p>\n\
    <p>refer to</p>\n<p><a href=\"https://github.com/halide/Halide/issues/1112\">https://github.com/halide/Halide/issues/1112</a></p>\n\
    <p>if the MPICH_GNI_NDREG_ENTRIES is not set properly\n<a href=\"https://github.com/mercury-hpc/mercury/issues/426\"\
    >https://github.com/mercury-hpc/mercury/issues/426</a></p>\n<p>some osmesa warning\
    \ from paraview if it is built in the Debug mode for building paraview (it is\
    \ ok when we use the Release mode to build the paraview)</p>\n<p>(  44.958s) [pvbatch.3\
    \       ]vtkOpenGLFramebufferObj:356    ERR| vtkOpenGLFramebufferObject (0x10005dc58e0):\
    \ failed at glGenFramebuffers 1 OpenGL errors detected\n1:   0 : (1280) Invalid\
    \ enum</p>\n<p>vtkOpenGLState.cxx:505   WARN| Error glBindFramebuffer1 OpenGL\
    \ errors detected\n2:   0 : (1280) Invalid enum</p>\n<p>Try to build the paraview\
    \ with the Release mode, otherwise, there are mosa related warnings</p>\n<p>For\
    \ the python on cori, refer to this (<a href=\"https://docs.nersc.gov/development/languages/python/nersc-python/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/development/languages/python/nersc-python/</a>)\n\
    If you only use the module option, but the python is not the default one, there\
    \ are some issues</p>\n<p>One issue is \"unnamed python module encoding\", or\
    \ other issues that have different gcc version which may cause the byte code issue\n\
    It is prefered to use the conda activate then the python virtual env if you not\
    \ use the default python3 system on cori</p>\n"
  stargazers_count: 0
  subscribers_count: 3
  topics: []
  updated_at: 1623227410.0
xsdk-project/installxSDK:
  data_format: 2
  description: Bash shell script for installing xSDK and other IDEAS packages
  filenames:
  - platformFiles/summit/spack.yaml
  - platformFiles/lassen/spack.yaml
  full_name: xsdk-project/installxSDK
  latest_release: v0.1.1
  readme: '<h1><a id="user-content-useful-supplementary-materials-for-installing-the-xsdk"
    class="anchor" aria-hidden="true" href="#useful-supplementary-materials-for-installing-the-xsdk"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Useful supplementary
    materials for installing the xSDK</h1>

    <p>See <a href="https://xsdk.info/download/" rel="nofollow">https://xsdk.info/download/</a>
    for full directions on obtaining the xSDK.</p>

    <p>The primary content of this repository includes packages.yaml and

    compilers.yaml files, as well as other files useful for configuring builds of

    the xSDK through Spack for various platforms.</p>

    <p>The files are arranged generally as follows:</p>

    <p>installxSDK/platformFiles/&lt;platform description&gt;/&lt;files for platfom&gt;</p>

    <p>This repository is to be tagged for each major and minor release of the xSDK.</p>

    '
  stargazers_count: 5
  subscribers_count: 8
  topics: []
  updated_at: 1669065329.0
