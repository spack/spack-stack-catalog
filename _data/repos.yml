AMReX-Microelectronics/artemis:
  data_format: 2
  description: ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver)
    couples the Maxwell's equations implementation in WarpX with classical equations
    that describe quantum material behavior (such as, LLG equation for micromagnetics
    and London equation for superconducting materials) for quantifying the performance
    of next-generation microelectronics.
  filenames:
  - Docs/spack.yaml
  - Tools/machines/lxplus-cern/spack.yaml
  full_name: AMReX-Microelectronics/artemis
  latest_release: null
  readme: '<h1><a id="user-content-artemis" class="anchor" aria-hidden="true" tabindex="-1"
    href="#artemis"><span aria-hidden="true" class="octicon octicon-link"></span></a>ARTEMIS</h1>

    '
  stargazers_count: 9
  subscribers_count: 5
  topics: []
  updated_at: 1690491777.0
CHIP-SPV/chipStar-Spack:
  data_format: 2
  description: Support for building chipStar and related libraries via Spack
  filenames:
  - Environments/ROCm/spack.yaml
  - Environments/LevelZero/spack.yaml
  full_name: CHIP-SPV/chipStar-Spack
  latest_release: null
  readme: '

    <h1><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h1>

    <p><a href="https://github.com/CHIP-SPV/chipStar">chipStar</a> (formerly CHIP-SPV)

    is software that allows software written to use the

    <a href="https://https://github.com/ROCm-Developer-Tools/HIP" rel="nofollow">Heterogeneous-compute
    Interface for Portability

    (HIP)</a>

    interface and kernel language to target GPUs via the

    <a href="https://registry.khronos.org/spir" rel="nofollow">SPIR-V</a> intermediate
    language.

    chipStar can use either the Intel Level Zero runtime or an OpenCL

    runtime as a backend.</p>

    <p>This repository contains support for building chipStar and its

    dependencies via the <a href="https://github.com/spack/spack">Spack</a> package

    manager.</p>

    <p>Note: most development to date has been done with the Level Zero

    environment, and it is expected that substantial work is needed for

    the environment targeting the OpenCL backend to work.</p>

    <h1><a id="user-content-prerequisites" class="anchor" aria-hidden="true" tabindex="-1"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h1>

    <ul>

    <li>An x86_64 system running a common Linux distribution.  OpenSLES 15 is

    the best tested to date.</li>

    <li>A working Spack installation.</li>

    <li>A recent Clang installation that is registered with Spack as a compiler.

    Versions 15 and 16 are best tested, but 14 might work.  We suggest

    installing the compiler via Spack (i.e., by installing something like

    <code>llvm@16.0.2</code> and then using <code>spack compiler add</code> with the
    llvm

    package''s install location), because the <code>chipstar</code> package defined

    in this repository depends on the <code>llvm</code> package anyway.</li>

    <li>A recent (at least version 2023.1) Intel OneAPI compiler installation

    that is registered with Spack as a compiler.  The recommended way

    of doing this is by installing the Spack <code>intel-oneapi-compilers</code>

    package, then registering the location of its compilers with Spack.

    E.g.,</li>

    </ul>

    <div class="highlight highlight-source-shell"><pre>$ spack install intel-oneapi-compilers@2023

    $ spack compiler add <span class="pl-s"><span class="pl-pds">$(</span>spack location
    -i intel-oneapi-compilers@2023<span class="pl-pds">)</span></span>/compiler/latest/linux</pre></div>

    <h1><a id="user-content-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h1>

    <ol start="0">

    <li>Clone this repository to the target system.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ git clone https://github.com/CHIP-SPV/CHIP-SPV-Spack</pre></div>

    <ol start="2">

    <li>Activate the environment you want to build.  E.g., for the

    environment that just builds chipStar with Level Zero backend:</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ <span class="pl-c1">cd</span>
    CHIP-SPV-Spack/Environments/LevelZero

    $ spack env activate <span class="pl-c1">.</span></pre></div>

    <ol start="3">

    <li>Concretize the active environment.  (In Spack terminology,

    "to concretize" means to let Spack examine the package specifications

    it has been asked to build, plus the available package repositories,

    resolve dependencies and check constraints, and decide exactly which

    packages it will build, in which order, and with which configuration.)</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack concretize -f -U</pre></div>

    <p>We suggest examining the output from running the <code>spack concretize</code>

    command to make sure that Spack''s concretizer has truly decided to

    use the configuration options and especially the compilers that you

    want it to use.  Note that the environment and related configuration

    are purposefully not overly constrained to use the given compiler

    for every dependency package, so even though there are some packages

    that must be built with <code>%clang</code>, there are others that may be

    built (or re-used from already-installed packages) using <code>%gcc</code> such

    as the system''s GCC installation.</p>

    <p>If Spack''s concretizer  didn''t do what you want, you can re-concretize

    the environment and be more explicit about what you want using command-line

    configuration options (recommended) or by editing the environment''s

    <code>spack.yaml</code> file or other configuration options that your Spack installation

    is using.  (Use <code>spack config blame</code> to see which configuration files
    Spack is

    using.)  For instance, if you have both <code>clang@16.0.2</code> and <code>clang@15.0.7</code>

    installed and registered as Spack compilers, and you want to build

    using <code>clang@15.0.7</code>, you may have to use a concretize command like
    the

    following:</p>

    <div class="highlight highlight-source-shell"><pre>$ spack -c <span class="pl-s"><span
    class="pl-pds">"</span>packages:chipstar:require:''%clang@15.0.7''<span class="pl-pds">"</span></span>
    concretize -f -U</pre></div>

    <p>As before, verify from the output of the <code>spack concretize</code> command
    that it

    is using the compiler version you want, <code>clang@15.0.7</code> in this example.</p>

    <ol start="4">

    <li>Build the environment.</li>

    </ol>

    <div class="highlight highlight-source-shell"><pre>$ spack install</pre></div>

    <p>Spack supports some options for controlling the build and installation,

    such as <code>-j</code> to limit the number of processes used for parallel builds,

    useful for being a good citizen on shared systems by not allowing Spack

    to use all available cores (its default).  See the Spack documentation for

    more information.</p>

    <p>Assuming all goes well with the build and install, a <code>spack find</code>

    should show the packages that you just built.</p>

    <ol start="5">

    <li>Use the installed software.  There are several ways you might

    update your environment to use the software, including:</li>

    </ol>

    <ul>

    <li><code>spack load chipstar</code></li>

    <li>Activating the environment that you used to build the software</li>

    <li>If your Spack configuration is such that it can generate module files

    and module files have been generated for the software you built

    via this environment, <code>module load chipstar</code>

    </li>

    </ul>

    <p>Note that you may need to modify your environment to be able to run

    programs produced using chipStar and the H4I libraries built

    using this Spack repository.  For instance, on some systems,

    one must load the <code>intel_compute_runtime</code> module before being

    able to run programs that use the Intel Level Zero runtime.</p>

    <h1><a id="user-content-todo" class="anchor" aria-hidden="true" tabindex="-1"
    href="#todo"><span aria-hidden="true" class="octicon octicon-link"></span></a>TODO</h1>

    <ul>

    <li>Clean up and verify the OpenCL-based environment.</li>

    <li>Ensure the OpenCL-based environment can use any OpenCL implementation.</li>

    <li>Incorporate H4I HIP libraries like H4I-HipBLAS into an environments.</li>

    <li>Support using the software installed by the environment via

    <code>module</code> command.</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 5
  topics: []
  updated_at: 1687550793.0
CUP-ECS/cajitafluids:
  data_format: 2
  description: A simple poisson finite difference fluid solver in Cajita/Kokkos for
    testing MPI communication abstractions and their performance
  filenames:
  - configs/github/spack.yaml
  full_name: CUP-ECS/cajitafluids
  latest_release: null
  readme: '<h1><a id="user-content-poisson-mpi-benchmark" class="anchor" aria-hidden="true"
    tabindex="-1" href="#poisson-mpi-benchmark"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Poisson MPI Benchmark</h1>

    <p>This directory contains code for a relatively simple finite difference

    fluid advection solver for exploring communication issues on modern architectures

    (particularly GPUs). The main goal is to look at different neighbor collective

    and GPU communication approaches.</p>

    <p>Computationally, the benchmark advects a material feature (that doesn''t otherwise
    effect

    fluid flow, e.g. by changing pressite) using the incompressible Euler fluid flow
    equations.

    Consider, for example, something like a dye being carried through a tank of water
    or a

    fragrance wafting across a room.</p>

    <p>The main elements of the benchmark are:</p>

    <ul>

    <li>Solution of the pressure gradient at each timestep to maintain

    incompressibility. The benchmark has two initial implementations:

    (1) Calling a matrix-free solver in HYPRE to solve the problem or (2)

    running a local matrix-free preconditioned CG solver, in which different

    MPI approaches for the halo exchange are explored.</li>

    <li>Interpolation (either cubic splines or linear) for semi-Lagrangian

    advection of the material being advected across timesteps.</li>

    <li>3rd-order Runge Kutta for time integration</li>

    </ul>

    <p>Sources:</p>

    <ul>

    <li>Fluid Simulation for Comptuer Graphics by Bridson</li>

    <li>Incremental Fluids in Kokkos (<a href="mailto:git@github.com">git@github.com</a>:pkestene/incremental-fluids-kokkos.git)</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1654983605.0
E4S-Project/e4s:
  data_format: 2
  description: E4S for Spack
  filenames:
  - environments/21.08/spack.yaml
  - environments/23.05/cuda-x86_64/spack.yaml
  - environments/23.08/cuda-x86_64/spack.yaml
  - environments/22.08/cuda-ppc64le.spack.yaml
  - environments/23.02/cuda-ppc64le/spack.yaml
  - environments/22.05/cuda-x86_64.spack.yaml
  - environments/23.02/cuda-x86_64/spack.yaml
  - environments/21.05/spack.yaml
  - environments/23.08/oneapi-x86_64/spack.yaml
  - environments/22.05/rocm.spack.yaml
  - environments/22.08/cuda-x86_64.spack.yaml
  - environments/23.05/rocm-x86_64/spack.yaml
  - environments/23.08/cuda-aarch64/spack.yaml
  full_name: E4S-Project/e4s
  latest_release: v23.08
  readme: "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\
    ><img src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\"\
    \ width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"></a></p> \n<p><a target=\"\
    _blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\
    \ alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    ><img src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    ><img src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\
    \ alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\"\
    \ style=\"max-width: 100%;\"></a>\n<a target=\"_blank\" rel=\"noopener noreferrer\
    \ nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    ><img src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\
    \ alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h1><a id=\"user-content-e4s\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#e4s\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>E4S</h1>\n<p>The <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">Extreme-scale Scientific Software Stack (E4S)</a> is a community\
    \ effort to provide open source\nsoftware packages for developing, deploying and\
    \ running scientific applications on high-performance\ncomputing (HPC) platforms.\
    \ E4S provides from-source builds and containers of a\n<a href=\"https://e4s-project.github.io/Resources/ProductInfo.html\"\
    \ rel=\"nofollow\">broad collection of HPC software packages</a>.</p>\n<p>E4S\
    \ is available to download in the following formats:</p>\n<ul>\n<li>\n<p>Containers:\
    \ Docker, Singularity, CharlieCloud, OVA</p>\n</li>\n<li>\n<p>Spack manifest (<code>spack.yaml</code>)\
    \ to install from source. These can be found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >environments</a> directory.</p>\n</li>\n<li>\n<p><a href=\"http://aws.amazon.com/\"\
    \ rel=\"nofollow\">AWS EC2 image</a> with image name <code>ami-0db9d49091db1c25f</code>\
    \ in <strong>US-West-2 (Oregon)</strong></p>\n</li>\n<li>\n<p><a href=\"https://oaciss.uoregon.edu/e4s/inventory.html\"\
    \ rel=\"nofollow\">E4S Build Cache</a></p>\n</li>\n</ul>\n<p>Please see <a href=\"\
    https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\">E4S Product Dictionary</a>\
    \ for complete list of E4S products.</p>\n<h2><a id=\"user-content-useful-links\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#useful-links\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Useful Links</h2>\n\
    <ul>\n<li>User Documentation: <a href=\"https://e4s.readthedocs.io\" rel=\"nofollow\"\
    >https://e4s.readthedocs.io</a>\n</li>\n<li>Main Page: <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a>\n</li>\n<li>E4S GitHub:\
    \ <a href=\"https://github.com/E4S-Project/\">https://github.com/E4S-Project/</a>\n\
    </li>\n<li>E4S Slack Channel: <a href=\"https://e4s-project.slack.com\" rel=\"\
    nofollow\">https://e4s-project.slack.com</a>\n</li>\n<li>Slack Channel Invitation:\
    \ <a href=\"https://communityinviter.com/apps/e4s-project/e4s\" rel=\"nofollow\"\
    >https://communityinviter.com/apps/e4s-project/e4s</a>\n</li>\n<li>E4S Dashboard:\
    \ <a href=\"https://dashboard.e4s.io/\" rel=\"nofollow\">https://dashboard.e4s.io/</a>\n\
    </li>\n</ul>\n<h2><a id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#related-projects\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Related Projects</h2>\n<ul>\n<li>\n<p><a href=\"\
    https://github.com/E4S-Project/E4S-Project.github.io\">E4S-Project/E4S-Project.github.io</a>\
    \ - E4S Documentation repo that is hosted on <a href=\"https://e4s-project.github.io/\"\
    \ rel=\"nofollow\">https://e4s-project.github.io/</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://github.com/E4S-Project/testsuite\">E4S-Project/testsuite</a>\
    \ - E4S Testsuite with collection of validation tests that can be run post-install.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-cl\">E4S-Project/e4s-cl</a>\
    \ - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.</p>\n\
    </li>\n<li>\n<p><a href=\"https://github.com/E4S-Project/e4s-ci-badges\">E4S-Project/e4s-ci-badges</a>\
    \ - Display CI badges for E4S products that are available from <a href=\"https://shields.io/\"\
    \ rel=\"nofollow\">shields.io</a></p>\n</li>\n</ul>\n<h2><a id=\"user-content-license\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>E4S is released as MIT license for more details see <a href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\
    >LICENSE</a> file</p>\n<h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Contact</h2>\n<ul>\n<li>Mike Heroux (<a href=\"mailto:maherou@sandia.gov\"\
    >maherou@sandia.gov</a>)</li>\n<li>Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\"\
    >sameer@cs.uoregon.edu</a>)</li>\n</ul>\n"
  stargazers_count: 18
  subscribers_count: 10
  topics: []
  updated_at: 1690987779.0
FZJ-INM1-BDA/siibra-python:
  data_format: 2
  description: Software interfaces for interacting with brain atlases - Python client
  filenames:
  - .ebrains/spack/siibra-spack.yaml
  full_name: FZJ-INM1-BDA/siibra-python
  latest_release: null
  stargazers_count: 37
  subscribers_count: 7
  topics:
  - brain
  - atlas
  - neuroscience
  - bigbrain
  - bigbrainproject
  - humanbrainproject
  updated_at: 1685929340.0
GoogleCloudPlatform/scientific-computing-examples:
  data_format: 2
  description: Open Source examples using Google Cloud to solve various Scientific
    and Technical Computing problems.
  filenames:
  - fluxfw-gcp/tf/examples/containers/spack.yaml
  full_name: GoogleCloudPlatform/scientific-computing-examples
  latest_release: null
  readme: '<h1><a id="user-content-scientific-computing-with-google-cloud" class="anchor"
    aria-hidden="true" tabindex="-1" href="#scientific-computing-with-google-cloud"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Scientific Computing
    with Google Cloud</h1>

    <p>A repository of examples.</p>

    <p>These examples are currently organized by the various schedulers used to

    orchestrate the scientific workloads on the Google Cloud Platform (GCP).</p>

    <hr>

    <h2><a id="user-content-flux" class="anchor" aria-hidden="true" tabindex="-1"
    href="#flux"><span aria-hidden="true" class="octicon octicon-link"></span></a>Flux</h2>

    <ul>

    <li><a href="/fluxfw-gcp/README.md">Flux Framework on Google Cloud</a></li>

    </ul>

    <h2><a id="user-content-kubernetes" class="anchor" aria-hidden="true" tabindex="-1"
    href="#kubernetes"><span aria-hidden="true" class="octicon octicon-link"></span></a>Kubernetes</h2>

    <ul>

    <li><a href="higgs/README.md">Rediscovering the Higgs boson using the Google Cloud
    Platform</a></li>

    <li><a href="slurm-cookbook/docker/README.md">Running Docker on Slurm (Cookbook)</a></li>

    </ul>

    <h2><a id="user-content-slurm" class="anchor" aria-hidden="true" tabindex="-1"
    href="#slurm"><span aria-hidden="true" class="octicon octicon-link"></span></a>Slurm</h2>

    <ul>

    <li><a href="slurm-cookbook/docker/README.md">HPC Toolkit Support for Slurm and
    Docker on Google Cloud</a></li>

    </ul>

    <h2><a id="user-content-notebooks" class="anchor" aria-hidden="true" tabindex="-1"
    href="#notebooks"><span aria-hidden="true" class="octicon octicon-link"></span></a>Notebooks</h2>

    <p>Various notebooks to demonstrate running Google Cloud from a notebook.</p>

    <ul>

    <li><a href="notebooks/batch_hello_world.ipynb">Hello World for Google Batch</a></li>

    </ul>

    '
  stargazers_count: 5
  subscribers_count: 7
  topics: []
  updated_at: 1680042420.0
JuliaParallel/MPI.jl:
  data_format: 2
  description: MPI wrappers for Julia
  filenames:
  - .ci/mvapich/spack.yaml
  full_name: JuliaParallel/MPI.jl
  latest_release: v0.20.14
  readme: '<h1><a id="user-content-mpi-interface-for-the-julia-language" class="anchor"
    aria-hidden="true" tabindex="-1" href="#mpi-interface-for-the-julia-language"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>MPI interface for the
    Julia language</h1>

    <p><a href="https://juliaparallel.github.io/MPI.jl/latest/" rel="nofollow"><img
    src="https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667"
    alt="Docs latest" data-canonical-src="https://img.shields.io/badge/docs-latest-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667"
    alt="Docs stable" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml"><img
    src="https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml/badge.svg"
    alt="Unit Tests" style="max-width: 100%;"></a>

    <a href="https://buildkite.com/julialang/mpi-dot-jl" rel="nofollow"><img src="https://camo.githubusercontent.com/87debbd756a8b45df7ac1f25dc034436051f7ccfe155df49f1ec1f6209e51caf/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65643831336263346437396635353761646264623832316231633863386465393839393936383665363937646634613337332e7376673f6272616e63683d6d6173746572"
    alt="GPU tests" data-canonical-src="https://badge.buildkite.com/ed813bc4d79f557adbdb821b1c8c8de98999686e697df4a373.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://codecov.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/00ad86424fd334dccd9dde2876e4f3e82b84ad4219e5c1661d6a06b63f46f516/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f4d50492e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572"
    alt="codecov.io" data-canonical-src="https://codecov.io/github/JuliaParallel/MPI.jl/coverage.svg?branch=master"
    style="max-width: 100%;"></a>

    <a href="https://coveralls.io/github/JuliaParallel/MPI.jl?branch=master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/4d989c928ad758732dcf79e5d1a0b592a1765763c2237af784955ed806e37ef1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f4d50492e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562"
    alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/JuliaParallel/MPI.jl/badge.svg?branch=master&amp;service=github"
    style="max-width: 100%;"></a></p>

    <p>This provides <a href="http://julialang.org/" rel="nofollow">Julia</a> interface
    to the Message Passing Interface (<a href="http://www.mpi-forum.org/" rel="nofollow">MPI</a>),
    roughly inspired by <a href="https://github.com/mpi4py/mpi4py/">mpi4py</a>.</p>

    <p>Please see the <a href="https://juliaparallel.github.io/MPI.jl/stable/" rel="nofollow">documentation</a>
    for instructions on <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/"
    rel="nofollow">configuration</a> and <a href="https://juliaparallel.github.io/MPI.jl/stable/usage/"
    rel="nofollow">usage</a>.</p>

    <p><strong>Breaking changes with v0.20:</strong> The way how MPI.jl is configured
    to use

    different MPI implementations has changed from v0.19 to v0.20 in a

    <em>non-backward-compatible</em> manner.

    Specifically, most <code>JULIA_MPI_XXX</code> variables do not have an effect
    anymore.

    Please refer to the

    <a href="https://juliaparallel.org/MPI.jl/stable/configuration/#Migration-from-MPI.jl-v0.19-or-earlier"
    rel="nofollow">docs</a>

    for information on how to migrate your existing configuration.</p>

    <h1><a id="user-content-help-and-discussion" class="anchor" aria-hidden="true"
    tabindex="-1" href="#help-and-discussion"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Help and discussion</h1>

    <p>For help and discussion, we suggest asking on the following venues:</p>

    <ul>

    <li><a href="https://discourse.julialang.org/c/domain/parallel/34" rel="nofollow">"Julia
    at Scale" topic on the Julia Discourse</a></li>

    <li>#distributed channel on the <a href="https://julialang.slack.com/" rel="nofollow">Julia
    Slack</a> (visit <a href="https://julialang.org/slack/" rel="nofollow">https://julialang.org/slack/</a>
    to join).</li>

    </ul>

    <h1><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h1>

    <p>Contributions are encouraged. In particular, MPI provides several hundred functions,
    only a small number of which are currently exposed. If there are additional functions
    you would like to use, please open an <a href="https://github.com/JuliaParallel/MPI.jl/issues">issue</a>
    or <a href="https://github.com/JuliaParallel/MPI.jl/pulls">pull request</a>.</p>

    <p>Additional examples and documentation improvements are also very welcome.</p>

    <h1><a id="user-content-citation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#citation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citation</h1>

    <p>If you use MPI.jl in your work, please cite the following paper:</p>

    <blockquote>

    <p>Simon Byrne, Lucas C. Wilcox, and Valentin Churavy (2021) "MPI.jl: Julia bindings
    for the Message Passing Interface". <em>JuliaCon Proceedings</em>, 1(1), 68, doi:
    <a href="https://doi.org/10.21105/jcon.00068" rel="nofollow">10.21105/jcon.00068</a></p>

    </blockquote>

    '
  stargazers_count: 329
  subscribers_count: 20
  topics:
  - mpi
  - julia
  - hpc
  - julia-language
  - mpich
  - openmpi
  - microsoft-mpi
  updated_at: 1692086647.0
LLNL/DiHydrogen:
  data_format: 2
  description: null
  filenames:
  - .gitlab/spack/environments/quartz/spack.yaml
  - .gitlab/spack/environments/corona/spack.yaml
  - .gitlab/spack/environments/pascal/spack.yaml
  full_name: LLNL/DiHydrogen
  latest_release: v0.2.1
  readme: '<h1><a id="user-content-dihydrogen" class="anchor" aria-hidden="true" tabindex="-1"
    href="#dihydrogen"><span aria-hidden="true" class="octicon octicon-link"></span></a>DiHydrogen</h1>

    <p>DiHydrogen is the second version of the

    <a href="https://github.com/llnl/elemental">Hydrogen</a> fork of the well-known

    distributed linear algebra library,

    <a href="https://github.com/elemental/elemental">Elemental</a>.  DiHydrogen aims

    to be a basic distributed multilinear algebra interface with a

    particular emphasis on the needs of the distributed machine learning

    effort, <a href="https://github.com/llnl/lbann">LBANN</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>DiHydrogen is distributed under the terms of the Apache License (Version 2.0).</p>

    <p>All new contributions must be made under the Apache-2.0 licenses.</p>

    <p>See <a href="https://github.com/LLNL/DiHydrogen/blob/develop/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/DiHydrogen/blob/develop/NOTICE">NOTICE</a> for
    details.</p>

    <p>SPDX-License-Identifier: Apache-2.0</p>

    <p>LLNL-CODE-800100</p>

    '
  stargazers_count: 4
  subscribers_count: 11
  topics:
  - cpp
  - math-physics
  updated_at: 1680394625.0
LLNL/UnifyFS:
  data_format: 2
  description: 'UnifyFS: A file system for burst buffers'
  filenames:
  - .spack-env/unifyfs-slurm-gcc4_9_3/spack.yaml
  - .spack-env/unifyfs-lsf-gcc4_9_3/spack.yaml
  full_name: LLNL/UnifyFS
  latest_release: v1.1
  readme: "<h1><a id=\"user-content-unifyfs-a-distributed-burst-buffer-file-system\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#unifyfs-a-distributed-burst-buffer-file-system\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UnifyFS:\
    \ A Distributed Burst Buffer File System</h1>\n<p>Node-local burst buffers are\
    \ becoming an indispensable hardware resource on\nlarge-scale supercomputers to\
    \ buffer the bursty I/O from scientific\napplications. However, there is a lack\
    \ of software support for burst buffers to\nbe efficiently shared by applications\
    \ within a batch-submitted job and recycled\nacross different batch jobs. In addition,\
    \ burst buffers need to cope with a\nvariety of challenging I/O patterns from\
    \ data-intensive scientific\napplications.</p>\n<p>UnifyFS is a user-level burst\
    \ buffer file system under active development.\nUnifyFS supports scalable and\
    \ efficient aggregation of I/O bandwidth from burst\nbuffers while having the\
    \ same life cycle as a batch-submitted job. While UnifyFS\nis designed for N-N\
    \ write/read, UnifyFS compliments its functionality with the\nsupport for N-1\
    \ write/read. It efficiently accelerates scientific I/O based on\nscalable metadata\
    \ indexing, co-located I/O delegation, and server-side read\nclustering and pipelining.</p>\n\
    <h2><a id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#documentation\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Documentation</h2>\n<p>UnifyFS documentation\
    \ is at <a href=\"https://unifyfs.readthedocs.io\" rel=\"nofollow\">https://unifyfs.readthedocs.io</a>.</p>\n\
    <p>For instructions on how to build and install UnifyFS,\nsee <a href=\"http://unifyfs.readthedocs.io/en/dev/build.html\"\
    \ rel=\"nofollow\">Build UnifyFS</a>.</p>\n<h2><a id=\"user-content-build-status\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#build-status\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build Status</h2>\n\
    <p>Status of UnifyFS development branch (dev):</p>\n<p><a target=\"_blank\" rel=\"\
    noopener noreferrer\" href=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    ><img src=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\
    \ alt=\"Build Status\" style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://unifyfs.readthedocs.io\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e83e6f0dfc2d353a5c6d482643646205f8fcc8e0b3327cb32dc9b27292e16823/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756e69667966732f62616467652f3f76657273696f6e3d646576\"\
    \ alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/unifyfs/badge/?version=dev\"\
    \ style=\"max-width: 100%;\"></a></p>\n<h2><a id=\"user-content-unifyfs-citation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#unifyfs-citation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>UnifyFS\
    \ Citation</h2>\n<p>We recommend that you use this citation for UnifyFS:</p>\n\
    <ul>\n<li>Michael Brim, Adam Moody, Seung-Hwan Lim, Ross Miller, Swen Boehm, Cameron\
    \ Stanavige, Kathryn Mohror, Sarp Oral, \u201CUnifyFS: A User-level Shared File\
    \ System for Unified Access to Distributed Local Storage,\u201D 37th IEEE International\
    \ Parallel &amp; Distributed Processing Symposium (IPDPS 2023), St. Petersburg,\
    \ FL, May 2023.</li>\n</ul>\n<h2><a id=\"user-content-contribute-and-develop\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contribute-and-develop\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contribute\
    \ and Develop</h2>\n<p>If you would like to help, please see our <a href=\"https://unifyfs.readthedocs.io/en/dev/contribute-ways.html\"\
    \ rel=\"nofollow\">contributing guidelines</a>.</p>\n"
  stargazers_count: 89
  subscribers_count: 20
  topics:
  - system-software
  - burst-buffers
  - file-system
  updated_at: 1693372449.0
LLNL/axom:
  data_format: 2
  description: CS infrastructure components for HPC applications
  filenames:
  - scripts/spack/configs/blueos_3_ppc64le_ib_p9/spack.yaml
  - scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/configs/linux_ubuntu_20/spack.yaml
  - scripts/spack/configs/toss_3_x86_64_ib/spack.yaml
  - scripts/spack/configs/toss_4_x86_64_ib/spack.yaml
  - scripts/spack/devtools_configs/toss_3_x86_64_ib/spack.yaml
  full_name: LLNL/axom
  latest_release: v0.8.1
  readme: '<h1><a id="" class="anchor" aria-hidden="true" tabindex="-1" href="#"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a target="_blank"
    rel="noopener noreferrer" href="/share/axom/logo/axom_logo.png?raw=true"><img
    src="/share/axom/logo/axom_logo.png?raw=true" width="250" valign="middle" alt="Axom"
    style="max-width: 100%;"></a></h1>

    <p><a href="https://dev.azure.com/axom/axom/_build/latest?definitionId=1&amp;branchName=develop"
    rel="nofollow"><img src="https://camo.githubusercontent.com/1e537c454d83150c4b7bfb804bc21f0072b06abd9dfb3b512cda35bbd87cfa74/68747470733a2f2f6465762e617a7572652e636f6d2f61786f6d2f61786f6d2f5f617069732f6275696c642f7374617475732f4c4c4e4c2e61786f6d3f6272616e63684e616d653d646576656c6f70"
    alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/axom/axom/_apis/build/status/LLNL.axom?branchName=develop"
    style="max-width: 100%;"></a>

    <a href="https://axom.readthedocs.io/en/develop/?badge=develop" rel="nofollow"><img
    src="https://camo.githubusercontent.com/0d1ad2943bef54d4b2dd8e5e6161872f93eb95a7b28498913b3b7c71c977b686/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f61786f6d2f62616467652f3f76657273696f6e3d646576656c6f70"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/axom/badge/?version=develop"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/blob/develop/LICENSE"><img src="https://camo.githubusercontent.com/8ccf186e7288af6d88a1f6a930c0fcc4e7a8a9936b34e07629d815d1eab4d977/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d425344253230332d2d436c617573652d626c75652e737667"
    alt="License" data-canonical-src="https://img.shields.io/badge/License-BSD%203--Clause-blue.svg"
    style="max-width: 100%;"></a>

    <a href="https://github.com/LLNL/axom/releases/latest"><img src="https://camo.githubusercontent.com/7e96e2e62e0ae13e391856d4c9a26779fb83684be5dd6274d812ce8c4c75e800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4c4c4e4c2f61786f6d2e737667"
    alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/LLNL/axom.svg"
    style="max-width: 100%;"></a></p>

    <p>Axom provides robust, flexible software infrastructure for the development
    of multi-physics applications and computational tools.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>Latest docs on Develop branch: <a href="https://axom.readthedocs.io" rel="nofollow">https://axom.readthedocs.io</a></p>

    <p>To access docs for other versions: <a href="https://readthedocs.org/projects/axom/"
    rel="nofollow">https://readthedocs.org/projects/axom/</a></p>

    <h2><a id="user-content-getting-involved" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-involved"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Involved</h2>

    <p>Axom is an open-source project and we welcome contributions from the community.</p>

    <h2><a id="user-content-mailing-list" class="anchor" aria-hidden="true" tabindex="-1"
    href="#mailing-list"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mailing
    List</h2>

    <p>The project maintains two email lists:</p>

    <ul>

    <li>''<a href="mailto:axom-users@llnl.gov">axom-users@llnl.gov</a>'' is how Axom
    users can contact developers for questions, report issues, etc.</li>

    <li>''<a href="mailto:axom-dev@llnl.gov">axom-dev@llnl.gov</a>'' is for communication
    among team members.</li>

    </ul>

    <h2><a id="user-content-contributions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributions</h2>

    <p>We welcome all kinds of contributions: new features, bug fixes, documentation
    edits.</p>

    <p>To contribute, make a <a href="https://github.com/llnl/axom/compare">pull request</a>,
    with <code>develop</code>

    as the destination branch. We use CI testing and your branch must pass these tests
    before

    being merged.</p>

    <p>For more information, see the <a href="https://github.com/llnl/axom/blob/develop/CONTRIBUTING.md">contributing
    guide</a>.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Thanks to all of Axom''s

    <a href="https://github.com/llnl/axom/graphs/contributors">contributors</a>.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Copyright (c) 2017-2023, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory.</p>

    <p>Copyrights and patents in the Axom project are retained by contributors.

    No copyright assignment is required to contribute to Axom.</p>

    <p>See <a href="./LICENSE">LICENSE</a> for details.</p>

    <p>Unlimited Open Source - BSD 3-clause Distribution

    <code>LLNL-CODE-741217</code> <code>OCEC-17-187</code></p>

    <h2><a id="user-content-spdx-usage" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spdx-usage"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPDX
    usage</h2>

    <p>Individual files contain SPDX tags instead of the full license text.

    This enables machine processing of license information based on the SPDX

    License Identifiers that are available here: <a href="https://spdx.org/licenses/"
    rel="nofollow">https://spdx.org/licenses/</a></p>

    <p>Files that are licensed as BSD 3-Clause contain the following

    text in the license header:</p>

    <pre><code>SPDX-License-Identifier: (BSD-3-Clause)

    </code></pre>

    <h2><a id="user-content-external-packages" class="anchor" aria-hidden="true" tabindex="-1"
    href="#external-packages"><span aria-hidden="true" class="octicon octicon-link"></span></a>External
    Packages</h2>

    <p>Axom bundles some of its external dependencies in its repository.  These

    packages are covered by various permissive licenses.  A summary listing

    follows.  See the license included with each package for full details.</p>

    <p>PackageName: BLT<br>

    PackageHomePage: <a href="https://github.com/LLNL/blt">https://github.com/LLNL/blt</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: CLI11<br>

    PackageHomePage: <a href="https://github.com/CLIUtils/CLI11">https://github.com/CLIUtils/CLI11</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: fmt<br>

    PackageHomePage: <a href="https://github.com/fmtlib/fmt">https://github.com/fmtlib/fmt</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: radiuss-spack-configs<br>

    PackageHomePage: <a href="https://github.com/LLNL/radiuss-spack-configs">https://github.com/LLNL/radiuss-spack-configs</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sol<br>

    PackageHomePage: <a href="https://github.com/ThePhD/sol2">https://github.com/ThePhD/sol2</a><br>

    PackageLicenseDeclared: MIT License</p>

    <p>PackageName: sparsehash<br>

    PackageHomePage: <a href="https://github.com/sparsehash/sparsehash">https://github.com/sparsehash/sparsehash</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    <p>PackageName: uberenv<br>

    PackageHomePage: <a href="https://github.com/LLNL/uberenv">https://github.com/LLNL/uberenv</a><br>

    PackageLicenseDeclared: BSD-3-Clause</p>

    '
  stargazers_count: 112
  subscribers_count: 21
  topics:
  - hpc
  - parallel-computing
  - llnl
  - cpp
  - c-plus-plus
  - app-infrastructure
  - radiuss
  - fortran
  updated_at: 1691934195.0
LLNL/radiuss-spack-testing:
  data_format: 2
  description: Gitlab CI automation of Spack testing with RADIUSS projects builds.
  filenames:
  - spack-environments/radiuss/spack.yaml
  - spack-environments/raja-suite/spack.yaml
  full_name: LLNL/radiuss-spack-testing
  latest_release: null
  readme: '<h1><a id="user-content-radiuss-spack-testing" class="anchor" aria-hidden="true"
    tabindex="-1" href="#radiuss-spack-testing"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>RADIUSS Spack Testing</h1>

    <p>The RADIUSS project promotes and supports key High Performance Computing (HPC)
    open-source software developed at the LLNL. These tools and libraries cover a
    wide range of features a team would need to develop a modern simulation code targeting
    HPC plaftorms.</p>

    <p>RADIUSS Spack Testing is a sub-project from the RADIUSS initiative providing
    a

    testing infrastructure to test Spack Packages automatically in GitLab while

    tracking changes in Spack.</p>

    <p>Access the <a href="https://radiuss-spack-testing.readthedocs.io/" rel="nofollow">documentation</a>.</p>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started</h2>

    <p>The primary goal of this repo is to be used in Gitlab. The Gitlab CI configuration
    is such that it will use Spack pipeline feature to generate and run a pipeline
    that builds one of the environments in the <code>spack-environments</code> directory.</p>

    <p>The specific environment to be built is controlled by the CI variable <code>ENV_NAME</code>.</p>

    <h3><a id="user-content-installing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing</h3>

    <p>This project requires no installation.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Please read <a href="https://github.com/LLNL/radiuss-spack-testing/CONTRIBUTING.md">CONTRIBUTING.md</a>
    for details on our code of conduct, and the process for submitting pull requests
    to us.</p>

    <h2><a id="user-content-versioning" class="anchor" aria-hidden="true" tabindex="-1"
    href="#versioning"><span aria-hidden="true" class="octicon octicon-link"></span></a>Versioning</h2>

    <p>version: 1.0.0</p>

    <p>TODO: Not even sure how to handle versioning here.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>Adrien M Bernede</p>

    <p>See also the list of <a href="https://github.com/LLNL/radiuss-spack-testing/contributors">contributors</a>
    who participated in this project.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a>
    file for details</p>

    <p>All new contributions must be made under the MIT License.</p>

    <p>See <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/LICENSE">LICENSE</a>,

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/LLNL/radiuss-spack-testing/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (MIT)</p>

    <p>LLNL-CODE-793462</p>

    <h2><a id="user-content-acknowledgments" class="anchor" aria-hidden="true" tabindex="-1"
    href="#acknowledgments"><span aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgments</h2>

    '
  stargazers_count: 1
  subscribers_count: 7
  topics:
  - radiuss
  updated_at: 1679009672.0
LLNL/sundials:
  data_format: 2
  description: Official development repository for SUNDIALS - a SUite of Nonlinear
    and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug
    fixes and minor changes.
  filenames:
  - docker/sundials-ci/e4s-quarterly/int64-single/spack.yaml
  - docker/sundials-ci/spack-nightly/int64-double/spack.yaml
  - docker/sundials-ci/spack-nightly/int32-double/spack.yaml
  full_name: LLNL/sundials
  latest_release: v6.6.0
  readme: '<h1><a id="user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"
    class="anchor" aria-hidden="true" tabindex="-1" href="#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SUNDIALS: SUite of
    Nonlinear and DIfferential/ALgebraic equation Solvers</h1>

    <h3><a id="user-content-version-660-jul-2023" class="anchor" aria-hidden="true"
    tabindex="-1" href="#version-660-jul-2023"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Version 6.6.0 (Jul 2023)</h3>

    <p><strong>Center for Applied Scientific Computing, Lawrence Livermore National
    Laboratory</strong></p>

    <p>SUNDIALS is a family of software packages providing robust and efficient time

    integrators and nonlinear solvers that can easily be incorporated into existing

    simulation codes. The packages are designed to require minimal information from

    the user, allow users to supply their own data structures underneath the

    packages, and enable interfacing with user-supplied or third-party algebraic

    solvers and preconditioners.</p>

    <p>The SUNDIALS suite consists of the following packages for ordinary differential

    equation (ODE) systems, differential-algebraic equation (DAE) systems, and

    nonlinear algebraic systems:</p>

    <ul>

    <li>

    <p>ARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form

    $$M(t) \, y'' = f_1(t,y) + f_2(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODE - for integrating stiff and nonstiff ODEs of the form

    $$y'' = f(t,y), \quad y(t_0) = y_0$$</p>

    </li>

    <li>

    <p>CVODES - for integrating and sensitivity analysis (forward and adjoint) of

    ODEs of the form

    $$y'' = f(t,y,p), \quad y(t_0) = y_0(p)$$</p>

    </li>

    <li>

    <p>IDA - for integrating DAEs of the form

    $$F(t,y,y'') = 0, \quad y(t_0) = y_0, \quad y''(t_0) = y_0''$$</p>

    </li>

    <li>

    <p>IDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs

    of the form

    $$F(t,y,y'',p) = 0, \quad y(t_0) = y_0(p), \quad y''(t_0) = y_0''(p)$$</p>

    </li>

    <li>

    <p>KINSOL - for solving nonlinear algebraic systems of the form

    $$F(u) = 0 \quad \text{or} \quad G(u) = u$$</p>

    </li>

    </ul>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>For installation directions see the <a href="https://sundials.readthedocs.io/en/latest/Install_link.html"
    rel="nofollow">online install guide</a>,

    the installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.</p>

    <p>Warning to users who receive more than one of the individual packages at

    different times: Mixing old and new versions of SUNDIALS may fail. To avoid

    such failures, obtain all desired package at the same time.</p>

    <h2><a id="user-content-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#support"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>Full user guides for all of the SUNDIALS packages are available <a href="https://sundials.readthedocs.io"
    rel="nofollow">online</a>

    and in the <a href="./doc">doc</a> directory. Additionally, the <a href="./doc">doc</a>
    directory

    contains documentation for the package example programs.</p>

    <p>For information on recent changes to SUNDIALS see the <a href="./CHANGELOG.md">CHANGELOG</a>

    or the introduction chapter of any package user guide.</p>

    <p>A list of Frequently Asked Questions on build and installation procedures as

    well as common usage issues is available on the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/faq"
    rel="nofollow">FAQ</a>.

    For dealing with systems with unphysical solutions or discontinuities see the

    SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/usage-notes" rel="nofollow">usage
    notes</a>.</p>

    <p>If you have a question not covered in the FAQ or usage notes, please submit

    your question to the SUNDIALS <a href="https://computing.llnl.gov/projects/sundials/mailing-list"
    rel="nofollow">mailing list</a>.</p>

    <h2><a id="user-content-contributing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug fixes or minor changes are preferred via a pull request to the

    <a href="https://github.com/LLNL/sundials">SUNDIALS GitHub repository</a>. For
    more

    information on contributing see the <a href="./CONTRIBUTING.md">CONTRIBUTING</a>
    file.</p>

    <h2><a id="user-content-citing" class="anchor" aria-hidden="true" tabindex="-1"
    href="#citing"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>See the <a href="https://sundials.readthedocs.io/en/latest/index.html#citing"
    rel="nofollow">online documentation</a>

    or <a href="./CITATIONS.md">CITATIONS</a> file for information on how to cite
    SUNDIALS in

    any publications reporting work done using SUNDIALS packages.</p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>The SUNDIALS library has been developed over many years by a number of

    contributors. The current SUNDIALS team consists of Cody J. Balos,

    David J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.

    We thank Radu Serban for significant and critical past contributions.</p>

    <p>Other contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,

    Peter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,

    Keith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,

    Yu Pan, Slaven Peles, Cosmin Petra, Steven B. Roberts, H. Hunter Schwartz,

    Jean M. Sexton, Dan Shumaker, Steve G. Smith, Shahbaj Sohal, Allan G. Taylor,

    Hilari C. Tiedeman, Chris White, Ting Yan, and Ulrike M. Yang.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>SUNDIALS is released under the BSD 3-clause license. See the <a href="./LICENSE">LICENSE</a>

    and <a href="./NOTICE">NOTICE</a> files for details. All new contributions must
    be made

    under the BSD 3-clause license.</p>

    <p><strong>Please Note</strong> If you are using SUNDIALS with any third party
    libraries linked

    in (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or <em>hypre</em>), be sure to review
    the

    respective license of the package as that license may have more restrictive

    terms than the SUNDIALS license.</p>

    <pre><code>SPDX-License-Identifier: BSD-3-Clause


    LLNL-CODE-667205  (ARKODE)

    UCRL-CODE-155951  (CVODE)

    UCRL-CODE-155950  (CVODES)

    UCRL-CODE-155952  (IDA)

    UCRL-CODE-237203  (IDAS)

    LLNL-CODE-665877  (KINSOL)

    </code></pre>

    '
  stargazers_count: 386
  subscribers_count: 35
  topics:
  - ode-solver
  - dae-solver
  - nonlinear-equation-solver
  - sensitivity-analysis
  - time-integration
  - scientific-computing
  - parallel-computing
  - hpc
  - math-physics
  - radiuss
  - solver
  - high-performance-computing
  updated_at: 1693212716.0
MeteoSwiss/fdb-fortran:
  data_format: 2
  description: Fortran Interface to ECMWF's FDB
  filenames:
  - docker/spack.yaml
  full_name: MeteoSwiss/fdb-fortran
  latest_release: null
  readme: '<h1><a id="user-content-fdb-fortran-interface" class="anchor" aria-hidden="true"
    tabindex="-1" href="#fdb-fortran-interface"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>FDB Fortran Interface</h1>

    <p>This is an experimental Fortran interface to ECMWF''s FDB (<a href="https://github.com/ecmwf/fdb">https://github.com/ecmwf/fdb</a>).
    It is not used operationally.</p>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics:
  - numericalweatherpredictions
  updated_at: 1678447894.0
NCAR/spack-casper:
  data_format: 2
  description: Spack production user software stack on the Casper system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-casper
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NCAR Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>casper</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Wed May 24 15:47:05 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>53676ae8f55e772e606ca7beb43a711c256b9024</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.06</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/casper/23.06</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/casper/23.06/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 0
  subscribers_count: 9
  topics: []
  updated_at: 1679548145.0
NCAR/spack-gust:
  data_format: 2
  description: Spack production user software stack on the Gust test system
  filenames:
  - spack.yaml
  full_name: NCAR/spack-gust
  latest_release: null
  readme: '<h1><a id="user-content-ncar-spack-deployment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#ncar-spack-deployment"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>NCAR Spack Deployment</h1>

    <p>This branch tracks the <strong>production</strong> deployment of Spack for
    the following configuration:</p>

    <table>

    <thead>

    <tr>

    <th></th>

    <th>gust</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>Creation date</td>

    <td>Thu Mar 30 18:51:24 MDT 2023</td>

    </tr>

    <tr>

    <td>ncar-spack commit</td>

    <td>fd3fc5c8cd67abe692e5e38bae52f29fb32700a3</td>

    </tr>

    <tr>

    <td>Host version</td>

    <td>23.04</td>

    </tr>

    <tr>

    <td>Spack version</td>

    <td></td>

    </tr>

    <tr>

    <td>Deployment path</td>

    <td>/glade/u/apps/gust/23.04</td>

    </tr>

    <tr>

    <td>Environments path</td>

    <td>/glade/work/csgteam/spack-deployments/gust/23.04/envs</td>

    </tr>

    </tbody>

    </table>

    <p>This repository should <em>only</em> be updated via the <code>publish</code>
    script contained in the build environment. Any manual changes to this branch will
    cause headaches when you or another consultant attempt to publish new packages!</p>

    '
  stargazers_count: 5
  subscribers_count: 13
  topics: []
  updated_at: 1684182805.0
NERSC/spack-infrastructure:
  data_format: 2
  description: null
  filenames:
  - spack-configs/perlmutter-e4s-23.05/prod/tools/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/prod/cce/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/cce/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/cuda/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/prod/data/spack.yaml
  - spack-configs/perlmutter-e4s-21.11/ci/spack.yaml
  - spack-configs/cori-e4s-22.02/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml
  - spack-configs/cori-e4s-20.10/prod/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/gcc/spack.yaml
  - spack-configs/perlmutter-user-spack/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml
  - spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml
  - spack-configs/perlmutter-spack-develop/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/nvhpc/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/math-libs/spack.yaml
  - spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml
  - spack-configs/cori-e4s-20.10/spack.yaml
  - spack-configs/cori-e4s-22.02/ci/spack.yaml
  - spack-configs/perlmutter-e4s-23.05/data/spack.yaml
  full_name: NERSC/spack-infrastructure
  latest_release: null
  readme: "<h1><a id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#spack-infrastructure\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Spack Infrastructure</h1>\n<p>The\
    \ Spack Infrastructure Project makes use of <a href=\"https://spack.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">spack package manager</a> to install spack software stack on\
    \ NERSC systems. This project contains spack configuration (<code>spack.yaml</code>)\
    \ required to build the spack stacks. The spack stack is based on <a href=\"https://e4s.io/\"\
    \ rel=\"nofollow\">Extreme-Scale Scientific Software Stack</a> (E4S) where we\
    \ install spack packages provided by E4S and use the recommended spack branch.\
    \ We leverage <a href=\"https://docs.gitlab.com/ee/ci/\" rel=\"nofollow\">Gitlab\
    \ CI</a> to automate deployment to ensure reproducible and automated builds. For\
    \ more details about this project you can see the documentation at <a href=\"\
    https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\">https://nersc-spack-infrastructure.rtfd.io</a></p>\n\
    <h2><a id=\"user-content-software-deployment-overview\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#software-deployment-overview\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Software Deployment Overview</h2>\n\
    <p>The software deployment consist of the following steps</p>\n<ol>\n<li>Acquire\
    \ Spack Configuration from E4S project <a href=\"https://github.com/E4S-Project/e4s\"\
    >https://github.com/E4S-Project/e4s</a>\n</li>\n<li>Create one or more spack configuration\
    \ files (spack.yaml) with list of E4S packages and integrate spack configuration\
    \ for NERSC system</li>\n<li>Create a Gitlab Job to trigger the pipeline for TDS\
    \ and Deployment system</li>\n<li>Create a Modulefile as entry point to stack</li>\n\
    <li>Write User Documentation</li>\n<li>Share spack configuration with open-source\
    \ community</li>\n<li>Send announcement to all NERSC users</li>\n</ol>\n<h3><a\
    \ id=\"user-content-step-1-acquire-spack-configuration\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-1-acquire-spack-configuration\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 1: Acquire Spack Configuration</h3>\n\
    <p>At NERSC, we plan our software deployment with E4S releases which is typically\
    \ every 3 months however we perform deployment every 6 months. Once E4S has released\
    \ the spack configuration we acquire the spack configuration which is typically\
    \ found in <a href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\
    >https://github.com/E4S-Project/e4s/tree/master/environments</a>. We also acquire\
    \ the spack <a href=\"https://github.com/spack/spack/branches\">branch</a> used\
    \ by E4S team as our baseline, this would be documented in the release notes.\
    \ The name of branch map to the E4S version so version 23.05 will have a branch\
    \ <a href=\"https://github.com/spack/spack/tree/e4s-23.05\">e4s-23.05</a>.</p>\n\
    <p>Next, we copy the packages into our project and create the spack configuration</p>\n\
    <h3><a id=\"user-content-step-2-create-spack-configuration\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-2-create-spack-configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 2:\
    \ Create Spack Configuration</h3>\n<p>In this step we create the spack configuration.\
    \ First we create a sub-directory in <em>spack-configs</em> with the naming convention\
    \ to distinguish E4S version. This typically includes the\nname of the system\
    \ such as <code>cori</code> or <code>perlmutter</code> followed by name of e4s\
    \ version such as <code>e4s-23.05</code>.</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre>$ <span class=\"pl-s1\">tree -L 1 spack-configs</span>\n<span class=\"pl-c1\"\
    >spack-configs</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-20.10</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cori-e4s-21.02</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 cori-e4s-21.05</span>\n<span class=\"pl-c1\">\u251C\
    \u2500\u2500 cori-e4s-22.02</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-21.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.05</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\"\
    >\u251C\u2500\u2500 perlmutter-e4s-23.05</span>\n<span class=\"pl-c1\">\u251C\u2500\
    \u2500 perlmutter-spack-develop</span>\n<span class=\"pl-c1\">\u2514\u2500\u2500\
    \ perlmutter-user-spack</span>\n\n<span class=\"pl-c1\">10 directories, 0 files</span></pre></div>\n\
    <p>Inside one of the stacks, you will see several sub-directories that are used\
    \ for defining a sub-stack. These sub-stacks correspond to <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">spack environments</a>. The <code>prod</code> directory is\
    \ used for production deployment to install from the buildcache.</p>\n<div class=\"\
    highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">tree -L\
    \ 3 spack-configs/perlmutter-e4s-22.11</span>\n<span class=\"pl-c1\">spack-configs/perlmutter-e4s-22.11</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 cce</span>\n<span class=\"pl-c1\">\u2502\
    \_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500\
    \ cuda</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">\u251C\u2500\u2500 definitions.yaml</span>\n<span class=\"\
    pl-c1\">\u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">\u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">\u251C\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">\u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"\
    pl-c1\">\u2514\u2500\u2500 prod</span>\n<span class=\"pl-c1\">    \u251C\u2500\
    \u2500 cce</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n\
    <span class=\"pl-c1\">    \u251C\u2500\u2500 cuda</span>\n<span class=\"pl-c1\"\
    >    \u2502\_\_ \u2514\u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\"> \
    \   \u251C\u2500\u2500 gcc</span>\n<span class=\"pl-c1\">    \u2502\_\_ \u2514\
    \u2500\u2500 spack.yaml</span>\n<span class=\"pl-c1\">    \u2514\u2500\u2500 nvhpc</span>\n\
    <span class=\"pl-c1\">        \u2514\u2500\u2500 spack.yaml</span>\n\n<span class=\"\
    pl-c1\">9 directories, 9 files</span></pre></div>\n<p>We create a special file\
    \ named <code>definitions.yaml</code> that is used for declaring definitions that\
    \ is referenced in <code>spack.yaml</code>. This file is appended to all spack\
    \ configuration. We do this\nto ensure all specs are defined in one place.</p>\n\
    <p>During this step, we will create the spack configuration and specify our preferred\
    \ compilers and package preference. We install software in buildcache so it can\
    \ be relocated to production path. In order to accomplish this task, we use <a\
    \ href=\"https://spack.readthedocs.io/en/latest/pipelines.html\" rel=\"nofollow\"\
    >spack pipelines</a> that uses <code>spack ci generate</code> and <code>spack\
    \ ci rebuild</code> to perform parallel pipeline execution. During this step,\
    \ we determine which packages to install from E4S and add our own packages to\
    \ comply with our site preference.</p>\n<h3><a id=\"user-content-step-3-create-gitlab-job-for-automation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-3-create-gitlab-job-for-automation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 3:\
    \ Create Gitlab Job for Automation</h3>\n<p>Once spack configuration is written,\
    \ we create a gitlab job to trigger the pipeline. This can be done by specifying\
    \ a job in <a href=\"https://github.com/NERSC/spack-infrastructure/blob/main/.gitlab-ci.yml\"\
    >.gitlab-ci.yml</a>.</p>\n<p>The gitlab job can be triggered through <a href=\"\
    https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\" rel=\"\
    nofollow\">scheduled pipelines</a>, <a href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\"\
    \ rel=\"nofollow\">web-interface</a>, or merge request to the project. A typical\
    \ gitlab job will look something like this. Shown below is for E4S 23.05 generate\
    \ job. We make use of gitlab feature named <a href=\"https://docs.gitlab.com/ee/ci/yaml/index.html#extends\"\
    \ rel=\"nofollow\">extends</a> which allows us to reuse configuration. The <code>spack\
    \ ci generate</code> command will be the same for each substack. There is two\
    \ jobs, first is the generate step performed by <code>spack ci generate</code>\
    \ and this triggers the downstream job created by spack.</p>\n<div class=\"highlight\
    \ highlight-source-yaml\"><pre><span class=\"pl-ent\">.perlmutter-e4s-23.05-generate</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">generate</span>\n\
    \  <span class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    ]</span>\n  <span class=\"pl-ent\">tags</span>: <span class=\"pl-s\">[perlmutter-e4s]</span>\n\
    \  <span class=\"pl-ent\">interruptible</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">allow_failure</span>: <span class=\"pl-c1\">true</span>\n\
    \  <span class=\"pl-ent\">rules</span>:\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"schedule\" || $CI_PIPELINE_SOURCE\
    \ == \"web\") &amp;&amp; ($PIPELINE_NAME == \"PERLMUTTER_E4S_23.05\")</span>\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"merge_request_event\")</span>\n      <span class=\"pl-ent\">changes</span>:\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/$STACK_NAME/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">before_script</span>:\n    <span class=\"pl-s\">- *copy_perlmutter_settings</span>\n\
    \    <span class=\"pl-s\">- *startup_modules</span>\n  <span class=\"pl-ent\"\
    >script</span>:\n    <span class=\"pl-s\">- *e4s_23_05_setup </span>\n    - <span\
    \ class=\"pl-s\">cd $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/$STACK_NAME</span>\n\
    \    - <span class=\"pl-s\">cat $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/definitions.yaml\
    \ &gt;&gt; spack.yaml</span>\n    - <span class=\"pl-s\">spack env activate --without-view\
    \  .</span>\n    - <span class=\"pl-s\">spack env st</span>\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">#</span>- spack -d concretize -f | tee $CI_PROJECT_DIR/concretize.log\
    \    </span>\n    - <span class=\"pl-s\">spack -d ci generate --check-index-only\
    \ --artifacts-root \"$CI_PROJECT_DIR/jobs_scratch_dir\" --output-file \"${CI_PROJECT_DIR}/jobs_scratch_dir/pipeline.yml\"\
    </span>\n  <span class=\"pl-ent\">artifacts</span>: \n    <span class=\"pl-ent\"\
    >paths</span>:\n    - <span class=\"pl-s\">${CI_PROJECT_DIR}/jobs_scratch_dir</span>\n\
    \n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-generate</span>:\n  <span\
    \ class=\"pl-ent\">extends</span>: <span class=\"pl-s\">.perlmutter-e4s-23.05-generate</span>\n\
    \  <span class=\"pl-ent\">variables</span>:\n    <span class=\"pl-ent\">STACK_NAME</span>:\
    \ <span class=\"pl-s\">cce</span>\n\n<span class=\"pl-ent\">perlmutter-e4s-23.05-cce-build</span>:\n\
    \  <span class=\"pl-ent\">stage</span>: <span class=\"pl-s\">build</span>\n  <span\
    \ class=\"pl-ent\">needs</span>: <span class=\"pl-s\">[\"perlmutter:check_spack_dependencies\"\
    , \"perlmutter-e4s-23.05-cce-generate\"]</span>\n  <span class=\"pl-ent\">allow_failure</span>:\
    \ <span class=\"pl-c1\">true</span>\n  <span class=\"pl-ent\">rules</span>:\n\
    \    - <span class=\"pl-ent\">if</span>: <span class=\"pl-s\">($CI_PIPELINE_SOURCE\
    \ == \"schedule\" || $CI_PIPELINE_SOURCE == \"web\") &amp;&amp; ($PIPELINE_NAME\
    \ == \"PERLMUTTER_E4S_23.05\")</span>\n    - <span class=\"pl-ent\">if</span>:\
    \ <span class=\"pl-s\">($CI_PIPELINE_SOURCE == \"merge_request_event\")</span>\n\
    \      <span class=\"pl-ent\">changes</span>:\n      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/cce/spack.yaml</span>\n\
    \      - <span class=\"pl-s\">spack-configs/perlmutter-e4s-23.05/definitions.yaml</span>\n\
    \  <span class=\"pl-ent\">trigger</span>:\n    <span class=\"pl-ent\">include</span>:\n\
    \      - <span class=\"pl-ent\">artifact</span>: <span class=\"pl-s\">jobs_scratch_dir/pipeline.yml</span>\n\
    \        <span class=\"pl-ent\">job</span>: <span class=\"pl-s\">perlmutter-e4s-23.05-cce-generate</span>\n\
    \    <span class=\"pl-ent\">strategy</span>: <span class=\"pl-s\">depend</span></pre></div>\n\
    <h3><a id=\"user-content-step-4-create-modulefile\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-4-create-modulefile\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 4: Create Modulefile</h3>\n\
    <p>In this step, we create a modulefile as entry point to software stack and setup\
    \ <code>spack</code>. We do not create spack generated modules for spack packages,\
    \ instead one is expected to use <code>spack load</code>.  Shown below are the\
    \ modulefiles available on NERSC system, they are typically called <code>e4s/&lt;version&gt;</code>\
    \ with a symbolic link to module <code>spack/e4s-&lt;version&gt;</code></p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml -t av e4s</span>\n<span\
    \ class=\"pl-c1\">/global/common/software/nersc/pm-2022.12.0/extra_modulefiles:</span>\n\
    <span class=\"pl-c1\">e4s/22.05</span>\n<span class=\"pl-c1\">e4s/22.11</span>\n\
    <span class=\"pl-c1\">spack/e4s-22.05</span>\n<span class=\"pl-c1\">spack/e4s-22.11</span></pre></div>\n\
    <p>Shown below is the content of our modulefile, the setup is subject to change</p>\n\
    <div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-e\"\
    >siddiq90@login37</span>&gt; <span class=\"pl-s1\">ml --raw show e4s</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">   /global/common/software/nersc/pm-2022.12.0/extra_modulefiles/e4s/22.11.lua:</span>\n\
    <span class=\"pl-c1\">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span>\n\
    <span class=\"pl-c1\">whatis([[</span>\n<span class=\"pl-c1\">        The Extreme-scale\
    \ Scientific Software Stack (E4S) is a collection of open source software packages\
    \ for running scientific applications on high-performance computing (HPC) platforms.</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n<span class=\"pl-c1\">help([[ The Extreme-scale\
    \ Scientific Software Stack (E4S) is a community effort to provide open source\
    \ software packages for developing, deploying and running scientific applications\
    \ on high-performance computing (HPC) platforms. E4S provides from-source builds\
    \ and containers of a broad collection of HPC software packages.</span>\n\n<span\
    \ class=\"pl-c1\">References:</span>\n<span class=\"pl-c1\">  - E4S User Docs:\
    \ https://e4s.readthedocs.io/en/latest/index.html</span>\n<span class=\"pl-c1\"\
    >  - E4S 22.11 Docs: https://docs.nersc.gov/applications/e4s/perlmutter/22.11/</span>\n\
    <span class=\"pl-c1\">  - E4S Homepage: https://e4s-project.github.io/</span>\n\
    <span class=\"pl-c1\">  - E4S GitHub: https://github.com/E4S-Project/e4s</span>\n\
    <span class=\"pl-c1\">        ]])</span>\n\n<span class=\"pl-c1\">local root =\
    \ \"/global/common/software/spackecp/perlmutter/e4s-22.11/default/spack\"</span>\n\
    \n<span class=\"pl-c1\">setenv(\"SPACK_GNUPGHOME\", pathJoin(os.getenv(\"HOME\"\
    ), \".gnupg\"))</span>\n<span class=\"pl-c1\">setenv(\"SPACK_SYSTEM_CONFIG_PATH\"\
    , \"/global/common/software/spackecp/perlmutter/spack_settings\")</span>\n<span\
    \ class=\"pl-c1\">-- setup spack shell functionality</span>\n<span class=\"pl-c1\"\
    >local shell = myShellType()</span>\n<span class=\"pl-c1\">if (mode() == \"load\"\
    ) then</span>\n<span class=\"pl-c1\">    local spack_setup = ''</span>\n<span\
    \ class=\"pl-c1\">    if (shell == \"sh\" or shell == \"bash\" or shell == \"\
    zsh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.sh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"csh\") then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.csh\")</span>\n<span class=\"pl-c1\">    elseif (shell\
    \ == \"fish\")  then</span>\n<span class=\"pl-c1\">         spack_setup = pathJoin(root,\
    \ \"share/spack/setup-env.fish\")</span>\n<span class=\"pl-c1\">    end</span>\n\
    \n<span class=\"pl-c1\">    -- If we are unable to find spack setup script let's\
    \ terminate now.</span>\n<span class=\"pl-c1\">    if not isFile(spack_setup)\
    \ then</span>\n<span class=\"pl-c1\">        LmodError(\"Unable to find spack\
    \ setup script \" .. spack_setup .. \"\\n\")</span>\n<span class=\"pl-c1\">  \
    \  end</span>\n\n<span class=\"pl-c1\">    execute{cmd=\"source \" .. spack_setup,\
    \ modeA={\"load\"}}</span>\n\n<span class=\"pl-c1\">    LmodMessage([[</span>\n\
    <span class=\"pl-c1\">    _______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">     The Extreme-Scale Scientific Software Stack (E4S) is\
    \ accessible via the Spack package manager.</span>\n\n<span class=\"pl-c1\"> \
    \    In order to access the production stack, you will need to load a spack environment.\
    \ Here are some tips to get started:</span>\n\n\n<span class=\"pl-c1\">     'spack\
    \ env list' - List all Spack environments</span>\n<span class=\"pl-c1\">     'spack\
    \ env activate gcc' - Activate the \"gcc\" Spack environment</span>\n<span class=\"\
    pl-c1\">     'spack env status' - Display the active Spack environment</span>\n\
    <span class=\"pl-c1\">     'spack load amrex' - Load the \"amrex\" Spack package\
    \ into your user environment</span>\n\n<span class=\"pl-c1\">     For additional\
    \ support, please refer to the following references:</span>\n\n<span class=\"\
    pl-c1\">       NERSC E4S Documentation: https://docs.nersc.gov/applications/e4s/</span>\n\
    <span class=\"pl-c1\">       E4S Documentation: https://e4s.readthedocs.io</span>\n\
    <span class=\"pl-c1\">       Spack Documentation: https://spack.readthedocs.io/en/latest/</span>\n\
    <span class=\"pl-c1\">       Spack Slack: https://spackpm.slack.com</span>\n\n\
    <span class=\"pl-c1\">    ______________________________________________________________________________________________________</span>\n\
    <span class=\"pl-c1\">    ]])</span>\n<span class=\"pl-c1\">-- To remove spack\
    \ from shell we need to remove a few environment variables, alias and remove $SPACK_ROOT/bin\
    \ from $PATH</span>\n<span class=\"pl-c1\">elseif (mode() == \"unload\" or mode()\
    \ == \"purge\") then</span>\n<span class=\"pl-c1\">    if (shell == \"sh\" or\
    \ shell == \"bash\" or shell == \"zsh\") then</span>\n<span class=\"pl-c1\"> \
    \     execute{cmd=\"unset SPACK_ENV\",modeA={\"unload\"}}</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unset SPACK_ROOT\",modeA={\"unload\"}}</span>\n<span\
    \ class=\"pl-c1\">      execute{cmd=\"unset -f spack\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">    elseif (shell == \"csh\") then</span>\n<span class=\"\
    pl-c1\">      execute{cmd=\"unsetenv SPACK_ENV\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">      execute{cmd=\"unsetenv SPACK_ROOT\",modeA={\"unload\"\
    }}</span>\n<span class=\"pl-c1\">      execute{cmd=\"unalias spack\",modeA={\"\
    unload\"}}</span>\n<span class=\"pl-c1\">    end</span>\n\n<span class=\"pl-c1\"\
    >    -- Need to remove $SPACK_ROOT/bin from $PATH which removes the 'spack' command</span>\n\
    <span class=\"pl-c1\">    remove_path(\"PATH\", pathJoin(root, \"bin\"))</span>\n\
    \n<span class=\"pl-c1\">    -- Remove alias spacktivate. Need to pipe to /dev/null\
    \ as invalid alias can report error to stderr</span>\n<span class=\"pl-c1\"> \
    \   execute{cmd=\"unalias spacktivate &gt; /dev/null\",modeA={\"unload\"}}</span>\n\
    <span class=\"pl-c1\">end</span></pre></div>\n<h3><a id=\"user-content-step-5-user-documentation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-5-user-documentation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 5:\
    \ User Documentation</h3>\n<p>User documentation is fundamental to help assist\
    \ users with using E4S at NERSC. We document every E4S release with its <em>Release\
    \ Date</em> and <em>End of Support</em> date along with a documentation page outlining\
    \ the software stack. Our E4S documentation is available at <a href=\"https://docs.nersc.gov/applications/e4s/\"\
    \ rel=\"nofollow\">https://docs.nersc.gov/applications/e4s/</a>. The release date\
    \ is when documentation is live. We perform this action in conjunction with release\
    \ of modulefile so that user gain access to software stack.</p>\n<p>Upon completion\
    \ of this task, we are ready to make announcement to our NERSC users</p>\n<h3><a\
    \ id=\"user-content-step-6-sharing-spack-configuration-with-open-source-community\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#step-6-sharing-spack-configuration-with-open-source-community\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step 6:\
    \ Sharing spack configuration with open-source community</h3>\n<p>In this step,\
    \ we share our spack configuration with open-source community that may benefit\
    \ the wider community. We share our spack configuration at <a href=\"https://github.com/spack/spack-configs\"\
    >https://github.com/spack/spack-configs</a>. In addition, we update the <a href=\"\
    https://e4s.readthedocs.io/en/latest/facility_e4s.html\" rel=\"nofollow\">E4S\
    \ Facility Dashboard</a> that shows all the E4S deployments across all the facilities.</p>\n\
    <h3><a id=\"user-content-step-7-public-announcement\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#step-7-public-announcement\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 7: Public Announcement</h3>\n\
    <p>This is the final step of the deployment process, where we make a public announcement\
    \ in NERSC weekly email, along with various slack channels such as Nersc User\
    \ Group (NUG), Spack, ECP and E4S slack.</p>\n<h2><a id=\"user-content-current-challenges\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#current-challenges\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Current\
    \ Challenges</h2>\n<p>There are several challenges with building spack stack at\
    \ NERSC which can be summarized as follows</p>\n<ul>\n<li>\n<p><strong>System\
    \ OS + Cray Programming Environment (CPE) changes</strong>: A system upgrade such\
    \ as change to <code>glibc</code> or upgrades in CPE can lead to full software\
    \ stack rebuild, especially if you have external packages set for packages like\
    \ <code>cray-mpich</code>, <code>cray-libsci</code> which generally change between\
    \ versions</p>\n</li>\n<li>\n<p><strong>Incompatibile compilers</strong>: Some\
    \ packages can't be built with certain compilers (<code>nvhpc</code>, <code>aocc</code>)\
    \ which could be due to several factors.</p>\n<ul>\n<li>An application doesn't\
    \ have support though it was be added in newer version but you don't have it in\
    \ your spack release used for deployment</li>\n<li>Lack of support in spack package\
    \ recipe or spack-core base including spack-cray detection. This may require getting\
    \ fix and cherry-pick commit or waiting for new version</li>\n<li>Spack Cray detection\
    \ is an important part in build errors including how one specifies externals via\
    \ <code>modules</code> vs <code>prefix</code> both could be provided and it requires\
    \ experimentation. An example of this is trying to get <code>cray-mpich</code>\
    \ external one could set something like this with modules or prefix</li>\n</ul>\n\
    <div class=\"highlight highlight-source-yaml\"><pre>  <span class=\"pl-ent\">cray-mpich</span>:\n\
    \    <span class=\"pl-ent\">buildable</span>: <span class=\"pl-c1\">false</span>\n\
    \    <span class=\"pl-ent\">externals</span>:\n    - <span class=\"pl-ent\">spec</span>:\
    \ <span class=\"pl-s\">cray-mpich@8.1.11 %gcc@9.3.0</span>\n      <span class=\"\
    pl-ent\">prefix</span>: <span class=\"pl-s\">/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1</span>\n\
    \      <span class=\"pl-ent\">modules</span>:\n      - <span class=\"pl-s\">cray-mpich/8.1.11</span>\n\
    \      - <span class=\"pl-s\">cudatoolkit/21.9_11.4</span></pre></div>\n<ul>\n\
    <li>\n<strong>Spack concretizer</strong> prevent one from chosing a build configration\
    \ for a spec. This requires a few troubleshooting step but usually boils down\
    \ to:\n<ul>\n<li>Read the spack package file <code>spack edit &lt;package&gt;</code>\
    \ for conflicts and try <code>spack spec</code> to see concretized spec.</li>\n\
    <li>Try different version, different compiler, different dependency. Some packages\
    \ have conflicting variant for instance one can't enable <code>+openmp</code>\
    \ and <code>+pthread</code> it is mutually exclusive.</li>\n</ul>\n</li>\n</ul>\n\
    </li>\n</ul>\n<p>There is a document <a href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\"\
    \ rel=\"nofollow\">Spack E4S Issues on Permlutter</a> outlining current issues\
    \ with spack. If you need access to document please contact <strong>Shahzeb Siddiqui</strong>.</p>\n\
    <h2><a id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#contact\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Contact</h2>\n<p>If you need elevated privledge or assistance with\
    \ this project please contact one of the maintainers:</p>\n<ul>\n<li>Shahzeb Siddiqui\
    \ - <a href=\"mailto:shahzebsiddiqui@lbl.gov\">shahzebsiddiqui@lbl.gov</a>\n</li>\n\
    <li>Erik Palmer - <a href=\"mailto:epalmer@lbl.gov\">epalmer@lbl.gov</a>\n</li>\n\
    <li>Justin Cook - <a href=\"mailto:JSCook@lbl.gov\">JSCook@lbl.gov</a>\n</li>\n\
    <li>E4S Team: Sameer Shende (<a href=\"mailto:sameer@cs.uoregon.edu\">sameer@cs.uoregon.edu</a>),\
    \ Christopher Peyralans (<a href=\"mailto:lpeyrala@uoregon.edu\">lpeyrala@uoregon.edu</a>),\
    \ Wyatt Spear (<a href=\"mailto:wspear@cs.uoregon.edu\">wspear@cs.uoregon.edu</a>),\
    \ Nicholas Chaimov (<a href=\"mailto:nchaimov@paratools.com\">nchaimov@paratools.com</a>)</li>\n\
    </ul>\n"
  stargazers_count: 8
  subscribers_count: 14
  topics: []
  updated_at: 1673545287.0
NERSC/timemory:
  data_format: 2
  description: 'Modular C++ Toolkit for Performance Analysis and Logging. Profiling
    API and Tools for C, C++, CUDA, Fortran, and Python. The C++ template API is essentially
    a framework to creating tools: it is designed to provide a unifying interface
    for recording various performance measurements alongside data logging and interfaces
    to other tools.'
  filenames:
  - docker/gpu/spack.yaml
  - docker/cpu/spack.yaml
  full_name: NERSC/timemory
  latest_release: v3.2.3
  readme: "<h1><a id=\"user-content-timemory\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#timemory\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>timemory</h1>\n<h2><a id=\"user-content-timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Timing +\
    \ Memory + Hardware Counter Utilities for C / C++ / CUDA / Python</h2>\n<p><a\
    \ href=\"https://travis-ci.org/NERSC/timemory\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9505e1c9d1da422846396830ac218c61bb3343ebe5402ffb3b05b52558266d67/68747470733a2f2f7472617669732d63692e6f72672f4e455253432f74696d656d6f72792e7376673f6272616e63683d6d6173746572\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/NERSC/timemory.svg?branch=master\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/jrmadsen/timemory/branch/master\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4a833ca1c608ec560c59f2db36c4ea6c9c466102cba6505d53e6fcd6deaa3d7c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38786b37326f6f7477736566693863312f6272616e63682f6d61737465723f7376673d74727565\"\
    \ alt=\"Build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/8xk72ootwsefi8c1/branch/master?svg=true\"\
    \ style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/NERSC/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/87983d45b3e2381d7edd4ba6c892d41b4aeddd939663bcf2fb8cc60d29d4496f/68747470733a2f2f636f6465636f762e696f2f67682f4e455253432f74696d656d6f72792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"\
    \ alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/NERSC/timemory/branch/master/graph/badge.svg\"\
    \ style=\"max-width: 100%;\"></a></p>\n<p><a href=\"https://github.com/NERSC/timemory\"\
    >timemory on GitHub (Source code)</a></p>\n<p><a href=\"https://timemory.readthedocs.io\"\
    \ rel=\"nofollow\">timemory General Documentation (ReadTheDocs)</a></p>\n<p><a\
    \ href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\
    >timemory Source Code Documentation (Doxygen)</a></p>\n<p><a href=\"https://cdash.nersc.gov/index.php?project=TiMemory\"\
    \ rel=\"nofollow\">timemory Testing Dashboard (CDash)</a></p>\n<p><a href=\"https://github.com/NERSC/timemory-tutorials\"\
    >timemory Tutorials</a></p>\n<ul>\n<li>\n<p><a href=\"https://www.youtube.com/watch?v=K1Pazcw7zVo\"\
    \ rel=\"nofollow\">ECP 2021 Tutorial Day 1 (YouTube)</a></p>\n</li>\n<li>\n<p><a\
    \ href=\"https://www.youtube.com/watch?v=-zIpZDiwrmI\" rel=\"nofollow\">ECP 2021\
    \ Tutorial Day 2 (YouTube)</a></p>\n</li>\n</ul>\n<p><a href=\"https://github.com/NERSC/timemory/wiki\"\
    >timemory Wiki</a></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>GitHub</td>\n<td><code>git clone https://github.com/NERSC/timemory.git</code></td>\n\
    </tr>\n<tr>\n<td>PyPi</td>\n<td><code>pip install timemory</code></td>\n</tr>\n\
    <tr>\n<td>Spack</td>\n<td><code>spack install timemory</code></td>\n</tr>\n<tr>\n\
    <td>conda-forge</td>\n<td><code>conda install -c conda-forge timemory</code></td>\n\
    </tr>\n<tr>\n<td></td>\n<td><a href=\"https://anaconda.org/conda-forge/timemory\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/33319eee64e9e77e6164e27e48c8d3e752580de537246f0108c2613a392c44d2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265636970652d74696d656d6f72792d677265656e2e737667\"\
    \ alt=\"Conda Recipe\" data-canonical-src=\"https://img.shields.io/badge/recipe-timemory-green.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/a9c6e0aeed14f60203f554ea93bf6b34a4c8f041c16d2e88bc3e2ab2c0e786bd/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/336c5f6fee8494649e0e14802c2fa61d049a0fc4d3c424a9b8f0626aa4b27f78/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"> <img src=\"https://camo.githubusercontent.com/4db6b05734f08002f400c6aaefe6579f74282758c11efbe421981e8200bd2c6d/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f706e2f636f6e64612d666f7267652f74696d656d6f72792e737667\"\
    \ alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/conda/pn/conda-forge/timemory.svg\"\
    \ style=\"max-width: 100%;\"></a></td>\n</tr>\n</tbody>\n</table>\n<h2><a id=\"\
    user-content-purpose\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #purpose\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Purpose</h2>\n\
    <p>The goal of timemory is to create an open-source performance measurement and\
    \ analyis package\nwith modular and reusable components which can be used to adapt\
    \ to any existing C/C++\nperformance measurement and analysis API and is arbitrarily\
    \ extendable by users within their\napplication.\nTimemory is not just another\
    \ profiling tool, it is a profling <em>toolkit</em> which streamlines building\
    \ custom\nprofiling tools through modularity and then utilizes the toolkit to\
    \ provides several pre-built tools.</p>\n<p>In other words, timemory provides\
    \ many pre-built tools, libraries, and interfaces but, due to it's modularity,\n\
    codes can re-use only individual pieces -- such as the classes for measuring different\
    \ timing intervals, memory usage,\nand hardware counters -- without the timemory\
    \ \"runtime management\".</p>\n<h2><a id=\"user-content-building-and-installing\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-and-installing\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ and Installing</h2>\n<p>Timemory uses a standard CMake installation.\nSeveral\
    \ installation examples can be found in the <a href=\"https://github.com/NERSC/timemory/wiki/Installation-Examples\"\
    >Wiki</a>. See the <a href=\"https://timemory.readthedocs.io/en/develop/installation.html\"\
    \ rel=\"nofollow\">installation documentation</a> for detailed information on\
    \ the CMake options.</p>\n<h2><a id=\"user-content-documentation\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#documentation\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p>The full\
    \ documentation is available at <a href=\"https://timemory.readthedocs.io\" rel=\"\
    nofollow\">timemory.readthedocs.io</a>.\nDetailed source documentation is provided\
    \ in the <a href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"\
    nofollow\">doygen</a>\nsection of the full documentation.\nTutorials are available\
    \ in the <a href=\"https://github.com/NERSC/timemory-tutorials\">github.com/NERSC/timemory-tutorials</a>.</p>\n\
    <h2><a id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#overview\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Overview</h2>\n<p><strong><em>The primary objective of the timemory\
    \ is the development of a common framework for binding together software\nmonitoring\
    \ code (i.e. performance analysis, debugging, logging) into a compact and highly-efficient\
    \ interface.</em></strong></p>\n<p>Timemory arose out of the need for a universal\
    \ adapator kit for the various APIs provided several existing tools\nand a straight-forward\
    \ and intuitive method for creating new tools. Timemory makes it possible to bundle\n\
    together deterministic performance measurements, statistical performance\nmeasurements\
    \ (i.e. sampling), debug messages, data logging, and data validation into the\
    \ same interface for\ncustom application-specific software monitoring interfaces,\
    \ easily building tools like <code>time</code>,\n<code>netstat</code>, instrumentation\
    \ profilers, sampling profilers, and writing implementations for MPI-P, MPI-T,\
    \ OMPT,\nKokkosP, etc. Furthermore, timemory can forward its markers to several\
    \ third-party profilers such as\n<a href=\"https://github.com/RRZE-HPC/likwid\"\
    >LIKWID</a>, <a href=\"https://github.com/LLNL/Caliper\">Caliper</a>,\n<a href=\"\
    https://www.cs.uoregon.edu/research/tau/home.php\" rel=\"nofollow\">TAU</a>, <a\
    \ href=\"https://github.com/gperftools/gperftools\">gperftools</a>,\n<a href=\"\
    https://perfetto.dev/docs/\" rel=\"nofollow\">Perfetto</a>, VTune, Allinea-MAP,\
    \ CrayPAT, Nsight-Systems, Nsight-Compute, and NVProf.</p>\n<p>Timemory provides\
    \ a front-end <a href=\"https://timemory.readthedocs.io/en/develop/api/library.html\"\
    \ rel=\"nofollow\">C/C++/Fortran API</a>\nand <a href=\"https://timemory.readthedocs.io/en/develop/api/python.html\"\
    \ rel=\"nofollow\">Python API</a> which allows arbitrary selection\nof 50+ different\
    \ components from timers to hardware counters to interfaces with third-party tools.\
    \ This is all\nbuilt generically from the toolkit API with type-safe bundles of\
    \ tools such as:\n<code>component_tuple&lt;wall_clock, papi_vector, nvtx_marker,\
    \ user_bundle&gt;</code>\nwhere <code>wall_clock</code> is a wall-clock timer,\n\
    <code>papi_vector</code> is a handle for hardware counters,\n<code>nvxt_marker</code>\
    \ creates notations in the NVIDIA CUDA profilers, and\n<code>user_bundle</code>\
    \ is a generic component which downstream users can insert more components into\
    \ at runtime.</p>\n<p>Performance measurement components written with timemory\
    \ are arbitrarily scalable up to any number of threads and\nprocesses and fully\
    \ support intermixing different measurements at different locations within the\
    \ program -- this\nuniquely enables timemory to be deployed to collect performance\
    \ data at scale in HPC because highly detailed collection can\noccur at specific\
    \ locations within the program where ubiquitous collection would simulatenously\
    \ degrade performance\nsignificantly and require a prohibitive amount of memory.</p>\n\
    <p>Timemory can be used as a backend to bundle instrumentation and sampling tools\
    \ together, support serialization to JSON/XML,\nand provide statistics among other\
    \ uses. It can also be utilized as a front-end to invoke\ncustom instrumentation\
    \ and sampling tools. Timemory uses the abstract term \"component\" for a structure\n\
    which encapsulates some performance analysis operation. The structure might encapsulate\
    \ function\ncalls to another tool, record timestamps for timing, log values provided\
    \ by the application,\nprovide a operator for replacing a function in the code\
    \ dynamically, audit the incoming arguments\nand/or outgoing return value from\
    \ function, or just provide stubs which can be overloaded by the linker.</p>\n\
    <h3><a id=\"user-content-visualization-and-analysis\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#visualization-and-analysis\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Visualization and Analysis</h3>\n\
    <p>The native output format of timemory is JSON and text; other output formats\
    \ such as XML are also supported.\nThe text format is intended to be human readable.\
    \ The JSON data\nis intended for analysis and comes in two flavors: hierarchical\
    \ and flat. Basic plotting capabilities are\navailable via <code>timemory-plotting</code>\
    \ but users are highly encouraged to use <a href=\"https://github.com/hatchet/hatchet\"\
    >hatchet</a>\nfor analyzing the heirarchical JSON data in pandas dataframes. <a\
    \ href=\"https://github.com/hatchet/hatchet\">Hatchet</a> supports\nfiltering,\
    \ unions, addition, subtractions, output to <code>dot</code> and flamegraph formats,\
    \ and an interactive Jupyter notebook.\nAt present, timemory supports 45+ metric\
    \ types for analysis in Hatchet.</p>\n<h3><a id=\"user-content-categories\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#categories\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Categories</h3>\n<p>There are\
    \ 4 primary categories in timemory: components, operations, bundlers, and storage.\
    \ Components provide\nthe specifics of how to perform a particular behavior, operations\
    \ provide the scaffold for requesting that\na component perform an operation in\
    \ complex scenarios, bundlers group components into a single generic handle,\n\
    and storage manages data collection over the lifetime of the application. When\
    \ all four categories are combined,\ntimemory effectively resembles a standard\
    \ performance analysis tool which passively collects data and provides\nreports\
    \ and analysis at the termination of the application. Timemory, however, makes\
    \ it <em>very easy</em> to subtract\nstorage from the equation and, in doing so,\
    \ transforms timemory into a toolkit for customized data collection.</p>\n<ol>\n\
    <li>\n<strong><em>Components</em></strong>\n<ul>\n<li>Individual classes which\
    \ encapsulate one or more measurement, analysis, logging, or third-party library\
    \ action(s)</li>\n<li>Any data specific to one instance of performing the action\
    \ is stored within the instance of the class</li>\n<li>Any configuration data\
    \ specific to that type is typically stored within static member functions which\
    \ return a reference to the configuration data</li>\n<li>These classes are designed\
    \ to support direct usage within other tools, libraries, etc.</li>\n<li>Examples\
    \ include:\n<ul>\n<li>\n<code>tim::component::wall_clock</code> : a simple wall-clock\
    \ timer</li>\n<li>\n<code>tim::component::vtune_profiler</code> : a simple component\
    \ which turns the VTune Profiler on and off (when VTune is actively profiling\
    \ application)</li>\n<li>\n<code>tim::component::data_tracker_integer</code> :\
    \ associates an integer values with a label as the application executes (e.g.\
    \ number of loop iterations used somewhere)</li>\n<li>\n<code>tim::component::papi_vector</code>\
    \ : uses the PAPI library to collect hardware-counters values</li>\n<li>\n<code>tim::component::user_bundle</code>\
    \ : encapsulates an array of components which the user can dynamically manipulate\
    \ during runtime</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Operations</em></strong>\n\
    <ul>\n<li>Templated classes whose primary purpose is to provide the implementation\
    \ for performing some action on a component, e.g. <code>tim::operation::start&lt;wall_clock&gt;</code>\
    \ will attempt to call the <code>start()</code> member function on a <code>wall_clock</code>\
    \ component instance</li>\n<li>Default implementations generally have one or two\
    \ public functions: a constructor and/or a function call operator\n<ul>\n<li>These\
    \ generally accept any/all arguments and use SFINAE to determine whether the operation\
    \ can be performed with or without the given arguments (i.e. does <code>wall_clock</code>\
    \ have a <code>store(int)</code> function? <code>store()</code>?)</li>\n</ul>\n\
    </li>\n<li>Operations are (generally) not directly utilized by the user and are\
    \ typically optimized out of the binary</li>\n<li>Examples include:\n<ul>\n<li>\n\
    <code>tim::operation::start</code> : instruct a component to start collection</li>\n\
    <li>\n<code>tim::operation::sample</code> : instruct a component to take individual\
    \ measurement</li>\n<li>\n<code>tim::operation::derive</code> : extra data from\
    \ other components if it is available</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n\
    <strong><em>Bundlers</em></strong>\n<ul>\n<li>Provide a generic handle for multiple\
    \ components</li>\n<li>Member functions generally accept any/all arguments and\
    \ use operations classes to correctly to handle differences between different\
    \ capabilities of the components it is bundling</li>\n<li>Examples include:\n\
    <ul>\n<li><code>tim::auto_tuple</code></li>\n<li><code>tim::component_tuple</code></li>\n\
    <li><code>tim::component_list</code></li>\n<li><code>tim::lightweight_tuple</code></li>\n\
    </ul>\n</li>\n<li>Various flavors provide different implicit behaviors and allocate\
    \ memory differently\n<ul>\n<li>\n<code>auto_tuple</code> starts all components\
    \ when constructed and stops all components when destructed whereas <code>component_tuple</code>\
    \ requires an explicit start</li>\n<li>\n<code>component_tuple</code> allocates\
    \ all components on the stack and components are \"always on\" whereas <code>component_list</code>\
    \ allocates components on the heap and thus components can be activated/deactivated\
    \ at runtime</li>\n<li>\n<code>lightweight_tuple</code> does not implicitly perform\
    \ any expensive actions, such as call-stack tracking in \"Storage\"</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>\n<strong><em>Storage</em></strong>\n<ul>\n<li>Provides\
    \ persistent storage for multiple instances of components over the lifetime of\
    \ a thread in the application</li>\n<li>Responsible for maintaining the hierarchy\
    \ and order of component measurements, i.e. call-stack tracking</li>\n<li>Responsible\
    \ for combining component data from multiple threads and/or processes and outputting\
    \ the results</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: <code>tim::lightweight_tuple</code>\
    \ is the recommended bundle for those seeking to use timemory as a toolkit for\
    \ implementing custom tools and interfaces</p>\n</blockquote>\n<h2><a id=\"user-content-features\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#features\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Features</h2>\n\
    <ul>\n<li>C++ Template API\n<ul>\n<li>Modular and fully-customizable</li>\n<li>Adheres\
    \ to C++ standard template library paradigm of \"you don't pay for what you don't\
    \ use\"</li>\n<li>Simplifies and facilitates creation and implementation of performance\
    \ measurement tools\n<ul>\n<li>Create your own instrumentation profiler</li>\n\
    <li>Create your own instrumentation library</li>\n<li>Create your own sampling\
    \ profiler</li>\n<li>Create your own sampling library</li>\n<li>Create your own\
    \ execution wrappers</li>\n<li>Supplement timemory-provided tools with your own\
    \ custom component(s)</li>\n<li>Thread-safe data aggregation</li>\n<li>Aggregate\
    \ collection over multiple processes (MPI and UPC++ support)</li>\n<li>Serialization\
    \ to text, JSON, XML</li>\n</ul>\n</li>\n<li>Components are composable with other\
    \ components</li>\n<li>Variadic component bundlers which maintain complete type-safety\n\
    <ul>\n<li>Components can be bundled together into a single handle without abstractions</li>\n\
    </ul>\n</li>\n<li>Components can store data in any valid C++ data type</li>\n\
    <li>Components can return data in any valid C++ data type</li>\n</ul>\n</li>\n\
    <li>C / C++ / CUDA / Fortran Library API\n<ul>\n<li>Straight-forward collection\
    \ of functions and macros for creating built-in performance analysis to your code</li>\n\
    <li>Component collection can be arbitrarily inter-mixed\n<ul>\n<li>E.g. collect\
    \ \"A\" and \"B\" in one region, \"A\" and \"C\" in another region</li>\n</ul>\n\
    </li>\n<li>Component collection can be dynamically manipulated at runtime\n<ul>\n\
    <li>E.g. add/remove \"A\" at any point, on any thread, on any process</li>\n</ul>\n\
    </li>\n</ul>\n</li>\n<li>Python API\n<ul>\n<li>Decorators and context-managers\
    \ for functions or regions in code</li>\n<li>Python function profiling</li>\n\
    <li>Python line-by-line profiling</li>\n<li>Every component in <code>timemory-avail</code>\
    \ is provided as a stand-alone Python class\n<ul>\n<li>Provide low-overhead measurements\
    \ for building your own Python profiling tools</li>\n</ul>\n</li>\n</ul>\n</li>\n\
    <li>Python Analysis via <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\"\
    >pandas</a>\n</li>\n<li>Command-line Tools\n<ul>\n<li>\n<a href=\"source/tools/timemory-avail/README.md\"\
    >timemory-avail</a>\n<ul>\n<li>Provides available components, settings, and hardware\
    \ counters</li>\n<li>Quick API reference tool</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timem/README.md\">timem</a> (UNIX)\n<ul>\n<li>Extended version of\
    \ UNIX <code>time</code> command-line tool that includes additional information\
    \ on memory usage, context switches, and hardware counters</li>\n<li>Support collecting\
    \ hardware counters (Linux-only, requires PAPI)</li>\n</ul>\n</li>\n<li>\n<a href=\"\
    source/tools/timemory-run/README.md\">timemory-run</a> (Linux)\n<ul>\n<li>Dynamic\
    \ instrumentation profiling tool</li>\n<li>Supports runtime instrumentation and\
    \ binary re-writing</li>\n</ul>\n</li>\n<li>\n<a href=\"source/tools/timemory-nvml/README.md\"\
    >timemory-nvml</a>\n<ul>\n<li>Data collection similar to <code>nvidia-smi</code>\n\
    </li>\n</ul>\n</li>\n<li>\n<code>timemory-python-profiler</code>\n<ul>\n<li>Python\
    \ function profiler supporting all timemory components</li>\n<li><code>from timemory.profiler\
    \ import Profile</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-trace</code>\n\
    <ul>\n<li>Python line-by-line profiler supporting all timemory components</li>\n\
    <li><code>from timemory.trace import Trace</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-line-profiler</code>\n\
    <ul>\n<li>Python line-by-line profiler based on <a href=\"https://pypi.org/project/line-profiler/\"\
    \ rel=\"nofollow\">line-profiler</a> package</li>\n<li>Extended to use components:\
    \ cpu-clock, memory-usage, context-switches, etc. (all components which collect\
    \ scalar values)</li>\n<li><code>from timemory.line_profiler import LineProfiler</code></li>\n\
    </ul>\n</li>\n</ul>\n</li>\n<li>Instrumentation Libraries\n<ul>\n<li>\n<a href=\"\
    source/tools/timemory-mpip/README.md\">timemory-mpip</a>: MPI Profiling Library\
    \ (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ncclp/README.md\">timemory-ncclp</a>:\
    \ NCCL Profiling Library (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ompt/README.md\"\
    >timemory-ompt</a>: OpenMP Profiling Library</li>\n<li>\n<a href=\"source/tools/timemory-compiler-instrument/README.md\"\
    >timemory-compiler-instrument</a>: Compiler instrumentation Library</li>\n<li>\n\
    <a href=\"source/tools/kokkos-connector/README.md\">kokkos-connector</a>: Kokkos\
    \ Profiling Libraries</li>\n</ul>\n</li>\n</ul>\n<h2><a id=\"user-content-samples\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#samples\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Samples</h2>\n\
    <p>Various macros are defined for C in <a href=\"source/timemory/timemory.h\"\
    >source/timemory/compat/timemory_c.h</a>\nand <a href=\"source/timemory/variadic/macros.hpp\"\
    >source/timemory/variadic/macros.hpp</a>. Numerous samples of\ntheir usage can\
    \ be found in the examples.</p>\n<h3><a id=\"user-content-sample-c-template-api\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#sample-c-template-api\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Sample C++\
    \ Template API</h3>\n<div class=\"highlight highlight-source-c++\"><pre>#<span\
    \ class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>timemory/timemory.hpp<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"\
    pl-k\">namespace</span> <span class=\"pl-en\">comp</span> <span class=\"pl-k\"\
    >=</span> tim::component;\n<span class=\"pl-k\">using</span> <span class=\"pl-k\"\
    >namespace</span> <span class=\"pl-en\">tim</span><span class=\"pl-k\">;</span>\n\
    \n<span class=\"pl-c\"><span class=\"pl-c\">//</span> specific set of components</span>\n\
    <span class=\"pl-k\">using</span> <span class=\"pl-c1\">specific_t</span> = component_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;;\n<span class=\"pl-k\">using</span> <span class=\"pl-c1\"\
    >generic_t</span>  = component_tuple&lt;comp::user_global_bundle&gt;;\n\n<span\
    \ class=\"pl-k\">int</span>\n<span class=\"pl-en\">main</span>(<span class=\"\
    pl-k\">int</span> argc, <span class=\"pl-k\">char</span>** argv)\n{\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> configure default settings</span>\n\
    \    <span class=\"pl-c1\">settings::flat_profile</span>() = <span class=\"pl-c1\"\
    >true</span>;\n    <span class=\"pl-c1\">settings::timing_units</span>() = <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span class=\"pl-pds\">\"\
    </span></span>;\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> initialize\
    \ with cmd-line</span>\n    <span class=\"pl-c1\">timemory_init</span>(argc, argv);\n\
    \    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> add argparse support</span>\n\
    \    <span class=\"pl-c1\">timemory_argparse</span>(&amp;argc, &amp;argv);\n\n\
    \    <span class=\"pl-c\"><span class=\"pl-c\">//</span> create a region \"main\"\
    </span>\n    <span class=\"pl-c1\">specific_t</span> m{ <span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span> };\n \
    \   m.<span class=\"pl-c1\">start</span>();\n    m.<span class=\"pl-c1\">stop</span>();\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">settings::enabled</span>() = <span\
    \ class=\"pl-c1\">false</span>;\n    <span class=\"pl-c1\">specific_t</span> h{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden<span class=\"pl-pds\"\
    >\"</span></span> };\n    h.<span class=\"pl-c1\">start</span>().<span class=\"\
    pl-c1\">stop</span>();\n    <span class=\"pl-c1\">settings::enabled</span>() =\
    \ <span class=\"pl-c1\">true</span>;\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Add peak_rss component to specific_t</span>\n    mpl::<span class=\"\
    pl-c1\">push_back_t</span>&lt;<span class=\"pl-c1\">specific_t</span>, comp::peak_rss&gt;\
    \ wprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>with peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n    \n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> create region collecting only peak_rss</span>\n    component_tuple&lt;comp::peak_rss&gt;\
    \ oprss{ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>only peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> };\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> convert component_tuple to a type that starts/stops upon construction/destruction</span>\n\
    \    {\n        scope::config _scope{};\n        <span class=\"pl-k\">if</span>(<span\
    \ class=\"pl-c1\">true</span>)  _scope += scope::flat{};\n        <span class=\"\
    pl-k\">if</span>(<span class=\"pl-c1\">false</span>) _scope += scope::timeline{};\n\
    \        <span class=\"pl-c1\">convert_t</span>&lt;<span class=\"pl-c1\">specific_t</span>,\
    \ auto_tuple&lt;&gt;&gt; scoped{ <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>scoped start/stop + flat<span class=\"pl-pds\">\"</span></span>, _scope\
    \ };\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> will yield auto_tuple&lt;comp::wall_clock,\
    \ comp::cpu_clock&gt;</span>\n    }\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of strings</span>\n    runtime::configure&lt;comp::user_global_bundle&gt;({\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span\
    \ class=\"pl-pds\">\"</span></span> });\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> configure the generic bundle via set of enumeration ids</span>\n\
    \    runtime::configure&lt;comp::user_global_bundle&gt;({ TIMEMORY_WALL_CLOCK,\
    \ TIMEMORY_CPU_CLOCK });\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ configure the generic bundle via component instances</span>\n    comp::user_global_bundle::configure&lt;comp::page_rss,\
    \ comp::papi_vector&gt;();\n    \n    <span class=\"pl-c1\">generic_t</span> g{\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>generic<span class=\"pl-pds\"\
    >\"</span></span>, quirk::config&lt;quirk::auto_start&gt;{} };\n    g.<span class=\"\
    pl-c1\">stop</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3><a id=\"user-content-sample-c--c-library-api\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sample-c--c-library-api\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Sample C / C++ Library API</h3>\n\
    <div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/library.h<span\
    \ class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>timemory/timemory.h<span class=\"\
    pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">int</span>\n<span class=\"pl-en\"\
    >main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span>**\
    \ argv)\n{\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> configure\
    \ settings</span>\n    <span class=\"pl-k\">int</span> overwrite       = <span\
    \ class=\"pl-c1\">0</span>;\n    <span class=\"pl-k\">int</span> update_settings\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> default to flat-profile</span>\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_FLAT_PROFILE<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ON<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> force timing units</span>\n    overwrite\
    \ = <span class=\"pl-c1\">1</span>;\n    <span class=\"pl-c1\">timemory_set_environ</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>TIMEMORY_TIMING_UNITS<span class=\"\
    pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>msec<span\
    \ class=\"pl-pds\">\"</span></span>, overwrite, update_settings);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> initialize with cmd-line</span>\n\
    \    <span class=\"pl-c1\">timemory_init_library</span>(argc, argv);\n\n    <span\
    \ class=\"pl-c\"><span class=\"pl-c\">//</span> check if inited, init with name</span>\n\
    \    <span class=\"pl-k\">if</span>(!<span class=\"pl-c1\">timemory_library_is_initialized</span>())\n\
    \        <span class=\"pl-c1\">timemory_named_init_library</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>ex-c<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> define the default set\
    \ of components</span>\n    <span class=\"pl-c1\">timemory_set_default</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock, cpu_clock<span class=\"\
    pl-pds\">\"</span></span>);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>\
    \ create a region \"main\"</span>\n    <span class=\"pl-c1\">timemory_push_region</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>);\n    <span class=\"pl-c1\">timemory_pop_region</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> pause and resume collection\
    \ globally</span>\n    <span class=\"pl-c1\">timemory_pause</span>();\n    <span\
    \ class=\"pl-c1\">timemory_push_region</span>(<span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_pop_region</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>hidden<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"\
    pl-c1\">timemory_resume</span>();\n\n    <span class=\"pl-c\"><span class=\"pl-c\"\
    >//</span> Add/remove component(s) to the current set of components</span>\n \
    \   <span class=\"pl-c1\">timemory_add_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_remove_components</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> get an identifier for\
    \ a region and end it</span>\n    <span class=\"pl-c1\">uint64_t</span> idx =\
    \ <span class=\"pl-c1\">timemory_get_begin_record</span>(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> assign an existing identifier for a region</span>\n\
    \    <span class=\"pl-c1\">timemory_begin_record</span>(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>indexed/2<span class=\"pl-pds\">\"</span></span>,\
    \ &amp;idx);\n    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n \
    \   <span class=\"pl-c\"><span class=\"pl-c\">//</span> create region collecting\
    \ a specific set of data</span>\n    <span class=\"pl-c1\">timemory_begin_record_enum</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>enum<span class=\"pl-pds\">\"\
    </span></span>, &amp;idx, TIMEMORY_PEAK_RSS, TIMEMORY_COMPONENTS_END);\n    <span\
    \ class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"pl-c1\"\
    >timemory_begin_record_types</span>(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>types<span class=\"pl-pds\">\"</span></span>, &amp;idx, <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>);\n\
    \    <span class=\"pl-c1\">timemory_end_record</span>(idx);\n\n    <span class=\"\
    pl-c\"><span class=\"pl-c\">//</span> replace current set of components and then\
    \ restore previous set</span>\n    <span class=\"pl-c1\">timemory_push_components</span>(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\"\
    >\"</span></span>);\n    <span class=\"pl-c1\">timemory_pop_components</span>();\n\
    \n    <span class=\"pl-c1\">timemory_push_components_enum</span>(<span class=\"\
    pl-c1\">2</span>, TIMEMORY_WALL_CLOCK, TIMEMORY_CPU_CLOCK);\n    <span class=\"\
    pl-c1\">timemory_pop_components</span>();\n\n    <span class=\"pl-c\"><span class=\"\
    pl-c\">//</span> Output the results</span>\n    <span class=\"pl-c1\">timemory_finalize_library</span>();\n\
    \    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n\
    <h3><a id=\"user-content-sample-fortran-api\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#sample-fortran-api\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Sample Fortran API</h3>\n<div class=\"\
    highlight highlight-source-fortran\"><pre><span class=\"pl-k\">program</span>\
    \ fortran_example\n    use timemory\n    use iso_c_binding, only : C_INT64_T\n\
    \    <span class=\"pl-k\">implicit none</span>\n    <span class=\"pl-k\">integer</span>(C_INT64_T)\
    \ <span class=\"pl-k\">::</span> idx\n\n    ! initialize with explicit name\n\
    \    <span class=\"pl-k\">call</span> timemory_init_library(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>ex-fortran<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! initialize with name extracted from get_command_argument(<span class=\"\
    pl-c1\">0</span>, ...)\n    ! <span class=\"pl-k\">call</span> timemory_init_library(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! define the default set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_set_default(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>wall_clock,\
    \ cpu_clock<span class=\"pl-pds\">\"</span></span>)\n\n    ! Start region <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! Add peak_rss <span class=\"pl-k\">to</span> the current\
    \ set of components\n    <span class=\"pl-k\">call</span> timemory_add_components(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\"\
    >\"</span></span>)\n\n    ! Nested region <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>inner<span class=\"pl-pds\">\"</span></span> nested under <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"\
    </span></span>\n    <span class=\"pl-k\">call</span> timemory_push_region(<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span class=\"pl-pds\">\"\
    </span></span>)\n\n    ! End the <span class=\"pl-s\"><span class=\"pl-pds\">\"\
    </span>inner<span class=\"pl-pds\">\"</span></span> region\n    <span class=\"\
    pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner<span class=\"pl-pds\">\"</span></span>)\n\n    ! remove peak_rss\n\
    \    <span class=\"pl-k\">call</span> timemory_remove_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>peak_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! begin a region and get an identifier\n    idx <span class=\"pl-k\">=</span>\
    \ timemory_get_begin_record(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>indexed<span\
    \ class=\"pl-pds\">\"</span></span>)\n\n    ! replace current set of components\n\
    \    <span class=\"pl-k\">call</span> timemory_push_components(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>page_rss<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Nested region <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> with only page_rss components\n    <span class=\"\
    pl-k\">call</span> timemory_push_region(<span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\n    ! <span\
    \ class=\"pl-k\">Stop</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inner<span\
    \ class=\"pl-pds\">\"</span></span> region with only page_rss components\n   \
    \ <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span>inner (pushed)<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! restore previous set of components\n    <span class=\"pl-k\">call</span>\
    \ timemory_pop_components()\n\n    ! end the <span class=\"pl-s\"><span class=\"\
    pl-pds\">\"</span>indexed<span class=\"pl-pds\">\"</span></span> region\n    <span\
    \ class=\"pl-k\">call</span> timemory_end_record(idx)\n\n    ! End <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>\n\
    \    <span class=\"pl-k\">call</span> timemory_pop_region(<span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>main<span class=\"pl-pds\">\"</span></span>)\n\
    \n    ! Output the results\n    <span class=\"pl-k\">call</span> timemory_finalize_library()\n\
    \n<span class=\"pl-k\">end program</span> fortran_example</pre></div>\n<h3><a\
    \ id=\"user-content-sample-python-api\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#sample-python-api\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Sample Python API</h3>\n<h4><a id=\"user-content-decorator\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#decorator\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Decorator</h4>\n\
    <div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span>\
    \ <span class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">bundle</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-s1\">marker</span>\n\n<span class=\"\
    pl-en\">@<span class=\"pl-en\">marker</span>([<span class=\"pl-s\">\"cpu_clock\"\
    </span>, <span class=\"pl-s\">\"peak_rss\"</span>])</span>\n<span class=\"pl-k\"\
    >def</span> <span class=\"pl-en\">foo</span>():\n    <span class=\"pl-k\">pass</span></pre></div>\n\
    <h4><a id=\"user-content-context-manager\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#context-manager\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Context Manager</h4>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">timemory</span>.<span class=\"pl-s1\">profiler</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-s1\">profile</span>\n\n<span class=\"pl-k\">def</span>\
    \ <span class=\"pl-en\">bar</span>():\n    <span class=\"pl-k\">with</span> <span\
    \ class=\"pl-en\">profile</span>([<span class=\"pl-s\">\"wall_clock\"</span>,\
    \ <span class=\"pl-s\">\"cpu_util\"</span>]):\n        <span class=\"pl-en\">foo</span>()</pre></div>\n\
    <h4><a id=\"user-content-individual-components\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#individual-components\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Individual Components</h4>\n<div class=\"\
    highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span\
    \ class=\"pl-s1\">timemory</span>.<span class=\"pl-s1\">component</span> <span\
    \ class=\"pl-k\">import</span> <span class=\"pl-v\">WallClock</span>\n\n<span\
    \ class=\"pl-k\">def</span> <span class=\"pl-en\">spam</span>():\n\n    <span\
    \ class=\"pl-s1\">wc</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\"\
    >WallClock</span>(<span class=\"pl-s\">\"spam\"</span>)\n    <span class=\"pl-s1\"\
    >wc</span>.<span class=\"pl-en\">start</span>()\n\n    <span class=\"pl-en\">bar</span>()\n\
    \n    <span class=\"pl-s1\">wc</span>.<span class=\"pl-en\">stop</span>()\n  \
    \  <span class=\"pl-s1\">data</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">wc</span>.<span class=\"pl-en\">get</span>()\n    <span class=\"pl-en\"\
    >print</span>(<span class=\"pl-s1\">data</span>)</pre></div>\n<h4><a id=\"user-content-argparse-support\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#argparse-support\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Argparse\
    \ Support</h4>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"\
    pl-k\">import</span> <span class=\"pl-s1\">argparse</span>\n\n<span class=\"pl-s1\"\
    >parser</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">argparse</span>.<span\
    \ class=\"pl-v\">ArgumentParser</span>(<span class=\"pl-s\">\"example\"</span>)\n\
    <span class=\"pl-c\"># ...</span>\n<span class=\"pl-s1\">timemory</span>.<span\
    \ class=\"pl-en\">add_arguments</span>(<span class=\"pl-s1\">parser</span>)\n\n\
    <span class=\"pl-s1\">args</span> <span class=\"pl-c1\">=</span> <span class=\"\
    pl-s1\">parser</span>.<span class=\"pl-en\">parse_args</span>()</pre></div>\n\
    <h4><a id=\"user-content-component-storage\" class=\"anchor\" aria-hidden=\"true\"\
    \ tabindex=\"-1\" href=\"#component-storage\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Component Storage</h4>\n<div class=\"highlight\
    \ highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"\
    pl-s1\">timemory</span>.<span class=\"pl-s1\">storage</span> <span class=\"pl-k\"\
    >import</span> <span class=\"pl-v\">WallClockStorage</span>\n\n<span class=\"\
    pl-c\"># data for current rank</span>\n<span class=\"pl-s1\">data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">get</span>()\n<span class=\"pl-c\"># combined data on rank zero\
    \ but all ranks must call it</span>\n<span class=\"pl-s1\">dmp_data</span> <span\
    \ class=\"pl-c1\">=</span> <span class=\"pl-v\">WallClockStorage</span>.<span\
    \ class=\"pl-en\">dmp_get</span>()</pre></div>\n<h2><a id=\"user-content-versioning\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#versioning\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Versioning</h2>\n\
    <p>Timemory originated as a very simple tool for recording timing and memory measurements\
    \ (hence the name) in C, C++, and Python and only supported\nthree modes prior\
    \ to the 3.0.0 release: a fixed set of timers, a pair of memory measurements,\
    \ and the combination of the two.\n<strong>Prior to the 3.0.0 release, timemory\
    \ was almost completely rewritten from scratch</strong> with the sole exceptions\
    \ of some C/C++ macro, e.g.\n<code>TIMEMORY_AUTO_TIMER</code>, and some Python\
    \ decorators and context-manager, e.g. <code>timemory.util.auto_timer</code>,\
    \ whose behavior were\nable to be fully replicated in the new release. Thus, while\
    \ it may appear that timemory is a mature project at v3.0+, it\nis essentially\
    \ still in it's first major release.</p>\n<h2><a id=\"user-content-citing-timemory\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#citing-timemory\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citing timemory</h2>\n\
    <p>To reference timemory in a publication, please cite the following paper:</p>\n\
    <ul>\n<li>Madsen, J.R. et al. (2020) Timemory: Modular Performance Analysis for\
    \ HPC. In: Sadayappan P., Chamberlain B., Juckeland G., Ltaief H. (eds) High Performance\
    \ Computing. ISC High Performance 2020. Lecture Notes in Computer Science, vol\
    \ 12151. Springer, Cham</li>\n</ul>\n<h2><a id=\"user-content-additional-information\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#additional-information\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Additional\
    \ Information</h2>\n<p>For more information, refer to the <a href=\"https://timemory.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">documentation</a>.</p>\n"
  stargazers_count: 325
  subscribers_count: 17
  topics:
  - python
  - cpp
  - cplusplus
  - performance
  - c
  - cross-platform
  - cross-language
  - memory-measurements
  - mpi
  - cuda
  - papi
  - hardware-counters
  - analysis
  - roofline
  - performance-measurement
  - instrumentation-api
  - gotcha
  - cupti
  - modular-design
  updated_at: 1693444259.0
NOAA-EMC/GSI:
  data_format: 2
  description: Gridpoint Statistical Interpolation
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/GSI
  latest_release: gefs_v12.0.2
  stargazers_count: 46
  subscribers_count: 21
  topics: []
  updated_at: 1691464170.0
NOAA-EMC/UPP:
  data_format: 2
  description: null
  filenames:
  - ci/spack.yaml
  full_name: NOAA-EMC/UPP
  latest_release: upp-srw-v2.1.0
  readme: '<h1><a id="user-content-unified-post-processing-upp" class="anchor" aria-hidden="true"
    tabindex="-1" href="#unified-post-processing-upp"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Unified Post-Processing (UPP)</h1>

    <p>The Unified Post Processor (UPP) software package is a software

    package designed to generate useful products from raw model

    output.</p>

    <p>The UPP is currently used in operations with the Global Forecast

    System (GFS), GFS Ensemble Forecast System (GEFS), North American

    Mesoscale (NAM), Rapid Refresh (RAP), High Resolution Rapid Refresh

    (HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)

    applications. It is also used in the Unified Forecasting System (UFS),

    including the Rapid Refresh Forecast System (RRFS), Hurricane Application

    Forecasting System (HAFS), and the Medium Range Weather (MRW) and Short

    Range Weather (SRW) Applications.</p>

    <p>The UPP provides the capability to compute a variety of diagnostic

    fields and interpolate to pressure levels or other vertical

    coordinates.</p>

    <p>UPP also incorporates the Joint Center for Satellite Data Assimilation

    (JCSDA) Community Radiative Transfer Model (CRTM) to compute model

    derived brightness temperature (TB) for various instruments and

    channels. This additional feature enables the generation of a number

    of simulated satellite products including GOES products.</p>

    <p>Output from the UPP is in National Weather Service (NWS) and World

    Meteorological Organization (WMO) GRIB2 format and can be used

    directly by visualization, plotting, or verification packages, or for

    further downstream post-processing, e.g. statistical post-processing

    techniques.</p>

    <p>Examples of UPP products include:</p>

    <ul>

    <li>T, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels</li>

    <li>SLP, shelter level T, humidity, and wind fields</li>

    <li>Precipitation-related fields</li>

    <li>PBL-related fields</li>

    <li>Severe weather products (e.g. CAPE, Vorticity, Wind shear)</li>

    <li>Radiative/Surface fluxes</li>

    <li>Cloud related fields</li>

    <li>Aviation products</li>

    <li>Radar reflectivity products</li>

    <li>Satellite look-alike products</li>

    </ul>

    <h2><a id="user-content-user-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#user-support"><span aria-hidden="true" class="octicon octicon-link"></span></a>User
    Support</h2>

    <p>Support for the UFS UPP is provided through <a href="https://github.com/NOAA-EMC/UPP/discussions">GitHub
    Discussions</a>.</p>

    <h2><a id="user-content-documentation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#documentation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

    <p>User Guide for latest public release: <a href="https://upp.readthedocs.io/en/latest/"
    rel="nofollow">https://upp.readthedocs.io/en/latest/</a>.</p>

    <p>Technical code-level documentation: <a href="https://noaa-emc.github.io/UPP/"
    rel="nofollow">https://noaa-emc.github.io/UPP/</a>.</p>

    <h2><a id="user-content-developer-information" class="anchor" aria-hidden="true"
    tabindex="-1" href="#developer-information"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Developer Information</h2>

    <p>Please see review the <a href="https://github.com/NOAA-EMC/UPP/wiki">wiki</a></p>

    <h2><a id="user-content-authors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#authors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h2>

    <p>NCEP/EMC Developers</p>

    <p>Code Managers: Wen Meng, Huiya Chuang, Kate Fossell</p>

    <h2><a id="user-content-prerequisites" class="anchor" aria-hidden="true" tabindex="-1"
    href="#prerequisites"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

    <p>The UPP requires certain NCEPLIBS packages to be installed via the

    HPC-Stack project. For instructions on installing these packages as a

    bundle via HPC-Stack, see: <a href="https://hpc-stack.readthedocs.io/en/latest/"
    rel="nofollow">https://hpc-stack.readthedocs.io/en/latest/</a>.

    Users may instead install packages via spack-stack. For instructions,

    see: <a href="https://spack-stack.readthedocs.io/en/latest/" rel="nofollow">https://spack-stack.readthedocs.io/en/latest/</a>.

    The <code>UPP/modulefiles</code> directory indicates which package versions are

    used and supported on Level 1 systems.</p>

    <p>Required NCEPLIBS packages:</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2">NCEPLIBS-g2</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl">NCEPLIBS-g2tmpl</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sp">NCEPLIBS-sp</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-ip">NCEPLIBS-ip</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-bacio">NCEPLIBS-bacio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-w3emc">NCEPLIBS-w3emc</a></li>

    <li><a href="https://github.com/noaa-emc/emc_crtm">CRTM</a></li>

    </ul>

    <p>Also required to build NCEPpost executable (cmake option

    BUILD_POSTEXEC):</p>

    <ul>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sigio">NCEPLIBS-sigio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-sfcio">NCEPLIBS-sfcio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-nemsio">NCEPLIBS-nemsio</a></li>

    <li><a href="https://github.com/NOAA-EMC/NCEPLIBS-gfsio">NCEPLIBS-gfsio</a></li>

    </ul>

    <p>The <a href="https://github.com/NOAA-EMC/NCEPLIBS-wrf_io">NCEPLIBS-wrf_io</a>

    library is required to build with NCEPpost with WRF-IO library (cmake

    option BUILD_WITH_WRFIO).</p>

    <p>The following third-party libraries are required:</p>

    <ul>

    <li><a href="https://github.com/Unidata/netcdf">netcdf</a></li>

    <li><a href="https://github.com/Unidata/netcdf-c">netcdf-c</a></li>

    <li><a href="https://github.com/Unidata/netcdf-fortran">netcdf-fortran</a></li>

    <li><a href="https://github.com/jasper-software/jasper">Jasper</a></li>

    <li><a href="http://www.libpng.org/pub/png/libpng.html" rel="nofollow">libpng</a></li>

    <li><a href="https://zlib.net/" rel="nofollow">zlib</a></li>

    <li><a href="https://github.com/HDFGroup/hdf5">hdf5</a></li>

    </ul>

    <h2><a id="user-content-building" class="anchor" aria-hidden="true" tabindex="-1"
    href="#building"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building</h2>

    <p>Builds include:</p>

    <ul>

    <li>

    <p>Inline post (UPP library): Currently only supported for the GFS, RRFS,

    HAFS, and the UFS-MRW Application.</p>

    </li>

    <li>

    <p>Offline post (UPP executable): Supported for Regional applications

    including SRW, RRFS, HAFS, and standalone applications of UPP.</p>

    </li>

    </ul>

    <p>CMake is used to manage all builds of the UPP.

    The script <code>UPP/tests/compile_upp.sh</code> can be used to automatically

    build UPP on fully supported platforms where HPC-stack is supported.

    Details in this script can be used to build on new platforms.</p>

    <h2><a id="user-content-disclaimer" class="anchor" aria-hidden="true" tabindex="-1"
    href="#disclaimer"><span aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an "as is" basis and the user assumes responsibility for

    its use. DOC has relinquished control of the information and no longer

    has responsibility to protect the integrity, confidentiality, or

    availability of the information. Any claims against the Department of

    Commerce stemming from the use of its GitHub project will be governed

    by all applicable Federal law. Any reference to specific commercial

    products, processes, or services by service mark, trademark,

    manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of

    Commerce. The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <h2><a id="user-content-upp-terms-of-use-notice" class="anchor" aria-hidden="true"
    tabindex="-1" href="#upp-terms-of-use-notice"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>UPP Terms of Use Notice</h2>

    <p>The UPP Terms of Use Notice is available at: <a href="https://github.com/NOAA-EMC/UPP/wiki/UPP-Terms-of-Use-Notice">https://github.com/NOAA-EMC/UPP/wiki/UPP-Terms-of-Use-Notice</a></p>

    '
  stargazers_count: 25
  subscribers_count: 14
  topics: []
  updated_at: 1693057566.0
PawseySC/pawsey-spack-config:
  data_format: 2
  description: Automated deployment system for the scientific software stack in use
    at Pawsey
  filenames:
  - systems/setonix/environments/astro/spack.yaml
  - systems/setonix/environments/num_libs/spack.yaml
  - systems/setonix/environments/wrf/spack.yaml
  - systems/setonix/environments/bench/spack.yaml
  full_name: PawseySC/pawsey-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-pawsey-spack-configuration" class="anchor" aria-hidden="true"
    tabindex="-1" href="#pawsey-spack-configuration"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Pawsey Spack Configuration</h1>

    <p>Scripts and configuration files used by the Pawsey Supercomputing Research
    Centre to deploy Spack and to install the scientific software stack on its supercomputing
    systems.</p>

    <h2><a id="user-content-installation" class="anchor" aria-hidden="true" tabindex="-1"
    href="#installation"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>Here is how to launch the software stack installation.</p>

    <ol>

    <li>Make sure the system you want to install the software stack on has a corresponding
    directory in <code>systems</code>. If not, you can start by creating a copy of
    an existing one.</li>

    <li>Edit the file <code>systems/&lt;system&gt;/settings.sh</code> as needed.</li>

    <li>Set and export the <code>INSTALL_PREFIX</code> variable to the full path of
    the filesystem location where you want the installation to be placed in. Note
    that it has to end with the same string as the one stored in the <code>DATE_TAG</code>
    variable, meaning that installations are versioned by installation date.</li>

    <li>Set and export the <code>INSTALL_GROUP</code> variable to the linux group
    that is going to own the installed files.</li>

    <li>Set and export the <code>SYSTEM</code> variable to the system you want to
    run the installation for, if it differs from the content of the <code>PAWSEY_CLUSTER</code>
    environment variable.</li>

    <li>Run the <code>scripts/install_software_stack.sh</code> script, preferably
    in a Slurm job or as a process detached from the login shell to prevent the installation
    from being aborted in case the SSH connection were to be interrupted unexpectedly.</li>

    </ol>

    <h3><a id="user-content-singularity" class="anchor" aria-hidden="true" tabindex="-1"
    href="#singularity"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h3>

    <p>You will need to ask the platforms team to apply root permissions to Singularity
    ss soon as it is installed. The script to run as root is found in the <code>bin</code>
    directory within the spack installation prefix.</p>

    <h3><a id="user-content-software-stack-modulefile" class="anchor" aria-hidden="true"
    tabindex="-1" href="#software-stack-modulefile"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Software stack modulefile</h3>

    <p>The platforms team will need to install the <code>$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua</code>
    module such that it will be loaded before the Cray compilers. They will also need
    to update user account creation process, following the updated <code>$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh</code>.</p>

    <h2><a id="user-content-repository-structure" class="anchor" aria-hidden="true"
    tabindex="-1" href="#repository-structure"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Repository structure</h2>

    <p>The repository is composed of the directories:</p>

    <ul>

    <li>

    <code>fixes/</code>: patches implemented by Pawsey staff to be applied to Spack
    prior to production use. They are meant to improve usability of Spack for Pawsey-specific
    use cases.</li>

    <li>

    <code>repo/</code>: custom Spack package recipes for software not yet supported
    by Spack or that needed modification in the build process to work on Pawsey systems.</li>

    <li>

    <code>shpc_registry/</code>: custom Singularity-HPC (SHPC) recipes to deploy containers.</li>

    <li>

    <code>scripts/</code>: BASH scripts used to automate the deployment process.</li>

    <li>

    <code>systems/&lt;system&gt;</code>: a directory containing configuration files
    specific to a system. Scripts will use these files to customise the Spack deployment
    and installation of the software stack.</li>

    </ul>

    <p>The <code>scripts/install_software_stack.sh</code> is the top-level script
    that executes the installation from start to finish except licensed software,
    that need some manual work. Refer to this script also as documentation of the
    installation process.</p>

    <h2><a id="user-content-the-scripts-directory" class="anchor" aria-hidden="true"
    tabindex="-1" href="#the-scripts-directory"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>The <code>scripts</code> directory</h2>

    <p>This project makes up a build system for the scientific software stack on Pawsey
    supercomputers. On a high level, there are two logical compontents to it:

    one to deploy Spack and SHPC (a software package to manage containers), and the
    other to use the tools mentioned before to install scientific software.</p>

    <p>The deployment of Spack and SHPC is implemented through the following executables
    BASH scripts within the <code>scripts</code> directory:</p>

    <ul>

    <li>

    <code>install_spack.sh</code> installs Spack on the system and creates the directory
    structure for the system-wide software stack installation.</li>

    <li>

    <code>install_python.sh</code> installs Python using Spack. To do so, and only
    in this case, Spack chooses <code>cray-python</code> as interpreter. Once Python
    is installed for different architectures and versions, <code>cray-python</code>
    won''t be used anymore.</li>

    <li>

    <code>install_shpc.sh</code> installs SHPC, a tool used to deploy containers.</li>

    </ul>

    <p>The software stack deployment is implemented in these scripts instead:</p>

    <ul>

    <li>

    <code>concretize_environments.sh</code> runs the concretization step for all Spack
    environments to be installed.</li>

    <li>

    <code>install_environments.sh</code> will install all Spack environments using
    Spack.</li>

    <li>

    <code>install_shpc_containers.sh</code> will pull Pawsey-supported containers
    and install them using SHPC.</li>

    <li>

    <code>post_installation_operations.sh</code> refreshes Lmod modulefiles for the
    installed software, applies permissions to licensed software, and other operations
    needed after the full stack deployment executed by Spack.</li>

    </ul>

    <h2><a id="user-content-the-systemssystem-directory" class="anchor" aria-hidden="true"
    tabindex="-1" href="#the-systemssystem-directory"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>The <code>systems/&lt;system&gt;</code> directory</h2>

    <p>This is where system specific configurations are placed. In particular, the
    following items must always be present.</p>

    <ul>

    <li>

    <code>configs/</code> is a directory containing <code>yaml</code> configuraiton
    files for Spack. There are three types of configuration:

    <ul>

    <li>

    <code>site/</code>: Spack configuration files that are valid for all users, which
    will sit in <code>$spack/etc/spack</code>.</li>

    <li>

    <code>project/</code>: Spack configuration files that are valid for project-wide
    installations executed by any user using the dedicated script <code>spack_project.sh</code>.</li>

    <li>

    <code>spackuser/</code>: Spack configuration files for system-wide installs, performed
    by Pawsey staff, which will sit in <code>/home/spack/.spack/</code>, allowing
    the <code>spack</code> user to override system-wide settings.</li>

    </ul>

    </li>

    <li>

    <code>environments/</code>: Spack environments to be deployed.</li>

    <li>

    <code>templates/</code>: modulefile templates for Spack.</li>

    </ul>

    <h2><a id="user-content-notes" class="anchor" aria-hidden="true" tabindex="-1"
    href="#notes"><span aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h2>

    <h3><a id="user-content-module-categories-in-use" class="anchor" aria-hidden="true"
    tabindex="-1" href="#module-categories-in-use"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Module categories in use</h3>

    <ul>

    <li>Spack (with compiler/arch tree)

    <ul>

    <li>

    <strong>NOTE</strong>: if updating list, still need to manually update <code>templates/modules/modulefile.lua</code>

    </li>

    <li><code>astro-applications</code></li>

    <li><code>bio-applications</code></li>

    <li><code>applications</code></li>

    <li><code>libraries</code></li>

    <li><code>programming-languages</code></li>

    <li><code>utilities</code></li>

    <li><code>visualisation</code></li>

    <li><code>python-packages</code></li>

    <li><code>benchmarking</code></li>

    <li><code>developer-tools</code></li>

    <li><code>dependencies</code></li>

    </ul>

    </li>

    <li>Pawsey custom builds (with compiler/arch tree)

    <ul>

    <li><code>custom/modules</code></li>

    </ul>

    </li>

    <li>Pawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)

    <ul>

    <li><code>pawsey/modules</code></li>

    </ul>

    </li>

    <li>SHPC containers modules (without compiler/arch tree)

    <ul>

    <li><code>containers/modules</code></li>

    </ul>

    </li>

    </ul>

    <h3><a id="user-content-testing-modules" class="anchor" aria-hidden="true" tabindex="-1"
    href="#testing-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a>Testing
    Modules</h3>

    <p>Current <code>modules.yaml</code> and the template <code>modulefile.lua</code>
    rely on additional features of Spack found in the feature/improved-lmod-modules
    (<a href="https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules">https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules</a>).<br>

    The update provides extra tokens that can be used when creating the module name
    and also extra keywords to the template.<br>

    These features have now been packaged in a patch, that is applied by <code>install_spack.sh</code>.</p>

    '
  stargazers_count: 0
  subscribers_count: 11
  topics: []
  updated_at: 1687655533.0
SCOREC/dcs-spack-config:
  data_format: 2
  description: Spack config for CCI DCS (AiMOS) system
  filenames:
  - spack.yaml
  - rhel8NvhpcWdmapp/spack.yaml
  full_name: SCOREC/dcs-spack-config
  latest_release: null
  readme: '<h1><a id="user-content-dcs-spack-config" class="anchor" aria-hidden="true"
    tabindex="-1" href="#dcs-spack-config"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>dcs-spack-config</h1>

    <p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies

    with the IBM XL compilers and Spectrum-MPI.</p>

    <h2><a id="user-content-contents" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contents"><span aria-hidden="true" class="octicon octicon-link"></span></a>contents</h2>

    <p>compilers.yaml - compiler list</p>

    <p>config.yaml - global config</p>

    <p>install.sh - package installation commands</p>

    <p>modules.yaml - hierarchical layout for lua modules</p>

    <p>packages.yaml - system installed packages</p>

    <p>README.md - this file</p>

    <p>setupSpack.sh - env needed for executing spack commands</p>

    <p>spack.yaml - list of packages to install</p>

    <h2><a id="user-content-setup" class="anchor" aria-hidden="true" tabindex="-1"
    href="#setup"><span aria-hidden="true" class="octicon octicon-link"></span></a>setup</h2>

    <pre><code>git clone git@github.com:spack/spack.git spack

    cd !$

    git checkout v0.13.3

    # add the simmetrix-simmodsuite package from the develop branch

    git cherry-pick 5ddf5e2

    # create the environment

    spack env create v0133

    spack env activate v0133

    # copy the yaml files into the v0133

    cp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.

    # copy the compiler yaml file into the spack etc dir

    cp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.

    </code></pre>

    <h2><a id="user-content-install-cmake" class="anchor" aria-hidden="true" tabindex="-1"
    href="#install-cmake"><span aria-hidden="true" class="octicon octicon-link"></span></a>install
    cmake</h2>

    <p>The bootstrap step of the cmake install fails with the XL compilers.  I

    installed it manually outside of the environment with spack and gcc4.8.5</p>

    <pre><code>spack install cmake%gcc@4.8.5_rhel7

    </code></pre>

    <p>Then added the path to <code>packages.yaml</code>.</p>

    <h2><a id="user-content-resuming-work-in-an-environment" class="anchor" aria-hidden="true"
    tabindex="-1" href="#resuming-work-in-an-environment"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>resuming work in an environment</h2>

    <pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh

    spack env activate v0133

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1633029356.0
UO-OACISS/e4s:
  data_format: 2
  description: E4S Spack environments and container recipes
  filenames:
  - docker-recipes/runner/ubuntu20.04-amd64-clang-16/spack.yaml
  - docker-recipes/runner/archived/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/runner/archived/ubuntu20.04-x86_64-gcc-11.2/spack.yaml
  - docker-recipes/runner/ubuntu20.04-amd64-gcc-11.4/spack.yaml
  - docker-recipes/runner/ubuntu20.04-amd64-gcc-12.3/spack.yaml
  - docker-recipes/runner/ubuntu20.04-amd64-oneapi/spack.yaml
  - docker-recipes/runner/ubuntu20.04-ppc64le-gcc-12.3/spack.yaml
  - docker-recipes/runner/archived/rhel8-ppc64le/spack.yaml
  - docker-recipes/archived/special/superlu-sc/spack.yaml
  - docker-recipes/archived/minimal/ubuntu22.04-ppc64le/spack.yaml
  - docker-recipes/archived/rhel7-runner-x86_64/spack.yaml
  - docker-recipes/minimal/ubuntu20.04-aarch64/spack.yaml
  - docker-recipes/runner/archived/ubuntu18.04-ppc64le/spack.yaml
  - docker-recipes/runner/archived/ubuntu20.04-x86_64-gcc-11.4-spack/spack.yaml
  - docker-recipes/runner/ubuntu20.04-ppc64le-gcc-11.4/spack.yaml
  full_name: UO-OACISS/e4s
  latest_release: null
  readme: '<p>This is a collection of configurations for building ECP SDK

    containers with combinations of packages, including the full

    E4S set.</p>

    <p>These are the set of stacks that are targeted for the first release:</p>

    <p><a target="_blank" rel="noopener noreferrer" href="figures/SDKdefinition1.png"><img
    src="figures/SDKdefinition1.png" alt="SDK definitions" style="max-width: 100%;"></a></p>

    <p>The configuration files for each container platform will be specified under
    each directory.  For example, the Docker configurations are under the "docker"
    subdirectory.  Each subdirectory will have a README.md file to explain how to
    build the container image for each stack.</p>

    '
  stargazers_count: 20
  subscribers_count: 7
  topics: []
  updated_at: 1687655805.0
boutproject/BOUT-configs:
  data_format: 2
  description: Configuration scripts for BOUT++
  filenames:
  - lassen/spack_env/bout/spack.yaml
  - lassen/spack_env/bout_petsc_with_hypre/spack.yaml
  full_name: boutproject/BOUT-configs
  latest_release: null
  readme: '<h1><a id="user-content-configuration-scripts" class="anchor" aria-hidden="true"
    tabindex="-1" href="#configuration-scripts"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Configuration scripts</h1>

    <p>The CMake and autotools (configure/make) scripts supplied with BOUT++

    should be able to automatically find and configure BOUT++ in most

    cases. Where a complex configuration is desired, for example including

    many dependencies (esp. complex dependencies like PETSc), or compiling

    for GPUs, configuration can be quite complex.</p>

    <p>The files in this directory are intended to be convenient shortcuts for

    configuration on particular machines. Where there are many scripts, these

    are put into sub-directories (e.g. "cori" and "lassen").</p>

    <h2><a id="user-content-environment" class="anchor" aria-hidden="true" tabindex="-1"
    href="#environment"><span aria-hidden="true" class="octicon octicon-link"></span></a>Environment</h2>

    <p>Scripts which set up the environment, for example loading and unloading

    modules, start with <code>setup</code> or <code>setup-env</code>. These are typically
    modifying

    shell environments and so should be invoked with <code>source</code>.</p>

    <h2><a id="user-content-bout-configuration" class="anchor" aria-hidden="true"
    tabindex="-1" href="#bout-configuration"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>BOUT++ configuration</h2>

    <p>The wrappers around CMake (or configure) start with <code>config</code> or
    <code>config-bout</code>.

    These are shell scripts which can be run without <code>source</code>.</p>

    '
  stargazers_count: 1
  subscribers_count: 17
  topics: []
  updated_at: 1686816130.0
camierjs/okina-jit:
  data_format: 2
  description: null
  filenames:
  - config/docker/spack.yaml
  full_name: camierjs/okina-jit
  latest_release: null
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed\
    \ under the terms of the BSD-3 license. All new contributions\nmust be made under\
    \ this license. See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>\
    \ for\ndetails.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release\
    \ Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1689268998.0
dbkinghorn/Benchmark-Containers:
  data_format: 2
  description: Dockerfile and Spack spec files for hardware optimized benchmark containers
  filenames:
  - quantum-espresso-amd/spack.yaml
  - hpl-amd/spack.yaml
  - hpcg-amd/spack.yaml
  - wrf-amd/spack.yaml
  - hmmer-amd/spack.yaml
  full_name: dbkinghorn/Benchmark-Containers
  latest_release: null
  readme: '<h1><a id="user-content-benchmark-containers" class="anchor" aria-hidden="true"
    tabindex="-1" href="#benchmark-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Benchmark Containers</h1>

    <p>This is a collection of container spec files used to build the images available
    on <a href="https://hub.docker.com/orgs/pugetsystems/repositories" rel="nofollow">https://hub.docker.com/orgs/pugetsystems/repositories</a></p>

    <p>Most of these images are based on performance optimized application builds
    for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.</p>

    <p>These container images are the basis for some of our Scientific and Machine
    Learning benchmarks at <a href="pugetsystems.com">Puget Systems</a>.</p>

    <p>Files for each application include,</p>

    <ul>

    <li>Spack spec.yaml (build specifications with targeted optimizations)</li>

    <li>Dockerfiles (Multi-stage build/install)</li>

    <li>*Enroot container-bundle (self running) build scripts</li>

    <li>Benchmarks</li>

    <li>Usage notes</li>

    </ul>

    <p>* Enroot container bundles are self-running containers. No container runtime
    (docker) install is needed. These ".run" files are generally too large to be hosted
    on GitHub. Download locations will be provided at a later time.</p>

    '
  stargazers_count: 1
  subscribers_count: 2
  topics: []
  updated_at: 1676846633.0
eth-cscs/spack-stack:
  data_format: 2
  description: fast spack builds on slow filesystem
  filenames:
  - packages/nvhpc/spack.yaml
  - recipe/nvhpc.spack.yaml
  - compilers/3-llvm/spack.yaml
  full_name: eth-cscs/spack-stack
  latest_release: null
  stargazers_count: 2
  subscribers_count: 4
  topics: []
  updated_at: 1684144105.0
fnalacceleratormodeling/synergia2-containers:
  data_format: 2
  description: null
  filenames:
  - cuda-11/spack.yaml
  - ubuntu-gcc/spack.yaml
  full_name: fnalacceleratormodeling/synergia2-containers
  latest_release: null
  readme: '<h1><a id="user-content-synergia2-containers" class="anchor" aria-hidden="true"
    tabindex="-1" href="#synergia2-containers"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>synergia2-containers</h1>

    <p>This repository contains docker recipes for building containers that contain
    all dependencies for synergia2. These recipes are generated using <a href="https://spack.readthedocs.io/en/latest/environments.html"
    rel="nofollow">spack environments</a> via <a href="https://spack.readthedocs.io/en/latest/containers.html"
    rel="nofollow"><code>spack containerize</code></a>, with some minor modifications.
    GithubActions is used to build these containers for <code>x86_64_v2</code> ISA
    and these containers can be pulled from the github container registry. For instructions
    on how to pull a particular image, visit the page associated with it <a href="https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers">here</a>.</p>

    <p>These containers are used as test environments for testing synergia2 via GithubActions.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1678463172.0
giordano/julia-on-fugaku:
  data_format: 2
  description: null
  filenames:
  - benchmarks/blas-axpy/spack-env/spack.yaml
  full_name: giordano/julia-on-fugaku
  latest_release: null
  readme: "<h1><a id=\"user-content-julia-on-fugaku-2022-07-23\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#julia-on-fugaku-2022-07-23\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Julia on Fugaku\
    \ (2022-07-23)</h1>\n<p><em>Note: many links refer to internal documentation which\
    \ is accessible only to Fugaku users.</em></p>\n<h2><a id=\"user-content-read-the-paper\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#read-the-paper\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Read the\
    \ paper</h2>\n<p>Benchmarks present in this repository have been published in\
    \ the paper <a href=\"https://doi.org/10.1109/CLUSTER51413.2022.00072\" rel=\"\
    nofollow\">Productivity meets\nPerformance: Julia on A64FX</a>, presented at\n\
    the 2022 IEEE International Conference on Cluster Computing (CLUSTER22), as part\
    \ of the\n<a href=\"https://arm-hpc-user-group.github.io/eahpc-2022/\" rel=\"\
    nofollow\">Embracing Arm for High Performance Computing\nWorkshop</a> (pre-print\
    \ available on arXiv:\n<a href=\"https://arxiv.org/abs/2207.12762\" rel=\"nofollow\"\
    ><code>2207.12762</code></a>).  See the <a href=\"./CITATION.bib\"><code>CITATION.bib</code></a>\n\
    file for a BibTeX entry to cite the paper.</p>\n<h2><a id=\"user-content-storage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#storage\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Storage</h2>\n\
    <p>Before doing anything on Fugaku, be aware that there are <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20220408_01\"\
    \ rel=\"nofollow\">tight\nlimits</a> on the size of (20 GiB)\nand the number of\
    \ inodes in (200k) your home directory.  If you use many Julia Pkg\nartifacts,\
    \ it's very likely you'll hit these limits.  You'll notice that you hit the limit\n\
    because any disk I/O operation will result in a <code>Disk quota exceeded</code>\
    \ error like this:</p>\n<div class=\"highlight highlight-text-shell-session\"\
    ><pre><span class=\"pl-e\">[user@fn01sv03 ~]</span>$ <span class=\"pl-s1\">touch\
    \ foo</span>\n<span class=\"pl-c1\">touch: cannot touch 'foo': Disk quota exceeded</span></pre></div>\n\
    <p>You can check the quota of your home directory with <code>accountd</code> for\
    \ the size, and <code>accountd -i</code> for the number of inodes.</p>\n<h3><a\
    \ id=\"user-content-using-the-data-directory\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#using-the-data-directory\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using the data directory</h3>\n\
    <p>In order to avoid clogging up the home directory you may want to move the Julia\
    \ depot to the\ndata directory:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>DATADIR=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/data/&lt;YOUR\
    \ GROUP&gt;/<span class=\"pl-smi\">${USER}</span><span class=\"pl-pds\">\"</span></span>\n\
    <span class=\"pl-k\">export</span> JULIA_DEPOT_PATH=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">\"</span><span class=\"pl-smi\">${DATADIR}</span>/julia-depot<span\
    \ class=\"pl-pds\">\"</span></span></pre></div>\n<h2><a id=\"user-content-interactive-usage\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#interactive-usage\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Interactive\
    \ usage</h2>\n<p>The login nodes you access via <code>login.fugaku.r-ccs.riken.jp</code>\
    \ (<a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/AccessToTheSystem/LoggingInToTheFugakuComputerWithLocalAccount.html\"\
    \ rel=\"nofollow\">connection\ninstructions</a>)\nhave Cascade Lake CPUs, so they\
    \ aren't much useful if you want to run an aarch64 Julia.</p>\n<p>You can <a href=\"\
    https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/Overview.html\"\
    \ rel=\"nofollow\">submit jobs to the\nqueue</a>\nto run Julia code on the A64FX\
    \ compute nodes, but this can be cumbersone if you need quick\nfeedback during\
    \ development or debugging.  You can also request an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/InteractiveJob.html\"\
    \ rel=\"nofollow\">interactive\nnode</a>,\nfor example with:</p>\n<pre><code>pjsub\
    \ --interact -L \"node=1\" -L \"rscgrp=int\" -L \"elapse=30:00\" --sparam \"wait-time=600\"\
    \ --mpi \"max-proc-per-node=4\"\n</code></pre>\n<h2><a id=\"user-content-available-software\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#available-software\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Available\
    \ software</h2>\n<p>Fugaku uses the <a href=\"https://spack.io/\" rel=\"nofollow\"\
    >Spack package manager</a>.  For more information about how\nto use it, see the\
    \ <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/FugakuSpackGuide/\"\
    \ rel=\"nofollow\">Fugaku Spack User\nGuide</a>.</p>\n<p>Note that Spack is installed\
    \ in <code>/vol0004</code>, this means that if your home directory isn't\nmounted\
    \ on this volume you will have to <a href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20211130_02\"\
    \ rel=\"nofollow\">explicitly request the\npartition</a> in your submission\n\
    job scripts or commands, for example by adding <code>-x PJM_LLIO_GFSCACHE=/vol0004</code>\
    \ to the\n<code>pjsub</code> command, or the line</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>PJM\
    \ -x PJM_LLIO_GFSCACHE=/vol0004</span></pre></div>\n<p>in a job script.</p>\n\
    <h2><a id=\"user-content-using-julia-on-the-compute-nodes\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#using-julia-on-the-compute-nodes\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Using Julia on the compute nodes</h2>\n\
    <p>There is a Julia module built with Spack <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/UsingOSS/oss_e.html#packages-installed-on-the-compute-nodes\"\
    \ rel=\"nofollow\">available on the compute\nnodes</a>,\nbut as of this writing\
    \ (2022-07-23) the version of Julia provided is 1.6.3, so you may want\nto download\
    \ a more recent version from the <a href=\"https://julialang.org/downloads/\"\
    \ rel=\"nofollow\">official\nwebsite</a>.  Use the <code>aarch64</code> builds\
    \ for Glibc Linux,\npreferably <a href=\"https://julialang.org/downloads/#current_stable_release\"\
    \ rel=\"nofollow\">latest stable</a> or even\nthe <a href=\"https://julialang.org/downloads/nightlies/\"\
    \ rel=\"nofollow\">nightly build</a> if you feel confident.</p>\n<p>To enable\
    \ full vectorisation you may need to set the environment variable\n<code>JULIA_LLVM_ARGS=\"\
    -aarch64-sve-vector-bits-min=512\"</code>.  Example:\n<a href=\"https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\"\
    >https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623</a>. \
    \ However, note that\nare a couple of severe bugs when using 512-bit vectors:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/JuliaLang/julia/issues/44401\">https://github.com/JuliaLang/julia/issues/44401</a>\
    \ (may be an upstream LLVM bug:\n<a href=\"https://github.com/llvm/llvm-project/issues/53331\"\
    >https://github.com/llvm/llvm-project/issues/53331</a>)</li>\n<li>\n<a href=\"\
    https://github.com/JuliaLang/julia/issues/44263\">https://github.com/JuliaLang/julia/issues/44263</a>\
    \ (only in Julia v1.8+)</li>\n</ul>\n<p><em><strong>Note</strong></em>: Julia\
    \ v1.9, which is based on <a href=\"https://community.arm.com/arm-community-blogs/b/tools-software-ides-blog/posts/llvm-14\"\
    \ rel=\"nofollow\">LLVM\n14</a>,\nis able to natively autovectorise code for A64FX\
    \ <em>without</em> having to set\n<code>JULIA_LLVM_ARGS</code>, side stepping\
    \ the issues above altogether.</p>\n<h2><a id=\"user-content-mpijl\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#mpijl\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>MPI.jl</h2>\n<p><a href=\"https://github.com/JuliaParallel/MPI.jl\"\
    ><code>MPI.jl</code></a> with default JLL-provided MPICH works\nout of the box!\
    \  In order to\n<a href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\"\
    \ rel=\"nofollow\">configure</a> <code>MPI.jl</code> v0.19 to\nuse system-provided\
    \ Fujitsu MPI (based on OpenMPI) you have to specify the <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/CompileCommands.html\"\
    \ rel=\"nofollow\">MPI C\ncompiler</a>\nfor A64FX with</p>\n<pre><code>julia --project\
    \ -e 'ENV[\"JULIA_MPI_BINARY\"]=\"system\"; ENV[\"JULIA_MPICC\"]=\"mpifcc\"; using\
    \ Pkg; Pkg.build(\"MPI\"; verbose=true)'\n</code></pre>\n<p><em><strong>Note #1</strong></em>:\
    \ <code>mpifcc</code> is available only on the compute nodes.  On the login nodes\
    \ that would be\n<code>mpifccpx</code>, but this is the cross compiler running\
    \ on Intel architecture, it's unlikely\nyou'll run an <code>aarch64</code> Julia\
    \ on there.  <a href=\"https://github.com/JuliaParallel/MPI.jl/issues/539\">Preliminary\n\
    tests</a> show that <code>MPI.jl</code> should work\nmostly fine with Fujitsu\
    \ MPI, but custom error handlers may not be available (read: trying\nto use them\
    \ causes segmentation faults).</p>\n<p><em><strong>Note #2</strong></em>: in <code>MPI.jl</code>\
    \ v0.20 Fujitsu MPI is a known ABI (it's the same as OpenMPI) and\nthere is nothing\
    \ special to do to configure it apart from <a href=\"https://juliaparallel.org/MPI.jl/dev/configuration/#Configuration-2\"\
    \ rel=\"nofollow\">choosing the system\nbinaries</a>.</p>\n<p><em><strong>Note\
    \ #3</strong></em>: we recommend using <code>MPI.jl</code>'s wrapper of <code>mpiexec</code>\
    \ to run MPI applications\nwith Julia:\n<a href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Julia-wrapper-for-mpiexec\"\
    \ rel=\"nofollow\"><code>mpiexecjl</code></a>.</p>\n<h3><a id=\"user-content-file-system-latency\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#file-system-latency\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>File system\
    \ latency</h3>\n<p>Fugaku has an advanced system to handle <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/index.html\"\
    \ rel=\"nofollow\">parallel file system\nlatency</a>.\nIn order.  In order to\
    \ speed up parallel applications run through MPI you may want to\ndistribute it\
    \ to the cache area of the second-layer storage on the first-layer storage using\n\
    <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/TheSecondLayerStrage.html#common-file-distribution-function-llio-transfer\"\
    \ rel=\"nofollow\"><code>llio_transfer</code></a>.\nIn particular, if you're using\
    \ Julia, you likely want to distribute the <code>julia</code> executable\nitself\
    \ together with its installation bundle.</p>\n<p>For example, assuming that you\
    \ are using the official binaries from the website, instead of\nthe Julia module\
    \ provided by Spack, you can do the following:</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Directory for log of\
    \ `llio_transfer` and its wrapper `dir_transfer`</span>\nLOGDIR=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${TMPDIR}</span>/log<span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Create the log directory if necessary</span>\nmkdir -p <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Get directory where Julia is placed</span>\nJL_BUNDLE=<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\"\
    >$(</span>dirname <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>julia --startup-file=no\
    \ -O0 --compile=min -e <span class=\"pl-s\"><span class=\"pl-pds\">'</span>print(Sys.BINDIR)<span\
    \ class=\"pl-pds\">'</span></span><span class=\"pl-pds\">)</span></span><span\
    \ class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span>\n\n\
    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Move Julia installation to\
    \ fast LLIO directory</span>\n/home/system/tool/dir_transfer -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Do not write\
    \ empty stdout/stderr files for MPI processes.</span>\n<span class=\"pl-k\">export</span>\
    \ PLE_MPI_STD_EMPTYFILE=off\n\nmpiexecjl --project=. -np ... julia ...\n\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Remove Julia installation directory\
    \ from the cache.</span>\n/home/system/tool/dir_transfer -p -l <span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${LOGDIR}</span><span\
    \ class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${JL_BUNDLE}</span><span class=\"pl-pds\">\"\
    </span></span></pre></div>\n<h2><a id=\"user-content-reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#reverse-engineering-fujitsu-compiler-using-llvm-output\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reverse\
    \ engineering Fujitsu compiler using LLVM output</h2>\n<p>The Fujitsu compiler\
    \ has <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/C/modeTradAndClangC.html\"\
    \ rel=\"nofollow\">two operation\nmodes</a>:\n\"trad\" (for \"traditional\") and\
    \ \"clang\" (enabled by the flag <code>-Nclang</code>).  In clang mode it's\n\
    based on LLVM (version 7 at the moment).  This means you can get it to emit LLVM\
    \ IR with\n<code>-emit-llvm</code>.  For example, with</p>\n<div class=\"highlight\
    \ highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\"\
    >echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>int main(){}<span\
    \ class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> fcc -Nclang -x\
    \ c - -S -emit-llvm -o -</span></pre></div>\n<p>you get</p>\n<div class=\"highlight\
    \ highlight-source-llvm\"><pre><span class=\"pl-c\">; ModuleID = '-'</span>\n\
    source_filename = <span class=\"pl-s\">\"-\"</span>\n<span class=\"pl-k\">target</span>\
    \ <span class=\"pl-k\">datalayout</span> = <span class=\"pl-s\">\"e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128\"\
    </span>\n<span class=\"pl-k\">target</span> <span class=\"pl-k\">triple</span>\
    \ = <span class=\"pl-s\">\"aarch64-unknown-linux-gnu\"</span>\n\n<span class=\"\
    pl-c\">; Function Attrs: norecurse nounwind readnone uwtable</span>\n<span class=\"\
    pl-k\">define</span> dso_local <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">@main</span>() <span class=\"pl-k\">local_unnamed_addr</span> #<span class=\"\
    pl-c1\">0</span> <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!8</span>\
    \ {\n  <span class=\"pl-k\">ret</span> <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">0</span>, <span class=\"pl-v\">!dbg</span> <span class=\"pl-v\">!11</span>\n\
    }\n\n<span class=\"pl-k\">attributes</span> #<span class=\"pl-c1\">0</span> =\
    \ { <span class=\"pl-k\">norecurse</span> <span class=\"pl-k\">nounwind</span>\
    \ <span class=\"pl-k\">readnone</span> <span class=\"pl-k\">uwtable</span> <span\
    \ class=\"pl-s\">\"correctly-rounded-divide-sqrt-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"disable-tail-calls\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"less-precise-fpmad\"\
    </span>=<span class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim\"\
    </span>=<span class=\"pl-s\">\"true\"</span> <span class=\"pl-s\">\"no-frame-pointer-elim-non-leaf\"\
    </span> <span class=\"pl-s\">\"no-infs-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"no-jump-tables\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> <span class=\"pl-s\">\"no-nans-fp-math\"</span>=<span class=\"\
    pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-signed-zeros-fp-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"no-trapping-math\"</span>=<span\
    \ class=\"pl-s\">\"false\"</span> <span class=\"pl-s\">\"stack-protector-buffer-size\"\
    </span>=<span class=\"pl-s\">\"8\"</span> <span class=\"pl-s\">\"target-cpu\"\
    </span>=<span class=\"pl-s\">\"a64fx\"</span> <span class=\"pl-s\">\"target-features\"\
    </span>=<span class=\"pl-s\">\"+crc,+crypto,+fp-armv8,+lse,+neon,+ras,+rdm,+sve,+v8.2a\"\
    </span> <span class=\"pl-s\">\"unsafe-fp-math\"</span>=<span class=\"pl-s\">\"\
    false\"</span> <span class=\"pl-s\">\"use-soft-float\"</span>=<span class=\"pl-s\"\
    >\"false\"</span> }\n\n<span class=\"pl-v\">!llvm.dbg.cu</span> = !{<span class=\"\
    pl-v\">!0</span>}\n<span class=\"pl-v\">!llvm.module.flags</span> = !{<span class=\"\
    pl-v\">!3</span>, <span class=\"pl-v\">!4</span>, <span class=\"pl-v\">!5</span>}\n\
    <span class=\"pl-v\">!llvm.ident</span> = !{<span class=\"pl-v\">!6</span>}\n\
    <span class=\"pl-v\">!llvm.compinfo</span> = !{<span class=\"pl-v\">!7</span>}\n\
    \n<span class=\"pl-v\">!0</span> = distinct <span class=\"pl-v\">!DICompileUnit</span>(language:\
    \ DW_LANG_C99, file: <span class=\"pl-v\">!1</span>, producer: <span class=\"\
    pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on\
    \ LLVM 7.1.0)\"</span>, isOptimized: <span class=\"pl-k\">true</span>, runtimeVersion:\
    \ <span class=\"pl-c1\">0</span>, emissionKind: LineTablesOnly, enums: <span class=\"\
    pl-v\">!2</span>)\n<span class=\"pl-v\">!1</span> = <span class=\"pl-v\">!DIFile</span>(filename:\
    \ <span class=\"pl-s\">\"-\"</span>, directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"\
    </span>)\n<span class=\"pl-v\">!2</span> = !{}\n<span class=\"pl-v\">!3</span>\
    \ = !{<span class=\"pl-k\">i32</span> <span class=\"pl-c1\">2</span>, !<span class=\"\
    pl-s\">\"Dwarf Version\"</span>, <span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">4</span>}\n<span class=\"pl-v\">!4</span> = !{<span class=\"pl-k\">i32</span>\
    \ <span class=\"pl-c1\">2</span>, !<span class=\"pl-s\">\"Debug Info Version\"\
    </span>, <span class=\"pl-k\">i32</span> <span class=\"pl-c1\">3</span>}\n<span\
    \ class=\"pl-v\">!5</span> = !{<span class=\"pl-k\">i32</span> <span class=\"\
    pl-c1\">1</span>, !<span class=\"pl-s\">\"wchar_size\"</span>, <span class=\"\
    pl-k\">i32</span> <span class=\"pl-c1\">4</span>}\n<span class=\"pl-v\">!6</span>\
    \ = !{!<span class=\"pl-s\">\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021\
    \ 10:55:52) (based on LLVM 7.1.0)\"</span>}\n<span class=\"pl-v\">!7</span> =\
    \ !{!<span class=\"pl-s\">\"C::clang\"</span>}\n<span class=\"pl-v\">!8</span>\
    \ = distinct <span class=\"pl-v\">!DISubprogram</span>(name: <span class=\"pl-s\"\
    >\"main\"</span>, scope: <span class=\"pl-v\">!9</span>, file: <span class=\"\
    pl-v\">!9</span>, line: <span class=\"pl-c1\">1</span>, type: <span class=\"pl-v\"\
    >!10</span>, isLocal: <span class=\"pl-k\">false</span>, isDefinition: <span class=\"\
    pl-k\">true</span>, scopeLine: <span class=\"pl-c1\">1</span>, isOptimized: <span\
    \ class=\"pl-k\">true</span>, unit: <span class=\"pl-v\">!0</span>, retainedNodes:\
    \ <span class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!9</span> = <span class=\"\
    pl-v\">!DIFile</span>(filename: <span class=\"pl-s\">\"&lt;stdin&gt;\"</span>,\
    \ directory: <span class=\"pl-s\">\"/home/ra000019/a04463\"</span>)\n<span class=\"\
    pl-v\">!10</span> = <span class=\"pl-v\">!DISubroutineType</span>(types: <span\
    \ class=\"pl-v\">!2</span>)\n<span class=\"pl-v\">!11</span> = <span class=\"\
    pl-v\">!DILocation</span>(line: <span class=\"pl-c1\">1</span>, column: <span\
    \ class=\"pl-c1\">12</span>, scope: <span class=\"pl-v\">!8</span>)</pre></div>\n\
    <h2><a id=\"user-content-systembenchmarksjl\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#systembenchmarksjl\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>SystemBenchmarks.jl</h2>\n<p>I ran\
    \ <a href=\"https://github.com/IanButterworth/SystemBenchmark.jl\"><code>SystemBenchmarks.jl</code></a>\
    \ on a\ncompute node.  Here are the results:\n<a href=\"https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\"\
    >https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968</a>.</p>\n\
    <h2><a id=\"user-content-blas\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#blas\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>BLAS</h2>\n<p>OpenBLAS seems to have poor performance:</p>\n<div class=\"\
    highlight highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span>\
    \ <span class=\"pl-k\">using</span> LinearAlgebra\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.589865257047898e10</span></pre></div>\n\
    <p>Up to v1.7, Julia uses OpenBLAS v0.3.17, which actually doesn't support A64FX\
    \ at all, so\nit's probably using the generic kernels.\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.19\"\
    ><code>v0.3.19</code></a> and\n<a href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.20\"\
    ><code>v0.3.20</code></a> improved support for\nthis chip, you can find a build\
    \ of 0.3.20 at\n<a href=\"https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\"\
    >https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz</a>,\n\
    but sadly there isn't a great performance improvement:</p>\n<div class=\"highlight\
    \ highlight-source-julia\"><pre>julia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">lbt_forward</span>(<span class=\"\
    pl-s\"><span class=\"pl-pds\">\"</span>lib/libopenblas64_.so<span class=\"pl-pds\"\
    >\"</span></span>)\n<span class=\"pl-c1\">4856</span>\n\njulia<span class=\"pl-k\"\
    >&gt;</span> <span class=\"pl-c1\">peakflops</span>()\n<span class=\"pl-c1\">2.6362952057793587e10</span></pre></div>\n\
    <p>There is an <a href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/Library/BLASLAPACKScaLAPACKLibrary.html#how-to-dynamically-load-and-use-blas-lapack-and-scalapack\"\
    \ rel=\"nofollow\">optimised\nBLAS</a>\nprovided by Fujitsu, with support for\
    \ SVE (with both LP64 and ILP64).  In order to use it,\ninstall <a href=\"https://github.com/giordano/FujitsuBLAS.jl\"\
    ><code>FujitsuBLAS.jl</code></a></p>\n<div class=\"highlight highlight-source-julia\"\
    ><pre>julia<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">using</span>\
    \ FujitsuBLAS, LinearAlgebra\n\njulia<span class=\"pl-k\">&gt;</span> BLAS<span\
    \ class=\"pl-k\">.</span><span class=\"pl-c1\">get_config</span>()\nLinearAlgebra<span\
    \ class=\"pl-k\">.</span>BLAS<span class=\"pl-k\">.</span>LBTConfig\nLibraries<span\
    \ class=\"pl-k\">:</span>\n\u2514 [ILP64] libfjlapackexsve_ilp64<span class=\"\
    pl-k\">.</span>so\n\njulia<span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\"\
    >peakflops</span>()\n<span class=\"pl-c1\">4.801227630694119e10</span></pre></div>\n\
    <p>The package <a href=\"https://github.com/carstenbauer/BLISBLAS.jl\"><code>BLISBLAS.jl</code></a>\
    \ similarly forwards\nBLAS calls to the <a href=\"https://github.com/flame/blis\"\
    >blis</a> library, which has optimised kernels\nfor A64FX.</p>\n<h2><a id=\"user-content-building-julia-from-source\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-julia-from-source\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ Julia from source</h2>\n<h3><a id=\"user-content-with-gcc\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#with-gcc\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>with GCC</h3>\n<p>Building Julia\
    \ from source with GCC (which is the default if you don't set <code>CC</code>\
    \ and <code>CXX</code>)\nworks fine, it's just <em>slow</em>:</p>\n<pre><code>[...]\n\
    \    JULIA usr/lib/julia/corecompiler.ji\nCore.Compiler \u2500\u2500\u2500\u2500\
    \ 903.661 seconds\n[...]\nBase  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500271.257337 seconds\nArgTools  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500 50.348227 seconds\nArtifacts  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500  1.193792 seconds\nBase64  \u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.057241 seconds\nCRC32c  \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.097865 seconds\n\
    FileWatching  \u2500\u2500\u2500\u2500\u2500  1.169747 seconds\nLibdl  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.026215 seconds\n\
    Logging  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.411966\
    \ seconds\nMmap  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.972844 seconds\nNetworkOptions  \u2500\u2500\u2500  1.159094 seconds\n\
    SHA  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  2.067851 seconds\nSerialization  \u2500\u2500\u2500\u2500  2.942512 seconds\n\
    Sockets  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.568797\
    \ seconds\nUnicode  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \  0.814165 seconds\nDelimitedFiles  \u2500\u2500\u2500  1.121546 seconds\nLinearAlgebra\
    \  \u2500\u2500\u2500\u2500109.560774 seconds\nMarkdown  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500  7.977584 seconds\nPrintf  \u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.635409 seconds\nRandom  \u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 13.843395 seconds\nTar\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500  3.146368 seconds\nDates  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500 16.694863 seconds\nDistributed  \u2500\u2500\u2500\u2500\
    \u2500\u2500  8.163152 seconds\nFuture  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500  0.060472 seconds\nInteractiveUtils  \u2500  5.245523\
    \ seconds\nLibGit2  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 15.469061 seconds\nProfile  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  5.399918 seconds\nSparseArrays  \u2500\u2500\u2500\u2500\u2500 42.660136\
    \ seconds\nUUIDs  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  0.165799 seconds\nREPL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500 40.149298 seconds\nSharedArrays  \u2500\u2500\
    \u2500\u2500\u2500  5.476926 seconds\nStatistics  \u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500  2.130843 seconds\nSuiteSparse  \u2500\u2500\u2500\u2500\u2500\u2500\
    \ 16.849304 seconds\nTOML  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500  0.714203 seconds\nTest  \u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.538098 seconds\nLibCURL  \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.547585 seconds\nDownloads\
    \  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.657012 seconds\nPkg  \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \ 54.053634 seconds\nLazyArtifacts  \u2500\u2500\u2500\u2500  0.019103 seconds\n\
    Stdlibs total  \u2500\u2500\u2500\u2500427.178257 seconds\nSysimage built. Summary:\n\
    Total \u2500\u2500\u2500\u2500\u2500\u2500\u2500 698.447219 seconds\nBase: \u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500 271.257337 seconds 38.8372%\nStdlibs: \u2500\
    \u2500\u2500\u2500 427.178257 seconds 61.1611%\n[...]\nPrecompilation complete.\
    \ Summary:\nTotal \u2500\u2500\u2500\u2500\u2500\u2500\u2500 1274.714700 seconds\n\
    Generation \u2500\u2500 886.445205 seconds 69.5407%\nExecution \u2500\u2500\u2500\
    \ 388.269495 seconds 30.4593%\n</code></pre>\n<h3><a id=\"user-content-with-fujitsu-compiler\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#with-fujitsu-compiler\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>With Fujitsu\
    \ compiler</h3>\n<p><em>For reference, the version used for the last build I attempted\
    \ was\n<a href=\"https://github.com/JuliaLang/julia/commit/1ad2396f05fa63a71e5842c814791cd7c7715100\"\
    ><code>1ad2396f</code></a></em></p>\n<p>Compiling Julia from source with the Fujitsu\
    \ compiler is complicated.  In particular, it's\nan absolute pain to use the Fujitsu\
    \ compiler in trad mode.  You can have some more luck with\nclang mode.</p>\n\
    <p>Preparation.  Create the <code>Make.user</code> file with this content (I'm\
    \ not sure this file is\nactually necessary when using Clang mode, but it definitely\
    \ is with trad mode):</p>\n<div class=\"highlight highlight-source-makefile\"\
    ><pre><span class=\"pl-k\">override</span> <span class=\"pl-smi\">ARCH</span>\
    \ := aarch64\n<span class=\"pl-k\">override</span> <span class=\"pl-smi\">BUILD_MACHINE</span>\
    \ := aarch64-unknown-linux-gnu</pre></div>\n<p>Then you can compile with (<code>-Nclang</code>\
    \ is to select clang mode)</p>\n<pre><code>make -j50 CC=\"fcc -Nclang\" CFLAGS=\"\
    -Kopenmp\" CXX=\"FCC -Nclang\" CXXFLAGS=\"-Kopenmp\"\n</code></pre>\n<p>The compiler\
    \ in trad mode doesn't define the macro <code>__SIZEOF_POINTER__</code>, so compilation\n\
    would fail in\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115</a>.\n\
    The solution is to set the macro <code>-D__SIZEOF_POINTER__=8</code> in the <code>CFLAGS</code>\
    \ (or just not use\ntrad mode).  Then, you may get errors like</p>\n<pre><code>/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2000:13:\
    \ error: initializer element is not a compile-time constant\n            jl_typename_type,\n\
    \            ^~~~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    /vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2025:43: error: initializer\
    \ element is not a compile-time constant\n    jl_typename_type-&gt;types = jl_svec(13,\
    \ jl_symbol_type, jl_any_type /*jl_module_type*/,\n                          \
    \                ^~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from\
    \ macro 'jl_svec'\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void\
    \ *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53:\
    \ note: expanded from macro '_Static_assert'\n      [!!sizeof (struct { int __error_if_negative:\
    \ (expr) ? 2 : -1; })]\n                                                    ^~~~\n\
    </code></pre>\n<p>This is the compiler's fault, which is supposed to be able to\
    \ handle this, but you can just\ndelete the assertions at lines\n<a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438</a>,\n\
    <a href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\"\
    >https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446</a>.</p>\n\
    <p>If you're lucky enough, with all these changes, you may be able to build <code>usr/bin/julia</code>.\n\
    Unfortunately, last time I tried, run this executable causes a segmentation fault\
    \ in\n<code>dl_init</code>:</p>\n<pre><code>(gdb) run\nStarting program: /vol0003/ra000019/a04463/repo/julia/julia\n\
    Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-151.el8.aarch64\n\
    [Thread debugging using libthread_db enabled]\nUsing host libthread_db library\
    \ \"/lib64/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation\
    \ fault.\n0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\n\
    Missing separate debuginfos, use: yum debuginfo-install FJSVxoslibmpg-2.0.0-25.14.1.el8.aarch64\
    \ elfutils-libelf-0.182-3.el8.aarch64\n(gdb) bt\n#0  0x000040000000def4 in _dl_init\
    \ () from /lib/ld-linux-aarch64.so.1\n#1  0x000040000020adb0 in _dl_catch_exception\
    \ () from /lib64/libc.so.6\n#2  0x00004000000125e4 in dl_open_worker () from /lib/ld-linux-aarch64.so.1\n\
    #3  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#4  0x0000400000011aa8\
    \ in _dl_open () from /lib/ld-linux-aarch64.so.1\n#5  0x0000400000091094 in dlopen_doit\
    \ () from /lib64/libdl.so.2\n#6  0x000040000020ad54 in _dl_catch_exception ()\
    \ from /lib64/libc.so.6\n#7  0x000040000020ae20 in _dl_catch_error () from /lib64/libc.so.6\n\
    #8  0x00004000000917f0 in _dlerror_run () from /lib64/libdl.so.2\n#9  0x0000400000091134\
    \ in dlopen@@GLIBC_2.17 () from /lib64/libdl.so.2\n#10 0x0000400000291f34 in load_library\
    \ (rel_path=0x400001e900c6 &lt;dep_libs+30&gt; \"libjulia-internal.so.1\", src_dir=&lt;optimized\
    \ out&gt;, err=1) at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:65\n\
    #11 0x0000400000291c78 in jl_load_libjulia_internal () at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:200\n\
    #12 0x000040000000de04 in call_init.part () from /lib/ld-linux-aarch64.so.1\n\
    #13 0x000040000000df08 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#14 0x0000400000001044\
    \ in _dl_start_user () from /lib/ld-linux-aarch64.so.1\nBacktrace stopped: previous\
    \ frame identical to this frame (corrupt stack?)\n</code></pre>\n"
  stargazers_count: 10
  subscribers_count: 3
  topics: []
  updated_at: 1690337110.0
hpc/mpifileutils:
  data_format: 2
  description: File utilities designed for scalability and performance.
  filenames:
  - spack.yaml
  full_name: hpc/mpifileutils
  latest_release: v0.11.1
  readme: '<h1><a id="user-content-mpifileutils" class="anchor" aria-hidden="true"
    tabindex="-1" href="#mpifileutils"><span aria-hidden="true" class="octicon octicon-link"></span></a>mpiFileUtils</h1>

    <p>mpiFileUtils provides both a library called <a href="src/common/README.md">libmfu</a>
    and a suite of MPI-based tools to manage large datasets, which may vary from large
    directory trees to large files. High-performance computing users often generate
    large datasets with parallel applications that run with many processes (millions
    in some cases). However those users are then stuck with single-process tools like
    cp and rm to manage their datasets. This suite provides MPI-based tools to handle
    typical jobs like copy, remove, and compare for such datasets, providing speedups
    of up to 20-30x.  It also provides a library that simplifies the creation of new
    tools or can be used in applications.</p>

    <p>Documentation is available on <a href="http://mpifileutils.readthedocs.io"
    rel="nofollow">ReadTheDocs</a>.</p>

    <h2><a id="user-content-daos-support" class="anchor" aria-hidden="true" tabindex="-1"
    href="#daos-support"><span aria-hidden="true" class="octicon octicon-link"></span></a>DAOS
    Support</h2>

    <p>mpiFileUtils supports a DAOS backend for dcp, dsync, and dcmp. Custom serialization
    and deserialization for DAOS containers to and from a POSIX filesystem is provided
    with daos-serialize and daos-deserialize. Details and usage examples are provided
    in <a href="DAOS-Support.md">DAOS Support</a>.</p>

    <h2><a id="user-content-contributors" class="anchor" aria-hidden="true" tabindex="-1"
    href="#contributors"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributors</h2>

    <p>We welcome contributions to the project.  For details on how to help, see our
    <a href="CONTRIBUTING.md">Contributor Guide</a></p>

    <h3><a id="user-content-copyrights" class="anchor" aria-hidden="true" tabindex="-1"
    href="#copyrights"><span aria-hidden="true" class="octicon octicon-link"></span></a>Copyrights</h3>

    <p>Copyright (c) 2013-2015, Lawrence Livermore National Security, LLC.

    Produced at the Lawrence Livermore National Laboratory

    CODE-673838</p>

    <p>Copyright (c) 2006-2007,2011-2015, Los Alamos National Security, LLC.

    (LA-CC-06-077, LA-CC-10-066, LA-CC-14-046)</p>

    <p>Copyright (2013-2015) UT-Battelle, LLC under Contract No.

    DE-AC05-00OR22725 with the Department of Energy.</p>

    <p>Copyright (c) 2015, DataDirect Networks, Inc.</p>

    <p>All rights reserved.</p>

    <h2><a id="user-content-build-status" class="anchor" aria-hidden="true" tabindex="-1"
    href="#build-status"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    Status</h2>

    <p>The current status of the mpiFileUtils master branch is <a href="https://travis-ci.org/hpc/mpifileutils"
    rel="nofollow"><img src="https://camo.githubusercontent.com/76717f664d99534173ac7e9fb8e904b0e4bd14fbd51ac6969a88de2e6e86a94f/68747470733a2f2f7472617669732d63692e6f72672f6870632f6d706966696c657574696c732e706e673f6272616e63683d6d6173746572"
    alt="Build Status" data-canonical-src="https://travis-ci.org/hpc/mpifileutils.png?branch=master"
    style="max-width: 100%;"></a>.</p>

    '
  stargazers_count: 141
  subscribers_count: 28
  topics: []
  updated_at: 1691176886.0
jaykalinani/AsterX:
  data_format: 2
  description: AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes
  filenames:
  - Docs/compile-notes/frontera-github/GPU/spack.yaml
  - Docs/compile-notes/frontera-github/CPU/spack.yaml
  full_name: jaykalinani/AsterX
  latest_release: null
  readme: '<p><a target="_blank" rel="noopener noreferrer" href="Docs/figures/asterx.png"><img
    align="top" src="Docs/figures/asterx.png" width="140" style="max-width: 100%;"></a></p>

    <p><strong>AsterX</strong> is a GPU-accelerated GRMHD code for dynamical spacetimes,
    written in C++. It is built upon the <a href="https://github.com/eschnett/CarpetX">CarpetX</a>
    driver, which is intended for the <a href="https://einsteintoolkit.org/" rel="nofollow">Einstein
    Toolkit</a>. <strong>CarpetX</strong> is based on <a href="https://amrex-codes.github.io"
    rel="nofollow">AMReX</a>, a software framework for block-structured AMR (adaptive
    mesh refinement).</p>

    <p>Full documentation will soon be available at <a href="https://asterx.readthedocs.io/en/latest/#"
    rel="nofollow">asterx.readthedocs.io</a>.</p>

    <ul>

    <li>

    <a href="https://github.com/jaykalinani/AsterX/actions"><img src="https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg"
    alt="GitHub CI" style="max-width: 100%;"></a>  <a href="https://asterx.readthedocs.io/en/latest/?badge=latest"
    rel="nofollow"><img src="https://camo.githubusercontent.com/8257fa34c1c5b6c660b31bf16a6196859c354c9c503b7742e1cdee871fbb96c8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374"
    alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/asterx/badge/?version=latest"
    style="max-width: 100%;"></a> <a href="https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md"><img
    src="https://camo.githubusercontent.com/b768fc44ae95216e4b53ff734978771466ba222596e760da27e9e60a0d47d6f7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667"
    alt="License: LGPL v3" data-canonical-src="https://img.shields.io/badge/License-LGPL_v3-blue.svg"
    style="max-width: 100%;"></a>

    </li>

    </ul>

    <h2><a id="user-content-overview" class="anchor" aria-hidden="true" tabindex="-1"
    href="#overview"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h2>

    <ul>

    <li>Heavily derived from the GRMHD code <a href="https://zenodo.org/record/4350072"
    rel="nofollow">Spritz</a>.</li>

    <li>Solves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes
    using high-resolution shock capturing (HRSC) schemes.</li>

    <li>Based on the flux-conservative Valencia formulation.</li>

    <li>Directly evolves the staggered vector potential.</li>

    </ul>

    <h2><a id="user-content-available-modules" class="anchor" aria-hidden="true" tabindex="-1"
    href="#available-modules"><span aria-hidden="true" class="octicon octicon-link"></span></a>Available
    modules</h2>

    <ul>

    <li>

    <code>AsterX</code> - the core GRMHD module</li>

    <li>

    <code>AsterSeeds</code> - initial data module</li>

    <li>

    <code>Con2PrimFactory</code> - module providing different conservative-to-primitive
    variable recovery routines</li>

    <li>

    <code>EOSX</code> - equation of state driver</li>

    <li>

    <code>ReconX</code> - provider of different reconstruction schemes</li>

    <li>

    <code>TOVSolver</code> - a modified version of the publicly available TOVSolver
    thorn used within the Einstein Toolkit</li>

    </ul>

    <h2><a id="user-content-getting-started" class="anchor" aria-hidden="true" tabindex="-1"
    href="#getting-started"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    started</h2>

    <p>Instructions for downloading and building the Einstein Toolkit including

    CarpetX can be found <a href="https://github.com/eschnett/CarpetX">here</a>.</p>

    <p>Details for building and running AsterX along with CarpetX will be added to
    <a href="https://asterx.readthedocs.io/en/latest/#" rel="nofollow">asterx.readthedocs.io</a>
    soon..</p>

    <h2><a id="user-content-related-talks-and-tutorials" class="anchor" aria-hidden="true"
    tabindex="-1" href="#related-talks-and-tutorials"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Related talks and tutorials</h2>

    <ul>

    <li>"<a href="http://einsteintoolkit.org/seminars/2021_03_18/index.html" rel="nofollow">Using
    CarpetX: A Guide for Early Adopters</a>".

    Recorded seminar talk by Erik Schnetter, providing an overview of the current
    capabilities of CarpetX.</li>

    <li>"<a href="https://einsteintoolkit.github.io/et2022uidaho/lectures/38-Tutorial8/index.html"
    rel="nofollow">Tutorial: GPUs and the Einstein Toolkit</a>".

    Recorded tutorial by Lorenzo Ennoggi, Jay Kalinani and Federico Lopez Armengol
    during the North American Einstein Toolkit workshop 2022, presenting a brief overview
    on AsterX, followed by a hands-on session.</li>

    <li>"<a href="https://drive.google.com/file/d/1Z4i--W56mxeNIu598LQTpEEowX56FOoD/view?usp=sharing"
    rel="nofollow">AsterX: a new open-source GPU-accelerated GRMHD code for dynamical
    spacetimes</a>".

    Slides based on the talk by Jay Kalinani at the APS April Meeting 2023.</li>

    </ul>

    '
  stargazers_count: 15
  subscribers_count: 10
  topics: []
  updated_at: 1691339230.0
jmellorcrummey/spack-configs:
  data_format: 2
  description: memoized spack configs for some DOE systems
  filenames:
  - anl/polaris/polaris.spack.yaml
  full_name: jmellorcrummey/spack-configs
  latest_release: null
  readme: "<p>This directory contains the various files, scripts, and instructions\
    \ for installing hpctoolkit\nat various sites, using Spack to do the install.</p>\n\
    <p>The top-level directory has an <a href=\"install.txt\">install.txt</a> script\
    \ with detailed,\nand hopefully, idiot-proof instructions for using Spack to install\
    \ hpctoolkit.</p>\n<p>It has a <code>bin</code> directory, containing a script\
    \ named <code>spacklink</code> that will set up a spack\nrepository to do the\
    \ installation at a specific <code>&lt;site&gt;</code> on a specific <code>&lt;machine&gt;</code>.</p>\n\
    <p>It has a number of sub-directories, named by <code>&lt;site&gt;</code>.\nEach\
    \ of those subdirectories contains one or more subdirectories, named by <code>&lt;machine&gt;</code>.</p>\n\
    <p>Each of those <code>&lt;site&gt;/&lt;machine&gt;</code> subdirectories contains\
    \ several files:</p>\n<ul>\n<li>\n<p><code>&lt;machine&gt;.config.yaml</code>:</p>\n\
    <p>specifies the directories in which to put the module files and packages for\
    \ a particular install.</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.modules.yaml</code>:</p>\n\
    <p>specifies information about the modules to be built</p>\n</li>\n<li>\n<p><code>&lt;machine&gt;.packages.yaml</code>:</p>\n\
    <p>this includes configuration for the software environment, including MPI, CUDA,\
    \ python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit</p>\n\
    </li>\n<li>\n<p><code>&lt;machine&gt;.spack.yaml</code>:</p>\n<p>this specifies\
    \ a Spack environment file, which allows building several HPCToolkit configurations\n\
    with Spack in one go. If present, the <code>spacklink</code> script will create\
    \ a new directory parallel to\nthe Spack repository called <code>spack-env</code>.\
    \ The installation steps then become:</p>\n</li>\n</ul>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>  $ spack/bin/spack -e spack-env concretize <span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> add \"-f\" to re-concretize as\
    \ needed</span>\n  $ spack/bin/spack -e spack-env install</pre></div>\n"
  stargazers_count: 3
  subscribers_count: 3
  topics: []
  updated_at: 1658934301.0
key4hep/key4hep-spack:
  data_format: 2
  description: A Spack recipe repository of Key4hep software.
  filenames:
  - environments/key4hep-nightly/spack.yaml
  - environments/key4hep-release/spack.yaml
  - environments/key4hep-ci/spack.yaml
  - environments/key4hep-nightly-debug/spack.yaml
  full_name: key4hep/key4hep-spack
  latest_release: '2021-10-29'
  readme: '<h1><a id="user-content-spack-package-repo-for-key4hep-software-packaging"
    class="anchor" aria-hidden="true" tabindex="-1" href="#spack-package-repo-for-key4hep-software-packaging"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>

    <a href="https://github.com/spack/spack">Spack</a> package repo for Key4HEP software
    packaging</h1>

    <p>This repository holds a set of Spack recipes for key4hep software.</p>

    <p>Consult the the <a href="https://cern.ch/key4hep" rel="nofollow">key4hep documentation
    website</a> and the

    <a href="https://spack.readthedocs.io/en/latest/" rel="nofollow">spack documentation</a>
    for more details.</p>

    <h2><a id="user-content-spack-versions" class="anchor" aria-hidden="true" tabindex="-1"
    href="#spack-versions"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Versions</h2>

    <p>The spack recipes in this repository should work with any version of spack
    (0.19

    is known to work and it''s possible older versions work too, newer than 0.19

    works). Some of the environments require spack 0.20 or newer since they use (or

    they include a file that uses) the <code>require</code> keyword which was introduced
    in

    <a href="https://github.com/spack/spack/releases/tag/v0.20.0">spack 0.20</a>.</p>

    <h2><a id="user-content-repository-contents" class="anchor" aria-hidden="true"
    tabindex="-1" href="#repository-contents"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Repository Contents</h2>

    <p>Apart from the recipes for key4hep packages in the folder <code>packages</code>,
    the

    repository contains a collection of environments used to build the stack in

    <code>environments</code> and some scripts used for publishing on cvmfs and other
    utilities

    in <code>scripts</code>. The builds run in Gitlab CI runners and the workflows
    can be found

    in the file <code>.gitlab-ci.yml</code> in the <a href="https://gitlab.cern.ch/key4hep/k4-deploy"
    rel="nofollow">gitlab

    repository</a>.</p>

    <p>Additionally, the file <code>.latest-commit</code> contains the latest commit
    of Spack used

    for the recent builds, which is updated from time to time to keep up with the

    develop branch of Spack.</p>

    <h2><a id="user-content-central-installations" class="anchor" aria-hidden="true"
    tabindex="-1" href="#central-installations"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Central Installations</h2>

    <p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org</code>
    (for

    CentOS 7) and <code>/cvmfs/sw-nightlies.hsf.org</code> (for CentOS 7, AlmaLinux
    9 and

    Ubuntu) see:</p>

    <p><a href="https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html"
    rel="nofollow">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>

    '
  stargazers_count: 8
  subscribers_count: 10
  topics: []
  updated_at: 1682439760.0
mfem/mfem:
  data_format: 2
  description: Lightweight, general, scalable C++ library for finite element methods
  filenames:
  - config/docker/spack.yaml
  full_name: mfem/mfem
  latest_release: v4.5.2
  readme: "<pre><code>                Finite Element Discretization Library\n    \
    \                           __\n                   _ __ ___   / _|  ___  _ __\
    \ ___\n                  | '_ ` _ \\ | |_  / _ \\| '_ ` _ \\\n               \
    \   | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_|\
    \ |_| |_|\n\n                           https://mfem.org\n</code></pre>\n<p><a\
    \ href=\"https://mfem.org\" rel=\"nofollow\">MFEM</a> is a modular parallel C++\
    \ library for finite element\nmethods. Its goal is to enable high-performance\
    \ scalable finite element\ndiscretization research and application development\
    \ on a wide variety of\nplatforms, ranging from laptops to supercomputers.</p>\n\
    <p>We welcome contributions and feedback from the community. Please see the file\n\
    <a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a> for additional details about our\
    \ development\nprocess.</p>\n<ul>\n<li>\n<p>For building instructions, see the\
    \ file <a href=\"INSTALL\">INSTALL</a>, or type \"make help\".</p>\n</li>\n<li>\n\
    <p>Copyright and licensing information can be found in files <a href=\"LICENSE\"\
    >LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>.</p>\n</li>\n<li>\n<p>The best\
    \ starting point for new users interested in MFEM's features is to\nreview the\
    \ examples and miniapps at <a href=\"https://mfem.org/examples\" rel=\"nofollow\"\
    >https://mfem.org/examples</a>.</p>\n</li>\n<li>\n<p>Instructions for learning\
    \ with Docker are in <a href=\"config/docker\">config/docker</a>.</p>\n</li>\n\
    </ul>\n<p>Conceptually, MFEM can be viewed as a finite element toolbox that provides\
    \ the\nbuilding blocks for developing finite element algorithms in a manner similar\
    \ to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides\
    \ support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\n\
    H(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\n\
    bilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping\
    \ of various finite element discretizations, including Galerkin\nmethods, mixed\
    \ finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization\
    \ and Discontinuous Petrov-Galerkin (DPG) approaches.</p>\n<p>MFEM includes classes\
    \ for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral\
    \ and hexahedral, as well as surface and topologically\nperiodical meshes. It\
    \ has general support for mesh refinement, including local\nconforming and non-conforming\
    \ (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for\
    \ high-order mesh elements with curved boundaries,\nare also supported.</p>\n\
    <p>When used as a \"finite element to linear algebra translator\", MFEM can take\
    \ a\nproblem described in terms of finite element-type objects, and produce the\n\
    corresponding linear algebra vectors and fully or partially assembled operators,\n\
    e.g. in the form of global sparse matrices or matrix-free operators. The library\n\
    includes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\n\
    well as support for sequential sparse direct solvers from the SuiteSparse\nlibrary.\
    \ Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit\
    \ and implicit Runge-Kutta time integrators are also available.</p>\n<p>MFEM supports\
    \ MPI-based parallelism throughout the library, and can readily be\nused as a\
    \ scalable unstructured finite element problem generator. Starting with\nversion\
    \ 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch\
    \ as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal\
    \ changes to switch from a serial to a highly-performant MPI-parallel\nversion\
    \ of the code, where they can take advantage of the integrated linear\nsolvers\
    \ from the hypre library. Comprehensive support for other external\npackages,\
    \ e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional\
    \ linear and nonlinear solvers, preconditioners, time integrators, etc.</p>\n\
    <p>For examples of using MFEM, see the <a href=\"examples\">examples/</a> and\
    \ <a href=\"miniapps\">miniapps/</a>\ndirectories, as well as the OpenGL visualization\
    \ tool GLVis which is available\nat <a href=\"https://glvis.org\" rel=\"nofollow\"\
    >https://glvis.org</a>.</p>\n<h2><a id=\"user-content-license\" class=\"anchor\"\
    \ aria-hidden=\"true\" tabindex=\"-1\" href=\"#license\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>MFEM is distributed\
    \ under the terms of the BSD-3 license. All new contributions\nmust be made under\
    \ this license. See <a href=\"LICENSE\">LICENSE</a> and <a href=\"NOTICE\">NOTICE</a>\
    \ for\ndetails.</p>\n<p>SPDX-License-Identifier: BSD-3-Clause <br>\nLLNL Release\
    \ Number: LLNL-CODE-806117 <br>\nDOI: 10.11578/dc.20171025.1248</p>\n"
  stargazers_count: 1355
  subscribers_count: 120
  topics:
  - finite-elements
  - high-order
  - high-performance-computing
  - parallel-computing
  - amr
  - computational-science
  - fem
  - scientific-computing
  - hpc
  - math-physics
  - radiuss
  updated_at: 1693528465.0
mochi-hpc-experiments/platform-configurations:
  data_format: 2
  description: This repository provides a set of configuration files and example scripts
    for running Mochi experiments on various platforms.
  filenames:
  - NERSC/Perlmutter/ss11/spack.yaml
  - ANL/Polaris/spack.yaml
  - ANL/Theta/spack.yaml
  - ORNL/Frontier/spack.yaml
  - NERSC/Perlmutter/ss10/spack.yaml
  full_name: mochi-hpc-experiments/platform-configurations
  latest_release: null
  readme: '<h1><a id="user-content-platform-configurations-for-mochi" class="anchor"
    aria-hidden="true" tabindex="-1" href="#platform-configurations-for-mochi"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Platform configurations
    for Mochi</h1>

    <p>This repository provides Spack configuration files, example job scripts, and

    notes about building and running Mochi-based codes on various platforms.

    Please refer to the subdirectory for your platform of interest for more

    information.</p>

    <p>The <code>generic</code> subdirectory contains a minimal Spack environment
    example that

    can be used as a starting point for systems for which there is no existing

    recipe.</p>

    <h2><a id="user-content-using-spackyaml-files" class="anchor" aria-hidden="true"
    tabindex="-1" href="#using-spackyaml-files"><span aria-hidden="true" class="octicon
    octicon-link"></span></a>Using spack.yaml files</h2>

    <p>Each platform subdirectory in this repository provides a <code>spack.yaml</code>
    file.

    A <code>spack.yaml</code> file fully describes a Spack environment, including

    system-provided packages and compilers. It does so independently of any

    <code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>,
    thereby

    preventing interference with user-specific spack configurations as much as

    possible.</p>

    <p>You may use <code>spack.yaml</code> files to create a

    <a href="https://spack.readthedocs.io/en/latest/environments.html" rel="nofollow">Spack
    environment</a>

    in which Mochi packages will be installed.</p>

    <p>If you don''t have Spack installed on your platform, clone it and set it up

    as follows.</p>

    <pre><code>$ git clone https://github.com/spack/spack.git

    $ . spack/share/spack/setup-env.sh

    </code></pre>

    <p>Remember that the second line needs to be executed every time you open a new

    terminal; it may be helpful to create an alias in your bashrc file as a

    shortcut.</p>

    <p>You will then need to clone <code>mochi-spack-packages</code>, which contains
    the Mochi packages.</p>

    <pre><code>$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git

    $ spack repo add mochi-spack-packages

    </code></pre>

    <p>Now clone the present repository and <code>cd</code> into the subdirectory
    relevant

    to your platform. For example:</p>

    <pre><code>$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git

    $ cd platform-configurations/ANL/Bebop

    </code></pre>

    <p>Edit the path to <code>mochi-spack-packages</code> in the <code>repos</code>
    field of the <code>spack.yaml</code> file to

    match your installation.</p>

    <p>Then, execute the following command

    (changing <em>myenv</em> into an appropriate name for your environment).</p>

    <pre><code>$ spack env create myenv spack.yaml

    </code></pre>

    <p>Change to a directory outside of the <code>platform-configurations</code> folders

    and activate the environment as follows.</p>

    <pre><code>$ spack env activate myenv

    </code></pre>

    <p>You may now add specs to your environment. For instance if you want

    to install Margo, execute the following command.</p>

    <pre><code>$ spack add mochi-margo

    </code></pre>

    <p>If the <code>spack.yaml</code> file provides multiple compilers and you want

    to use another than the default one, specify the compiler explicitely,

    for example:</p>

    <pre><code>$ spack add mochi-margo %gcc@8.2.0

    </code></pre>

    <p>Note that the <code>spack.yaml</code> file you used may already have a spec

    added as an example (usually <code>mochi-margo</code>). You can remove it as

    follows.</p>

    <pre><code>$ spack rm mochi-margo

    </code></pre>

    <p>Once you have added the specs you need in your environment, install

    everything by executing the following command.</p>

    <pre><code>$ spack install

    </code></pre>

    <p>You may add more specs later on. For more information on how to manage

    Spack environments, please refer to the Spack documentation.</p>

    <h2><a id="user-content-contributing-to-this-repository" class="anchor" aria-hidden="true"
    tabindex="-1" href="#contributing-to-this-repository"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Contributing to this repository</h2>

    <p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,

    please submit a merge request with it, and ensure the following.</p>

    <ul>

    <li>The <code>spack.yaml</code> file should contain the compiler(s) that have
    been tested

    and confirmed to work with Mochi packages.</li>

    <li>The <code>spack.yaml</code> file should try to list system-provided packages,

    in particular packages used for building (<code>cmake</code>, <code>autoconf</code>,
    etc.),

    and relevant system-provided MPI implementations.

    <ul>

    <li>Note that this must be done manually.  Spack provides a <code>spack external
    find</code> command that can be used to locate a subset of system packages,

    but it does not populate the <code>spack.yaml</code> file.</li>

    </ul>

    </li>

    <li>The <code>spack.yaml</code> file should contain the relevant variants for
    packages,

    in particular the transport methods to use with <code>libfabric</code>.</li>

    <li>The path to the <code>spack.yaml</code> file should be of the form

    <code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>

    <li>Please make sure that your <code>spack.yaml</code> is a reliable way to work
    with

    Mochi on the target platform, other people will rely on it!</li>

    </ul>

    <p>You can also contribute changes to existing <code>spack.yaml</code> files,
    in particular

    to add working compilers, system packages, etc. As always, please test that

    new setups work before creating a merge request.</p>

    '
  stargazers_count: 4
  subscribers_count: 3
  topics: []
  updated_at: 1682086466.0
mochi-hpc/mochi-raft:
  data_format: 2
  description: Mochi-based implementation of RAFT using c-raft
  filenames:
  - polaris-spack.yaml
  full_name: mochi-hpc/mochi-raft
  latest_release: null
  readme: '<h1><a id="user-content-mochi-raft" class="anchor" aria-hidden="true" tabindex="-1"
    href="#mochi-raft"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mochi-RAFT</h1>

    <p>This repository provides an implementation of the RAFT protocol using

    Margo for communication and <a href="https://github.com/canonical/raft">C-Raft</a>

    for the protocol itself.</p>

    <p>Mochi-RAFT (Mraft) is modular and allows users to provide their own

    implementation of a persistent log.</p>

    '
  stargazers_count: 0
  subscribers_count: 6
  topics: []
  updated_at: 1692622489.0
olcf/spack-environments:
  data_format: 2
  description: Spack Environments Templates for OLCF resources
  filenames:
  - linux-sles15-zen2/spock/spack.yaml
  - linux-centos7-broadwell/or-slurm/spack.yaml
  - linux-rhel8-ppc64le/summit/spack.yaml
  full_name: olcf/spack-environments
  latest_release: null
  readme: '<p>OLCF Spack Environments Templates</p>

    <p>Companion files the for: <a href="https://docs.olcf.ornl.gov/software/spack_env/index.html"
    rel="nofollow">OLCF Documentaton for spack environments</a></p>

    <h2><a id="user-content-purpose" class="anchor" aria-hidden="true" tabindex="-1"
    href="#purpose"><span aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

    <p>The provided Spack environment files are intended to assist OLCF users in setup
    their development environment at the

    OLCF.  The base environment file includes the compilers and packages that are
    installed at the system level.</p>

    <p>Spack documentation can be found <a href="https://spack.readthedocs.io/" rel="nofollow">here</a>.</p>

    '
  stargazers_count: 4
  subscribers_count: 20
  topics: []
  updated_at: 1670008521.0
robertu94/libpressio_opt:
  data_format: 2
  description: A optimizing autotuing plugin for libpressio
  filenames:
  - spack.yaml
  full_name: robertu94/libpressio_opt
  latest_release: 0.11.0
  readme: "<h1><a id=\"user-content-libpressioopt\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#libpressioopt\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>LibPressioOpt</h1>\n<p>LibPressioOpt provides\
    \ a plugin for libpressio that provides optimization routines to configure compressors.</p>\n\
    <h2><a id=\"user-content-using-libpressioopt\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#using-libpressioopt\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Using LibPressioOpt</h2>\n<p>Please\
    \ see <code>./test/opt_example_c.c</code> for an example of the API.</p>\n<h2><a\
    \ id=\"user-content-getting-started\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#getting-started\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Getting Started</h2>\n<p>LibPressioOpt provides three new major features\
    \ on top of LibPressio:</p>\n<ul>\n<li>the <code>opt</code> meta compressor which\
    \ allows for searching for the optimal configuration of the compressor</li>\n\
    <li>\n<code>pressio_search</code> modules which allow for searching for an optimal\
    \ set of configuration of parameters</li>\n<li>\n<code>pressio_search_metrics</code>\
    \ modules which compute properties of the search process itself</li>\n</ul>\n\
    <p>See [Opt Configuration](@ref optoptions) for more information on the configuration\
    \ options.</p>\n<h2><a id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#dependencies\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>\n<code>cmake</code>\
    \ version <code>3.13</code> or later</li>\n<li>either:\n<ul>\n<li>\n<code>gcc-8.3.0</code>\
    \ or later</li>\n<li>\n<code>clang-9.0.0</code> or later</li>\n</ul>\n</li>\n\
    <li>LibDistributed version 0.0.8 or later</li>\n<li>LibPressio version 0.40.1\
    \ or later</li>\n<li>An MPI implementation supporting MPI-3 or later.  Tested\
    \ on OpenMPI 4.0.2</li>\n<li>Dlib after commit <code>95271cfe43ffceeadeb1a73bf033794b501e86f4</code>\
    \ (after release 19.21)</li>\n</ul>\n<h2><a id=\"user-content-installing-libpressioopt-using-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installing-libpressioopt-using-spack\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing\
    \ LibPressioOpt using Spack</h2>\n<p>LibPressioOpt can be built using <a href=\"\
    https://github.com/spack/spack/\">spack</a>.</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>git clone https://github.com/robertu94/spack_packages robertu94_packages\n\
    spack repo add robertu94_packages\nspack install libpressio-opt</pre></div>\n\
    <p>You can substantially reduce install times by not installing ImageMagick and\
    \ PETSc support for libpressio.</p>\n<pre><code>spack install libpressio-opt ^libpressio~magick~petsc\n\
    </code></pre>\n<h2><a id=\"user-content-building-and-installing-libpressioopt-manually\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#building-and-installing-libpressioopt-manually\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ and Installing LibPressioOpt Manually</h2>\n<p>LibPressioOpt uses CMake to configure\
    \ build options.  See CMake documentation to see how to configure options</p>\n\
    <ul>\n<li>\n<code>CMAKE_INSTALL_PREFIX</code> - install the library to a local\
    \ directory prefix</li>\n<li>\n<code>BUILD_DOCS</code> - build the project documentation</li>\n\
    <li>\n<code>BUILD_TESTING</code> - build the test cases</li>\n</ul>\n<div class=\"\
    highlight highlight-source-shell\"><pre>BUILD_DIR=build\nmkdir <span class=\"\
    pl-smi\">$BUILD_DIR</span>\n<span class=\"pl-c1\">cd</span> <span class=\"pl-smi\"\
    >$BUILD_DIR</span>\ncmake ..\nmake\nmake <span class=\"pl-c1\">test</span>\nmake\
    \ install</pre></div>\n<p>To build the documentation:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>BUILD_DIR=build\nmkdir <span class=\"pl-smi\"\
    >$BUILD_DIR</span>\n<span class=\"pl-c1\">cd</span> <span class=\"pl-smi\">$BUILD_DIR</span>\n\
    cmake .. -DBUILD_DOCS=ON\nmake docs\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> the html docs can be found in $BUILD_DIR/html/index.html</span>\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> the man pages can be found in $BUILD_DIR/man/</span></pre></div>\n\
    <h2><a id=\"user-content-stability\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#stability\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Stability</h2>\n<p>As of version 1.0.0, LibPressioOpt will follow\
    \ the following API stability guidelines:</p>\n<ul>\n<li>The functions defined\
    \ in files in <code>./include</code> are to considered stable</li>\n<li>The functions\
    \ defined in files or its subdirectories in <code>./include/libpressio_opt_ext/</code>\
    \ considered unstable.</li>\n</ul>\n<p>Stable means:</p>\n<ul>\n<li>New APIs may\
    \ be introduced with the increase of the minor version number.</li>\n<li>APIs\
    \ may gain additional overloads for C++ compatible interfaces with an increase\
    \ in the minor version number.</li>\n<li>An API may change the number or type\
    \ of parameters with an increase in the major version number.</li>\n<li>An API\
    \ may be removed with the change of the major version number</li>\n</ul>\n<p>Unstable\
    \ means:</p>\n<ul>\n<li>The API may change for any reason with the increase of\
    \ the minor version number</li>\n</ul>\n<p>Additionally, the performance of functions,\
    \ memory usage patterns may change for both stable and unstable code with the\
    \ increase of the patch version.</p>\n<h2><a id=\"user-content-bug-reports\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#bug-reports\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Bug Reports</h2>\n<p>Please files\
    \ bugs to the Github Issues page on the robertu94 github repository.</p>\n<p>Please\
    \ read this post on <a href=\"https://codingnest.com/how-to-file-a-good-bug-report/\"\
    \ rel=\"nofollow\">how to file a good bug report</a>.\_ After reading this post,\
    \ please provide the following information specific to LibPressioOpt:</p>\n<ul>\n\
    <li>Your OS version and distribution information, usually this can be found in\
    \ <code>/etc/os-release</code>\n</li>\n<li>the output of <code>cmake -L $BUILD_DIR</code>\n\
    </li>\n<li>the version of each of LibPressioOpts's dependencies listed in the\
    \ README that you have installed. Where possible, please provide the commit hashes.</li>\n\
    </ul>\n<h2><a id=\"user-content-cite\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#cite\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Cite</h2>\n<p>If you find this work useful, please consider citing</p>\n\
    <div class=\"highlight highlight-text-bibtex\"><pre><span class=\"pl-k\">@article</span>{<span\
    \ class=\"pl-en\">underwood2022optzconfig</span>,\n  <span class=\"pl-s\">title</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>OptZConfig: Efficient Parallel\
    \ Optimization of Lossy Compression Configuration<span class=\"pl-pds\">}</span></span>,\n\
    \  <span class=\"pl-s\">author</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>Underwood, Robert and Calhoun, Jon C and Di, Sheng and Apon, Amy and\
    \ Cappello, Franck<span class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\"\
    >journal</span>=<span class=\"pl-s\"><span class=\"pl-pds\">{</span>IEEE Transactions\
    \ on Parallel and Distributed Systems<span class=\"pl-pds\">}</span></span>,\n\
    \  <span class=\"pl-s\">year</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>2022<span class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\">publisher</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>IEEE<span class=\"pl-pds\">}</span></span>\n\
    }</pre></div>\n<p>or if you only optimize compression ratio</p>\n<div class=\"\
    highlight highlight-text-bibtex\"><pre><span class=\"pl-k\">@inproceedings</span>{<span\
    \ class=\"pl-en\">underwood2020fraz</span>,\n  <span class=\"pl-s\">title</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>Fraz: A generic high-fidelity\
    \ fixed-ratio lossy compression framework for scientific floating-point data<span\
    \ class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\">author</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>Underwood, Robert and Di, Sheng\
    \ and Calhoun, Jon C and Cappello, Franck<span class=\"pl-pds\">}</span></span>,\n\
    \  <span class=\"pl-s\">booktitle</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>2020 IEEE International Parallel and Distributed Processing Symposium\
    \ (IPDPS)<span class=\"pl-pds\">}</span></span>,\n  <span class=\"pl-s\">pages</span>=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">{</span>567--577<span class=\"pl-pds\"\
    >}</span></span>,\n  <span class=\"pl-s\">year</span>=<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">{</span>2020<span class=\"pl-pds\">}</span></span>,\n  <span\
    \ class=\"pl-s\">organization</span>=<span class=\"pl-s\"><span class=\"pl-pds\"\
    >{</span>IEEE<span class=\"pl-pds\">}</span></span>\n}\n</pre></div>\n"
  stargazers_count: 0
  subscribers_count: 4
  topics: []
  updated_at: 1636674438.0
simonpintarelli/nlcglib:
  data_format: 2
  description: Nonlinear CG methods for wave-function optimization in DFT
  filenames:
  - spack-envs/q-e-sirius-lumi/spack.yaml
  - spack-envs/q-e-sirius-cpu-only/spack.yaml
  full_name: simonpintarelli/nlcglib
  latest_release: v0.9.1
  stargazers_count: 6
  subscribers_count: 2
  topics: []
  updated_at: 1671059412.0
spack/spack-configs:
  data_format: 2
  description: Share Spack configuration files with other HPC sites
  filenames:
  - NERSC/perlmutter/e4s-22.05/nvhpc/spack.yaml
  - NERSC/cori/e4s-21.02/prod/spack.yaml
  - NERSC/perlmutter/e4s-23.05/data/spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/NERSC-Cori/intel-spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/NERSC-Cori/gcc-spack.yaml
  - OLCF/andes/spack.yaml
  - NERSC/perlmutter/e4s-23.05/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.08/spack.yaml
  - NREL/configs/eagle/software/spack.yaml
  - NERSC/perlmutter/e4s-22.11/prod/gcc/spack.yaml
  - BOISESTATE/borah/environments/netcdf+hdf5+fftw/_spack.yaml
  - NREL/configs/rhodes/compilers/spack.yaml
  - BOISESTATE/borah/environments/base/_spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/cce/spack.yaml
  - NREL/configs/eagle/base/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/tools/spack.yaml
  - BOISESTATE/borah/applications/gromacs/_spack.yaml
  - NERSC/perlmutter/e4s-22.05/prod/gcc/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cce/spack.yaml
  - OLCF/summit/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.05/spack.yaml
  - BOISESTATE/borah/environments/b4s/_spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.05/spack.yaml
  - ANL/JLSE/Arcticus/E4S-22.02/spack.yaml
  - NERSC/perlmutter/e4s-22.11/gcc/spack.yaml
  - NREL/configs/eagle/utilities/spack.yaml
  - NERSC/perlmutter/e4s-22.11/cuda/spack.yaml
  - UOREGON/E4S-21.05-Facility-Examples/Frank-Jupiter/spack.yaml
  - NERSC/perlmutter/e4s-23.05/cuda/spack.yaml
  - NERSC/perlmutter/e4s-23.05/nvhpc/spack.yaml
  - NREL/configs/rhodes/utilities/spack.yaml
  - NERSC/perlmutter/e4s-22.05/cuda/spack.yaml
  - OLCF/frontier/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/nvhpc/spack.yaml
  - NREL/configs/eagle/compilers/spack.yaml
  - NERSC/perlmutter/e4s-23.05/prod/gcc/spack.yaml
  - ANL/JLSE/Arcticus/E4S-21.11/prod/spack.yaml
  full_name: spack/spack-configs
  latest_release: null
  readme: '<h1><a id="user-content-spack-configs" class="anchor" aria-hidden="true"
    tabindex="-1" href="#spack-configs"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spack
    Configs</h1>

    <p>This is a repository that sites can use to share their configuration

    files for Spack.  You can contribute your own configuration files, or

    browse around and look at what others have done.</p>

    <h2><a id="user-content-license" class="anchor" aria-hidden="true" tabindex="-1"
    href="#license"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>Spack is distributed under the terms of both the MIT license and the

    Apache License (Version 2.0). Users may choose either license, at their

    option.</p>

    <p>All new contributions must be made under both the MIT and Apache-2.0

    licenses.</p>

    <p>See <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-MIT">LICENSE-MIT</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE">LICENSE-APACHE</a>,

    <a href="https://github.com/spack/spack-configs/blob/master/COPYRIGHT">COPYRIGHT</a>,
    and

    <a href="https://github.com/spack/spack-configs/blob/master/NOTICE">NOTICE</a>
    for details.</p>

    <p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>

    <p>LLNL-CODE-811652</p>

    '
  stargazers_count: 53
  subscribers_count: 26
  topics: []
  updated_at: 1692756888.0
ukri-excalibur/excalibur-tests:
  data_format: 2
  description: Performance benchmarks and regression tests for the ExCALIBUR project
  filenames:
  - benchmarks/spack/cosma7/rockport-openmpi-compute-node/spack.yaml
  - benchmarks/spack/isambard-a64fx/compute-node/spack.yaml
  - benchmarks/spack/archer2/compute-node/spack.yaml
  - benchmarks/spack/isambard-macs/rome/spack.yaml
  - benchmarks/spack/isambard-phase3/ampere/spack.yaml
  - benchmarks/spack/csd3-skylake/compute-node/spack.yaml
  - benchmarks/spack/github-actions/default/spack.yaml
  - benchmarks/spack/isambard-macs/volta/spack.yaml
  full_name: ukri-excalibur/excalibur-tests
  latest_release: null
  readme: "<h1><a id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"\
    true\" tabindex=\"-1\" href=\"#excalibur-tests\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>ExCALIBUR tests</h1>\n<p>Performance benchmarks\
    \ and regression tests for the ExCALIBUR project.</p>\n<p>These benchmarks are\
    \ based on a similar project by\n<a href=\"https://github.com/stackhpc/hpc-tests\"\
    >StackHPC</a>.</p>\n<p><em><strong>Note</strong>: at the moment the ExCALIBUR\
    \ benchmarks are a work-in-progress.</em></p>\n<h2><a id=\"user-content-installation\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#installation\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n\
    <p>We require Python version 3.7 or later. Install the <strong>excalibur-tests</strong>\
    \ package with <code>pip</code> by</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>pip install -e <span class=\"pl-c1\">.</span></pre></div>\n<p>The <code>-e/--editable</code>\
    \ flag is recommended for two reasons.</p>\n<ul>\n<li>Spack installs packages\
    \ in a <code>opt</code> directory under the spack environment. With <code>-e</code>\
    \ the spack\nenvironment remains in your local directory and <code>pip</code>\
    \ creates symlinks to it. Without <code>-e</code> spack\nwill install packages\
    \ inside your python environment.</li>\n<li>For <a href=\"https://setuptools.pypa.io/en/latest/userguide/development_mode.html\"\
    \ rel=\"nofollow\">development</a>,\nthe <code>-e</code> flag to <code>pip</code>\
    \ links the installed package to the files in the local\ndirectory, instead of\
    \ copying, to allow making changes to the installed package.</li>\n</ul>\n<p>Note\
    \ that to use <code>-e</code> with a project configured with a <code>pyproject.toml</code>\
    \ you need <code>pip</code> version 22 or later.</p>\n<p>On most systems, it is\
    \ recommended to install the package in a virtual environment.\nFor example, using\
    \ the python3 <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow\"\
    >built-in virtual environment tool <code>venv</code></a>,\ncreate an environment\
    \ called <code>my_environment</code> with</p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>python3 -m venv ./my_environment</pre></div>\n<p>and activate it with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">source</span>\
    \ ./my_environment/bin/activate</pre></div>\n<h3><a id=\"user-content-spack\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#spack\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n\
    <p>The <code>pip install</code> command will install a compatible version of <strong>ReFrame</strong>\
    \ from\n<a href=\"https://pypi.org/project/ReFrame-HPC/\" rel=\"nofollow\">PyPi</a>.\
    \ However, you will have to\nmanually provide an installation of <strong>Spack</strong>.</p>\n\
    <p><a href=\"https://spack.io/\" rel=\"nofollow\">Spack</a> is a package manager\
    \ specifically designed for HPC\nfacilities. In some HPC facilities there may\
    \ be already a central Spack installation available.\nHowever, the version installed\
    \ is most likely too old to support all the features\nused by this package. Therefore\
    \ we recommend you install the latest version locally,\nfollowing the instructions\
    \ below.</p>\n<p><em><strong>Note</strong>: if you have already installed spack\
    \ locally and you want to upgrade to\na newer version, you might first have to\
    \ clear the cache to avoid conflicts:\n<code>spack clean -m</code></em></p>\n\
    <p>Follow the <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\"\
    \ rel=\"nofollow\">official instructions</a>\nto install the latest version of\
    \ Spack (summarised here for convenience, but not guaranteed to be\nup-to-date):</p>\n\
    <ul>\n<li>git clone spack:\n<code>git clone -c feature.manyFiles=true https://github.com/spack/spack.git</code>\n\
    </li>\n<li>run spack setup script: <code>source ./spack/share/spack/setup-env.sh</code>\n\
    </li>\n<li>check spack is in <code>$PATH</code>, for example <code>spack --version</code>\n\
    </li>\n</ul>\n<p>In order to use Spack in ReFrame, the framework we use to run\
    \ the benchmarks\n(see below), the directory where the <code>spack</code> program\
    \ is installed needs to be in\nthe <code>PATH</code> environment variable. This\
    \ is taken care of by the <code>setup-env.sh</code>\nscript as above, and you\
    \ can have your shell init script (e.g. <code>.bashrc</code>)\ndo that automatically\
    \ in every session, by adding the following lines to it:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SPACK_ROOT=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/spack<span class=\"\
    pl-pds\">\"</span></span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-k\"\
    >-f</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"\
    pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span class=\"pl-pds\">\"\
    </span></span> ]<span class=\"pl-k\">;</span> <span class=\"pl-k\">then</span>\n\
    \    <span class=\"pl-c1\">source</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >\"</span><span class=\"pl-smi\">${SPACK_ROOT}</span>/share/spack/setup-env.sh<span\
    \ class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">fi</span></pre></div>\n\
    <p>replacing <code>/path/to/spack</code> with the actual path to your Spack installation.</p>\n\
    <p>ReFrame also requires a <a href=\"https://spack.readthedocs.io/en/latest/environments.html\"\
    \ rel=\"nofollow\">Spack\nEnvironment</a>.  We\nprovide Spack environments for\
    \ some of the systems that are part of the\nExCALIBUR and DiRAC projects in\n\
    <a href=\"https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack\"\
    >https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack/</a>.\n\
    If you want to use a different Spack environment,\nset the environment variable\
    \ <code>EXCALIBUR_SPACK_ENV</code> to the path of the directory\nwhere the environment\
    \ is.  If this is not set, ReFrame will try to use the\nenvironment for the current\
    \ system if known, otherwise it will automatically\ncreate a very basic environment\
    \ (see \"Usage on unsupported systems\" section below).</p>\n<h2><a id=\"user-content-configuration\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#configuration\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuration</h2>\n\
    <h3><a id=\"user-content-reframe\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"\
    -1\" href=\"#reframe\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>ReFrame</h3>\n<p><a href=\"https://reframe-hpc.readthedocs.io/en/stable/\"\
    \ rel=\"nofollow\">ReFrame</a> is a high-level\nframework for writing regression\
    \ tests for HPC systems.  For our tests we\nrequire ReFrame v4.1.3.</p>\n<p>We\
    \ provide a ReFrame configuration file with the settings of some systems that\n\
    are part of the ExCALIBUR or DiRAC projects.  You can point ReFrame to this file\
    \ by\nsetting the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILES\"\
    \ rel=\"nofollow\"><code>RFM_CONFIG_FILES</code></a>\nenvironment variable:</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span>\
    \ RFM_CONFIG_FILES=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span\
    \ class=\"pl-smi\">${PWD}</span>/benchmarks/reframe_config.py<span class=\"pl-pds\"\
    >\"</span></span></pre></div>\n<p>If you want to use a different ReFrame configuration\
    \ file, for example because\nyou use a different system, you can set this environment\
    \ variable to the path of\nthat file.</p>\n<p><strong>Note</strong>: in order\
    \ to use the Spack build system in ReFrame, the <code>spack</code>\nexecutable\
    \ must be in the <code>PATH</code> also on the compute nodes of a cluster, if\n\
    you want to run your benchmarks on them. This is taken care of by adding it\n\
    to your init file (see spack section above).</p>\n<p>However, you will also need\
    \ to set the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\"\
    \ rel=\"nofollow\"><code>RFM_USE_LOGIN_SHELL</code></a>\nenvironment variable\
    \ (<code>export RFM_USE_LOGIN_SHELL=\"true\"</code>) in order to make ReFrame\
    \ use</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"\
    pl-k\">!</span><span class=\"pl-c\"><span class=\"pl-c\">#</span>/bin/bash -l</span></pre></div>\n\
    <p>as <a href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\
    >shebang</a> line, which would load\nthe user's init script.</p>\n<h2><a id=\"\
    user-content-usage\" class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"\
    #usage\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n\
    <p>Once you have set up Spack and ReFrame, you can execute a benchmark with</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/BENCH_NAME\
    \ -r --performance-report</pre></div>\n<p>where <code>benchmarks/apps/BENCH_NAME</code>\
    \ is the directory where the benchmark is.  The command\nabove assumes you have\
    \ the program <code>reframe</code> in your PATH.  If you have followed the instructions\n\
    to install using <code>pip</code> into the default directory, it should have been\
    \ automatically added.\nIf it is not the case, call <code>reframe</code> with\
    \ its relative or absolute path.</p>\n<p>For example, to run the Sombrero benchmark\
    \ in the <code>benchmarks/apps/sombrero</code> directory you can\nuse</p>\n<div\
    \ class=\"highlight highlight-source-shell\"><pre>reframe -c benchmarks/apps/sombrero\
    \ -r --performance-report</pre></div>\n<p>For benchmarks that use the Spack build\
    \ system, the tests define a default Spack specification\nto be installed in the\
    \ environment, but users can change it when invoking ReFrame on the\ncommand line\
    \ with the\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\"\
    \ rel=\"nofollow\"><code>-S</code></a> option to set\nthe <code>spack_spec</code>\
    \ variable:</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S spack_spec='sombrero@2021-08-16%intel'\n</code></pre>\n<h3><a id=\"user-content-setting-environment-variables\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#setting-environment-variables\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting\
    \ environment variables</h3>\n<p>All the built-in fields of ReFrame regression\
    \ classes can be set on a per-job basis using the\n<code>-S</code> command-line\
    \ option. One useful such field is\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.env_vars\"\
    \ rel=\"nofollow\"><code>env_vars</code></a>,\nwhich controls the environment\
    \ variables used in a job.\nThe syntax to set dictionary items, like for <code>env_vars</code>,\
    \ is a comma-separated list of <code>key:value</code> pairs: <code>-S dict=key_1:value_1,key_2:value_2</code>.\n\
    For example</p>\n<pre><code>reframe -c benchmarks/apps/sombrero -r --performance-report\
    \ -S env_vars=OMP_PLACES:threads\n</code></pre>\n<p>runs the <code>benchmarks/apps/sombrero</code>\
    \ benchmark setting the environment variable <code>OMP_PLACES</code>\nto <code>threads</code>.</p>\n\
    <h3><a id=\"user-content-selecting-system-and-queue-access-options\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#selecting-system-and-queue-access-options\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Selecting\
    \ system and queue access options</h3>\n<p>The provided ReFrame configuration\
    \ file contains the settings for multiple systems.  If you\nuse it, the automatic\
    \ detection of the system may fail, as some systems may use clashing\nhostnames.\
    \  To avoid this, you can use the flag <a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\"\
    \ rel=\"nofollow\"><code>--system NAME:PARTITION</code></a>\nto specify the system\
    \ (and optionally the partition) to use.</p>\n<p>Additionally, if submitting jobs\
    \ to the compute nodes requires additional options, like for\nexample the resource\
    \ group you belong to (for example <code>--account=...</code> for Slurm), you\
    \ have\nto pass the command line flag\n<a href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\"\
    \ rel=\"nofollow\"><code>--job-option=...</code></a>\nto <code>reframe</code>\
    \ (e.g., <code>--job-option='--account=...'</code>).</p>\n<h3><a id=\"user-content-usage-on-unsupported-systems\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#usage-on-unsupported-systems\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage on\
    \ unsupported systems</h3>\n<p>The configuration provided in <a href=\"./reframe_config.py\"\
    ><code>reframe_config.py</code></a> lets you run the\nbenchmarks on pre-configured\
    \ HPC systems.  However you\ncan use this framework on any system by choosing\
    \ the \"default\" system with <code>--system default</code>, or by using your\
    \ own ReFrame configuration.  You can use the \"default\" system to run\nbenchmarks\
    \ in ReFrame without using a queue manager or an MPI launcher (e.g. on a personal\
    \ workstation).</p>\n<p>If you choose the \"default\" system and a benchmark using\
    \ the Spack build system,\na new empty Spack environment will be automatically\
    \ created in\n<code>benchmarks/spack/default</code> when ReFrame is launched for\
    \ the first time.\nYou should populate the environment with the packages already\
    \ installed on your system\nbefore running Spack to avoid excessively rebuilding\
    \ system packages. See the\n<em>Spack configuration</em> section of <a href=\"\
    ./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for instructions on how\n\
    to set up a Spack environment.\nIn particular, make sure that at least a compiler\
    \ and an MPI library are added into the environment.\nAfter the Spack environment\
    \ is set up, tell ReFrame to use it by setting the environment\nvariable <code>EXCALIBUR_SPACK_ENV</code>,\
    \ as described above.</p>\n<h3><a id=\"user-content-system-specific-flags\" class=\"\
    anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#system-specific-flags\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System-specific\
    \ flags</h3>\n<p>While the aim is to automate as much system-specific configuration\
    \ as possible, there are some options that have to be provided by the user, such\
    \ as accounting details, and unfortunately the syntax can vary.\nThe file <a href=\"\
    ./SYSTEMS.md\"><code>SYSTEMS.md</code></a> contains information about the use\
    \ of this framework on specific systems.</p>\n<h2><a id=\"user-content-contributing-new-systems-or-benchmarks\"\
    \ class=\"anchor\" aria-hidden=\"true\" tabindex=\"-1\" href=\"#contributing-new-systems-or-benchmarks\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing\
    \ new systems or benchmarks</h2>\n<p>Feel free to add new benchmark apps or support\
    \ new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read\
    \ <a href=\"./CONTRIBUTING.md\"><code>CONTRIBUTING.md</code></a> for more details.</p>\n"
  stargazers_count: 8
  subscribers_count: 7
  topics: []
  updated_at: 1686579984.0
