var data = [
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "inputs/spack/spack.yaml"
        ],
        "full_name": "cinemascienceworkflows/2021-05_ExaWind-AMRWind",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-configs\" class=\"anchor\" href=\"#spack-configs\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack Configs</h1>\n<p>This is a repository that sites can use to share their configuration\nfiles for Spack.  You can contribute your own configuration files, or\nbrowse around and look at what others have done.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-MIT\">LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE\">LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack-configs/blob/master/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack-configs/blob/master/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 5,
        "topics": [],
        "updated_at": 1621478944.0
    },
    {
        "data_format": 2,
        "description": "Mobject is a prototype Mochi object storage system based on RADOS",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mobject",
        "latest_release": "v0.5",
        "readme": "",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1621277137.0
    },
    {
        "data_format": 2,
        "description": "A Tutorial for LibPressio",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "FTHPC/libpressio_tutorial",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-libpressio-tutorial\" class=\"anchor\" href=\"#libpressio-tutorial\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>LibPressio Tutorial</h1>\n<p>This repository contains a number of example applications to help you learn how\nto use LibPressio lossy compression.  The exercises are located in <code>exercises/</code>\nand have their own instructions in the README.md file.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1621038319.0
    },
    {
        "data_format": 2,
        "description": "A microservice (i.e., Mochi provider) for high performance bulk storage of raw data regions",
        "filenames": [
            "spack.yaml",
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-bake",
        "latest_release": "v0.6.3",
        "readme": "<h1>\n<a id=\"user-content-bake\" class=\"anchor\" href=\"#bake\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bake</h1>\n<p>Bake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage of raw data regions.  Bake uses modular backends to store data\non persistent memory, conventional file systems, or other storage media.</p>\n<p>See <a href=\"https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\">https://www.mcs.anl.gov/research/projects/mochi/</a> and\n<a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/</a> for more information about Mochi.</p>\n<p>Bake's scope is limited exclusively to data storage.  Capabilities such as\nindexing, name spaces, and sharding must be provided by other microservice\ncomponents.</p>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>The easiest way to install Bake is through spack:</p>\n<p><code>spack install bake</code></p>\n<p>This will install BAKE and its dependencies.  Please refer to the end of the\ndocument for manual compilation instructions.</p>\n<h2>\n<a id=\"user-content-architecture\" class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>Like most Mochi services, BAKE relies on a client/provider architecture.\nA provider, identified by its <em>address</em> and <em>multiplex id</em>, manages one or more\n<em>BAKE targets</em>, referenced externally by their <em>target id</em>.</p>\n<p>A target can be thought of as a storage device.  This may be (for example) a\nPMDK volume or a local file system.</p>\n<h2>\n<a id=\"user-content-setting-up-a-bake-target\" class=\"anchor\" href=\"#setting-up-a-bake-target\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up a BAKE target</h2>\n<p>BAKE requires the backend storage file to be created beforehand using\n<code>bake-mkpool</code>. For instance:</p>\n<p><code>bake-mkpool -s 500M /dev/shm/foo.dat</code></p>\n<p>creates a 500 MB file at <em>/dev/shm/foo.dat</em> to be used by BAKE as a target.\nBake will use the <code>pmem</code> (persistent memory) backend by default, which means\nthat the underlying file will memory mapped for access usign the PMDK\nlibrary.  You can also providie an explicit prefix (such as <code>file:</code> for the\nconventional file backend or <code>pmem:</code> for the persistent memory backend) to\ndictate a specific target type.</p>\n<h2>\n<a id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>BAKE ships with a default daemon program that can setup providers and attach\nto storage targets. This daemon can be started as follows:</p>\n<p><code>bake-server-daemon [options] &lt;listen_address&gt; &lt;bake_pool_1&gt; &lt;bake_pool_2&gt; ...</code></p>\n<p>The program takes a set of options followed by an address at which to listen for\nincoming RPCs, and a list of\nBAKE targets already created using <code>bake-mkpool</code>.</p>\n<p>For example:</p>\n<p><code>bake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234 /dev/shm/foo.dat /dev/shm/bar.dat</code></p>\n<p>The following options are accepted:</p>\n<ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (<em>providers</em> or <em>targets</em>).</li>\n</ul>\n<p>The <em>providers</em> mode indicates that, if multiple BAKE targets are used (as above),\nthese targets should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... <em>N</em> where <em>N</em> is the number of storage targets\nto manage. The <em>targets</em> mode indicates that a single provider should be used to\nmanage all the storage targets.</p>\n<h2>\n<a id=\"user-content-integrating-bake-into-a-larger-service\" class=\"anchor\" href=\"#integrating-bake-into-a-larger-service\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Integrating Bake into a larger service</h2>\n<p>Bake is not intended to be a standalone user-facing service.  See\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\" rel=\"nofollow\">https://mochi.readthedocs.io/en/latest/bedrock.html</a> for guidance on how to\nintegrate it with other providers using Mochi's Bedrock capability.</p>\n<h2>\n<a id=\"user-content-client-api-example\" class=\"anchor\" href=\"#client-api-example\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client API example</h2>\n<p>Data is stored in <code>regions</code> within a <code>target</code> using explicit create,\nwrite, and persist operations.  The caller cannot dictate the region id\nthat will be used to reference a region; this identifier is generated\nby Bake at creation time.  The region size must be specified at creation\ntime as well; there is no mechanism for extending the size of an existing\nregion.</p>\n<div class=\"highlight highlight-source-c\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>bake-client.h<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span> **argv)\n{\n    <span class=\"pl-k\">char</span> *svr_addr_str; <span class=\"pl-c\"><span class=\"pl-c\">//</span> string address of the BAKE server</span>\n    <span class=\"pl-c1\">hg_addr_t</span> svr_addr; <span class=\"pl-c\"><span class=\"pl-c\">//</span> Mercury address of the BAKE server</span>\n    margo_instance_id mid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> Margo instance id</span>\n    <span class=\"pl-c1\">bake_client_t</span> bcl; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE client</span>\n    <span class=\"pl-c1\">bake_provider_handle_t</span> bph; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE handle to provider</span>\n    <span class=\"pl-c1\">uint8_t</span> mplex_id; <span class=\"pl-c\"><span class=\"pl-c\">//</span> multiplex id of the provider</span>\n    <span class=\"pl-c1\">uint32_t</span> target_number; <span class=\"pl-c\"><span class=\"pl-c\">//</span> target to use</span>\n    <span class=\"pl-c1\">bake_region_id_t</span> rid; <span class=\"pl-c\"><span class=\"pl-c\">//</span> BAKE region id handle</span>\n\t<span class=\"pl-c1\">bake_target_id_t</span>* bti; <span class=\"pl-c\"><span class=\"pl-c\">//</span> array of target ids</span>\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> ... setup variables ... <span class=\"pl-c\">*/</span></span>\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Initialize Margo <span class=\"pl-c\">*/</span></span>\n\tmid = <span class=\"pl-c1\">margo_init</span>(..., MARGO_CLIENT_MODE, <span class=\"pl-c1\">0</span>, -<span class=\"pl-c1\">1</span>);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Lookup the server <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_lookup</span>(mid, svr_addr_str, &amp;svr_addr);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Creates the BAKE client <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_client_init</span>(mid, &amp;bcl);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Creates the provider handle <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_provider_handle_create</span>(bcl, svr_addr, mplex_id, &amp;bph);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Asks the provider for up to target_number target ids <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">uint32_t</span> num_targets = <span class=\"pl-c1\">0</span>;\n\tbti = <span class=\"pl-c1\">calloc</span>(num_targets, <span class=\"pl-k\">sizeof</span>(*bti));\n\t<span class=\"pl-c1\">bake_probe</span>(bph, target_number, bti, &amp;num_targets);\n\t<span class=\"pl-k\">if</span>(num_targets &lt; target_number) {\n\t\t<span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error: provider has only <span class=\"pl-c1\">%d</span> storage targets<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>, num_targets);\n\t}\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Create a region <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">size_t</span> size = ...; <span class=\"pl-c\"><span class=\"pl-c\">//</span> size of the region to create</span>\n\t<span class=\"pl-c1\">bake_create</span>(bph, bti[target_number-<span class=\"pl-c1\">1</span>], size, &amp;rid);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Write data into the region at offset 0 <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-k\">char</span>* buf = ...;\n\t<span class=\"pl-c1\">bake_write</span>(bph, rid, <span class=\"pl-c1\">0</span>, buf, size);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Make all modifications persistent <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_persist</span>(bph, rid);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release provider handle <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_provider_handle_release</span>(bph);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Release BAKE client <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">bake_client_finalize</span>(bcl);\n\t<span class=\"pl-c\"><span class=\"pl-c\">/*</span> Cleanup Margo resources <span class=\"pl-c\">*/</span></span>\n\t<span class=\"pl-c1\">margo_addr_free</span>(mid, svr_addr);\n\t<span class=\"pl-c1\">margo_finalize</span>(mid);\n\t<span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n<p>Note that a <code>bake_region_id_t</code> object is persistent.  It can be written\n(into a file or a socket) and stored or sent to another program. These\nregion ids are what uniquely reference a region within a given target.</p>\n<p>The rest of the client-side API can be found in <code>bake-client.h</code>.</p>\n<h2>\n<a id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider API</h2>\n<p>The bake-server-daemon source is a good example of how to create providers and\nattach storage targets to them. The provider-side API is located in\n<em>bake-server.h</em>, and consists of mainly two functions:</p>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span> <span class=\"pl-en\">bake_provider_register</span>(margo_instance_id                     mid,\n                           <span class=\"pl-c1\">uint16_t</span>                              provider_id,\n                           <span class=\"pl-k\">const</span> <span class=\"pl-k\">struct</span> bake_provider_init_info* args,\n                           <span class=\"pl-c1\">bake_provider_t</span>*                      provider);</pre></div>\n<p>This creates a provider at the given provider id using the specified margo\ninstance.  The <code>args</code> parameter can be used to modify default settings,\nincluding passing in a fully specified json configuration block.  See\n<code>bake-server.h</code> for details.</p>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">int</span> <span class=\"pl-en\">bake_provider_attach_target</span>(<span class=\"pl-c1\">bake_provider_t</span>   provider,\n                                <span class=\"pl-k\">const</span> <span class=\"pl-k\">char</span>*       target_name,\n                                <span class=\"pl-c1\">bake_target_id_t</span>* target_id);</pre></div>\n<p>This makes the provider manage the given storage target.</p>\n<p>Other functions are available to create and detach targets from a provider.</p>\n<h2>\n<a id=\"user-content-generic-bake-benchmark\" class=\"anchor\" href=\"#generic-bake-benchmark\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Generic Bake benchmark</h2>\n<p>By using <code>--enable-benchmark</code> when compiling Bake (or <code>+benchmark</code> when using Spack),\nyou will build a <code>bake-benchmark</code> program that can be used as a configurable benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure Bake with\n<code>CC=mpicc</code> and <code>CXX=mpicxx</code>.</p>\n<p>The benchmark is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a server, while non-zero ranks act as clients. The server will not create\na Bake target. The Bake target needs to be created (with <code>bake-makepool</code>) beforehand.</p>\n<p>The program takes as parameter the path to a JSON file containing the sequence\nof benchmarks to execute. An example of such a file is located in <code>src/benchmark.json</code>.\nEach entry in the <code>benchmarks</code> array corresponds to a benchmark. The <code>type</code> field indicates\nthe type of benchmark to execute. The <code>repetitions</code> field indicates how many times the\nbenchmark should be repeated.</p>\n<p>The following table describes each type of benchmark and their parameters.</p>\n<table>\n<thead>\n<tr>\n<th>type</th>\n<th>parameter</th>\n<th>default</th>\n<th>description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>write</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number of regions to write</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the input buffer for each write</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to write to the same region</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the input buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number of region to persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to erase the created regions after the benchmark executed</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>read</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number of region to read</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer for each read</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-region</td>\n<td>false</td>\n<td>Whether to access the same region for each read</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>create-write-persist</td>\n<td>num-entries</td>\n<td>1</td>\n<td>Number of regions to create/write/persist</td>\n</tr>\n<tr>\n<td></td>\n<td>region-sizes</td>\n<td>-</td>\n<td>Size of the regions, or range (e.g. [12, 24])</td>\n</tr>\n<tr>\n<td></td>\n<td>reuse-buffer</td>\n<td>false</td>\n<td>Whether to reuse the same buffer on clients for each operation</td>\n</tr>\n<tr>\n<td></td>\n<td>preregister-bulk</td>\n<td>false</td>\n<td>Whether to preregister the client's buffer for RDMA</td>\n</tr>\n<tr>\n<td></td>\n<td>erase-on-teardown</td>\n<td>true</td>\n<td>Whether to remove the regions after the benchmark</td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-manual-installation\" class=\"anchor\" href=\"#manual-installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manual installation</h2>\n<p>BAKE depends on the following libraries:</p>\n<ul>\n<li>uuid (install uuid-dev package on ubuntu)</li>\n<li>PMDK (see instructions below)</li>\n<li>json-c</li>\n<li>mochi-abt-io</li>\n<li>mochi-margo</li>\n</ul>\n<p>Bake will automatically identify these dependencies at configure time using\npkg-config. To compile BAKE:</p>\n<ul>\n<li><code>./prepare.sh</code></li>\n<li><code>mkdir build</code></li>\n<li><code>cd build</code></li>\n<li><code>../configure --prefix=/home/carns/working/install</code></li>\n<li><code>make</code></li>\n</ul>\n<p>If any dependencies are installed in a nonstandard location, then\nmodify the configure step listed above to include the following argument:</p>\n<ul>\n<li><code>PKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig</code></li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1620945435.0
    },
    {
        "data_format": 2,
        "description": "Python interface for Mochi's Bedrock service.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/py-mochi-bedrock",
        "latest_release": "v0.1",
        "readme": "<h1>\n<a id=\"user-content-py-bedrock\" class=\"anchor\" href=\"#py-bedrock\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Py-Bedrock</h1>\n<p>Py-Bedrock providers Python utilities to configure and deploy Mochi-based\nservices using Python.</p>\n<h2>\n<a id=\"user-content-running-the-jupyter-demo\" class=\"anchor\" href=\"#running-the-jupyter-demo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the Jupyter demo</h2>\n<p>Create a spack environment and add the required packages in it.</p>\n<pre><code>spack env create py-bedrock-demo\nspack env activate py-bedrock-demo\nspack add py-mochi-bedrock\nspack add py-jupyterlab-server\nspack install\n</code></pre>\n<p>Deactivate and re-activate the environment for the PYTHONPATH variable to\nbe updated.</p>\n<pre><code>spack env deactivate\nspack env activate py-bedrock-demo\n</code></pre>\n<p>Run the Jupyter server.</p>\n<pre><code>jupyter notebook --ip 0.0.0.0 --port 8888\n</code></pre>\n<p>Then from your browser, open the <code>notebooks/Demo.ipynb</code> notebook,\nand start playing!</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1620857361.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "envs/broken-verbs-chris8x/spack.yaml",
            "envs/dev/spack.yaml",
            "envs/chris8x/spack.yaml"
        ],
        "full_name": "range3/spack-playground",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-playground\" class=\"anchor\" href=\"#spack-playground\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>spack-playground</h1>\n<h2>\n<a id=\"user-content-env\" class=\"anchor\" href=\"#env\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Env</h2>\n<div class=\"highlight highlight-source-shell\"><pre>$ <span class=\"pl-c1\">cd</span> /workspaces/spack-playground\n$ spack env create -d envs/dev\n$ spack env activate -p -d envs/dev\n$ spack external find</pre></div>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1620808001.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "tandem/submodules/yateto/tests/spack.yaml"
        ],
        "full_name": "le-raffael/AdaptiveTimeSteppingSEAS",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-playground\" class=\"anchor\" href=\"#spack-playground\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>spack-playground</h1>\n<h2>\n<a id=\"user-content-env\" class=\"anchor\" href=\"#env\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Env</h2>\n<div class=\"highlight highlight-source-shell\"><pre>$ <span class=\"pl-c1\">cd</span> /workspaces/spack-playground\n$ spack env create -d envs/dev\n$ spack env activate -p -d envs/dev\n$ spack external find</pre></div>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1620773652.0
    },
    {
        "data_format": 2,
        "description": "Mochi bootstrapping service.",
        "filenames": [
            "spack.yaml",
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-bedrock",
        "latest_release": "v0.3",
        "readme": "<h1>\n<a id=\"user-content-bedrock\" class=\"anchor\" href=\"#bedrock\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bedrock</h1>\n<p>Bedrock is Mochi's service bootstrapping mechanism.\nFor documentations and tutorials, please see\n<a href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\" rel=\"nofollow\">here</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1620916986.0
    },
    {
        "data_format": 2,
        "description": "Spack Environments ",
        "filenames": [
            "cent8/envs/avx512/rproject/spack.yaml",
            "cent7/library/bak/spack.yaml",
            "cent7/bioinformatics/spack.yaml",
            "cent7/apps/spack.yaml",
            "cent8/envs/avx512/python/spack.yaml",
            "cent7/library/spack.yaml",
            "cent8/envs/avx/rproject/spack.yaml",
            "cent8/envs/avx2/python/spack.yaml",
            "compilers/envs/compilers/spack.yaml",
            "cent7/mpis/spack.yaml",
            "cent7/libs_old/spack.yaml",
            "cent8/envs/avx/python/spack.yaml",
            "cent8/envs/avx512/lusoft/spack.yaml",
            "cent8/envs/x86_64/spack.yaml",
            "cent8/envs/avx2/rproject/spack.yaml",
            "cent8/envs/avx/lusoft/spack.yaml",
            "cent7/bioinformatics_default/spack.yaml",
            "cent7/py_376/spack.yaml",
            "cent7/bio_old/spack.yaml",
            "cent7/library/spack.yaml~",
            "cent8/envs/solhawk/spack.yaml",
            "cent8/envs/avx2/lusoft/spack.yaml",
            "cent7/ece_hpc/spack.yaml",
            "cent7/bioinformatics_default/spack.yaml.bak",
            "cent7/python_376/spack.yaml"
        ],
        "full_name": "alexpacheco/spackenv",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-environments\" class=\"anchor\" href=\"#spack-environments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SPACK Environments</h1>\n<p>This repo contains the environment definitions to deploy site-software on Lehigh University's Research Computing resources via SPACK environments.</p>\n<h2>\n<a id=\"user-content-software-deployment-for-centos-8x\" class=\"anchor\" href=\"#software-deployment-for-centos-8x\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Software deployment for CentOS 8.x</h2>\n<p>Software is deployed using two Spack installations.</p>\n<ol>\n<li>For compilers and module environments</li>\n<li>Site software for general use</li>\n</ol>\n<h3>\n<a id=\"user-content-compilers\" class=\"anchor\" href=\"#compilers\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compilers</h3>\n<p>This spack installation provides the gcc, nvhpc and cuda compilers, and lmod software for module management. In the future, this installation will also provide intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were installed in /share/Apps/intel with older intel compilers. This installation should not be used for deploying site software nor should the software provided be made available using the module environment.</p>\n<p>To reproduce installation</p>\n<pre><code>git clone https://github.com/alexpacheco/spackenv.git\ncd spackenv/compilers/envs/compilers\nspack env activate -d .\nspack concretize -f # optional\nspack install\n</code></pre>\n<p>The directory <code>etc/lmod</code> contains the LMOD configuration to switch between avx, avx2 and avx512 enabled <code>MODULEPATHS</code></p>\n<h3>\n<a id=\"user-content-lu-software\" class=\"anchor\" href=\"#lu-software\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>LU Software</h3>\n<p>This spack installation provides the deployed site-software on Sol and Hawk.</p>\n<p>To reproduce this installation, you need to first copy the site configuration files from <code>etc/spack</code> to your spack install tree. This assumes that SLURM and the compiler environment above is already installed. Edit the <code>packages.yaml</code> file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel, cuda, and nvhpc. The file <code>repo.yaml</code> is hardwired with  location of the lubio repository and should be changed to your location. The directory <code>templates</code> contains the template lua file for a few modules as defined in the <code>modules.yaml</code> file  and should be copied to the <code>etc</code> directory in your spack installation tree.</p>\n<p>On Sol, these files are available at <code>/share/Apps/lusoft/etc/spack</code>.</p>\n<h4>\n<a id=\"user-content-available-environments\" class=\"anchor\" href=\"#available-environments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Available Environments</h4>\n<h5>\n<a id=\"user-content-solhawk\" class=\"anchor\" href=\"#solhawk\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>solhawk</h5>\n<p>This environment builds the entire software except the various python and r packages for ivybridge, haswell and skylake_avx512 architectures. This environment also builds the tcl environment modules that is not currently used. This should be build first and any new packages should be added to this environment.</p>\n<pre><code>cd spackenv/cent8/envs/solhawk\nspack env activate -d .\nspack concretize -f # optional\nspack install\n</code></pre>\n<h4>\n<a id=\"user-content-avxavx2avx512\" class=\"anchor\" href=\"#avxavx2avx512\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>avx/avx2/avx512</h4>\n<p>These environment builds the software stack except the various python and r packages for ivybridge/haswell/skylake_avx512 architectures. If software in the <code>solhawk</code> environment is already built, then these environments are only setting up the installation root for the LMOD module files <code>/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}</code>. The only reason these environments exist is due to SPACK's inability to built a architecture based LMOD module tree similar to the TCL module tree.\n<em>Note</em>: If you change the path of the installation root, make sure that you change the corresponding path in <code>compilers/etc/SitePackage.lua</code>.</p>\n<pre><code>cd spackenv/cent8/envs/avx2/lusoft\nspack env activate -d .\nspack concretize -f # optional\nspack install\n</code></pre>\n<h4>\n<a id=\"user-content-python-and-r-packages\" class=\"anchor\" href=\"#python-and-r-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Python and R packages</h4>\n<p>Rather than building module files for various python and r packages, a single module is created for a filesystem view of all python and r packages respectively. The path to the r filesystem is setup as <code>R_LIBS_SITE</code> so that any application such as <code>trinity</code> that requires many R packages only need to load the r module. If new packages added to the above environments require a dependent R package, then that dependency should be added to the rpoject environment and concretized. The python environment uses a <code>concretization: together</code> and may not provide the same python package as the above software environments. The filesystem views are hardwired as <code>/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}</code> and <code>/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}</code>.</p>\n<pre><code>cd spackenv/cent8/envs/avx/python\nspack env activate -d .\nspack concretize -f # optional\nspack install\n</code></pre>\n<pre><code>cd spackenv/cent8/envs/avx512/rproject\nspack env activate -d .\nspack concretize -f # optional\nspack install\n</code></pre>\n<h4>\n<a id=\"user-content-x86_64\" class=\"anchor\" href=\"#x86_64\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>x86_64</h4>\n<p>This environment builds unoptimized software such as anaconda python, gnu parallel, scree, tmux, etc for generic x86_64 processor.</p>\n<h2>\n<a id=\"user-content-centos-7x-software\" class=\"anchor\" href=\"#centos-7x-software\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CentOS 7.x software</h2>\n<p>This just collects the various environments for building software before the CentOS 8.x upgrade.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1620234577.0
    },
    {
        "data_format": 2,
        "description": "Spack configuration files and scripts for use on machines at NREL",
        "filenames": [
            "configs/eagle/base/spack.yaml",
            "configs/eagle/software/spack.yaml",
            "configs/eagle/compilers/spack.yaml",
            "configs/rhodes/compilers/spack.yaml",
            "configs/rhodes/software/spack.yaml",
            "configs/rhodes/utilities/spack.yaml",
            "configs/eagle/utilities/spack.yaml",
            "configs/rhodes/base/spack.yaml",
            "envs/exawind/spack.yaml"
        ],
        "full_name": "jrood-nrel/spack-configs",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" class=\"anchor\" href=\"#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack configuration files and scripts for use on machines at NREL</h1>\n<p>These software installations are maintained by Jon Rood for the HPACF group at NREL and are tailored to the applications our group develops. The list of available modules can be seen in <a href=\"modules.txt\">modules.txt</a>. They are open to anyone to use on our machines. The software installations are organized by date snapshots. The binaries, compilers, and utilties are not updated as often as the software modules, so dated symlinks might point to older dates for those. However, each date snapshot of the modules should be able to stand on its own so that older snapshots can be purged safely over time.</p>\n<ul>\n<li>\"base\" is just a newer version of GCC to replace the system GCC 4.8.5 which is far too old to build many recent projects.</li>\n<li>\"binaries\" are generally the binary downloads of Paraview and Visit.</li>\n<li>\"compilers\" are the latest set of compilers built using the base GCC.</li>\n<li>\"utilities\" are the latest set of utility programs that don't rely on MPI and are built using the base GCC.</li>\n<li>\"software\" are the latest set of generally larger programs and dependencies that rely on MPI. Each date corresponds to a single MPI implementation so there is no confusion as to which MPI was used for the applications. These modules are built using a farily recent GCC, Clang, or Intel compiler provided from the \"compilers\" modules, using the highest optimization flags specific to the machine architecture.</li>\n</ul>\n<p>The Spack hierarchy is linked in the following manner where each installation is based on other upstream Spack installations. \"software\" depends on \"utilities\", which both depend on \"compilers\". This hierarchy allows Spack to point to packages it needs which are already built upstream. The \"compilers\" installation exposes only the modules for compilers, while the \"utilities\" modules inherit modules from itself as well as the dependency packages in the \"compilers\" installation except the compiler modules themselves.</p>\n<p>Currently there is no perfect way to advertise deprecation or addition, and evolution of these modules. I have an MOTD you can cat in your login script to see updates. Generally the latest 4 sets of modules will likely be kept and new sets have been showing up around every 3 to 6 months.</p>\n<p>To use these modules you can add the following to your <code>~/.bashrc</code> for example and choose the module set (date) you prefer, and the GCC or Intel compiled software modules:</p>\n<pre><code>#------------------------------------------\n\n#MPT 2.22\n#MODULES=modules-2020-07\n#COMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3.1\n#MODULES=modules-2019-10-08\n#COMPILER=gcc-7.4.0\n#COMPILER=clang-7.0.1\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-23\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-08\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-01-10\n#COMPILER=gcc-7.3.0\n#COMPILER=intel-18.0.4\n\n#Recommended default according to where \"modules\" is currently symlinked\nMODULES=modules\nCOMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\nmodule purge\nmodule unuse ${MODULEPATH}\nmodule use /nopt/nrel/ecom/hpacf/binaries/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/compilers/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/utilities/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}\nmodule load gcc\nmodule load git\nmodule load python\n#etc...\n\n#------------------------------------------\n</code></pre>\n<p>If <code>module avail</code> does not show the modules on Eagle, try removing the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>\n<p>Also included in this directory is a recommended Spack configurations you can use to build your own packages on the machines supported at NREL. Once you have <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code> which should copy the yaml files into your instance of Spack. Or you can copy the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack compilers</code> should then show you many available compilers. Source your Spack's <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code> in your <code>.bashrc</code> so that your Spack instance will add its own module path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack compilers</code> doesn't show you the updated list of compilers. The <code>~/.spack</code> directory takes highest precendence in the Spack configuration.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1620946052.0
    },
    {
        "data_format": 2,
        "description": "trying to use spack in gh actions without docker images",
        "filenames": [
            "tools/environments/ci/spack.yaml"
        ],
        "full_name": "haampie-spack/ci-example-2",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" class=\"anchor\" href=\"#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack configuration files and scripts for use on machines at NREL</h1>\n<p>These software installations are maintained by Jon Rood for the HPACF group at NREL and are tailored to the applications our group develops. The list of available modules can be seen in <a href=\"modules.txt\">modules.txt</a>. They are open to anyone to use on our machines. The software installations are organized by date snapshots. The binaries, compilers, and utilties are not updated as often as the software modules, so dated symlinks might point to older dates for those. However, each date snapshot of the modules should be able to stand on its own so that older snapshots can be purged safely over time.</p>\n<ul>\n<li>\"base\" is just a newer version of GCC to replace the system GCC 4.8.5 which is far too old to build many recent projects.</li>\n<li>\"binaries\" are generally the binary downloads of Paraview and Visit.</li>\n<li>\"compilers\" are the latest set of compilers built using the base GCC.</li>\n<li>\"utilities\" are the latest set of utility programs that don't rely on MPI and are built using the base GCC.</li>\n<li>\"software\" are the latest set of generally larger programs and dependencies that rely on MPI. Each date corresponds to a single MPI implementation so there is no confusion as to which MPI was used for the applications. These modules are built using a farily recent GCC, Clang, or Intel compiler provided from the \"compilers\" modules, using the highest optimization flags specific to the machine architecture.</li>\n</ul>\n<p>The Spack hierarchy is linked in the following manner where each installation is based on other upstream Spack installations. \"software\" depends on \"utilities\", which both depend on \"compilers\". This hierarchy allows Spack to point to packages it needs which are already built upstream. The \"compilers\" installation exposes only the modules for compilers, while the \"utilities\" modules inherit modules from itself as well as the dependency packages in the \"compilers\" installation except the compiler modules themselves.</p>\n<p>Currently there is no perfect way to advertise deprecation or addition, and evolution of these modules. I have an MOTD you can cat in your login script to see updates. Generally the latest 4 sets of modules will likely be kept and new sets have been showing up around every 3 to 6 months.</p>\n<p>To use these modules you can add the following to your <code>~/.bashrc</code> for example and choose the module set (date) you prefer, and the GCC or Intel compiled software modules:</p>\n<pre><code>#------------------------------------------\n\n#MPT 2.22\n#MODULES=modules-2020-07\n#COMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3.1\n#MODULES=modules-2019-10-08\n#COMPILER=gcc-7.4.0\n#COMPILER=clang-7.0.1\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-23\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-08\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-01-10\n#COMPILER=gcc-7.3.0\n#COMPILER=intel-18.0.4\n\n#Recommended default according to where \"modules\" is currently symlinked\nMODULES=modules\nCOMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\nmodule purge\nmodule unuse ${MODULEPATH}\nmodule use /nopt/nrel/ecom/hpacf/binaries/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/compilers/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/utilities/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}\nmodule load gcc\nmodule load git\nmodule load python\n#etc...\n\n#------------------------------------------\n</code></pre>\n<p>If <code>module avail</code> does not show the modules on Eagle, try removing the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>\n<p>Also included in this directory is a recommended Spack configurations you can use to build your own packages on the machines supported at NREL. Once you have <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code> which should copy the yaml files into your instance of Spack. Or you can copy the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack compilers</code> should then show you many available compilers. Source your Spack's <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code> in your <code>.bashrc</code> so that your Spack instance will add its own module path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack compilers</code> doesn't show you the updated list of compilers. The <code>~/.spack</code> directory takes highest precendence in the Spack configuration.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1620232443.0
    },
    {
        "data_format": 2,
        "description": "Spack support for SeisSol and related tools",
        "filenames": [
            "deployment/env-utils-image/templates/spack.yaml.t",
            "deployment/default-env-utils-images/image-files/amd64/spack.yaml",
            "deployment/default-env-utils-images/image-files/arm64/spack.yaml"
        ],
        "full_name": "SeisSol/seissol-spack-aid",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>spack</h1>\n<p>Spack support for SeisSol and related tools</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1619723394.0
    },
    {
        "data_format": 2,
        "description": "Sonata is a Mochi service for JSON document storage. It is based on UnQLite and Thallium.",
        "filenames": [
            "spack.yaml",
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-sonata",
        "latest_release": "v0.6.2",
        "readme": "<h1>\n<a id=\"user-content-what-is-sonata\" class=\"anchor\" href=\"#what-is-sonata\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What is Sonata?</h1>\n<p>Sonata is a remotely-accessibl JSON document store based on UnQLite and on\nthe Mochi suit of libraries. It enables managing collections of JSON records,\nsearching through them, and running Jx9 scripts on them.</p>\n<h1>\n<a id=\"user-content-got-some-examples\" class=\"anchor\" href=\"#got-some-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Got some examples?</h1>\n<p>A comprehensive set of examples is available in <a href=\"examples\">this directory</a>.</p>\n<h1>\n<a id=\"user-content-how-do-i-install-sonata\" class=\"anchor\" href=\"#how-do-i-install-sonata\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How do I install Sonata?</h1>\n<p>The easiest way to install Sonata is to use <a href=\"https://spack.readthedocs.io\" rel=\"nofollow\">spack</a>.\nOnce you have spack installed and setup on your machine, you need to added the\nmochi namespace to it, as follows.</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>You can now install Sonata as follows.</p>\n<pre><code>spack install mochi-sonata\n</code></pre>\n<h1>\n<a id=\"user-content-and-then\" class=\"anchor\" href=\"#and-then\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>And then?</h1>\n<p>Sonata comes in three libraries: sonata-server, sonata-client, and sonata-admin.\nThe server library contains the <code>sonata::Provider</code> class, which allows to start\na Sonata service on a server program. The admin library contains the\n<code>sonata::Admin</code> class, which enables creating and destroying database on a\nrunning provider. The <code>sonata::Client</code> class is contained in the client library.\nThis class provides the main interface to open a database, and manipulat\ncollections.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1619728396.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "eugeneswalker/exawind-containers",
        "latest_release": null,
        "readme": "<h2>\n<a id=\"user-content-working-with-the-docker-image-ecpe4sexawindlatest\" class=\"anchor\" href=\"#working-with-the-docker-image-ecpe4sexawindlatest\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Working with the Docker image (ecpe4s/exawind:latest)</h2>\n<ol>\n<li>Build the Docker image</li>\n</ol>\n<pre><code>$&gt; ./build-docker-image.sh\n</code></pre>\n<ol start=\"2\">\n<li>Launch a container from the image</li>\n</ol>\n<pre><code>$&gt; docker run -it --rm ecpe4s/exawind\n\nroot@8df184bdac63:/# which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nroot@8df184bdac63:/# which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n</code></pre>\n<h2>\n<a id=\"user-content-working-with-the-singularity-image-exawindsif\" class=\"anchor\" href=\"#working-with-the-singularity-image-exawindsif\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Working with the Singularity image (exawind.sif)</h2>\n<ol>\n<li>Build the Docker image:</li>\n</ol>\n<pre><code>$&gt; ./build-docker-image.sh\n</code></pre>\n<ol start=\"2\">\n<li>Build the Singularity image:</li>\n</ol>\n<pre><code>$&gt; ./build-singularity-image.sh\n</code></pre>\n<ol start=\"3\">\n<li>Run the Singularity image:</li>\n</ol>\n<pre><code>$&gt; ./exawind.sif\n\nExawind Singularity&gt; which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nExawind Singularity&gt; which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n</code></pre>\n<h2>\n<a id=\"user-content-run-selected-exawind-regression-tests\" class=\"anchor\" href=\"#run-selected-exawind-regression-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Run Selected ExaWind Regression Tests</h2>\n<ol>\n<li>\n<p>Launch a container using either the Docker or Singularity image (see above)</p>\n</li>\n<li>\n<p>Clone this repository in the newly launched container and run the tests (here illustrated with Singularity)</p>\n</li>\n</ol>\n<pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers ~/exawind-containers\nExawind Singularity&gt; cd ~/exawind-containers/demo\n\n\nExawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh\nPASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15\n\n\nExawind Singularity&gt; ./run-nalu-wind-tests.sh\nPASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11\nPASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13\n...\n\n\nExawind Singularity&gt; ./run-amr-wind-tests.sh\nfinished abl_bndry_output\nfinished abl_godunov\n...\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619816372.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "nyx/inputs/spack/spack.yaml"
        ],
        "full_name": "m-s-will/nyx",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-nyx-with-ascent-in-container\" class=\"anchor\" href=\"#nyx-with-ascent-in-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Nyx with Ascent in Container</h1>\n<p>This project contains a Dockerfile and all necessary components to create a Docker container for Nyx.\nThe container is available on <a href=\"https://hub.docker.com/repository/docker/mswill/elwe_nyx\" rel=\"nofollow\">Dockerhub</a>, however these versions may not always be up to date.</p>\n<h2>\n<a id=\"user-content-building-the-container\" class=\"anchor\" href=\"#building-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the container</h2>\n<p>The Ascent actions can be changed by editing <a href=\"https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml\">ascent_actions.yaml</a>.\nWhen finished with the customization, the container can be rebuilt by navigating into the source directory and executing:</p>\n<pre><code>$ docker build -t &lt;mytag&gt; .\n</code></pre>\n<p>The Nyx simulation is being run during container creation and provides a Cinema database.</p>\n<h2>\n<a id=\"user-content-running-the-container\" class=\"anchor\" href=\"#running-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the container</h2>\n<p>After either pulling or building the container, it can be run by calling:</p>\n<pre><code>$ docker run -p 80:80 &lt;mytag&gt;.\n</code></pre>\n<p><code>-p 80:80</code> makes port 80 available on the outside which is needed for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code> in our browser.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619477496.0
    },
    {
        "data_format": 2,
        "description": "Singularity recipe for Octave",
        "filenames": [
            "6.2.0/spack.yaml"
        ],
        "full_name": "icaoberg/singularity-octave",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-singularity-octave\" class=\"anchor\" href=\"#singularity-octave\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>singularity-octave</h1>\n<p><a href=\"https://www.travis-ci.com/icaoberg/singularity-octave\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2ee2520b43fa597d24d8c42ccae9e2d15ea0e54a927d5b90207cde03bd895e9c/68747470733a2f2f7777772e7472617669732d63692e636f6d2f6963616f626572672f73696e67756c61726974792d6f63746176652e7376673f6272616e63683d6d61696e\" alt=\"Build Status\" data-canonical-src=\"https://www.travis-ci.com/icaoberg/singularity-octave.svg?branch=main\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" alt=\"Octave\" data-canonical-src=\"https://www.gnu.org/software/octave/img/GNU_Octave_4-4-0_screenshot_1600x900.png\" style=\"max-width:100%;\"></a></p>\n<p>Singularity recipe for <a href=\"https://www.gnu.org/software/octave/\" rel=\"nofollow\">octave</a>.</p>\n<h2>\n<a id=\"user-content-building-the-image-using-the-recipe\" class=\"anchor\" href=\"#building-the-image-using-the-recipe\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the image using the recipe</h2>\n<h3>\n<a id=\"user-content-to-build-the-image-locally\" class=\"anchor\" href=\"#to-build-the-image-locally\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the image locally</h3>\n<p>Run the script <code>build.sh</code> to build image locally.</p>\n<pre><code>bash ./build.sh\n</code></pre>\n<h3>\n<a id=\"user-content-to-build-the-image-remotely\" class=\"anchor\" href=\"#to-build-the-image-remotely\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the image remotely</h3>\n<p>Run the script <code>rbuild.sh</code> to build image locally.</p>\n<pre><code>bash ./build.sh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-the-container-on-bridges-or-similar\" class=\"anchor\" href=\"#installing-the-container-on-bridges-or-similar\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing the container on Bridges (or similar)</h2>\n<p>Copy the</p>\n<ul>\n<li>\n<code>SIF</code> file</li>\n<li>and the <code>octave</code> and <code>octave-gui</code> scripts</li>\n</ul>\n<p>to <code>/opt/packages/octave/6.2.0</code>.</p>\n<p>Copy the file <code>modulefile.lua</code> to <code>/opt/modules/octave</code> as <code>6.2.0.lua</code>.</p>\n<hr>\n<p>Copyright \u00a9 2021 Pittsburgh Supercomputing Center. All Rights Reserved.</p>\n<p><a href=\"http://www.andrew.cmu.edu/~icaoberg\" rel=\"nofollow\">icaoberg</a> at the <a href=\"http://www.psc.edu\" rel=\"nofollow\">Pittsburgh Supercomputing Center</a> in the <a href=\"https://www.cmu.edu/mcs/\" rel=\"nofollow\">Mellon College of Science</a> at <a href=\"http://www.cmu.edu\" rel=\"nofollow\">Carnegie Mellon University</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [
            "singularity",
            "octave",
            "singularity-recipe"
        ],
        "updated_at": 1619522434.0
    },
    {
        "data_format": 2,
        "description": "simple margo-projected keyval service",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-sdskv",
        "latest_release": "v0.1.13",
        "readme": "<h1>\n<a id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" href=\"#sdskv-sds-keyval\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SDSKV (SDS Key/Val)</h1>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>SDSKV can easily be installed using Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n<p>This will install SDSKV (and any required dependencies).\nAvailable backends will be <em>Map</em> (in-memory C++ std::map, useful for testing)\nand BwTree (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code> and <code>+leveldb</code> respectively. For example:</p>\n<p><code>spack install sdskeyval+bdb+leveldb</code></p>\n<p>Note that if you are using a system boost path in spack (in your\npackages.yaml) rather than letting spack build boost, then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages on\nyour system.</p>\n<h2>\n<a id=\"user-content-architecture\" class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>List most mochi services, SDSKV relies on a client/provider architecture.\nA provider, identified by its <em>address</em> and <em>multiplex id</em>, manages one or more\ndatabases, referenced externally by their database id.</p>\n<h2>\n<a id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>SDSKV ships with a default daemon program that can setup providers and\ndatabases. This daemon can be started as follows:</p>\n<p><code>sdskv-server-daemon [OPTIONS] &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb] &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb] ...</code></p>\n<p>For example:</p>\n<p><code>sdskv-server-daemon tcp://localhost:1234 foo:bdb bar</code></p>\n<p>listen_addr is the address at which to listen; database names should be provided in the form\n<em>name:type</em> where <em>type</em> is <em>map</em> (std::map), <em>bwt</em> (BwTree), <em>bdb</em> (Berkeley DB), or <em>ldb</em> (LevelDB).</p>\n<p>For database that are persistent like BerkeleyDB or LevelDB, the name should be a path to the\nfile where the database will be put (this file should not exist).</p>\n<p>The following additional options are accepted:</p>\n<ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (providers or databases).</li>\n</ul>\n<p>The providers mode indicates that, if multiple SDSKV databases are used (as above),\nthese databases should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\nto manage. The targets mode indicates that a single provider should be used to\nmanage all the databases. This provider will be accessible at multiplex id 1.</p>\n<h2>\n<a id=\"user-content-client-api\" class=\"anchor\" href=\"#client-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client API</h2>\n<p>The client API is available in <em>sdskv-client.h</em>.\nThe codes in the <em>test</em> folder illustrate how to use it.</p>\n<h2>\n<a id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider API</h2>\n<p>The server-side API is available in <em>sdskv-server.h</em>.\nThe code of the daemon (<em>src/sdskv-server-daemon.c</em>) can be used as an example.</p>\n<h3>\n<a id=\"user-content-custom-key-comparison-function\" class=\"anchor\" href=\"#custom-key-comparison-function\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Custom key comparison function</h3>\n<p>It is possible to specify a custom function for comparing/sorting keys\nwhen creating a provider. A comparison function must have the following prototype:</p>\n<p><code>int (*)(const void* key1, size_t keysize1, const void* key2, size_t keysize2)</code></p>\n<p>Its return value must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0 if key1 &gt; key2.\nIt must define a total order of the key space.</p>\n<h2>\n<a id=\"user-content-c-api\" class=\"anchor\" href=\"#c-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ API</h2>\n<p>An object-oriented C++ API is available in <code>sdskv-client.hpp</code> and <code>sdskv-server.hpp</code>.\nOn the client side this API provides the <code>client</code>, <code>provider_handle</code>, and <code>database</code> objects.\nExamples of usage of these objects can be found in the <code>test/sdskv-cxx-test.cc</code>.\nOn the server side, this API provides a <code>provider</code> object.</p>\n<h2>\n<a id=\"user-content-benchmark\" class=\"anchor\" href=\"#benchmark\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Benchmark</h2>\n<p>SDSKV can be compiled with <code>--enable-benchmark</code> (or <code>+benchmark</code> in Spack). In this case,\nSDSKV requires the JsonCPP and MPI dependencies (when compiling manually, use <code>CXX=mpicxx</code> in\nyour configure step, for example), and it will build and install the <code>sdskv-benchmark</code> program.</p>\n<p>This program is an MPI program that reads a JSON file describing a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server. Other ranks act as clients, all executing\nthis access pattern.</p>\n<p>The following is an example of a JSON file.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>protocol<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>seed<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>server<span class=\"pl-pds\">\"</span></span> : {\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>use-progress-thread<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rpc-thread-count<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>database<span class=\"pl-pds\">\"</span></span> : {\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>path<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/dev/shm<span class=\"pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmarks<span class=\"pl-pds\">\"</span></span> : [\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">24</span>, <span class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>get<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">64</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">128</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n<p>The JSON file starts with the protocol to use, and a seed for the random-number generator (RNG).\nThe actual seed used on each rank will actually be a function of this global seed and the rank of\nthe client. The RNG will be reset with this seed after each benchmark.</p>\n<p>The <code>server</code> field sets up the provider and the database. Database types can be <code>map</code>, <code>ldb</code>, or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which is a list of benchmarks to execute. Each benchmark is composed\nof three steps. A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em> phase. The setup phase may for\nexample store a bunch of keys in the database that the execution phase will read by (in the case of a\n<em>get</em> benchmark, for example). The teardown phase will usually remove all the keys that were written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n<p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>, <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n<code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>), and a number of repetitions. The benchmark will be\nexecuted as many times as requested (without resetting the RNG in between repetitions). Taking the\nexample of the <code>put</code> benchmark above, each repetition will put 30 key/value pairs into the database.\nThe key size will be chosen randomly in a uniform manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded). Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI barrier between clients is executed in between each benchmark and in between the setup,\nexecution, and teardown phases, so that the execution phase is always executed at the same time\non all the clients. Once all the repetitions are done for a given benchmark entry, the program\nwill report statistics on the timings: average time, variance, standard deviation, mininum, maximum,\nmedian, first and third quartiles. Note that these times are for a repetition, not for single operations\nwithin a repetition. To get the timing of each individual operation, it is then necessary to divide\nthe times by the number of key/value pairs involved in the benchmark.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1620851629.0
    },
    {
        "data_format": 2,
        "description": "Sonata is a Mochi service for JSON document storage. It is based on UnQLite and Thallium.",
        "filenames": [
            "spack.yaml",
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-sonata",
        "latest_release": "v0.6.2",
        "readme": "<h1>\n<a id=\"user-content-what-is-sonata\" class=\"anchor\" href=\"#what-is-sonata\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What is Sonata?</h1>\n<p>Sonata is a remotely-accessibl JSON document store based on UnQLite and on\nthe Mochi suit of libraries. It enables managing collections of JSON records,\nsearching through them, and running Jx9 scripts on them.</p>\n<h1>\n<a id=\"user-content-got-some-examples\" class=\"anchor\" href=\"#got-some-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Got some examples?</h1>\n<p>A comprehensive set of examples is available in <a href=\"examples\">this directory</a>.</p>\n<h1>\n<a id=\"user-content-how-do-i-install-sonata\" class=\"anchor\" href=\"#how-do-i-install-sonata\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How do I install Sonata?</h1>\n<p>The easiest way to install Sonata is to use <a href=\"https://spack.readthedocs.io\" rel=\"nofollow\">spack</a>.\nOnce you have spack installed and setup on your machine, you need to added the\nmochi namespace to it, as follows.</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>You can now install Sonata as follows.</p>\n<pre><code>spack install mochi-sonata\n</code></pre>\n<h1>\n<a id=\"user-content-and-then\" class=\"anchor\" href=\"#and-then\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>And then?</h1>\n<p>Sonata comes in three libraries: sonata-server, sonata-client, and sonata-admin.\nThe server library contains the <code>sonata::Provider</code> class, which allows to start\na Sonata service on a server program. The admin library contains the\n<code>sonata::Admin</code> class, which enables creating and destroying database on a\nrunning provider. The <code>sonata::Client</code> class is contained in the client library.\nThis class provides the main interface to open a database, and manipulat\ncollections.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1619728396.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "eugeneswalker/exawind-containers",
        "latest_release": null,
        "readme": "<h2>\n<a id=\"user-content-working-with-the-docker-image-ecpe4sexawindlatest\" class=\"anchor\" href=\"#working-with-the-docker-image-ecpe4sexawindlatest\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Working with the Docker image (ecpe4s/exawind:latest)</h2>\n<ol>\n<li>Build the Docker image</li>\n</ol>\n<pre><code>$&gt; ./build-docker-image.sh\n</code></pre>\n<ol start=\"2\">\n<li>Launch a container from the image</li>\n</ol>\n<pre><code>$&gt; docker run -it --rm ecpe4s/exawind\n\nroot@8df184bdac63:/# which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nroot@8df184bdac63:/# which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n</code></pre>\n<h2>\n<a id=\"user-content-working-with-the-singularity-image-exawindsif\" class=\"anchor\" href=\"#working-with-the-singularity-image-exawindsif\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Working with the Singularity image (exawind.sif)</h2>\n<ol>\n<li>Build the Docker image:</li>\n</ol>\n<pre><code>$&gt; ./build-docker-image.sh\n</code></pre>\n<ol start=\"2\">\n<li>Build the Singularity image:</li>\n</ol>\n<pre><code>$&gt; ./build-singularity-image.sh\n</code></pre>\n<ol start=\"3\">\n<li>Run the Singularity image:</li>\n</ol>\n<pre><code>$&gt; ./exawind.sif\n\nExawind Singularity&gt; which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nExawind Singularity&gt; which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n</code></pre>\n<h2>\n<a id=\"user-content-run-selected-exawind-regression-tests\" class=\"anchor\" href=\"#run-selected-exawind-regression-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Run Selected ExaWind Regression Tests</h2>\n<ol>\n<li>\n<p>Launch a container using either the Docker or Singularity image (see above)</p>\n</li>\n<li>\n<p>Clone this repository in the newly launched container and run the tests (here illustrated with Singularity)</p>\n</li>\n</ol>\n<pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers ~/exawind-containers\nExawind Singularity&gt; cd ~/exawind-containers/demo\n\n\nExawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh\nPASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15\n\n\nExawind Singularity&gt; ./run-nalu-wind-tests.sh\nPASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11\nPASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13\n...\n\n\nExawind Singularity&gt; ./run-amr-wind-tests.sh\nfinished abl_bndry_output\nfinished abl_godunov\n...\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619816372.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "nyx/inputs/spack/spack.yaml"
        ],
        "full_name": "m-s-will/nyx",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-nyx-with-ascent-in-container\" class=\"anchor\" href=\"#nyx-with-ascent-in-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Nyx with Ascent in Container</h1>\n<p>This project contains a Dockerfile and all necessary components to create a Docker container for Nyx.\nThe container is available on <a href=\"https://hub.docker.com/repository/docker/mswill/elwe_nyx\" rel=\"nofollow\">Dockerhub</a>, however these versions may not always be up to date.</p>\n<h2>\n<a id=\"user-content-building-the-container\" class=\"anchor\" href=\"#building-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the container</h2>\n<p>The Ascent actions can be changed by editing <a href=\"https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml\">ascent_actions.yaml</a>.\nWhen finished with the customization, the container can be rebuilt by navigating into the source directory and executing:</p>\n<pre><code>$ docker build -t &lt;mytag&gt; .\n</code></pre>\n<p>The Nyx simulation is being run during container creation and provides a Cinema database.</p>\n<h2>\n<a id=\"user-content-running-the-container\" class=\"anchor\" href=\"#running-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the container</h2>\n<p>After either pulling or building the container, it can be run by calling:</p>\n<pre><code>$ docker run -p 80:80 &lt;mytag&gt;.\n</code></pre>\n<p><code>-p 80:80</code> makes port 80 available on the outside which is needed for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code> in our browser.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619477496.0
    },
    {
        "data_format": 2,
        "description": "Singularity recipe for Octave",
        "filenames": [
            "6.2.0/spack.yaml"
        ],
        "full_name": "icaoberg/singularity-octave",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-singularity-octave\" class=\"anchor\" href=\"#singularity-octave\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>singularity-octave</h1>\n<p><a href=\"https://www.travis-ci.com/icaoberg/singularity-octave\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2ee2520b43fa597d24d8c42ccae9e2d15ea0e54a927d5b90207cde03bd895e9c/68747470733a2f2f7777772e7472617669732d63692e636f6d2f6963616f626572672f73696e67756c61726974792d6f63746176652e7376673f6272616e63683d6d61696e\" alt=\"Build Status\" data-canonical-src=\"https://www.travis-ci.com/icaoberg/singularity-octave.svg?branch=main\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" alt=\"Octave\" data-canonical-src=\"https://www.gnu.org/software/octave/img/GNU_Octave_4-4-0_screenshot_1600x900.png\" style=\"max-width:100%;\"></a></p>\n<p>Singularity recipe for <a href=\"https://www.gnu.org/software/octave/\" rel=\"nofollow\">octave</a>.</p>\n<h2>\n<a id=\"user-content-building-the-image-using-the-recipe\" class=\"anchor\" href=\"#building-the-image-using-the-recipe\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the image using the recipe</h2>\n<h3>\n<a id=\"user-content-to-build-the-image-locally\" class=\"anchor\" href=\"#to-build-the-image-locally\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the image locally</h3>\n<p>Run the script <code>build.sh</code> to build image locally.</p>\n<pre><code>bash ./build.sh\n</code></pre>\n<h3>\n<a id=\"user-content-to-build-the-image-remotely\" class=\"anchor\" href=\"#to-build-the-image-remotely\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the image remotely</h3>\n<p>Run the script <code>rbuild.sh</code> to build image locally.</p>\n<pre><code>bash ./build.sh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-the-container-on-bridges-or-similar\" class=\"anchor\" href=\"#installing-the-container-on-bridges-or-similar\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing the container on Bridges (or similar)</h2>\n<p>Copy the</p>\n<ul>\n<li>\n<code>SIF</code> file</li>\n<li>and the <code>octave</code> and <code>octave-gui</code> scripts</li>\n</ul>\n<p>to <code>/opt/packages/octave/6.2.0</code>.</p>\n<p>Copy the file <code>modulefile.lua</code> to <code>/opt/modules/octave</code> as <code>6.2.0.lua</code>.</p>\n<hr>\n<p>Copyright \u00a9 2021 Pittsburgh Supercomputing Center. All Rights Reserved.</p>\n<p><a href=\"http://www.andrew.cmu.edu/~icaoberg\" rel=\"nofollow\">icaoberg</a> at the <a href=\"http://www.psc.edu\" rel=\"nofollow\">Pittsburgh Supercomputing Center</a> in the <a href=\"https://www.cmu.edu/mcs/\" rel=\"nofollow\">Mellon College of Science</a> at <a href=\"http://www.cmu.edu\" rel=\"nofollow\">Carnegie Mellon University</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [
            "singularity",
            "octave",
            "singularity-recipe"
        ],
        "updated_at": 1619522434.0
    },
    {
        "data_format": 2,
        "description": "simple margo-projected keyval service",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-sdskv",
        "latest_release": "v0.1.13",
        "readme": "<h1>\n<a id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" href=\"#sdskv-sds-keyval\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SDSKV (SDS Key/Val)</h1>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>SDSKV can easily be installed using Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n<p>This will install SDSKV (and any required dependencies).\nAvailable backends will be <em>Map</em> (in-memory C++ std::map, useful for testing)\nand BwTree (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code> and <code>+leveldb</code> respectively. For example:</p>\n<p><code>spack install sdskeyval+bdb+leveldb</code></p>\n<p>Note that if you are using a system boost path in spack (in your\npackages.yaml) rather than letting spack build boost, then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages on\nyour system.</p>\n<h2>\n<a id=\"user-content-architecture\" class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>List most mochi services, SDSKV relies on a client/provider architecture.\nA provider, identified by its <em>address</em> and <em>multiplex id</em>, manages one or more\ndatabases, referenced externally by their database id.</p>\n<h2>\n<a id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>SDSKV ships with a default daemon program that can setup providers and\ndatabases. This daemon can be started as follows:</p>\n<p><code>sdskv-server-daemon [OPTIONS] &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb] &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb] ...</code></p>\n<p>For example:</p>\n<p><code>sdskv-server-daemon tcp://localhost:1234 foo:bdb bar</code></p>\n<p>listen_addr is the address at which to listen; database names should be provided in the form\n<em>name:type</em> where <em>type</em> is <em>map</em> (std::map), <em>bwt</em> (BwTree), <em>bdb</em> (Berkeley DB), or <em>ldb</em> (LevelDB).</p>\n<p>For database that are persistent like BerkeleyDB or LevelDB, the name should be a path to the\nfile where the database will be put (this file should not exist).</p>\n<p>The following additional options are accepted:</p>\n<ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (providers or databases).</li>\n</ul>\n<p>The providers mode indicates that, if multiple SDSKV databases are used (as above),\nthese databases should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\nto manage. The targets mode indicates that a single provider should be used to\nmanage all the databases. This provider will be accessible at multiplex id 1.</p>\n<h2>\n<a id=\"user-content-client-api\" class=\"anchor\" href=\"#client-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client API</h2>\n<p>The client API is available in <em>sdskv-client.h</em>.\nThe codes in the <em>test</em> folder illustrate how to use it.</p>\n<h2>\n<a id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider API</h2>\n<p>The server-side API is available in <em>sdskv-server.h</em>.\nThe code of the daemon (<em>src/sdskv-server-daemon.c</em>) can be used as an example.</p>\n<h3>\n<a id=\"user-content-custom-key-comparison-function\" class=\"anchor\" href=\"#custom-key-comparison-function\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Custom key comparison function</h3>\n<p>It is possible to specify a custom function for comparing/sorting keys\nwhen creating a provider. A comparison function must have the following prototype:</p>\n<p><code>int (*)(const void* key1, size_t keysize1, const void* key2, size_t keysize2)</code></p>\n<p>Its return value must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0 if key1 &gt; key2.\nIt must define a total order of the key space.</p>\n<h2>\n<a id=\"user-content-c-api\" class=\"anchor\" href=\"#c-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ API</h2>\n<p>An object-oriented C++ API is available in <code>sdskv-client.hpp</code> and <code>sdskv-server.hpp</code>.\nOn the client side this API provides the <code>client</code>, <code>provider_handle</code>, and <code>database</code> objects.\nExamples of usage of these objects can be found in the <code>test/sdskv-cxx-test.cc</code>.\nOn the server side, this API provides a <code>provider</code> object.</p>\n<h2>\n<a id=\"user-content-benchmark\" class=\"anchor\" href=\"#benchmark\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Benchmark</h2>\n<p>SDSKV can be compiled with <code>--enable-benchmark</code> (or <code>+benchmark</code> in Spack). In this case,\nSDSKV requires the JsonCPP and MPI dependencies (when compiling manually, use <code>CXX=mpicxx</code> in\nyour configure step, for example), and it will build and install the <code>sdskv-benchmark</code> program.</p>\n<p>This program is an MPI program that reads a JSON file describing a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server. Other ranks act as clients, all executing\nthis access pattern.</p>\n<p>The following is an example of a JSON file.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>protocol<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>seed<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>server<span class=\"pl-pds\">\"</span></span> : {\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>use-progress-thread<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rpc-thread-count<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>database<span class=\"pl-pds\">\"</span></span> : {\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>path<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/dev/shm<span class=\"pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmarks<span class=\"pl-pds\">\"</span></span> : [\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">24</span>, <span class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>get<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">64</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">128</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n<p>The JSON file starts with the protocol to use, and a seed for the random-number generator (RNG).\nThe actual seed used on each rank will actually be a function of this global seed and the rank of\nthe client. The RNG will be reset with this seed after each benchmark.</p>\n<p>The <code>server</code> field sets up the provider and the database. Database types can be <code>map</code>, <code>ldb</code>, or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which is a list of benchmarks to execute. Each benchmark is composed\nof three steps. A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em> phase. The setup phase may for\nexample store a bunch of keys in the database that the execution phase will read by (in the case of a\n<em>get</em> benchmark, for example). The teardown phase will usually remove all the keys that were written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n<p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>, <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n<code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>), and a number of repetitions. The benchmark will be\nexecuted as many times as requested (without resetting the RNG in between repetitions). Taking the\nexample of the <code>put</code> benchmark above, each repetition will put 30 key/value pairs into the database.\nThe key size will be chosen randomly in a uniform manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded). Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI barrier between clients is executed in between each benchmark and in between the setup,\nexecution, and teardown phases, so that the execution phase is always executed at the same time\non all the clients. Once all the repetitions are done for a given benchmark entry, the program\nwill report statistics on the timings: average time, variance, standard deviation, mininum, maximum,\nmedian, first and third quartiles. Note that these times are for a repetition, not for single operations\nwithin a repetition. To get the timing of each individual operation, it is then necessary to divide\nthe times by the number of key/value pairs involved in the benchmark.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1620851629.0
    },
    {
        "data_format": 2,
        "description": "Sonata is a Mochi service for JSON document storage. It is based on UnQLite and Thallium.",
        "filenames": [
            "spack.yaml",
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-sonata",
        "latest_release": "v0.6.2",
        "readme": "<h1>\n<a id=\"user-content-what-is-sonata\" class=\"anchor\" href=\"#what-is-sonata\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What is Sonata?</h1>\n<p>Sonata is a remotely-accessibl JSON document store based on UnQLite and on\nthe Mochi suit of libraries. It enables managing collections of JSON records,\nsearching through them, and running Jx9 scripts on them.</p>\n<h1>\n<a id=\"user-content-got-some-examples\" class=\"anchor\" href=\"#got-some-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Got some examples?</h1>\n<p>A comprehensive set of examples is available in <a href=\"examples\">this directory</a>.</p>\n<h1>\n<a id=\"user-content-how-do-i-install-sonata\" class=\"anchor\" href=\"#how-do-i-install-sonata\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How do I install Sonata?</h1>\n<p>The easiest way to install Sonata is to use <a href=\"https://spack.readthedocs.io\" rel=\"nofollow\">spack</a>.\nOnce you have spack installed and setup on your machine, you need to added the\nmochi namespace to it, as follows.</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>You can now install Sonata as follows.</p>\n<pre><code>spack install mochi-sonata\n</code></pre>\n<h1>\n<a id=\"user-content-and-then\" class=\"anchor\" href=\"#and-then\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>And then?</h1>\n<p>Sonata comes in three libraries: sonata-server, sonata-client, and sonata-admin.\nThe server library contains the <code>sonata::Provider</code> class, which allows to start\na Sonata service on a server program. The admin library contains the\n<code>sonata::Admin</code> class, which enables creating and destroying database on a\nrunning provider. The <code>sonata::Client</code> class is contained in the client library.\nThis class provides the main interface to open a database, and manipulat\ncollections.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1619728396.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "eugeneswalker/exawind-containers",
        "latest_release": null,
        "readme": "<h2>\n<a id=\"user-content-working-with-the-docker-image-ecpe4sexawindlatest\" class=\"anchor\" href=\"#working-with-the-docker-image-ecpe4sexawindlatest\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Working with the Docker image (ecpe4s/exawind:latest)</h2>\n<ol>\n<li>Build the Docker image</li>\n</ol>\n<pre><code>$&gt; ./build-docker-image.sh\n</code></pre>\n<ol start=\"2\">\n<li>Launch a container from the image</li>\n</ol>\n<pre><code>$&gt; docker run -it --rm ecpe4s/exawind\n\nroot@8df184bdac63:/# which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nroot@8df184bdac63:/# which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n</code></pre>\n<h2>\n<a id=\"user-content-working-with-the-singularity-image-exawindsif\" class=\"anchor\" href=\"#working-with-the-singularity-image-exawindsif\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Working with the Singularity image (exawind.sif)</h2>\n<ol>\n<li>Build the Docker image:</li>\n</ol>\n<pre><code>$&gt; ./build-docker-image.sh\n</code></pre>\n<ol start=\"2\">\n<li>Build the Singularity image:</li>\n</ol>\n<pre><code>$&gt; ./build-singularity-image.sh\n</code></pre>\n<ol start=\"3\">\n<li>Run the Singularity image:</li>\n</ol>\n<pre><code>$&gt; ./exawind.sif\n\nExawind Singularity&gt; which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nExawind Singularity&gt; which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n</code></pre>\n<h2>\n<a id=\"user-content-run-selected-exawind-regression-tests\" class=\"anchor\" href=\"#run-selected-exawind-regression-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Run Selected ExaWind Regression Tests</h2>\n<ol>\n<li>\n<p>Launch a container using either the Docker or Singularity image (see above)</p>\n</li>\n<li>\n<p>Clone this repository in the newly launched container and run the tests (here illustrated with Singularity)</p>\n</li>\n</ol>\n<pre><code>Exawind Singularity&gt; git clone https://github.com/eugeneswalker/exawind-containers ~/exawind-containers\nExawind Singularity&gt; cd ~/exawind-containers/demo\n\n\nExawind Singularity&gt; ./run-nonIsoEdgeOpenJet.sh\nPASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15\n\n\nExawind Singularity&gt; ./run-nalu-wind-tests.sh\nPASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11\nPASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13\n...\n\n\nExawind Singularity&gt; ./run-amr-wind-tests.sh\nfinished abl_bndry_output\nfinished abl_godunov\n...\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619816372.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "nyx/inputs/spack/spack.yaml"
        ],
        "full_name": "m-s-will/nyx",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-nyx-with-ascent-in-container\" class=\"anchor\" href=\"#nyx-with-ascent-in-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Nyx with Ascent in Container</h1>\n<p>This project contains a Dockerfile and all necessary components to create a Docker container for Nyx.\nThe container is available on <a href=\"https://hub.docker.com/repository/docker/mswill/elwe_nyx\" rel=\"nofollow\">Dockerhub</a>, however these versions may not always be up to date.</p>\n<h2>\n<a id=\"user-content-building-the-container\" class=\"anchor\" href=\"#building-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the container</h2>\n<p>The Ascent actions can be changed by editing <a href=\"https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml\">ascent_actions.yaml</a>.\nWhen finished with the customization, the container can be rebuilt by navigating into the source directory and executing:</p>\n<pre><code>$ docker build -t &lt;mytag&gt; .\n</code></pre>\n<p>The Nyx simulation is being run during container creation and provides a Cinema database.</p>\n<h2>\n<a id=\"user-content-running-the-container\" class=\"anchor\" href=\"#running-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the container</h2>\n<p>After either pulling or building the container, it can be run by calling:</p>\n<pre><code>$ docker run -p 80:80 &lt;mytag&gt;.\n</code></pre>\n<p><code>-p 80:80</code> makes port 80 available on the outside which is needed for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code> in our browser.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619477496.0
    },
    {
        "data_format": 2,
        "description": "Singularity recipe for Octave",
        "filenames": [
            "6.2.0/spack.yaml"
        ],
        "full_name": "icaoberg/singularity-octave",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-singularity-octave\" class=\"anchor\" href=\"#singularity-octave\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>singularity-octave</h1>\n<p><a href=\"https://www.travis-ci.com/icaoberg/singularity-octave\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2ee2520b43fa597d24d8c42ccae9e2d15ea0e54a927d5b90207cde03bd895e9c/68747470733a2f2f7777772e7472617669732d63692e636f6d2f6963616f626572672f73696e67756c61726974792d6f63746176652e7376673f6272616e63683d6d61696e\" alt=\"Build Status\" data-canonical-src=\"https://www.travis-ci.com/icaoberg/singularity-octave.svg?branch=main\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" alt=\"Octave\" data-canonical-src=\"https://www.gnu.org/software/octave/img/GNU_Octave_4-4-0_screenshot_1600x900.png\" style=\"max-width:100%;\"></a></p>\n<p>Singularity recipe for <a href=\"https://www.gnu.org/software/octave/\" rel=\"nofollow\">octave</a>.</p>\n<h2>\n<a id=\"user-content-building-the-image-using-the-recipe\" class=\"anchor\" href=\"#building-the-image-using-the-recipe\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the image using the recipe</h2>\n<h3>\n<a id=\"user-content-to-build-the-image-locally\" class=\"anchor\" href=\"#to-build-the-image-locally\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the image locally</h3>\n<p>Run the script <code>build.sh</code> to build image locally.</p>\n<pre><code>bash ./build.sh\n</code></pre>\n<h3>\n<a id=\"user-content-to-build-the-image-remotely\" class=\"anchor\" href=\"#to-build-the-image-remotely\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the image remotely</h3>\n<p>Run the script <code>rbuild.sh</code> to build image locally.</p>\n<pre><code>bash ./build.sh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-the-container-on-bridges-or-similar\" class=\"anchor\" href=\"#installing-the-container-on-bridges-or-similar\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing the container on Bridges (or similar)</h2>\n<p>Copy the</p>\n<ul>\n<li>\n<code>SIF</code> file</li>\n<li>and the <code>octave</code> and <code>octave-gui</code> scripts</li>\n</ul>\n<p>to <code>/opt/packages/octave/6.2.0</code>.</p>\n<p>Copy the file <code>modulefile.lua</code> to <code>/opt/modules/octave</code> as <code>6.2.0.lua</code>.</p>\n<hr>\n<p>Copyright \u00a9 2021 Pittsburgh Supercomputing Center. All Rights Reserved.</p>\n<p><a href=\"http://www.andrew.cmu.edu/~icaoberg\" rel=\"nofollow\">icaoberg</a> at the <a href=\"http://www.psc.edu\" rel=\"nofollow\">Pittsburgh Supercomputing Center</a> in the <a href=\"https://www.cmu.edu/mcs/\" rel=\"nofollow\">Mellon College of Science</a> at <a href=\"http://www.cmu.edu\" rel=\"nofollow\">Carnegie Mellon University</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [
            "singularity",
            "octave",
            "singularity-recipe"
        ],
        "updated_at": 1619522434.0
    },
    {
        "data_format": 2,
        "description": "simple margo-projected keyval service",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-sdskv",
        "latest_release": "v0.1.13",
        "readme": "<h1>\n<a id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" href=\"#sdskv-sds-keyval\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SDSKV (SDS Key/Val)</h1>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>SDSKV can easily be installed using Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n<p>This will install SDSKV (and any required dependencies).\nAvailable backends will be <em>Map</em> (in-memory C++ std::map, useful for testing)\nand BwTree (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code> and <code>+leveldb</code> respectively. For example:</p>\n<p><code>spack install sdskeyval+bdb+leveldb</code></p>\n<p>Note that if you are using a system boost path in spack (in your\npackages.yaml) rather than letting spack build boost, then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages on\nyour system.</p>\n<h2>\n<a id=\"user-content-architecture\" class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>List most mochi services, SDSKV relies on a client/provider architecture.\nA provider, identified by its <em>address</em> and <em>multiplex id</em>, manages one or more\ndatabases, referenced externally by their database id.</p>\n<h2>\n<a id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>SDSKV ships with a default daemon program that can setup providers and\ndatabases. This daemon can be started as follows:</p>\n<p><code>sdskv-server-daemon [OPTIONS] &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb] &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb] ...</code></p>\n<p>For example:</p>\n<p><code>sdskv-server-daemon tcp://localhost:1234 foo:bdb bar</code></p>\n<p>listen_addr is the address at which to listen; database names should be provided in the form\n<em>name:type</em> where <em>type</em> is <em>map</em> (std::map), <em>bwt</em> (BwTree), <em>bdb</em> (Berkeley DB), or <em>ldb</em> (LevelDB).</p>\n<p>For database that are persistent like BerkeleyDB or LevelDB, the name should be a path to the\nfile where the database will be put (this file should not exist).</p>\n<p>The following additional options are accepted:</p>\n<ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (providers or databases).</li>\n</ul>\n<p>The providers mode indicates that, if multiple SDSKV databases are used (as above),\nthese databases should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\nto manage. The targets mode indicates that a single provider should be used to\nmanage all the databases. This provider will be accessible at multiplex id 1.</p>\n<h2>\n<a id=\"user-content-client-api\" class=\"anchor\" href=\"#client-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client API</h2>\n<p>The client API is available in <em>sdskv-client.h</em>.\nThe codes in the <em>test</em> folder illustrate how to use it.</p>\n<h2>\n<a id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider API</h2>\n<p>The server-side API is available in <em>sdskv-server.h</em>.\nThe code of the daemon (<em>src/sdskv-server-daemon.c</em>) can be used as an example.</p>\n<h3>\n<a id=\"user-content-custom-key-comparison-function\" class=\"anchor\" href=\"#custom-key-comparison-function\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Custom key comparison function</h3>\n<p>It is possible to specify a custom function for comparing/sorting keys\nwhen creating a provider. A comparison function must have the following prototype:</p>\n<p><code>int (*)(const void* key1, size_t keysize1, const void* key2, size_t keysize2)</code></p>\n<p>Its return value must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0 if key1 &gt; key2.\nIt must define a total order of the key space.</p>\n<h2>\n<a id=\"user-content-c-api\" class=\"anchor\" href=\"#c-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ API</h2>\n<p>An object-oriented C++ API is available in <code>sdskv-client.hpp</code> and <code>sdskv-server.hpp</code>.\nOn the client side this API provides the <code>client</code>, <code>provider_handle</code>, and <code>database</code> objects.\nExamples of usage of these objects can be found in the <code>test/sdskv-cxx-test.cc</code>.\nOn the server side, this API provides a <code>provider</code> object.</p>\n<h2>\n<a id=\"user-content-benchmark\" class=\"anchor\" href=\"#benchmark\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Benchmark</h2>\n<p>SDSKV can be compiled with <code>--enable-benchmark</code> (or <code>+benchmark</code> in Spack). In this case,\nSDSKV requires the JsonCPP and MPI dependencies (when compiling manually, use <code>CXX=mpicxx</code> in\nyour configure step, for example), and it will build and install the <code>sdskv-benchmark</code> program.</p>\n<p>This program is an MPI program that reads a JSON file describing a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server. Other ranks act as clients, all executing\nthis access pattern.</p>\n<p>The following is an example of a JSON file.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>protocol<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>seed<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>server<span class=\"pl-pds\">\"</span></span> : {\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>use-progress-thread<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rpc-thread-count<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>database<span class=\"pl-pds\">\"</span></span> : {\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>path<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/dev/shm<span class=\"pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmarks<span class=\"pl-pds\">\"</span></span> : [\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">24</span>, <span class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>get<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">64</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">128</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n<p>The JSON file starts with the protocol to use, and a seed for the random-number generator (RNG).\nThe actual seed used on each rank will actually be a function of this global seed and the rank of\nthe client. The RNG will be reset with this seed after each benchmark.</p>\n<p>The <code>server</code> field sets up the provider and the database. Database types can be <code>map</code>, <code>ldb</code>, or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which is a list of benchmarks to execute. Each benchmark is composed\nof three steps. A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em> phase. The setup phase may for\nexample store a bunch of keys in the database that the execution phase will read by (in the case of a\n<em>get</em> benchmark, for example). The teardown phase will usually remove all the keys that were written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n<p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>, <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n<code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>), and a number of repetitions. The benchmark will be\nexecuted as many times as requested (without resetting the RNG in between repetitions). Taking the\nexample of the <code>put</code> benchmark above, each repetition will put 30 key/value pairs into the database.\nThe key size will be chosen randomly in a uniform manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded). Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI barrier between clients is executed in between each benchmark and in between the setup,\nexecution, and teardown phases, so that the execution phase is always executed at the same time\non all the clients. Once all the repetitions are done for a given benchmark entry, the program\nwill report statistics on the timings: average time, variance, standard deviation, mininum, maximum,\nmedian, first and third quartiles. Note that these times are for a repetition, not for single operations\nwithin a repetition. To get the timing of each individual operation, it is then necessary to divide\nthe times by the number of key/value pairs involved in the benchmark.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1620851629.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "TurbulentDynamics/tdLBCpp",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-turbulent-dynamics-lattice-boltzmann-c\" class=\"anchor\" href=\"#turbulent-dynamics-lattice-boltzmann-c\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Turbulent Dynamics Lattice Boltzmann (C++)</h1>\n<p>This is a basic version of the multi-node heterogeneous HPC code to run billions of cell simulation.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1619466471.0
    },
    {
        "data_format": 2,
        "description": "Raft implementation which depends on Mochi Project and Symas LMDB",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "KoyamaSohei/raft",
        "latest_release": null,
        "readme": "<h2>\n<a id=\"user-content-raft\" class=\"anchor\" href=\"#raft\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>raft</h2>\n<p><a href=\"https://raft.github.io/\" rel=\"nofollow\">Raft</a> implementation which depends on <a href=\"https://mochi.readthedocs.io/\" rel=\"nofollow\">Mochi Project</a> and <a href=\"https://symas.com/lmdb/\" rel=\"nofollow\">Symas LMDB</a></p>\n<p>this is one of projects in <a href=\"http://www.hpcs.cs.tsukuba.ac.jp/~tatebe/lecture/r02/dpro/\" rel=\"nofollow\">\u4e3b\u5c02\u653b\u5b9f\u9a13 K-16</a></p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1612651620.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "wangzhezhe/mona-vtk",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-mona-vtk-examples\" class=\"anchor\" href=\"#mona-vtk-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>MoNA-VTK examples</h1>\n<p>This repo shows how to implement the MonaController and use it for Paraview Catalyst to do the in-situ data analytics. The <code>src</code> folder contains the implementation details of the MonaController based on the MonaCommunicator which is implemented based on <a href=\"https://github.com/mochi-hpc/mochi-mona\">mochi-mona</a>.</p>\n<p>There are several examples in the <code>example</code> folder:</p>\n<ul>\n<li>\n<p>basic: This example shows that how the MonaController can be used to execute the basic vtk parallel operations such as send and recv vtk object.</p>\n</li>\n<li>\n<p>icetExample: This exmaple shows that how the mochi-mona can be used to execute the iceT test cases based on the iceT wrapper for the mochi-mona.</p>\n</li>\n<li>\n<p>MandelbulbCatalystExample: This example shows how the MonaController can be used to execute the tightly coupled in-situ analytics in distributed way.</p>\n</li>\n<li>\n<p>MandelbulbColza: This example shows how the MonaController can be used to execute the loosely coupled in-situ analytics in distributed way, the <a href=\"https://github.com/mochi-hpc/mochi-colza\">mochi-colza</a> is used as the data staging service for this example.</p>\n</li>\n<li>\n<p>GrayScottColza: This example is similar with the MandelbulbColza case but the simulation data is generated by Gray-Scott simulation.</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n<p>We assume there is a new account on cori system, and we need following operations to install necessary depedencies</p>\n<p><strong>Spack configuration</strong></p>\n<p>There are two ways to use the Spack to install the software packages, the first one is to init the package.yaml file and the second one is to use the spack env.</p>\n<p>For example, we use <code>spack arch -p</code> to check the current architecture. If the architecture is the cray, the <code>package.yaml</code> file should locate at the <code>~/.spack/cray/</code>. And we update the <code>package.yaml</code> file as needed for installing the mochi-software stacks. One sample <code>package.yaml</code> for cori system is located in <code>./config/cori/packages.yaml</code>.</p>\n<p>The repo of the spack used by the mochi project: <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo.git\" rel=\"nofollow\">https://xgitlab.cels.anl.gov/sds/sds-repo.git</a>, we need to add this repo into the spack system by executing <code>spack repo add sds-repo</code> at the current direactly.</p>\n<p><strong>Building ParaView patch version</strong></p>\n<p>The source code of ParaView patch is located at this repo: <a href=\"https://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration\" rel=\"nofollow\">https://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration</a>.</p>\n<pre><code>git clone https://gitlab.kitware.com/mdorier/paraview.git\ncd paraview\ngit checkout ecb0a075f459c9db78bdd57bf83d715a99f0fe55\ngit submodule update --init --recursive\n</code></pre>\n<p>The ParaView needs the osmesa to support the capability of in-situ rendering. We use the osmesa installed by the spack on the cori system:</p>\n<pre><code>module load spack\nspack load -r mesa/qozjngg\nPATH=\"/global/common/cori/software/altd/2.0/bin:$PATH\"\n</code></pre>\n<p>We also need to set the compiler on the cori before building the ParaView</p>\n<pre><code># for compiling vtk on cori\nexport CRAYPE_LINK_TYPE=dynamic\n\n# let cc and CC to be the gnu compier\nmodule swap PrgEnv-intel PrgEnv-gnu\n\nmodule swap gcc/8.3.0 gcc/9.3.0\n</code></pre>\n<p>At the build direactory of the ParaView, we use cmake commands as follows (if we assume the source direactory is <code>~/cworkspace/src/ParaView_patch/paraview</code>):</p>\n<pre><code>cmake ~/cworkspace/src/ParaView_patch/paraview -DPARAVIEW_USE_QT=OFF -DPARAVIEW_USE_PYTHON=ON -DPARAVIEW_USE_MPI=ON -DVTK_OPENGL_HAS_OSMESA:BOOL=TRUE -DVTK_USE_X:BOOL=FALSE -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_PYTHON_OPTIONAL_LINK=OFF -DCMAKE_BUILD_TYPE=Release\n</code></pre>\n<p><strong>Building and installing Colza</strong></p>\n<p>This command will install the mochi-colza and other related mochi softwares</p>\n<pre><code>spack install mochi-colza@main+drc+examples%gcc@9.3.0\n</code></pre>\n<p><strong>Building all examples</strong></p>\n<p>We can load these depedencies if all packages are installed successfully. The sample commands are located in <code>config/cori/monavtkEnv.sh</code>. We execute these commands before building the mona-vtk examples.</p>\n<p>Then we can build the mona-vtk the cmake command like this:</p>\n<pre><code>cmake ~/cworkspace/src/mona-vtk/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=$SCRATCH/build_paraview_patch_release/ -DENABLE_EXAMPLE=ON -DParaView_DIR=$SCRATCH/build_paraview_patch_release/ -DBUILD_SHARED_LIBS=ON \n</code></pre>\n<h2>\n<a id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n<p>The scripts for scale evaluation are located at the <code>example/MandelbulbColza/testScripts</code> and <code>./example/GrayScottColza/testScripts</code> separately.</p>\n<p>For example, we can set the build and src dir properly at the beginning of the scripts, such as</p>\n<pre><code>BUILDDIR=/global/cscratch1/sd/zw241/build_monavtk\nSRCDIR=/global/homes/z/zw241/cworkspace/src/mona-vtk\n</code></pre>\n<p>and then use sbatch to submit jobs with specific node configurations as needed:</p>\n<pre><code>sbatch ~/cworkspace/src/mona-vtk/example/MandelbulbColza/testScripts/strongscale/cori_strongscale_mona_4.scripts\n</code></pre>\n<p>or</p>\n<pre><code>sbatch ~/cworkspace/src/mona-vtk/example/GrayScottColza/testScripts/strongscale/cori_gsstrongscale_mona_128_512.scripts\n</code></pre>\n<p>We can check the corresponding server and log file to get the particular data put and analysing time.</p>\n<p>For example, the <code>mbclient_mona_4_512.log</code> records the client information when there are 4 staging processes and 512 client pracesses.</p>\n<p>For the <code>MandelbulbColza</code> example, we can set the size of the data block by updating the <code>BLOCKLENW</code>, <code>BLOCKLENH</code> and <code>BLOCKLEND</code> in the associated script.</p>\n<p>For the <code>GrayScottColza</code> example, we can set the size of the data block by updating the <code>L</code> value at the client configuration file. For example, at the <code>client_settings_monaback_408.json</code>, we set the <code>L</code> as 408, which means there are <code>408*408*408</code> cells for each data block.</p>\n<h2>\n<a id=\"user-content-other-potential-issues\" class=\"anchor\" href=\"#other-potential-issues\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other potential issues</h2>\n<p>We could also try to install osmesa by spack manaully:</p>\n<pre><code>spack install mesa+osmesa~llvm swr=none\n</code></pre>\n<p><a href=\"https://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5\" rel=\"nofollow\">https://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5</a></p>\n<pre><code>/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so: undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023'\n</code></pre>\n<p>try this:</p>\n<p>SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")</p>\n<p>refer to</p>\n<p><a href=\"https://github.com/halide/Halide/issues/1112\">https://github.com/halide/Halide/issues/1112</a></p>\n<p>if the MPICH_GNI_NDREG_ENTRIES is not set properly\n<a href=\"https://github.com/mercury-hpc/mercury/issues/426\">https://github.com/mercury-hpc/mercury/issues/426</a></p>\n<p>some osmesa warning from paraview if it is built in the Debug mode for building paraview (it is ok when we use the Release mode to build the paraview)</p>\n<p>(  44.958s) [pvbatch.3       ]vtkOpenGLFramebufferObj:356    ERR| vtkOpenGLFramebufferObject (0x10005dc58e0): failed at glGenFramebuffers 1 OpenGL errors detected\n1:   0 : (1280) Invalid enum</p>\n<p>vtkOpenGLState.cxx:505   WARN| Error glBindFramebuffer1 OpenGL errors detected\n2:   0 : (1280) Invalid enum</p>\n<p>Try to build the paraview with the Release mode, otherwise, there are mosa related warnings</p>\n<p>For the python on cori, refer to this (<a href=\"https://docs.nersc.gov/development/languages/python/nersc-python/\" rel=\"nofollow\">https://docs.nersc.gov/development/languages/python/nersc-python/</a>)\nIf you only use the module option, but the python is not the default one, there are some issues</p>\n<p>One issue is \"unnamed python module encoding\", or other issues that have different gcc version which may cause the byte code issue\nIt is prefered to use the conda activate then the python virtual env if you not use the default python3 system on cori</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1617912788.0
    },
    {
        "data_format": 2,
        "description": "Mochi-based staging service for in situ analysis and visualization",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-colza",
        "latest_release": "v0.1",
        "readme": "",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1617665054.0
    },
    {
        "data_format": 2,
        "description": "Mochi's REsource Migration Interface",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-remi",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-resource-migration-interface\" class=\"anchor\" href=\"#resource-migration-interface\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>REsource Migration Interface</h1>\n<p>REMI is a Mochi microservice designed to handle the migration of sets of files\nfrom a node to another. It uses RDMA and memory mapping to efficiently transfer\npotentially large groups of files at once.</p>\n<h3>\n<a id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing</h3>\n<p>Just like all Mochi services, REMI can be installed using Spack. Once you have\nclone the <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">sds-repo</a> package repository\nand added it to your spack installation, you can install REMI using the following\ncommand:</p>\n<pre><code>spack install mochi-remi\n</code></pre>\n<p>REMI depends on <a href=\"https://xgitlab.cels.anl.gov/sds/thallium/\" rel=\"nofollow\">Thallium</a>, which\nSpack will install (if needed) along with Thallium's own dependencies. It also\ndepends on Bedrock, unless the <code>bedrock</code> variant is disable when installing\nwith Spack (i.e. passing <code>~bedrock</code> to the above command).</p>\n<h3>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h3>\n<p>REMI works with <em>filesets</em>. A fileset consists of a root directory and\na set of file paths relative to this root directory. A fileset is also characterized\nby the name of its <em>migration class</em>.</p>\n<p>REMI clients create filesets to group files corresponding to a particular resource\n(e.g. a database's files). They can then request the migration of fileset to\na target provider.</p>\n<p>Uppon receiving a request for migration, a provider will recreate the tree of\ndirectories required to receive the files of the fileset, create the files,\nmmap them into memory, and issue an RDMA pull operation from the client's files\n(themselves mmap-ed into the client's memory).</p>\n<p>Following successful migration, the provider will call a user-supplied callback\ncorresponding to the particular fileset's migration class.</p>\n<p>For an example of code, please see the <a href=\"examples\">examples</a>\nfolder in the source tree.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1614271878.0
    },
    {
        "data_format": 2,
        "description": "Python binding to the Mochi Sonata microservice.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/py-mochi-sonata",
        "latest_release": null,
        "readme": "<p>Py-Sonata is a Python interface for the <a href=\"https://github.com/mochi-hpc/mochi-sonata\">Sonata Mochi microservice</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1614213349.0
    },
    {
        "data_format": 2,
        "description": "Template for a thallium-based Mochi microservice.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/thallium-microservice-template",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-thallium-microservice-template\" class=\"anchor\" href=\"#thallium-microservice-template\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Thallium Microservice Template</h1>\n<p>This project is a template to start developing a Mochi microservice based on Thallium.\nThe complete documentation to get started using this template is available\n<a href=\"https://mochi.readthedocs.io/en/latest/templates/02_thallium.html\" rel=\"nofollow\">here</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1614210486.0
    },
    {
        "data_format": 2,
        "description": "Template for a margo-based Mochi microservice.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/margo-microservice-template",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-margo-microservice-template\" class=\"anchor\" href=\"#margo-microservice-template\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo Microservice Template</h1>\n<p>This project is a template to start developing a Mochi microservice based on Margo.\nThe complete documentation to get started using this template is available\n<a href=\"https://mochi.readthedocs.io/en/latest/templates/01_margo.html\" rel=\"nofollow\">here</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1614210543.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mdorier/test-ssg-cori",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h1>\n<p>Setup spack and sds-repo, clone this repository and <code>cd</code> in it, then:</p>\n<pre><code>spack env create ssg-test spack.yaml\nspack env activate ssg-test\nspack install\nspack env deactivate\n</code></pre>\n<p>Then to build the code:</p>\n<pre><code>export CRAYPE_LINK_TYPE=dynamic\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\nspack env activate ssg-test\nmkdir build\ncd build\ncmake ..\nmake\n</code></pre>\n<h1>\n<a id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n<p>From the <code>build</code> directory:</p>\n<pre><code>export MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 128 ./test-server\n# one of the server will print \"Credential: X\", copy the X\n</code></pre>\n<p>In another terminal window, with current working directory set to <code>build</code>:</p>\n<pre><code>export MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 1 ./test-client X # replace X with the copied value\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1614204735.0
    },
    {
        "data_format": 2,
        "description": "Benchmark exercizing the ParallelEventProcessor feature of HEPnOS.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "hepnos/HEPnOS-PEP-Benchmark",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h1>\n<p>Setup spack and sds-repo, clone this repository and <code>cd</code> in it, then:</p>\n<pre><code>spack env create ssg-test spack.yaml\nspack env activate ssg-test\nspack install\nspack env deactivate\n</code></pre>\n<p>Then to build the code:</p>\n<pre><code>export CRAYPE_LINK_TYPE=dynamic\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\nspack env activate ssg-test\nmkdir build\ncd build\ncmake ..\nmake\n</code></pre>\n<h1>\n<a id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h1>\n<p>From the <code>build</code> directory:</p>\n<pre><code>export MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 128 ./test-server\n# one of the server will print \"Credential: X\", copy the X\n</code></pre>\n<p>In another terminal window, with current working directory set to <code>build</code>:</p>\n<pre><code>export MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 1 ./test-client X # replace X with the copied value\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1613603490.0
    },
    {
        "data_format": 2,
        "description": "HEPnOS is a distributed object store for high energy physics applications, developed at Argonne National Laboratory.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "hepnos/HEPnOS",
        "latest_release": "v0.4.2",
        "readme": "<h1>\n<a id=\"user-content-hepnos\" class=\"anchor\" href=\"#hepnos\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>HEPnOS</h1>\n<p>HEPnOS is the <em>High-Energy Physics's new Object Store</em>, a distributed storage\nsystem specially designed for HEP experiments and workflows for the FermiLab.\nHEPnOS relies on libraries developed at Argonne National Laboratory within the\ncontext of the Mochi project (ANL, CMU, LANL, HDF Group).</p>\n<p>For information on copyright and licensing, see the COPYRIGHT file.\nFor information on how to use, see the <a href=\"https://xgitlab.cels.anl.gov/sds/HEPnOS/wikis/home\" rel=\"nofollow\">wiki</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1617116230.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "contrib/spack/spack.yaml"
        ],
        "full_name": "felixthieme/2020_ASPECT_IGG",
        "latest_release": null,
        "readme": "<p>(Cloned from ASPECT by Felix Thieme (Idaho Geodynamics Group) on 5/27/2020)</p>\n<h1>\n<a id=\"user-content-aspect---advanced-solver-for-problems-in-earths-convection\" class=\"anchor\" href=\"#aspect---advanced-solver-for-problems-in-earths-convection\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ASPECT - Advanced Solver for Problems in Earth's ConvecTion</h1>\n<p><a href=\"https://github.com/geodynamics/aspect/blob/master/LICENSE\"><img src=\"https://camo.githubusercontent.com/6bdbfedce993ff7baeecb8c93e87eeebe79d7ae3d19002c54f87e301ec0e7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6372616e2f6c2f646576746f6f6c732e737667\" alt=\"License GPL2:\" data-canonical-src=\"https://img.shields.io/cran/l/devtools.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.2653531\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/91da28a81e083b7f3b47a26fd70f2dfcf0a87a9306f2b6f0d457a65ebe089752/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e323635333533312e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.2653531.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.6084/m9.figshare.4865333\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7f17ee0a3d31869d37f8d1b1f43540d6fb99d9a8c72bcf879977682693cbe1a7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6765742d5044462d677265656e2e737667\" alt=\"pdf manual\" data-canonical-src=\"https://img.shields.io/badge/get-PDF-green.svg\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-about\" class=\"anchor\" href=\"#about\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>About</h2>\n<p>ASPECT is a code to simulate convection in Earth's mantle and elsewhere.\nIt has grown from a pure mantle-convection code into a tool for many\ngeodynamic applications including applications for inner core convection,\nlithospheric scale deformation, two-phase flow, and numerical methods development.\nThe project is supported by CIG (<a href=\"http://geodynamics.org\" rel=\"nofollow\">http://geodynamics.org</a>).</p>\n<h2>\n<a id=\"user-content-installation-instructions\" class=\"anchor\" href=\"#installation-instructions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation instructions</h2>\n<p>The steps to install the necessary dependencies and ASPECT itself are described\nin the Installation instructions section of the ASPECT\n<a href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\">manual</a>. If you encounter\nproblems during the installation, please consult our\n<a href=\"https://github.com/geodynamics/aspect/wiki\">wiki</a> for typical installation\nproblems or specific instructions for MacOS users, before asking your question\non the mailing list.</p>\n<h2>\n<a id=\"user-content-running-and-extending-aspect\" class=\"anchor\" href=\"#running-and-extending-aspect\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running and extending ASPECT</h2>\n<p>Instructions on how to run and extend, as well as on how to interpret the\noutput of ASPECT can also be found in the ASPECT\n<a href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\">manual</a>. This manual also\ndiscusses the structure of the source code.</p>\n<p>For getting started, you can also watch our online\n<a href=\"https://geodynamics.org/cig/events/calendar/2016-cig-all-hands-meeting/aspect-tutorial/tutorial/\" rel=\"nofollow\">tutorial</a>.</p>\n<h2>\n<a id=\"user-content-contributing-to-aspect\" class=\"anchor\" href=\"#contributing-to-aspect\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing to ASPECT</h2>\n<p>ASPECT is a community project that lives by the participation of its\nmembers \u2014 i.e., including you! It is our goal to build an inclusive\nand participatory community so we are happy that you are interested in\nparticipating! We have collected a set of guidelines and advice on how\nto get involved in the community and keep them in the\n<a href=\"CONTRIBUTING.md\">CONTRIBUTING.md</a>\nfile in ASPECT's repository.</p>\n<h2>\n<a id=\"user-content-more-information\" class=\"anchor\" href=\"#more-information\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>More information</h2>\n<p>For more information see:</p>\n<ul>\n<li>\n<p>The official website at <a href=\"https://aspect.geodynamics.org\" rel=\"nofollow\">https://aspect.geodynamics.org</a></p>\n</li>\n<li>\n<p>The current <a href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\">manual</a></p>\n</li>\n<li>\n<p><a href=\"https://aspect.geodynamics.org/cite.html\" rel=\"nofollow\">How to cite ASPECT</a></p>\n</li>\n<li>\n<p>For questions on the source code of ASPECT, portability, installation, new or existing features, etc., use the <a href=\"https://community.geodynamics.org/c/aspect\" rel=\"nofollow\">ASPECT forum</a>. This forum is where the ASPECT users and developers all hang out. Archived discussions from the inactive aspect-devel mailing list can be downloaded at <a href=\"http://lists.geodynamics.org/pipermail/aspect-devel\" rel=\"nofollow\">aspect-devel archives</a>.</p>\n</li>\n<li>\n<p>ASPECT is primarily based on the deal.II library. If you have particular questions about deal.II, contact the <a href=\"https://www.dealii.org/mail.html\" rel=\"nofollow\">deal.II discussion groups</a>.</p>\n</li>\n<li>\n<p>In case of more general questions about mantle convection, you can contact the <a href=\"http://lists.geodynamics.org/cgi-bin/mailman/listinfo/cig-MC\" rel=\"nofollow\">CIG mantle convection mailing lists</a>.</p>\n</li>\n<li>\n<p>ASPECT is being developed by a large, collaborative, and inclusive community. It is currently maintained by the following people:</p>\n<ul>\n<li>Wolfgang Bangerth: <a href=\"mailto:bangerth@math.colostate.edu\">bangerth@math.colostate.edu</a>\n</li>\n<li>Juliane Dannberg: <a href=\"mailto:judannberg@gmail.com\">judannberg@gmail.com</a>\n</li>\n<li>Rene Gassmoeller: <a href=\"mailto:rene.gassmoeller@mailbox.org\">rene.gassmoeller@mailbox.org</a>\n</li>\n<li>Timo Heister: <a href=\"mailto:heister@clemson.edu\">heister@clemson.edu</a>\n</li>\n</ul>\n</li>\n<li>\n<p>The following people have significantly contributed and furthered ASPECT's goals and are therefore Principal Developers:</p>\n<ul>\n<li>Jacky Austermann</li>\n<li>Wolfgang Bangerth</li>\n<li>Juliane Dannberg</li>\n<li>Menno Fraters</li>\n<li>Rene Gassmoeller</li>\n<li>Anne Glerum</li>\n<li>Timo Heister</li>\n<li>John Naliboff</li>\n</ul>\n</li>\n<li>\n<p>A complete and growing list of the many authors that have contributed over the years can be found at <a href=\"https://github.com/geodynamics/aspect/graphs/contributors\">github</a></p>\n</li>\n<li>\n<p>If you have specific questions about ASPECT that are not suitable for public and archived mailing lists, feel free to contact the maintainers or principal developers.</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>ASPECT is published under <a href=\"LICENSE\">GPL v2 or newer</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1590632076.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "player1537/dhmem",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-dhmem-simplified-cross-workflow-communication\" class=\"anchor\" href=\"#dhmem-simplified-cross-workflow-communication\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dhmem: Simplified Cross-Workflow Communication</h1>\n<h2>\n<a id=\"user-content-buildinginstalling\" class=\"anchor\" href=\"#buildinginstalling\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building/Installing</h2>\n<p>To build, either vendor the source code and include with CMake's <code>add_subdirectory</code> or add via <code>ExternalProject_Add</code>.</p>\n<h2>\n<a id=\"user-content-example\" class=\"anchor\" href=\"#example\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Example</h2>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>dhmem/dhmem.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>cstdio<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">char</span> **argv) {\n    dhmem::Dhmem <span class=\"pl-smi\">dhmem</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>shared_memory_namespace<span class=\"pl-pds\">\"</span></span>);\n\n    <span class=\"pl-k\">auto</span> &amp;n = dhmem.<span class=\"pl-smi\">shared</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n    <span class=\"pl-k\">auto</span> &amp;mutex = dhmem.<span class=\"pl-smi\">shared</span>&lt;dhmem::mutex&gt;();\n    \n    {\n        dhmem::scoped_lock <span class=\"pl-smi\">lock</span>(mutex);\n        ++n;\n        <span class=\"pl-c1\">std::printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>n = %d<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>, n);\n    }\n\n    <span class=\"pl-c1\">std::printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Press Enter to quit...<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    <span class=\"pl-c1\">std::getchar</span>();\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1614216540.0
    },
    {
        "data_format": 2,
        "description": "A random and evolving collection of ansible playbooks.",
        "filenames": [
            "roles/ronin_cluster/files/ronin_cluster-spack.yaml"
        ],
        "full_name": "smutch/playbooks",
        "latest_release": null,
        "readme": "<h2>\n<a id=\"user-content-playbooks\" class=\"anchor\" href=\"#playbooks\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Playbooks</h2>\n<p>This is a random collection of playbooks and roles as I begin my journey using\nansible to automate the tedious set up devel machines.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1612705252.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "UCR-Research-Computing/using-nautilus-cluster",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-using-nautilus-cluster\" class=\"anchor\" href=\"#using-nautilus-cluster\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>using-nautilus-cluster</h1>\n<h3>\n<a id=\"user-content-basic-commmands\" class=\"anchor\" href=\"#basic-commmands\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>basic commmands</h3>\n<div class=\"highlight highlight-source-shell\"><pre>\nkubectl get pods\nkubectl create -f <span class=\"pl-k\">&lt;</span>yaml-file<span class=\"pl-k\">&gt;</span>\nkubectl delete pods <span class=\"pl-k\">&lt;</span>pod-name<span class=\"pl-k\">&gt;</span>\n\nkubectl <span class=\"pl-c1\">exec</span> -it <span class=\"pl-k\">&lt;</span>pod-name<span class=\"pl-k\">&gt;</span> bash\nkubectl port-forward <span class=\"pl-k\">&lt;</span>pod-name<span class=\"pl-k\">&gt;</span> 8888:8888\n</pre></div>\n<h3>\n<a id=\"user-content-starting-jupyter\" class=\"anchor\" href=\"#starting-jupyter\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting Jupyter</h3>\n<p>Use the tensorflow-cpu-pod.yaml or tensorflow-gpu-pod.yaml file to start the pod</p>\n<div class=\"highlight highlight-source-shell\"><pre>\nkubectl create -f tensorflow-gpu-pod.yaml\nkubectl <span class=\"pl-c1\">exec</span> -it gpu-pod-example bash\n\njovyan@gpu-pod-example:<span class=\"pl-k\">~</span>$ jupyter notebook --ip=<span class=\"pl-s\"><span class=\"pl-pds\">'</span>0.0.0.0<span class=\"pl-pds\">'</span></span>\n\nkubectl port-forward gpu-pod-example 8888:8888\n</pre></div>\n<ul>\n<li>open browser to localhost:8888 and paste in the token from the jupyter notebook start command</li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 0,
        "topics": [],
        "updated_at": 1607345085.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "software/spack/spack_installed_yaml.sh"
        ],
        "full_name": "baberlevi/script-pourri",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-script-pourri\" class=\"anchor\" href=\"#script-pourri\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>script-pourri</h1>\n<p>Unrelated scripts, not worth creating repos for individually, but little examples that will save me time by having them readily accessible so I don't need to lookup syntax or option flags again.</p>\n<ul>\n<li>boxftp.sh - Reverse mirror upload a directory to box via ftp (make sure ~/.lftprc is setup for ssl)\n<ul>\n<li>set ftp:ssl-force yes</li>\n<li>set ftp:ssl-protect-data yes</li>\n<li>set ftp:ssl-auth TLS</li>\n</ul>\n</li>\n<li>daily_churn.sh - read in a bunch of text files with file size usage per day (one file per user folder), sum up by day and output so I can look at daily delta</li>\n<li>turtle_data_cleanup.r - read in a tsv, do some data manipulation, output csv</li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1552633444.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "clover/inputs/spack/spack.yaml"
        ],
        "full_name": "m-s-will/clover",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-cloverleaf3d-with-ascent-in-container\" class=\"anchor\" href=\"#cloverleaf3d-with-ascent-in-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CloverLeaf3D with Ascent in Container</h1>\n<p>This project contains a Dockerfile and all necessary components to create a Docker container for CloverLeaf3D.\nThe container is available on <a href=\"https://hub.docker.com/repository/docker/mswill/elwe_clover\" rel=\"nofollow\">Dockerhub</a>, however these versions may not always be up to date.</p>\n<h2>\n<a id=\"user-content-building-the-container\" class=\"anchor\" href=\"#building-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the container</h2>\n<p>The Ascent actions can be changed by editing <a href=\"https://github.com/m-s-will/clover/blob/main/clover/inputs/ascent/ascent_actions.yaml\">ascent_actions.yaml</a>.\nWhen finished with the customization, the container can be rebuilt by navigating into the source directory and executing:</p>\n<pre><code>$ docker build -t &lt;mytag&gt; .\n</code></pre>\n<p>The CloverLeaf3D simulation is being run during container creation and provides a Cinema database.</p>\n<h2>\n<a id=\"user-content-running-the-container\" class=\"anchor\" href=\"#running-the-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the container</h2>\n<p>After either pulling or building the container, it can be run by calling:</p>\n<pre><code>$ docker run -p 80:80 &lt;mytag&gt;.\n</code></pre>\n<p><code>-p 80:80</code> makes port 80 available on the outside which is needed for the Cinema viewer. We can then connect to it by visiting <code>localhost:80</code> in our browser.</p>\n<p align=\"center\">\n<a href=\"viewer.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"750\" src=\"viewer.png\" style=\"max-width:100%;\"></a>\n</p>\n<p align=\"center\">Overview over the Cinema viewer running via nginx in the container.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619023093.0
    },
    {
        "data_format": 2,
        "description": "Reduces SYMBIOMON metrics",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "srini009/reducer",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-margo-microservice-template\" class=\"anchor\" href=\"#margo-microservice-template\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo Microservice Template</h1>\n<p>This project is a template to start developing a Mochi microservice based on Margo.\nIf you want to implement your own microservice, please read ahead. Though this project\nprovides many examples of how to use the Margo API, you may want to refer to the Margo\ndocumentation <a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a> for more detail.</p>\n<h2>\n<a id=\"user-content-the-mochi-philosophy\" class=\"anchor\" href=\"#the-mochi-philosophy\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Mochi philosophy</h2>\n<p>The philosophy of the Mochi project consists of providing a set of building blocks\nfor developing HPC data service. Each building block is meant to offer <strong>efficient</strong>,\n<strong>location-agnostic</strong> access to a <strong>simple set of functionalities</strong> through\n<strong>modular backends</strong>, while <strong>seamlessly sharing hardware</strong> (compute and network)\nwith other building blocks.</p>\n<p>A <strong>simple set of functionalities</strong> may be, for example, <em>\"storing and retrieving\nsmall key/value pairs\"</em>, a common feature found in many storage systems to manage\nmetadata. The <strong>location-agnostic</strong> aspect aims at making such a feature available\nto user programs in the same manner and through the same API regardless of whether\nthe service runs in the same process, on the same node but on different processes,\nor on a different node across a network. The <strong>modular backends</strong> aspect makes it\npossible to abstract the implementation of such a feature and, if not providing\nmultiple implementations, at least providing the means for someone to easily swap\nthe default implementation of the feature for their own. Because multiple building\nblocks may be running on the same node, such a building block should efficiently\nshare the compute and network hardware with other building blocks. This is done\nby sharing a common networking and threading layer: Margo.</p>\n<h2>\n<a id=\"user-content-design-overview\" class=\"anchor\" href=\"#design-overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design overview</h2>\n<p>The typical design of a Mochi microservice revolves around three libraries:\n<strong>server</strong>, <strong>client</strong>, and <strong>admin</strong>.</p>\n<ul>\n<li>The server library contains a service <strong>provider</strong>, that is, an object that\ncan receive some predefined RPCs to offer a particular functionality. Within\nthe same process, multiple providers of the same service may be instantiated,\nusing distinct <strong>provider ids</strong> (<code>uint16_t</code>). A provider is responsible for\nmanaging a set of <strong>resources</strong>. In the example of a storage for key/value\npairs, a resource may be a database. The functionalities of a provider may\nbe enabled by multiple <strong>backends</strong>. For example, a database may be implemented\nusing LevelDB, BerkeleyDB, or simply using an in-memory hash table.\nPrograms sending requests to a provider should <strong>not</strong> be unaware of the backend used\nto implement the requested functionality. This allows multiple backends to be\ntested, and for backends to evolve independently from user applications.</li>\n<li>The client library is the library through which user applications or higher-level\nservices interact with providers. It will typically provide a <strong>client</strong> structure\nthat is used to register the set of RPCs that can be invoked, and a <strong>resource handle</strong>\nstructure that references a particular resource located on a particular provider.\nUser applications will typically initialize a singe client object for a service, and\nfrom this client object instantiate as many resource handles as needed to interact with\navailable resources. Resources are identified by a <strong>resource id</strong>, which are generally\neither a name, an integer, or a\n<a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\" rel=\"nofollow\">uuid</a> (this template\nproject uses uuids).</li>\n<li>The admin library is the library through which a user application can send\nrequests that are meant for the provider itself rather than for a resource.\nA few most common such requests include the creation and destruction of\nresources, their migration, etc. It can be useful to think of the admin\nlibrary as the set of features you would want to provide to the person or\napplication that sets up the service, rather than the person or application\nthat uses its functionalities.</li>\n</ul>\n<h2>\n<a id=\"user-content-organization-of-this-template-project\" class=\"anchor\" href=\"#organization-of-this-template-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Organization of this template project</h2>\n<p>This template project illustrates how a Margo-based microservice could\nbe architected. It can be compiled as-is, and provides a couple of\nfunctionalities that make the provider print a \"Hello World\" message\non its standard output, or compute the sum of two integers.</p>\n<p>This template project uses <strong>alpha</strong> as the name of your microservice.\nFunctions, types, files, and libraries therefore use the <strong>alpha</strong> prefix.\nThe first step in setting up this project for your microservice will be\nto replace this prefix. The generic name <strong>resource</strong> should also be\nreplaced with a more specific name, such as <strong>database</strong>. This renaming\nstep can be done by using the <em>setup.py</em> script at the root of this repository\n(see next section).</p>\n<p>The <em>include</em> directory of this template project provides public header files.</p>\n<ul>\n<li>\n<em>alpha/alpha-common.h</em> contains APIs that are common to the three\nlibraries, such as error codes or common types;</li>\n<li>\n<em>alpha/alpha-client.h</em> contains the client-side functions to create\nand destroy a client object;</li>\n<li>\n<em>alpha/alpha-resource.h</em> contains the client-side functions to create\nand destroy resource handles, and to interact with a resource through\na resource handle;</li>\n<li>\n<em>alpha/alpha-server.h</em> contains functions to register and destroy\na provider;</li>\n<li>\n<em>alpha/alpha-backend.h</em> contains the definition of a structure that\none would need to implement in order to provide a new backend for\nyour microservice;</li>\n<li>\n<em>alpha/alpha-admin.h</em> contains the functions to create and destroy\nan admin object, as well as admin functions to interact with a provider;</li>\n<li>\n<em>alpha/alpha-provider-handle.h</em> contains the definition of a provider handle.\nThis type of construct is often used in Mochi services to encapsulate\nan address and a provider id.</li>\n</ul>\n<p>The implementation of all these functions is located in the <em>src</em> directory.\nThe source also includes functionalities such as a small header-based logging library.\nThe <em>src/dummy</em> directory provides a default implementation of a backend. This\nbackend also exemplifies the use of the <a href=\"https://github.com/json-c/json-c\">json-c</a> library\nfor JSON-based resource configuration. We recommend that you implement a dummy backend for your\nservice, as a way of testing application logic and RPCs without the burden of complex\nexternal dependencies. For instance, a dummy backend may be a backend that simply\nacknowledges requests but does not process them, or provides mock results.</p>\n<p>The <em>examples</em> directory contains an example using the microservice:\nthe server example will start a provider and print its address (if logging was enabled).\nThe admin example will connect to this provider and have it create a resource, then\nprint the resource id. The client example can be run next to interact with the resource.</p>\n<p>The <em>tests</em> directory contains a set of unit tests for your service.\nIt relies on <a href=\"https://nemequ.github.io/munit\" rel=\"nofollow\">\u00b5nit</a> (included in this repository),\na C unit-test library under an MIT license. Feel free to continue using it as you\nadd more functionalities to your microservice; unit-testing is just good software\ndevelopment practice in general.</p>\n<p>The template also contains a <em>spack.yaml</em> file at its root that can be used to\ninstall its dependencies. You may add additional dependencies into this file as\nyour microservice gets more complex.</p>\n<p>As you modify this project to implement your own microservice, feel free to remove\nany dependencies you don't like (such as json-c or \u00b5nit) and adapt it to your needs!</p>\n<h2>\n<a id=\"user-content-setting-up-your-project\" class=\"anchor\" href=\"#setting-up-your-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up your project</h2>\n<p>Let's assume you want to create a microservice called \"yellow\", which manages\na phone directory (association between names and phone numbers). The following\nshows how to setup your project:</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/templates/margo-microservice-template.git\nmv margo-microservice-template yellow\ncd yellow\nrm -rf .git\npython setup.py\n$ Enter the name of your service: yellow\n$ Enter the name of the resources (e.g., database): phonebook\n</code></pre>\n<p>The python script will edit and rename all the files, replacing <em>alpha</em> with <em>yellow</em>\nand <em>resource</em> with <em>phonebook</em>.</p>\n<h2>\n<a id=\"user-content-building-the-project\" class=\"anchor\" href=\"#building-the-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the project</h2>\n<p>The project's dependencies may be build using <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack</a>.\nYou will need to have setup <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">sds-repo</a> as external\nnamespace for spack, which can be done as follows.</p>\n<pre><code># from outside of your project directory\ngit clone git@xgitlab.cels.anl.gov:sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>The easiest way to setup the dependencies for this project is to create a spack environment\nusing the <em>spack.yaml</em> file located at the root of the project, as follows.</p>\n<pre><code># create an anonymous environment\ncd margo-microservice-template\nspack env activate .\nspack install\n</code></pre>\n<p>or as follows.</p>\n<pre><code># create an environment named myenv\ncd margo-microservice-template\nspack env create myenv spack.yaml\nspack env activate myenv\nspack install\n</code></pre>\n<p>Once the dependencies have been installed, you may build the project as follows.</p>\n<pre><code>mkdir build\ncd build\ncmake .. -DENABLE_LOG_INFO=ON -DENABLE_LOG_ERROR=ON -DENABLE_LOG_DEBUG=ON -DENABLE_TESTS=ON -DENABLE_EXAMPLES=ON\nmake\n</code></pre>\n<p>You can test the project using <code>make test</code> from the build directory.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619097876.0
    },
    {
        "data_format": 2,
        "description": "Personal fork of the sds-key Mochi microservice.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "srini009/sds-keyval",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" href=\"#sdskv-sds-keyval\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SDSKV (SDS Key/Val)</h1>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>SDSKV can easily be installed using Spack:</p>\n<p><code>spack install sdskeyval</code></p>\n<p>This will install SDSKV (and any required dependencies).\nAvailable backends will be <em>Map</em> (in-memory C++ std::map, useful for testing)\nand BwTree (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass <code>+bdb</code> and <code>+leveldb</code> respectively. For example:</p>\n<p><code>spack install sdskeyval+bdb+leveldb</code></p>\n<p>Note that if you are using a system boost path in spack (in your\npackages.yaml) rather than letting spack build boost, then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages on\nyour system.</p>\n<h2>\n<a id=\"user-content-architecture\" class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Architecture</h2>\n<p>List most mochi services, SDSKV relies on a client/provider architecture.\nA provider, identified by its <em>address</em> and <em>multiplex id</em>, manages one or more\ndatabases, referenced externally by their database id.</p>\n<h2>\n<a id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Starting a daemon</h2>\n<p>SDSKV ships with a default daemon program that can setup providers and\ndatabases. This daemon can be started as follows:</p>\n<p><code>sdskv-server-daemon [OPTIONS] &lt;listen_addr&gt; &lt;db name 1&gt;[:map|:bwt|:bdb|:ldb] &lt;db name 2&gt;[:map|:bwt|:bdb|:ldb] ...</code></p>\n<p>For example:</p>\n<p><code>sdskv-server-daemon tcp://localhost:1234 foo:bdb bar</code></p>\n<p>listen_addr is the address at which to listen; database names should be provided in the form\n<em>name:type</em> where <em>type</em> is <em>map</em> (std::map), <em>bwt</em> (BwTree), <em>bdb</em> (Berkeley DB), or <em>ldb</em> (LevelDB).</p>\n<p>For database that are persistent like BerkeleyDB or LevelDB, the name should be a path to the\nfile where the database will be put (this file should not exist).</p>\n<p>The following additional options are accepted:</p>\n<ul>\n<li>\n<code>-f</code> provides the name of the file in which to write the address of the daemon.</li>\n<li>\n<code>-m</code> provides the mode (providers or databases).</li>\n</ul>\n<p>The providers mode indicates that, if multiple SDSKV databases are used (as above),\nthese databases should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\nto manage. The targets mode indicates that a single provider should be used to\nmanage all the databases. This provider will be accessible at multiplex id 1.</p>\n<h2>\n<a id=\"user-content-client-api\" class=\"anchor\" href=\"#client-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Client API</h2>\n<p>The client API is available in <em>sdskv-client.h</em>.\nThe codes in the <em>test</em> folder illustrate how to use it.</p>\n<h2>\n<a id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provider API</h2>\n<p>The server-side API is available in <em>sdskv-server.h</em>.\nThe code of the daemon (<em>src/sdskv-server-daemon.c</em>) can be used as an example.</p>\n<h3>\n<a id=\"user-content-custom-key-comparison-function\" class=\"anchor\" href=\"#custom-key-comparison-function\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Custom key comparison function</h3>\n<p>It is possible to specify a custom function for comparing/sorting keys\nwhen creating a provider. A comparison function must have the following prototype:</p>\n<p><code>int (*)(const void* key1, size_t keysize1, const void* key2, size_t keysize2)</code></p>\n<p>Its return value must be &lt; 0 if key1 &lt; key2, 0 if key1 = key2, &gt; 0 if key1 &gt; key2.\nIt must define a total order of the key space.</p>\n<h2>\n<a id=\"user-content-c-api\" class=\"anchor\" href=\"#c-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ API</h2>\n<p>An object-oriented C++ API is available in <code>sdskv-client.hpp</code> and <code>sdskv-server.hpp</code>.\nOn the client side this API provides the <code>client</code>, <code>provider_handle</code>, and <code>database</code> objects.\nExamples of usage of these objects can be found in the <code>test/sdskv-cxx-test.cc</code>.\nOn the server side, this API provides a <code>provider</code> object.</p>\n<h2>\n<a id=\"user-content-benchmark\" class=\"anchor\" href=\"#benchmark\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Benchmark</h2>\n<p>SDSKV can be compiled with <code>--enable-benchmark</code> (or <code>+benchmark</code> in Spack). In this case,\nSDSKV requires the JsonCPP and MPI dependencies (when compiling manually, use <code>CXX=mpicxx</code> in\nyour configure step, for example), and it will build and install the <code>sdskv-benchmark</code> program.</p>\n<p>This program is an MPI program that reads a JSON file describing a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server. Other ranks act as clients, all executing\nthis access pattern.</p>\n<p>The following is an example of a JSON file.</p>\n<div class=\"highlight highlight-source-json\"><pre>{\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>protocol<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tcp<span class=\"pl-pds\">\"</span></span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>seed<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>server<span class=\"pl-pds\">\"</span></span> : {\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>use-progress-thread<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">false</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rpc-thread-count<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">0</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>database<span class=\"pl-pds\">\"</span></span> : {\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>map<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmark-db<span class=\"pl-pds\">\"</span></span>,\n\t\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>path<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/dev/shm<span class=\"pl-pds\">\"</span></span>\n\t\t}\n\t},\n\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>benchmarks<span class=\"pl-pds\">\"</span></span> : [\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>put<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : [ <span class=\"pl-c1\">24</span>, <span class=\"pl-c1\">48</span> ],\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t},\n\t{\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>get<span class=\"pl-pds\">\"</span></span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>repetitions<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">10</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num-entries<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">30</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>key-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">64</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>val-sizes<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">128</span>,\n\t\t<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>erase-on-teardown<span class=\"pl-pds\">\"</span></span> : <span class=\"pl-c1\">true</span>\n\t}\n\t]\n}</pre></div>\n<p>The JSON file starts with the protocol to use, and a seed for the random-number generator (RNG).\nThe actual seed used on each rank will actually be a function of this global seed and the rank of\nthe client. The RNG will be reset with this seed after each benchmark.</p>\n<p>The <code>server</code> field sets up the provider and the database. Database types can be <code>map</code>, <code>ldb</code>, or <code>bdb</code>.\nThen follows the <code>benchmarks</code> entry, which is a list of benchmarks to execute. Each benchmark is composed\nof three steps. A <em>setup</em> phase, an <em>execution</em> phase, and a <em>teardown</em> phase. The setup phase may for\nexample store a bunch of keys in the database that the execution phase will read by (in the case of a\n<em>get</em> benchmark, for example). The teardown phase will usually remove all the keys that were written\nduring the benchmark, if \"erase-on-teardown\" is set to <code>true</code>.</p>\n<p>Each benchmark entry has a <code>type</code> (which may be <code>put</code>, <code>put-multi</code>, <code>get</code>, <code>get-multi</code>, <code>length</code>,\n<code>length-multi</code>, <code>erase</code>, and <code>erase-multi</code>), and a number of repetitions. The benchmark will be\nexecuted as many times as requested (without resetting the RNG in between repetitions). Taking the\nexample of the <code>put</code> benchmark above, each repetition will put 30 key/value pairs into the database.\nThe key size will be chosen randomly in a uniform manner in the interval <code>[8, 32 [</code> (32 excluded).\nThe value size will be chosen randomly in a uniform manner in <code>[24, 48 [</code> (48 excluded). Note that\nyou may also set a specific size instead of a range.</p>\n<p>An MPI barrier between clients is executed in between each benchmark and in between the setup,\nexecution, and teardown phases, so that the execution phase is always executed at the same time\non all the clients. Once all the repetitions are done for a given benchmark entry, the program\nwill report statistics on the timings: average time, variance, standard deviation, mininum, maximum,\nmedian, first and third quartiles. Note that these times are for a repetition, not for single operations\nwithin a repetition. To get the timing of each individual operation, it is then necessary to divide\nthe times by the number of key/value pairs involved in the benchmark.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1618836554.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "builds/openmp/spack.yaml",
            "builds/cuda/spack.yaml"
        ],
        "full_name": "DavidPoliakoff/tuning-spack",
        "latest_release": null,
        "readme": "<p>Steps: get spack, as of this moment 0.16.1 seems good</p>\n<p>Clone this repo</p>\n<p>Spack repo add /path/to/this/repo/root</p>\n<p>cd builds/openmp or builds/cuda</p>\n<p>spack env activate .</p>\n<p>spack concretize -f</p>\n<p>spack install</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1615254927.0
    },
    {
        "data_format": 2,
        "description": "Aggregator microservice built using Mochi that is a part of SYMBIOMON",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "srini009/aggregator",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-margo-microservice-template\" class=\"anchor\" href=\"#margo-microservice-template\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo Microservice Template</h1>\n<p>This project is a template to start developing a Mochi microservice based on Margo.\nIf you want to implement your own microservice, please read ahead. Though this project\nprovides many examples of how to use the Margo API, you may want to refer to the Margo\ndocumentation <a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a> for more detail.</p>\n<h2>\n<a id=\"user-content-the-mochi-philosophy\" class=\"anchor\" href=\"#the-mochi-philosophy\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Mochi philosophy</h2>\n<p>The philosophy of the Mochi project consists of providing a set of building blocks\nfor developing HPC data service. Each building block is meant to offer <strong>efficient</strong>,\n<strong>location-agnostic</strong> access to a <strong>simple set of functionalities</strong> through\n<strong>modular backends</strong>, while <strong>seamlessly sharing hardware</strong> (compute and network)\nwith other building blocks.</p>\n<p>A <strong>simple set of functionalities</strong> may be, for example, <em>\"storing and retrieving\nsmall key/value pairs\"</em>, a common feature found in many storage systems to manage\nmetadata. The <strong>location-agnostic</strong> aspect aims at making such a feature available\nto user programs in the same manner and through the same API regardless of whether\nthe service runs in the same process, on the same node but on different processes,\nor on a different node across a network. The <strong>modular backends</strong> aspect makes it\npossible to abstract the implementation of such a feature and, if not providing\nmultiple implementations, at least providing the means for someone to easily swap\nthe default implementation of the feature for their own. Because multiple building\nblocks may be running on the same node, such a building block should efficiently\nshare the compute and network hardware with other building blocks. This is done\nby sharing a common networking and threading layer: Margo.</p>\n<h2>\n<a id=\"user-content-design-overview\" class=\"anchor\" href=\"#design-overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design overview</h2>\n<p>The typical design of a Mochi microservice revolves around three libraries:\n<strong>server</strong>, <strong>client</strong>, and <strong>admin</strong>.</p>\n<ul>\n<li>The server library contains a service <strong>provider</strong>, that is, an object that\ncan receive some predefined RPCs to offer a particular functionality. Within\nthe same process, multiple providers of the same service may be instantiated,\nusing distinct <strong>provider ids</strong> (<code>uint16_t</code>). A provider is responsible for\nmanaging a set of <strong>resources</strong>. In the example of a storage for key/value\npairs, a resource may be a database. The functionalities of a provider may\nbe enabled by multiple <strong>backends</strong>. For example, a database may be implemented\nusing LevelDB, BerkeleyDB, or simply using an in-memory hash table.\nPrograms sending requests to a provider should <strong>not</strong> be unaware of the backend used\nto implement the requested functionality. This allows multiple backends to be\ntested, and for backends to evolve independently from user applications.</li>\n<li>The client library is the library through which user applications or higher-level\nservices interact with providers. It will typically provide a <strong>client</strong> structure\nthat is used to register the set of RPCs that can be invoked, and a <strong>resource handle</strong>\nstructure that references a particular resource located on a particular provider.\nUser applications will typically initialize a singe client object for a service, and\nfrom this client object instantiate as many resource handles as needed to interact with\navailable resources. Resources are identified by a <strong>resource id</strong>, which are generally\neither a name, an integer, or a\n<a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\" rel=\"nofollow\">uuid</a> (this template\nproject uses uuids).</li>\n<li>The admin library is the library through which a user application can send\nrequests that are meant for the provider itself rather than for a resource.\nA few most common such requests include the creation and destruction of\nresources, their migration, etc. It can be useful to think of the admin\nlibrary as the set of features you would want to provide to the person or\napplication that sets up the service, rather than the person or application\nthat uses its functionalities.</li>\n</ul>\n<h2>\n<a id=\"user-content-organization-of-this-template-project\" class=\"anchor\" href=\"#organization-of-this-template-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Organization of this template project</h2>\n<p>This template project illustrates how a Margo-based microservice could\nbe architected. It can be compiled as-is, and provides a couple of\nfunctionalities that make the provider print a \"Hello World\" message\non its standard output, or compute the sum of two integers.</p>\n<p>This template project uses <strong>alpha</strong> as the name of your microservice.\nFunctions, types, files, and libraries therefore use the <strong>alpha</strong> prefix.\nThe first step in setting up this project for your microservice will be\nto replace this prefix. The generic name <strong>resource</strong> should also be\nreplaced with a more specific name, such as <strong>database</strong>. This renaming\nstep can be done by using the <em>setup.py</em> script at the root of this repository\n(see next section).</p>\n<p>The <em>include</em> directory of this template project provides public header files.</p>\n<ul>\n<li>\n<em>alpha/alpha-common.h</em> contains APIs that are common to the three\nlibraries, such as error codes or common types;</li>\n<li>\n<em>alpha/alpha-client.h</em> contains the client-side functions to create\nand destroy a client object;</li>\n<li>\n<em>alpha/alpha-resource.h</em> contains the client-side functions to create\nand destroy resource handles, and to interact with a resource through\na resource handle;</li>\n<li>\n<em>alpha/alpha-server.h</em> contains functions to register and destroy\na provider;</li>\n<li>\n<em>alpha/alpha-backend.h</em> contains the definition of a structure that\none would need to implement in order to provide a new backend for\nyour microservice;</li>\n<li>\n<em>alpha/alpha-admin.h</em> contains the functions to create and destroy\nan admin object, as well as admin functions to interact with a provider;</li>\n<li>\n<em>alpha/alpha-provider-handle.h</em> contains the definition of a provider handle.\nThis type of construct is often used in Mochi services to encapsulate\nan address and a provider id.</li>\n</ul>\n<p>The implementation of all these functions is located in the <em>src</em> directory.\nThe source also includes functionalities such as a small header-based logging library.\nThe <em>src/dummy</em> directory provides a default implementation of a backend. This\nbackend also exemplifies the use of the <a href=\"https://github.com/json-c/json-c\">json-c</a> library\nfor JSON-based resource configuration. We recommend that you implement a dummy backend for your\nservice, as a way of testing application logic and RPCs without the burden of complex\nexternal dependencies. For instance, a dummy backend may be a backend that simply\nacknowledges requests but does not process them, or provides mock results.</p>\n<p>The <em>examples</em> directory contains an example using the microservice:\nthe server example will start a provider and print its address (if logging was enabled).\nThe admin example will connect to this provider and have it create a resource, then\nprint the resource id. The client example can be run next to interact with the resource.</p>\n<p>The <em>tests</em> directory contains a set of unit tests for your service.\nIt relies on <a href=\"https://nemequ.github.io/munit\" rel=\"nofollow\">\u00b5nit</a> (included in this repository),\na C unit-test library under an MIT license. Feel free to continue using it as you\nadd more functionalities to your microservice; unit-testing is just good software\ndevelopment practice in general.</p>\n<p>The template also contains a <em>spack.yaml</em> file at its root that can be used to\ninstall its dependencies. You may add additional dependencies into this file as\nyour microservice gets more complex.</p>\n<p>As you modify this project to implement your own microservice, feel free to remove\nany dependencies you don't like (such as json-c or \u00b5nit) and adapt it to your needs!</p>\n<h2>\n<a id=\"user-content-setting-up-your-project\" class=\"anchor\" href=\"#setting-up-your-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up your project</h2>\n<p>Let's assume you want to create a microservice called \"yellow\", which manages\na phone directory (association between names and phone numbers). The following\nshows how to setup your project:</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/templates/margo-microservice-template.git\nmv margo-microservice-template yellow\ncd yellow\nrm -rf .git\npython setup.py\n$ Enter the name of your service: yellow\n$ Enter the name of the resources (e.g., database): phonebook\n</code></pre>\n<p>The python script will edit and rename all the files, replacing <em>alpha</em> with <em>yellow</em>\nand <em>resource</em> with <em>phonebook</em>.</p>\n<h2>\n<a id=\"user-content-building-the-project\" class=\"anchor\" href=\"#building-the-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the project</h2>\n<p>The project's dependencies may be build using <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack</a>.\nYou will need to have setup <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">sds-repo</a> as external\nnamespace for spack, which can be done as follows.</p>\n<pre><code># from outside of your project directory\ngit clone git@xgitlab.cels.anl.gov:sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>The easiest way to setup the dependencies for this project is to create a spack environment\nusing the <em>spack.yaml</em> file located at the root of the project, as follows.</p>\n<pre><code># create an anonymous environment\ncd margo-microservice-template\nspack env activate .\nspack install\n</code></pre>\n<p>or as follows.</p>\n<pre><code># create an environment named myenv\ncd margo-microservice-template\nspack env create myenv spack.yaml\nspack env activate myenv\nspack install\n</code></pre>\n<p>Once the dependencies have been installed, you may build the project as follows.</p>\n<pre><code>mkdir build\ncd build\ncmake .. -DENABLE_LOG_INFO=ON -DENABLE_LOG_ERROR=ON -DENABLE_LOG_DEBUG=ON -DENABLE_TESTS=ON -DENABLE_EXAMPLES=ON\nmake\n</code></pre>\n<p>You can test the project using <code>make test</code> from the build directory.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1615293700.0
    },
    {
        "data_format": 2,
        "description": "Collector microservice built using Mochi that is part of SYMBIOMON",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "srini009/collector",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-margo-microservice-template\" class=\"anchor\" href=\"#margo-microservice-template\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo Microservice Template</h1>\n<p>This project is a template to start developing a Mochi microservice based on Margo.\nIf you want to implement your own microservice, please read ahead. Though this project\nprovides many examples of how to use the Margo API, you may want to refer to the Margo\ndocumentation <a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a> for more detail.</p>\n<h2>\n<a id=\"user-content-the-mochi-philosophy\" class=\"anchor\" href=\"#the-mochi-philosophy\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Mochi philosophy</h2>\n<p>The philosophy of the Mochi project consists of providing a set of building blocks\nfor developing HPC data service. Each building block is meant to offer <strong>efficient</strong>,\n<strong>location-agnostic</strong> access to a <strong>simple set of functionalities</strong> through\n<strong>modular backends</strong>, while <strong>seamlessly sharing hardware</strong> (compute and network)\nwith other building blocks.</p>\n<p>A <strong>simple set of functionalities</strong> may be, for example, <em>\"storing and retrieving\nsmall key/value pairs\"</em>, a common feature found in many storage systems to manage\nmetadata. The <strong>location-agnostic</strong> aspect aims at making such a feature available\nto user programs in the same manner and through the same API regardless of whether\nthe service runs in the same process, on the same node but on different processes,\nor on a different node across a network. The <strong>modular backends</strong> aspect makes it\npossible to abstract the implementation of such a feature and, if not providing\nmultiple implementations, at least providing the means for someone to easily swap\nthe default implementation of the feature for their own. Because multiple building\nblocks may be running on the same node, such a building block should efficiently\nshare the compute and network hardware with other building blocks. This is done\nby sharing a common networking and threading layer: Margo.</p>\n<h2>\n<a id=\"user-content-design-overview\" class=\"anchor\" href=\"#design-overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design overview</h2>\n<p>The typical design of a Mochi microservice revolves around three libraries:\n<strong>server</strong>, <strong>client</strong>, and <strong>admin</strong>.</p>\n<ul>\n<li>The server library contains a service <strong>provider</strong>, that is, an object that\ncan receive some predefined RPCs to offer a particular functionality. Within\nthe same process, multiple providers of the same service may be instantiated,\nusing distinct <strong>provider ids</strong> (<code>uint16_t</code>). A provider is responsible for\nmanaging a set of <strong>resources</strong>. In the example of a storage for key/value\npairs, a resource may be a database. The functionalities of a provider may\nbe enabled by multiple <strong>backends</strong>. For example, a database may be implemented\nusing LevelDB, BerkeleyDB, or simply using an in-memory hash table.\nPrograms sending requests to a provider should <strong>not</strong> be unaware of the backend used\nto implement the requested functionality. This allows multiple backends to be\ntested, and for backends to evolve independently from user applications.</li>\n<li>The client library is the library through which user applications or higher-level\nservices interact with providers. It will typically provide a <strong>client</strong> structure\nthat is used to register the set of RPCs that can be invoked, and a <strong>resource handle</strong>\nstructure that references a particular resource located on a particular provider.\nUser applications will typically initialize a singe client object for a service, and\nfrom this client object instantiate as many resource handles as needed to interact with\navailable resources. Resources are identified by a <strong>resource id</strong>, which are generally\neither a name, an integer, or a\n<a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\" rel=\"nofollow\">uuid</a> (this template\nproject uses uuids).</li>\n<li>The admin library is the library through which a user application can send\nrequests that are meant for the provider itself rather than for a resource.\nA few most common such requests include the creation and destruction of\nresources, their migration, etc. It can be useful to think of the admin\nlibrary as the set of features you would want to provide to the person or\napplication that sets up the service, rather than the person or application\nthat uses its functionalities.</li>\n</ul>\n<h2>\n<a id=\"user-content-organization-of-this-template-project\" class=\"anchor\" href=\"#organization-of-this-template-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Organization of this template project</h2>\n<p>This template project illustrates how a Margo-based microservice could\nbe architected. It can be compiled as-is, and provides a couple of\nfunctionalities that make the provider print a \"Hello World\" message\non its standard output, or compute the sum of two integers.</p>\n<p>This template project uses <strong>alpha</strong> as the name of your microservice.\nFunctions, types, files, and libraries therefore use the <strong>alpha</strong> prefix.\nThe first step in setting up this project for your microservice will be\nto replace this prefix. The generic name <strong>resource</strong> should also be\nreplaced with a more specific name, such as <strong>database</strong>. This renaming\nstep can be done by using the <em>setup.py</em> script at the root of this repository\n(see next section).</p>\n<p>The <em>include</em> directory of this template project provides public header files.</p>\n<ul>\n<li>\n<em>alpha/alpha-common.h</em> contains APIs that are common to the three\nlibraries, such as error codes or common types;</li>\n<li>\n<em>alpha/alpha-client.h</em> contains the client-side functions to create\nand destroy a client object;</li>\n<li>\n<em>alpha/alpha-resource.h</em> contains the client-side functions to create\nand destroy resource handles, and to interact with a resource through\na resource handle;</li>\n<li>\n<em>alpha/alpha-server.h</em> contains functions to register and destroy\na provider;</li>\n<li>\n<em>alpha/alpha-backend.h</em> contains the definition of a structure that\none would need to implement in order to provide a new backend for\nyour microservice;</li>\n<li>\n<em>alpha/alpha-admin.h</em> contains the functions to create and destroy\nan admin object, as well as admin functions to interact with a provider;</li>\n<li>\n<em>alpha/alpha-provider-handle.h</em> contains the definition of a provider handle.\nThis type of construct is often used in Mochi services to encapsulate\nan address and a provider id.</li>\n</ul>\n<p>The implementation of all these functions is located in the <em>src</em> directory.\nThe source also includes functionalities such as a small header-based logging library.\nThe <em>src/dummy</em> directory provides a default implementation of a backend. This\nbackend also exemplifies the use of the <a href=\"https://github.com/json-c/json-c\">json-c</a> library\nfor JSON-based resource configuration. We recommend that you implement a dummy backend for your\nservice, as a way of testing application logic and RPCs without the burden of complex\nexternal dependencies. For instance, a dummy backend may be a backend that simply\nacknowledges requests but does not process them, or provides mock results.</p>\n<p>The <em>examples</em> directory contains an example using the microservice:\nthe server example will start a provider and print its address (if logging was enabled).\nThe admin example will connect to this provider and have it create a resource, then\nprint the resource id. The client example can be run next to interact with the resource.</p>\n<p>The <em>tests</em> directory contains a set of unit tests for your service.\nIt relies on <a href=\"https://nemequ.github.io/munit\" rel=\"nofollow\">\u00b5nit</a> (included in this repository),\na C unit-test library under an MIT license. Feel free to continue using it as you\nadd more functionalities to your microservice; unit-testing is just good software\ndevelopment practice in general.</p>\n<p>The template also contains a <em>spack.yaml</em> file at its root that can be used to\ninstall its dependencies. You may add additional dependencies into this file as\nyour microservice gets more complex.</p>\n<p>As you modify this project to implement your own microservice, feel free to remove\nany dependencies you don't like (such as json-c or \u00b5nit) and adapt it to your needs!</p>\n<h2>\n<a id=\"user-content-setting-up-your-project\" class=\"anchor\" href=\"#setting-up-your-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up your project</h2>\n<p>Let's assume you want to create a microservice called \"yellow\", which manages\na phone directory (association between names and phone numbers). The following\nshows how to setup your project:</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/templates/margo-microservice-template.git\nmv margo-microservice-template yellow\ncd yellow\nrm -rf .git\npython setup.py\n$ Enter the name of your service: yellow\n$ Enter the name of the resources (e.g., database): phonebook\n</code></pre>\n<p>The python script will edit and rename all the files, replacing <em>alpha</em> with <em>yellow</em>\nand <em>resource</em> with <em>phonebook</em>.</p>\n<h2>\n<a id=\"user-content-building-the-project\" class=\"anchor\" href=\"#building-the-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the project</h2>\n<p>The project's dependencies may be build using <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack</a>.\nYou will need to have setup <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">sds-repo</a> as external\nnamespace for spack, which can be done as follows.</p>\n<pre><code># from outside of your project directory\ngit clone git@xgitlab.cels.anl.gov:sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>The easiest way to setup the dependencies for this project is to create a spack environment\nusing the <em>spack.yaml</em> file located at the root of the project, as follows.</p>\n<pre><code># create an anonymous environment\ncd margo-microservice-template\nspack env activate .\nspack install\n</code></pre>\n<p>or as follows.</p>\n<pre><code># create an environment named myenv\ncd margo-microservice-template\nspack env create myenv spack.yaml\nspack env activate myenv\nspack install\n</code></pre>\n<p>Once the dependencies have been installed, you may build the project as follows.</p>\n<pre><code>mkdir build\ncd build\ncmake .. -DENABLE_LOG_INFO=ON -DENABLE_LOG_ERROR=ON -DENABLE_LOG_DEBUG=ON -DENABLE_TESTS=ON -DENABLE_EXAMPLES=ON\nmake\n</code></pre>\n<p>You can test the project using <code>make test</code> from the build directory.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1615278214.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "player1537-playground/triple-r",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-margo-microservice-template\" class=\"anchor\" href=\"#margo-microservice-template\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo Microservice Template</h1>\n<p>This project is a template to start developing a Mochi microservice based on Margo.\nIf you want to implement your own microservice, please read ahead. Though this project\nprovides many examples of how to use the Margo API, you may want to refer to the Margo\ndocumentation <a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a> for more detail.</p>\n<h2>\n<a id=\"user-content-the-mochi-philosophy\" class=\"anchor\" href=\"#the-mochi-philosophy\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Mochi philosophy</h2>\n<p>The philosophy of the Mochi project consists of providing a set of building blocks\nfor developing HPC data service. Each building block is meant to offer <strong>efficient</strong>,\n<strong>location-agnostic</strong> access to a <strong>simple set of functionalities</strong> through\n<strong>modular backends</strong>, while <strong>seamlessly sharing hardware</strong> (compute and network)\nwith other building blocks.</p>\n<p>A <strong>simple set of functionalities</strong> may be, for example, <em>\"storing and retrieving\nsmall key/value pairs\"</em>, a common feature found in many storage systems to manage\nmetadata. The <strong>location-agnostic</strong> aspect aims at making such a feature available\nto user programs in the same manner and through the same API regardless of whether\nthe service runs in the same process, on the same node but on different processes,\nor on a different node across a network. The <strong>modular backends</strong> aspect makes it\npossible to abstract the implementation of such a feature and, if not providing\nmultiple implementations, at least providing the means for someone to easily swap\nthe default implementation of the feature for their own. Because multiple building\nblocks may be running on the same node, such a building block should efficiently\nshare the compute and network hardware with other building blocks. This is done\nby sharing a common networking and threading layer: Margo.</p>\n<h2>\n<a id=\"user-content-design-overview\" class=\"anchor\" href=\"#design-overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design overview</h2>\n<p>The typical design of a Mochi microservice revolves around three libraries:\n<strong>server</strong>, <strong>client</strong>, and <strong>admin</strong>.</p>\n<ul>\n<li>The server library contains a service <strong>provider</strong>, that is, an object that\ncan receive some predefined RPCs to offer a particular functionality. Within\nthe same process, multiple providers of the same service may be instantiated,\nusing distinct <strong>provider ids</strong> (<code>uint16_t</code>). A provider is responsible for\nmanaging a set of <strong>resources</strong>. In the example of a storage for key/value\npairs, a resource may be a database. The functionalities of a provider may\nbe enabled by multiple <strong>backends</strong>. For example, a database may be implemented\nusing LevelDB, BerkeleyDB, or simply using an in-memory hash table.\nPrograms sending requests to a provider should <strong>not</strong> be unaware of the backend used\nto implement the requested functionality. This allows multiple backends to be\ntested, and for backends to evolve independently from user applications.</li>\n<li>The client library is the library through which user applications or higher-level\nservices interact with providers. It will typically provide a <strong>client</strong> structure\nthat is used to register the set of RPCs that can be invoked, and a <strong>resource handle</strong>\nstructure that references a particular resource located on a particular provider.\nUser applications will typically initialize a singe client object for a service, and\nfrom this client object instantiate as many resource handles as needed to interact with\navailable resources. Resources are identified by a <strong>resource id</strong>, which are generally\neither a name, an integer, or a\n<a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\" rel=\"nofollow\">uuid</a> (this template\nproject uses uuids).</li>\n<li>The admin library is the library through which a user application can send\nrequests that are meant for the provider itself rather than for a resource.\nA few most common such requests include the creation and destruction of\nresources, their migration, etc. It can be useful to think of the admin\nlibrary as the set of features you would want to provide to the person or\napplication that sets up the service, rather than the person or application\nthat uses its functionalities.</li>\n</ul>\n<h2>\n<a id=\"user-content-organization-of-this-template-project\" class=\"anchor\" href=\"#organization-of-this-template-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Organization of this template project</h2>\n<p>This template project illustrates how a Margo-based microservice could\nbe architected. It can be compiled as-is, and provides a couple of\nfunctionalities that make the provider print a \"Hello World\" message\non its standard output, or compute the sum of two integers.</p>\n<p>This template project uses <strong>alpha</strong> as the name of your microservice.\nFunctions, types, files, and libraries therefore use the <strong>alpha</strong> prefix.\nThe first step in setting up this project for your microservice will be\nto replace this prefix. The generic name <strong>resource</strong> should also be\nreplaced with a more specific name, such as <strong>database</strong>. This renaming\nstep can be done by using the <em>setup.py</em> script at the root of this repository\n(see next section).</p>\n<p>The <em>include</em> directory of this template project provides public header files.</p>\n<ul>\n<li>\n<em>alpha/alpha-common.h</em> contains APIs that are common to the three\nlibraries, such as error codes or common types;</li>\n<li>\n<em>alpha/alpha-client.h</em> contains the client-side functions to create\nand destroy a client object;</li>\n<li>\n<em>alpha/alpha-resource.h</em> contains the client-side functions to create\nand destroy resource handles, and to interact with a resource through\na resource handle;</li>\n<li>\n<em>alpha/alpha-server.h</em> contains functions to register and destroy\na provider;</li>\n<li>\n<em>alpha/alpha-backend.h</em> contains the definition of a structure that\none would need to implement in order to provide a new backend for\nyour microservice;</li>\n<li>\n<em>alpha/alpha-admin.h</em> contains the functions to create and destroy\nan admin object, as well as admin functions to interact with a provider;</li>\n<li>\n<em>alpha/alpha-provider-handle.h</em> contains the definition of a provider handle.\nThis type of construct is often used in Mochi services to encapsulate\nan address and a provider id.</li>\n</ul>\n<p>The implementation of all these functions is located in the <em>src</em> directory.\nThe source also includes functionalities such as a small header-based logging library.\nThe <em>src/dummy</em> directory provides a default implementation of a backend. This\nbackend also exemplifies the use of the <a href=\"https://github.com/json-c/json-c\">json-c</a> library\nfor JSON-based resource configuration. We recommend that you implement a dummy backend for your\nservice, as a way of testing application logic and RPCs without the burden of complex\nexternal dependencies. For instance, a dummy backend may be a backend that simply\nacknowledges requests but does not process them, or provides mock results.</p>\n<p>The <em>examples</em> directory contains an example using the microservice:\nthe server example will start a provider and print its address (if logging was enabled).\nThe admin example will connect to this provider and have it create a resource, then\nprint the resource id. The client example can be run next to interact with the resource.</p>\n<p>The <em>tests</em> directory contains a set of unit tests for your service.\nIt relies on <a href=\"https://nemequ.github.io/munit\" rel=\"nofollow\">\u00b5nit</a> (included in this repository),\na C unit-test library under an MIT license. Feel free to continue using it as you\nadd more functionalities to your microservice; unit-testing is just good software\ndevelopment practice in general.</p>\n<p>The template also contains a <em>spack.yaml</em> file at its root that can be used to\ninstall its dependencies. You may add additional dependencies into this file as\nyour microservice gets more complex.</p>\n<p>As you modify this project to implement your own microservice, feel free to remove\nany dependencies you don't like (such as json-c or \u00b5nit) and adapt it to your needs!</p>\n<h2>\n<a id=\"user-content-setting-up-your-project\" class=\"anchor\" href=\"#setting-up-your-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up your project</h2>\n<p>Let's assume you want to create a microservice called \"yellow\", which manages\na phone directory (association between names and phone numbers). The following\nshows how to setup your project:</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/templates/margo-microservice-template.git\nmv margo-microservice-template yellow\ncd yellow\nrm -rf .git\npython setup.py\n$ Enter the name of your service: yellow\n$ Enter the name of the resources (e.g., database): phonebook\n</code></pre>\n<p>The python script will edit and rename all the files, replacing <em>alpha</em> with <em>yellow</em>\nand <em>resource</em> with <em>phonebook</em>.</p>\n<h2>\n<a id=\"user-content-building-the-project\" class=\"anchor\" href=\"#building-the-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the project</h2>\n<p>The project's dependencies may be build using <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack</a>.\nYou will need to have setup <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">sds-repo</a> as external\nnamespace for spack, which can be done as follows.</p>\n<pre><code># from outside of your project directory\ngit clone git@xgitlab.cels.anl.gov:sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>The easiest way to setup the dependencies for this project is to create a spack environment\nusing the <em>spack.yaml</em> file located at the root of the project, as follows.</p>\n<pre><code># create an anonymous environment\ncd margo-microservice-template\nspack env activate .\nspack install\n</code></pre>\n<p>or as follows.</p>\n<pre><code># create an environment named myenv\ncd margo-microservice-template\nspack env create myenv spack.yaml\nspack env activate myenv\nspack install\n</code></pre>\n<p>Once the dependencies have been installed, you may build the project as follows.</p>\n<pre><code>mkdir build\ncd build\ncmake .. -DENABLE_LOG_INFO=ON -DENABLE_LOG_ERROR=ON -DENABLE_LOG_DEBUG=ON -DENABLE_TESTS=ON -DENABLE_EXAMPLES=ON\nmake\n</code></pre>\n<p>You can test the project using <code>make test</code> from the build directory.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1614726226.0
    },
    {
        "data_format": 2,
        "description": "SYMBIOMON Monitoring Microservice",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "srini009/symbiomon",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-margo-microservice-template\" class=\"anchor\" href=\"#margo-microservice-template\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo Microservice Template</h1>\n<p>This project is a template to start developing a Mochi microservice based on Margo.\nIf you want to implement your own microservice, please read ahead. Though this project\nprovides many examples of how to use the Margo API, you may want to refer to the Margo\ndocumentation <a href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a> for more detail.</p>\n<h2>\n<a id=\"user-content-the-mochi-philosophy\" class=\"anchor\" href=\"#the-mochi-philosophy\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Mochi philosophy</h2>\n<p>The philosophy of the Mochi project consists of providing a set of building blocks\nfor developing HPC data service. Each building block is meant to offer <strong>efficient</strong>,\n<strong>location-agnostic</strong> access to a <strong>simple set of functionalities</strong> through\n<strong>modular backends</strong>, while <strong>seamlessly sharing hardware</strong> (compute and network)\nwith other building blocks.</p>\n<p>A <strong>simple set of functionalities</strong> may be, for example, <em>\"storing and retrieving\nsmall key/value pairs\"</em>, a common feature found in many storage systems to manage\nmetadata. The <strong>location-agnostic</strong> aspect aims at making such a feature available\nto user programs in the same manner and through the same API regardless of whether\nthe service runs in the same process, on the same node but on different processes,\nor on a different node across a network. The <strong>modular backends</strong> aspect makes it\npossible to abstract the implementation of such a feature and, if not providing\nmultiple implementations, at least providing the means for someone to easily swap\nthe default implementation of the feature for their own. Because multiple building\nblocks may be running on the same node, such a building block should efficiently\nshare the compute and network hardware with other building blocks. This is done\nby sharing a common networking and threading layer: Margo.</p>\n<h2>\n<a id=\"user-content-design-overview\" class=\"anchor\" href=\"#design-overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design overview</h2>\n<p>The typical design of a Mochi microservice revolves around three libraries:\n<strong>server</strong>, <strong>client</strong>, and <strong>admin</strong>.</p>\n<ul>\n<li>The server library contains a service <strong>provider</strong>, that is, an object that\ncan receive some predefined RPCs to offer a particular functionality. Within\nthe same process, multiple providers of the same service may be instantiated,\nusing distinct <strong>provider ids</strong> (<code>uint16_t</code>). A provider is responsible for\nmanaging a set of <strong>resources</strong>. In the example of a storage for key/value\npairs, a resource may be a database. The functionalities of a provider may\nbe enabled by multiple <strong>backends</strong>. For example, a database may be implemented\nusing LevelDB, BerkeleyDB, or simply using an in-memory hash table.\nPrograms sending requests to a provider should <strong>not</strong> be unaware of the backend used\nto implement the requested functionality. This allows multiple backends to be\ntested, and for backends to evolve independently from user applications.</li>\n<li>The client library is the library through which user applications or higher-level\nservices interact with providers. It will typically provide a <strong>client</strong> structure\nthat is used to register the set of RPCs that can be invoked, and a <strong>resource handle</strong>\nstructure that references a particular resource located on a particular provider.\nUser applications will typically initialize a singe client object for a service, and\nfrom this client object instantiate as many resource handles as needed to interact with\navailable resources. Resources are identified by a <strong>resource id</strong>, which are generally\neither a name, an integer, or a\n<a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\" rel=\"nofollow\">uuid</a> (this template\nproject uses uuids).</li>\n<li>The admin library is the library through which a user application can send\nrequests that are meant for the provider itself rather than for a resource.\nA few most common such requests include the creation and destruction of\nresources, their migration, etc. It can be useful to think of the admin\nlibrary as the set of features you would want to provide to the person or\napplication that sets up the service, rather than the person or application\nthat uses its functionalities.</li>\n</ul>\n<h2>\n<a id=\"user-content-organization-of-this-template-project\" class=\"anchor\" href=\"#organization-of-this-template-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Organization of this template project</h2>\n<p>This template project illustrates how a Margo-based microservice could\nbe architected. It can be compiled as-is, and provides a couple of\nfunctionalities that make the provider print a \"Hello World\" message\non its standard output, or compute the sum of two integers.</p>\n<p>This template project uses <strong>alpha</strong> as the name of your microservice.\nFunctions, types, files, and libraries therefore use the <strong>alpha</strong> prefix.\nThe first step in setting up this project for your microservice will be\nto replace this prefix. The generic name <strong>resource</strong> should also be\nreplaced with a more specific name, such as <strong>database</strong>. This renaming\nstep can be done by using the <em>setup.py</em> script at the root of this repository\n(see next section).</p>\n<p>The <em>include</em> directory of this template project provides public header files.</p>\n<ul>\n<li>\n<em>alpha/alpha-common.h</em> contains APIs that are common to the three\nlibraries, such as error codes or common types;</li>\n<li>\n<em>alpha/alpha-client.h</em> contains the client-side functions to create\nand destroy a client object;</li>\n<li>\n<em>alpha/alpha-resource.h</em> contains the client-side functions to create\nand destroy resource handles, and to interact with a resource through\na resource handle;</li>\n<li>\n<em>alpha/alpha-server.h</em> contains functions to register and destroy\na provider;</li>\n<li>\n<em>alpha/alpha-backend.h</em> contains the definition of a structure that\none would need to implement in order to provide a new backend for\nyour microservice;</li>\n<li>\n<em>alpha/alpha-admin.h</em> contains the functions to create and destroy\nan admin object, as well as admin functions to interact with a provider;</li>\n<li>\n<em>alpha/alpha-provider-handle.h</em> contains the definition of a provider handle.\nThis type of construct is often used in Mochi services to encapsulate\nan address and a provider id.</li>\n</ul>\n<p>The implementation of all these functions is located in the <em>src</em> directory.\nThe source also includes functionalities such as a small header-based logging library.\nThe <em>src/dummy</em> directory provides a default implementation of a backend. This\nbackend also exemplifies the use of the <a href=\"https://github.com/json-c/json-c\">json-c</a> library\nfor JSON-based resource configuration. We recommend that you implement a dummy backend for your\nservice, as a way of testing application logic and RPCs without the burden of complex\nexternal dependencies. For instance, a dummy backend may be a backend that simply\nacknowledges requests but does not process them, or provides mock results.</p>\n<p>The <em>examples</em> directory contains an example using the microservice:\nthe server example will start a provider and print its address (if logging was enabled).\nThe admin example will connect to this provider and have it create a resource, then\nprint the resource id. The client example can be run next to interact with the resource.</p>\n<p>The <em>tests</em> directory contains a set of unit tests for your service.\nIt relies on <a href=\"https://nemequ.github.io/munit\" rel=\"nofollow\">\u00b5nit</a> (included in this repository),\na C unit-test library under an MIT license. Feel free to continue using it as you\nadd more functionalities to your microservice; unit-testing is just good software\ndevelopment practice in general.</p>\n<p>The template also contains a <em>spack.yaml</em> file at its root that can be used to\ninstall its dependencies. You may add additional dependencies into this file as\nyour microservice gets more complex.</p>\n<p>As you modify this project to implement your own microservice, feel free to remove\nany dependencies you don't like (such as json-c or \u00b5nit) and adapt it to your needs!</p>\n<h2>\n<a id=\"user-content-setting-up-your-project\" class=\"anchor\" href=\"#setting-up-your-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setting up your project</h2>\n<p>Let's assume you want to create a microservice called \"yellow\", which manages\na phone directory (association between names and phone numbers). The following\nshows how to setup your project:</p>\n<pre><code>git clone https://xgitlab.cels.anl.gov/sds/templates/margo-microservice-template.git\nmv margo-microservice-template yellow\ncd yellow\nrm -rf .git\npython setup.py\n$ Enter the name of your service: yellow\n$ Enter the name of the resources (e.g., database): phonebook\n</code></pre>\n<p>The python script will edit and rename all the files, replacing <em>alpha</em> with <em>yellow</em>\nand <em>resource</em> with <em>phonebook</em>.</p>\n<h2>\n<a id=\"user-content-building-the-project\" class=\"anchor\" href=\"#building-the-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the project</h2>\n<p>The project's dependencies may be build using <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack</a>.\nYou will need to have setup <a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">sds-repo</a> as external\nnamespace for spack, which can be done as follows.</p>\n<pre><code># from outside of your project directory\ngit clone git@xgitlab.cels.anl.gov:sds/sds-repo.git\nspack repo add sds-repo\n</code></pre>\n<p>The easiest way to setup the dependencies for this project is to create a spack environment\nusing the <em>spack.yaml</em> file located at the root of the project, as follows.</p>\n<pre><code># create an anonymous environment\ncd margo-microservice-template\nspack env activate .\nspack install\n</code></pre>\n<p>or as follows.</p>\n<pre><code># create an environment named myenv\ncd margo-microservice-template\nspack env create myenv spack.yaml\nspack env activate myenv\nspack install\n</code></pre>\n<p>Once the dependencies have been installed, you may build the project as follows.</p>\n<pre><code>mkdir build\ncd build\ncmake .. -DENABLE_LOG_INFO=ON -DENABLE_LOG_ERROR=ON -DENABLE_LOG_DEBUG=ON -DENABLE_TESTS=ON -DENABLE_EXAMPLES=ON\nmake\n</code></pre>\n<p>You can test the project using <code>make test</code> from the build directory.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619096999.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "player1537-playground/decaf-superbuild",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-decaf--henson-superbuild\" class=\"anchor\" href=\"#decaf--henson-superbuild\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Decaf / Henson Superbuild</h1>\n<p>This repository makes use of CMake features to enable easier integration and\nuse of Decaf and/or Henson for scientific workflows. In essence, external\nlow-level dependencies (boost, cmake, mpich, diy, and python) are installed\nusing Spack, Python dependencies (networkx, scipy, numpy, matplotlib) are\ninstalled within a Python virtual environment, and higher-level dependencies\n(decaf, diy, qhull, tess, and henson) are built from source using CMake's\nExternalProject library.</p>\n<p>The dependencies that are built by CMake also put their source code in a local\ndirectory for easier modification and development. For example, after changing\nHenson code manually, the entire set of dependencies are re-built with the same\nbasic build command.</p>\n<h2>\n<a id=\"user-content-usage-gosh\" class=\"anchor\" href=\"#usage-gosh\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage (\"go.sh\")</h2>\n<p>There is a helper script at the root of this repository that helps automate\nmany of the commands. It can be used for every step of the process and is short\nand easy to read if modifications are needed.</p>\n<p><strong>Spack Dependencies</strong> are defined in the <code>spack.yaml</code> file.</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span> Load the Spack environment defined by the spack.yaml file</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span>   (Run this every time you load the project)</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c1\">eval</span> <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>./go.sh spack env activate --sh .<span class=\"pl-pds\">)</span></span></span>\n\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span> Install the dependencies</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span>   (Run this once)</span></span>\n$ <span class=\"pl-s1\">./go.sh spack install</span></pre></div>\n<p><strong>Python Dependencies</strong> are defined in the <code>requirments.txt</code> file.</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span> Setup and install the Python dependencies</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span>  (Run this once)</span></span>\n$ <span class=\"pl-s1\">./go.sh venv</span>\n\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span> Load the Python environment</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span>  (Run this every time you load the project)</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c1\">source</span> venv/bin/activate</span></pre></div>\n<p><strong>Source Dependencies</strong> are defined the in root <code>CMakeLists.txt</code> file and the <code>cmake/Find&lt;Package&gt;.cmake</code> files.</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span> Setup the build directory</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span>  (Run this every time you change the CMakeLists.txt file)</span></span>\n$ <span class=\"pl-s1\">./go.sh cmake</span>\n\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span> Build the source dependencies and main project</span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span>  (Run this every time you change the code)</span></span>\n$ <span class=\"pl-s1\">./go.sh make</span></pre></div>\n<p><strong>Running the Code</strong> requires setting up the <code>LD_LIBRARY_PATH</code> environment variable.</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c\"><span class=\"pl-c\">#</span> Run the built code with the correct environment</span></span>\n$ <span class=\"pl-s1\">./go.sh <span class=\"pl-c1\">exec</span> build/my_executable</span></pre></div>\n<h2>\n<a id=\"user-content-simplest-usage-copy-paste\" class=\"anchor\" href=\"#simplest-usage-copy-paste\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Simplest Usage (copy-paste)</h2>\n<p>Run these once to setup the project.</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\">eval</span> <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>./go.sh spack env activate --sh .<span class=\"pl-pds\">)</span></span></span>\n$ <span class=\"pl-s1\">./go.sh spack install</span>\n$ <span class=\"pl-s1\">./go.sh venv</span>\n$ <span class=\"pl-s1\"><span class=\"pl-c1\">source</span> venv/bin/activate</span>\n$ <span class=\"pl-s1\">./go.sh cmake</span>\n$ <span class=\"pl-s1\">./go.sh make</span></pre></div>\n<p>Run these when starting to work on this project again.</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\"><span class=\"pl-c1\">eval</span> <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>./go.sh spack env activate --sh .<span class=\"pl-pds\">)</span></span></span>\n$ <span class=\"pl-s1\"><span class=\"pl-c1\">source</span> venv/bin/activate</span>\n$ <span class=\"pl-s1\">./go.sh cmake</span>\n$ <span class=\"pl-s1\">./go.sh make</span></pre></div>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1609822020.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack_bwa_docker_ubuntu2004_x86_64.yaml"
        ],
        "full_name": "CINECA-HPC/container_bioinfo_bwa_ubuntu2004_x86_64",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-container_bioinfo_bwa_ubuntu2004_x86_64\" class=\"anchor\" href=\"#container_bioinfo_bwa_ubuntu2004_x86_64\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>container_bioinfo_bwa_ubuntu2004_x86_64</h1>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1612481523.0
    },
    {
        "data_format": 2,
        "description": "Recipes to generate container images and experiment with Github registry",
        "filenames": [
            "gromacs/spack.yaml",
            "quantum-espresso/spack.yaml"
        ],
        "full_name": "alalazo/container-images",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-container-images\" class=\"anchor\" href=\"#container-images\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>container-images</h1>\n<p>Recipes to generate container images and experiment with Github registry</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1617273120.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack_bismark_docker_ubuntu2004_x86_64.yaml"
        ],
        "full_name": "CINECA-HPC/container_bioinfo_bismark_ubuntu2004_x86_64",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-container_bioinfo_bismark_ubuntu2004_x86_64\" class=\"anchor\" href=\"#container_bioinfo_bismark_ubuntu2004_x86_64\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>container_bioinfo_bismark_ubuntu2004_x86_64</h1>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1606942003.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack_openmpi_strip_ubuntu2004.yaml"
        ],
        "full_name": "CINECA-HPC/container_spack_ubuntu2004_x86_64",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-container_spack_ubuntu2004_x86_64\" class=\"anchor\" href=\"#container_spack_ubuntu2004_x86_64\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>container_spack_ubuntu2004_x86_64</h1>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1614022773.0
    },
    {
        "data_format": 2,
        "description": "CCI DRP Spack configuration",
        "filenames": [
            "openFoam24/spack.yaml"
        ],
        "full_name": "SCOREC/drp-spack-config",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-drp-spack-config\" class=\"anchor\" href=\"#drp-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>drp-spack-config</h1>\n<p>CCI DRP Spack configuration</p>\n<h1>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h1>\n<p>openFoam24 - spack environment for an OpenFoam Organization 2.4.0 install</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 3,
        "topics": [],
        "updated_at": 1593675795.0
    },
    {
        "data_format": 2,
        "description": "Containers for arch x86_64 based on Centos 7 and 8 with GNU 7 and 8 compiler and different versions of Spack 0.15.4 and 0.16.0",
        "filenames": [
            "spack_openmpi_strip_centos8.yaml"
        ],
        "full_name": "CINECA-HPC/container_spack_centos_x86_64",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-container_spack_centos_x86_64\" class=\"anchor\" href=\"#container_spack_centos_x86_64\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>container_spack_centos_x86_64</h1>\n<p>Containers for arch x86_64 based on Centos 7 with GNU 7 compiler and different versions of Spack</p>\n<ul>\n<li>15.4</li>\n<li>16.0</li>\n</ul>\n<p>IMPORTANT (NOT NECESSARY IF YOU START FROM A DOCKER IMAGE): When you are going to work inside the container remember to source these 2 file in order to set the proper module environment with spack and Lmod</p>\n<ul>\n<li>source /opt/spack/share/spack/setup-env.sh</li>\n<li>source /usr/share/lmod/8.2.7/init/sh</li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [
            "spack"
        ],
        "updated_at": 1614203765.0
    },
    {
        "data_format": 2,
        "description": "My development environment built with spack",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "jacobmerson/spack-develop-env",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-container_spack_centos_x86_64\" class=\"anchor\" href=\"#container_spack_centos_x86_64\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>container_spack_centos_x86_64</h1>\n<p>Containers for arch x86_64 based on Centos 7 with GNU 7 compiler and different versions of Spack</p>\n<ul>\n<li>15.4</li>\n<li>16.0</li>\n</ul>\n<p>IMPORTANT (NOT NECESSARY IF YOU START FROM A DOCKER IMAGE): When you are going to work inside the container remember to source these 2 file in order to set the proper module environment with spack and Lmod</p>\n<ul>\n<li>source /opt/spack/share/spack/setup-env.sh</li>\n<li>source /usr/share/lmod/8.2.7/init/sh</li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1588763757.0
    },
    {
        "data_format": 2,
        "description": "A mirror of Ristra's internal gitlab repository. ",
        "filenames": [
            "env/power9le/flecsalemm-deps/spack.yaml",
            "env/x86_64/flecsalemm-deps/spack.yaml",
            ".gitlab-ci/env/local-build/spack.yaml",
            ".gitlab-ci/env/dry-run/spack.yaml",
            ".gitlab-ci/env/root-build/spack.yaml",
            "env/broadwell/flecsalemm-deps/spack.yaml"
        ],
        "full_name": "laristra/ristra_spackages",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-ristra-spackages\" class=\"anchor\" href=\"#ristra-spackages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Ristra Spackages</h1>\n<p>This repository contains the custom spackage files for the repos in laristra family.</p>\n<h2>\n<a id=\"user-content-basic-usage\" class=\"anchor\" href=\"#basic-usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Basic Usage</h2>\n<p>We assume the user wish to work in the home directory and already have a spack instance setup.  The minimum required version of spack is 0.15.2.</p>\n<p>To get the content of this repo</p>\n<pre><code>$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git\n</code></pre>\n<p>To use the custom spackage files with your spack</p>\n<pre><code>$ spack repo add ristra_spackages/spack-repo\n==&gt; Added repo with namespace 'lanl_ristra'.\n\n$ spack repo list\n==&gt; 2 package repositories.\nlanl_ristra        /home/&lt;user&gt;/ristra_spackages/spack-repo\nbuiltin            /home/&lt;user&gt;/spack/var/spack/repos/builtin\n</code></pre>\n<p>[Optional]\nTo ensure you have this custom repo in your spack all the time, move the <code>repos.yaml</code> into your spack config folder</p>\n<pre><code>$ mv /home/&lt;user&gt;/.spack/linux/repos.yaml /home/&lt;user&gt;/spack/etc/spack/\n</code></pre>\n<p>Please see the <a href=\"https://spack.readthedocs.io/en/latest/configuration.html\" rel=\"nofollow\">Spack documentation</a> for more detailed info.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1619495889.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "var/spack/environments/daint/spack.yaml",
            "var/spack/environments/tsa/spack.yaml"
        ],
        "full_name": "MeteoSwiss-APN/spack",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-the-meteoschweiz-spack-deployment\" class=\"anchor\" href=\"#the-meteoschweiz-spack-deployment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The Meteoschweiz Spack Deployment</h1>\n<p>Official Spack documentation <a href=\"#-spack\">below</a>.</p>\n<h2>\n<a id=\"user-content-building-software-on-tsadaint\" class=\"anchor\" href=\"#building-software-on-tsadaint\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building software on tsa/daint</h2>\n<p>First git clone the Meteoschweiz spack fork and source the spack file under spack/share/spack in order to use it</p>\n<pre><code>$ git clone https://github.com/elsagermann/spack.git\n$ cd spack/share/spack\n$ . setup-env.sh\n</code></pre>\n<p>Then activate the environment machine (tsa, daint)</p>\n<pre><code>$ spack env activate &lt;machine&gt;\n</code></pre>\n<p>You are then able to build any packages available (<em>spack list</em> to print the whole list of available packages)</p>\n<pre><code>$ spack install &lt;package&gt;@&lt;version&gt;%&lt;compiler&gt; +&lt;variants&gt;\n</code></pre>\n<p>Ex:</p>\n<pre><code>$ spack install cosmo@master%pgi cosmo_target=gpu\n</code></pre>\n<p>This will clone the package, build it and then install the chosen package and all its dependencies under <em>/scratch/$USER/install/tsa</em> (see <em>config.yaml</em> file section for details). The build-stage of your package and its dependencies are not kept (add <em>--keep-stage</em> after the install command in order to keep it). Module files are also created during this process and installed under <em>/scratch/$USER/modules/</em></p>\n<h2>\n<a id=\"user-content-dev-building-software-on-tsadaint\" class=\"anchor\" href=\"#dev-building-software-on-tsadaint\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dev-building software on tsa/daint</h2>\n<p>If you do not want to git clone the source of the package you want to install, especially if you are developing, you can use a local source in order to install your package. In order to do so, first go to the base directory of the package and then use spack <em>dev-build</em> instead of spack install</p>\n<pre><code>$ cd &lt;package_base_directory&gt;\n$ spack dev-build &lt;package&gt;@&lt;version&gt;%&lt;compiler&gt; +&lt;variants&gt;\n</code></pre>\n<p>The package, its dependencies and its modules will be still installed under <em>/scratch/$USER/install/tsa</em> &amp; <em>/scratch/$USER/modules/</em></p>\n<h2>\n<a id=\"user-content-spack-info\" class=\"anchor\" href=\"#spack-info\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack info</h2>\n<p>Use the spack command</p>\n<pre><code>$ spack info &lt;package&gt;\n</code></pre>\n<p>in order to get a list of all possible building configuration available such as: version available, list of dependencies and variants. Variants are a key-feature of spack since it tells it which build configuration we want (i.e COSMO with target gpu or cpu)</p>\n<h2>\n<a id=\"user-content-spack-edit\" class=\"anchor\" href=\"#spack-edit\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack edit</h2>\n<p>Use the spack command</p>\n<pre><code>$ spack edit &lt;package&gt;\n</code></pre>\n<p>in order to open the correspondig <em>package.py</em> file and edit it directly</p>\n<h2>\n<a id=\"user-content-machine-specific-config-files\" class=\"anchor\" href=\"#machine-specific-config-files\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Machine specific config files</h2>\n<p>Are available under <em>spack/var/spack/environements/<code>&lt;machine&gt;</code></em>. Their structure is:</p>\n<ul>\n    <li>spack.yaml (spack environment file, describes the set of packages to be installed, and includes the below machine config files)</li>\n    <li>config:</li>\n        <ul>\n            <li>\n\t    -compilers.yaml (all info about available compilers, machine specific compiler flags, module to load (PrgEnv) before compiling)</li>\n            <li>-packages.yaml (all info about the already installed dependencies, i.e their module names or paths)</li>\n            <li>-modules.yaml (all info about the created modules, i.e which env variable or modules should be set once loaded)</li>\n            <li>-config.yaml (specifies the main installation path and the main module installation path, where to find the binaries etc.)</li>\n        </ul>\n    \n</ul>\n<h1>\n<a id=\"user-content--spack\" class=\"anchor\" href=\"#-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\" width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\" style=\"max-width:100%;\"></a> Spack</h1>\n<p><a href=\"https://travis-ci.org/spack/spack\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/be67f91ea78cc90b2cc005e3fc22f792ee6c6b9664537968cd5873f24a60b61d/68747470733a2f2f7472617669732d63692e6f72672f737061636b2f737061636b2e7376673f6272616e63683d646576656c6f70\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/spack/spack.svg?branch=develop\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/spack/spack/actions\"><img src=\"https://github.com/spack/spack/workflows/linux%20builds/badge.svg\" alt=\"Linux Builds\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/spack/spack\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4e223725486ecdae463d02d6ebd2b814945366210a908fc6f04b044ada8a7820/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://spack.readthedocs.io\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/523aba38ec3f8d2294b874493fe63feed5805b98460c385611397b02be14a51c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\" style=\"max-width:100%;\"></a>\n<a href=\"https://spackpm.herokuapp.com\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/39669916879beaeda0aef12ebdc4b5f7a626f48df14c253cf0b6db3b4c563202/68747470733a2f2f737061636b706d2e6865726f6b756170702e636f6d2f62616467652e737667\" alt=\"Slack\" data-canonical-src=\"https://spackpm.herokuapp.com/badge.svg\" style=\"max-width:100%;\"></a></p>\n<p>Spack is a multi-platform package manager that builds and installs\nmultiple versions and configurations of software. It works on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing a\nnew version of a package does not break existing installations, so many\nconfigurations of the same package can coexist.</p>\n<p>Spack offers a simple \"spec\" syntax that allows users to specify versions\nand configuration options. Package files are written in pure Python, and\nspecs allow package authors to write a single script for many different\nbuilds of the same package.  With Spack, you can build your software\n<em>all</em> the ways you want to.</p>\n<p>See the\n<a href=\"http://spack.readthedocs.io/en/latest/features.html\" rel=\"nofollow\">Feature Overview</a>\nfor examples and highlights.</p>\n<p>To install spack and your first package, make sure you have Python.\nThen:</p>\n<pre><code>$ git clone https://github.com/spack/spack.git\n$ cd spack/bin\n$ ./spack install zlib\n</code></pre>\n<h2>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p><a href=\"http://spack.readthedocs.io/\" rel=\"nofollow\"><strong>Full documentation</strong></a> is available, or\nrun <code>spack help</code> or <code>spack help --all</code>.</p>\n<h2>\n<a id=\"user-content-tutorial\" class=\"anchor\" href=\"#tutorial\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tutorial</h2>\n<p>We maintain a\n<a href=\"http://spack.readthedocs.io/en/latest/tutorial.html\" rel=\"nofollow\"><strong>hands-on tutorial</strong></a>.\nIt covers basic to advanced usage, packaging, developer features, and large HPC\ndeployments.  You can do all of the exercises on your own laptop using a\nDocker container.</p>\n<p>Feel free to use these materials to teach users at your organization\nabout Spack.</p>\n<h2>\n<a id=\"user-content-community\" class=\"anchor\" href=\"#community\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Community</h2>\n<p>Spack is an open source project.  Questions, discussion, and\ncontributions are welcome. Contributions can be anything from new\npackages to bugfixes, documentation, or even new core features.</p>\n<p>Resources:</p>\n<ul>\n<li>\n<strong>Slack workspace</strong>: <a href=\"https://spackpm.slack.com\" rel=\"nofollow\">spackpm.slack.com</a>.\nTo get an invitation, <a href=\"https://spackpm.herokuapp.com\" rel=\"nofollow\"><strong>click here</strong></a>.</li>\n<li>\n<strong>Mailing list</strong>: <a href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\">groups.google.com/d/forum/spack</a>\n</li>\n<li>\n<strong>Twitter</strong>: <a href=\"https://twitter.com/spackpm\" rel=\"nofollow\">@spackpm</a>. Be sure to\n<code>@mention</code> us!</li>\n</ul>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Contributing to Spack is relatively easy.  Just send us a\n<a href=\"https://help.github.com/articles/using-pull-requests/\">pull request</a>.\nWhen you send your request, make <code>develop</code> the destination branch on the\n<a href=\"https://github.com/spack/spack\">Spack repository</a>.</p>\n<p>Your PR must pass Spack's unit tests and documentation tests, and must be\n<a href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"nofollow\">PEP 8</a> compliant.  We enforce\nthese guidelines with <a href=\"https://travis-ci.org/spack/spack\" rel=\"nofollow\">Travis CI</a>.  To\nrun these tests locally, and for helpful tips on git, see our\n<a href=\"http://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\">Contribution Guide</a>.</p>\n<p>Spack uses a rough approximation of the\n<a href=\"http://nvie.com/posts/a-successful-git-branching-model/\" rel=\"nofollow\">Git Flow</a>\nbranching model.  The <code>develop</code> branch contains the latest\ncontributions, and <code>master</code> is always tagged and points to the latest\nstable release.</p>\n<h2>\n<a id=\"user-content-code-of-conduct\" class=\"anchor\" href=\"#code-of-conduct\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Code of Conduct</h2>\n<p>Please note that Spack has a\n<a href=\".github/CODE_OF_CONDUCT.md\"><strong>Code of Conduct</strong></a>. By participating in\nthe Spack community, you agree to abide by its rules.</p>\n<h2>\n<a id=\"user-content-authors\" class=\"anchor\" href=\"#authors\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>Many thanks go to Spack's <a href=\"https://github.com/spack/spack/graphs/contributors\">contributors</a>.</p>\n<p>Spack was created by Todd Gamblin, <a href=\"mailto:tgamblin@llnl.gov\">tgamblin@llnl.gov</a>.</p>\n<h3>\n<a id=\"user-content-citing-spack\" class=\"anchor\" href=\"#citing-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citing Spack</h3>\n<p>If you are referencing Spack in a publication, please cite the following paper:</p>\n<ul>\n<li>Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de Supinski, and W. Scott Futral.\n<a href=\"http://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\" rel=\"nofollow\"><strong>The Spack Package Manager: Bringing Order to HPC Software Chaos</strong></a>.\nIn <em>Supercomputing 2015 (SC\u201915)</em>, Austin, Texas, November 15-20 2015. LLNL-CONF-669890.</li>\n</ul>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-647188</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 3,
        "topics": [],
        "updated_at": 1584116847.0
    },
    {
        "data_format": 2,
        "description": "Spack config for CCI DCS (AiMOS) system",
        "filenames": [
            "v0133gccSpectrum/spack.yaml",
            "v0133gcc/spack.yaml",
            "v0160gcc/spack.yaml",
            "spack.yaml"
        ],
        "full_name": "SCOREC/dcs-spack-config",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-dcs-spack-config\" class=\"anchor\" href=\"#dcs-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>dcs-spack-config</h1>\n<p>CCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies\nwith the IBM XL compilers and Spectrum-MPI.</p>\n<h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n<p>compilers.yaml - compiler list</p>\n<p>config.yaml - global config</p>\n<p>install.sh - package installation commands</p>\n<p>modules.yaml - hierarchical layout for lua modules</p>\n<p>packages.yaml - system installed packages</p>\n<p>README.md - this file</p>\n<p>setupSpack.sh - env needed for executing spack commands</p>\n<p>spack.yaml - list of packages to install</p>\n<h2>\n<a id=\"user-content-setup\" class=\"anchor\" href=\"#setup\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>setup</h2>\n<pre><code>git clone git@github.com:spack/spack.git spack\ncd !$\ngit checkout v0.13.3\n# add the simmetrix-simmodsuite package from the develop branch\ngit cherry-pick 5ddf5e2\n# create the environment\nspack env create v0133\nspack env activate v0133\n# copy the yaml files into the v0133\ncp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.\n# copy the compiler yaml file into the spack etc dir\ncp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.\n</code></pre>\n<h2>\n<a id=\"user-content-install-cmake\" class=\"anchor\" href=\"#install-cmake\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>install cmake</h2>\n<p>The bootstrap step of the cmake install fails with the XL compilers.  I\ninstalled it manually outside of the environment with spack and gcc4.8.5</p>\n<pre><code>spack install cmake%gcc@4.8.5_rhel7\n</code></pre>\n<p>Then added the path to <code>packages.yaml</code>.</p>\n<h2>\n<a id=\"user-content-resuming-work-in-an-environment\" class=\"anchor\" href=\"#resuming-work-in-an-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>resuming work in an environment</h2>\n<pre><code>source /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh\nspack env activate v0133\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1608689847.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack_environments/users/llnl_lc/x86_64_cuda/spack.yaml",
            "spack_environments/developer_release_ppc64le_cuda_spack.yaml",
            "spack_environments/users/llnl_lc/ppc64le_cuda/spack.yaml",
            "spack_environments/developer_release_x86_64_cuda_spack.yaml",
            "spack_environments/developer_release_osx_spack.yaml"
        ],
        "full_name": "bvanessen/lbann_distconv",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-lbann-livermore-big-artificial-neural-network-toolkit\" class=\"anchor\" href=\"#lbann-livermore-big-artificial-neural-network-toolkit\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>LBANN: Livermore Big Artificial Neural Network Toolkit</h1>\n<p>The Livermore Big Artificial Neural Network toolkit (LBANN) is an\nopen-source, HPC-centric, deep learning training framework that is\noptimized to compose multiple levels of parallelism.</p>\n<p>LBANN provides model-parallel acceleration through domain\ndecomposition to optimize for strong scaling of network training.  It\nalso allows for composition of model-parallelism with both data\nparallelism and ensemble training methods for training large neural\nnetworks with massive amounts of data.  LBANN is able to advantage of\ntightly-coupled accelerators, low-latency high-bandwidth networking,\nand high-bandwidth parallel file systems.</p>\n<p>LBANN supports state-of-the-art training algorithms such as\nunsupervised, self-supervised, and adversarial (GAN) training methods\nin addition to traditional supervised learning.  It also supports\nrecurrent neural networks via back propagation through time (BPTT)\ntraining, transfer learning, and multi-model and ensemble training\nmethods.</p>\n<h2>\n<a id=\"user-content-building-lbann\" class=\"anchor\" href=\"#building-lbann\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building LBANN</h2>\n<p>The preferred method for LBANN users to install LBANN is to use\n<a href=\"https://github.com/llnl/spack\">Spack</a>. After some system\nconfiguration, this should be as straightforward as</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack install lbann</pre></div>\n<p>More detailed instructions for building and installing LBANN are\navailable at the <a href=\"https://lbann.readthedocs.io/en/latest/index.html\" rel=\"nofollow\">main LBANN\ndocumentation</a>.</p>\n<h2>\n<a id=\"user-content-running-lbann\" class=\"anchor\" href=\"#running-lbann\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running LBANN</h2>\n<p>The basic template for running LBANN is</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">&lt;</span>mpi-launcher<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">&lt;</span>mpi-options<span class=\"pl-k\">&gt;</span> \\\n    lbann <span class=\"pl-k\">&lt;</span>lbann-options<span class=\"pl-k\">&gt;</span> \\\n    --model=model.prototext \\\n    --optimizer=opt.prototext \\\n    --reader=data_reader.prototext</pre></div>\n<p>When using GPGPU accelerators, users should be aware that LBANN is\noptimized for the case in which one assigns one GPU per MPI\n<em>rank</em>. This should be borne in mind when choosing the parameters for\nthe MPI launcher.</p>\n<p>More details about running LBANN are documented\n<a href=\"https://lbann.readthedocs.io/en/latest/running_lbann.html\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-publications\" class=\"anchor\" href=\"#publications\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Publications</h2>\n<p>A list of publications, presentations and posters are shown\n<a href=\"https://lbann.readthedocs.io/en/latest/publications.html\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-reporting-issues\" class=\"anchor\" href=\"#reporting-issues\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reporting issues</h2>\n<p>Issues, questions, and bugs can be raised on the <a href=\"https://github.com/llnl/lbann/issues\">Github issue\ntracker</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1570967710.0
    },
    {
        "data_format": 2,
        "description": "Documentation and automation for provisioning the core software environment at University of Colorado Boulder Research Computing",
        "filenames": [
            "spack/environments/develop/spack.yaml",
            "spack/environments/summer2020/spack.yaml",
            "spack/environments/spring2020/spack.yaml"
        ],
        "full_name": "ResearchComputing/core-software",
        "latest_release": null,
        "readme": "<p>The Research Computing core software environment provides compilers,\nmpi, libraries, language environments, and applications that are of\ngeneral use to the CU Boulder Research Computing user community.</p>\n<h2>\n<a id=\"user-content-manual-installation-procedures\" class=\"anchor\" href=\"#manual-installation-procedures\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manual installation procedures</h2>\n<p>Manual software installation procedures are available in the <code>Summit</code>\nand <code>Blanca</code> directories, organized by\n<code>Cluster/SoftwareName/VersionNumber</code>. The <code>VersionNumber</code> file\ncontains build notes (bash commands, notes, instructions etc.) to\ninstall that software package for each compiler and MPI.</p>\n<h2>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h2>\n<p>Spack, when deployed as intended, will be a central part of the\nprovisioning of our Core Software service. Included here is the\nconfiguration and installation script for Spack as installed and\npresented at CU Boulder Research Computing.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 8,
        "topics": [],
        "updated_at": 1616702962.0
    },
    {
        "data_format": 2,
        "description": "spack config for erp cluster",
        "filenames": [
            "openFoam24/spack.yaml",
            "v61c1b71_gcc910/spack.yaml"
        ],
        "full_name": "SCOREC/centos7-spack-config",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-centos7-spack-config\" class=\"anchor\" href=\"#centos7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>centos7-spack-config</h1>\n<p>centos7 spack configuration and scripts</p>\n<h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1612003004.0
    },
    {
        "data_format": 2,
        "description": "Spack configuration files",
        "filenames": [
            "compilers.yaml/trinitite/graveyard/dot-spack-cray-compilers.yaml",
            "compilers.yaml/rzansel/spack-built-compilers.yaml",
            "compilers.yaml/rzansel/c-spack-built-gcc-llvm-compilers.yaml",
            "vanguard/darwin/darwin-optane-spack-gcc-compilers.yaml",
            "compilers.yaml/rzansel/etc-spack-defaults.yaml",
            "vanguard/darwin/darwin-general-spack-gcc-packages.yaml",
            "compilers.yaml/darwin/darwin-arm/spack-built-compilers.yaml",
            "compilers.yaml/darwin/darwin-general/spack-built-compilers.yaml",
            "compilers.yaml/trinitite/graveyard/dot-spack-linux-compilers.yaml",
            "compilers.yaml/darwin/darwin-power9/spack-built-compilers.yaml",
            "compilers.yaml/rzansel/c-spack-built-gcc-compilers.yaml"
        ],
        "full_name": "floquet/yaml-library",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-scicell\" class=\"anchor\" href=\"#scicell\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SciCell++</h1>\n<p><a href=\"https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\" alt=\"GitHub-master-push\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/tachidok/scicellxx\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4d304208a40f5037293d6f8b02ab726b9654e85e8557e43b51ae5a91077fa596/68747470733a2f2f636f6465636f762e696f2f67682f7461636869646f6b2f73636963656c6c78782f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d4a41414f465353314951\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/tachidok/scicellxx/branch/master/graph/badge.svg?token=JAAOFSS1IQ\" style=\"max-width:100%;\"></a>\n<a href=\"https://scicellxx.readthedocs.io\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6ada579e5e58ef38465ec81b91143b7b634c899e63a4a834dc39199f9ded19e6/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73636963656c6c78782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/scicellxx/badge/?version=latest\" style=\"max-width:100%;\"></a></p>\n<hr>\n<h2>\n<a id=\"user-content-welcome\" class=\"anchor\" href=\"#welcome\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Welcome!</h2>\n<p>This is the official GitHub repository for the <strong>SciCell++</strong> project.</p>\n<h2>\n<a id=\"user-content-what-is-scicell\" class=\"anchor\" href=\"#what-is-scicell\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What is SciCell++?</h2>\n<p>SciCell++ is an object-oriented framework for the simulation of biological and physical phenomena modelled as continuous or discrete processes.</p>\n<h2>\n<a id=\"user-content-table-of-contents\" class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Table of Contents</h2>\n<ol>\n<li><a href=\"#installation\">Installation</a></li>\n<li><a href=\"#demos\">Demos</a></li>\n<li><a href=\"#documentation\">Documentation</a></li>\n<li><a href=\"#how_to_contribute\">How to contribute</a></li>\n<li><a href=\"#facts_and_curiosities\">Facts and curiosities</a></li>\n<li><a href=\"#license\">License</a></li>\n</ol>\n<h2>\n<a id=\"user-content-installation-\" class=\"anchor\" href=\"#installation-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation <a name=\"user-content-installation\"></a>\n</h2>\n<h3>\n<a id=\"user-content-docker-based-installation\" class=\"anchor\" href=\"#docker-based-installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Docker-based installation</h3>\n<p>We are adopting containers to ease the installation and release of\nversions so you do not need to worry about any dependencies.</p>\n<p>This section and installation procedure is under development.\n<g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji></p>\n<p>Follow the instructions in\n<a href=\"https://docs.docker.com/engine/install/\" rel=\"nofollow\">here</a> to get Docker\ninstalled in your system.</p>\n<p>Then get the image from our Docker repository and ta-dah, you are\nready to go.</p>\n<h3>\n<a id=\"user-content-fast-installation-and-starting-up\" class=\"anchor\" href=\"#fast-installation-and-starting-up\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Fast installation and starting up!!!</h3>\n<h4>\n<a id=\"user-content-what-you-need-to-have-it-running-and-working-nicely\" class=\"anchor\" href=\"#what-you-need-to-have-it-running-and-working-nicely\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What you need to have it running and working nicely?</h4>\n<ul>\n<li>\n<p>A C++ compiler - demo drivers and library built with version\n7.4.0. It may work with previous versions as well.</p>\n</li>\n<li>\n<p>CMake - to configure and install it. We tested with version 3.10.2.</p>\n</li>\n<li>\n<p>Python - to test output from demo drivers with validation files\n(also to produce nice plots). We tested with version 3.7.3 but it\nshould work with any version &gt;= 3</p>\n</li>\n</ul>\n<h5>\n<a id=\"user-content-optional\" class=\"anchor\" href=\"#optional\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Optional</h5>\n<ul>\n<li>MPI support for parallel features - <code>not currently supported</code>.</li>\n</ul>\n<h4>\n<a id=\"user-content-get-your-own-copy-of-the-project\" class=\"anchor\" href=\"#get-your-own-copy-of-the-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Get your own copy of the project</h4>\n<p>You need <strong>git</strong> installed in your computer, then type in a terminal</p>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/tachidok/scicellxx\n<span class=\"pl-c1\">cd</span> scicellxx\ngit checkout -b john_cool</pre></div>\n<p>After executing the first line you will be prompted with your GitHub\nuser name and your password. The third line generates your fully\ncustomised branch, we assume that your name is <em>john_cool</em></p>\n<h4>\n<a id=\"user-content-configuration\" class=\"anchor\" href=\"#configuration\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuration</h4>\n<ul>\n<li>In a terminal (shell command line) go into the <code>scicellxx</code> folder\nthen type</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>./autogen.sh</pre></div>\n<ul>\n<li>Follow up the instructions on screen to configure your own copy of\nthe project.</li>\n</ul>\n<h2>\n<a id=\"user-content-demos-\" class=\"anchor\" href=\"#demos-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Demos <a name=\"user-content-demos\"></a>\n</h2>\n<p>Demos live in the <code>demos</code> folder. You should run all of them to make sure everything is working fine. If you did not run them at installation time (by default) you can do it at any time by opening a terminal, going into the build folder (the default one is <code>build</code>) and typing</p>\n<div class=\"highlight highlight-source-shell\"><pre>./ctest</pre></div>\n<p>A large number of demos is expected to live in the <code>demos</code> folder. Review the <a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">corresponding documentation</a> for their full description.</p>\n<h3>\n<a id=\"user-content-featured-demos\" class=\"anchor\" href=\"#featured-demos\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Featured demos</h3>\n<ul>\n<li>Interpolation</li>\n<li>Linear solvers</li>\n<li>Matrices operations</li>\n<li>Newton's method</li>\n<li>Solution of ODE's\n<ul>\n<li>Lotka-Volterra solved with different time steppers</li>\n<li>N-body problem (only 3-body and 4-body)</li>\n<li>Explicit time steppers</li>\n<li>Implicit time steppers (full implicit and <em>E(PC)^k E</em>\nimplementations)</li>\n<li>Adaptive time steppers</li>\n</ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-documentation-\" class=\"anchor\" href=\"#documentation-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation <a name=\"user-content-documentation\"></a>\n</h2>\n<p>The full documentation is <a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-how-to-contribute-\" class=\"anchor\" href=\"#how-to-contribute-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to contribute <a name=\"user-content-how_to_contribute\"></a>\n</h2>\n<p>Please check the <a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">corresponding documentation</a> section for contributions.</p>\n<h2>\n<a id=\"user-content-facts-and-curiosities-\" class=\"anchor\" href=\"#facts-and-curiosities-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Facts and curiosities <a name=\"user-content-facts_and_curiosities\"></a>\n</h2>\n<h3>\n<a id=\"user-content-how-many-developers-are-currently-working-on-this-project\" class=\"anchor\" href=\"#how-many-developers-are-currently-working-on-this-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How many developers are currently working on this project?</h3>\n<p>At Wednesday, March/31, 2021 there is one and only one developer, me\n<g-emoji class=\"g-emoji\" alias=\"no_mouth\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f636.png\">\ud83d\ude36</g-emoji> <g-emoji class=\"g-emoji\" alias=\"email\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/2709.png\">\u2709\ufe0f</g-emoji></p>\n<p><g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji></p>\n<h3>\n<a id=\"user-content-when-did-this-start\" class=\"anchor\" href=\"#when-did-this-start\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>When did this start?</h3>\n<p>This project was initially uploaded to GitHub on Friday, 11 March 2016\n<g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>\n<h2>\n<a id=\"user-content-license-\" class=\"anchor\" href=\"#license-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License <a name=\"user-content-license\"></a>\n</h2>\n<p>Licensed under the GNU GPLv3. A copy can be found on the <a href=\"./LICENSE\">LICENSE</a> file.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1585737463.0
    },
    {
        "data_format": 2,
        "description": "rhel7 spack configuration and scripts",
        "filenames": [
            "v0.13.2/spack.yaml",
            "v0.15.4/spack.yaml"
        ],
        "full_name": "SCOREC/rhel7-spack-config",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-setup-on-scorec\" class=\"anchor\" href=\"#setup-on-scorec\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\nsource setupSpack.sh\n</code></pre>\n<h1>\n<a id=\"user-content-rhel7-spack-config\" class=\"anchor\" href=\"#rhel7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7 spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained in this repo is for documentation purposes (e.g., in case we had to reinstall the entire stack from scratch) and should not be executed as it will not use all of our existing package installs.  More discussion of package installation is below.</p>\n<h2>\n<a id=\"user-content-useful-commands\" class=\"anchor\" href=\"#useful-commands\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-new-packages\" class=\"anchor\" href=\"#installing-new-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack package updates could result in additional installation of packages with little or no package source code changes.  These additional installs can be avoided when installing new packages by first examining the output of the <code>spack spec -I</code> command.  If a utility/infrastructure level package, such as cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column then it means that the existing install will be used.  If spack does not default to using the existing install you can append the hash of the package to the spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0 patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2 arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n</code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change to the new mpich version yet.  So, we will get the hash of the existing mpich 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\nniuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n<p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code> syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0 ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n<h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 5,
        "topics": [],
        "updated_at": 1614024389.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "inputs/spack/spack.yaml"
        ],
        "full_name": "cinemascienceworkflows/2021-04_ExaWind-NaluWind",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-setup-on-scorec\" class=\"anchor\" href=\"#setup-on-scorec\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\nsource setupSpack.sh\n</code></pre>\n<h1>\n<a id=\"user-content-rhel7-spack-config\" class=\"anchor\" href=\"#rhel7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7 spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained in this repo is for documentation purposes (e.g., in case we had to reinstall the entire stack from scratch) and should not be executed as it will not use all of our existing package installs.  More discussion of package installation is below.</p>\n<h2>\n<a id=\"user-content-useful-commands\" class=\"anchor\" href=\"#useful-commands\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-new-packages\" class=\"anchor\" href=\"#installing-new-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack package updates could result in additional installation of packages with little or no package source code changes.  These additional installs can be avoided when installing new packages by first examining the output of the <code>spack spec -I</code> command.  If a utility/infrastructure level package, such as cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column then it means that the existing install will be used.  If spack does not default to using the existing install you can append the hash of the package to the spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0 patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2 arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n</code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change to the new mpich version yet.  So, we will get the hash of the existing mpich 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\nniuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n<p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code> syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0 ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n<h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 5,
        "topics": [],
        "updated_at": 1618440690.0
    },
    {
        "data_format": 2,
        "description": "Tutorial workflow",
        "filenames": [
            "inputs/spack/spack.yaml"
        ],
        "full_name": "cinemascienceworkflows/2021-04_ECP-Tutorial",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-setup-on-scorec\" class=\"anchor\" href=\"#setup-on-scorec\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\nsource setupSpack.sh\n</code></pre>\n<h1>\n<a id=\"user-content-rhel7-spack-config\" class=\"anchor\" href=\"#rhel7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7 spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained in this repo is for documentation purposes (e.g., in case we had to reinstall the entire stack from scratch) and should not be executed as it will not use all of our existing package installs.  More discussion of package installation is below.</p>\n<h2>\n<a id=\"user-content-useful-commands\" class=\"anchor\" href=\"#useful-commands\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-new-packages\" class=\"anchor\" href=\"#installing-new-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack package updates could result in additional installation of packages with little or no package source code changes.  These additional installs can be avoided when installing new packages by first examining the output of the <code>spack spec -I</code> command.  If a utility/infrastructure level package, such as cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column then it means that the existing install will be used.  If spack does not default to using the existing install you can append the hash of the package to the spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0 patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2 arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n</code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change to the new mpich version yet.  So, we will get the hash of the existing mpich 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\nniuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n<p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code> syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0 ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n<h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 5,
        "topics": [],
        "updated_at": 1618446347.0
    },
    {
        "data_format": 2,
        "description": "ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver ) couples the Maxwell equation implementation in WarpX with an LLG module for studying micromagnetics and performance of next-generation microelectronics.",
        "filenames": [
            "Docs/spack.yaml"
        ],
        "full_name": "ECP-WarpX/artemis",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-artemis\" class=\"anchor\" href=\"#artemis\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ARTEMIS</h1>\n<h2>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h2>\n<p>ARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a development branch of WarpX for modeling micromagnetics and electrodynamic waves in next-generation microelectornics.</p>\n<h2>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p>In order to learn how to install and run the code, please see the online documentation:\n<a href=\"https://warpx.readthedocs.io\" rel=\"nofollow\">https://warpx.readthedocs.io</a></p>\n<p>To contact the developers, feel free to open an issue on this repo.</p>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Our workflow is described in <a href=\"CONTRIBUTING.rst\">CONTRIBUTING.rst</a>.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>WarpX Copyright (c) 2018-2021, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.</p>\n<p>If you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab's Innovation &amp; Partnerships Office at\n<a href=\"mailto:IPO@lbl.gov\">IPO@lbl.gov</a>.</p>\n<p>NOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.</p>\n<p>License for WarpX can be found at <a href=\"LICENSE.txt\">LICENSE.txt</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1616476808.0
    },
    {
        "data_format": 2,
        "description": "EuXFEL Spack Package Repository",
        "filenames": [
            ".docker/opt/spack/etc/spack/spack.yaml"
        ],
        "full_name": "panosc-eu/spack-repo",
        "latest_release": null,
        "readme": "<h2>\n<a id=\"user-content-e4s-release-2102\" class=\"anchor\" href=\"#e4s-release-2102\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>E4S Release 21.02</h2>\n<p>February 2021 release of E4S (21.02)</p>\n<h3>\n<a id=\"user-content-files\" class=\"anchor\" href=\"#files\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Files</h3>\n<ul>\n<li>\n<code>spack-commit-ref.txt</code> -- Spack commit reference</li>\n<li>\n<code>spack.yaml</code> -- Spack Environment containing <code>packages:</code> and <code>specs:</code>\n<ul>\n<li>\n<code>packages:</code> version preferences for non-root specs</li>\n<li>\n<code>specs:</code> version-pinned root specs comprising this release of E4S</li>\n</ul>\n</li>\n</ul>\n<p><em>Packages in E4S but not available in versioned form are commented out</em></p>\n<h3>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n<p>E4S 21.02 is based on Spack tag <code>e4s-21.02</code></p>\n<ul>\n<li><a href=\"https://github.com/spack/spack\">https://github.com/spack/spack</a></li>\n<li>Tag <code>e4s-21.02</code> (<code>@develop</code> as of <code>Fri Feb 26 14:57:40 2021 -0800</code>)</li>\n</ul>\n<h3>\n<a id=\"user-content-packages\" class=\"anchor\" href=\"#packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Packages</h3>\n<table>\n<thead>\n<tr>\n<th>Package</th>\n<th>Version</th>\n<th>Group</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>adios</td>\n<td>1.13.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>adios2</td>\n<td>2.7.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>aml</td>\n<td>0.1.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>amrex</td>\n<td>21.02</td>\n<td></td>\n</tr>\n<tr>\n<td>arborx</td>\n<td>0.9-beta</td>\n<td>math</td>\n</tr>\n<tr>\n<td>argobots</td>\n<td>1.0</td>\n<td></td>\n</tr>\n<tr>\n<td>ascent</td>\n<td>0.6.0</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>axom</td>\n<td>0.4.0</td>\n<td></td>\n</tr>\n<tr>\n<td>bolt</td>\n<td>2.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>caliper</td>\n<td>2.5.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>darshan-runtime</td>\n<td>3.2.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>darshan-util</td>\n<td>3.2.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>dyninst</td>\n<td>10.2.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>faodel</td>\n<td>1.1906.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>flecsi</td>\n<td>1.4</td>\n<td>math</td>\n</tr>\n<tr>\n<td>flit</td>\n<td>2.1.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>fortrilinos</td>\n<td>2.0.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>gasnet</td>\n<td>2020.3.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>ginkgo</td>\n<td>1.3.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>globalarrays</td>\n<td>5.8</td>\n<td></td>\n</tr>\n<tr>\n<td>gotcha</td>\n<td>1.0.3</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>hdf5</td>\n<td>1.10.7</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>hpctoolkit</td>\n<td>2020.08.3</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>hpx</td>\n<td>1.6.0</td>\n<td></td>\n</tr>\n<tr>\n<td>hypre</td>\n<td>2.20.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>kokkos</td>\n<td>3.2.00</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>kokkos-kernels</td>\n<td>3.2.00</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>legion</td>\n<td>20.03.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>libnrm</td>\n<td>0.1.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>libquo</td>\n<td>1.3.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>magma</td>\n<td>2.5.4</td>\n<td>math</td>\n</tr>\n<tr>\n<td>mercury</td>\n<td>2.0.0</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>mfem</td>\n<td>4.2.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>mpifileutils</td>\n<td>0.10.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>ninja</td>\n<td>1.10.2</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>omega-h</td>\n<td>9.32.5</td>\n<td>math</td>\n</tr>\n<tr>\n<td>openmpi</td>\n<td>4.0.5</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>openpmd-api</td>\n<td>0.13.2</td>\n<td></td>\n</tr>\n<tr>\n<td>papi</td>\n<td>6.0.0.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>papyrus</td>\n<td>1.0.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>parallel-netcdf</td>\n<td>1.12.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>pdt</td>\n<td>3.25.1</td>\n<td></td>\n</tr>\n<tr>\n<td>petsc</td>\n<td>3.14.4</td>\n<td>math</td>\n</tr>\n<tr>\n<td>phist</td>\n<td>1.9.3</td>\n<td>math</td>\n</tr>\n<tr>\n<td>plasma</td>\n<td>20.9.20</td>\n<td>math</td>\n</tr>\n<tr>\n<td>precice</td>\n<td>2.2.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>pumi</td>\n<td>2.2.5</td>\n<td>math</td>\n</tr>\n<tr>\n<td>py-jupyterhub</td>\n<td>1.0.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>py-libensemble</td>\n<td>0.7.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>py-petsc4py</td>\n<td>3.14.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>qthreads</td>\n<td>1.16</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>raja</td>\n<td>0.13.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>rempi</td>\n<td>1.1.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>scr</td>\n<td>2.0.0</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>slate</td>\n<td>2020.10.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>slepc</td>\n<td>3.14.2</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>stc</td>\n<td>0.8.3</td>\n<td></td>\n</tr>\n<tr>\n<td>strumpack</td>\n<td>5.1.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>sundials</td>\n<td>5.7.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>superlu</td>\n<td>5.2.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>superlu-dist</td>\n<td>6.4.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>swig</td>\n<td>4.0.2-f</td>\n<td></td>\n</tr>\n<tr>\n<td>sz</td>\n<td>2.1.11.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>tasmanian</td>\n<td>7.3</td>\n<td>math</td>\n</tr>\n<tr>\n<td>tau</td>\n<td>2.30.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>trilinos</td>\n<td>13.0.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>turbine</td>\n<td>1.2.3</td>\n<td></td>\n</tr>\n<tr>\n<td>umap</td>\n<td>2.1.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>umpire</td>\n<td>4.1.2</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>unifyfs</td>\n<td>0.9.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>upcxx</td>\n<td>2020.10.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>veloc</td>\n<td>1.4</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>zfp</td>\n<td>0.5.5</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>llvm-doe</td>\n<td>doe</td>\n<td>dev tools</td>\n</tr>\n</tbody>\n</table>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1616613995.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "etc/spack.yaml",
            "spack.yaml"
        ],
        "full_name": "CUP-ECS/ExaCLAMR",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-exaclamr\" class=\"anchor\" href=\"#exaclamr\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ExaCLAMR</h1>\n<p>Re-Implementation of the Shallow Water Solver LANL/CLAMR using Kokkos, Cabana, and Cajita.</p>\n<h2>\n<a id=\"user-content-current-status\" class=\"anchor\" href=\"#current-status\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Current Status</h2>\n<ul>\n<li>Properly functions using\n<ul>\n<li>Serial</li>\n<li>OpenMP</li>\n<li>Cuda</li>\n<li>Serial + MPI</li>\n<li>OpenMP + MPI</li>\n<li>Cuda + MPI</li>\n</ul>\n</li>\n<li>Able to write to Silo files using PMPIO (Tested on Mac in Serial, OpenMP, Serial + MPI, OpenMP + MPI)</li>\n<li>Can Visualize results using VisIt</li>\n</ul>\n<h2>\n<a id=\"user-content-future-directions-and-tasks\" class=\"anchor\" href=\"#future-directions-and-tasks\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Future Directions and Tasks</h2>\n<ul>\n<li>[x] Fix Cuda MPI issue in use of Cajita Halo gather (currently functioning with a work around using CudaUVM and a custom halo exchange). It might be an issue with how ExaCLAMR is using the Cajita gather?</li>\n<li>[x] Get Silo to build on Wheeler and Xena and get it working with the CudaUVM case</li>\n<li>[x] Template the mesh and problem manager classes for regular grids, AMR grids</li>\n<li>[ ] Investigate using Cabana AoSoA</li>\n<li>[ ] Add particle physics</li>\n</ul>\n<h2>\n<a id=\"user-content-building-exaclamr\" class=\"anchor\" href=\"#building-exaclamr\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building ExaCLAMR</h2>\n<p>ExaCLAKMR is built and installed using cmake, and relies on variety of packages and\nlibraries:</p>\n<ul>\n<li>Kokkos - Programming system for accelerated and threaded architectures</li>\n<li>Cabana/Cajita - Framework for regular mesh and particle oprogramming in Kokkos</li>\n<li>Silo - Parallel I/O library for reading in restarts and writing output for\nvisualization using VisIt or Paraview</li>\n<li>HeFFTE - GPU-accelerated high-speed fast fourier transform library (Note: not\nneeded by ExaCLAMR but we'll want it for the z-model implementation)</li>\n</ul>\n<h3>\n<a id=\"user-content-building-with-a-spack-environment\" class=\"anchor\" href=\"#building-with-a-spack-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building with a Spack environment</h3>\n<p>Generally, the easiest way to build ExaCLAMR is to use <a href=\"http://spack.io\" rel=\"nofollow\">Spack</a> to\neither install and load the prerequisites or to create a dedicated environment\nfor building and running AppName. The spack specification (etc/spack.yaml) is\nincluded to create a spack environment in which the build and run AppName. Note, however\n//that there are important caveats at the top of this file you'll ened to pay attention to\nto use it//. In particular, to use it to build a CUDA environment you'll need to patch your\ncabana/packages.py spec and set teh cuda architecture kokkos uses. Alternatively, you\ncan just remove the cuda specifiers from the spack.yaml file.</p>\n<p>To create a spack environment for compiling and running ExaCLAMR in a build directory:</p>\n<pre><code>prompt&gt; mkdir build; cd build\nprompt&gt; spack env create -d . /path/to/ExaCLAMR/etc/spack.yaml\nprompt&gt; spack env activate .\nprompt&gt; spack concretize\nprompt&gt; spack install\n</code></pre>\n<p>Once all ExaCLAMR dependencies are installed either manually or via a\nSpack environment, use cmake to build it from the chosen build\ndirectory:</p>\n<pre><code>cmake /path/to/ExaCLAMR\n</code></pre>\n<h3>\n<a id=\"user-content-building-on-unm-carc-wheeler\" class=\"anchor\" href=\"#building-on-unm-carc-wheeler\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building on UNM CARC Wheeler</h3>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/CUP-ECS/ExaCLAMR.git\n<span class=\"pl-c1\">cd</span> ExaCLAMR\nbash scripts/build_wheeler.sh -a\nmkdir -p data\nmkdir -p data/raw</pre></div>\n<h3>\n<a id=\"user-content-running-on-unm-carc-wheeler---example-on-2-ranks-serial-mpiopenmp\" class=\"anchor\" href=\"#running-on-unm-carc-wheeler---example-on-2-ranks-serial-mpiopenmp\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running on UNM CARC Wheeler - Example on 2 Ranks (Serial, MPI+OpenMP)</h3>\n<div class=\"highlight highlight-source-shell\"><pre>module load cmake-3.15.4-gcc-8.3.0-rmxifnl\nmodule load openmpi-3.1.4-gcc-8.3.0-w3pkrvv\nmodule load gcc-8.3.0-gcc-4.8.5-wwpinbr\nmodule load hypre-2.14.0-gcc-7.3.0-openmpi-mkl-zndhsgh\nmpirun -np 2 --display-map --map-by ppr:1:node --bind-to none -machinefile <span class=\"pl-smi\">$PBS_NODEFILE</span> -x PATH -x LD_LIBRARY_PATH ./build/examples/DamBreak\nmpirun -np 2 --display-map --map-by ppr:1:node --bind-to none -machinefile <span class=\"pl-smi\">$PBS_NODEFILE</span> -x PATH -x LD_LIBRARY_PATH ./build/examples/DamBreak -mopenmp</pre></div>\n<h3>\n<a id=\"user-content-building-on-unm-carc-xena\" class=\"anchor\" href=\"#building-on-unm-carc-xena\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building on UNM CARC Xena</h3>\n<ul>\n<li>Note: You have to build on a compute node with a GPU</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/CUP-ECS/ExaCLAMR.git\n<span class=\"pl-c1\">cd</span> ExaCLAMR\nbash scripts/build_xena.sh -a\nmkdir -p data\nmkdir -p data/raw</pre></div>\n<h3>\n<a id=\"user-content-running-on-unm-carc-xena\" class=\"anchor\" href=\"#running-on-unm-carc-xena\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running on UNM CARC Xena</h3>\n<div class=\"highlight highlight-source-shell\"><pre>sbatch scripts/xena_run.sh</pre></div>\n<h2>\n<a id=\"user-content-performance\" class=\"anchor\" href=\"#performance\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Performance</h2>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1621397061.0
    },
    {
        "data_format": 2,
        "description": "testing spack's containerize command",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "js947/spack-docker-test",
        "latest_release": null,
        "readme": "<p><a href=\"https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg\" alt=\"Build container\" style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-spack-docker-test\" class=\"anchor\" href=\"#spack-docker-test\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>spack-docker-test</h1>\n<p>testing spack's containerize command</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1606980182.0
    },
    {
        "data_format": 2,
        "description": "All the codes and scripts are available in this repository.",
        "filenames": [
            "SICM/spack.yaml"
        ],
        "full_name": "onkarbpatil/sc20-benchmarks",
        "latest_release": "sc2020v1.1",
        "readme": "<h1>\n<a id=\"user-content-pace-provbench\" class=\"anchor\" href=\"#pace-provbench\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>PACE-ProvBench</h1>\n<p>PACE-ProvBench is a Platform independent tool to quickly setup test suite/environment for usability and performance test on any new machines,\nand it provides an easy way to compare the performance across multiple systems. When tests are running, all runtime\ninformation including software, hardware, environment settings are recorded in the database, those data can be compared\nafterwards. This project uses object oriented design to encapsulate the information relating to benchmark testing, and\npresents a clearer high-level representation, which aims to make the benchmark testing easier to extend and maintain,\nmeantime the testing provenance is captured.</p>\n<p>Reach to Fang (Cherry) Liu (<a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a>) if you have any questions.</p>\n<h1>\n<a id=\"user-content-repo-structure\" class=\"anchor\" href=\"#repo-structure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repo Structure</h1>\n<pre><code>&lt;PACE-ProvBench Root Dir&gt; \n  | - Application  (includes all application related data, build scripts, input data, recipe and module files/installation placeholder)\n  | - Utitilies (include all automation bash scripts, either is used in python code, or for building Spack software tool chaim, or used as bootstraping)\n  | - SRC (The main source code for ProvBench, all python codes)\n  | - UnitTest (Test and query interface for users to invoking the tests and query the results)\n  | - Test (Default test output place holder)\n  | - SC20Test (includes all automation test scripts which generates the test result for the paper) \n  | - Images (stores all images used in this documentation)\n  | - Design (includes the design documentation)\n</code></pre>\n<p>Please check the detailed repo structure at <a href=\"repo_directory_struc.md\">repo_directory_struc</a></p>\n<h2>\n<a id=\"user-content-checkout-the-repository\" class=\"anchor\" href=\"#checkout-the-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Checkout the repository</h2>\n<p><code>git clone https://github.com/pace-gt/PACE-ProvBench.git</code></p>\n<p>Due to SPACK has some filesystem requirement, the current test needs to be done on a physical RHEL7 node\nwith local filesystem.</p>\n<h2>\n<a id=\"user-content-few-terminologies\" class=\"anchor\" href=\"#few-terminologies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Few Terminologies</h2>\n<p>Experiment \u2013 each test run, usually one application with multiple runs</p>\n<p>ROLEs \u2013 person who interacts with the framework</p>\n<ul>\n<li>Developer: develops and extends the framework in functionalities and design</li>\n<li>Contributor: builds the test suite and adds new applications</li>\n<li>User: run the tests and analyzes the data collected by the framework</li>\n</ul>\n<p>RECIPE \u2013 defines how the application is run from command line</p>\n<h2>\n<a id=\"user-content-system-requirements\" class=\"anchor\" href=\"#system-requirements\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System Requirements</h2>\n<ul>\n<li>\n<p>Easy to rebuild the software in a short time span with as little as possible manual steps:</p>\n<p>-- Use LLNL SPACK tool to build the underline compilers and libraries, using SPACK ENV to ensure automation and reproducibility (this is an optional step, Contributor can build software manually as needed)</p>\n<p>-- Provide the template build scripts and module files for Contributor to build the test suite on existing applications</p>\n<p>-- Allow easily to add new applications</p>\n</li>\n<li>\n<p>Information collected are permanently stored</p>\n<p>-- includes all software, hardware, running environment</p>\n<p>-- information can be used to rebuild the tests</p>\n</li>\n<li>\n<p>Framework should be easy to extend</p>\n<p>-- Object-oriented programming style is adopted</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-high-level-objects-design-and-workflow\" class=\"anchor\" href=\"#high-level-objects-design-and-workflow\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>High Level Objects Design and workflow</h2>\n<p>This is for developer only, PACE-ProvBench has 7 main objects all under python package <code>&lt;repo root&gt;/SRC/pace/provbench</code>:</p>\n<ul>\n<li>Application : represents all information and functionalities for one application in test suite</li>\n<li>Runtime : provides the information related to each Experiment run</li>\n<li>System : captures hareware information for each individual host</li>\n<li>Result: processes the performance result, e.g. average/mean/max/min time</li>\n<li>Database: interacts with database, construct the insert/update/select queries</li>\n<li>Command: encapsultes the command line invokation for each application</li>\n<li>Experiment: includes all above objects, serves as the entry point for user interaction</li>\n</ul>\n<p><a href=\"Images/objectflow.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/objectflow.png\" alt=\"PACE-ProvBench Object and Data flow\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-repository-directory-structure\" class=\"anchor\" href=\"#repository-directory-structure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repository Directory Structure</h2>\n<p>Please check <a href=\"repo_directory_struc.md\">repository directory structure</a> for details.\nIt gives the detailed description on how each directory is for, and naming convention on how to put the new information in.</p>\n<h2>\n<a id=\"user-content-building-the-initial-test-suite\" class=\"anchor\" href=\"#building-the-initial-test-suite\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the initial test suite</h2>\n<p>Please check <a href=\"build_testsuite.md\">Build Initial Test Suite</a> for how to establish the initial benchmark suite with\none application (leslie-spec), this initial test suite should allow user to experience the PACE-ProvBench framework\nin terms of functionalities.</p>\n<h2>\n<a id=\"user-content-run-tests-as-a-user\" class=\"anchor\" href=\"#run-tests-as-a-user\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Run tests as a user</h2>\n<p>Please check <a href=\"run_test.md\">User run test</a> for how to run a test.</p>\n<p><a href=\"Images/runtest.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/runtest.png\" alt=\"Run test as a user\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-adding-new-application-to-pace-provbench\" class=\"anchor\" href=\"#adding-new-application-to-pace-provbench\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new application to PACE-ProvBench</h2>\n<p>The general steps are as follows, please check <a href=\"add_new_application.md\">add new application</a> session for details.</p>\n<pre><code>* build the application using the pace_build.sh from $PACEPROVBENCH/Application/Source\n* add new module file under $PACEPROVBENCH/Application/Module/&lt;appname&gt;/&lt;version&gt;.lua\n* add new recipe file under $PACEPROVBENCH/Application/Recipe/&lt;appname&gt;.inp\n* follow the step on how to run a test \n</code></pre>\n<p><a href=\"Images/newappflow.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/newappflow.png\" alt=\"Add New Application\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-query-the-database\" class=\"anchor\" href=\"#query-the-database\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Query the database</h2>\n<p>User can access PACE-ProvBench database to gather performance data from the runs they had through the query interface.\nPlease see <a href=\"query_database.md\">how to query the database</a> session for more details.</p>\n<h2>\n<a id=\"user-content-summary\" class=\"anchor\" href=\"#summary\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Summary</h2>\n<ul>\n<li>\n<p>Current PACE-ProvBench provides:</p>\n<p>-- A way to build the test suite</p>\n<p>-- A way to integrate new test application</p>\n<p>-- A way to capture the provenance information and store permanently</p>\n<p>-- A way to easy query the provenance information with given criteria</p>\n<p>-- A way to easy extend the framework</p>\n</li>\n<li>\n<p>Future work</p>\n<p>-- More test and validation need to be done</p>\n<p>-- More applications need to be added to test suite</p>\n<p>-- Extend the framework to handle more data analytics to answer HPC data center\u2019 questions</p>\n<p>-- Publish the work in paper and github</p>\n</li>\n</ul>\n<p>Contributed by Fang (Cherry) Liu <a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a></p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1590903633.0
    },
    {
        "data_format": 2,
        "description": "Minor work intended to do self study on GPGPU programming.",
        "filenames": [
            "1D_advection_FCT/kokkos/spack.yaml"
        ],
        "full_name": "class4kayaker/GPGPU_self_study",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-pace-provbench\" class=\"anchor\" href=\"#pace-provbench\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>PACE-ProvBench</h1>\n<p>PACE-ProvBench is a Platform independent tool to quickly setup test suite/environment for usability and performance test on any new machines,\nand it provides an easy way to compare the performance across multiple systems. When tests are running, all runtime\ninformation including software, hardware, environment settings are recorded in the database, those data can be compared\nafterwards. This project uses object oriented design to encapsulate the information relating to benchmark testing, and\npresents a clearer high-level representation, which aims to make the benchmark testing easier to extend and maintain,\nmeantime the testing provenance is captured.</p>\n<p>Reach to Fang (Cherry) Liu (<a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a>) if you have any questions.</p>\n<h1>\n<a id=\"user-content-repo-structure\" class=\"anchor\" href=\"#repo-structure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repo Structure</h1>\n<pre><code>&lt;PACE-ProvBench Root Dir&gt; \n  | - Application  (includes all application related data, build scripts, input data, recipe and module files/installation placeholder)\n  | - Utitilies (include all automation bash scripts, either is used in python code, or for building Spack software tool chaim, or used as bootstraping)\n  | - SRC (The main source code for ProvBench, all python codes)\n  | - UnitTest (Test and query interface for users to invoking the tests and query the results)\n  | - Test (Default test output place holder)\n  | - SC20Test (includes all automation test scripts which generates the test result for the paper) \n  | - Images (stores all images used in this documentation)\n  | - Design (includes the design documentation)\n</code></pre>\n<p>Please check the detailed repo structure at <a href=\"repo_directory_struc.md\">repo_directory_struc</a></p>\n<h2>\n<a id=\"user-content-checkout-the-repository\" class=\"anchor\" href=\"#checkout-the-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Checkout the repository</h2>\n<p><code>git clone https://github.com/pace-gt/PACE-ProvBench.git</code></p>\n<p>Due to SPACK has some filesystem requirement, the current test needs to be done on a physical RHEL7 node\nwith local filesystem.</p>\n<h2>\n<a id=\"user-content-few-terminologies\" class=\"anchor\" href=\"#few-terminologies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Few Terminologies</h2>\n<p>Experiment \u2013 each test run, usually one application with multiple runs</p>\n<p>ROLEs \u2013 person who interacts with the framework</p>\n<ul>\n<li>Developer: develops and extends the framework in functionalities and design</li>\n<li>Contributor: builds the test suite and adds new applications</li>\n<li>User: run the tests and analyzes the data collected by the framework</li>\n</ul>\n<p>RECIPE \u2013 defines how the application is run from command line</p>\n<h2>\n<a id=\"user-content-system-requirements\" class=\"anchor\" href=\"#system-requirements\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System Requirements</h2>\n<ul>\n<li>\n<p>Easy to rebuild the software in a short time span with as little as possible manual steps:</p>\n<p>-- Use LLNL SPACK tool to build the underline compilers and libraries, using SPACK ENV to ensure automation and reproducibility (this is an optional step, Contributor can build software manually as needed)</p>\n<p>-- Provide the template build scripts and module files for Contributor to build the test suite on existing applications</p>\n<p>-- Allow easily to add new applications</p>\n</li>\n<li>\n<p>Information collected are permanently stored</p>\n<p>-- includes all software, hardware, running environment</p>\n<p>-- information can be used to rebuild the tests</p>\n</li>\n<li>\n<p>Framework should be easy to extend</p>\n<p>-- Object-oriented programming style is adopted</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-high-level-objects-design-and-workflow\" class=\"anchor\" href=\"#high-level-objects-design-and-workflow\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>High Level Objects Design and workflow</h2>\n<p>This is for developer only, PACE-ProvBench has 7 main objects all under python package <code>&lt;repo root&gt;/SRC/pace/provbench</code>:</p>\n<ul>\n<li>Application : represents all information and functionalities for one application in test suite</li>\n<li>Runtime : provides the information related to each Experiment run</li>\n<li>System : captures hareware information for each individual host</li>\n<li>Result: processes the performance result, e.g. average/mean/max/min time</li>\n<li>Database: interacts with database, construct the insert/update/select queries</li>\n<li>Command: encapsultes the command line invokation for each application</li>\n<li>Experiment: includes all above objects, serves as the entry point for user interaction</li>\n</ul>\n<p><a href=\"Images/objectflow.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/objectflow.png\" alt=\"PACE-ProvBench Object and Data flow\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-repository-directory-structure\" class=\"anchor\" href=\"#repository-directory-structure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repository Directory Structure</h2>\n<p>Please check <a href=\"repo_directory_struc.md\">repository directory structure</a> for details.\nIt gives the detailed description on how each directory is for, and naming convention on how to put the new information in.</p>\n<h2>\n<a id=\"user-content-building-the-initial-test-suite\" class=\"anchor\" href=\"#building-the-initial-test-suite\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the initial test suite</h2>\n<p>Please check <a href=\"build_testsuite.md\">Build Initial Test Suite</a> for how to establish the initial benchmark suite with\none application (leslie-spec), this initial test suite should allow user to experience the PACE-ProvBench framework\nin terms of functionalities.</p>\n<h2>\n<a id=\"user-content-run-tests-as-a-user\" class=\"anchor\" href=\"#run-tests-as-a-user\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Run tests as a user</h2>\n<p>Please check <a href=\"run_test.md\">User run test</a> for how to run a test.</p>\n<p><a href=\"Images/runtest.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/runtest.png\" alt=\"Run test as a user\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-adding-new-application-to-pace-provbench\" class=\"anchor\" href=\"#adding-new-application-to-pace-provbench\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new application to PACE-ProvBench</h2>\n<p>The general steps are as follows, please check <a href=\"add_new_application.md\">add new application</a> session for details.</p>\n<pre><code>* build the application using the pace_build.sh from $PACEPROVBENCH/Application/Source\n* add new module file under $PACEPROVBENCH/Application/Module/&lt;appname&gt;/&lt;version&gt;.lua\n* add new recipe file under $PACEPROVBENCH/Application/Recipe/&lt;appname&gt;.inp\n* follow the step on how to run a test \n</code></pre>\n<p><a href=\"Images/newappflow.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/newappflow.png\" alt=\"Add New Application\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-query-the-database\" class=\"anchor\" href=\"#query-the-database\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Query the database</h2>\n<p>User can access PACE-ProvBench database to gather performance data from the runs they had through the query interface.\nPlease see <a href=\"query_database.md\">how to query the database</a> session for more details.</p>\n<h2>\n<a id=\"user-content-summary\" class=\"anchor\" href=\"#summary\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Summary</h2>\n<ul>\n<li>\n<p>Current PACE-ProvBench provides:</p>\n<p>-- A way to build the test suite</p>\n<p>-- A way to integrate new test application</p>\n<p>-- A way to capture the provenance information and store permanently</p>\n<p>-- A way to easy query the provenance information with given criteria</p>\n<p>-- A way to easy extend the framework</p>\n</li>\n<li>\n<p>Future work</p>\n<p>-- More test and validation need to be done</p>\n<p>-- More applications need to be added to test suite</p>\n<p>-- Extend the framework to handle more data analytics to answer HPC data center\u2019 questions</p>\n<p>-- Publish the work in paper and github</p>\n</li>\n</ul>\n<p>Contributed by Fang (Cherry) Liu <a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a></p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1616491492.0
    },
    {
        "data_format": 2,
        "description": "Performance Analysis",
        "filenames": [
            "scripts/summit/summit_spack.yaml"
        ],
        "full_name": "CODARcode/PerformanceAnalysis",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-performance-data-analysis\" class=\"anchor\" href=\"#performance-data-analysis\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Performance Data Analysis</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Branch</th>\n<th align=\"left\">Status</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">master</td>\n<td align=\"left\">\n<a href=\"https://travis-ci.org/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d6176705ab1b1ddb9abdad4a84fb18b9f3f7720d2cddb0b1ae2e5238e85332a4/68747470733a2f2f7472617669732d63692e6f72672f434f444152636f64652f506572666f726d616e6365416e616c797369732e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/CODARcode/PerformanceAnalysis.svg?branch=master\" style=\"max-width:100%;\"></a> <a href=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/99c1ab43c88b2244a028750bad5e98f9e393273432513453bf8b8eba6eeea2df/68747470733a2f2f636f6465636f762e696f2f67682f434f444152636f64652f506572666f726d616e6365416e616c797369732f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d4235565056535a494934\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis/branch/master/graph/badge.svg?token=B5VPVSZII4\" style=\"max-width:100%;\"></a>\n</td>\n</tr>\n<tr>\n<td align=\"left\">develop</td>\n<td align=\"left\">\n<a href=\"https://travis-ci.org/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/def9cf7b52f068db3cc82f122249a1e66c1af6751ae0c3ee9f70f72e9b1d581b/68747470733a2f2f7472617669732d63692e6f72672f434f444152636f64652f506572666f726d616e6365416e616c797369732e7376673f6272616e63683d72656c65617365\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/CODARcode/PerformanceAnalysis.svg?branch=release\" style=\"max-width:100%;\"></a> <a href=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0e7958c5895230859b4cdeb23f6544526403cbb209a75d2a955f5d3b2a36e3d4/68747470733a2f2f636f6465636f762e696f2f67682f434f444152636f64652f506572666f726d616e6365416e616c797369732f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d4235565056535a494934\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis/branch/develop/graph/badge.svg?token=B5VPVSZII4\" style=\"max-width:100%;\"></a>\n</td>\n</tr>\n</tbody>\n</table>\n<p>This library is part of the <a href=\"https://github.com/CODARcode/Chimbuko\">CHIMBUKO</a> software framework and provides the C/C++ API to process <a href=\"http://tau.uoregon.edu\" rel=\"nofollow\">TAU</a> performance traces which can be produced by multiple workflow components, processes, and threads. Its purpose is to detect events in the trace data that reveal useful information to developers of High Performance Computing applications.</p>\n<h1>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>Comprehensive documentation on the installation and running of Chimbuko, as well as a full API reference, can be found <a href=\"https://chimbuko-performance-analysis.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a>.</p>\n<h1>\n<a id=\"user-content-releases\" class=\"anchor\" href=\"#releases\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Releases</h1>\n<ul>\n<li>Latest release: v4.0.0</li>\n</ul>\n<h1>\n<a id=\"user-content-directory-layout\" class=\"anchor\" href=\"#directory-layout\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Directory layout</h1>\n<ul>\n<li>\n<p>3rdparty: third party libraries</p>\n</li>\n<li>\n<p>app: applications of PerformanceAnalysis library including the on-node AD module, provenance database server, parameter server and pseudo clients (for debug and test purpose)</p>\n</li>\n<li>\n<p>docker: docker files for Chimbuko's stack and examples</p>\n</li>\n<li>\n<p>docs: web documentation</p>\n</li>\n<li>\n<p>include: header files</p>\n</li>\n<li>\n<p>scripts: scripts for interacting with the provenance database and for deployment on specific machines (e.g. Summit)</p>\n</li>\n<li>\n<p>sphinx: web documentation builder</p>\n</li>\n<li>\n<p>src: source files</p>\n</li>\n<li>\n<p>test: source files for test (using gtest)</p>\n</li>\n</ul>\n<h1>\n<a id=\"user-content-reporting-bugs\" class=\"anchor\" href=\"#reporting-bugs\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reporting Bugs</h1>\n<p>If you find a bug, please open an <a href=\"https://github.com/CODARcode/PerformanceAnalysis/issues\">issue on PerformanceAnalysis github repositoty</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1607994885.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "SICM/spack.yaml"
        ],
        "full_name": "onkarbpatil/IPDPS2020-benchmarks",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-performance-data-analysis\" class=\"anchor\" href=\"#performance-data-analysis\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Performance Data Analysis</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Branch</th>\n<th align=\"left\">Status</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">master</td>\n<td align=\"left\">\n<a href=\"https://travis-ci.org/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d6176705ab1b1ddb9abdad4a84fb18b9f3f7720d2cddb0b1ae2e5238e85332a4/68747470733a2f2f7472617669732d63692e6f72672f434f444152636f64652f506572666f726d616e6365416e616c797369732e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/CODARcode/PerformanceAnalysis.svg?branch=master\" style=\"max-width:100%;\"></a> <a href=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/99c1ab43c88b2244a028750bad5e98f9e393273432513453bf8b8eba6eeea2df/68747470733a2f2f636f6465636f762e696f2f67682f434f444152636f64652f506572666f726d616e6365416e616c797369732f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d4235565056535a494934\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis/branch/master/graph/badge.svg?token=B5VPVSZII4\" style=\"max-width:100%;\"></a>\n</td>\n</tr>\n<tr>\n<td align=\"left\">develop</td>\n<td align=\"left\">\n<a href=\"https://travis-ci.org/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/def9cf7b52f068db3cc82f122249a1e66c1af6751ae0c3ee9f70f72e9b1d581b/68747470733a2f2f7472617669732d63692e6f72672f434f444152636f64652f506572666f726d616e6365416e616c797369732e7376673f6272616e63683d72656c65617365\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/CODARcode/PerformanceAnalysis.svg?branch=release\" style=\"max-width:100%;\"></a> <a href=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0e7958c5895230859b4cdeb23f6544526403cbb209a75d2a955f5d3b2a36e3d4/68747470733a2f2f636f6465636f762e696f2f67682f434f444152636f64652f506572666f726d616e6365416e616c797369732f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d4235565056535a494934\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis/branch/develop/graph/badge.svg?token=B5VPVSZII4\" style=\"max-width:100%;\"></a>\n</td>\n</tr>\n</tbody>\n</table>\n<p>This library is part of the <a href=\"https://github.com/CODARcode/Chimbuko\">CHIMBUKO</a> software framework and provides the C/C++ API to process <a href=\"http://tau.uoregon.edu\" rel=\"nofollow\">TAU</a> performance traces which can be produced by multiple workflow components, processes, and threads. Its purpose is to detect events in the trace data that reveal useful information to developers of High Performance Computing applications.</p>\n<h1>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>Comprehensive documentation on the installation and running of Chimbuko, as well as a full API reference, can be found <a href=\"https://chimbuko-performance-analysis.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a>.</p>\n<h1>\n<a id=\"user-content-releases\" class=\"anchor\" href=\"#releases\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Releases</h1>\n<ul>\n<li>Latest release: v4.0.0</li>\n</ul>\n<h1>\n<a id=\"user-content-directory-layout\" class=\"anchor\" href=\"#directory-layout\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Directory layout</h1>\n<ul>\n<li>\n<p>3rdparty: third party libraries</p>\n</li>\n<li>\n<p>app: applications of PerformanceAnalysis library including the on-node AD module, provenance database server, parameter server and pseudo clients (for debug and test purpose)</p>\n</li>\n<li>\n<p>docker: docker files for Chimbuko's stack and examples</p>\n</li>\n<li>\n<p>docs: web documentation</p>\n</li>\n<li>\n<p>include: header files</p>\n</li>\n<li>\n<p>scripts: scripts for interacting with the provenance database and for deployment on specific machines (e.g. Summit)</p>\n</li>\n<li>\n<p>sphinx: web documentation builder</p>\n</li>\n<li>\n<p>src: source files</p>\n</li>\n<li>\n<p>test: source files for test (using gtest)</p>\n</li>\n</ul>\n<h1>\n<a id=\"user-content-reporting-bugs\" class=\"anchor\" href=\"#reporting-bugs\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reporting Bugs</h1>\n<p>If you find a bug, please open an <a href=\"https://github.com/CODARcode/PerformanceAnalysis/issues\">issue on PerformanceAnalysis github repositoty</a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 0,
        "topics": [],
        "updated_at": 1591389900.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "env/spack.yaml"
        ],
        "full_name": "ucsd-galaxy-lab/agora-gizmo-runs",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-agora-gizmo-runs\" class=\"anchor\" href=\"#agora-gizmo-runs\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>AGORA GIZMO Runs</h1>\n<p>This repository contains data and notes needed to reproduce several GIZMO runs for the AGORA project.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1609985474.0
    },
    {
        "data_format": 2,
        "description": "Spack package manager customization for GIZMO",
        "filenames": [
            "environments/gizmo-deps/spack.yaml",
            "environments/gizmo-grackle/spack.yaml"
        ],
        "full_name": "ucsd-galaxy-lab/gizmo-spack",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-gizmo-spack\" class=\"anchor\" href=\"#gizmo-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>GIZMO Spack</h1>\n<p><a href=\"http://www.tapir.caltech.edu/~phopkins/Site/GIZMO.html\" rel=\"nofollow\">GIZMO</a> simulation software stack through <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a></p>\n<h2>\n<a id=\"user-content-about\" class=\"anchor\" href=\"#about\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>About</h2>\n<p>This project provides relevant files to set up a curated software stack, centering around GIZMO, on various HPC sites through Spack.</p>\n<h2>\n<a id=\"user-content-layout\" class=\"anchor\" href=\"#layout\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Layout</h2>\n<ul>\n<li>\n<code>configs</code>: Example Spack <a href=\"https://spack.readthedocs.io/en/latest/configuration.html\" rel=\"nofollow\">configuration files</a> (<code>compilers.yaml</code> and <code>packages.yaml</code>) for various HPC sites.\n<ul>\n<li><a href=\"https://www.psc.edu/bridges\" rel=\"nofollow\"><code>bridges</code></a></li>\n<li><a href=\"https://www.tacc.utexas.edu/systems/stampede2\" rel=\"nofollow\"><code>stampede2</code></a></li>\n<li><a href=\"https://www.sdsc.edu/services/hpc/hpc_systems.html#tscc\" rel=\"nofollow\"><code>tscc</code></a></li>\n</ul>\n</li>\n<li>\n<code>environments</code>: Example Spack <a href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\">environments</a>.\n<ul>\n<li><code>gizmo-deps</code></li>\n<li><code>gizmo-grackle</code></li>\n</ul>\n</li>\n<li>\n<code>repos/gizmo</code>: The <code>gizmo</code> Spack <a href=\"https://spack.readthedocs.io/en/latest/repositories.html\" rel=\"nofollow\">package repository</a>.\n<ul>\n<li>\n<code>packages</code>\n<ul>\n<li>\n<code>ahf-gizmo</code>: AMIGA halo finder configured for GIZMO simulations.</li>\n<li>\n<code>gizmo</code>: A flexible, massively-parallel, multi-physics simulation code.</li>\n<li>\n<code>gizmo-deps</code>: A dummy package to install GIZMO dependencies.</li>\n<li>\n<code>grackle</code>: Grackle is a chemistry and radiative cooling library for astrophysical simulations and models.</li>\n<li>\n<code>music</code>: Multi-Scale Initial Conditions for Cosmological Simulations.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n<h3>\n<a id=\"user-content-spack-setup\" class=\"anchor\" href=\"#spack-setup\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack setup</h3>\n<p>First, you need to <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"nofollow\">set up Spack</a>. Then clone this repository somewhere and change to that directory:</p>\n<pre><code>git clone https://github.com/qobilidop/gizmo-spack.git\ncd gizmo-spack\n</code></pre>\n<p>If you are working on an HPC site, the example configuration files might be helpful. They could be used directly by symlinking (or copying) to the <code>~/.spack</code> directory (assuming we are on Stampede2):</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">ln -s \"$PWD\"/configs/stampede2/* ~/.spack/</span></pre></div>\n<p>Or used indirectly as references.</p>\n<h3>\n<a id=\"user-content-package-repository-installation\" class=\"anchor\" href=\"#package-repository-installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Package repository installation</h3>\n<p>To install the <code>gizmo</code> package repository:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">spack repo add repos/gizmo</span></pre></div>\n<p>To check if the <code>gizmo</code> package repository is installed:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">spack repo list</span></pre></div>\n<p>You could also check individual package's information:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">spack info gizmo</span></pre></div>\n<p>To uninstall the <code>gizmo</code> package repository:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">spack repo rm gizmo</span></pre></div>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1609985511.0
    },
    {
        "data_format": 2,
        "description": "A suite of FIRE-2 simulations targeting LBG-like galaxies",
        "filenames": [
            "env/env-spack.yaml"
        ],
        "full_name": "ucsd-galaxy-lab/fire-lbg-suite",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-fire-lbg-suite-wip\" class=\"anchor\" href=\"#fire-lbg-suite-wip\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>FIRE LBG Suite (WIP)</h1>\n<h2>\n<a id=\"user-content-reproduction-notes\" class=\"anchor\" href=\"#reproduction-notes\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reproduction Notes</h2>\n<p>There are three major steps to reproduce this work:</p>\n<ol>\n<li>\n<a href=\"pre-process/\">pre-process</a>: prepare a sample of zoom ICs</li>\n<li>\n<a href=\"run/\">run</a>: evolve ICs to the target redshift</li>\n<li>\n<a href=\"post-process/\">post-process</a>: find galaxy structures and measure their basic properties</li>\n</ol>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1609985547.0
    },
    {
        "data_format": 2,
        "description": "Experiments using Colza for In Situ Analysis",
        "filenames": [
            "cori/resizing/spack.yaml",
            "cori/overhead/spack.yaml",
            "cori/vtk/spack.yaml"
        ],
        "full_name": "mochi-hpc-experiments/colza-experiments",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-colza-experiments\" class=\"anchor\" href=\"#colza-experiments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Colza Experiments</h1>\n<p>This repository contains scripts to reproduce experiments\nrelated to the Colza elastic in situ analysis framework.\nThese experiments were run on the Cori supercomputer.</p>\n<p>Each subfolder contains a README file explaining what the\nexperiment in the subfolder does, how to install its\ndependencies, and how to run it.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1617986620.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml",
            "spack-llvm.yaml",
            "spack-qmcpack.yaml"
        ],
        "full_name": "eugeneswalker/qmcpack-demo",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-colza-experiments\" class=\"anchor\" href=\"#colza-experiments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Colza Experiments</h1>\n<p>This repository contains scripts to reproduce experiments\nrelated to the Colza elastic in situ analysis framework.\nThese experiments were run on the Cori supercomputer.</p>\n<p>Each subfolder contains a README file explaining what the\nexperiment in the subfolder does, how to install its\ndependencies, and how to run it.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1615539156.0
    },
    {
        "data_format": 2,
        "description": "SIRIUS AppImage (using just the bare minimum)",
        "filenames": [
            "sirius/spack.yaml",
            "libtree/spack.yaml"
        ],
        "full_name": "haampie/sirius-appimage",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-creating-an-appimage-from-a-spack-environment\" class=\"anchor\" href=\"#creating-an-appimage-from-a-spack-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating an AppImage from a spack environment</h1>\n<p>HPC container runtimes often use squashfs as an archive to store an image, which is then mounted on compute nodes and made writeable using overlayfs where the top layer is a ramfs. This trick gives good performance particularly on shared filesystems, since the squashfs file is a single blob on the disk and has good caching behavior.</p>\n<p>However, perfect isolation from the host system is not always possible, in particular when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into the container, and the question is what the point of containers really is if they still depend on the host system.</p>\n<p>Instead of using containers, one can still deploy applications as a single self-contained blob on the filesystem by using the AppImage runtime. The basic idea is to create an executable which unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\">SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a> and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\">AppImage runtime</a>.</p>\n<h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./build.sh</span></pre></div>\n<h2>\n<a id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n<span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n<span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\">build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                      : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n<span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n<span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n<span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double} default value for APW linearization energies</span>\n<span class=\"pl-c1\">  --auto_enu allow search of APW linearization energies</span>\n<span class=\"pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\">  --rel      use scalar-relativistic solver</span></pre></div>\n<h2>\n<a id=\"user-content-running-on-piz-daint\" class=\"anchor\" href=\"#running-on-piz-daint\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running on piz daint</h2>\n<p>For Piz Daint I've modified the <code>sirius/spack.yaml</code> a bit so that it links against system libmpi.so (<code>^cray-mpich</code> that is):</p>\n<pre><code>daint103 $ ./build.sh\n...\n\ndaint103 $ du -sh sirius.app # binary size (includes compressed squashfs)\n26M\tsirius.app\n\ndaint103 $ ./sirius.app --appimage-extract # runtime allows you to extract\nsquashfs-root/AppRun\nsquashfs-root/usr\nsquashfs-root/usr/bin\nsquashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\nsquashfs-root/usr/lib\nsquashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\nsquashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\nsrun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\ninput file does not exist\n===========================================================================================================\n                            #         Total          %   Parent %        Median           Min           Max\n-----------------------------------------------------------------------------------------------------------\nsirius                      1       2.30 ms     100.00     100.00       2.30 ms       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms      60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize        1     333.28 us      14.52      14.52     333.28 us     333.28 us     333.28 us\n\n===========================================================================================================\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1616530138.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "source/mpifileutils-0.11/spack.yaml"
        ],
        "full_name": "perrynzhou/mpifileutils-note",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-creating-an-appimage-from-a-spack-environment\" class=\"anchor\" href=\"#creating-an-appimage-from-a-spack-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating an AppImage from a spack environment</h1>\n<p>HPC container runtimes often use squashfs as an archive to store an image, which is then mounted on compute nodes and made writeable using overlayfs where the top layer is a ramfs. This trick gives good performance particularly on shared filesystems, since the squashfs file is a single blob on the disk and has good caching behavior.</p>\n<p>However, perfect isolation from the host system is not always possible, in particular when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into the container, and the question is what the point of containers really is if they still depend on the host system.</p>\n<p>Instead of using containers, one can still deploy applications as a single self-contained blob on the filesystem by using the AppImage runtime. The basic idea is to create an executable which unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\">SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a> and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\">AppImage runtime</a>.</p>\n<h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./build.sh</span></pre></div>\n<h2>\n<a id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n<span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n<span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\">build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                      : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n<span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n<span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n<span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double} default value for APW linearization energies</span>\n<span class=\"pl-c1\">  --auto_enu allow search of APW linearization energies</span>\n<span class=\"pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\">  --rel      use scalar-relativistic solver</span></pre></div>\n<h2>\n<a id=\"user-content-running-on-piz-daint\" class=\"anchor\" href=\"#running-on-piz-daint\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running on piz daint</h2>\n<p>For Piz Daint I've modified the <code>sirius/spack.yaml</code> a bit so that it links against system libmpi.so (<code>^cray-mpich</code> that is):</p>\n<pre><code>daint103 $ ./build.sh\n...\n\ndaint103 $ du -sh sirius.app # binary size (includes compressed squashfs)\n26M\tsirius.app\n\ndaint103 $ ./sirius.app --appimage-extract # runtime allows you to extract\nsquashfs-root/AppRun\nsquashfs-root/usr\nsquashfs-root/usr/bin\nsquashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\nsquashfs-root/usr/lib\nsquashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\nsquashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\nsrun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\ninput file does not exist\n===========================================================================================================\n                            #         Total          %   Parent %        Median           Min           Max\n-----------------------------------------------------------------------------------------------------------\nsirius                      1       2.30 ms     100.00     100.00       2.30 ms       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms      60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize        1     333.28 us      14.52      14.52     333.28 us     333.28 us     333.28 us\n\n===========================================================================================================\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1616236348.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "johnny8266/g4e",
        "latest_release": null,
        "readme": "<p><a href=\"https://gitpod.io/#https://gitlab.com/eic/escalate/g4e\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/daadb4894128d1e19b72d80236f5959f1f2b47f9fe081373f3246131f0189f6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476974706f642d72656164792d2d746f2d2d636f64652d626c75653f6c6f676f3d676974706f64\" alt=\"Gitpod ready-to-code\" data-canonical-src=\"https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod\" style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-geant-4-eic-g4e\" class=\"anchor\" href=\"#geant-4-eic-g4e\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Geant 4 EIC (g4e)</h1>\n<p><a href=\"https://g4e.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/91cb0a1c7d5eb279b680cc13aeb9f2393426ee8897446cf932040a2bbfa9681f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6734652f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/g4e/badge/?version=latest\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://camo.githubusercontent.com/4c75e02b6f97e485ffa93517c1484e2c7e0c0fbef0c62d18713504934d7d6b6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746c61622f706970656c696e652f6a6c61622d6569632f6734652f6d6173746572\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4c75e02b6f97e485ffa93517c1484e2c7e0c0fbef0c62d18713504934d7d6b6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746c61622f706970656c696e652f6a6c61622d6569632f6734652f6d6173746572\" alt=\"Gitlab pipeline status (branch)\" data-canonical-src=\"https://img.shields.io/gitlab/pipeline/jlab-eic/g4e/master\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://g4e.readthedocs.org/\" rel=\"nofollow\">The documentation is at g4e.readthedocs.io</a></p>\n<p><a href=\"docs/_images/JLEICgeant4-v1a.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"docs/_images/JLEICgeant4-v1a.png\" alt=\"JLEIC detector\" style=\"max-width:100%;\"></a></p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1610666933.0
    },
    {
        "data_format": 2,
        "description": "Pantheon Container Recipes",
        "filenames": [
            "spack_env/spack.yaml"
        ],
        "full_name": "eugeneswalker/pantheon-containers",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-pantheon-base\" class=\"anchor\" href=\"#pantheon-base\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Pantheon-base</h1>\n<p>In order to build this image, execute the <code>./build.sh</code> script.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1606979724.0
    },
    {
        "data_format": 2,
        "description": "Utility library to handle small, reusable pools of both device memory buffers (via allocators) and device executors (with multiple scheduling policies).",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "SC-SGS/CPPuddle",
        "latest_release": null,
        "readme": "<h3>\n<a id=\"user-content-cppuddle\" class=\"anchor\" href=\"#cppuddle\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CPPuddle</h3>\n<p>WARNING: This repository is a work in progress and should not be relied on for production use!</p>\n<p><a href=\"https://github.com/SC-SGS/CPPuddle/workflows/ctests/badge.svg\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/SC-SGS/CPPuddle/workflows/ctests/badge.svg\" alt=\"ctests\" style=\"max-width:100%;\"></a></p>\n<h4>\n<a id=\"user-content-purpose\" class=\"anchor\" href=\"#purpose\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Purpose</h4>\n<p>This repository was initially created to explore how to best use HPX and Kokkos together!\nFor fine-grained GPU tasks, we needed a way to avoid excessive allocations of one-usage GPU buffers (as allocations block the device for all streams) and creation/deletion of GPU executors (as those are usually tied to a stream which is expensive to create as well).</p>\n<p>We currently test it in the experimental build of <a href=\"https://github.com/STEllAR-GROUP/octotiger\">Octo-Tiger</a>, together with <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>.\nIn this use-case, allocating GPU buffers for all sub-grids in advance would have wasted a lot of memory. On the other hand, unified memory would have caused unnecessary GPU to CPU page migrations (as the old input data gets overwritten anyway). Allocating buffers on-the-fly would have blocked the device. Hence, we currently test this buffer management solution!</p>\n<h4>\n<a id=\"user-content-tools-provided-by-this-repository\" class=\"anchor\" href=\"#tools-provided-by-this-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tools provided by this repository</h4>\n<ul>\n<li>Allocators that reuse previousely allocated buffers if available (works with normal heap memory, pinned memory, aligned memory, CUDA device memory, and Kokkos Views). Note that separate buffers do not coexist on a single chunk of continuous memory, but use different allocations.</li>\n<li>Executor pools and various scheduling policies (round robin, priority queue, multi-gpu), which rely on reference counting to gauge the current load of a executor instead of querying the device itself.</li>\n</ul>\n<h4>\n<a id=\"user-content-requirements\" class=\"anchor\" href=\"#requirements\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Requirements</h4>\n<ul>\n<li>C++14</li>\n<li>CMake (&gt;= 3.11)</li>\n<li>Optional (for the header-only utilities / test): CUDA, Boost, <a href=\"https://github.com/STEllAR-GROUP/hpx\">HPX</a>, <a href=\"https://github.com/kokkos/kokkos\">Kokkos</a>, <a href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\">HPX-Kokkos</a>\n</li>\n</ul>\n<p>The submodules can be used to obtain the optional dependencies which are required for testing the header-only utilities. If these tests are not required, the submodule (and the respective buildscripts in /scripts) can be ignored safely.</p>\n<h4>\n<a id=\"user-content-build--install\" class=\"anchor\" href=\"#build--install\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build / Install</h4>\n<pre><code>  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF                                                             \n  cmake --build /path/to/build -- -j4 VERBOSE=1                                                                                                                                                                                                          \n  cmake --build /path/to/build --target install  \n</code></pre>\n<p>If installed correctly, cppuddle can be used in other cmake-based projects via</p>\n<pre><code>find_package(CPPuddle REQUIRED)\n</code></pre>\n",
        "stargazers_count": 0,
        "subscribers_count": 3,
        "topics": [],
        "updated_at": 1620362115.0
    },
    {
        "data_format": 2,
        "description": "NMC software deployment environments leveraging Spack.",
        "filenames": [
            "dev/ecp-x86_64/3-sdk/spack.yaml",
            "prod/xx-fe1/_manual/spack.yaml",
            "prod/ecp-x86_64/5-e4s/spack.yaml",
            "dev/ecp-x86_64/5-e4s/spack.yaml",
            "dev/xx-fe1/_manual/spack.yaml",
            "prod/ecp-p9-4v100/5-e4s/spack.yaml",
            "dev/ecp-x86_64/2-compute/spack.yaml",
            "dev/ecp-x86_64/0-base/spack.yaml",
            "prod/gitlab-runner/1-core/spack.yaml",
            "dev/xx-fe1/4-py/spack.yaml",
            "dev/ecp-p9-4v100/_manual/spack.yaml",
            "dev/ecp-x86_64/1-core/spack.yaml",
            "prod/ecp-p9-4v100/_manual/spack.yaml",
            "prod/ecp-p9-4v100/3-sdk/spack.yaml",
            "prod/ecp-x86_64/3-sdk/spack.yaml",
            "dev/gitlab-runner/1-core/spack.yaml",
            "dev/ecp-p9-4v100/5-e4s/spack.yaml",
            "prod/xx-fe1/4-py/spack.yaml",
            "prod/ecp-p9-4v100/0-base/spack.yaml",
            "prod/ecp-x86_64/2-compute/spack.yaml",
            "prod/ecp-p9-4v100/4-py/spack.yaml",
            "prod/ecp-x86_64/0-base/spack.yaml",
            "prod/ecp-p9-4v100/1-core/spack.yaml",
            "dev/xx-fe1/0-base/spack.yaml",
            "dev/ecp-x86_64/_manual/spack.yaml",
            "prod/ecp-x86_64/_manual/spack.yaml",
            "dev/ecp-x86_64/4-py/spack.yaml",
            "dev/ecp-p9-4v100/0-base/spack.yaml",
            "dev/ecp-p9-4v100/2-compute/spack.yaml",
            "prod/ecp-x86_64/4-py/spack.yaml",
            "dev/ecp-p9-4v100/1-core/spack.yaml",
            "prod/ecp-x86_64/1-core/spack.yaml",
            "dev/ecp-p9-4v100/4-py/spack.yaml",
            "prod/xx-fe1/0-base/spack.yaml",
            "prod/ecp-p9-4v100/2-compute/spack.yaml",
            "dev/ecp-p9-4v100/3-sdk/spack.yaml"
        ],
        "full_name": "paulbry/nmc-swd",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-nmc-sw-deployment\" class=\"anchor\" href=\"#nmc-sw-deployment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>NMC SW Deployment</h1>\n<p>NMC software deployment stacks, please note that at this time the CI aspect\ndoes not function correctly and must be accounted for manually.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1599857534.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "environments/production/base/spack.yaml",
            "environments/production/rcm/spack.yaml"
        ],
        "full_name": "RemoteConnectionManager/CINECA_RCM_deployments",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-here-we-collect-recipes-for-rcm-deploy-on-cineca-clusters\" class=\"anchor\" href=\"#here-we-collect-recipes-for-rcm-deploy-on-cineca-clusters\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Here we collect recipes for RCM deploy on CINECA clusters</h1>\n<p>download:</p>\n<pre><code>git clone --recursive  --branch master https://github.com/RemoteConnectionManager/CINECA_RCM_deployments.git\ncd CINECA_RCM_deployments\n</code></pre>\n<p>If plan to develop, align all submodules to their branches specified in .gitsubmodules</p>\n<pre><code>git submodule foreach -q --recursive 'branch=\"$(git config -f $toplevel/.gitmodules submodule.$name.branch)\"; git checkout $branch'\n</code></pre>\n<p>update the repo and submodules from origin:\ngit pull\ngit submodule update --recursive</p>\n<ul>\n<li><a href=\"GIT_HINTS.md\">Other hints on git operations</a></li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 3,
        "topics": [],
        "updated_at": 1581964634.0
    },
    {
        "data_format": 2,
        "description": "preterm birth project workflowr",
        "filenames": [
            "workflow/ldsc_spack.yaml"
        ],
        "full_name": "CreRecombinase/ptb_workflowr",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-ptb\" class=\"anchor\" href=\"#ptb\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ptb</h1>\n<p>A <a href=\"https://github.com/jdblischak/workflowr\">workflowr</a> project about pre-term birth, epigenetics and GWAS.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1588983897.0
    },
    {
        "data_format": 2,
        "description": "Deploy components and scripts for RCM",
        "filenames": [
            "deploy/environments/rcm/spack.yaml",
            "deploy/base_spack_devel/environments/base/spack.yaml",
            "deploy/environments/insitu/spack.yaml"
        ],
        "full_name": "RemoteConnectionManager/RCM_spack_deploy",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-rcm_spack_deploy\" class=\"anchor\" href=\"#rcm_spack_deploy\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>RCM_spack_deploy</h1>\n<p>deploy components and scripts for RCM</p>\n<p>First step: clone this repo:</p>\n<pre><code>git clone  https://github.com/RemoteConnectionManager/RCM_spack_deploy.git &lt;folder name&gt;\n</code></pre>\n<p>Short story:</p>\n<pre><code>cd &lt;folder name&gt;\nbin/spack-deploy   --workdir deploy/base_spack_devel/ gitmanager deploy \nbin/spack-deploy   --workdir deploy/base_spack_devel/ spackmanager config_setup\n</code></pre>\n<p>More info can be found in:</p>\n<pre><code>recipes/hosts/&lt;host&gt;/README.md\n</code></pre>\n<ul>\n<li><a href=\"https://github.com/RemoteConnectionManager/RCM_spack_deploy/blob/master/GIT_HINTS.md\">Git hints</a></li>\n<li><a href=\"https://github.com/RemoteConnectionManager/RCM_spack_deploy/blob/master/DEPLOY_HINTS.md\">Deployment hints</a></li>\n<li><a href=\"https://github.com/RemoteConnectionManager/RCM_spack_deploy/blob/master/old_stuff/README.md\">Old README</a></li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 2,
        "topics": [],
        "updated_at": 1570754492.0
    },
    {
        "data_format": 2,
        "description": "Benchmarking of Sonata on Theta and Summit.",
        "filenames": [
            "theta/spack.yaml",
            "summit/spack.yaml"
        ],
        "full_name": "mochi-hpc-experiments/sonata-benchmarking",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-mpifileutils\" class=\"anchor\" href=\"#mpifileutils\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>mpiFileUtils</h1>\n<p>mpiFileUtils provides both a library called <a href=\"src/common/README.md\">libmfu</a> and a suite of MPI-based tools to manage large datasets, which may vary from large directory trees to large files. High-performance computing users often generate large datasets with parallel applications that run with many processes (millions in some cases). However those users are then stuck with single-process tools like cp and rm to manage their datasets. This suite provides MPI-based tools to handle typical jobs like copy, remove, and compare for such datasets, providing speedups of up to 20-30x.  It also provides a library that simplifies the creation of new tools or can be used in applications.</p>\n<p>Documentation is available on <a href=\"http://mpifileutils.readthedocs.io\" rel=\"nofollow\">ReadTheDocs</a>.</p>\n<h2>\n<a id=\"user-content-daos-support\" class=\"anchor\" href=\"#daos-support\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>DAOS Support</h2>\n<p>mpiFileUtils supports a DAOS backend for dcp, dsync, and dcmp. Custom serialization and deserialization for DAOS containers to and from a POSIX filesystem is provided with daos-serialize and daos-deserialize. Details and usage examples are provided in <a href=\"DAOS-Support.md\">DAOS Support</a>.</p>\n<h2>\n<a id=\"user-content-contributors\" class=\"anchor\" href=\"#contributors\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributors</h2>\n<p>We welcome contributions to the project.  For details on how to help, see our <a href=\".github/CONTRIBUTING.md\">Contributor Guide</a></p>\n<h3>\n<a id=\"user-content-copyrights\" class=\"anchor\" href=\"#copyrights\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Copyrights</h3>\n<p>Copyright (c) 2013-2015, Lawrence Livermore National Security, LLC.\nProduced at the Lawrence Livermore National Laboratory\nCODE-673838</p>\n<p>Copyright (c) 2006-2007,2011-2015, Los Alamos National Security, LLC.\n(LA-CC-06-077, LA-CC-10-066, LA-CC-14-046)</p>\n<p>Copyright (2013-2015) UT-Battelle, LLC under Contract No.\nDE-AC05-00OR22725 with the Department of Energy.</p>\n<p>Copyright (c) 2015, DataDirect Networks, Inc.</p>\n<p>All rights reserved.</p>\n<h2>\n<a id=\"user-content-build-status\" class=\"anchor\" href=\"#build-status\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build Status</h2>\n<p>The current status of the mpiFileUtils master branch is <a href=\"https://travis-ci.org/hpc/mpifileutils\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/76717f664d99534173ac7e9fb8e904b0e4bd14fbd51ac6969a88de2e6e86a94f/68747470733a2f2f7472617669732d63692e6f72672f6870632f6d706966696c657574696c732e706e673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/hpc/mpifileutils.png?branch=master\" style=\"max-width:100%;\"></a>.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1614187071.0
    },
    {
        "data_format": 2,
        "description": "This repository provides a set of configuration files and example scripts for running Mochi experiments on various platforms.",
        "filenames": [
            "ANL/Theta/spack.yaml",
            "NERSC/Cori/spack.yaml",
            "ANL/JLSE/spack.yaml",
            "ORNL/Summit/spack.yaml",
            "ANL/Bebop/spack.yaml"
        ],
        "full_name": "mochi-hpc-experiments/platform-configurations",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-platform-configurations-for-mochi\" class=\"anchor\" href=\"#platform-configurations-for-mochi\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Platform configurations for Mochi</h1>\n<p>This repository provides Spack configuration files, example job scripts, and\nnotes about building and running Mochi-based codes on various platforms.\nPlease refer to the subdirectory for your platform of interest for more\ninformation.</p>\n<h2>\n<a id=\"user-content-using-spackyaml-files\" class=\"anchor\" href=\"#using-spackyaml-files\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using spack.yaml files</h2>\n<p>Each platform subdirectory in this repository provides a <code>spack.yaml</code> file.\nA <code>spack.yaml</code> file fully describes a Spack environment, including\nsystem-provided packages and compilers. It does so independently of any\n<code>compilers.yaml</code> or <code>packages.yaml</code> files installed in <code>~/.spack</code>, thereby\npreventing interference with user-specific spack configurations as much as\npossible.</p>\n<p>You may use <code>spack.yaml</code> files to create a\n<a href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\">Spack environment</a>\nin which Mochi packages will be installed.</p>\n<p>If you don't have Spack installed on your platform, clone it and set it up\nas follows.</p>\n<pre><code>$ git clone https://github.com/spack/spack.git\n$ . spack/share/spack/setup-env.sh\n</code></pre>\n<p>Remember that the second line needs to be executed every time you open a new\nterminal; it may be helpful to create an alias in your bashrc file as a\nshortcut.</p>\n<p>You will then need to clone <code>sds-repo</code>, which contains the Mochi packages.</p>\n<pre><code>$ git clone https://xgitlab.cels.anl.gov/sds/sds-repo.git\n$ spack repo add sds-repo\n</code></pre>\n<p>Now clone the present repository and <code>cd</code> into the subdirectory relevant\nto your platform. For example:</p>\n<pre><code>$ git clone https://xgitlab.cels.anl.gov/sds/experiments/platform-configurations.git\n$ cd platform-configurations/ANL/Bebop\n</code></pre>\n<p>Edit the path to <code>sds-repo</code> in the <code>repos</code> field of the <code>spack.yaml</code> file to\nmatch your installation.</p>\n<p>Then, execute the following command\n(changing <em>myenv</em> into an appropriate name for your environment).</p>\n<pre><code>$ spack env create myenv spack.yaml\n</code></pre>\n<p>Change to a directory outside of the <code>platform-configurations</code> folders\nand activate the environment as follows.</p>\n<pre><code>$ spack env activate myenv\n</code></pre>\n<p>You may now add specs to your environment. For instance if you want\nto install Margo, execute the following command.</p>\n<pre><code>$ spack add mochi-margo\n</code></pre>\n<p>If the <code>spack.yaml</code> file provides multiple compilers and you want\nto use another than the default one, specify the compiler explicitely,\nfor example:</p>\n<pre><code>$ spack add mochi-margo %gcc@8.2.0\n</code></pre>\n<p>Note that the <code>spack.yaml</code> file you used may already have a spec\nadded as an example (usually <code>mochi-margo</code>). You can remove it as\nfollows.</p>\n<pre><code>$ spack rm mochi-margo\n</code></pre>\n<p>Once you have added the specs you need in your environment, install\neverything by executing the following command.</p>\n<pre><code>$ spack install\n</code></pre>\n<p>You may add more specs later on. For more information on how to manage\nSpack environments, please refer to the Spack documentation.</p>\n<h2>\n<a id=\"user-content-contributing-to-this-repository\" class=\"anchor\" href=\"#contributing-to-this-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing to this repository</h2>\n<p>Should you want to contribute a <code>spack.yaml</code> for a particular machine,\nplease submit a merge request with it, and ensure the following.</p>\n<ul>\n<li>The <code>spack.yaml</code> file should contain the compiler(s) that have been tested\nand confirmed to work with Mochi packages.</li>\n<li>The <code>spack.yaml</code> file should try to list system-provided packages,\nin particular packages used for building (<code>cmake</code>, <code>autoconf</code>, etc.),\nand relevant system-provided MPI implementations.\n<ul>\n<li>Note that this must be done manually.  Spack provides a <code>spack external find</code> command that can be used to locate a subset of system packages,\nbut it does not populate the <code>spack.yaml</code> file.</li>\n</ul>\n</li>\n<li>The <code>spack.yaml</code> file should contain the relevant variants for packages,\nin particular the transport methods to use with <code>libfabric</code>.</li>\n<li>The path to the <code>spack.yaml</code> file should be of the form\n<code>&lt;institution&gt;/&lt;platform&gt;/spack.yaml</code>.</li>\n<li>Please make sure that your <code>spack.yaml</code> is a reliable way to work with\nMochi on the target platform, other people will rely on it!</li>\n</ul>\n<p>You can also contribute changes to existing <code>spack.yaml</code> files, in particular\nto add working compilers, system packages, etc. As always, please test that\nnew setups work before creating a merge request.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1614187849.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "haampie-throwaway/spack-status-code",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-github-container-registry\" class=\"anchor\" href=\"#spack-github-container-registry\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack GitHub Container Registry</h1>\n<p>This repository is a testing bed to develop a spack container (using a Dockerfile\ngenerated with <code>spack containerize</code> against a spack.yaml) that can be triggered\nto update with a <a href=\"https://github.com/autamus/binoc\">binoc</a> GitHub action\nand then build and test the container, and if it works, push to a GitHub container\nregistry. We want to do the following:</p>\n<ul>\n<li><a href=\"#minimize-container-size\">1. Minimize the size of the container</a></li>\n<li><a href=\"#binoc-github-action\">2. Binoc GitHub Action</a></li>\n<li>\n<a href=\"#tests\">3. Figure out how tests are added, and results are captured</a>\n<ul>\n<li>What percentage of spack packages have tests?</li>\n<li>Can we capture and get unique identifiers for output?</li>\n</ul>\n</li>\n<li><a href=\"#\">4. Add GitHub action to build, test, and capture results</a></li>\n<li><a href=\"#\">5. Create static repository to hold results</a></li>\n<li><a href=\"#\">6. Push container to GitHub registry (and test limits)</a></li>\n</ul>\n<h2>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h2>\n<p>We have an idea that we would want to be able to:</p>\n<ol>\n<li>configure a repository to regularly check for updates for some set of spack packages</li>\n<li>given an update, open a pull request to build and test a container</li>\n</ol>\n<p>And if the container build and tests are successful, we would want to push\nthe container to a registry. This requires the stages that are described here,\nbroadly:</p>\n<h2>\n<a id=\"user-content-stages\" class=\"anchor\" href=\"#stages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Stages</h2>\n<h3>\n<a id=\"user-content-minimize-container-size\" class=\"anchor\" href=\"#minimize-container-size\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimize Container Size</h3>\n<p>The original goal of this small test was to see if we can use a multi-stage\nbuild to build binaries and then remove spack. This was the first time I tried this,\nand to my surprise, spack already does this! See the <a href=\"minimize-container\">minimize-container</a>\nfolder for an overview.</p>\n<h3>\n<a id=\"user-content-binoc-github-action\" class=\"anchor\" href=\"#binoc-github-action\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Binoc GitHub Action</h3>\n<p>We added a small folder of packages, with a root under <a href=\"spack\">spack</a>,\nthe idea being that we might have other package managers here in a different namespace.\nThat looks like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ tree spack/\nspack/\n\u251c\u2500\u2500 p\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 py-black\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 py-pylint\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 package.py\n\u2514\u2500\u2500 s\n    \u251c\u2500\u2500 singularity\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 package.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 singularity_v3.4.0_remove_root_check.patch\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spack_perms_fix.sh.j2\n    \u2514\u2500\u2500 sublime-text\n        \u2514\u2500\u2500 package.py</pre></div>\n<p>We then added a GitHub workflow file to run binoc at  <a href=\".github/workflows/binoc.yml\">.github/workflows/binoc.yml</a>.\nTo test it, we start with a pull request (and it will be run on a scheduled basis after that.\nWhen an update is present, the binoc robot should open a pull request. For early\ntesting, I'm not using an actual GitHub user, and am providing information for the GitHub\nactions bot. I suspect if we want this PR to trigger testing, we will need an actual\nuser credential.</p>\n<h3>\n<a id=\"user-content-tests\" class=\"anchor\" href=\"#tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tests</h3>\n<p>I'm actually not sure how spack represents tests. I know you can do an install with\nthem, e.g.,</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ spack install <span class=\"pl-k\">&lt;</span>package<span class=\"pl-k\">&gt;</span> --run-tests</pre></div>\n<p>But I'd like to know where/how that works, what kind of tests are run, how\noutput is stored (if at all) and how tests are namespaced. We would want to\nunderstand this so that we can couple the container build with testing, to:</p>\n<ol>\n<li>be sure that tests still work!</li>\n<li>upload results to some testing repository (possibly using go-github) for future comparison.</li>\n</ol>\n<h3>\n<a id=\"user-content-resources\" class=\"anchor\" href=\"#resources\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Resources</h3>\n<p>The following resources (things mentioned above) might be useful:</p>\n<ul>\n<li><a href=\"https://github.com/arken/ait/blob/master/apis/github/files.go\">https://github.com/arken/ait/blob/master/apis/github/files.go</a></li>\n<li><a href=\"https://github.com/google/go-github\">https://github.com/google/go-github</a></li>\n<li>\n<a href=\"https://github.com/autamus/docs\">https://github.com/autamus/docs</a> as a place to write docs</li>\n</ul>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1611769807.0
    },
    {
        "data_format": 2,
        "description": "Container files for building centos7 with netcdf fortran",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "thomas-robinson/centos7-netcdff",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-centos7-netcdff\" class=\"anchor\" href=\"#centos7-netcdff\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>centos7-netcdff</h1>\n<p>Container files for building centos7 with netcdf fortran</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1615499000.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "ezajko/oc",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h1>\n<h2>\n<a id=\"user-content-install-requirements\" class=\"anchor\" href=\"#install-requirements\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Install requirements</h2>\n<pre><code>yum install -y epel-release\nyum install -y ansible python-netaddr git\n</code></pre>\n<p><em>IMPORTANT: Make sure that you installed the epel version. The <code>extras</code> repository\nhas ansible 2.4, which is incompatible with this playbook!</em></p>\n<h2>\n<a id=\"user-content-clone-this-repo\" class=\"anchor\" href=\"#clone-this-repo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Clone this repo</h2>\n<pre><code>git clone --recursive https://bitbucket.versatushpc.com.br/scm/opencattus/deployment.git\ncd deployment\ngit submodule init\ngit submodule update\n</code></pre>\n<h2>\n<a id=\"user-content-runninng\" class=\"anchor\" href=\"#runninng\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Runninng</h2>\n<ul>\n<li>\n<p>Before begin make sure to have, at last, the list of mac of the nodes.</p>\n</li>\n<li>\n<p>Edit <code>nodes.yaml</code>. The variable structures need stay the same. Here is a list of variables and their meanings</p>\n<table>\n<thead>\n<tr>\n<th>variable</th>\n<th>required</th>\n<th>desc</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>mac</td>\n<td>yes</td>\n<td>mac addess of the node</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>no</td>\n<td>IPMI username, if ommited the default* one is used</td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>no</td>\n<td>IPMI password, if ommited the default* one is used</td>\n</tr>\n<tr>\n<td>slurm.Sockets</td>\n<td>only for Slurm</td>\n<td>Sockets slurm.conf entry</td>\n</tr>\n<tr>\n<td>slurm.CoresPerSocket</td>\n<td>only for Slurm</td>\n<td>CoresPerSocket slurm.conf entry</td>\n</tr>\n<tr>\n<td>slurm.ThreadsPerCore</td>\n<td>only for Slurm</td>\n<td>ThreadsPerCore slurm.conf entry</td>\n</tr>\n</tbody>\n</table>\n<p><em>* default here means the value present in <code>answers-&lt;date&gt;.yaml</code>.</em></p>\n</li>\n<li>\n<p>Run <code>ansible-playbook config.yaml</code> to create configuration file</p>\n<ul>\n<li>Answer the questions to configure the environment.</li>\n<li>A new file named answers-.yaml will be created, where <code>&lt;date&gt;</code> is the date for today with the hour. This\nfile contains all your answers to all previous questions, you will use this in the next steps.</li>\n</ul>\n</li>\n<li>\n<p>Run <code>ansible-playbook all.yaml -e @answer-file.yaml</code> to run all phases in sequence</p>\n<p>Or run each of these steps in order:</p>\n</li>\n<li>\n<p>Run <code>ansible-playbook deploy.yaml -e @answer-&lt;date&gt;.yaml</code> to install the base system</p>\n</li>\n<li>\n<p>Add the image <code>ansible-playbook add-image.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>To configure infiniband <code>ansible-playbook infiniband.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>Install OpenHPC <code>ansible-playbook basic-openhpc.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>If using Slurm, install Slurm <code>ansible-playbook slurm.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>If using PBS, install PBS <code>ansible-playbook pbs.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>To install ganglia <code>ansible-playbook ganglia.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>To configure postfix <code>ansible-playbook postfix.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>To configure spack <code>ansible-playbook spack.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>To install TexLive  <code>ansible-playbook latex-support.yaml -e @answers-&lt;date&gt;.yaml</code></p>\n</li>\n<li>\n<p>Finally to create nodes, run: <code>ansible-deploy define-nodes.yaml -e @answers-&lt;date&gt;.yaml</code>. The nodes will be\ndefined in the order they appear in the file.</p>\n</li>\n</ul>\n<hr>\n<h1>\n<a id=\"user-content-running-single-role\" class=\"anchor\" href=\"#running-single-role\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running single role</h1>\n<p><code>ansible -m include_role -a 'name=&lt;ROLE_NAME&gt;' sms -e @answers-...yaml</code></p>\n<h1>\n<a id=\"user-content-running-single-playbook\" class=\"anchor\" href=\"#running-single-playbook\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running single playbook</h1>\n<p><code>ansible -m include_tasks -a 'roles/xcat/tasks/install.yaml' sms -e @answers-...yaml</code></p>\n<h1>\n<a id=\"user-content-questions\" class=\"anchor\" href=\"#questions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Questions</h1>\n<table>\n<thead>\n<tr>\n<th>name</th>\n<th>prompt</th>\n<th>default</th>\n<th>choices</th>\n<th>help</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>cluster_name</td>\n<td>Hostname?</td>\n<td>headnode</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>domain_name</td>\n<td>Domain name?</td>\n<td>cluster.example.com</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipaadmin_password</td>\n<td>FreeIPA admin password</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipadm_password</td>\n<td>FreeIPA Directory Manager password</td>\n<td></td>\n<td></td>\n<td>FreeIPA Directory Manager password<br><br>It uses the same password as admin password entered before. This is used<br>for authenticating to LDAP.<br>\n</td>\n</tr>\n<tr>\n<td>nodes_prefix</td>\n<td>Node prefix?</td>\n<td>node</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_separator</td>\n<td>Node name separtor (optional)</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_padding</td>\n<td>Node name padding?</td>\n<td>3</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_external</td>\n<td>External interface?</td>\n<td>eth0</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_internal</td>\n<td>Internal interface?</td>\n<td>eth1</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network</td>\n<td>Management network?</td>\n<td>172.26.0.0/16</td>\n<td></td>\n<td>Management network is the primary network. Is the one by<br>which nodes boot and where services like DHCP, DNS, TFTP<br>talk.<br>\n</td>\n</tr>\n<tr>\n<td>sms_ip</td>\n<td>Head node management network internal IP?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network_ip_start</td>\n<td>Management network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is the Management Network first node IP address. Remaning nodes<br>will be addressed by subsequent address.<br><br>Expects an IP in the form 10.1.0.1<br>\n</td>\n</tr>\n<tr>\n<td>xcat_dhcp_dynamicrange</td>\n<td>xCAT DHCP Dynamic range?</td>\n<td></td>\n<td></td>\n<td>Dynamic range used for xCAT during node discovery.<br><br>Expects a IP range like 1.1.1.1-1.1.1.10<br>\n</td>\n</tr>\n<tr>\n<td>service_network</td>\n<td>Enter the service network</td>\n<td>172.25.0.0/16</td>\n<td></td>\n<td>This is Service Network. Is the network used for BMC services and alike. It<br>expects to receive a CIDR notation address like 10.1.0.0/16. The network address<br>for the nodes are inferred from this network, starting from 10.1.0.2 up to<br>as many as nodes are defined on cluster.csv<br>\n</td>\n</tr>\n<tr>\n<td>service_network_ip_start</td>\n<td>Service network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is BMC address of the first node. The reimaing nodes<br>will be named with subsequent IP address.<br><br>Expects an IP address like 10.2.0.1<br>\n</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>What is the default IPMI username</td>\n<td>ADMIN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>IPMI default password</td>\n<td></td>\n<td></td>\n<td>This can be overriden by node basis. The password<br>is setup for IPMI connection together with IPMI username<br>asked before<br>\n</td>\n</tr>\n<tr>\n<td>name</td>\n<td>prompt</td>\n<td>default</td>\n<td>choices</td>\n<td>help</td>\n</tr>\n<tr>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n</tr>\n<tr>\n<td>cluster_name</td>\n<td>Hostname?</td>\n<td>headnode</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>domain_name</td>\n<td>Domain name?</td>\n<td>cluster.example.com</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipaadmin_password</td>\n<td>FreeIPA admin password</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipadm_password</td>\n<td>FreeIPA Directory Manager password</td>\n<td></td>\n<td></td>\n<td>FreeIPA Directory Manager password<br><br>It uses the same password as admin password entered before. This is used<br>for authenticating to LDAP.<br>\n</td>\n</tr>\n<tr>\n<td>nodes_prefix</td>\n<td>Node prefix?</td>\n<td>node</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_separator</td>\n<td>Node name separtor (optional)</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_padding</td>\n<td>Node name padding?</td>\n<td>3</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_external</td>\n<td>External interface?</td>\n<td>eth0</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_internal</td>\n<td>Internal interface?</td>\n<td>eth1</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network</td>\n<td>Management network?</td>\n<td>172.26.0.0/16</td>\n<td></td>\n<td>Management network is the primary network. Is the one by<br>which nodes boot and where services like DHCP, DNS, TFTP<br>talk.<br>\n</td>\n</tr>\n<tr>\n<td>sms_ip</td>\n<td>Head node management network internal IP?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network_ip_start</td>\n<td>Management network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is the Management Network first node IP address. Remaning nodes<br>will be addressed by subsequent address.<br><br>Expects an IP in the form 10.1.0.1<br>\n</td>\n</tr>\n<tr>\n<td>xcat_dhcp_dynamicrange</td>\n<td>xCAT DHCP Dynamic range?</td>\n<td></td>\n<td></td>\n<td>Dynamic range used for xCAT during node discovery.<br><br>Expects a IP range like 1.1.1.1-1.1.1.10<br>\n</td>\n</tr>\n<tr>\n<td>service_network_enabled</td>\n<td>Configure service network?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Network used for BMC/IPMI services</td>\n</tr>\n<tr>\n<td>service_network</td>\n<td>Enter the service network</td>\n<td>172.25.0.0/16</td>\n<td></td>\n<td>This is Service Network. Is the network used for BMC services and alike. It<br>expects to receive a CIDR notation address like 10.1.0.0/16. The network address<br>for the nodes are inferred from this network, starting from 10.1.0.2 up to<br>as many as nodes are defined on cluster.csv<br>\n</td>\n</tr>\n<tr>\n<td>service_network_ip_start</td>\n<td>Service network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is BMC address of the first node. The reimaing nodes<br>will be named with subsequent IP address.<br><br>Expects an IP address like 10.2.0.1<br>\n</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>What is the default IPMI username</td>\n<td>ADMIN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>IPMI default password</td>\n<td></td>\n<td></td>\n<td>This can be overriden by node basis. The password<br>is setup for IPMI connection together with IPMI username<br>asked before<br>\n</td>\n</tr>\n<tr>\n<td>queue_system</td>\n<td>Choose a queue system</td>\n<td>none</td>\n<td>none, slurm, pbs</td>\n<td></td>\n</tr>\n<tr>\n<td>pbs_default_place</td>\n<td>PBS default place</td>\n<td>shared</td>\n<td>shared, scatter</td>\n<td>PBS default.place option<br>\n</td>\n</tr>\n<tr>\n<td>postfix_install</td>\n<td>Install postfix?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Enable installation and configuration of postfix<br>\n</td>\n</tr>\n<tr>\n<td>postfix_profile</td>\n<td>Choose a profile for postfix installation?</td>\n<td>local</td>\n<td>relay, local, sasl</td>\n<td>Select the profile. There are 3 options<br>  local) All messages are delivered locally only<br>  relay) Messages are relayed to another MTA<br>  sasl)  Messages are relayed to another MTA, but it<br>         uses user/password to connect to it<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Type the MTA to relay to?</td>\n<td></td>\n<td></td>\n<td>The relay address, ex: relay-smtp.example.com<br>\n</td>\n</tr>\n<tr>\n<td>postfix_mynetworks_more</td>\n<td>Custom trusted networks?</td>\n<td></td>\n<td></td>\n<td>Comma separated list, localhost and cluster networks are already added by default<br>Ex: 192.168.123.0/24, 10.0.0.0/8<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Relay server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_relay_port</td>\n<td>Relay port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_user</td>\n<td>SMTP user?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_password</td>\n<td>SMTP password?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_server</td>\n<td>SMTP server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_port</td>\n<td>SMTP port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>certificate_install</td>\n<td>Create certificate</td>\n<td>yes</td>\n<td>yes, no</td>\n<td></td>\n</tr>\n<tr>\n<td>ib_stack</td>\n<td>Infiniband stack</td>\n<td>none</td>\n<td>none, upstream, mellanox</td>\n<td>none      =&gt; Do not install Infiniband at all<br>upstream  =&gt; The main stream OFED stack, opensource and provided by default repos<br>mellanox  =&gt; The Mellanox OFED stack<br>\n</td>\n</tr>\n<tr>\n<td>ib_network</td>\n<td>Application network</td>\n<td>172.27.0.0/16</td>\n<td></td>\n<td>This is the network used by applications to talk, is a high speed network.<br><br>Expcets a network address like 172.27.0.0/16<br>\n</td>\n</tr>\n<tr>\n<td>ib_network_ip_start</td>\n<td>Infiniband network first node IP address</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>name</td>\n<td>prompt</td>\n<td>default</td>\n<td>choices</td>\n<td>help</td>\n</tr>\n<tr>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n</tr>\n<tr>\n<td>cluster_name</td>\n<td>Hostname?</td>\n<td>headnode</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>domain_name</td>\n<td>Domain name?</td>\n<td>cluster.example.com</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipaadmin_password</td>\n<td>FreeIPA admin password</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipadm_password</td>\n<td>FreeIPA Directory Manager password</td>\n<td></td>\n<td></td>\n<td>FreeIPA Directory Manager password<br><br>It uses the same password as admin password entered before. This is used<br>for authenticating to LDAP.<br>\n</td>\n</tr>\n<tr>\n<td>nodes_prefix</td>\n<td>Node prefix?</td>\n<td>n</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_separator</td>\n<td>Node name separtor (optional)</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_padding</td>\n<td>Node name padding?</td>\n<td>2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_external</td>\n<td>External interface?</td>\n<td>eth0</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_internal</td>\n<td>Internal interface?</td>\n<td>eth1</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network</td>\n<td>Management network?</td>\n<td>172.26.0.0/16</td>\n<td></td>\n<td>Management network is the primary network. Is the one by<br>which nodes boot and where services like DHCP, DNS, TFTP<br>talk.<br>\n</td>\n</tr>\n<tr>\n<td>sms_ip</td>\n<td>Head node management network internal IP?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network_ip_start</td>\n<td>Management network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is the Management Network first node IP address. Remaning nodes<br>will be addressed by subsequent address.<br><br>Expects an IP in the form 10.1.0.1<br>\n</td>\n</tr>\n<tr>\n<td>xcat_dhcp_dynamicrange</td>\n<td>xCAT DHCP Dynamic range?</td>\n<td></td>\n<td></td>\n<td>Dynamic range used for xCAT during node discovery.<br><br>Expects a IP range like 1.1.1.1-1.1.1.10<br>\n</td>\n</tr>\n<tr>\n<td>service_network_enabled</td>\n<td>Configure service network?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Network used for BMC/IPMI services</td>\n</tr>\n<tr>\n<td>service_network</td>\n<td>Enter the service network</td>\n<td>172.25.0.0/16</td>\n<td></td>\n<td>This is Service Network. Is the network used for BMC services and alike. It<br>expects to receive a CIDR notation address like 10.1.0.0/16. The network address<br>for the nodes are inferred from this network, starting from 10.1.0.2 up to<br>as many as nodes are defined on cluster.csv<br>\n</td>\n</tr>\n<tr>\n<td>service_network_ip_start</td>\n<td>Service network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is BMC address of the first node. The reimaing nodes<br>will be named with subsequent IP address.<br><br>Expects an IP address like 10.2.0.1<br>\n</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>What is the default IPMI username</td>\n<td>ADMIN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>IPMI default password</td>\n<td></td>\n<td></td>\n<td>This can be overriden by node basis. The password<br>is setup for IPMI connection together with IPMI username<br>asked before<br>\n</td>\n</tr>\n<tr>\n<td>queue_system</td>\n<td>Choose a queue system</td>\n<td>none</td>\n<td>none, slurm, pbs</td>\n<td></td>\n</tr>\n<tr>\n<td>pbs_default_place</td>\n<td>PBS default place</td>\n<td>shared</td>\n<td>shared, scatter</td>\n<td>PBS default.place option<br>\n</td>\n</tr>\n<tr>\n<td>slurm_partition_name</td>\n<td>Slurm default partition name</td>\n<td>batch</td>\n<td></td>\n<td>The Slurm partition name<br>\n</td>\n</tr>\n<tr>\n<td>postfix_install</td>\n<td>Install postfix?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Enable installation and configuration of postfix<br>\n</td>\n</tr>\n<tr>\n<td>postfix_profile</td>\n<td>Choose a profile for postfix installation?</td>\n<td>local</td>\n<td>relay, local, sasl</td>\n<td>Select the profile. There are 3 options<br>  local) All messages are delivered locally only<br>  relay) Messages are relayed to another MTA<br>  sasl)  Messages are relayed to another MTA, but it<br>         uses user/password to connect to it<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Type the MTA to relay to?</td>\n<td></td>\n<td></td>\n<td>The relay address, ex: relay-smtp.example.com<br>\n</td>\n</tr>\n<tr>\n<td>postfix_mynetworks_more</td>\n<td>Custom trusted networks?</td>\n<td></td>\n<td></td>\n<td>Comma separated list, localhost and cluster networks are already added by default<br>Ex: 192.168.123.0/24, 10.0.0.0/8<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Relay server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_relay_port</td>\n<td>Relay port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_user</td>\n<td>SMTP user?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_password</td>\n<td>SMTP password?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_server</td>\n<td>SMTP server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_port</td>\n<td>SMTP port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>certificate_install</td>\n<td>Create certificate</td>\n<td>yes</td>\n<td>yes, no</td>\n<td></td>\n</tr>\n<tr>\n<td>ib_stack</td>\n<td>Infiniband stack</td>\n<td>none</td>\n<td>none, upstream, mellanox</td>\n<td>none      =&gt; Do not install Infiniband at all<br>upstream  =&gt; The main stream OFED stack, opensource and provided by default repos<br>mellanox  =&gt; The Mellanox OFED stack<br>\n</td>\n</tr>\n<tr>\n<td>ib_network</td>\n<td>Application network</td>\n<td>172.27.0.0/16</td>\n<td></td>\n<td>This is the network used by applications to talk, is a high speed network.<br><br>Expcets a network address like 172.27.0.0/16<br>\n</td>\n</tr>\n<tr>\n<td>ib_network_ip_start</td>\n<td>Infiniband network first node IP address</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>timezone</td>\n<td>Select timezone</td>\n<td>America/Sao_Paulo</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>name</td>\n<td>prompt</td>\n<td>default</td>\n<td>choices</td>\n<td>help</td>\n</tr>\n<tr>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n</tr>\n<tr>\n<td>cluster_name</td>\n<td>Hostname?</td>\n<td>headnode</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>domain_name</td>\n<td>Domain name?</td>\n<td>cluster.example.com</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipaadmin_password</td>\n<td>FreeIPA admin password</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipadm_password</td>\n<td>FreeIPA Directory Manager password</td>\n<td></td>\n<td></td>\n<td>FreeIPA Directory Manager password<br><br>It uses the same password as admin password entered before. This is used<br>for authenticating to LDAP.<br>\n</td>\n</tr>\n<tr>\n<td>nodes_prefix</td>\n<td>Node prefix?</td>\n<td>n</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_separator</td>\n<td>Node name separtor (optional)</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_padding</td>\n<td>Node name padding?</td>\n<td>2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_external</td>\n<td>External interface?</td>\n<td>eth0</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_internal</td>\n<td>Internal interface?</td>\n<td>eth1</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network</td>\n<td>Management network?</td>\n<td>172.26.0.0/16</td>\n<td></td>\n<td>Management network is the primary network. Is the one by<br>which nodes boot and where services like DHCP, DNS, TFTP<br>talk.<br>\n</td>\n</tr>\n<tr>\n<td>sms_ip</td>\n<td>Head node management network internal IP?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network_ip_start</td>\n<td>Management network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is the Management Network first node IP address. Remaning nodes<br>will be addressed by subsequent address.<br><br>Expects an IP in the form 10.1.0.1<br>\n</td>\n</tr>\n<tr>\n<td>xcat_dhcp_dynamicrange</td>\n<td>xCAT DHCP Dynamic range?</td>\n<td></td>\n<td></td>\n<td>Dynamic range used for xCAT during node discovery.<br><br>Expects a IP range like 1.1.1.1-1.1.1.10<br>\n</td>\n</tr>\n<tr>\n<td>service_network_enabled</td>\n<td>Configure service network?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Network used for BMC/IPMI services</td>\n</tr>\n<tr>\n<td>service_network</td>\n<td>Enter the service network</td>\n<td>172.25.0.0/16</td>\n<td></td>\n<td>This is Service Network. Is the network used for BMC services and alike. It<br>expects to receive a CIDR notation address like 10.1.0.0/16. The network address<br>for the nodes are inferred from this network, starting from 10.1.0.2 up to<br>as many as nodes are defined on cluster.csv<br>\n</td>\n</tr>\n<tr>\n<td>service_network_ip_start</td>\n<td>Service network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is BMC address of the first node. The reimaing nodes<br>will be named with subsequent IP address.<br><br>Expects an IP address like 10.2.0.1<br>\n</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>What is the default IPMI username</td>\n<td>ADMIN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>IPMI default password</td>\n<td></td>\n<td></td>\n<td>This can be overriden by node basis. The password<br>is setup for IPMI connection together with IPMI username<br>asked before<br>\n</td>\n</tr>\n<tr>\n<td>queue_system</td>\n<td>Choose a queue system</td>\n<td>none</td>\n<td>none, slurm, pbs</td>\n<td></td>\n</tr>\n<tr>\n<td>pbs_default_place</td>\n<td>PBS default place</td>\n<td>shared</td>\n<td>shared, scatter</td>\n<td>PBS default.place option<br>\n</td>\n</tr>\n<tr>\n<td>slurm_partition_name</td>\n<td>Slurm default partition name</td>\n<td>batch</td>\n<td></td>\n<td>The Slurm partition name<br>\n</td>\n</tr>\n<tr>\n<td>postfix_install</td>\n<td>Install postfix?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Enable installation and configuration of postfix<br>\n</td>\n</tr>\n<tr>\n<td>postfix_profile</td>\n<td>Choose a profile for postfix installation?</td>\n<td>local</td>\n<td>relay, local, sasl</td>\n<td>Select the profile. There are 3 options<br>  local) All messages are delivered locally only<br>  relay) Messages are relayed to another MTA<br>  sasl)  Messages are relayed to another MTA, but it<br>         uses user/password to connect to it<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Type the MTA to relay to?</td>\n<td></td>\n<td></td>\n<td>The relay address, ex: relay-smtp.example.com<br>\n</td>\n</tr>\n<tr>\n<td>postfix_mynetworks_more</td>\n<td>Custom trusted networks?</td>\n<td></td>\n<td></td>\n<td>Comma separated list, localhost and cluster networks are already added by default<br>Ex: 192.168.123.0/24, 10.0.0.0/8<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Relay server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_relay_port</td>\n<td>Relay port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_user</td>\n<td>SMTP user?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_password</td>\n<td>SMTP password?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_server</td>\n<td>SMTP server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_port</td>\n<td>SMTP port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>certificate_install</td>\n<td>Create certificate</td>\n<td>yes</td>\n<td>yes, no</td>\n<td></td>\n</tr>\n<tr>\n<td>ib_stack</td>\n<td>Infiniband stack</td>\n<td>none</td>\n<td>none, upstream, mellanox</td>\n<td>none      =&gt; Do not install Infiniband at all<br>upstream  =&gt; The main stream OFED stack, opensource and provided by default repos<br>mellanox  =&gt; The Mellanox OFED stack<br>\n</td>\n</tr>\n<tr>\n<td>ib_network</td>\n<td>Application network</td>\n<td>172.27.0.0/16</td>\n<td></td>\n<td>This is the network used by applications to talk, is a high speed network.<br><br>Expcets a network address like 172.27.0.0/16<br>\n</td>\n</tr>\n<tr>\n<td>ib_network_ip_start</td>\n<td>Infiniband network first node IP address</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>timezone</td>\n<td>Select timezone</td>\n<td>America/Sao_Paulo</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>name</td>\n<td>prompt</td>\n<td>default</td>\n<td>choices</td>\n<td>help</td>\n</tr>\n<tr>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n</tr>\n<tr>\n<td>cluster_name</td>\n<td>Hostname?</td>\n<td>headnode</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>domain_name</td>\n<td>Domain name?</td>\n<td>cluster.example.com</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipaadmin_password</td>\n<td>FreeIPA admin password</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipadm_password</td>\n<td>FreeIPA Directory Manager password</td>\n<td></td>\n<td></td>\n<td>FreeIPA Directory Manager password<br><br>It uses the same password as admin password entered before. This is used<br>for authenticating to LDAP.<br>\n</td>\n</tr>\n<tr>\n<td>nodes_prefix</td>\n<td>Node prefix?</td>\n<td>n</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_separator</td>\n<td>Node name separtor (optional)</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_padding</td>\n<td>Node name padding?</td>\n<td>2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_external</td>\n<td>External interface?</td>\n<td>eth0</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_internal</td>\n<td>Internal interface?</td>\n<td>eth1</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network</td>\n<td>Management network?</td>\n<td>172.26.0.0/16</td>\n<td></td>\n<td>Management network is the primary network. Is the one by<br>which nodes boot and where services like DHCP, DNS, TFTP<br>talk.<br>\n</td>\n</tr>\n<tr>\n<td>sms_ip</td>\n<td>Head node management network internal IP?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network_ip_start</td>\n<td>Management network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is the Management Network first node IP address. Remaning nodes<br>will be addressed by subsequent address.<br><br>Expects an IP in the form 10.1.0.1<br>\n</td>\n</tr>\n<tr>\n<td>xcat_dhcp_dynamicrange</td>\n<td>xCAT DHCP Dynamic range?</td>\n<td></td>\n<td></td>\n<td>Dynamic range used for xCAT during node discovery.<br><br>Expects a IP range like 1.1.1.1-1.1.1.10<br>\n</td>\n</tr>\n<tr>\n<td>service_network_enabled</td>\n<td>Configure service network?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Network used for BMC/IPMI services</td>\n</tr>\n<tr>\n<td>service_network</td>\n<td>Enter the service network</td>\n<td>172.25.0.0/16</td>\n<td></td>\n<td>This is Service Network. Is the network used for BMC services and alike. It<br>expects to receive a CIDR notation address like 10.1.0.0/16. The network address<br>for the nodes are inferred from this network, starting from 10.1.0.2 up to<br>as many as nodes are defined on cluster.csv<br>\n</td>\n</tr>\n<tr>\n<td>service_network_ip_start</td>\n<td>Service network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is BMC address of the first node. The reimaing nodes<br>will be named with subsequent IP address.<br><br>Expects an IP address like 10.2.0.1<br>\n</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>What is the default IPMI username</td>\n<td>ADMIN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>IPMI default password</td>\n<td></td>\n<td></td>\n<td>This can be overriden by node basis. The password<br>is setup for IPMI connection together with IPMI username<br>asked before<br>\n</td>\n</tr>\n<tr>\n<td>queue_system</td>\n<td>Choose a queue system</td>\n<td>none</td>\n<td>none, slurm, pbs</td>\n<td></td>\n</tr>\n<tr>\n<td>pbs_default_place</td>\n<td>PBS default place</td>\n<td>shared</td>\n<td>shared, scatter</td>\n<td>PBS default.place option<br>\n</td>\n</tr>\n<tr>\n<td>slurm_partition_name</td>\n<td>Slurm default partition name</td>\n<td>batch</td>\n<td></td>\n<td>The Slurm partition name<br>\n</td>\n</tr>\n<tr>\n<td>postfix_install</td>\n<td>Install postfix?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Enable installation and configuration of postfix<br>\n</td>\n</tr>\n<tr>\n<td>postfix_profile</td>\n<td>Choose a profile for postfix installation?</td>\n<td>local</td>\n<td>relay, local, sasl</td>\n<td>Select the profile. There are 3 options<br>  local) All messages are delivered locally only<br>  relay) Messages are relayed to another MTA<br>  sasl)  Messages are relayed to another MTA, but it<br>         uses user/password to connect to it<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Type the MTA to relay to?</td>\n<td></td>\n<td></td>\n<td>The relay address, ex: relay-smtp.example.com<br>\n</td>\n</tr>\n<tr>\n<td>postfix_mynetworks_more</td>\n<td>Custom trusted networks?</td>\n<td></td>\n<td></td>\n<td>Comma separated list, localhost and cluster networks are already added by default<br>Ex: 192.168.123.0/24, 10.0.0.0/8<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Relay server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_relay_port</td>\n<td>Relay port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_user</td>\n<td>SMTP user?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_password</td>\n<td>SMTP password?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_server</td>\n<td>SMTP server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_port</td>\n<td>SMTP port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>certificate_install</td>\n<td>Create certificate</td>\n<td>yes</td>\n<td>yes, no</td>\n<td></td>\n</tr>\n<tr>\n<td>ib_stack</td>\n<td>Infiniband stack</td>\n<td>none</td>\n<td>none, upstream, mellanox</td>\n<td>none      =&gt; Do not install Infiniband at all<br>upstream  =&gt; The main stream OFED stack, opensource and provided by default repos<br>mellanox  =&gt; The Mellanox OFED stack<br>\n</td>\n</tr>\n<tr>\n<td>ib_network</td>\n<td>Application network</td>\n<td>172.27.0.0/16</td>\n<td></td>\n<td>This is the network used by applications to talk, is a high speed network.<br><br>Expcets a network address like 172.27.0.0/16<br>\n</td>\n</tr>\n<tr>\n<td>ib_network_ip_start</td>\n<td>Infiniband network first node IP address</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>timezone</td>\n<td>Select timezone</td>\n<td>America/Sao_Paulo</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>name</td>\n<td>prompt</td>\n<td>default</td>\n<td>choices</td>\n<td>help</td>\n</tr>\n<tr>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n</tr>\n<tr>\n<td>cluster_name</td>\n<td>Hostname?</td>\n<td>headnode</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>domain_name</td>\n<td>Domain name?</td>\n<td>cluster.example.com</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipaadmin_password</td>\n<td>FreeIPA admin password</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipadm_password</td>\n<td>FreeIPA Directory Manager password</td>\n<td></td>\n<td></td>\n<td>FreeIPA Directory Manager password<br><br>It uses the same password as admin password entered before. This is used<br>for authenticating to LDAP.<br>\n</td>\n</tr>\n<tr>\n<td>nodes_prefix</td>\n<td>Node prefix?</td>\n<td>n</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_separator</td>\n<td>Node name separtor (optional)</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_padding</td>\n<td>Node name padding?</td>\n<td>2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_external</td>\n<td>External interface?</td>\n<td>eth0</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_internal</td>\n<td>Internal interface?</td>\n<td>eth1</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network</td>\n<td>Management network?</td>\n<td>172.26.0.0/16</td>\n<td></td>\n<td>Management network is the primary network. Is the one by<br>which nodes boot and where services like DHCP, DNS, TFTP<br>talk.<br>\n</td>\n</tr>\n<tr>\n<td>sms_ip</td>\n<td>Head node management network internal IP?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network_ip_start</td>\n<td>Management network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is the Management Network first node IP address. Remaning nodes<br>will be addressed by subsequent address.<br><br>Expects an IP in the form 10.1.0.1<br>\n</td>\n</tr>\n<tr>\n<td>xcat_dhcp_dynamicrange</td>\n<td>xCAT DHCP Dynamic range?</td>\n<td></td>\n<td></td>\n<td>Dynamic range used for xCAT during node discovery.<br><br>Expects a IP range like 1.1.1.1-1.1.1.10<br>\n</td>\n</tr>\n<tr>\n<td>service_network_enabled</td>\n<td>Configure service network?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Network used for BMC/IPMI services</td>\n</tr>\n<tr>\n<td>service_network</td>\n<td>Enter the service network</td>\n<td>172.25.0.0/16</td>\n<td></td>\n<td>This is Service Network. Is the network used for BMC services and alike. It<br>expects to receive a CIDR notation address like 10.1.0.0/16. The network address<br>for the nodes are inferred from this network, starting from 10.1.0.2 up to<br>as many as nodes are defined on cluster.csv<br>\n</td>\n</tr>\n<tr>\n<td>service_network_ip_start</td>\n<td>Service network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is BMC address of the first node. The reimaing nodes<br>will be named with subsequent IP address.<br><br>Expects an IP address like 10.2.0.1<br>\n</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>What is the default IPMI username</td>\n<td>ADMIN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>IPMI default password</td>\n<td></td>\n<td></td>\n<td>This can be overriden by node basis. The password<br>is setup for IPMI connection together with IPMI username<br>asked before<br>\n</td>\n</tr>\n<tr>\n<td>queue_system</td>\n<td>Choose a queue system</td>\n<td>none</td>\n<td>none, slurm, pbs</td>\n<td></td>\n</tr>\n<tr>\n<td>pbs_default_place</td>\n<td>PBS default place</td>\n<td>shared</td>\n<td>shared, scatter</td>\n<td>PBS default.place option<br>\n</td>\n</tr>\n<tr>\n<td>slurm_partition_name</td>\n<td>Slurm default partition name</td>\n<td>batch</td>\n<td></td>\n<td>The Slurm partition name<br>\n</td>\n</tr>\n<tr>\n<td>postfix_install</td>\n<td>Install postfix?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Enable installation and configuration of postfix<br>\n</td>\n</tr>\n<tr>\n<td>postfix_profile</td>\n<td>Choose a profile for postfix installation?</td>\n<td>local</td>\n<td>relay, local, sasl</td>\n<td>Select the profile. There are 3 options<br>  local) All messages are delivered locally only<br>  relay) Messages are relayed to another MTA<br>  sasl)  Messages are relayed to another MTA, but it<br>         uses user/password to connect to it<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Type the MTA to relay to?</td>\n<td></td>\n<td></td>\n<td>The relay address, ex: relay-smtp.example.com<br>\n</td>\n</tr>\n<tr>\n<td>postfix_mynetworks_more</td>\n<td>Custom trusted networks?</td>\n<td></td>\n<td></td>\n<td>Comma separated list, localhost and cluster networks are already added by default<br>Ex: 192.168.123.0/24, 10.0.0.0/8<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Relay server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_relay_port</td>\n<td>Relay port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_user</td>\n<td>SMTP user?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_password</td>\n<td>SMTP password?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_server</td>\n<td>SMTP server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_port</td>\n<td>SMTP port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>certificate_install</td>\n<td>Create certificate</td>\n<td>yes</td>\n<td>yes, no</td>\n<td></td>\n</tr>\n<tr>\n<td>ib_stack</td>\n<td>Infiniband stack</td>\n<td>none</td>\n<td>none, upstream, mellanox</td>\n<td>none      =&gt; Do not install Infiniband at all<br>upstream  =&gt; The main stream OFED stack, opensource and provided by default repos<br>mellanox  =&gt; The Mellanox OFED stack<br>\n</td>\n</tr>\n<tr>\n<td>ib_network</td>\n<td>Application network</td>\n<td>172.27.0.0/16</td>\n<td></td>\n<td>This is the network used by applications to talk, is a high speed network.<br><br>Expcets a network address like 172.27.0.0/16<br>\n</td>\n</tr>\n<tr>\n<td>ib_network_ip_start</td>\n<td>Infiniband network first node IP address</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>timezone</td>\n<td>Select timezone</td>\n<td>America/Sao_Paulo</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>name</td>\n<td>prompt</td>\n<td>default</td>\n<td>choices</td>\n<td>help</td>\n</tr>\n<tr>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n</tr>\n<tr>\n<td>cluster_name</td>\n<td>Hostname?</td>\n<td>headnode</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>domain_name</td>\n<td>Domain name?</td>\n<td>cluster.example.com</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipaadmin_password</td>\n<td>FreeIPA admin password</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipadm_password</td>\n<td>FreeIPA Directory Manager password</td>\n<td></td>\n<td></td>\n<td>FreeIPA Directory Manager password<br><br>It uses the same password as admin password entered before. This is used<br>for authenticating to LDAP.<br>\n</td>\n</tr>\n<tr>\n<td>nodes_prefix</td>\n<td>Node prefix?</td>\n<td>n</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_separator</td>\n<td>Node name separtor (optional)</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>nodes_padding</td>\n<td>Node name padding?</td>\n<td>2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_external</td>\n<td>External interface?</td>\n<td>eth0</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_eth_internal</td>\n<td>Internal interface?</td>\n<td>eth1</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network</td>\n<td>Management network?</td>\n<td>172.26.0.0/16</td>\n<td></td>\n<td>Management network is the primary network. Is the one by<br>which nodes boot and where services like DHCP, DNS, TFTP<br>talk.<br>\n</td>\n</tr>\n<tr>\n<td>sms_ip</td>\n<td>Head node management network internal IP?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>sms_network_ip_start</td>\n<td>Management network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is the Management Network first node IP address. Remaning nodes<br>will be addressed by subsequent address.<br><br>Expects an IP in the form 10.1.0.1<br>\n</td>\n</tr>\n<tr>\n<td>xcat_dhcp_dynamicrange</td>\n<td>xCAT DHCP Dynamic range?</td>\n<td></td>\n<td></td>\n<td>Dynamic range used for xCAT during node discovery.<br><br>Expects a IP range like 1.1.1.1-1.1.1.10<br>\n</td>\n</tr>\n<tr>\n<td>service_network_enabled</td>\n<td>Configure service network?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Network used for BMC/IPMI services</td>\n</tr>\n<tr>\n<td>service_network</td>\n<td>Enter the service network</td>\n<td>172.25.0.0/16</td>\n<td></td>\n<td>This is Service Network. Is the network used for BMC services and alike. It<br>expects to receive a CIDR notation address like 10.1.0.0/16. The network address<br>for the nodes are inferred from this network, starting from 10.1.0.2 up to<br>as many as nodes are defined on cluster.csv<br>\n</td>\n</tr>\n<tr>\n<td>service_network_ip_start</td>\n<td>Service network first node IP address</td>\n<td></td>\n<td></td>\n<td>This is BMC address of the first node. The reimaing nodes<br>will be named with subsequent IP address.<br><br>Expects an IP address like 10.2.0.1<br>\n</td>\n</tr>\n<tr>\n<td>ipmi_user</td>\n<td>What is the default IPMI username</td>\n<td>ADMIN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ipmi_password</td>\n<td>IPMI default password</td>\n<td></td>\n<td></td>\n<td>This can be overriden by node basis. The password<br>is setup for IPMI connection together with IPMI username<br>asked before<br>\n</td>\n</tr>\n<tr>\n<td>queue_system</td>\n<td>Choose a queue system</td>\n<td>none</td>\n<td>none, slurm, pbs</td>\n<td></td>\n</tr>\n<tr>\n<td>pbs_default_place</td>\n<td>PBS default place</td>\n<td>shared</td>\n<td>shared, scatter</td>\n<td>PBS default.place option<br>\n</td>\n</tr>\n<tr>\n<td>slurm_partition_name</td>\n<td>Slurm default partition name</td>\n<td>batch</td>\n<td></td>\n<td>The Slurm partition name<br>\n</td>\n</tr>\n<tr>\n<td>postfix_install</td>\n<td>Install postfix?</td>\n<td>yes</td>\n<td>yes, no</td>\n<td>Enable installation and configuration of postfix<br>\n</td>\n</tr>\n<tr>\n<td>postfix_profile</td>\n<td>Choose a profile for postfix installation?</td>\n<td>local</td>\n<td>relay, local, sasl</td>\n<td>Select the profile. There are 3 options<br>  local) All messages are delivered locally only<br>  relay) Messages are relayed to another MTA<br>  sasl)  Messages are relayed to another MTA, but it<br>         uses user/password to connect to it<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Type the MTA to relay to?</td>\n<td></td>\n<td></td>\n<td>The relay address, ex: relay-smtp.example.com<br>\n</td>\n</tr>\n<tr>\n<td>postfix_mynetworks_more</td>\n<td>Custom trusted networks?</td>\n<td></td>\n<td></td>\n<td>Comma separated list, localhost and cluster networks are already added by default<br>Ex: 192.168.123.0/24, 10.0.0.0/8<br>\n</td>\n</tr>\n<tr>\n<td>postfix_relay_server</td>\n<td>Relay server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_relay_port</td>\n<td>Relay port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_user</td>\n<td>SMTP user?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_password</td>\n<td>SMTP password?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_server</td>\n<td>SMTP server?</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>postfix_sasl_port</td>\n<td>SMTP port?</td>\n<td>25</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>certificate_install</td>\n<td>Create certificate</td>\n<td>yes</td>\n<td>yes, no</td>\n<td></td>\n</tr>\n<tr>\n<td>ib_stack</td>\n<td>Infiniband stack</td>\n<td>none</td>\n<td>none, upstream, mellanox</td>\n<td>none      =&gt; Do not install Infiniband at all<br>upstream  =&gt; The main stream OFED stack, opensource and provided by default repos<br>mellanox  =&gt; The Mellanox OFED stack<br>\n</td>\n</tr>\n<tr>\n<td>ib_network</td>\n<td>Application network</td>\n<td>172.27.0.0/16</td>\n<td></td>\n<td>This is the network used by applications to talk, is a high speed network.<br><br>Expcets a network address like 172.27.0.0/16<br>\n</td>\n</tr>\n<tr>\n<td>ib_network_ip_start</td>\n<td>Infiniband network first node IP address</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>timezone</td>\n<td>Select timezone</td>\n<td>America/Sao_Paulo</td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n",
        "stargazers_count": 0,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1599073995.0
    },
    {
        "data_format": 2,
        "description": "Container recipes used by Spack for test purposes",
        "filenames": [
            "clingo/spack.yaml"
        ],
        "full_name": "spack/spack-ci-containers",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-ci-containers\" class=\"anchor\" href=\"#spack-ci-containers\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack CI containers</h1>\n<p>This repository contains recipes for containers that are\nused to test Spack under CI.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>\n<p>See <a href=\"https://github.com/spack/spack-ci-containers/blob/master/LICENSE-MIT\">LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack-ci-containers/blob/master/LICENSE-APACHE\">LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack-ci-containers/blob/master/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack-ci-containers/blob/master/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1616189112.0
    },
    {
        "data_format": 2,
        "description": "Base Docker Image for CDSE containers running at CARC",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "UNM-CARC/docker_base",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-docker_basemaster\" class=\"anchor\" href=\"#docker_basemaster\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>docker_base:master</h1>\n<p>Base Docker Image for CDSE containers. Master container is generic openmpi\nand x86_64.</p>\n",
        "stargazers_count": 0,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1573104660.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "tests/spack.yaml"
        ],
        "full_name": "SeisSol/yateto",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-yateto\" class=\"anchor\" href=\"#yateto\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>YATeTo</h1>\n<p>It is <strong>Y</strong>et <strong>A</strong>nother <strong>Te</strong>nsor <strong>To</strong>olbox for discontinuous Galerkin methods and other\napplications. You can find much more information about the package\n<a href=\"https://arxiv.org/abs/1903.11521\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<div class=\"highlight highlight-source-shell\"><pre>pip install -e <span class=\"pl-c1\">.</span></pre></div>\n<h2>\n<a id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-s1\">yateto</span> <span class=\"pl-k\">import</span> <span class=\"pl-c1\">*</span>\n\n...\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">add</span>(<span class=\"pl-s1\">g</span>):\n  <span class=\"pl-v\">N</span> <span class=\"pl-c1\">=</span> <span class=\"pl-c1\">8</span>\n  <span class=\"pl-v\">A</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Tensor</span>(<span class=\"pl-s\">'A'</span>, (<span class=\"pl-v\">N</span>, <span class=\"pl-v\">N</span>))\n  <span class=\"pl-v\">B</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Tensor</span>(<span class=\"pl-s\">'B'</span>, (<span class=\"pl-v\">N</span>, <span class=\"pl-v\">N</span>, <span class=\"pl-v\">N</span>))\n  <span class=\"pl-s1\">w</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Tensor</span>(<span class=\"pl-s\">'w'</span>, (<span class=\"pl-v\">N</span>,))\n  <span class=\"pl-v\">C</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Tensor</span>(<span class=\"pl-s\">'C'</span>, (<span class=\"pl-v\">N</span>, <span class=\"pl-v\">N</span>))\n  \n  <span class=\"pl-s1\">kernel</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\">C</span>[<span class=\"pl-s\">'ij'</span>] <span class=\"pl-c1\">&lt;=</span> <span class=\"pl-c1\">2.0</span> <span class=\"pl-c1\">*</span> <span class=\"pl-v\">C</span>[<span class=\"pl-s\">'ij'</span>] <span class=\"pl-c1\">+</span> <span class=\"pl-v\">A</span>[<span class=\"pl-s\">'lj'</span>] <span class=\"pl-c1\">*</span> <span class=\"pl-v\">B</span>[<span class=\"pl-s\">'ikl'</span>] <span class=\"pl-c1\">*</span> <span class=\"pl-s1\">w</span>[<span class=\"pl-s\">'k'</span>]\n  <span class=\"pl-s1\">g</span>.<span class=\"pl-en\">add</span>(<span class=\"pl-s1\">name</span><span class=\"pl-c1\">=</span><span class=\"pl-s\">'kernel'</span>, <span class=\"pl-s1\">ast</span><span class=\"pl-c1\">=</span><span class=\"pl-s1\">kernel</span>)\n\n<span class=\"pl-c\"># 'd' - double precision; 'hsw' - haswell-like architecture</span>\n<span class=\"pl-s1\">arch</span> <span class=\"pl-c1\">=</span> <span class=\"pl-en\">useArchitectureIdentifiedBy</span>(<span class=\"pl-s\">\"dhsw\"</span>)\n<span class=\"pl-s1\">generator</span> <span class=\"pl-c1\">=</span> <span class=\"pl-v\">Generator</span>(<span class=\"pl-s1\">arch</span>)\n<span class=\"pl-en\">add</span>(<span class=\"pl-s1\">generator</span>)\n<span class=\"pl-s1\">generator</span>.<span class=\"pl-en\">generate</span>(<span class=\"pl-s1\">output_dir</span>, <span class=\"pl-v\">GeneratorCollection</span>([<span class=\"pl-v\">LIBXSMM</span>(<span class=\"pl-s1\">arch</span>), <span class=\"pl-v\">Eigen</span>(<span class=\"pl-s1\">arch</span>)]))\n...</pre></div>\n",
        "stargazers_count": 0,
        "subscribers_count": 12,
        "topics": [],
        "updated_at": 1620414091.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "hariharan-devarajan/emacs",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" class=\"anchor\" href=\"#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack configuration files and scripts for use on machines at NREL</h1>\n<p>These software installations are maintained by Jon Rood for the HPACF group at NREL and are tailored to the applications our group develops. The list of available modules can be seen in <a href=\"modules.txt\">modules.txt</a>. They are open to anyone to use on our machines. The software installations are organized by date snapshots. The binaries, compilers, and utilties are not updated as often as the software modules, so dated symlinks might point to older dates for those. However, each date snapshot of the modules should be able to stand on its own so that older snapshots can be purged safely over time.</p>\n<ul>\n<li>\"base\" is just a newer version of GCC to replace the system GCC 4.8.5 which is far too old to build many recent projects.</li>\n<li>\"binaries\" are generally the binary downloads of Paraview and Visit.</li>\n<li>\"compilers\" are the latest set of compilers built using the base GCC.</li>\n<li>\"utilities\" are the latest set of utility programs that don't rely on MPI and are built using the base GCC.</li>\n<li>\"software\" are the latest set of generally larger programs and dependencies that rely on MPI. Each date corresponds to a single MPI implementation so there is no confusion as to which MPI was used for the applications. These modules are built using a farily recent GCC, Clang, or Intel compiler provided from the \"compilers\" modules, using the highest optimization flags specific to the machine architecture.</li>\n</ul>\n<p>The Spack hierarchy is linked in the following manner where each installation is based on other upstream Spack installations. \"software\" depends on \"utilities\", which both depend on \"compilers\". This hierarchy allows Spack to point to packages it needs which are already built upstream. The \"compilers\" installation exposes only the modules for compilers, while the \"utilities\" modules inherit modules from itself as well as the dependency packages in the \"compilers\" installation except the compiler modules themselves.</p>\n<p>Currently there is no perfect way to advertise deprecation or addition, and evolution of these modules. I have an MOTD you can cat in your login script to see updates. Generally the latest 4 sets of modules will likely be kept and new sets have been showing up around every 3 to 6 months.</p>\n<p>To use these modules you can add the following to your <code>~/.bashrc</code> for example and choose the module set (date) you prefer, and the GCC or Intel compiled software modules:</p>\n<pre><code>#------------------------------------------\n\n#MPT 2.22\n#MODULES=modules-2020-07\n#COMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3.1\n#MODULES=modules-2019-10-08\n#COMPILER=gcc-7.4.0\n#COMPILER=clang-7.0.1\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-23\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-08\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-01-10\n#COMPILER=gcc-7.3.0\n#COMPILER=intel-18.0.4\n\n#Recommended default according to where \"modules\" is currently symlinked\nMODULES=modules\nCOMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\nmodule purge\nmodule unuse ${MODULEPATH}\nmodule use /nopt/nrel/ecom/hpacf/binaries/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/compilers/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/utilities/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}\nmodule load gcc\nmodule load git\nmodule load python\n#etc...\n\n#------------------------------------------\n</code></pre>\n<p>If <code>module avail</code> does not show the modules on Eagle, try removing the LMOD cache with <code>rm -rf ~/.lmod.d/.cache</code></p>\n<p>Also included in this directory is a recommended Spack configurations you can use to build your own packages on the machines supported at NREL. Once you have <code>SPACK_ROOT</code> set you can run <code>/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh</code> which should copy the yaml files into your instance of Spack. Or you can copy the yaml files into your <code>${SPACK_ROOT}/etc</code> directory manually. <code>spack compilers</code> should then show you many available compilers. Source your Spack's <code>setup-env.sh</code> after you do the <code>module unuse ${MODULEPATH}</code> in your <code>.bashrc</code> so that your Spack instance will add its own module path to MODULEPATH. Remove <code>~/.spack/linux</code> if it exists and <code>spack compilers</code> doesn't show you the updated list of compilers. The <code>~/.spack</code> directory takes highest precendence in the Spack configuration.</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1620426207.0
    },
    {
        "data_format": 2,
        "description": "The Spack-operator manages automated builds on a distributed and heterogeneus kubernetes cluster",
        "filenames": [
            "config/samples/package_v1alpha1_spack.yaml",
            "config/rbac/spack_editor_role.yaml",
            "config/manifests/spack_base_image.yaml",
            "config/rbac/spack_viewer_role.yaml"
        ],
        "full_name": "ArangoGutierrez/spack-operator",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-operator\" class=\"anchor\" href=\"#spack-operator\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>spack-operator</h1>\n<p>The Spack-operator manages automated builds on a distributed and heterogeneus kubernetes cluster</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1613727652.0
    },
    {
        "data_format": 2,
        "description": "ECP Tutorial",
        "filenames": [
            "examples/spack/spack.yaml"
        ],
        "full_name": "supercontainers/ecp-tutorial",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-getting-started-with-containers-on-hpc\" class=\"anchor\" href=\"#getting-started-with-containers-on-hpc\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting Started with Containers on HPC</h1>\n<p>View this on <a href=\"https://supercontainers.github.io/ecp-tutorial/\" rel=\"nofollow\">GitHub Pages</a>.</p>\n<h2>\n<a id=\"user-content-ecp-supercontainers-tutorial-session\" class=\"anchor\" href=\"#ecp-supercontainers-tutorial-session\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ECP Supercontainers Tutorial Session</h2>\n<div><a href=\"images/ecp.jpg\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"images/ecp.jpg\" width=\"250\" style=\"max-width:100%;\"></a></div>\n<h2>\n<a id=\"user-content-details\" class=\"anchor\" href=\"#details\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Details</h2>\n<p>Short Tutorial Session</p>\n<p>Venue: ECP Annual Meeting 2021</p>\n<p>Date: Tuesday, April 13, 2019  1:00pm - 2:30pm EDT</p>\n<p>Location: Remote</p>\n<p>Topic Area: Programming Models &amp; Systems Software</p>\n<p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific Software Development, DevOps</p>\n<h2>\n<a id=\"user-content-tutorial-login-details\" class=\"anchor\" href=\"#tutorial-login-details\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tutorial Login details</h2>\n<p>Appropriate login details to our EC2 VM instances and an (optional) training account to the Cori supercomputer will all be provided to you at the start of the tutorial session. Please claim your own instance in the table at the bottom of the <a href=\"https://docs.google.com/document/d/1rmi5tSuk_7Q5YVDS1SD7TcxjoEYFgXK-ofvUV2jmL4Y/edit?usp=sharing\" rel=\"nofollow\">Google Doc</a></p>\n<h3>\n<a id=\"user-content-ec2-login\" class=\"anchor\" href=\"#ec2-login\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>EC2 Login</h3>\n<p>hostname: tutXX.supercontainers.org</p>\n<p>user: tutorial</p>\n<p>password: Will be provided</p>\n<h3>\n<a id=\"user-content-nersc-login\" class=\"anchor\" href=\"#nersc-login\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>NERSC Login</h3>\n<p>hostname: cori.nesrc.gov</p>\n<p>Sign Up; Go to <a href=\"https://iris.nersc.gov/train\" rel=\"nofollow\">this page</a> to sign up for the account.  Use training code <em>dJ2d</em>.  If you already have a NERSC account, you can use that account.</p>\n<h2>\n<a id=\"user-content-abstract\" class=\"anchor\" href=\"#abstract\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Abstract</h2>\n<p>Container computing has revolutionized the way applications are developed and delivered. It offers opportunities that never existed before for significantly improving efficiency of scientific workflows and easily moving these workflows from the laptop to the supercomputer. Tools like Docker, Shifter, Singularity and Charliecloud enable a new paradigm for scientific and technical computing. However, to fully unlock its potential, users and administrators need to understand how to utilize these new approaches. This tutorial will introduce attendees to the basics of creating container images, explain best practices, and cover more advanced topics such as creating images to be run on HPC platforms using various container runtimes. The tutorial will also explain how research scientists can utilize container-based computing to accelerate their research and how these tools can boost the impact of their research by enabling better reproducibility and sharing of their scientific process without compromising security.</p>\n<p>This is an short version of the highly successful tutorial presented at multiple SC conferences and multiple ECP Summit Meetings.</p>\n<h2>\n<a id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h2>\n<p>This is a hands-on tutorial. Participants will need a laptop/workstation with an ssh client to make best use of time during the tutorial.  We will be providing training user accounts to both pre-configured EC2 instances as well as the Cori Supercomputer at NERSC.</p>\n<div><a href=\"images/AWS_logo.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"images/AWS_logo.png\" width=\"250\" style=\"max-width:100%;\"></a></div>\n<p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards. EC2 images and temporary login credentials will be distributed onsite at the tutorial.</p>\n<p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2 to run through the tutorial again. We recommend you use your own EC2 key and change the password.</p>\n<p>US-West-Oregon: ami-09bd35c8089302e0d</p>\n<h3>\n<a id=\"user-content-optional-prerequisites\" class=\"anchor\" href=\"#optional-prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Optional Prerequisites</h3>\n<p>Users can also install Docker and Singularity prior to attending the tutorial session. Here, it may be beneficial to create a docker and sylabs (singularity) account in advance at <a href=\"https://cloud.docker.com/\" rel=\"nofollow\">https://cloud.docker.com/</a> and <a href=\"https://cloud.sylabs.io/\" rel=\"nofollow\">https://cloud.sylabs.io/</a> This accounts will be needed to create images on docker cloud/dockerhub and sylabs cloud.</p>\n<p><a href=\"https://sylabs.io/guides/3.3/user-guide/\" rel=\"nofollow\">Install Singularity on Linux</a></p>\n<p><a href=\"https://www.docker.com/products/docker-desktop\" rel=\"nofollow\">Install Docker for Desktop</a></p>\n<h2>\n<a id=\"user-content-questions\" class=\"anchor\" href=\"#questions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Questions</h2>\n<p>You can ask questions verbally or with this <a href=\"https://docs.google.com/document/d/1rmi5tSuk_7Q5YVDS1SD7TcxjoEYFgXK-ofvUV2jmL4Y/edit?usp=sharing\" rel=\"nofollow\">Google Doc</a>.\nPlease append your question below the others in the document.</p>\n<p>We have also created a Slack Team for any and all related HPC container discussions.  The invitation link is <a href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-schedule\" class=\"anchor\" href=\"#schedule\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Schedule</h2>\n<p>13:00 \u2013 13:15 <a href=\"https://drive.google.com/file/d/1-Zszgfs3PZZUH88XGHy5TrW6jggyh81W/view?usp=sharing\" rel=\"nofollow\">Introduction to Containers in HPC</a> (Younge)</p>\n<p>13:15 \u2013 13:30 <a href=\"/01-hands-on.md\">How to build your first Docker container</a> (Canon)</p>\n<p>13:30 \u2013 13:45 <a href=\"/02-hands-on.md\">How to deploy a container on a supercomputer</a> (Canon)</p>\n<p>13:45 - 14:05 <a href=\"/03-hands-on.md\">How to use Singularity to run on a supercomuter</a> (Younge)</p>\n<p>14:05 - 14:15 <a href=\"https://drive.google.com/file/d/1T1xJzcV1HcCR0sNerGX67zRTX-dt4CdJ/view?usp=sharing\" rel=\"nofollow\">Best Practices and Wrap Up</a> (Canon)</p>\n<p>14:15 - 14:30 Containers and E4S (Shende)</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1618443995.0
    },
    {
        "data_format": 2,
        "description": "A spack stack with radiuss (some) radiuss packages",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "LLNL/radiuss-stack",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-radiuss-stack\" class=\"anchor\" href=\"#radiuss-stack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>RADIUSS Stack</h1>\n<p>The RADIUSS project promotes and supports key High Performance Computing (HPC) open-source software developed at the LLNL. These tools and libraries cover a wide range of features a team would need to develop a modern simulation code targeting HPC plaftorms.</p>\n<p>RADIUSS Stack project aims at creating a spack stack (environment) for RADIUSS projects, and test it with CI.</p>\n<h2>\n<a id=\"user-content-getting-started\" class=\"anchor\" href=\"#getting-started\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>This project is standalone and mainly consist of configuarion files for spack.</p>\n<h3>\n<a id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h3>\n<p>This project introduces a radiuss stack described in <code>spack.yaml</code>.</p>\n<h3>\n<a id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing</h3>\n<p>This project requires no installation. Installing RADIUSS stack simply requires to run spack install in this directory.</p>\n<p>This has only be tested on Livermore Computing quartz. The goal being both to extend the number of machines it can be used on and complete the list of packages in the stack.</p>\n<h2>\n<a id=\"user-content-running-the-tests\" class=\"anchor\" href=\"#running-the-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the tests</h2>\n<p>Testing consists in building the stack on LC Gitlab CI.</p>\n<p>TODO: automate the update of spack.</p>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Please read <a href=\"https://github.com/LLNL/radiuss-ci/CONTRIBUTING.md\">CONTRIBUTING.md</a> for details on our code of conduct, and the process for submitting pull requests to us.</p>\n<h2>\n<a id=\"user-content-versioning\" class=\"anchor\" href=\"#versioning\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Versioning</h2>\n<p>version: 1.0.0</p>\n<p>TODO: Not even sure how to handle versioning here.</p>\n<h2>\n<a id=\"user-content-authors\" class=\"anchor\" href=\"#authors\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>Adrien M Bernede</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>This project is licensed under the MIT License - see the <a href=\"LICENSE\">LICENSE</a> file for details</p>\n<p>All new contributions must be made under the MIT License.</p>\n<p>See <a href=\"https://github.com/LLNL/radiuss-stack/blob/master/LICENSE\">LICENSE</a>,\n<a href=\"https://github.com/LLNL/radiuss-stack/blob/master/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/LLNL/radiuss-stack/blob/master/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (MIT)</p>\n<p>LLNL-CODE-793462</p>\n<h2>\n<a id=\"user-content-acknowledgments\" class=\"anchor\" href=\"#acknowledgments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h2>\n",
        "stargazers_count": 1,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1614661368.0
    },
    {
        "data_format": 2,
        "description": "Define and run your benchmarks",
        "filenames": [
            "tests/test_spack.yaml"
        ],
        "full_name": "BlueBrain/hpcbench",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-lbann-livermore-big-artificial-neural-network-toolkit\" class=\"anchor\" href=\"#lbann-livermore-big-artificial-neural-network-toolkit\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>LBANN: Livermore Big Artificial Neural Network Toolkit</h1>\n<p>The Livermore Big Artificial Neural Network toolkit (LBANN) is an\nopen-source, HPC-centric, deep learning training framework that is\noptimized to compose multiple levels of parallelism.</p>\n<p>LBANN provides model-parallel acceleration through domain\ndecomposition to optimize for strong scaling of network training.  It\nalso allows for composition of model-parallelism with both data\nparallelism and ensemble training methods for training large neural\nnetworks with massive amounts of data.  LBANN is able to advantage of\ntightly-coupled accelerators, low-latency high-bandwidth networking,\nand high-bandwidth parallel file systems.</p>\n<p>LBANN supports state-of-the-art training algorithms such as\nunsupervised, self-supervised, and adversarial (GAN) training methods\nin addition to traditional supervised learning.  It also supports\nrecurrent neural networks via back propagation through time (BPTT)\ntraining, transfer learning, and multi-model and ensemble training\nmethods.</p>\n<h2>\n<a id=\"user-content-building-lbann\" class=\"anchor\" href=\"#building-lbann\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building LBANN</h2>\n<p>The preferred method for LBANN users to install LBANN is to use\n<a href=\"https://github.com/llnl/spack\">Spack</a>. After some system\nconfiguration, this should be as straightforward as</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack install lbann</pre></div>\n<p>More detailed instructions for building and installing LBANN are\navailable at the <a href=\"https://lbann.readthedocs.io/en/latest/index.html\" rel=\"nofollow\">main LBANN\ndocumentation</a>.</p>\n<h2>\n<a id=\"user-content-running-lbann\" class=\"anchor\" href=\"#running-lbann\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running LBANN</h2>\n<p>The basic template for running LBANN is</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">&lt;</span>mpi-launcher<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">&lt;</span>mpi-options<span class=\"pl-k\">&gt;</span> \\\n    lbann <span class=\"pl-k\">&lt;</span>lbann-options<span class=\"pl-k\">&gt;</span> \\\n    --model=model.prototext \\\n    --optimizer=opt.prototext \\\n    --reader=data_reader.prototext</pre></div>\n<p>When using GPGPU accelerators, users should be aware that LBANN is\noptimized for the case in which one assigns one GPU per MPI\n<em>rank</em>. This should be borne in mind when choosing the parameters for\nthe MPI launcher.</p>\n<p>More details about running LBANN are documented\n<a href=\"https://lbann.readthedocs.io/en/latest/running_lbann.html\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-publications\" class=\"anchor\" href=\"#publications\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Publications</h2>\n<p>A list of publications, presentations and posters are shown\n<a href=\"https://lbann.readthedocs.io/en/latest/publications.html\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-reporting-issues\" class=\"anchor\" href=\"#reporting-issues\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reporting issues</h2>\n<p>Issues, questions, and bugs can be raised on the <a href=\"https://github.com/llnl/lbann/issues\">Github issue\ntracker</a>.</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 12,
        "topics": [],
        "updated_at": 1581967361.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "inputs/spack/spack.yaml"
        ],
        "full_name": "cinemascienceworkflows/2021-04_Miniapp-Ascent",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-setup-on-scorec\" class=\"anchor\" href=\"#setup-on-scorec\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>setup on SCOREC</h1>\n<pre><code>cd /opt/scorec/spack/rhel7-spack-config/\nsource setupSpack.sh\n</code></pre>\n<h1>\n<a id=\"user-content-rhel7-spack-config\" class=\"anchor\" href=\"#rhel7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>rhel7-spack-config</h1>\n<p>rhel7 spack configuration and scripts</p>\n<p>The <code>install.sh</code> script maintained in this repo is for documentation purposes (e.g., in case we had to reinstall the entire stack from scratch) and should not be executed as it will not use all of our existing package installs.  More discussion of package installation is below.</p>\n<h2>\n<a id=\"user-content-useful-commands\" class=\"anchor\" href=\"#useful-commands\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>useful commands</h2>\n<p>regenerate lmod module tree:</p>\n<pre><code>spack module lmod refresh\n</code></pre>\n<h2>\n<a id=\"user-content-installing-new-packages\" class=\"anchor\" href=\"#installing-new-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>installing new packages</h2>\n<p>Our spack repo is tracking the master spack branch.  Spack package updates could result in additional installation of packages with little or no package source code changes.  These additional installs can be avoided when installing new packages by first examining the output of the <code>spack spec -I</code> command.  If a utility/infrastructure level package, such as cmake or mpich, is marked with a <code>[+]</code> symbol in the leftmost column then it means that the existing install will be used.  If spack does not default to using the existing install you can append the hash of the package to the spec command.</p>\n<p>For example, lets see what happens when we ask for a pumi install using gcc 7.3.0</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0 patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2 arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n</code></pre>\n<p>Spack wants to install mpich 3.3, but we don't want to change to the new mpich version yet.  So, we will get the hash of the existing mpich 3.2.1 install:</p>\n<pre><code>$ spack find -ldv mpich%gcc@7.3.0\n==&gt; 1 installed package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\nniuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n</code></pre>\n<p>then append the hash <code>niuhmad</code> to the spec for pumi using the <code>^</code> syntax to specify it as a dependency:</p>\n<pre><code>$ spack spec -I pumi@develop%gcc@7.3.0 ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n</code></pre>\n<p>And see that in the Concretized spec it is now using the existing mpich 3.2.1 install.</p>\n<h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 5,
        "topics": [],
        "updated_at": 1618439690.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "BetterWang/g4e",
        "latest_release": null,
        "readme": "<p><a href=\"https://gitpod.io/#https://gitlab.com/eic/escalate/g4e\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/daadb4894128d1e19b72d80236f5959f1f2b47f9fe081373f3246131f0189f6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476974706f642d72656164792d2d746f2d2d636f64652d626c75653f6c6f676f3d676974706f64\" alt=\"Gitpod ready-to-code\" data-canonical-src=\"https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod\" style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-geant-4-eic-g4e\" class=\"anchor\" href=\"#geant-4-eic-g4e\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Geant 4 EIC (g4e)</h1>\n<p><a href=\"https://g4e.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/91cb0a1c7d5eb279b680cc13aeb9f2393426ee8897446cf932040a2bbfa9681f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6734652f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/g4e/badge/?version=latest\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://camo.githubusercontent.com/4c75e02b6f97e485ffa93517c1484e2c7e0c0fbef0c62d18713504934d7d6b6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746c61622f706970656c696e652f6a6c61622d6569632f6734652f6d6173746572\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4c75e02b6f97e485ffa93517c1484e2c7e0c0fbef0c62d18713504934d7d6b6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746c61622f706970656c696e652f6a6c61622d6569632f6734652f6d6173746572\" alt=\"Gitlab pipeline status (branch)\" data-canonical-src=\"https://img.shields.io/gitlab/pipeline/jlab-eic/g4e/master\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://g4e.readthedocs.org/\" rel=\"nofollow\">The documentation is at g4e.readthedocs.io</a></p>\n<p><a href=\"docs/_images/JLEICgeant4-v1a.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"docs/_images/JLEICgeant4-v1a.png\" alt=\"JLEIC detector\" style=\"max-width:100%;\"></a></p>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1608812924.0
    },
    {
        "data_format": 2,
        "description": "Provenance based Benchmark suite",
        "filenames": [
            "Utilities/spack-config/var/spack/environments/bench_intel19_mv2_external_apps/spack.yaml",
            "Utilities/spack-config/var/spack/environments/base_intel/spack.yaml",
            "Utilities/spack-config/var/spack/environments/bench_intel_mvapich/spack.yaml",
            "Utilities/spack-config/var/spack/environments/bench_intel19_ompi_external_apps/spack.yaml",
            "Utilities/spack-config/var/spack/environments/base_gcc/spack.yaml",
            "Utilities/spack-config/var/spack/environments/bench_intel_openmpi/spack.yaml",
            "Utilities/spack-config/var/spack/environments/base_gcc_apps/spack.yaml"
        ],
        "full_name": "pace-gt/PACE-ProvBench",
        "latest_release": "v1.0.0",
        "readme": "<h1>\n<a id=\"user-content-pace-provbench\" class=\"anchor\" href=\"#pace-provbench\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>PACE-ProvBench</h1>\n<p>PACE-ProvBench is a Platform independent tool to quickly setup test suite/environment for usability and performance test on any new machines,\nand it provides an easy way to compare the performance across multiple systems. When tests are running, all runtime\ninformation including software, hardware, environment settings are recorded in the database, those data can be compared\nafterwards. This project uses object oriented design to encapsulate the information relating to benchmark testing, and\npresents a clearer high-level representation, which aims to make the benchmark testing easier to extend and maintain,\nmeantime the testing provenance is captured.</p>\n<p>Reach to Fang (Cherry) Liu (<a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a>) if you have any questions.</p>\n<h1>\n<a id=\"user-content-repo-structure\" class=\"anchor\" href=\"#repo-structure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repo Structure</h1>\n<pre><code>&lt;PACE-ProvBench Root Dir&gt; \n  | - Application  (includes all application related data, build scripts, input data, recipe and module files/installation placeholder)\n  | - Utitilies (include all automation bash scripts, either is used in python code, or for building Spack software tool chaim, or used as bootstraping)\n  | - SRC (The main source code for ProvBench, all python codes)\n  | - UnitTest (Test and query interface for users to invoking the tests and query the results)\n  | - Test (Default test output place holder)\n  | - SC20Test (includes all automation test scripts which generates the test result for the paper) \n  | - Images (stores all images used in this documentation)\n  | - Design (includes the design documentation)\n</code></pre>\n<p>Please check the detailed repo structure at <a href=\"repo_directory_struc.md\">repo_directory_struc</a></p>\n<h2>\n<a id=\"user-content-checkout-the-repository\" class=\"anchor\" href=\"#checkout-the-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Checkout the repository</h2>\n<p><code>git clone https://github.com/pace-gt/PACE-ProvBench.git</code></p>\n<p>Due to SPACK has some filesystem requirement, the current test needs to be done on a physical RHEL7 node\nwith local filesystem.</p>\n<h2>\n<a id=\"user-content-few-terminologies\" class=\"anchor\" href=\"#few-terminologies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Few Terminologies</h2>\n<p>Experiment \u2013 each test run, usually one application with multiple runs</p>\n<p>ROLEs \u2013 person who interacts with the framework</p>\n<ul>\n<li>Developer: develops and extends the framework in functionalities and design</li>\n<li>Contributor: builds the test suite and adds new applications</li>\n<li>User: run the tests and analyzes the data collected by the framework</li>\n</ul>\n<p>RECIPE \u2013 defines how the application is run from command line</p>\n<h2>\n<a id=\"user-content-system-requirements\" class=\"anchor\" href=\"#system-requirements\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>System Requirements</h2>\n<ul>\n<li>\n<p>Easy to rebuild the software in a short time span with as little as possible manual steps:</p>\n<p>-- Use LLNL SPACK tool to build the underline compilers and libraries, using SPACK ENV to ensure automation and reproducibility (this is an optional step, Contributor can build software manually as needed)</p>\n<p>-- Provide the template build scripts and module files for Contributor to build the test suite on existing applications</p>\n<p>-- Allow easily to add new applications</p>\n</li>\n<li>\n<p>Information collected are permanently stored</p>\n<p>-- includes all software, hardware, running environment</p>\n<p>-- information can be used to rebuild the tests</p>\n</li>\n<li>\n<p>Framework should be easy to extend</p>\n<p>-- Object-oriented programming style is adopted</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-high-level-objects-design-and-workflow\" class=\"anchor\" href=\"#high-level-objects-design-and-workflow\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>High Level Objects Design and workflow</h2>\n<p>This is for developer only, PACE-ProvBench has 7 main objects all under python package <code>&lt;repo root&gt;/SRC/pace/provbench</code>:</p>\n<ul>\n<li>Application : represents all information and functionalities for one application in test suite</li>\n<li>Runtime : provides the information related to each Experiment run</li>\n<li>System : captures hareware information for each individual host</li>\n<li>Result: processes the performance result, e.g. average/mean/max/min time</li>\n<li>Database: interacts with database, construct the insert/update/select queries</li>\n<li>Command: encapsultes the command line invokation for each application</li>\n<li>Experiment: includes all above objects, serves as the entry point for user interaction</li>\n</ul>\n<p><a href=\"Images/objectflow.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/objectflow.png\" alt=\"PACE-ProvBench Object and Data flow\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-repository-directory-structure\" class=\"anchor\" href=\"#repository-directory-structure\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repository Directory Structure</h2>\n<p>Please check <a href=\"repo_directory_struc.md\">repository directory structure</a> for details.\nIt gives the detailed description on how each directory is for, and naming convention on how to put the new information in.</p>\n<h2>\n<a id=\"user-content-building-the-initial-test-suite\" class=\"anchor\" href=\"#building-the-initial-test-suite\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the initial test suite</h2>\n<p>Please check <a href=\"build_testsuite.md\">Build Initial Test Suite</a> for how to establish the initial benchmark suite with\none application (leslie-spec), this initial test suite should allow user to experience the PACE-ProvBench framework\nin terms of functionalities.</p>\n<h2>\n<a id=\"user-content-run-tests-as-a-user\" class=\"anchor\" href=\"#run-tests-as-a-user\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Run tests as a user</h2>\n<p>Please check <a href=\"run_test.md\">User run test</a> for how to run a test.</p>\n<p><a href=\"Images/runtest.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/runtest.png\" alt=\"Run test as a user\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-adding-new-application-to-pace-provbench\" class=\"anchor\" href=\"#adding-new-application-to-pace-provbench\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding new application to PACE-ProvBench</h2>\n<p>The general steps are as follows, please check <a href=\"add_new_application.md\">add new application</a> session for details.</p>\n<pre><code>* build the application using the pace_build.sh from $PACEPROVBENCH/Application/Source\n* add new module file under $PACEPROVBENCH/Application/Module/&lt;appname&gt;/&lt;version&gt;.lua\n* add new recipe file under $PACEPROVBENCH/Application/Recipe/&lt;appname&gt;.inp\n* follow the step on how to run a test \n</code></pre>\n<p><a href=\"Images/newappflow.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"Images/newappflow.png\" alt=\"Add New Application\" width=\"55%\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-query-the-database\" class=\"anchor\" href=\"#query-the-database\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Query the database</h2>\n<p>User can access PACE-ProvBench database to gather performance data from the runs they had through the query interface.\nPlease see <a href=\"query_database.md\">how to query the database</a> session for more details.</p>\n<h2>\n<a id=\"user-content-summary\" class=\"anchor\" href=\"#summary\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Summary</h2>\n<ul>\n<li>\n<p>Current PACE-ProvBench provides:</p>\n<p>-- A way to build the test suite</p>\n<p>-- A way to integrate new test application</p>\n<p>-- A way to capture the provenance information and store permanently</p>\n<p>-- A way to easy query the provenance information with given criteria</p>\n<p>-- A way to easy extend the framework</p>\n</li>\n<li>\n<p>Future work</p>\n<p>-- More test and validation need to be done</p>\n<p>-- More applications need to be added to test suite</p>\n<p>-- Extend the framework to handle more data analytics to answer HPC data center\u2019 questions</p>\n<p>-- Publish the work in paper and github</p>\n</li>\n</ul>\n<p>Contributed by Fang (Cherry) Liu <a href=\"mailto:fang.liu@gatech.edu\">fang.liu@gatech.edu</a></p>\n",
        "stargazers_count": 1,
        "subscribers_count": 0,
        "topics": [],
        "updated_at": 1614318555.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "inputs/spack/spack.yaml"
        ],
        "full_name": "cinemascienceworkflows/2021-04_Nyx-Ascent",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-eic-spack-repository\" class=\"anchor\" href=\"#eic-spack-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>EIC Spack Repository</h1>\n<p><a href=\"https://github.com/eic/eic-spack/actions?query=workflow%3A%22Build+Environments%22\"><img src=\"https://github.com/eic/eic-spack/workflows/Build%20Environments/badge.svg\" alt=\"Build Environments\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/eic/eic-spack-docker/actions?query=workflow%3A%22Build+Docker+Images%22\"><img src=\"https://github.com/eic/eic-spack-docker/workflows/Build%20Docker%20Images/badge.svg\" alt=\"Build Docker Images\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/eic/eic-spack-cvmfs-tests/actions?query=workflow%3A%22EIC+CI+against+CVMFS+Software+Stack%22\"><img src=\"https://github.com/eic/eic-spack-cvmfs-tests/workflows/EIC%20CI%20against%20CVMFS%20Software%20Stack/badge.svg\" alt=\"EIC CI against CVMFS Software Stack\" style=\"max-width:100%;\"></a></p>\n<p>This repository contains <a href=\"https://spack.readthedocs.io/en/latest/index.html\" rel=\"nofollow\">Spack</a> packages for the EIC.</p>\n<p>While we encourage the inclusion of Spack packages in the upstream repository, we realize that some packages may not be mature enough or have too small of a user base to be accepted there.</p>\n<h2>\n<a id=\"user-content-installing-spack\" class=\"anchor\" href=\"#installing-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing Spack</h2>\n<p>Installing Spack is outside the scope of this repository, but described in the Spack <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"nofollow\">Getting Started</a> page.</p>\n<h2>\n<a id=\"user-content-adding-the-eic-spack-repository\" class=\"anchor\" href=\"#adding-the-eic-spack-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding the EIC Spack Repository</h2>\n<ol>\n<li>Clone this repository:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/eic/eic-spack.git</pre></div>\n<ol start=\"2\">\n<li>Add this repository to your Spack configuration:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack repo add eic-spack</pre></div>\n<h2>\n<a id=\"user-content-installing-eic-spack-packages\" class=\"anchor\" href=\"#installing-eic-spack-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing EIC Spack Packages</h2>\n<ol>\n<li>Find an EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack find eic-smear</pre></div>\n<ol start=\"2\">\n<li>Install an EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack install eic-smear</pre></div>\n<p>If this is the first package you install, it will also install all dependencies.</p>\n<h2>\n<a id=\"user-content-using-eic-spack-packages\" class=\"anchor\" href=\"#using-eic-spack-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using EIC Spack Packages</h2>\n<ol>\n<li>Load the EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack load eic-smear</pre></div>\n<ol start=\"2\">\n<li>Unload the EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack unload eic-smear</pre></div>\n<ol start=\"3\">\n<li>Unload all Spack packages:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack unload -a</pre></div>\n<h2>\n<a id=\"user-content-using-eic-spack-packages-in-environments\" class=\"anchor\" href=\"#using-eic-spack-packages-in-environments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using EIC Spack Packages in Environments</h2>\n<ol>\n<li>Create and activate a new Spack environment:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack env create eic-smear\nspack env activate eic-smear</pre></div>\n<ol start=\"2\">\n<li>Install an EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack install eic-smear</pre></div>\n<p>If you already installed this package earlier, this will go very quick.</p>\n<ol start=\"3\">\n<li>Deactivate the Spack environment:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack env deactivate</pre></div>\n<p>You can verify with <code>which root</code> inside and outside the environment that you did indeed use a different installation base.</p>\n<h2>\n<a id=\"user-content-containerizing-a-spack-environment\" class=\"anchor\" href=\"#containerizing-a-spack-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Containerizing a Spack Environment</h2>\n<p>Once you have a Spack environment setup, you can easily turn it into a Docker container recipe from any directory with an environment spack.yaml file:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-smi\">$SPACK_ROOT</span>/var/spack/environments/eic-smear/\nspack containerize <span class=\"pl-k\">&gt;</span> Dockerfile</pre></div>\n",
        "stargazers_count": 1,
        "subscribers_count": 5,
        "topics": [],
        "updated_at": 1618440344.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "x86_64/spack.yaml",
            "ppc64le/spack.yaml"
        ],
        "full_name": "eugeneswalker/llvm-containers",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-colza-experiments\" class=\"anchor\" href=\"#colza-experiments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Colza Experiments</h1>\n<p>This repository contains scripts to reproduce experiments\nrelated to the Colza elastic in situ analysis framework.\nThese experiments were run on the Cori supercomputer.</p>\n<p>Each subfolder contains a README file explaining what the\nexperiment in the subfolder does, how to install its\ndependencies, and how to run it.</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1615511465.0
    },
    {
        "data_format": 2,
        "description": "Extracting a minimal version of the appimage runtime + any compression algorithm support + statically/dynamically linking against libfuse instead of dlopen",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "haampie/appimage_runtime",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-appimage-runtime-without-all-the-appfolder-business\" class=\"anchor\" href=\"#appimage-runtime-without-all-the-appfolder-business\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>AppImage runtime without all the appfolder business</h1>\n<p>Building the dependencies -- note that you might want to mark libfuse as external (<code>spack external find --not-buildable pkg-config pkgconf libfuse</code>) so that you can use the system setuid fusermount binary.</p>\n<pre><code>$ spack -e . install -v\n</code></pre>\n<p>If you build libfuse with spack, you'll have to do the system install by hand and make fusermount3 a setuid binary:</p>\n<pre><code>sudo chown root:root /path/to/fusermount3\nsudo chmod u+s /path/to/bin/fusermount3\n</code></pre>\n<p>Now build the runtime:</p>\n<pre><code>$ export C_INCLUDE_PATH=.spack-env/view/include\n$ export LIBRARY_PATH=.spack-env/view/lib\n$ make\n</code></pre>\n<p>Size overhead from the runtime is small:</p>\n<p><a href=\"screenshot.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"screenshot.png\" alt=\"screenshot\" style=\"max-width:100%;\"></a></p>\n<p>Now create an AppRun executable in a folder and squashfs it:</p>\n<pre><code>$ mkdir -p example\n$ echo $'#!/usr/bin/bash'$'\\n'$'echo \"hello world\"' &gt; example/AppRun\n$ chmod +x example/AppRun\n$ mksquashfs example example.squashfs -comp zstd -quiet\n</code></pre>\n<p>And merge runtime and the squashfs file into an executable:</p>\n<pre><code>$ cat runtime example.squashfs &gt; app\n$ chmod +x app\n$ ./app\nhello world\n</code></pre>\n<p>Notes about licensing:</p>\n<ul>\n<li>zstd is dual BSD and GPLv2 licensed</li>\n<li>squashfuse is BSD licensed</li>\n<li>libfuse is LGPL licensed</li>\n<li>runtime.c is from AppImageKit and libappimage, which is licensed MIT</li>\n</ul>\n<p>I still have to figure out whether or not statically linking to libfuse is a good idea in terms of licensing, as well as the implications of dual licensing of zstd.</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1617255870.0
    },
    {
        "data_format": 2,
        "description": "exawind/nalu-wind deployment using Spack and E4S build cache (demo)",
        "filenames": [
            "uoregon/mpich-container/spack.yaml",
            "summit/spack.yaml",
            "uoregon/spectrum-mpi/spack.yaml",
            "uoregon/mpich-container-ubuntu18.04-x86_64/spack.yaml",
            "uoregon/mpich-container-ubuntu20.04-x86_64/spack.yaml",
            "uoregon/mpich/spack.yaml",
            "uoregon/mpich-cuda-container-ubuntu18.04-x86_64/spack.yaml",
            "uoregon/openmpi/spack.yaml"
        ],
        "full_name": "eugeneswalker/nalu-wind-demo",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-creating-an-appimage-from-a-spack-environment\" class=\"anchor\" href=\"#creating-an-appimage-from-a-spack-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating an AppImage from a spack environment</h1>\n<p>HPC container runtimes often use squashfs as an archive to store an image, which is then mounted on compute nodes and made writeable using overlayfs where the top layer is a ramfs. This trick gives good performance particularly on shared filesystems, since the squashfs file is a single blob on the disk and has good caching behavior.</p>\n<p>However, perfect isolation from the host system is not always possible, in particular when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into the container, and the question is what the point of containers really is if they still depend on the host system.</p>\n<p>Instead of using containers, one can still deploy applications as a single self-contained blob on the filesystem by using the AppImage runtime. The basic idea is to create an executable which unwraps and mounts a squashfs file baked into the binary.</p>\n<p>This repo shows how to do that using spack environments, where we install <a href=\"https://github.com/electronic-structure/SIRIUS/\">SIRIUS</a>, bundle it using <a href=\"https://github.com/haampie/libtree\">libtree</a> and then create a self-unwrapping binary using the <a href=\"https://github.com/AppImage/AppImageKit\">AppImage runtime</a>.</p>\n<h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./build.sh</span></pre></div>\n<h2>\n<a id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running</h2>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">./sirius.app sirius.scf</span>\n<span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\n<span class=\"pl-c1\">SIRIUS version : 6.5.7</span>\n<span class=\"pl-c1\">git hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n<span class=\"pl-c1\">git branch     : release v6.5.7</span>\n<span class=\"pl-c1\">build time     : 2021-03-23 10:46:06</span>\n<span class=\"pl-c1\">start time     : Tue, 23 Mar 2021 12:34:25</span>\n\n<span class=\"pl-c1\">number of MPI ranks           : 1</span>\n<span class=\"pl-c1\">MPI grid                      : 1 1 1</span>\n<span class=\"pl-c1\">maximum number of OMP threads : 16</span>\n\n<span class=\"pl-c1\">...</span>\n\n\n$ <span class=\"pl-s1\">./sirius.app atom</span>\n<span class=\"pl-c1\">SIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7</span>\n\n<span class=\"pl-c1\">Atom (L)APW+lo basis generation.</span>\n\n<span class=\"pl-c1\">Usage: atom [options]</span>\n<span class=\"pl-c1\">Options:</span>\n<span class=\"pl-c1\">  --help     print this help and exit</span>\n<span class=\"pl-c1\">  --symbol=  {string} symbol of a chemical element</span>\n<span class=\"pl-c1\">  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis</span>\n<span class=\"pl-c1\">  --core=    {double} cutoff for core states: energy (in Ha, if &lt;0), radius (in a.u. if &gt;0)</span>\n<span class=\"pl-c1\">  --order=   {int} order of augmentation</span>\n<span class=\"pl-c1\">  --apw_enu= {double} default value for APW linearization energies</span>\n<span class=\"pl-c1\">  --auto_enu allow search of APW linearization energies</span>\n<span class=\"pl-c1\">  --xml      xml output for Exciting code</span>\n<span class=\"pl-c1\">  --rel      use scalar-relativistic solver</span></pre></div>\n<h2>\n<a id=\"user-content-running-on-piz-daint\" class=\"anchor\" href=\"#running-on-piz-daint\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running on piz daint</h2>\n<p>For Piz Daint I've modified the <code>sirius/spack.yaml</code> a bit so that it links against system libmpi.so (<code>^cray-mpich</code> that is):</p>\n<pre><code>daint103 $ ./build.sh\n...\n\ndaint103 $ du -sh sirius.app # binary size (includes compressed squashfs)\n26M\tsirius.app\n\ndaint103 $ ./sirius.app --appimage-extract # runtime allows you to extract\nsquashfs-root/AppRun\nsquashfs-root/usr\nsquashfs-root/usr/bin\nsquashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\nsquashfs-root/usr/lib\nsquashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\nsquashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\nsrun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\ninput file does not exist\n===========================================================================================================\n                            #         Total          %   Parent %        Median           Min           Max\n-----------------------------------------------------------------------------------------------------------\nsirius                      1       2.30 ms     100.00     100.00       2.30 ms       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms      60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize        1     333.28 us      14.52      14.52     333.28 us     333.28 us     333.28 us\n\n===========================================================================================================\n</code></pre>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1614903870.0
    },
    {
        "data_format": 2,
        "description": "Spack environments for OLCF resources.",
        "filenames": [
            "hosts/lyra/envs/base/spack.yaml",
            "hosts/summit/envs/base/spack.yaml",
            "hosts/peak/envs/base/spack.yaml",
            "hosts/andes/envs/base/spack.yaml"
        ],
        "full_name": "mpbelhorn/olcf-spack-environments",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-olcf-spack-environments\" class=\"anchor\" href=\"#olcf-spack-environments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>OLCF Spack Environments</h1>\n<p>This repo contains the infrastructure and environment definitions to deploy\nsite-provided software on OLCF resources via Spack environments.</p>\n<h2>\n<a id=\"user-content-getting-started\" class=\"anchor\" href=\"#getting-started\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>Clone this repo and it's facility-modified spack fork somewhere on an OLCF\nfilesystem:</p>\n<pre><code>git clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git\n</code></pre>\n<p>or</p>\n<pre><code>git clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments\n</code></pre>\n<p>Next, initialize spack and the build environment. This is done by calling</p>\n<pre><code>FACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base . ./init-facility-spack.sh\n</code></pre>\n<p>This will configure the spack build- and run-time environment build and install\nthe facility spack environment <code>FACSPACK_ENV_NAME</code> tracked by this repo for the\ncurrent machine in a private location under <code>FACSPACK_MY_ENVS</code>. Both of these\nvariables are optional. If omitted, each variable will take on their default\nvalues:</p>\n<pre><code>FACSPACK_MY_ENVS=\"/sw/${_THIS_HOST}/spack-envs\"\nFACSPACK_ENV_NAME=\"base\"\n</code></pre>\n<p>such that sourcing this script by itself</p>\n<pre><code>. ./init-facility-spack.sh\n</code></pre>\n<p>will setup the runtime shell environment to manipulate the production spack\nenvironment on the current system.</p>\n<p>This repo will always track at least one spack environment per machine named\n<code>base</code> which is the complete standard software environment used in production\nfor that machine. Furthermore, only the user account with owner permissions on\nthe production environment may be used to manipulate it in the default\n<code>FACSPACK_MY_ENVS</code>.  This is an intentional safety mechanism to prevent multiple\nusers from concurrently modifying the production environment. Users may set an\nalternate <code>FACSPACK_MY_ENVS</code> under which they can run build tests using any\ntracked <code>hosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml</code> file in this repo.</p>\n<p>From these variables, a unique path per each environment name will be\nconstructed:</p>\n<pre><code>FACSPACK_ENV=\"${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}\"\n</code></pre>\n<p>The value of <code>${_THIS_HOST}</code> is determined automatically from the hostname on\nwhich the init script is being run. For each system and environment tracked in\nthis repo that you wish to work on, ensure that the final expanded value of\n<code>FACSPACK_ENV</code> corresponds to an actual existing directory.</p>\n<p>Configuration paths in our <code>spack.yaml</code> environments that are not fixed to\nuniversal values are expressed in terms of relative paths to either the spack\ninstance setup by <code>init-facility-spack</code> or the path to the <code>FACSPACK_MY_ENVS</code>.\nThese paths are referenced in the <code>spack.yaml</code> files via environment variables\nset by <code>init-facility-spack</code>. This allows the <code>spack.yaml</code> environment files to\ndefine portable and relocatable spack environments which can be re-deployed in\narbitrary private locations by any users without needing to modify the\nenvironment file.</p>\n<p>The following variables are exported in Spack's runtime environment by\n<code>init-facility-spack</code> and can be referred to in the <code>spack.yaml</code> the enviornment\nfiles tracked in this repo.</p>\n<ul>\n<li>\n<code>${FACSPACK_ENV}</code>:\nPath to where spack environment will be installed. Contains subdirs <code>opt</code>\nand <code>modules</code>.</li>\n<li>\n<code>${FACSPACK_ENV_MODULEROOT}</code>:\nShortcut to <code>${FACSPACK_ENV}/modules</code> under which static and\nspack-generated modules are generated. Contains subdirectories <code>spack</code>,\n<code>flat</code>, and <code>site</code> corresponding to lmod, tcl, and static modulefiles\nrespectively.</li>\n<li>\n<code>${FACSPACK_CONF_COMMON}</code>:\nPath to facility-wide common configuration files under <code>${this_repo}/share</code>.</li>\n<li>\n<code>${FACSPACK_CONF_HOST}</code>:\nPath to host-specific configuration files under <code>${this_repo}/hosts/${_THIS_HOST}</code>\n</li>\n</ul>\n<p>There are (as of spack v0.15.0) a couple exceptional paths used in <code>spack.yaml</code>\nfiles which cannot de-reference environment variables. These affect</p>\n<ul>\n<li>Mirrors</li>\n<li>Extensions</li>\n</ul>\n<p>Spack does not internally expand environment variables in the configuration of\nthese items so they must be expressed as hard-coded full path strings. The\ndefault values in this repo should point to permanent world-readable paths on\nthe OLCF filesystem populated with OLCF-maintained extensions and mirrors.</p>\n<h2>\n<a id=\"user-content-spack-fork\" class=\"anchor\" href=\"#spack-fork\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack Fork</h2>\n<p>The upstream development branch of spack is not used directly. Instead, the OLCF\nhas implemented some customizations that are tracked in the \"olcf-X.Y.Z\"\nbranches of a <a href=\"https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0\">facility fork of spack</a>\nwhere <code>X.Y.Z</code> refers to the tagged release of upstream spack from which the\nOLCF-modified branch is forked.</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1613705324.0
    },
    {
        "data_format": 2,
        "description": "Collective Knowledge repository with CK package and virtual environment front-end for Spack packages:",
        "filenames": [
            "package/.cm/alias-a-spack-r-yaml",
            "package/.cm/alias-a-spack-perl-yaml-libyaml",
            "package/.cm/alias-a-spack-yaml-cpp"
        ],
        "full_name": "ctuning/ck-spack",
        "latest_release": "20181220",
        "readme": "<h1>\n<a id=\"user-content-collective-knowledge-repository-for-spack-packages\" class=\"anchor\" href=\"#collective-knowledge-repository-for-spack-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Collective Knowledge repository for Spack packages</h1>\n<p><a href=\"https://github.com/ctuning/ck\"><img src=\"https://github.com/ctuning/ck-guide-images/raw/master/ck-compatible.svg\" alt=\"compatibility\" style=\"max-width:100%;\"></a>\n<a href=\"http://creativecommons.org/licenses/by/4.0/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/bca967b18143b8a5b2ffe78bd4a1a30f6bc21de83bd8336f748e96498af38b38/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d43432532304259253230342e302d6c69676874677265792e737667\" alt=\"License: CC BY 4.0\" data-canonical-src=\"https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg\" style=\"max-width:100%;\"></a></p>\n<p>This repository provides functionality to connect spack packages and CK workflows.\nIt's an on-going project so please be patient.</p>\n<p>Resources:</p>\n<ul>\n<li><a href=\"http://cKnowledge.org\" rel=\"nofollow\">CK framework</a></li>\n<li><a href=\"https://github.com/ctuning/ck/wiki/First-Steps\">CK first steps</a></li>\n<li><a href=\"https://github.com/ctuning/ck/wiki/Portable-workflows\">CK portable workflows</a></li>\n<li><a href=\"http://spack.io\" rel=\"nofollow\">Spack</a></li>\n</ul>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h1>\n<ul>\n<li>CK: BSD, 3-clause</li>\n<li>Spack: LGPL v2.1</li>\n</ul>\n<h1>\n<a id=\"user-content-minimal-ck-installation\" class=\"anchor\" href=\"#minimal-ck-installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimal CK installation</h1>\n<p>The minimal installation requires:</p>\n<ul>\n<li>Python 2.7 or 3.3+ (limitation is mainly due to unitests)</li>\n<li>Git command line client.</li>\n</ul>\n<p>You can install CK in your local user space as follows:</p>\n<pre><code>$ git clone http://github.com/ctuning/ck\n$ export PATH=$PWD/ck/bin:$PATH\n$ export PYTHONPATH=$PWD/ck:$PYTHONPATH\n</code></pre>\n<p>You can also install CK via PIP with sudo to avoid setting up environment variables yourself:</p>\n<pre><code>$ sudo pip install ck\n</code></pre>\n<h1>\n<a id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h1>\n<p>Install this repository and dependencies:</p>\n<pre><code>$ ck pull repo:ck-spack\n</code></pre>\n<p>List available packages imported from spack:</p>\n<pre><code>$ ck ls package:spack-*\n</code></pre>\n<p>Install any package such as abinit:</p>\n<pre><code>$ ck install package:spack-abinit\n or\n$ ck install package:spack-abinit --env.PACKAGE_VERSION=\"8.8.2\" --env.SPACK_EXTRA_CMD=\"\"\n</code></pre>\n<p>See CK virtual environment for all installed CK packages:</p>\n<pre><code>$ ck show env\n</code></pre>\n<p>Run virtual CK environment:</p>\n<pre><code>$ ck virtual env --tags=spack,native\n</code></pre>\n<h1>\n<a id=\"user-content-feedback-and-suggestions\" class=\"anchor\" href=\"#feedback-and-suggestions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Feedback and suggestions</h1>\n<ul>\n<li>Contact <a href=\"https://github.com/ctuning/ck/wiki/Contacts\">CK community</a>\n</li>\n<li>Contact <a href=\"https://groups.google.com/forum/#!forum/spack\" rel=\"nofollow\">Spack community</a>\n</li>\n</ul>\n",
        "stargazers_count": 1,
        "subscribers_count": 3,
        "topics": [],
        "updated_at": 1539728824.0
    },
    {
        "data_format": 2,
        "description": "Testing a build and deploy setup for Spack containers via GitHub Actions and registry",
        "filenames": [
            "minimize-container/spack.yaml"
        ],
        "full_name": "autamus/spacktainer-registry",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-github-container-registry\" class=\"anchor\" href=\"#spack-github-container-registry\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack GitHub Container Registry</h1>\n<p>This repository is a testing bed to develop a spack container (using a Dockerfile\ngenerated with <code>spack containerize</code> against a spack.yaml) that can be triggered\nto update with a <a href=\"https://github.com/autamus/binoc\">binoc</a> GitHub action\nand then build and test the container, and if it works, push to a GitHub container\nregistry. We want to do the following:</p>\n<ul>\n<li><a href=\"#minimize-container-size\">1. Minimize the size of the container</a></li>\n<li><a href=\"#binoc-github-action\">2. Binoc GitHub Action</a></li>\n<li>\n<a href=\"#tests\">3. Figure out how tests are added, and results are captured</a>\n<ul>\n<li>What percentage of spack packages have tests?</li>\n<li>Can we capture and get unique identifiers for output?</li>\n</ul>\n</li>\n<li><a href=\"#\">4. Add GitHub action to build, test, and capture results</a></li>\n<li><a href=\"#\">5. Create static repository to hold results</a></li>\n<li><a href=\"#\">6. Push container to GitHub registry (and test limits)</a></li>\n</ul>\n<h2>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h2>\n<p>We have an idea that we would want to be able to:</p>\n<ol>\n<li>configure a repository to regularly check for updates for some set of spack packages</li>\n<li>given an update, open a pull request to build and test a container</li>\n</ol>\n<p>And if the container build and tests are successful, we would want to push\nthe container to a registry. This requires the stages that are described here,\nbroadly:</p>\n<h2>\n<a id=\"user-content-stages\" class=\"anchor\" href=\"#stages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Stages</h2>\n<h3>\n<a id=\"user-content-minimize-container-size\" class=\"anchor\" href=\"#minimize-container-size\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimize Container Size</h3>\n<p>The original goal of this small test was to see if we can use a multi-stage\nbuild to build binaries and then remove spack. This was the first time I tried this,\nand to my surprise, spack already does this! See the <a href=\"minimize-container\">minimize-container</a>\nfolder for an overview.</p>\n<h3>\n<a id=\"user-content-binoc-github-action\" class=\"anchor\" href=\"#binoc-github-action\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Binoc GitHub Action</h3>\n<p>We added a small folder of packages, with a root under <a href=\"spack\">spack</a>,\nthe idea being that we might have other package managers here in a different namespace.\nThat looks like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ tree spack/\nspack/\n\u251c\u2500\u2500 p\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 py-black\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 py-pylint\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 package.py\n\u2514\u2500\u2500 s\n    \u251c\u2500\u2500 singularity\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 package.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 singularity_v3.4.0_remove_root_check.patch\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spack_perms_fix.sh.j2\n    \u2514\u2500\u2500 sublime-text\n        \u2514\u2500\u2500 package.py</pre></div>\n<p>We then added a GitHub workflow file to run binoc at  <a href=\".github/workflows/binoc.yml\">.github/workflows/binoc.yml</a>.\nTo test it, we start with a pull request (and it will be run on a scheduled basis after that.\nWhen an update is present, the binoc robot should open a pull request. For early\ntesting, I'm not using an actual GitHub user, and am providing information for the GitHub\nactions bot. I suspect if we want this PR to trigger testing, we will need an actual\nuser credential.</p>\n<h3>\n<a id=\"user-content-tests\" class=\"anchor\" href=\"#tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tests</h3>\n<p>I'm actually not sure how spack represents tests. I know you can do an install with\nthem, e.g.,</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ spack install <span class=\"pl-k\">&lt;</span>package<span class=\"pl-k\">&gt;</span> --run-tests</pre></div>\n<p>But I'd like to know where/how that works, what kind of tests are run, how\noutput is stored (if at all) and how tests are namespaced. We would want to\nunderstand this so that we can couple the container build with testing, to:</p>\n<ol>\n<li>be sure that tests still work!</li>\n<li>upload results to some testing repository (possibly using go-github) for future comparison.</li>\n</ol>\n<h3>\n<a id=\"user-content-resources\" class=\"anchor\" href=\"#resources\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Resources</h3>\n<p>The following resources (things mentioned above) might be useful:</p>\n<ul>\n<li><a href=\"https://github.com/arken/ait/blob/master/apis/github/files.go\">https://github.com/arken/ait/blob/master/apis/github/files.go</a></li>\n<li><a href=\"https://github.com/google/go-github\">https://github.com/google/go-github</a></li>\n<li>\n<a href=\"https://github.com/autamus/docs\">https://github.com/autamus/docs</a> as a place to write docs</li>\n</ul>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1617831663.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "tools/environments/ci/spack.yaml"
        ],
        "full_name": "haampie-spack/ci-example",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-github-container-registry\" class=\"anchor\" href=\"#spack-github-container-registry\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack GitHub Container Registry</h1>\n<p>This repository is a testing bed to develop a spack container (using a Dockerfile\ngenerated with <code>spack containerize</code> against a spack.yaml) that can be triggered\nto update with a <a href=\"https://github.com/autamus/binoc\">binoc</a> GitHub action\nand then build and test the container, and if it works, push to a GitHub container\nregistry. We want to do the following:</p>\n<ul>\n<li><a href=\"#minimize-container-size\">1. Minimize the size of the container</a></li>\n<li><a href=\"#binoc-github-action\">2. Binoc GitHub Action</a></li>\n<li>\n<a href=\"#tests\">3. Figure out how tests are added, and results are captured</a>\n<ul>\n<li>What percentage of spack packages have tests?</li>\n<li>Can we capture and get unique identifiers for output?</li>\n</ul>\n</li>\n<li><a href=\"#\">4. Add GitHub action to build, test, and capture results</a></li>\n<li><a href=\"#\">5. Create static repository to hold results</a></li>\n<li><a href=\"#\">6. Push container to GitHub registry (and test limits)</a></li>\n</ul>\n<h2>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h2>\n<p>We have an idea that we would want to be able to:</p>\n<ol>\n<li>configure a repository to regularly check for updates for some set of spack packages</li>\n<li>given an update, open a pull request to build and test a container</li>\n</ol>\n<p>And if the container build and tests are successful, we would want to push\nthe container to a registry. This requires the stages that are described here,\nbroadly:</p>\n<h2>\n<a id=\"user-content-stages\" class=\"anchor\" href=\"#stages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Stages</h2>\n<h3>\n<a id=\"user-content-minimize-container-size\" class=\"anchor\" href=\"#minimize-container-size\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimize Container Size</h3>\n<p>The original goal of this small test was to see if we can use a multi-stage\nbuild to build binaries and then remove spack. This was the first time I tried this,\nand to my surprise, spack already does this! See the <a href=\"minimize-container\">minimize-container</a>\nfolder for an overview.</p>\n<h3>\n<a id=\"user-content-binoc-github-action\" class=\"anchor\" href=\"#binoc-github-action\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Binoc GitHub Action</h3>\n<p>We added a small folder of packages, with a root under <a href=\"spack\">spack</a>,\nthe idea being that we might have other package managers here in a different namespace.\nThat looks like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ tree spack/\nspack/\n\u251c\u2500\u2500 p\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 py-black\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 py-pylint\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 package.py\n\u2514\u2500\u2500 s\n    \u251c\u2500\u2500 singularity\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 package.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 singularity_v3.4.0_remove_root_check.patch\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spack_perms_fix.sh.j2\n    \u2514\u2500\u2500 sublime-text\n        \u2514\u2500\u2500 package.py</pre></div>\n<p>We then added a GitHub workflow file to run binoc at  <a href=\".github/workflows/binoc.yml\">.github/workflows/binoc.yml</a>.\nTo test it, we start with a pull request (and it will be run on a scheduled basis after that.\nWhen an update is present, the binoc robot should open a pull request. For early\ntesting, I'm not using an actual GitHub user, and am providing information for the GitHub\nactions bot. I suspect if we want this PR to trigger testing, we will need an actual\nuser credential.</p>\n<h3>\n<a id=\"user-content-tests\" class=\"anchor\" href=\"#tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tests</h3>\n<p>I'm actually not sure how spack represents tests. I know you can do an install with\nthem, e.g.,</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ spack install <span class=\"pl-k\">&lt;</span>package<span class=\"pl-k\">&gt;</span> --run-tests</pre></div>\n<p>But I'd like to know where/how that works, what kind of tests are run, how\noutput is stored (if at all) and how tests are namespaced. We would want to\nunderstand this so that we can couple the container build with testing, to:</p>\n<ol>\n<li>be sure that tests still work!</li>\n<li>upload results to some testing repository (possibly using go-github) for future comparison.</li>\n</ol>\n<h3>\n<a id=\"user-content-resources\" class=\"anchor\" href=\"#resources\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Resources</h3>\n<p>The following resources (things mentioned above) might be useful:</p>\n<ul>\n<li><a href=\"https://github.com/arken/ait/blob/master/apis/github/files.go\">https://github.com/arken/ait/blob/master/apis/github/files.go</a></li>\n<li><a href=\"https://github.com/google/go-github\">https://github.com/google/go-github</a></li>\n<li>\n<a href=\"https://github.com/autamus/docs\">https://github.com/autamus/docs</a> as a place to write docs</li>\n</ul>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1616683389.0
    },
    {
        "data_format": 2,
        "description": "Slides for the \"Software Management Course\" at CSCS (May, 14th 2019)",
        "filenames": [
            "docker/spack.yaml"
        ],
        "full_name": "spack/spack-cscs2019",
        "latest_release": null,
        "readme": "<p>\"Software Development and Deployment with Spack\"</p>\n<p>Slides for the \"Software Management Course\" at CSCS (May 14th, 2019) in Lugano, based on the awesome <a href=\"https://github.com/hakimel/reveal.js\">reveal.js</a></p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>MIT licensed</p>\n<p>Copyright (C) 2019 Hakim El Hattab, Massimiliano Culpo</p>\n",
        "stargazers_count": 1,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1611191034.0
    },
    {
        "data_format": 2,
        "description": "Spec files for research software library installed at Iowa State University via Spack",
        "filenames": [
            "2-mpis/spack.yaml",
            "3-packages/spack.yaml",
            "1-compilers/spack.yaml"
        ],
        "full_name": "ResearchIT/isu-spack",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-exawind-code-builder\" class=\"anchor\" href=\"#exawind-code-builder\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ExaWind Code Builder</h1>\n<p><a href=\"https://exawind.github.io/exawind-builder\" rel=\"nofollow\">Documentation</a></p>\n<p>ExaWind Builder is a collection of bash scripts to configure and compile the\ncodes used within the <a href=\"https://github.com/exawind\">ExaWind</a> project on various\nhigh-performance computing (HPC) systems. The builder provides the following</p>\n<ul>\n<li>\n<p><strong>Platform configuration</strong>: Provides the minimal set of modules that must be\nloaded when compiling with different compilers and MPI libraries on different\nHPC systems.</p>\n</li>\n<li>\n<p><strong>Software configuration</strong>: Provides baseline CMake configuration that can be\nused to configure the various options when building a <em>project</em>, e.g.,\nenable/disable optional modules, automate specification of paths to various\nlibraries, configure release vs. debug builds.</p>\n</li>\n<li>\n<p><strong>Build script generation</strong>: Generates an executable end-user script for a\ncombination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>\n</li>\n<li>\n<p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific\nscript that allows the user to recreate the exact environment used to build\nthe codes during runtime.</p>\n</li>\n</ul>\n<p>The build scripts are intended for developers who might want to compile the\ncodes with different configuration options, build different branches during\ntheir development cycle, or link to a different development version of a library\nthat is currently not available in the standard installation on the system. Please see the\n<a href=\"https://exawind.github.io/exawind-builder\" rel=\"nofollow\">documentation</a> for\ndetails on how to use this to build ExaWind software.</p>\n<h2>\n<a id=\"user-content-installation-and-usage\" class=\"anchor\" href=\"#installation-and-usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation and usage</h2>\n<h3>\n<a id=\"user-content-using-exawind-builder-with-pre-installed-exawind-environment\" class=\"anchor\" href=\"#using-exawind-builder-with-pre-installed-exawind-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using exawind-builder with pre-installed ExaWind environment</h3>\n<p>ExaWind Builder is already installed and setup on OLCF Summit, NREL\nEagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly\nto using build scripts from the central installation. Please consult <a href=\"https://exawind.github.io/exawind-builder/basic.html#basic-usage\" rel=\"nofollow\">user\nmanual</a> to\nlearn how to use the scripts.</p>\n<h3>\n<a id=\"user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions\" class=\"anchor\" href=\"#bootstrapping-exawind-builder-with-pre-configured-system-definitions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bootstrapping exawind-builder with pre-configured system definitions</h3>\n<p>ExaWind builder has <a href=\"https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems\" rel=\"nofollow\">pre-built\nconfigurations</a>\nfor several systems. On these systems you can use the <code>bootstrap</code> script to\nquickly get up and running. Please consult <a href=\"https://exawind.github.io/exawind-builder/installation.html\" rel=\"nofollow\">installation\nmanual</a>. The\nrelevant steps are shown below.</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Download bootstrap script</span>\ncurl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Make it executable</span>\nchmod a+x bootstrap.sh\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Execute bootstrap and provide system/compiler combination</span>\n./bootstrap.sh -s [SYSTEM] -c [COMPILER]\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Examples</span>\n./bootstrap.sh -s spack -c clang       <span class=\"pl-c\"><span class=\"pl-c\">#</span> On MacOS with homebrew</span>\n./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system\n./bootstrap.sh -s eagle -c gcc         <span class=\"pl-c\"><span class=\"pl-c\">#</span> NREL Eagle</span>\n./bootstrap.sh -s cori -c intel        <span class=\"pl-c\"><span class=\"pl-c\">#</span> NERSC Cori</span>\n./bootstrap.sh -s snl-ascicgpu -c gcc  <span class=\"pl-c\"><span class=\"pl-c\">#</span> SNL GPU development machine</span></pre></div>\n<h3>\n<a id=\"user-content-creating-new-system-configuration\" class=\"anchor\" href=\"#creating-new-system-configuration\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating new system configuration</h3>\n<p>You can add new system definitions to exawind-builder for use on new systems\nthat are not used by ExaWind team. Please see <a href=\"https://exawind.github.io/exawind-builder/advanced.html\" rel=\"nofollow\">manual\ninstallation</a> and\n<a href=\"https://exawind.github.io/exawind-builder/newsys.html\" rel=\"nofollow\">adding a new system</a>\nsections in the user manual.</p>\n<h2>\n<a id=\"user-content-links\" class=\"anchor\" href=\"#links\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Links</h2>\n<ul>\n<li><a href=\"https://www.exawind.org\" rel=\"nofollow\">ExaWind</a></li>\n<li><a href=\"https://github.com/exawind\">ExaWind GitHub Organization</a></li>\n<li><a href=\"https://a2e.energy.gov/about/hfm\" rel=\"nofollow\">A2e HFM</a></li>\n</ul>\n",
        "stargazers_count": 1,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1589517108.0
    },
    {
        "data_format": 2,
        "description": "Documentations and tutorials for Margo, Thallium, Argobots, Mercury, and other Mochi libraries.",
        "filenames": [
            "code/spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-doc",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-mochi-documentation\" class=\"anchor\" href=\"#mochi-documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Mochi documentation</h1>\n<p>This repository contains a Sphinx-based documentation\nfor the Mochi libraries: Margo, Thallium, Argobots, Mercury,\nABT-IO, and SSG, as well as corresponding code examples.</p>\n<h2>\n<a id=\"user-content-building-the-documentation\" class=\"anchor\" href=\"#building-the-documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the documentation</h2>\n<p>To build and/orcontribute to this documentation, make sure\nthat you have Sphinx installed as well as the ReadTheDoc theme.\nThese can be installed as follows using Python's <code>pip</code>.</p>\n<pre><code>pip install sphinx\npip install sphinx_rtd_theme\n</code></pre>\n<p>Once you have these dependencies installed, clone this\nrepository and cd into it. You can change the documentation\nby editing the files in the source subdirectory (these files\nuse the .rst format). You can build the documentation\nusing the following command.</p>\n<pre><code>cd docs\nmake html\n</code></pre>\n<p>And check the result by opening the <code>build/index.html</code> page\nthat has been created in the docs directory.</p>\n<h2>\n<a id=\"user-content-building-the-code-examples\" class=\"anchor\" href=\"#building-the-code-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building the code examples</h2>\n<p>To build the code, you will need spack and the\n<a href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\">sds-repo</a> setup.</p>\n<pre><code>cd code\nspack env create mochi-doc-env spack.yaml\nspack env activate mochi-doc-env\nspack install\nmkdir build\ncd build\ncmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc\nmake\n</code></pre>\n",
        "stargazers_count": 2,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1621119976.0
    },
    {
        "data_format": 2,
        "description": "Dockerfile and artifacts (minus build cache) to create Spack tutorial container.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "spack/spack-tutorial-container",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-tutorial-container\" class=\"anchor\" href=\"#spack-tutorial-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack Tutorial Container</h1>\n<p>This repository contains a container image you can use to do the\n<a href=\"https://spack.readthedocs.io/en/latest/tutorial.html\" rel=\"nofollow\">Spack Tutorial</a>.\nIt's exactly like the AWS images we use when we give the tutorial at\nconferences.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-MIT\">LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-APACHE\">LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack-tutorial-container/blob/master/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack-tutorial-container/blob/master/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n",
        "stargazers_count": 2,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1620084410.0
    },
    {
        "data_format": 2,
        "description": "CPP port of mobility analysis project",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "nickrobison-usds/mobility-cpp",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-make-mobility-fast\" class=\"anchor\" href=\"#make-mobility-fast\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Make Mobility Fast</h1>\n<p>Try to fix some issues with our python analysis and make it more performant.</p>\n<h2>\n<a id=\"user-content-setup\" class=\"anchor\" href=\"#setup\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Setup</h2>\n<p>git submodule update --init --recursive\nvcpkg install geos tbb arrow range-v3 gdal</p>\n<h3>\n<a id=\"user-content-cluster\" class=\"anchor\" href=\"#cluster\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Cluster</h3>\n<h4>\n<a id=\"user-content-cades\" class=\"anchor\" href=\"#cades\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CADES</h4>\n<div class=\"highlight highlight-source-shell\"><pre>module load PE-gnu/4.0\nspack env activate <span class=\"pl-c1\">.</span>\nspack install\ncmake -B build/</pre></div>\n<h4>\n<a id=\"user-content-cori\" class=\"anchor\" href=\"#cori\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CORI</h4>\n<div class=\"highlight highlight-source-shell\"><pre>module swap PrgEnv-intel PrgEnv-cray\nspack env activate <span class=\"pl-c1\">.</span>\nspack install\ncmake -DCMAKE_TOOLCHAIN_FILE=cmake/toolchains/Cori.cmake -B build/</pre></div>\n<h4>\n<a id=\"user-content-theta\" class=\"anchor\" href=\"#theta\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Theta</h4>\n<blockquote>\n<p>Note: We don't currently support building with static linking (which is the default on Theta).</p>\n</blockquote>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> CRAYPE_LINK_TYPE=dynamic\nmodule swap craype-mic-knl craype-haswell\nmodule swap PrgEnv-intel PrgEnv-gnu\nspack env activate <span class=\"pl-c1\">.</span>\nspack install\nmodule load cmake cray-jemalloc\ncmake -DCMAKE_TOOLCHAIN_FILE=cmake/toolchains/Theta.cmake -B build/ </pre></div>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-k\">~</span>/mobility-cpp\n<span class=\"pl-c1\">.</span> /gpfs/mira-home/nickrobison/spack/share/spack/setup-env.sh\nspack env activate <span class=\"pl-c1\">.</span></pre></div>\n<h3>\n<a id=\"user-content-python\" class=\"anchor\" href=\"#python\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Python</h3>\n<p>This repo contains a couple of helper Jupyter notebooks for testing ideas and building datasets.</p>\n<p>Setup is based on <code>virtualenv</code>, but Conda could be used just as easily.</p>\n<div class=\"highlight highlight-source-shell\"><pre>pip3 install virtualenv\nvirtualenv venv\n<span class=\"pl-c1\">source</span> venv/bin/activate\npip3 install -r requirements.txt</pre></div>\n<p>Start the notebook: <code>jupyter notebook python/</code></p>\n<p>Some of the notebooks are described here:</p>\n<h4>\n<a id=\"user-content-join-locations\" class=\"anchor\" href=\"#join-locations\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Join locations</h4>\n<p>This notebook builds the <code>Joined_POI.parquet</code> file which is used by some of the analysis applications.\nIt requires the <code>core_poi.csv</code> files from Safegraph and the combined <code>block_groups.shp</code> file, which is built by combining all of the block group files from the Census bureau into a single file.</p>\n<p>The output should be placed in the <code>${DATA_DIR}/reference</code> directory.</p>\n<h4>\n<a id=\"user-content-output-inspection\" class=\"anchor\" href=\"#output-inspection\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Output Inspection</h4>\n<p>This notebook contains some helper cells for inspecting the output of the various analysis tools.</p>\n<h2>\n<a id=\"user-content-reference-datasets\" class=\"anchor\" href=\"#reference-datasets\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reference datasets</h2>\n<p>The application makes use of a couple of reference datasets that need to be built, prior to launch.</p>\n<h3>\n<a id=\"user-content-unified-census-block-file\" class=\"anchor\" href=\"#unified-census-block-file\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Unified Census Block file</h3>\n<h3>\n<a id=\"user-content-joined_poi\" class=\"anchor\" href=\"#joined_poi\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Joined_POI</h3>\n<p>We need to join the Safegraph Core_POI dataset with unified Census Block file generated in the previous step.</p>\n<ol>\n<li>Download the entirety of the POI catalog from the</li>\n<li>Unzip and un-gzip the poi files.</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>find <span class=\"pl-c1\">.</span> -name <span class=\"pl-s\"><span class=\"pl-pds\">'</span>*.zip<span class=\"pl-pds\">'</span></span> -exec sh -c <span class=\"pl-s\"><span class=\"pl-pds\">'</span>unzip -o -d \"${0%.*}\" \"$0\"<span class=\"pl-pds\">'</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>{}<span class=\"pl-pds\">'</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>;<span class=\"pl-pds\">'</span></span>\ngunzip -r <span class=\"pl-c1\">.</span></pre></div>\n<ol start=\"3\">\n<li>Join them all together into a single, massive set of Parquet files.</li>\n</ol>\n",
        "stargazers_count": 2,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1605222503.0
    },
    {
        "data_format": 2,
        "description": "Spack tutorial",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "MiddelkoopT/spack-tutorial",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-github-container-registry\" class=\"anchor\" href=\"#spack-github-container-registry\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack GitHub Container Registry</h1>\n<p>This repository is a testing bed to develop a spack container (using a Dockerfile\ngenerated with <code>spack containerize</code> against a spack.yaml) that can be triggered\nto update with a <a href=\"https://github.com/autamus/binoc\">binoc</a> GitHub action\nand then build and test the container, and if it works, push to a GitHub container\nregistry. We want to do the following:</p>\n<ul>\n<li><a href=\"#minimize-container-size\">1. Minimize the size of the container</a></li>\n<li><a href=\"#binoc-github-action\">2. Binoc GitHub Action</a></li>\n<li>\n<a href=\"#tests\">3. Figure out how tests are added, and results are captured</a>\n<ul>\n<li>What percentage of spack packages have tests?</li>\n<li>Can we capture and get unique identifiers for output?</li>\n</ul>\n</li>\n<li><a href=\"#\">4. Add GitHub action to build, test, and capture results</a></li>\n<li><a href=\"#\">5. Create static repository to hold results</a></li>\n<li><a href=\"#\">6. Push container to GitHub registry (and test limits)</a></li>\n</ul>\n<h2>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h2>\n<p>We have an idea that we would want to be able to:</p>\n<ol>\n<li>configure a repository to regularly check for updates for some set of spack packages</li>\n<li>given an update, open a pull request to build and test a container</li>\n</ol>\n<p>And if the container build and tests are successful, we would want to push\nthe container to a registry. This requires the stages that are described here,\nbroadly:</p>\n<h2>\n<a id=\"user-content-stages\" class=\"anchor\" href=\"#stages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Stages</h2>\n<h3>\n<a id=\"user-content-minimize-container-size\" class=\"anchor\" href=\"#minimize-container-size\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Minimize Container Size</h3>\n<p>The original goal of this small test was to see if we can use a multi-stage\nbuild to build binaries and then remove spack. This was the first time I tried this,\nand to my surprise, spack already does this! See the <a href=\"minimize-container\">minimize-container</a>\nfolder for an overview.</p>\n<h3>\n<a id=\"user-content-binoc-github-action\" class=\"anchor\" href=\"#binoc-github-action\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Binoc GitHub Action</h3>\n<p>We added a small folder of packages, with a root under <a href=\"spack\">spack</a>,\nthe idea being that we might have other package managers here in a different namespace.\nThat looks like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ tree spack/\nspack/\n\u251c\u2500\u2500 p\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 py-black\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 package.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 py-pylint\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 package.py\n\u2514\u2500\u2500 s\n    \u251c\u2500\u2500 singularity\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 package.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 singularity_v3.4.0_remove_root_check.patch\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spack_perms_fix.sh.j2\n    \u2514\u2500\u2500 sublime-text\n        \u2514\u2500\u2500 package.py</pre></div>\n<p>We then added a GitHub workflow file to run binoc at  <a href=\".github/workflows/binoc.yml\">.github/workflows/binoc.yml</a>.\nTo test it, we start with a pull request (and it will be run on a scheduled basis after that.\nWhen an update is present, the binoc robot should open a pull request. For early\ntesting, I'm not using an actual GitHub user, and am providing information for the GitHub\nactions bot. I suspect if we want this PR to trigger testing, we will need an actual\nuser credential.</p>\n<h3>\n<a id=\"user-content-tests\" class=\"anchor\" href=\"#tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Tests</h3>\n<p>I'm actually not sure how spack represents tests. I know you can do an install with\nthem, e.g.,</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ spack install <span class=\"pl-k\">&lt;</span>package<span class=\"pl-k\">&gt;</span> --run-tests</pre></div>\n<p>But I'd like to know where/how that works, what kind of tests are run, how\noutput is stored (if at all) and how tests are namespaced. We would want to\nunderstand this so that we can couple the container build with testing, to:</p>\n<ol>\n<li>be sure that tests still work!</li>\n<li>upload results to some testing repository (possibly using go-github) for future comparison.</li>\n</ol>\n<h3>\n<a id=\"user-content-resources\" class=\"anchor\" href=\"#resources\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Resources</h3>\n<p>The following resources (things mentioned above) might be useful:</p>\n<ul>\n<li><a href=\"https://github.com/arken/ait/blob/master/apis/github/files.go\">https://github.com/arken/ait/blob/master/apis/github/files.go</a></li>\n<li><a href=\"https://github.com/google/go-github\">https://github.com/google/go-github</a></li>\n<li>\n<a href=\"https://github.com/autamus/docs\">https://github.com/autamus/docs</a> as a place to write docs</li>\n</ul>\n",
        "stargazers_count": 2,
        "subscribers_count": 1,
        "topics": [],
        "updated_at": 1619574775.0
    },
    {
        "data_format": 2,
        "description": "2021 IN PROGRESS -- Getting Started with Containers on HPC",
        "filenames": [
            "exercises/spack_contenerize/spack.yaml",
            "files/spack_contenerize/spack.yaml"
        ],
        "full_name": "supercontainers/isc-tutorial",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-getting-started-with-containers-on-hpc\" class=\"anchor\" href=\"#getting-started-with-containers-on-hpc\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting Started with Containers on HPC</h1>\n<p>View this on <a href=\"https://supercontainers.github.io/isc-tutorial/\" rel=\"nofollow\">GitHub Pages</a>.</p>\n<h2>\n<a id=\"user-content-ecp-supercontainers-tutorial-session\" class=\"anchor\" href=\"#ecp-supercontainers-tutorial-session\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ECP Supercontainers Tutorial Session</h2>\n<p><a href=\"fig/ecp.jpg\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"fig/ecp.jpg\" width=\"250\" style=\"max-width:100%;\"></a><a href=\"fig/pawsey.jpeg\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"fig/pawsey.jpeg\" width=\"250\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-details\" class=\"anchor\" href=\"#details\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Details</h2>\n<p>Half-day Tutorial Session</p>\n<p>Venue: International Supercomputing Conference (ISC21)</p>\n<p>Date: TBD, 24 or 25 June 2021 2:00pm - 6:00pm (European Central Time)</p>\n<p>Location: Virtual</p>\n<p>Link: <a href=\"https://www.isc-hpc.com/\" rel=\"nofollow\">Getting Started with Containers in HPC @ ISC21</a></p>\n<p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific Software Development, DevOps</p>\n<h2>\n<a id=\"user-content-ec2-login\" class=\"anchor\" href=\"#ec2-login\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>EC2 Login</h2>\n<p>These will be provided the day of the tutorial.</p>\n<h2>\n<a id=\"user-content-abstract\" class=\"anchor\" href=\"#abstract\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Abstract</h2>\n<p>Container computing has revolutionized the way applications are developed and delivered. It offers opportunities that never existed before for significantly improving efficiency of scientific workflows and easily moving these workflows from the laptop to the supercomputer. Tools like Docker, Shifter, Singularity, Charliecloud and Podman enable a new paradigm for scientific and technical computing. However, to fully unlock its potential, users and administrators need to understand how to utilize these new approaches. This tutorial will introduce attendees to the basics of creating container images, explain best practices, and cover more advanced topics such as creating images to be run on HPC platforms using various container runtimes. The tutorial will also explain how research scientists can utilize container-based computing to accelerate their research and how these tools can boost the impact of their research by enabling better reproducibility and sharing of their scientific process without compromising security.</p>\n<p>This is an updated version of the highly successful tutorial presented at SC16-20 and ISC19.</p>\n<h2>\n<a id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h2>\n<p>This is a hands-on tutorial. Participants should bring a laptop and load or pre-install a terminal and/or ssh client in advance to make best use of time during the tutorial.  We will be providing training user accounts to both pre-configured EC2 instances.</p>\n<div><a href=\"fig/AWS_logo.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"fig/AWS_logo.png\" width=\"250\" style=\"max-width:100%;\"></a></div>\n<p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards. EC2 images and temporary login credentials will be distributed onsite at the tutorial.</p>\n<p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2 to run through the tutorial again. We recommend you use your own EC2 key and change the password.</p>\n<p>US-West-Oregon: ami-0fe12765123c6a840</p>\n<h3>\n<a id=\"user-content-optional-prerequisites\" class=\"anchor\" href=\"#optional-prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Optional Prerequisites</h3>\n<p>Users can also install Docker and Singularity prior to attending the tutorial session. Here, it may be beneficial to create a docker and sylabs (singularity) account in advance at <a href=\"https://cloud.docker.com/\" rel=\"nofollow\">https://cloud.docker.com/</a> and <a href=\"https://cloud.sylabs.io/\" rel=\"nofollow\">https://cloud.sylabs.io/</a> This accounts will be needed to create images on docker cloud/dockerhub and sylabs cloud.</p>\n<p><a href=\"https://sylabs.io/guides/3.7/user-guide/\" rel=\"nofollow\">Install Singularity on Linux</a></p>\n<p><a href=\"https://repo.sylabs.io/desktop/\" rel=\"nofollow\">Install Singualrity on Mac</a> (Alpha)</p>\n<p><a href=\"https://www.docker.com/products/docker-desktop\" rel=\"nofollow\">Install Docker for Desktop</a></p>\n<h2>\n<a id=\"user-content-questions\" class=\"anchor\" href=\"#questions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Questions</h2>\n<p>You can ask questions verbally or with this <a href=\"https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing\" rel=\"nofollow\">Google Doc</a>.\nPlease append your question below the others in the document.</p>\n<p>We have also created a Slack Team for this.  The invitation link is <a href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-schedule-tbd\" class=\"anchor\" href=\"#schedule-tbd\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Schedule (TBD)</h2>\n<p>14:00 - 14:15 Introduction to containers in HPC (Shane)<br>\nIncluding defining jargon (containers, images, registries/repos,..)</p>\n<p>14:15 - 14:55 Build and run your first container with Podman (Shane)<br>\nIncluding also minimal pull and run examples, to define these concepts</p>\n<p>14:55 - 15:30 Deploy containers on a supercomputer (Marco)</p>\n<p>15:30 - 16:00 High-performance containers (Marco)</p>\n<p>16:00 - 16:30 BREAK</p>\n<p>16:30 - 17:05 Best practices (Shane)</p>\n<p>17:05 - 17:35 E4S containers initiative (Sameer)</p>\n<p>17:35 - 17:55 Advanced container builds (Eduardo)</p>\n<p>17:55 - 18:00 Wrap-up and final Q&amp;A</p>\n",
        "stargazers_count": 3,
        "subscribers_count": 8,
        "topics": [
            "hpc",
            "containers",
            "singularity-container",
            "singularity",
            "shifter",
            "docker",
            "tutorial",
            "supercomputer"
        ],
        "updated_at": 1621435939.0
    },
    {
        "data_format": 2,
        "description": "A Spack overlay repository of HEP software packaging.",
        "filenames": [
            "environments/key4hep-release/spack.yaml",
            "environments/geant4-data-share/spack.yaml",
            "environments/key4hep-release-broadwell/spack.yaml",
            "environments/key4hep-nightlies-debug/spack.yaml",
            "environments/key4hep-release-user/spack.yaml",
            "environments/key4hep-debug/spack.yaml",
            "environments/key4hep-nightlies/spack.yaml"
        ],
        "full_name": "key4hep/key4hep-spack",
        "latest_release": "2021-02-25a-opt",
        "readme": "<h1>\n<a id=\"user-content-spack-package-repo-for-key4hep-software-packaging\" class=\"anchor\" href=\"#spack-package-repo-for-key4hep-software-packaging\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://github.com/spack/spack\">Spack</a> package repo for Key4HEP software packaging</h1>\n<p>This repository holds a set of Spack recipes for key4hep software. It grew out of <a href=\"https://github.com/HSF/hep-spack\">https://github.com/HSF/hep-spack</a>, and many recipes habe been included in the upstream spack repostiory.</p>\n<p>Consult the <a href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\">spack documentation</a> and the <a href=\"https://cern.ch/key4hep\" rel=\"nofollow\">key4hep documentation website</a> for more details.</p>\n<h3>\n<a id=\"user-content-repository-contents\" class=\"anchor\" href=\"#repository-contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Repository Contents</h3>\n<p>Apart from the recipes for key4hep packages in the folder <code>packages</code>, the repository contains some <code>scripts</code> used for publishing on cvmfs, and <code>config</code> files for spack.</p>\n<h3>\n<a id=\"user-content-central-installations\" class=\"anchor\" href=\"#central-installations\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Central Installations</h3>\n<p>Installations of the software stack can be found under <code>/cvmfs/sw.hsf.org/</code>, see:</p>\n<p><a href=\"https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html\" rel=\"nofollow\">https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html</a></p>\n",
        "stargazers_count": 3,
        "subscribers_count": 8,
        "topics": [],
        "updated_at": 1621523159.0
    },
    {
        "data_format": 2,
        "description": "HPC Container Tutorial at SC20",
        "filenames": [
            "exercises/spack_contenerize/spack.yaml",
            "files/spack_contenerize/spack.yaml"
        ],
        "full_name": "supercontainers/sc20-tutorial",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-using-containers-to-accelerate-hpc\" class=\"anchor\" href=\"#using-containers-to-accelerate-hpc\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Containers to Accelerate HPC</h1>\n<p>View this on <a href=\"https://supercontainers.github.io/sc20-tutorial/\" rel=\"nofollow\">GitHub Pages</a>.</p>\n<h2>\n<a id=\"user-content-ecp-supercontainers-tutorial-session\" class=\"anchor\" href=\"#ecp-supercontainers-tutorial-session\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ECP Supercontainers Tutorial Session</h2>\n<p><a href=\"fig/ecp.jpg\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"fig/ecp.jpg\" width=\"250\" style=\"max-width:100%;\"></a><a href=\"fig/pawsey.jpeg\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"fig/pawsey.jpeg\" width=\"250\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-details\" class=\"anchor\" href=\"#details\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Details</h2>\n<p>Half-day Tutorial Session</p>\n<p>Venue: Supercomputing Conference 2020 (SC20')</p>\n<p>Date: Tuesday, 10 November 2020 2:30pm - 6:30pm (Eastern Standard Time)</p>\n<p>Location: Virtual (Atlanta, GA, USA)</p>\n<p>Link: <a href=\"https://sc20.supercomputing.org/presentation/?id=tut129&amp;sess=sess271\" rel=\"nofollow\">Container Computing for HPC and Scientific Workflows @ SC20</a></p>\n<p>Topic Area: Programming Models &amp; Systems Software</p>\n<p>Keywords: Containerized HPC, System Software and Runtime Systems, Scientific Software Development, DevOps</p>\n<h2>\n<a id=\"user-content-ec2-login\" class=\"anchor\" href=\"#ec2-login\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>EC2 Login</h2>\n<p>These will be provided the day of the tutorial.</p>\n<h2>\n<a id=\"user-content-abstract\" class=\"anchor\" href=\"#abstract\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Abstract</h2>\n<p>Container computing has revolutionized the way applications are developed and delivered. It offers opportunities that never existed before for significantly improving efficiency of scientific workflows and easily moving these workflows from the laptop to the supercomputer. Tools like Docker, Shifter, Singularity and Charliecloud enable a new paradigm for scientific and technical computing. However, to fully unlock its potential, users and administrators need to understand how to utilize these new approaches. This tutorial will introduce attendees to the basics of creating container images, explain best practices, and cover more advanced topics such as creating images to be run on HPC platforms using various container runtimes. The tutorial will also explain how research scientists can utilize container-based computing to accelerate their research and how these tools can boost the impact of their research by enabling better reproducibility and sharing of their scientific process without compromising security.</p>\n<p>This is an updated version of the highly successful tutorial presented at SC16, SC17, SC18 and SC19.</p>\n<h2>\n<a id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h2>\n<p>This is a hands-on tutorial. Participants should bring a laptop and load or pre-install a terminal and/or ssh client in advance to make best use of time during the tutorial.  We will be providing training user accounts to both pre-configured EC2 instances.</p>\n<div><a href=\"fig/AWS_logo.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"fig/AWS_logo.png\" width=\"250\" style=\"max-width:100%;\"></a></div>\n<p>This tutorial is supported by the Amazon AWS Machine Learning Research Awards. EC2 images and temporary login credentials will be distributed onsite at the tutorial.</p>\n<p>After the tutorial, you can boot our tutorial image yourself on Amazon EC2 to run through the tutorial again. We recommend you use your own EC2 key and change the password.</p>\n<p>US-West-Oregon: ami-0fe12765123c6a840</p>\n<h3>\n<a id=\"user-content-optional-prerequisites\" class=\"anchor\" href=\"#optional-prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Optional Prerequisites</h3>\n<p>Users can also install Docker and Singularity prior to attending the tutorial session. Here, it may be beneficial to create a docker and sylabs (singularity) account in advance at <a href=\"https://cloud.docker.com/\" rel=\"nofollow\">https://cloud.docker.com/</a> and <a href=\"https://cloud.sylabs.io/\" rel=\"nofollow\">https://cloud.sylabs.io/</a> This accounts will be needed to create images on docker cloud/dockerhub and sylabs cloud.</p>\n<p><a href=\"https://sylabs.io/guides/3.3/user-guide/\" rel=\"nofollow\">Install Singularity on Linux</a></p>\n<p><a href=\"https://repo.sylabs.io/desktop/\" rel=\"nofollow\">Install Singualrity on Mac</a> (Alpha)</p>\n<p><a href=\"https://www.docker.com/products/docker-desktop\" rel=\"nofollow\">Install Docker for Desktop</a></p>\n<h2>\n<a id=\"user-content-questions\" class=\"anchor\" href=\"#questions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Questions</h2>\n<p>You can ask questions verbally or with this <a href=\"https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing\" rel=\"nofollow\">Google Doc</a>.\nPlease append your question below the others in the document.</p>\n<p>We have also created a Slack Team for this.  The invitation link is <a href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-schedule\" class=\"anchor\" href=\"#schedule\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Schedule</h2>\n<p>14:30 - 14:45 Introduction to containers in HPC (Shane)<br>\nIncluding defining jargon (containers, images, registries/repos,..)</p>\n<p>14:45 - 15:25 Build and run your first Docker container (Shane)<br>\nIncluding also minimal pull and run examples, to define these concepts</p>\n<p>15:25 - 15:40 BREAK</p>\n<p>15:40 - 16:15 Deploy containers on a supercomputer (Marco)</p>\n<p>16:15 - 16:40 High-performance containers (Marco)</p>\n<p>16:40 - 16:55 BREAK</p>\n<p>16:55 - 17:15 Best practices (Shane)</p>\n<p>17:15 - 17:35 E4S containers initiative (Sameer)</p>\n<p>17:35 - 17:55 Advanced container builds (Eduardo)</p>\n<p>17:55 - 18:00 Wrap-up and final Q&amp;A</p>\n\n",
        "stargazers_count": 3,
        "subscribers_count": 5,
        "topics": [],
        "updated_at": 1619529963.0
    },
    {
        "data_format": 2,
        "description": "RADIUSS CI project aims at providing sensible default configurations and tools for GitLab CI.",
        "filenames": [
            "spack-environments/toss_3_x86_64_ib/gcc_4_9_3_conduit/spack.yaml",
            "spack-environments/toss_3_x86_64_ib/gcc_8_1_0/spack.yaml",
            "spack-environments/toss_3_x86_64_ib/intel_17_0_0_conduit/spack.yaml",
            "spack-environments/toss_3_x86_64_ib/clang_4_0_0_conduit/spack.yaml"
        ],
        "full_name": "LLNL/radiuss-ci",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-radiuss-ci\" class=\"anchor\" href=\"#radiuss-ci\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>RADIUSS CI</h1>\n<p>The RADIUSS project promotes and supports key High Performance Computing (HPC) open-source software developed at the LLNL. These tools and libraries cover a wide range of features a team would need to develop a modern simulation code targeting HPC plaftorms.</p>\n<p>RADIUSS CI project aims at providing sensible default configurations and tools for GitLab CI.</p>\n<p>Access the <a href=\"https://radiuss-ci.readthedocs.io/\" rel=\"nofollow\">documentation</a>.</p>\n<h2>\n<a id=\"user-content-getting-started\" class=\"anchor\" href=\"#getting-started\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Getting Started</h2>\n<p>This project may be used as a submodule (for its tools) or remotely (for its configuration files).</p>\n<h3>\n<a id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h3>\n<p>The pipeline generator is a python tools which requires pyyaml@5.1 at least.</p>\n<p>Example of python configuration:</p>\n<pre><code>virtualenv radiuss-ci\n. radiuss-ci/bin/activate\npip install pyyaml\npip freeze | grep pyyaml\n</code></pre>\n<h3>\n<a id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing</h3>\n<p>This project requires no installation.</p>\n<h2>\n<a id=\"user-content-running-the-tests\" class=\"anchor\" href=\"#running-the-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running the tests</h2>\n<p>TODO: Explain how to run python tests once available.</p>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Please read <a href=\"https://github.com/LLNL/radiuss-ci/CONTRIBUTING.md\">CONTRIBUTING.md</a> for details on our code of conduct, and the process for submitting pull requests to us.</p>\n<h2>\n<a id=\"user-content-versioning\" class=\"anchor\" href=\"#versioning\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Versioning</h2>\n<p>version: 1.0.0</p>\n<p>TODO: Not even sure how to handle versioning here.</p>\n<h2>\n<a id=\"user-content-authors\" class=\"anchor\" href=\"#authors\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Authors</h2>\n<p>David A Beckingsale, Adrien M Bernede</p>\n<p>See also the list of <a href=\"https://github.com/LLNL/radiuss-ci/contributors\">contributors</a> who participated in this project.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>This project is licensed under the MIT License - see the <a href=\"LICENSE\">LICENSE</a> file for details</p>\n<p>All new contributions must be made under the MIT License.</p>\n<p>See <a href=\"https://github.com/LLNL/radiuss-ci/blob/master/LICENSE\">LICENSE</a>,\n<a href=\"https://github.com/LLNL/radiuss-ci/blob/master/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/LLNL/radiuss-ci/blob/master/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (MIT)</p>\n<p>LLNL-CODE-793462</p>\n<h2>\n<a id=\"user-content-acknowledgments\" class=\"anchor\" href=\"#acknowledgments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h2>\n",
        "stargazers_count": 3,
        "subscribers_count": 5,
        "topics": [
            "radiuss"
        ],
        "updated_at": 1611300706.0
    },
    {
        "data_format": 2,
        "description": "Spack packages for the Electron Ion Collider",
        "filenames": [
            "environments/eic/spack.yaml"
        ],
        "full_name": "eic/eic-spack",
        "latest_release": "v0.15",
        "readme": "<h1>\n<a id=\"user-content-eic-spack-repository\" class=\"anchor\" href=\"#eic-spack-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>EIC Spack Repository</h1>\n<p><a href=\"https://github.com/eic/eic-spack/actions?query=workflow%3A%22Build+Environments%22\"><img src=\"https://github.com/eic/eic-spack/workflows/Build%20Environments/badge.svg\" alt=\"Build Environments\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/eic/eic-spack-docker/actions?query=workflow%3A%22Build+Docker+Images%22\"><img src=\"https://github.com/eic/eic-spack-docker/workflows/Build%20Docker%20Images/badge.svg\" alt=\"Build Docker Images\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/eic/eic-spack-cvmfs-tests/actions?query=workflow%3A%22EIC+CI+against+CVMFS+Software+Stack%22\"><img src=\"https://github.com/eic/eic-spack-cvmfs-tests/workflows/EIC%20CI%20against%20CVMFS%20Software%20Stack/badge.svg\" alt=\"EIC CI against CVMFS Software Stack\" style=\"max-width:100%;\"></a></p>\n<p>This repository contains <a href=\"https://spack.readthedocs.io/en/latest/index.html\" rel=\"nofollow\">Spack</a> packages for the EIC.</p>\n<p>While we encourage the inclusion of Spack packages in the upstream repository, we realize that some packages may not be mature enough or have too small of a user base to be accepted there.</p>\n<h2>\n<a id=\"user-content-installing-spack\" class=\"anchor\" href=\"#installing-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing Spack</h2>\n<p>Installing Spack is outside the scope of this repository, but described in the Spack <a href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"nofollow\">Getting Started</a> page.</p>\n<h2>\n<a id=\"user-content-adding-the-eic-spack-repository\" class=\"anchor\" href=\"#adding-the-eic-spack-repository\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding the EIC Spack Repository</h2>\n<ol>\n<li>Clone this repository:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/eic/eic-spack.git</pre></div>\n<ol start=\"2\">\n<li>Add this repository to your Spack configuration:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack repo add eic-spack</pre></div>\n<h2>\n<a id=\"user-content-installing-eic-spack-packages\" class=\"anchor\" href=\"#installing-eic-spack-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing EIC Spack Packages</h2>\n<ol>\n<li>Find an EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack find eic-smear</pre></div>\n<ol start=\"2\">\n<li>Install an EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack install eic-smear</pre></div>\n<p>If this is the first package you install, it will also install all dependencies.</p>\n<h2>\n<a id=\"user-content-using-eic-spack-packages\" class=\"anchor\" href=\"#using-eic-spack-packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using EIC Spack Packages</h2>\n<ol>\n<li>Load the EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack load eic-smear</pre></div>\n<ol start=\"2\">\n<li>Unload the EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack unload eic-smear</pre></div>\n<ol start=\"3\">\n<li>Unload all Spack packages:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack unload -a</pre></div>\n<h2>\n<a id=\"user-content-using-eic-spack-packages-in-environments\" class=\"anchor\" href=\"#using-eic-spack-packages-in-environments\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using EIC Spack Packages in Environments</h2>\n<ol>\n<li>Create and activate a new Spack environment:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack env create eic-smear\nspack env activate eic-smear</pre></div>\n<ol start=\"2\">\n<li>Install an EIC Spack package:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack install eic-smear</pre></div>\n<p>If you already installed this package earlier, this will go very quick.</p>\n<ol start=\"3\">\n<li>Deactivate the Spack environment:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>spack env deactivate</pre></div>\n<p>You can verify with <code>which root</code> inside and outside the environment that you did indeed use a different installation base.</p>\n<h2>\n<a id=\"user-content-containerizing-a-spack-environment\" class=\"anchor\" href=\"#containerizing-a-spack-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Containerizing a Spack Environment</h2>\n<p>Once you have a Spack environment setup, you can easily turn it into a Docker container recipe from any directory with an environment spack.yaml file:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">cd</span> <span class=\"pl-smi\">$SPACK_ROOT</span>/var/spack/environments/eic-smear/\nspack containerize <span class=\"pl-k\">&gt;</span> Dockerfile</pre></div>\n",
        "stargazers_count": 3,
        "subscribers_count": 9,
        "topics": [
            "spack",
            "spack-packages",
            "spack-repo",
            "eic"
        ],
        "updated_at": 1620972930.0
    },
    {
        "data_format": 2,
        "description": "Localized documentation for Spack",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "spack/localized-docs",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-localized-documentation-for-spack\" class=\"anchor\" href=\"#localized-documentation-for-spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Localized Documentation for Spack</h1>\n<p>This repository contains translations of <a href=\"/spack/spack\">Spack</a>'s\ndocumentation.  It implements the workflow described in the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\" rel=\"nofollow\">Sphinx docs</a>.</p>\n<p>The instructions here describe how you can contribute by:</p>\n<ol>\n<li>Adding to an existing translation, and</li>\n<li>Creating a translation in a new language.</li>\n</ol>\n<h2>\n<a id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Prerequisites</h2>\n<ol>\n<li>\n<p>First, init the <code>spack</code> submodule:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">git clone https://github.com/spack/localized-docs</span>\n$ <span class=\"pl-s1\"><span class=\"pl-c1\">cd</span> localized-docs</span>\n$ <span class=\"pl-s1\">git submodule init</span>\n$ <span class=\"pl-s1\">git submodule update</span></pre></div>\n</li>\n<li>\n<p>To use this repository you'll need Sphinx, some plugins for it, and\n<code>gettext</code>.  To install these dependencies, using <code>pip</code> and <code>brew</code>, you\ncan run:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">pip3 install -r requirements.txt</span>\n$ <span class=\"pl-s1\">brew install gettext</span></pre></div>\n<p>Using Spack, you can just take advantage of the <code>spack.yaml</code> file at\nthe root of this repo:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">spack install</span>\n<span class=\"pl-c1\">spack env activate .</span></pre></div>\n<p>This will install the tools you need and put them in your <code>PATH</code>.</p>\n</li>\n</ol>\n<h2>\n<a id=\"user-content-adding-to-an-existing-translation\" class=\"anchor\" href=\"#adding-to-an-existing-translation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Adding to an existing translation</h2>\n<p>Translations in this repository are stored in <code>.po</code> files under\n<code>translations</code>.  There is one translation per languages, and each file is\nnamed according to its\n<a href=\"https://www.gnu.org/software/gettext/manual/html_node/Language-Codes.html#Language-Codes\" rel=\"nofollow\">ISO-639 language code</a>.\nSo, the Japanese translation data for Spack is stored in\n<code>translations/ja.po</code>.</p>\n<p>If you want to add to an existing translation, all you need to do is edit\nthe appropriate <code>.po</code> file and add translated strings to it.  <code>.po</code> files\nare comprised of <code>msgid</code>/<code>msgstr</code> pairs.  The <code>msgid</code> corresponds to an\nEnglish string in the original documentation, and the <code>msgstr</code> is its\ntranslation in the target language.  For example, for Japanese, the\ntranslation of \"Basic Usage\" is stored like this:</p>\n<pre><code>#: ../spack/lib/spack/docs/basic_usage.rst:10\nmsgid \"Basic Usage\"\nmsgstr \"\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9\"\n</code></pre>\n<p>To add a translation:</p>\n<ol>\n<li>Update <code>msgstr</code> elements in the appropriate <code>.po</code> files;</li>\n<li>Run <code>make</code>;</li>\n<li>Commit the results;</li>\n<li>Submit a pull request so that we can merge your changes.</li>\n</ol>\n<p>That's all!  Merged pull requests will automatically trigger a rebuild of\nthe translated docs, and you should see your changes at\n<a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\">spack.readthedocs.io</a>.</p>\n<p>If you want to look at the documentation while you're editing it, running\n<code>make</code> also generates per-language builds of the docs in <code>html/&lt;lang&gt;</code>.\nSo, to see the Japanese documentation, you can run <code>make</code> and open\n<code>html/ja/index.html</code> in a local web browser.</p>\n<h2>\n<a id=\"user-content-creating-a-new-translation\" class=\"anchor\" href=\"#creating-a-new-translation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating a new translation</h2>\n<p>To create a new translation, add the language to the <code>languages</code> list in\nthe <code>Makefile</code>.  For example, if the only language is Japanese (<code>ja</code>) and\nyou want to add German (<code>de</code>), just add <code>de</code>:</p>\n<div class=\"highlight highlight-source-makefile\"><pre><span class=\"pl-smi\">languages</span> = ja de</pre></div>\n<p>Running <code>make</code>, will create files in <code>docs</code>, <code>locale</code>, and\n<code>translations</code>, and <code>html</code>:</p>\n<pre><code>    translations/de.po          # German translation file\n    translations/de.mo          # generated from de.po\n    locale/de/LC_MESSAGES/*.mo  # symlinks to translations/de.mo\n    docs/de/                    # a Sphinx build directory for German docs\n    html/de/                    # HTML built by Sphinx from docs/de\n</code></pre>\n<p>Add everything <em>except</em> <code>html</code>, then commit. <code>html</code> is ignored by default\n(see <code>.gitignore</code>), so you can just run this:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">git add <span class=\"pl-c1\">.</span></span>\n$ <span class=\"pl-s1\">git commit</span></pre></div>\n<p>See instructions above for how to start translating.</p>\n<h2>\n<a id=\"user-content-workflow\" class=\"anchor\" href=\"#workflow\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Workflow</h2>\n<p>This repository implements the\n<a href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\" rel=\"nofollow\">workflow described here</a>.\nMost users will only need to concern themselves with <code>translations/*.po</code>\nfiles, but we provide a short summary here so that you can understand how\neverything works.</p>\n<p>Translation is done as follows:</p>\n<ol>\n<li>\n<p>First, we use (or rather Sphinx uses) the <code>gettext</code> tool to extract\nstrings to be translated from each <code>.rst</code> document in the Spack\ndocumentation. This results in a set of <code>.pot</code> files in\n<code>templates/*.pot</code>.  These contain keys (<code>msgid</code>s) for unique strings,\nas well as their location (file and line number) in the documentation.</p>\n</li>\n<li>\n<p>We merge the <code>.pot</code> files into a single <code>merged.pot</code> file to eliminate\nduplicate strings in multiple files.</p>\n</li>\n<li>\n<p><code>merged.pot</code> is used to create an initial <code>translations/&lt;lang&gt;.po</code>\nfile.  Translations are added to <code>msgstr</code> fields in the <code>.po</code> file.</p>\n</li>\n<li>\n<p>A single <code>translations/&lt;lang&gt;.mo</code> file is generated from the <code>.po</code>\nfile. The <code>.mo</code> file is in a special binary format.</p>\n</li>\n<li>\n<p>We generate symlinks in <code>locale/&lt;lang&gt;/LC_MESSAGES/*.mo</code> that all\npoint back to the single, unified <code>translations/&lt;lang&gt;.mo</code> file.  The\n<code>locale</code> directory can then be used with Sphinx to build translated\ndocumentation.</p>\n</li>\n</ol>\n<p>The top-level <code>Makefile</code> implements this workflow, so you don't have to\nthink too much about it.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>This repository is part of Spack, which distributed under the terms of\nboth the MIT license and the Apache License (Version 2.0). Users may\nchoose either license, at their option.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/localized-docs/blob/master/LICENSE-MIT\">LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/localized-docs//blob/master/LICENSE-APACHE\">LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/localized-docs/blob/master/COPYRIGHT\">COPYRIGHT</a>,\nand <a href=\"https://github.com/spack/localized-docs/blob/master/NOTICE\">NOTICE</a>\nfor details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-647188</p>\n",
        "stargazers_count": 3,
        "subscribers_count": 6,
        "topics": [],
        "updated_at": 1596332289.0
    },
    {
        "data_format": 2,
        "description": "Scripts to help building Exawind codes on various systems",
        "filenames": [
            "etc/spack/ornl-summit/spack-matrix.yaml",
            "etc/spack/spack/spack.yaml",
            "etc/spack/nrel-eagle/spack.yaml"
        ],
        "full_name": "Exawind/exawind-builder",
        "latest_release": "v0.1.0",
        "readme": "<h1>\n<a id=\"user-content-exawind-code-builder\" class=\"anchor\" href=\"#exawind-code-builder\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ExaWind Code Builder</h1>\n<p><a href=\"https://exawind.github.io/exawind-builder\" rel=\"nofollow\">Documentation</a></p>\n<p>ExaWind Builder is a collection of bash scripts to configure and compile the\ncodes used within the <a href=\"https://github.com/exawind\">ExaWind</a> project on various\nhigh-performance computing (HPC) systems. The builder provides the following</p>\n<ul>\n<li>\n<p><strong>Platform configuration</strong>: Provides the minimal set of modules that must be\nloaded when compiling with different compilers and MPI libraries on different\nHPC systems.</p>\n</li>\n<li>\n<p><strong>Software configuration</strong>: Provides baseline CMake configuration that can be\nused to configure the various options when building a <em>project</em>, e.g.,\nenable/disable optional modules, automate specification of paths to various\nlibraries, configure release vs. debug builds.</p>\n</li>\n<li>\n<p><strong>Build script generation</strong>: Generates an executable end-user script for a\ncombination of <em>system</em>, <em>compiler</em>, and <em>project</em>.</p>\n</li>\n<li>\n<p><strong>Exawind environment generation</strong>: Generates a source-able, platform-specific\nscript that allows the user to recreate the exact environment used to build\nthe codes during runtime.</p>\n</li>\n</ul>\n<p>The build scripts are intended for developers who might want to compile the\ncodes with different configuration options, build different branches during\ntheir development cycle, or link to a different development version of a library\nthat is currently not available in the standard installation on the system. Please see the\n<a href=\"https://exawind.github.io/exawind-builder\" rel=\"nofollow\">documentation</a> for\ndetails on how to use this to build ExaWind software.</p>\n<h2>\n<a id=\"user-content-installation-and-usage\" class=\"anchor\" href=\"#installation-and-usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation and usage</h2>\n<h3>\n<a id=\"user-content-using-exawind-builder-with-pre-installed-exawind-environment\" class=\"anchor\" href=\"#using-exawind-builder-with-pre-installed-exawind-environment\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using exawind-builder with pre-installed ExaWind environment</h3>\n<p>ExaWind Builder is already installed and setup on OLCF Summit, NREL\nEagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly\nto using build scripts from the central installation. Please consult <a href=\"https://exawind.github.io/exawind-builder/basic.html#basic-usage\" rel=\"nofollow\">user\nmanual</a> to\nlearn how to use the scripts.</p>\n<h3>\n<a id=\"user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions\" class=\"anchor\" href=\"#bootstrapping-exawind-builder-with-pre-configured-system-definitions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Bootstrapping exawind-builder with pre-configured system definitions</h3>\n<p>ExaWind builder has <a href=\"https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems\" rel=\"nofollow\">pre-built\nconfigurations</a>\nfor several systems. On these systems you can use the <code>bootstrap</code> script to\nquickly get up and running. Please consult <a href=\"https://exawind.github.io/exawind-builder/installation.html\" rel=\"nofollow\">installation\nmanual</a>. The\nrelevant steps are shown below.</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Download bootstrap script</span>\ncurl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Make it executable</span>\nchmod a+x bootstrap.sh\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Execute bootstrap and provide system/compiler combination</span>\n./bootstrap.sh -s [SYSTEM] -c [COMPILER]\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Examples</span>\n./bootstrap.sh -s spack -c clang       <span class=\"pl-c\"><span class=\"pl-c\">#</span> On MacOS with homebrew</span>\n./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system\n./bootstrap.sh -s eagle -c gcc         <span class=\"pl-c\"><span class=\"pl-c\">#</span> NREL Eagle</span>\n./bootstrap.sh -s cori -c intel        <span class=\"pl-c\"><span class=\"pl-c\">#</span> NERSC Cori</span>\n./bootstrap.sh -s snl-ascicgpu -c gcc  <span class=\"pl-c\"><span class=\"pl-c\">#</span> SNL GPU development machine</span></pre></div>\n<h3>\n<a id=\"user-content-creating-new-system-configuration\" class=\"anchor\" href=\"#creating-new-system-configuration\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Creating new system configuration</h3>\n<p>You can add new system definitions to exawind-builder for use on new systems\nthat are not used by ExaWind team. Please see <a href=\"https://exawind.github.io/exawind-builder/advanced.html\" rel=\"nofollow\">manual\ninstallation</a> and\n<a href=\"https://exawind.github.io/exawind-builder/newsys.html\" rel=\"nofollow\">adding a new system</a>\nsections in the user manual.</p>\n<h2>\n<a id=\"user-content-links\" class=\"anchor\" href=\"#links\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Links</h2>\n<ul>\n<li><a href=\"https://www.exawind.org\" rel=\"nofollow\">ExaWind</a></li>\n<li><a href=\"https://github.com/exawind\">ExaWind GitHub Organization</a></li>\n<li><a href=\"https://a2e.energy.gov/about/hfm\" rel=\"nofollow\">A2e HFM</a></li>\n</ul>\n",
        "stargazers_count": 3,
        "subscribers_count": 4,
        "topics": [
            "cmake",
            "build",
            "exawind",
            "hpc",
            "exawind-builder"
        ],
        "updated_at": 1619496711.0
    },
    {
        "data_format": 2,
        "description": "Object-oriented numerical library",
        "filenames": [
            "docs/source/spack.yaml",
            "tools/docker_and_spack/01_build_docker_container_from_spack/spack.yaml"
        ],
        "full_name": "tachidok/scicellxx",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-scicell\" class=\"anchor\" href=\"#scicell\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SciCell++</h1>\n<p><a href=\"https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/tachidok/scicellxx/workflows/Build-and-Test/badge.svg?branch=master&amp;event=push\" alt=\"GitHub-master-push\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/tachidok/scicellxx\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4d304208a40f5037293d6f8b02ab726b9654e85e8557e43b51ae5a91077fa596/68747470733a2f2f636f6465636f762e696f2f67682f7461636869646f6b2f73636963656c6c78782f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d4a41414f465353314951\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/tachidok/scicellxx/branch/master/graph/badge.svg?token=JAAOFSS1IQ\" style=\"max-width:100%;\"></a>\n<a href=\"https://scicellxx.readthedocs.io\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6ada579e5e58ef38465ec81b91143b7b634c899e63a4a834dc39199f9ded19e6/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73636963656c6c78782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/scicellxx/badge/?version=latest\" style=\"max-width:100%;\"></a></p>\n<hr>\n<h2>\n<a id=\"user-content-welcome\" class=\"anchor\" href=\"#welcome\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Welcome!</h2>\n<p>This is the official GitHub repository for the <strong>SciCell++</strong> project.</p>\n<h2>\n<a id=\"user-content-what-is-scicell\" class=\"anchor\" href=\"#what-is-scicell\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What is SciCell++?</h2>\n<p>SciCell++ is an object-oriented framework for the simulation of biological and physical phenomena modelled as continuous or discrete processes.</p>\n<h2>\n<a id=\"user-content-table-of-contents\" class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Table of Contents</h2>\n<ol>\n<li><a href=\"#installation\">Installation</a></li>\n<li><a href=\"#demos\">Demos</a></li>\n<li><a href=\"#documentation\">Documentation</a></li>\n<li><a href=\"#how_to_contribute\">How to contribute</a></li>\n<li><a href=\"#facts_and_curiosities\">Facts and curiosities</a></li>\n<li><a href=\"#license\">License</a></li>\n</ol>\n<h2>\n<a id=\"user-content-installation-\" class=\"anchor\" href=\"#installation-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation <a name=\"user-content-installation\"></a>\n</h2>\n<h3>\n<a id=\"user-content-docker-based-installation\" class=\"anchor\" href=\"#docker-based-installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Docker-based installation</h3>\n<p>We are adopting containers to ease the installation and release of\nversions so you do not need to worry about any dependencies.</p>\n<p>This section and installation procedure is under development.\n<g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji></p>\n<p>Follow the instructions in\n<a href=\"https://docs.docker.com/engine/install/\" rel=\"nofollow\">here</a> to get Docker\ninstalled in your system.</p>\n<p>Then get the image from our Docker repository and ta-dah, you are\nready to go.</p>\n<h3>\n<a id=\"user-content-fast-installation-and-starting-up\" class=\"anchor\" href=\"#fast-installation-and-starting-up\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Fast installation and starting up!!!</h3>\n<h4>\n<a id=\"user-content-what-you-need-to-have-it-running-and-working-nicely\" class=\"anchor\" href=\"#what-you-need-to-have-it-running-and-working-nicely\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What you need to have it running and working nicely?</h4>\n<ul>\n<li>\n<p>A C++ compiler - demo drivers and library built with version\n7.4.0. It may work with previous versions as well.</p>\n</li>\n<li>\n<p>CMake - to configure and install it. We tested with version 3.10.2.</p>\n</li>\n<li>\n<p>Python - to test output from demo drivers with validation files\n(also to produce nice plots). We tested with version 3.7.3 but it\nshould work with any version &gt;= 3</p>\n</li>\n</ul>\n<h5>\n<a id=\"user-content-optional\" class=\"anchor\" href=\"#optional\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Optional</h5>\n<ul>\n<li>MPI support for parallel features - <code>not currently supported</code>.</li>\n</ul>\n<h4>\n<a id=\"user-content-get-your-own-copy-of-the-project\" class=\"anchor\" href=\"#get-your-own-copy-of-the-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Get your own copy of the project</h4>\n<p>You need <strong>git</strong> installed in your computer, then type in a terminal</p>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/tachidok/scicellxx\n<span class=\"pl-c1\">cd</span> scicellxx\ngit checkout -b john_cool</pre></div>\n<p>After executing the first line you will be prompted with your GitHub\nuser name and your password. The third line generates your fully\ncustomised branch, we assume that your name is <em>john_cool</em></p>\n<h4>\n<a id=\"user-content-configuration\" class=\"anchor\" href=\"#configuration\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configuration</h4>\n<ul>\n<li>In a terminal (shell command line) go into the <code>scicellxx</code> folder\nthen type</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>./autogen.sh</pre></div>\n<ul>\n<li>Follow up the instructions on screen to configure your own copy of\nthe project.</li>\n</ul>\n<h2>\n<a id=\"user-content-demos-\" class=\"anchor\" href=\"#demos-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Demos <a name=\"user-content-demos\"></a>\n</h2>\n<p>Demos live in the <code>demos</code> folder. You should run all of them to make sure everything is working fine. If you did not run them at installation time (by default) you can do it at any time by opening a terminal, going into the build folder (the default one is <code>build</code>) and typing</p>\n<div class=\"highlight highlight-source-shell\"><pre>./ctest</pre></div>\n<p>A large number of demos is expected to live in the <code>demos</code> folder. Review the <a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">corresponding documentation</a> for their full description.</p>\n<h3>\n<a id=\"user-content-featured-demos\" class=\"anchor\" href=\"#featured-demos\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Featured demos</h3>\n<ul>\n<li>Interpolation</li>\n<li>Linear solvers</li>\n<li>Matrices operations</li>\n<li>Newton's method</li>\n<li>Solution of ODE's\n<ul>\n<li>Lotka-Volterra solved with different time steppers</li>\n<li>N-body problem (only 3-body and 4-body)</li>\n<li>Explicit time steppers</li>\n<li>Implicit time steppers (full implicit and <em>E(PC)^k E</em>\nimplementations)</li>\n<li>Adaptive time steppers</li>\n</ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-documentation-\" class=\"anchor\" href=\"#documentation-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation <a name=\"user-content-documentation\"></a>\n</h2>\n<p>The full documentation is <a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-how-to-contribute-\" class=\"anchor\" href=\"#how-to-contribute-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to contribute <a name=\"user-content-how_to_contribute\"></a>\n</h2>\n<p>Please check the <a href=\"https://scicellxx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">corresponding documentation</a> section for contributions.</p>\n<h2>\n<a id=\"user-content-facts-and-curiosities-\" class=\"anchor\" href=\"#facts-and-curiosities-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Facts and curiosities <a name=\"user-content-facts_and_curiosities\"></a>\n</h2>\n<h3>\n<a id=\"user-content-how-many-developers-are-currently-working-on-this-project\" class=\"anchor\" href=\"#how-many-developers-are-currently-working-on-this-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How many developers are currently working on this project?</h3>\n<p>At Wednesday, March/31, 2021 there is one and only one developer, me\n<g-emoji class=\"g-emoji\" alias=\"no_mouth\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f636.png\">\ud83d\ude36</g-emoji> <g-emoji class=\"g-emoji\" alias=\"email\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/2709.png\">\u2709\ufe0f</g-emoji></p>\n<p><g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji> <g-emoji class=\"g-emoji\" alias=\"construction\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f6a7.png\">\ud83d\udea7</g-emoji></p>\n<h3>\n<a id=\"user-content-when-did-this-start\" class=\"anchor\" href=\"#when-did-this-start\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>When did this start?</h3>\n<p>This project was initially uploaded to GitHub on Friday, 11 March 2016\n<g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>\n<h2>\n<a id=\"user-content-license-\" class=\"anchor\" href=\"#license-\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License <a name=\"user-content-license\"></a>\n</h2>\n<p>Licensed under the GNU GPLv3. A copy can be found on the <a href=\"./LICENSE\">LICENSE</a> file.</p>\n",
        "stargazers_count": 4,
        "subscribers_count": 2,
        "topics": [
            "numerical-methods",
            "finite-element-methods",
            "parallel-programming",
            "linear-algebra",
            "equation-solver",
            "smoothed-particle-hydrodynamics",
            "finite-difference-methods",
            "object-oriented-programming"
        ],
        "updated_at": 1617696000.0
    },
    {
        "data_format": 2,
        "description": "E4S for Spack",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "E4S-Project/e4s",
        "latest_release": null,
        "readme": "<h2>\n<a id=\"user-content-e4s-release-2102\" class=\"anchor\" href=\"#e4s-release-2102\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>E4S Release 21.02</h2>\n<p>February 2021 release of E4S (21.02)</p>\n<h3>\n<a id=\"user-content-files\" class=\"anchor\" href=\"#files\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Files</h3>\n<ul>\n<li>\n<code>spack-commit-ref.txt</code> -- Spack commit reference</li>\n<li>\n<code>spack.yaml</code> -- Spack Environment containing <code>packages:</code> and <code>specs:</code>\n<ul>\n<li>\n<code>packages:</code> version preferences for non-root specs</li>\n<li>\n<code>specs:</code> version-pinned root specs comprising this release of E4S</li>\n</ul>\n</li>\n</ul>\n<p><em>Packages in E4S but not available in versioned form are commented out</em></p>\n<h3>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h3>\n<p>E4S 21.02 is based on Spack tag <code>e4s-21.02</code></p>\n<ul>\n<li><a href=\"https://github.com/spack/spack\">https://github.com/spack/spack</a></li>\n<li>Tag <code>e4s-21.02</code> (<code>@develop</code> as of <code>Fri Feb 26 14:57:40 2021 -0800</code>)</li>\n</ul>\n<h3>\n<a id=\"user-content-packages\" class=\"anchor\" href=\"#packages\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Packages</h3>\n<table>\n<thead>\n<tr>\n<th>Package</th>\n<th>Version</th>\n<th>Group</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>adios</td>\n<td>1.13.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>adios2</td>\n<td>2.7.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>aml</td>\n<td>0.1.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>amrex</td>\n<td>21.02</td>\n<td></td>\n</tr>\n<tr>\n<td>arborx</td>\n<td>0.9-beta</td>\n<td>math</td>\n</tr>\n<tr>\n<td>argobots</td>\n<td>1.0</td>\n<td></td>\n</tr>\n<tr>\n<td>ascent</td>\n<td>0.6.0</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>axom</td>\n<td>0.4.0</td>\n<td></td>\n</tr>\n<tr>\n<td>bolt</td>\n<td>2.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>caliper</td>\n<td>2.5.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>darshan-runtime</td>\n<td>3.2.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>darshan-util</td>\n<td>3.2.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>dyninst</td>\n<td>10.2.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>faodel</td>\n<td>1.1906.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>flecsi</td>\n<td>1.4</td>\n<td>math</td>\n</tr>\n<tr>\n<td>flit</td>\n<td>2.1.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>fortrilinos</td>\n<td>2.0.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>gasnet</td>\n<td>2020.3.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>ginkgo</td>\n<td>1.3.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>globalarrays</td>\n<td>5.8</td>\n<td></td>\n</tr>\n<tr>\n<td>gotcha</td>\n<td>1.0.3</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>hdf5</td>\n<td>1.10.7</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>hpctoolkit</td>\n<td>2020.08.3</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>hpx</td>\n<td>1.6.0</td>\n<td></td>\n</tr>\n<tr>\n<td>hypre</td>\n<td>2.20.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>kokkos</td>\n<td>3.2.00</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>kokkos-kernels</td>\n<td>3.2.00</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>legion</td>\n<td>20.03.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>libnrm</td>\n<td>0.1.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>libquo</td>\n<td>1.3.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>magma</td>\n<td>2.5.4</td>\n<td>math</td>\n</tr>\n<tr>\n<td>mercury</td>\n<td>2.0.0</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>mfem</td>\n<td>4.2.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>mpifileutils</td>\n<td>0.10.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>ninja</td>\n<td>1.10.2</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>omega-h</td>\n<td>9.32.5</td>\n<td>math</td>\n</tr>\n<tr>\n<td>openmpi</td>\n<td>4.0.5</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>openpmd-api</td>\n<td>0.13.2</td>\n<td></td>\n</tr>\n<tr>\n<td>papi</td>\n<td>6.0.0.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>papyrus</td>\n<td>1.0.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>parallel-netcdf</td>\n<td>1.12.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>pdt</td>\n<td>3.25.1</td>\n<td></td>\n</tr>\n<tr>\n<td>petsc</td>\n<td>3.14.4</td>\n<td>math</td>\n</tr>\n<tr>\n<td>phist</td>\n<td>1.9.3</td>\n<td>math</td>\n</tr>\n<tr>\n<td>plasma</td>\n<td>20.9.20</td>\n<td>math</td>\n</tr>\n<tr>\n<td>precice</td>\n<td>2.2.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>pumi</td>\n<td>2.2.5</td>\n<td>math</td>\n</tr>\n<tr>\n<td>py-jupyterhub</td>\n<td>1.0.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>py-libensemble</td>\n<td>0.7.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>py-petsc4py</td>\n<td>3.14.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>qthreads</td>\n<td>1.16</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>raja</td>\n<td>0.13.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>rempi</td>\n<td>1.1.0</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>scr</td>\n<td>2.0.0</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>slate</td>\n<td>2020.10.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>slepc</td>\n<td>3.14.2</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>stc</td>\n<td>0.8.3</td>\n<td></td>\n</tr>\n<tr>\n<td>strumpack</td>\n<td>5.1.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>sundials</td>\n<td>5.7.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>superlu</td>\n<td>5.2.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>superlu-dist</td>\n<td>6.4.0</td>\n<td>math</td>\n</tr>\n<tr>\n<td>swig</td>\n<td>4.0.2-f</td>\n<td></td>\n</tr>\n<tr>\n<td>sz</td>\n<td>2.1.11.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>tasmanian</td>\n<td>7.3</td>\n<td>math</td>\n</tr>\n<tr>\n<td>tau</td>\n<td>2.30.1</td>\n<td>dev tools</td>\n</tr>\n<tr>\n<td>trilinos</td>\n<td>13.0.1</td>\n<td>math</td>\n</tr>\n<tr>\n<td>turbine</td>\n<td>1.2.3</td>\n<td></td>\n</tr>\n<tr>\n<td>umap</td>\n<td>2.1.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>umpire</td>\n<td>4.1.2</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>unifyfs</td>\n<td>0.9.1</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>upcxx</td>\n<td>2020.10.0</td>\n<td>pmr core</td>\n</tr>\n<tr>\n<td>veloc</td>\n<td>1.4</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td>zfp</td>\n<td>0.5.5</td>\n<td>data+viz</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>llvm-doe</td>\n<td>doe</td>\n<td>dev tools</td>\n</tr>\n</tbody>\n</table>\n",
        "stargazers_count": 4,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1617360306.0
    },
    {
        "data_format": 2,
        "description": "one-key installation to install gnuplot, sz, zfp, and z-checker, and complete the configuration automatically for the testing.",
        "filenames": [
            "libpressio-opt/spack.yaml"
        ],
        "full_name": "CODARcode/z-checker-installer",
        "latest_release": "0.6.0",
        "readme": "<h1>\n<a id=\"user-content-z-checker-installer\" class=\"anchor\" href=\"#z-checker-installer\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Z-checker installer</h1>\n<p>(C) 2017-2021 by Mathematics and Computer Science (MCS), Argonne National Laboratory.</p>\n<p>See COPYRIGHT in top-level directory.</p>\n<p>Major authors: Sheng Di, Dingwen Tao, Hanqi Guo\nOther contributors: Robert Underwood, Hengzhi Chen</p>\n<h2>\n<a id=\"user-content-3rd-party-librariestools\" class=\"anchor\" href=\"#3rd-party-librariestools\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>3rd party libraries/tools</h2>\n<ul>\n<li>cmake (version: 3.13+)</li>\n<li>gcc (version: 7.3+)</li>\n<li>g++</li>\n<li>git</li>\n<li>texlive (e.g., execute 'sudo yum install texlive-*' on linux)</li>\n<li>ghostscript(gsview) (z-checker-install.sh can install it automatically if missing)</li>\n<li>latexmk (z-checker-install.sh will install latexmk automatically if missing)</li>\n<li>gnuplot (z-checker-install.sh will install gnuplot automatically if missing)</li>\n<li>perl (used by only web-visualization support)</li>\n</ul>\n<p>The following libraries - libpng, tif22pnm and sam2p are used to convert slice image png files to eps. If plotSliceImag option is disabled (in zc.config), these three libraries are not needed.</p>\n<ul>\n<li>libpng (z-checker-install.sh will install tif22pnm automatically if missing; in fact, libpng can be installed using system installation command such as 'yum install libpng-devel' on linux.)</li>\n<li>tif22pnm (z-checker-install.sh will install tif22pnm automatically if missing)</li>\n<li>sam2p (z-checker-install.sh will install sam2p automatically if missing)</li>\n</ul>\n<p>For simplicity,\nthe Fedora users need to run the following command for installation:</p>\n<div class=\"highlight highlight-source-shell\"><pre>sudo dnf install -y gcc gcc-c++ git cmake zlib-devel libzstd-devel gfortran which xorg-x11-server-Xorg gnuplot libpng-devel findutils unzip latexmk texlive\n<span class=\"pl-k\">&lt;</span><span class=\"pl-k\">!</span>-- required texlive package: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${comment.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${pifont.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${natbib.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${amsmath.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${morefloats.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${geometry.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${nopageno.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${subfigure.sty}</span>)<span class=\"pl-pds\">\"</span></span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tex(<span class=\"pl-smi\">${enumitem.sty}</span>)<span class=\"pl-pds\">\"</span></span>--<span class=\"pl-k\">&gt;</span>\ngit clone http://github.com/CODARcode/z-checker-installer\n<span class=\"pl-c1\">cd</span> z-checker-installer\n./z-checker-install.sh</pre></div>\n<p>the Ubuntu users need to run the following command for installation:</p>\n<div class=\"highlight highlight-source-shell\"><pre>sudo sudo apt-get install -y gcc g++ git cmake zlib-devel gfortran gnuplot libpng-devel xorg openbox findutils unzip latexmk texlive-full texlive-fonts-recommends --no-install-recommends\ngit clone http://github.com/CODARcode/z-checker-installer\n<span class=\"pl-c1\">cd</span> z-checker-installer\n./z-checker-install.sh</pre></div>\n<h2>\n<a id=\"user-content-testinginstallation-method\" class=\"anchor\" href=\"#testinginstallation-method\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Testing/Installation method</h2>\n<p>z-checker-install.sh will download latexmk, gnuplot, Z-checker, ZFP, and SZ and install them one by one automatically, and then add the patches to let ZFP and SZ fit for Z-checker.</p>\n<p>After installation, please download the two testing data sets, CESM-ATM and MD-simulation (exaalt). The two data sets are available only for the purpose of research of compression. Please ask for the data by contacting <a href=\"\">sdi1@anl.gov</a> if interested.</p>\n<p>LibpressioOPT is a library that is able to search for the appropriate error bound setting based on user-sepcified metric values such as compression ratio and PSNR. Z-checker itself has some simple built-in algorithms to do this work, which may not be as accurate as LibpressioOPT. To this end, you also need to install spack and use spack to install some preliminary libraries. For more details, please read the z-checker-installer-instruction.pdf in the ./doc/ directory. If you don't need LibpressioOPT, you just need to run './z-checker-installer.sh' to install everything.</p>\n<h3>\n<a id=\"user-content-quick-start\" class=\"anchor\" href=\"#quick-start\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Quick Start</h3>\n<p>Then, you are ready to conduct the compression checking.\nYou can generate compression results with SZ and ZFP using the following simple steps:\n(Note: you have to run z-checker-install.sh to install the software before doing the following tests)</p>\n<ol>\n<li>\n<p>Configure the error bound setting and comparison cases in errBounds.cfg.</p>\n</li>\n<li>\n<p>Create a new test-case, by executing \"createZCCase.sh [test-case-name]\". You need to replace [test-case-name] by a meaningful name.\nFor example:\n[user@localhost z-checker-installer] ./createZCCase.sh CESM-ATM-tylor-data</p>\n</li>\n<li>\n<p>Perform the checking by running the command \"runZCCase.sh\": runZCCase.sh [data_type] [error-bound-mode] [test-case-name] [data dir] [extension] [dimensions....].\nExample:\n[user@localhost z-checker-installer] ./runZCCase.sh -f REL CESM-ATM-tylor-data /home/shdi/CESM-testdata/1800x3600 dat 3600 1800</p>\n</li>\n</ol>\n<p>Then, you can find the report generated in z-checker-installer/Z-checker/[test-case-name]/report.</p>\n<h3>\n<a id=\"user-content-step-by-step-checking\" class=\"anchor\" href=\"#step-by-step-checking\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step-by-step Checking</h3>\n<p>Unlike the above one-command checking, the following steps present the generation of compression results step by step.</p>\n<ol>\n<li>\n<p>Go to zfp/utils/, and then execute \"zfp-zc-ratedistortion.sh [data directory] [dimension sizes....]\". The compression results are stored in the compressionResults/ directory.\nFor example, suppose the directory of CESM-ATM data set is here: /home/shdi/CESM-testdata/1800x3600, then the command is \"zfp-zc-ratedistortion.sh /home/shdi/CESM-testdata/1800x3600 3600 1800\". Note: the data files stored in the directory are also ending with .dat and the dimension sizes are the same (1800x3600) in this test-case.</p>\n</li>\n<li>\n<p>Similarly, go to SZ/example/, and then generate compression results by SZ compressor as follows: \"sz-zc-ratedistortion.sh [data directory] [dimension sizes....]\". The compression results are stored in the compressionResults/ directory.\nAs for the example CESM-ATM, the test command is \"sz-zc-ratedistortion.sh /home/shdi/CESM-testdata/1800x3600 3600 1800\".</p>\n</li>\n<li>\n<p>Then, go to Z-checker/examples/ directory, and run the command \"./analyzeDataProperty.sh [data directory] [dimension sizes....]\" to generate the data properties based on the data sets. This step has nothing to do with the compressors. The data analysis results are stored in the dataProperties/ directory.</p>\n</li>\n<li>\n<p>Generate the figure files: run the command \"./generateReport.sh\" simply. The results of comparing different compressors (such as sz and zfp in this test-case) are stored in the directory called compareCompressors/.</p>\n</li>\n</ol>\n<h3>\n<a id=\"user-content-create-a-new-case\" class=\"anchor\" href=\"#create-a-new-case\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Create a new case</h3>\n<p>\"createZCCase.sh [test-case-name]\" allows you to create a new test-case.  This command will create a new workspace directory in Z-checker, SZ, and zfp respectively. The compression results will be put in those workspace directories to avoid bing messed with other test-cases.</p>\n<p>For example, if you run the generateReport.sh in the directory ./Z-checker/examples, it is actually one test case, where the compression results and data analysis results will be put in the dataProperty/ and compressionResults/ under it.\nFor another test case with another set of data or application, you can create a new workspace directory by the script createZCCase.sh (which calls ./Z-checker/createNewCase.sh).</p>\n<h3>\n<a id=\"user-content-z-checker-updatesh\" class=\"anchor\" href=\"#z-checker-updatesh\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>z-checker-update.sh</h3>\n<p>z-checker-update.sh can be used to update the repository (pull the new update from the server), so that you don't have to perform the update manually.</p>\n<h3>\n<a id=\"user-content-web-installation\" class=\"anchor\" href=\"#web-installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>web installation</h3>\n<p>Web installation allows to install a web server on the local machine, such that you can visualize the data through a local webpage and other people can view the data/results via that page if public ip is provided.\nz-checker-web-install.sh</p>\n<h3>\n<a id=\"user-content-add-a-new-compressor\" class=\"anchor\" href=\"#add-a-new-compressor\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Add a new compressor</h3>\n<ol>\n<li>Make a monitoring program (e.g., called testfloat_CompDecomp.c) for your compressor. An example can be found in SZ/example/testfloat_CompDecomp.c, which is used for SZ compressor.)</li>\n<li>Modify the manageCompressor.cfg based on the workspaceDir on your computer and directory containing the compiled executable monitoring program.</li>\n<li>Suppose the new compressor's name is zz and the compression mode is called 'best'; then, run the following command to add the new compressor:\n./manageCompressor -a zz -m best -c manageCompressor.cfg</li>\n<li>Then, open errBounds.cfg to modify the error bounds for the new compressor; and also modify the comparison cases as follows (the compressor name 'zz_b' was set in manageCompressor.cfg):\ncomparisonCases=\"sz_f(1E-1),sz_d(1E-1),zfp(1E-1) sz_f(1E-2),sz_d(1E-2),zfp(1E-2)\" --&gt; comparisonCases=\"sz_f(1E-1),sz_d(1E-1),zfp(1E-1),zz_b(1E-2) sz_f(1E-2),sz_d(1E-2),zfp(1E-2),zz_b(1E-2)\"</li>\n<li>Finally, create a test case like this: ./createZCCase.sh case_name</li>\n<li>Perform the assessment by runZCCase.sh.</li>\n</ol>\n<h3>\n<a id=\"user-content-remove-a-compressor\" class=\"anchor\" href=\"#remove-a-compressor\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Remove a compressor</h3>\n<p>Remove sz_f (sz fast mode):\n$ manageCompressor -d sz -m fast -c manageCompressor-sz-f.cfg\nRemove sz_d (sz fast mode):\n$ manageCompressor -d sz -m deft -c manageCompressor-sz-d.cfg\nRemove zfp:\n$ manageCompressor -d zfp -c manageCompressor-zfp.cfg</p>\n<h3>\n<a id=\"user-content-generate-z-checker-report-based-on-hdf5-files\" class=\"anchor\" href=\"#generate-z-checker-report-based-on-hdf5-files\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Generate Z-checker report based on HDF5 files</h3>\n<p>You can generate Z-checker report directly based on an HDF5 file.\nTo this end, you need to install HDF5 library before hand, and then compile the Z-checker/HDF5Reader as follows:</p>\n<p>You need to modify Makefile.linux2 by replacing \"HDF5PATH = /home/sdi/Install/hdf5-1.10.1-install\" by your HDF5 installation path.\nThen:\nmake -f Makefile.linux2</p>\n<p>You will find the executable 'testHDF5_CompDecomp' generated on Z-checker/HDF5Reader/test/ directory.\nYou can use this command to read HDF5 file and generate analysis results.</p>\n<p>After that, you can use 'installHDF5Reader.sh' and 'runZCCase_hdf5.sh' to generate the .pdf report.\nMore details can be found in testHDF5/README.txt</p>\n<h3>\n<a id=\"user-content-generate-z-checker-report-based-on-adios2-files\" class=\"anchor\" href=\"#generate-z-checker-report-based-on-adios2-files\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Generate Z-checker report based on ADIOS2 files</h3>\n<p>Go to the directory ADIOS2Header, and then do the following steps:</p>\n<ol>\n<li>Modify the ADIOS2's installation path in Makefile</li>\n<li>make</li>\n<li>execute 'testAdios2'</li>\n</ol>\n<p>Example:\ntestAdios2 -i myVector_cpp.bp -n 2 -v bpFloats bpInts -o [target output directory]</p>\n<p>The generated binary data files will be put in the target output directory. A meta file called 'varInfo.txt' contains the extracted variables' information and it will be put in the target output directory as well.\nvarInfo.txt and the binary files can be processed by runZCCase.sh</p>\n",
        "stargazers_count": 4,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1619655975.0
    },
    {
        "data_format": 2,
        "description": null,
        "filenames": [
            "spack/spack.yaml"
        ],
        "full_name": "ECP-CANDLE/Supervisor",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-centos7-spack-config\" class=\"anchor\" href=\"#centos7-spack-config\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>centos7-spack-config</h1>\n<p>centos7 spack configuration and scripts</p>\n<h2>\n<a id=\"user-content-contents\" class=\"anchor\" href=\"#contents\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>contents</h2>\n<p>compilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands</p>\n",
        "stargazers_count": 6,
        "subscribers_count": 9,
        "topics": [],
        "updated_at": 1611214776.0
    },
    {
        "data_format": 2,
        "description": "Training materials for setting up and using a research infrastructure based on Jupyter notebooks: https://cusy.io/en/seminars",
        "filenames": [
            "spackenvs/python-374/spack.yaml"
        ],
        "full_name": "veit/jupyter-tutorial",
        "latest_release": "0.8.0",
        "readme": "<h1>\n<a id=\"user-content-performance-data-analysis\" class=\"anchor\" href=\"#performance-data-analysis\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Performance Data Analysis</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Branch</th>\n<th align=\"left\">Status</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">master</td>\n<td align=\"left\">\n<a href=\"https://travis-ci.org/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d6176705ab1b1ddb9abdad4a84fb18b9f3f7720d2cddb0b1ae2e5238e85332a4/68747470733a2f2f7472617669732d63692e6f72672f434f444152636f64652f506572666f726d616e6365416e616c797369732e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/CODARcode/PerformanceAnalysis.svg?branch=master\" style=\"max-width:100%;\"></a> <a href=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/99c1ab43c88b2244a028750bad5e98f9e393273432513453bf8b8eba6eeea2df/68747470733a2f2f636f6465636f762e696f2f67682f434f444152636f64652f506572666f726d616e6365416e616c797369732f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d4235565056535a494934\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis/branch/master/graph/badge.svg?token=B5VPVSZII4\" style=\"max-width:100%;\"></a>\n</td>\n</tr>\n<tr>\n<td align=\"left\">develop</td>\n<td align=\"left\">\n<a href=\"https://travis-ci.org/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/def9cf7b52f068db3cc82f122249a1e66c1af6751ae0c3ee9f70f72e9b1d581b/68747470733a2f2f7472617669732d63692e6f72672f434f444152636f64652f506572666f726d616e6365416e616c797369732e7376673f6272616e63683d72656c65617365\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/CODARcode/PerformanceAnalysis.svg?branch=release\" style=\"max-width:100%;\"></a> <a href=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0e7958c5895230859b4cdeb23f6544526403cbb209a75d2a955f5d3b2a36e3d4/68747470733a2f2f636f6465636f762e696f2f67682f434f444152636f64652f506572666f726d616e6365416e616c797369732f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d4235565056535a494934\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/CODARcode/PerformanceAnalysis/branch/develop/graph/badge.svg?token=B5VPVSZII4\" style=\"max-width:100%;\"></a>\n</td>\n</tr>\n</tbody>\n</table>\n<p>This library is part of the <a href=\"https://github.com/CODARcode/Chimbuko\">CHIMBUKO</a> software framework and provides the C/C++ API to process <a href=\"http://tau.uoregon.edu\" rel=\"nofollow\">TAU</a> performance traces which can be produced by multiple workflow components, processes, and threads. Its purpose is to detect events in the trace data that reveal useful information to developers of High Performance Computing applications.</p>\n<h1>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>Comprehensive documentation on the installation and running of Chimbuko, as well as a full API reference, can be found <a href=\"https://chimbuko-performance-analysis.readthedocs.io/en/latest/\" rel=\"nofollow\">here</a>.</p>\n<h1>\n<a id=\"user-content-releases\" class=\"anchor\" href=\"#releases\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Releases</h1>\n<ul>\n<li>Latest release: v4.0.0</li>\n</ul>\n<h1>\n<a id=\"user-content-directory-layout\" class=\"anchor\" href=\"#directory-layout\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Directory layout</h1>\n<ul>\n<li>\n<p>3rdparty: third party libraries</p>\n</li>\n<li>\n<p>app: applications of PerformanceAnalysis library including the on-node AD module, provenance database server, parameter server and pseudo clients (for debug and test purpose)</p>\n</li>\n<li>\n<p>docker: docker files for Chimbuko's stack and examples</p>\n</li>\n<li>\n<p>docs: web documentation</p>\n</li>\n<li>\n<p>include: header files</p>\n</li>\n<li>\n<p>scripts: scripts for interacting with the provenance database and for deployment on specific machines (e.g. Summit)</p>\n</li>\n<li>\n<p>sphinx: web documentation builder</p>\n</li>\n<li>\n<p>src: source files</p>\n</li>\n<li>\n<p>test: source files for test (using gtest)</p>\n</li>\n</ul>\n<h1>\n<a id=\"user-content-reporting-bugs\" class=\"anchor\" href=\"#reporting-bugs\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Reporting Bugs</h1>\n<p>If you find a bug, please open an <a href=\"https://github.com/CODARcode/PerformanceAnalysis/issues\">issue on PerformanceAnalysis github repositoty</a>.</p>\n",
        "stargazers_count": 6,
        "subscribers_count": 4,
        "topics": [
            "jupyter",
            "jupyter-notebooks",
            "jupyter-kernels",
            "ipython",
            "ipywidgets",
            "ipython-widget",
            "spack",
            "pipenv",
            "dvc",
            "data-science",
            "pandas"
        ],
        "updated_at": 1621538249.0
    },
    {
        "data_format": 2,
        "description": "Argobots bindings for the Mercury RPC library",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-margo",
        "latest_release": "v0.9.4",
        "readme": "<h1>\n<a id=\"user-content-margo\" class=\"anchor\" href=\"#margo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n<p><a href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" alt=\"\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\" rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\nlibrary optimized for use in HPC environments.  Its native API presents a\ncallback-oriented interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\" rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n<p>Margo combines Mercury and Argobots to simplify development of distributed\nservices.  Mercury operations are presented as conventional blocking\noperations, and RPC handlers are presented as sequential threads.  This\nconfiguration enables high degree of concurrency while hiding the\ncomplexity associated with asynchronous communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends callers after issuing a Mercury operation, and\nautomatically resumes them when the operation completes.  This allows\nother concurrent user-level threads to make progress while Mercury\noperations are in flight without consuming operating system threads.\nThe goal of this design is to combine the performance advantages of\nMercury's native event-driven execution model with the progamming\nsimplicity of a multi-threaded execution model.</p>\n<p>A companion library called abt-io provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\">https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should be compatible with any Mercury network\ntransport (NA plugin).  The documentation assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury for\nsimplicity.  This plugin is only valid for communication between\nprocesses on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\">Using Margo with other Mercury NA\nplugins</a> for information\non other configuration options.</p>\n<h2>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"nofollow\">https://spack.io/</a>).</p>\n<h2>\n<a id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\">https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n</ul>\n<h3>\n<a id=\"user-content-recommended-mercury-build-options\" class=\"anchor\" href=\"#recommended-mercury-build-options\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury build options</h3>\n<ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should be compiled with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path for cases in which a Mercury service is linked into the same\nexecutable as the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n<h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"-g -Wall\"\n</code></pre>\n<h2>\n<a id=\"user-content-running-examples\" class=\"anchor\" href=\"#running-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]: an example RPC definition</li>\n</ul>\n<p>The following example shows how to execute them.  Note that when the server starts it will display the address that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val: 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3] running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\nGot response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n<p>The client will issue 4 concurrent RPCs to the server and wait for them to\ncomplete.</p>\n<h2>\n<a id=\"user-content-running-tests\" class=\"anchor\" href=\"#running-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running tests</h2>\n<p><code>make check</code></p>\n<h2>\n<a id=\"user-content-using-margo-with-the-other-na-plugins\" class=\"anchor\" href=\"#using-margo-with-the-other-na-plugins\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Margo with the other NA plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\" rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible with any Mercury transport and uses the same address\nformat.</p>\n<h2>\n<a id=\"user-content-instrumentation\" class=\"anchor\" href=\"#instrumentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Instrumentation</h2>\n<p>See the <a href=\"doc/instrumentation.md\">Instrumentation documentation</a> for\ninformation on how to extract diagnostic instrumentation from Margo.</p>\n<h2>\n<a id=\"user-content-debugging\" class=\"anchor\" href=\"#debugging\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Debugging</h2>\n<p>See the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo debugging\nfeatures and strategies.</p>\n<h2>\n<a id=\"user-content-design-details\" class=\"anchor\" href=\"#design-details\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design details</h2>\n<p><a href=\"doc/fig/margo-diagram.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware wrappers to common Mercury library functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The wrappers\nhave the same arguments as their native Mercury counterparts except that no\ncallback function is specified.  Each function blocks until the operation\nis complete.  The above diagram illustrates a typical control flow.</p>\n<p>Margo launches a long-running user-level thread internally to drive\nprogress on Mercury and execute Mercury callback functions (labeled\n<code>__margo_progress()</code> above).  This thread can be assigned to a\ndedicated Argobots execution stream (i.e., an operating system thread)\nto drive network progress with a dedicated core.  Otherwise it will be\nautomatically scheduled when the caller's execution stream is blocked\nwaiting for network events as shown in the above diagram.</p>\n<p>Argobots eventual constructs are used to suspend and resume user-level\nthreads while Mercury operations are in flight.</p>\n<p>Margo allows several different threading/multicore configurations:</p>\n<ul>\n<li>The progress loop can run on a dedicated operating system thread or not</li>\n<li>Multiple Margo instances (and thus progress loops) can be\nexecuted on different operating system threads</li>\n<li>(for servers) a single Margo instance can launch RPC handlers\non different operating system threads</li>\n</ul>\n",
        "stargazers_count": 7,
        "subscribers_count": 7,
        "topics": [],
        "updated_at": 1620438942.0
    },
    {
        "data_format": 2,
        "description": "Argobots bindings for the Mercury RPC library",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-margo",
        "latest_release": "v0.9.4",
        "readme": "<h1>\n<a id=\"user-content-margo\" class=\"anchor\" href=\"#margo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n<p><a href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" alt=\"\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\" rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\nlibrary optimized for use in HPC environments.  Its native API presents a\ncallback-oriented interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\" rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n<p>Margo combines Mercury and Argobots to simplify development of distributed\nservices.  Mercury operations are presented as conventional blocking\noperations, and RPC handlers are presented as sequential threads.  This\nconfiguration enables high degree of concurrency while hiding the\ncomplexity associated with asynchronous communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends callers after issuing a Mercury operation, and\nautomatically resumes them when the operation completes.  This allows\nother concurrent user-level threads to make progress while Mercury\noperations are in flight without consuming operating system threads.\nThe goal of this design is to combine the performance advantages of\nMercury's native event-driven execution model with the progamming\nsimplicity of a multi-threaded execution model.</p>\n<p>A companion library called abt-io provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\">https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should be compatible with any Mercury network\ntransport (NA plugin).  The documentation assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury for\nsimplicity.  This plugin is only valid for communication between\nprocesses on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\">Using Margo with other Mercury NA\nplugins</a> for information\non other configuration options.</p>\n<h2>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"nofollow\">https://spack.io/</a>).</p>\n<h2>\n<a id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\">https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n</ul>\n<h3>\n<a id=\"user-content-recommended-mercury-build-options\" class=\"anchor\" href=\"#recommended-mercury-build-options\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury build options</h3>\n<ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should be compiled with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path for cases in which a Mercury service is linked into the same\nexecutable as the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n<h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"-g -Wall\"\n</code></pre>\n<h2>\n<a id=\"user-content-running-examples\" class=\"anchor\" href=\"#running-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]: an example RPC definition</li>\n</ul>\n<p>The following example shows how to execute them.  Note that when the server starts it will display the address that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val: 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3] running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\nGot response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n<p>The client will issue 4 concurrent RPCs to the server and wait for them to\ncomplete.</p>\n<h2>\n<a id=\"user-content-running-tests\" class=\"anchor\" href=\"#running-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running tests</h2>\n<p><code>make check</code></p>\n<h2>\n<a id=\"user-content-using-margo-with-the-other-na-plugins\" class=\"anchor\" href=\"#using-margo-with-the-other-na-plugins\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Margo with the other NA plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\" rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible with any Mercury transport and uses the same address\nformat.</p>\n<h2>\n<a id=\"user-content-instrumentation\" class=\"anchor\" href=\"#instrumentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Instrumentation</h2>\n<p>See the <a href=\"doc/instrumentation.md\">Instrumentation documentation</a> for\ninformation on how to extract diagnostic instrumentation from Margo.</p>\n<h2>\n<a id=\"user-content-debugging\" class=\"anchor\" href=\"#debugging\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Debugging</h2>\n<p>See the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo debugging\nfeatures and strategies.</p>\n<h2>\n<a id=\"user-content-design-details\" class=\"anchor\" href=\"#design-details\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design details</h2>\n<p><a href=\"doc/fig/margo-diagram.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware wrappers to common Mercury library functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The wrappers\nhave the same arguments as their native Mercury counterparts except that no\ncallback function is specified.  Each function blocks until the operation\nis complete.  The above diagram illustrates a typical control flow.</p>\n<p>Margo launches a long-running user-level thread internally to drive\nprogress on Mercury and execute Mercury callback functions (labeled\n<code>__margo_progress()</code> above).  This thread can be assigned to a\ndedicated Argobots execution stream (i.e., an operating system thread)\nto drive network progress with a dedicated core.  Otherwise it will be\nautomatically scheduled when the caller's execution stream is blocked\nwaiting for network events as shown in the above diagram.</p>\n<p>Argobots eventual constructs are used to suspend and resume user-level\nthreads while Mercury operations are in flight.</p>\n<p>Margo allows several different threading/multicore configurations:</p>\n<ul>\n<li>The progress loop can run on a dedicated operating system thread or not</li>\n<li>Multiple Margo instances (and thus progress loops) can be\nexecuted on different operating system threads</li>\n<li>(for servers) a single Margo instance can launch RPC handlers\non different operating system threads</li>\n</ul>\n",
        "stargazers_count": 7,
        "subscribers_count": 7,
        "topics": [],
        "updated_at": 1620438942.0
    },
    {
        "data_format": 2,
        "description": "Argobots bindings for the Mercury RPC library",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "mochi-hpc/mochi-margo",
        "latest_release": "v0.9.4",
        "readme": "<h1>\n<a id=\"user-content-margo\" class=\"anchor\" href=\"#margo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Margo</h1>\n<p><a href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" alt=\"\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware bindings to the Mercury RPC library.</p>\n<p>Mercury (<a href=\"https://mercury-hpc.github.io/\" rel=\"nofollow\">https://mercury-hpc.github.io/</a>) is a remote procedure call\nlibrary optimized for use in HPC environments.  Its native API presents a\ncallback-oriented interface to manage asynchronous operation.  Argobots\n(<a href=\"https://www.argobots.org/\" rel=\"nofollow\">https://www.argobots.org/</a>) is a user-level threading package.</p>\n<p>Margo combines Mercury and Argobots to simplify development of distributed\nservices.  Mercury operations are presented as conventional blocking\noperations, and RPC handlers are presented as sequential threads.  This\nconfiguration enables high degree of concurrency while hiding the\ncomplexity associated with asynchronous communication progress and callback\nmanagement.</p>\n<p>Internally, Margo suspends callers after issuing a Mercury operation, and\nautomatically resumes them when the operation completes.  This allows\nother concurrent user-level threads to make progress while Mercury\noperations are in flight without consuming operating system threads.\nThe goal of this design is to combine the performance advantages of\nMercury's native event-driven execution model with the progamming\nsimplicity of a multi-threaded execution model.</p>\n<p>A companion library called abt-io provides similar wrappers for POSIX I/O\nfunctions: <a href=\"https://github.com/mochi-hpc/mochi-abt-io\">https://github.com/mochi-hpc/mochi-abt-io</a></p>\n<p>Note that Margo should be compatible with any Mercury network\ntransport (NA plugin).  The documentation assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury for\nsimplicity.  This plugin is only valid for communication between\nprocesses on a single node.  See <a href=\"##using-margo-with-other-mercury-na-plugins\">Using Margo with other Mercury NA\nplugins</a> for information\non other configuration options.</p>\n<h2>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack</h2>\n<p>The simplest way to install Margo is by installing the \"mochi-margo\" package\nin spack (<a href=\"https://spack.io/\" rel=\"nofollow\">https://spack.io/</a>).</p>\n<h2>\n<a id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<ul>\n<li>mercury  (git clone --recurse-submodules <a href=\"https://github.com/mercury-hpc/mercury.git\">https://github.com/mercury-hpc/mercury.git</a>)</li>\n<li>argobots (git clone <a href=\"https://github.com/pmodels/argobots.git\">https://github.com/pmodels/argobots.git</a>)</li>\n</ul>\n<h3>\n<a id=\"user-content-recommended-mercury-build-options\" class=\"anchor\" href=\"#recommended-mercury-build-options\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Recommended Mercury build options</h3>\n<ul>\n<li>Mercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable the\nBoost preprocessor macros for encoding.</li>\n<li>Mercury should be compiled with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path for cases in which a Mercury service is linked into the same\nexecutable as the client</li>\n</ul>\n<p>Example Mercury compilation:</p>\n<pre><code>mkdir build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n</code></pre>\n<h2>\n<a id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building</h2>\n<p>Example configuration:</p>\n<pre><code>../configure --prefix=/home/pcarns/working/install \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"-g -Wall\"\n</code></pre>\n<h2>\n<a id=\"user-content-running-examples\" class=\"anchor\" href=\"#running-examples\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running examples</h2>\n<p>The examples subdirectory contains:</p>\n<ul>\n<li>margo-example-client.c: an example client</li>\n<li>margo-example-server.c: an example server</li>\n<li>my-rpc.[ch]: an example RPC definition</li>\n</ul>\n<p>The following example shows how to execute them.  Note that when the server starts it will display the address that the client can use to connect to it.</p>\n<pre><code>$ examples/margo-example-server na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val: 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3] running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\nGot response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n</code></pre>\n<p>The client will issue 4 concurrent RPCs to the server and wait for them to\ncomplete.</p>\n<h2>\n<a id=\"user-content-running-tests\" class=\"anchor\" href=\"#running-tests\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running tests</h2>\n<p><code>make check</code></p>\n<h2>\n<a id=\"user-content-using-margo-with-the-other-na-plugins\" class=\"anchor\" href=\"#using-margo-with-the-other-na-plugins\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Using Margo with the other NA plugins</h2>\n<p>See the <a href=\"http://mercury-hpc.github.io/documentation/\" rel=\"nofollow\">Mercury\ndocumentation</a> for details.\nMargo is compatible with any Mercury transport and uses the same address\nformat.</p>\n<h2>\n<a id=\"user-content-instrumentation\" class=\"anchor\" href=\"#instrumentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Instrumentation</h2>\n<p>See the <a href=\"doc/instrumentation.md\">Instrumentation documentation</a> for\ninformation on how to extract diagnostic instrumentation from Margo.</p>\n<h2>\n<a id=\"user-content-debugging\" class=\"anchor\" href=\"#debugging\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Debugging</h2>\n<p>See the <a href=\"doc/debugging.md\">Debugging documentation</a> for Margo debugging\nfeatures and strategies.</p>\n<h2>\n<a id=\"user-content-design-details\" class=\"anchor\" href=\"#design-details\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Design details</h2>\n<p><a href=\"doc/fig/margo-diagram.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width:100%;\"></a></p>\n<p>Margo provides Argobots-aware wrappers to common Mercury library functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The wrappers\nhave the same arguments as their native Mercury counterparts except that no\ncallback function is specified.  Each function blocks until the operation\nis complete.  The above diagram illustrates a typical control flow.</p>\n<p>Margo launches a long-running user-level thread internally to drive\nprogress on Mercury and execute Mercury callback functions (labeled\n<code>__margo_progress()</code> above).  This thread can be assigned to a\ndedicated Argobots execution stream (i.e., an operating system thread)\nto drive network progress with a dedicated core.  Otherwise it will be\nautomatically scheduled when the caller's execution stream is blocked\nwaiting for network events as shown in the above diagram.</p>\n<p>Argobots eventual constructs are used to suspend and resume user-level\nthreads while Mercury operations are in flight.</p>\n<p>Margo allows several different threading/multicore configurations:</p>\n<ul>\n<li>The progress loop can run on a dedicated operating system thread or not</li>\n<li>Multiple Margo instances (and thus progress loops) can be\nexecuted on different operating system threads</li>\n<li>(for servers) a single Margo instance can launch RPC handlers\non different operating system threads</li>\n</ul>\n",
        "stargazers_count": 7,
        "subscribers_count": 7,
        "topics": [],
        "updated_at": 1620438942.0
    },
    {
        "data_format": 2,
        "description": "Repository for installation routines of the external software required by FairRoot",
        "filenames": [
            "env/apr21/sim_mt_headless/spack.yaml",
            "test/env/fairmq/spack.yaml",
            "test/env/r3broot/spack.yaml",
            "test/env/fairlogger/spack.yaml",
            "test/env/jun19_fairroot_18_4/spack.yaml",
            "env/jun19/sim/spack.yaml",
            "env/nov20/sim/spack.yaml",
            "env/dev/sim/spack.yaml",
            "env/apr21/sim/spack.yaml",
            "env/jun19/sim_mt/spack.yaml",
            "test/env/dds/spack.yaml",
            "env/nov20/sim_mt_headless/spack.yaml",
            "env/apr21/sim_mt/spack.yaml",
            "env/dev/sim_mt/spack.yaml",
            "env/dev/sim_mt_headless/spack.yaml",
            "env/nov20/sim_mt/spack.yaml",
            "test/env/fairroot_develop/spack.yaml"
        ],
        "full_name": "FairRootGroup/FairSoft",
        "latest_release": "apr21",
        "readme": "<h1>\n<a id=\"user-content-fairsoft\" class=\"anchor\" href=\"#fairsoft\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>FairSoft</h1>\n<p>The FairSoft distribution provides the software packages needed to compile and run the <a href=\"https://github.com/FairRootGroup/FairRoot\">FairRoot framework</a> and experiment packages based on FairRoot. FairSoft is a source distribution with recurring releases for macOS and Linux.</p>\n<h2>\n<a id=\"user-content-installation-from-source\" class=\"anchor\" href=\"#installation-from-source\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation from Source</h2>\n<p>Choose between the classic (called \"Legacy\") installation method or the new Spack-based one:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Legacy</strong></th>\n<th><strong>Spack (EXPERIMENTAL)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>This is the classic bash/cmake based setup system.</td>\n<td>This is an ongoing standardization and modernization effort based on Spack (which itself is still under heavy development). Most things are already working. For early adopters.</td>\n</tr>\n<tr>\n<td>Releases are reflected in the git history via tags and branches, e.g.: <code>apr21</code>, <code>jun19p2</code>, <code>nov20_patches</code>\n</td>\n<td>Always use the latest <code>dev</code> branch. Multiple releases are described within the metadata contained in the repo (read on in the Installation instructions on how to select a release).</td>\n</tr>\n<tr>\n<td>\u25ba <a href=\"legacy/README.md\">continue</a>\n</td>\n<td>\u25ba <a href=\"docs/README.md\">continue</a>\n</td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-installation-of-pre-compiled-binaries\" class=\"anchor\" href=\"#installation-of-pre-compiled-binaries\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation of pre-compiled Binaries</h2>\n<p><em>Note</em>: FairSoft is primarily a source distribution. Availability of latest releases as pre-compiled binaries may be delayed.</p>\n<h3>\n<a id=\"user-content-gsi-virgo-cluster\" class=\"anchor\" href=\"#gsi-virgo-cluster\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>GSI Virgo Cluster</h3>\n<p>For all <a href=\"https://hpc.gsi.de/virgo/platform/software.html#application-environment\" rel=\"nofollow\">VAEs</a> at <code>/cvmfs/fairsoft.gsi.de/&lt;vae-os&gt;/fairsoft/&lt;release&gt;</code>. Use by exporting the <code>SIMPATH</code> environment variable pointing to one of the directories.</p>\n<h3>\n<a id=\"user-content-macos-beta\" class=\"anchor\" href=\"#macos-beta\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>macOS (beta)</h3>\n<p>Supported OS versions: <code>10.15</code>, <code>11</code><br>\nSupported <em>Command Line Tools for Xcode</em>: <code>12+</code><br>\nFairSoft config: <a href=\"FairSoftConfig.cmake\">default</a>, no other configs planned<br></p>\n<ol>\n<li>Install <em>Command Line Tools for Xcode</em> from <a href=\"https://developer.apple.com/downloads\" rel=\"nofollow\">https://developer.apple.com/downloads</a> (requires Apple account)</li>\n<li>Install <a href=\"https://brew.sh/\" rel=\"nofollow\">Homebrew</a>\n</li>\n<li>Run <code>brew update &amp;&amp; brew doctor</code> and fix potential issues reported by these commands until <code>Your system is ready to brew.</code>\n</li>\n<li>Run</li>\n</ol>\n<pre><code>brew tap fairrootgroup/fairsoft\nbrew install fairsoft@21.4\n</code></pre>\n<ol start=\"5\">\n<li>Use via <code>export SIMPATH=$(brew --prefix fairsoft@21.4)</code>\n</li>\n</ol>\n<p><em>Note</em>: macOS is a fast moving target and it is possible the packages will stop working from one day to another after some system component was updated. We try our best to keep up, one great way to help is to provide detailed problem reports <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\">here on github</a>.</p>\n<h3>\n<a id=\"user-content-other-platforms\" class=\"anchor\" href=\"#other-platforms\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Other platforms</h3>\n<p>Binary packages for non-GSI Linux as well as Spack binary caches and/or pre-populated install trees are planned for the future.</p>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>Please ask your questions, request features, and report issues by <a href=\"https://github.com/FairRootGroup/FairSoft/issues/new\">creating a github issue</a>.</p>\n",
        "stargazers_count": 7,
        "subscribers_count": 13,
        "topics": [],
        "updated_at": 1621280529.0
    },
    {
        "data_format": 2,
        "description": "Installing spack without system dependencies",
        "filenames": [
            "build/6_spack/spack.yaml",
            "build/3_more_tools/spack.yaml",
            "build/5_runtime/spack.yaml",
            "build/2_compiler/spack.yaml",
            "build/1_ccache/spack.yaml"
        ],
        "full_name": "haampie/spack-batteries-included",
        "latest_release": "develop",
        "readme": "<p><a href=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml\"><img src=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\" alt=\"Update spack develop version\" style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\" href=\"#-spack-with-batteries-included-linuxx86_64\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><g-emoji class=\"g-emoji\" alias=\"battery\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png\">\ud83d\udd0b</g-emoji> Spack with batteries included (linux/x86_64)</h1>\n<p><a href=\"https://github.com/spack/spack\">Spack</a> is a package manager, and package managers should be trivial to install.</p>\n<p>This repo offers a single, static executable for Spack:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">wget -qO spack.x https://github.com/haampie/spack-batteries-included/releases/download/develop/spack-x86_64.x</span>\n$ <span class=\"pl-s1\">chmod +x spack.x</span>\n$ <span class=\"pl-s1\">./spack.x install zstd +programs <span class=\"pl-k\">~</span>shared build_type=Release</span></pre></div>\n<h2>\n<a id=\"user-content-what-version-of-spack-is-shipped\" class=\"anchor\" href=\"#what-version-of-spack-is-shipped\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>What version of Spack is shipped?</h2>\n<p>The URL above gives you a rolling release of Spack's develop branch, which is updated\nhourly. The exact commit SHA is included as a file and can be retrieved like this:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract spack_sha <span class=\"pl-k\">&amp;&amp;</span> cat spack/spack_sha</span>\n<span class=\"pl-c1\">[prints the Spack commit sha]</span></pre></div>\n<h2>\n<a id=\"user-content-supported-platforms\" class=\"anchor\" href=\"#supported-platforms\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Supported platforms</h2>\n<ul>\n<li>CentOS 7 and above</li>\n<li>Ubuntu 14.04 and above</li>\n<li>Debian 8 and above</li>\n<li>Fedora 20 and above</li>\n<li>SUSE Linux 13 and above</li>\n<li>Arch Linux</li>\n<li>Gentoo</li>\n<li>Windows Subsystem for Linux 2 with any of the above distro's.</li>\n</ul>\n<p>The system dependencies are <code>glibc 2.17</code> and above and optionally the <code>fusermount</code>\nexecutable. If your system supports rootless containers it likely has <code>fusermount</code>\ninstalled already!</p>\n<h2>\n<a id=\"user-content-how-does-it-work\" class=\"anchor\" href=\"#how-does-it-work\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How does it work?</h2>\n<p><code>spack.x</code> consists of a modified version of the AppImage runtime concatenated\nwith a big squashfs file which includes <code>binutils</code>, <code>bzip2</code>, <code>clingo</code>, <code>curl</code>,\n<code>file</code>, <code>git</code>, <code>gmake</code>, <code>gpg</code>, <code>gzip</code>, <code>openssl</code>, <code>patch</code>, <code>patchelf</code>, <code>python</code>,\n<code>py-boto3</code>, <code>tar</code>, <code>unzip</code>, <code>xz</code>, <code>zstd</code> and their dependencies.</p>\n<p>When you run <code>spack.x [args]</code> it will use <code>fusermount</code> to\nmount this squashfs file in a temporary directory, and then execute the\nentrypoint executable <a href=\"build/6_spack/spack\">spack</a>.</p>\n<p>The <code>spack</code> executable sets some environment variables like <code>PATH</code> and\n<code>DL_LIBRARY_PATH</code> to the bin and lib folders of the squashfs file, and then it\nexecutes <code>python3 spack_src/bin/spack [args]</code>.</p>\n<p>When the command is done running, the runtime unmounts the squashfs file again.</p>\n<h2>\n<a id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\" class=\"anchor\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>My system doesn't allow me to use <code>fusermount</code>, what now?</h2>\n<p><code>fusermount</code> is used to mount a squashfs file included in the binary. If you\ndon't want that, you can just extract it:</p>\n<pre><code>$ spack.x --squashfs-extract\n$ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n</code></pre>\n<p>but working with the extracted <code>spack</code> folder can come with a performance\npenalty on shared filesystems in HPC centers.</p>\n<h2>\n<a id=\"user-content-differences-and-improvements-over-appimage-runtime\" class=\"anchor\" href=\"#differences-and-improvements-over-appimage-runtime\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Differences and improvements over AppImage runtime</h2>\n<ul>\n<li>spack.x uses <code>zstd</code> for faster decompression;</li>\n<li>spack.x itself is an entirely static binary;</li>\n<li>spack.x does not need to dlopen libfuse.so.</li>\n</ul>\n<h2>\n<a id=\"user-content-troubleshooting\" class=\"anchor\" href=\"#troubleshooting\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Troubleshooting</h2>\n<p><strong>immutability</strong> The squashfs mountpoint is a readonly folder, meaning that\nspack can't write to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard directories, see <code>spack.x config blame config</code> for details.</p>\n<p>Note, spack.x applies <a href=\"https://github.com/spack/spack/pull/20158/\">this patch</a>\nto ensure that log files are written to the <code>config:misc_cache</code> folder.</p>\n<p><strong>openssl</strong>: By default spack.x uses <code>ca-certificates-mozilla</code> for downloading\npackage sources over https. If you somehow need to use system certificates,\nset <code>SSL_CERT_DIR</code> and <code>GIT_SSL_CAPATH</code> or <code>SSL_CERT_FILE</code> and <code>GIT_SSL_CERT</code>.</p>\n<h2>\n<a id=\"user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" href=\"#can-i-run-spackx-inside-a-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Can I run spack.x inside a container?</h2>\n<p>Yes, but please don't! Since <code>fusermount</code> is a setuid binary, you will need to\nrun a privileged container, which is never a good idea.</p>\n<p>The recommended way to run spack.x inside a container is to just extract it:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">spack.x --squashfs-extract</span>\n$ <span class=\"pl-s1\">./spack/spack --version</span></pre></div>\n<p>If you insist on running spack.x in Docker, this is one way to do it:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">sudo docker run --privileged --device /dev/fuse -it -v <span class=\"pl-smi\">$PWD</span>/spack.x:/bin/spack.x ubuntu:18.04</span>\n# <span class=\"pl-s1\">apt update <span class=\"pl-k\">&amp;&amp;</span> apt install fuse <span class=\"pl-c\"><span class=\"pl-c\">#</span> install fusermount</span></span>\n# <span class=\"pl-s1\">spack.x --version</span></pre></div>\n<h2>\n<a id=\"user-content-running-an-executable-shipped-with-spackx-directly\" class=\"anchor\" href=\"#running-an-executable-shipped-with-spackx-directly\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Running an executable shipped with spack.x directly</h2>\n<p>If you want to run an executable shipped with <code>spack.x</code> directly instead\nof invoking spack (the default entrypoint), try this:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">NO_ENTRYPOINT= spack.x which python</span>\n<span class=\"pl-c1\">/tmp/.mount_spack.h0zr1h/view/bin/python</span></pre></div>\n<hr>\n<h2>\n<a id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\" href=\"#how-do-i-build-spackx-myself\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How do I build spack.x myself?</h2>\n<p>Initially you may need docker to get a rootfs filesystem for centos 7.</p>\n<p>Building goes like this:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre><span class=\"pl-c1\">make rootfs-with-spack</span>\n<span class=\"pl-c1\">make</span></pre></div>\n<p>You'll find the output in</p>\n<pre><code>build/output\n</code></pre>\n",
        "stargazers_count": 8,
        "subscribers_count": 1,
        "topics": [
            "spack",
            "squashfs",
            "libfuse"
        ],
        "updated_at": 1621562669.0
    },
    {
        "data_format": 2,
        "description": "[Experimental] AMReX Python Bindings",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "AMReX-Codes/pyamrex",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-pyamrex\" class=\"anchor\" href=\"#pyamrex\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>pyAMReX</h1>\n<p><a href=\"https://www.python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\" alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\" style=\"max-width:100%;\"></a> <a href=\"https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e\" alt=\"Python3 API: Pre-Alpha\" title=\"Status: Pre-Alpha\" data-canonical-src=\"https://img.shields.io/badge/phase-pre--alpha-yellowgreen\" style=\"max-width:100%;\"></a>\n<a href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License AMReX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width:100%;\"></a><br>\n<a href=\"https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development\" alt=\"linux\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development\" alt=\"macos\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development\" alt=\"windows\" style=\"max-width:100%;\"></a></p>\n<p>pyAMReX is part of AMReX.</p>\n<p>Due to its <strong>highly experimental</strong> nature, we develop it currently in a separate respository.</p>\n<p>We will add further information here once first development versions are ready for testing.</p>\n<h2>\n<a id=\"user-content-users\" class=\"anchor\" href=\"#users\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Users</h2>\n<p><em>to do</em></p>\n<ul>\n<li>pip/pypa</li>\n<li>conda-forge</li>\n<li>spack</li>\n<li>brew</li>\n<li>...</li>\n</ul>\n<h3>\n<a id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h3>\n<p><em>to do</em></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">amrex</span>\n\n<span class=\"pl-s1\">small_end</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">amrex</span>.<span class=\"pl-v\">Int_Vect</span>()\n<span class=\"pl-s1\">big_end</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">amrex</span>.<span class=\"pl-v\">Int_Vect</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>)\n\n<span class=\"pl-s1\">b</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">amrex</span>.<span class=\"pl-v\">Box</span>(<span class=\"pl-s1\">small_end</span>, <span class=\"pl-s1\">big_end</span>)\n<span class=\"pl-en\">print</span>(<span class=\"pl-s1\">b</span>)\n\n<span class=\"pl-c\"># ...</span></pre></div>\n<h2>\n<a id=\"user-content-developers\" class=\"anchor\" href=\"#developers\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Developers</h2>\n<p>If you are new to CMake, <a href=\"https://hsf-training.github.io/hsf-training-cmake-webpage/\" rel=\"nofollow\">this short tutorial</a> from the HEP Software foundation is the perfect place to get started with it.</p>\n<p>If you just want to use CMake to build the project, jump into sections <em>1. Introduction</em>, <em>2. Building with CMake</em> and <em>9. Finding Packages</em>.</p>\n<h3>\n<a id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dependencies</h3>\n<p>pyAMReX depends on the following popular third party software.</p>\n<ul>\n<li>a mature <a href=\"https://en.wikipedia.org/wiki/C%2B%2B14\" rel=\"nofollow\">C++14</a> compiler: e.g. g++ 5.0+, clang 5.0+, VS 2017+</li>\n<li><a href=\"https://cmake.org\" rel=\"nofollow\">CMake 3.18.0+</a></li>\n<li>\n<a href=\"https://amrex-codes.github.io\" rel=\"nofollow\">AMReX <em>development</em></a>: we automatically download and compile a copy of AMReX</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11/\">pybind11</a> 2.6.2+: we automatically download and compile a copy of pybind11 (<a href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)\n<ul>\n<li>\n<a href=\"https://python.org\" rel=\"nofollow\">Python</a> 3.6+</li>\n<li>\n<a href=\"https://numpy.org\" rel=\"nofollow\">Numpy</a> 1.15+</li>\n</ul>\n</li>\n</ul>\n<p>Optional dependencies include:</p>\n<ul>\n<li>\n<a href=\"https://www.openmp.org\" rel=\"nofollow\">mpi4py</a> 2.1+: for multi-node and/or multi-GPU execution</li>\n<li>\n<a href=\"https://ccache.dev\" rel=\"nofollow\">CCache</a>: to speed up rebuilds (needs 3.7.9+ for CUDA)</li>\n<li>further <a href=\"https://github.com/AMReX-Codes/amrex/\">optional dependencies of AMReX</a>\n</li>\n<li>\n<a href=\"https://docs.pytest.org/en/stable/\" rel=\"nofollow\">pytest</a> 6.2+: for running unit tests</li>\n</ul>\n<h3>\n<a id=\"user-content-install-dependencies\" class=\"anchor\" href=\"#install-dependencies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Install Dependencies</h3>\n<p>macOS/Linux:</p>\n<div class=\"highlight highlight-source-shell\"><pre>spack env activate -d <span class=\"pl-c1\">.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> spack add cuda</span>\nspack install</pre></div>\n<p>(in new terminals, re-activate the environment with <code>spack env activate -d .</code> again)</p>\n<p>or macOS/Linux:</p>\n<div class=\"highlight highlight-source-shell\"><pre>brew update\nbrew install ccache cmake libomp mpi4py numpy open-mpi python</pre></div>\n<p>Now, <code>cmake --version</code> should be at version 3.18.0 or newer.</p>\n<p>Or go:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                                    --user</span>\npython3 -m pip install -U pip setuptools wheel\npython3 -m pip install -U cmake</pre></div>\n<p>If you wish to run unit tests, then please install <code>pytest</code></p>\n<div class=\"highlight highlight-source-shell\"><pre>python3 -m pip install -U pytest</pre></div>\n<h3>\n<a id=\"user-content-configure-your-compiler\" class=\"anchor\" href=\"#configure-your-compiler\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Configure your compiler</h3>\n<p>For example, using the Clang compiler:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> CC=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which clang<span class=\"pl-pds\">)</span></span>\n<span class=\"pl-k\">export</span> CXX=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which clang++<span class=\"pl-pds\">)</span></span></pre></div>\n<p>If you also want to select a CUDA compiler:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> CUDACXX=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which nvcc<span class=\"pl-pds\">)</span></span>\n<span class=\"pl-k\">export</span> CUDAHOSTCXX=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span>which clang++<span class=\"pl-pds\">)</span></span></pre></div>\n<h3>\n<a id=\"user-content-build--test\" class=\"anchor\" href=\"#build--test\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build &amp; Test</h3>\n<p>From the base of the pyAMReX source directory, execute:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional controls (example):</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>export AMREX_SPACEDIM=3</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>export AMREX_MPI=ON</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>export AMREX_OMP=ON</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>export AMREX_GPU_BACKEND=CUDA</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>export AMREX_SRC=$PWD/../amrex</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>export CMAKE_BUILD_PARALLEL_LEVEL=8</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                 --force-reinstall --user</span>\npython3 -m pip install -v <span class=\"pl-c1\">.</span></pre></div>\n<p>On successful installation, you can run the unit tests (assuming <code>pytest</code> is\ninstalled). If <code>AMREX_MPI=ON</code>, then please prepend the following commands with <code>mpiexec -np &lt;NUM_PROCS&gt;</code></p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Run all tests </span>\npython -m pytest tests/\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run tests from a single file</span>\npython -m pytest tests/test_intvect.py\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run a single test (useful during debugging)</span>\npython -m pytest tests/test_intvect.py::test_iv_conversions</pre></div>\n<p>If you are iterating on C++ builds, it might be faster to just call CMake:</p>\n<div class=\"highlight highlight-source-shell\"><pre>cmake -S <span class=\"pl-c1\">.</span> -B build\ncmake --build build -j 8  <span class=\"pl-c\"><span class=\"pl-c\">#</span> repeat this step to fix compile errors</span></pre></div>\n<h3>\n<a id=\"user-content-build-options\" class=\"anchor\" href=\"#build-options\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build Options</h3>\n<p>If you are using the pip-driven install, selected <a href=\"https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake\" rel=\"nofollow\">AMReX CMake options</a> can be controlled with environment variables:</p>\n<table>\n<thead>\n<tr>\n<th>Environment Variable</th>\n<th>Default &amp; Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>AMREX_OMP</code></td>\n<td>ON/<strong>OFF</strong>\n</td>\n<td>Enable OpenMP</td>\n</tr>\n<tr>\n<td><code>AMREX_GPU_BACKEND</code></td>\n<td>\n<strong>NONE</strong>/SYCL/CUDA/HIP</td>\n<td>On-node, accelerated GPU backend</td>\n</tr>\n<tr>\n<td><code>AMREX_MPI</code></td>\n<td>ON/<strong>OFF</strong>\n</td>\n<td>Enable MPI</td>\n</tr>\n<tr>\n<td><code>AMREX_PRECISION</code></td>\n<td>SINGLE/<strong>DOUBLE</strong>\n</td>\n<td>Precision of AMReX Real type</td>\n</tr>\n<tr>\n<td><code>AMREX_SPACEDIM</code></td>\n<td>1/2/<strong>3</strong>\n</td>\n<td>Dimension of AMReX</td>\n</tr>\n<tr>\n<td><code>AMREX_BUILD_SHARED_LIBS</code></td>\n<td>ON/<strong>OFF</strong>\n</td>\n<td>Build the core AMReX library as shared library</td>\n</tr>\n<tr>\n<td><code>AMREX_SRC</code></td>\n<td><em>None</em></td>\n<td>Absolute path to AMReX source directory (preferred if set)</td>\n</tr>\n<tr>\n<td><code>AMREX_REPO</code></td>\n<td><code>https://github.com/AMReX-Codes/amrex.git</code></td>\n<td>Repository URI to pull and build AMReX from</td>\n</tr>\n<tr>\n<td><code>AMREX_BRANCH</code></td>\n<td><code>development</code></td>\n<td>Repository branch for <code>AMREX_REPO</code>\n</td>\n</tr>\n<tr>\n<td><code>AMREX_INTERNAL</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>Needs a pre-installed AMReX library if set to <code>OFF</code>\n</td>\n</tr>\n<tr>\n<td><code>AMREX_LIBDIR</code></td>\n<td>\n<em>None</em>         (note: not yet implemented)</td>\n<td>If set, search for pre-built AMReX C++ libraries (see below)</td>\n</tr>\n<tr>\n<td><code>CMAKE_BUILD_PARALLEL_LEVEL</code></td>\n<td>2</td>\n<td>Number of parallel build threads</td>\n</tr>\n</tbody>\n</table>\n<p>For example, one can also build against a local AMReX copy.\nAssuming AMReX' source is located in <code>$HOME/src/amrex</code>, then <code>export AMREX_SRC=$HOME/src/amrex</code>.</p>\n<p>Or as a one-liner, assuming your AMReX source directory is located in <code>../amrex</code>:</p>\n<div class=\"highlight highlight-source-shell\"><pre>AMREX_SRC=<span class=\"pl-smi\">$PWD</span>/../amrex python3 -m pip install -v --force-reinstall <span class=\"pl-c1\">.</span></pre></div>\n<p>Note that you need to use absolute paths for external source trees, because pip builds in a temporary directory.</p>\n<p>Or build against an AMReX feature branch of a colleague.\nAssuming your colleague pushed AMReX to <code>https://github.com/WeiqunZhang/amrex/</code> in a branch <code>new-feature</code> then</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">unset</span> AMREX_SRC  <span class=\"pl-c\"><span class=\"pl-c\">#</span> preferred if set</span>\nAMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3 -m pip install -v --force-reinstall <span class=\"pl-c1\">.</span></pre></div>\n<p>You can speed up the install further if you pre-install AMReX, e.g. with a package manager.\nSet <code>AMREX_INTERNAL=OFF</code> and add installation prefix of AMReX to the environment variable <a href=\"https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html\" rel=\"nofollow\">CMAKE_PREFIX_PATH</a>.\nPlease see the <a href=\"#Developers\">short CMake tutorial that we linked above</a> if this sounds new to you.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>pyAMReX Copyright (c) 2021, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.</p>\n<p>If you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab's Innovation &amp; Partnerships Office at\n<a href=\"mailto:IPO@lbl.gov\">IPO@lbl.gov</a>.</p>\n<p>NOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.</p>\n<p>License for pyamrex can be found at <a href=\"LICENSE\">LICENSE</a>.</p>\n",
        "stargazers_count": 8,
        "subscribers_count": 15,
        "topics": [
            "amrex",
            "python"
        ],
        "updated_at": 1618453857.0
    },
    {
        "data_format": 2,
        "description": "E4S Spack environments and container recipes",
        "filenames": [
            "spack-sdk-environments/tools_and_technology/spack.yaml",
            "docker-recipes/rhel7-runner-x86_64/spack.yaml",
            "spack-sdk-environments/compilers_and_support/spack.yaml",
            "docker-recipes/rhel8-runner-ppc64le/spack.yaml",
            "spack-sdk-environments/visualization_analysis_reduction/spack.yaml",
            "spack-sdk-environments/pmr_core/spack.yaml",
            "spack-sdk-environments/xsdk/spack.yaml",
            "spack-sdk-environments/data-mgmt_io-services_checkpoint-restart/spack.yaml",
            "spack-sdk-environments/e4s_ecosystem/spack.yaml",
            "docker-recipes/rhel8-runner-x86_64/spack.yaml",
            "docker-recipes/superlu-sc/spack.yaml",
            "docker-recipes/rhel7-runner-ppc64le/spack.yaml"
        ],
        "full_name": "UO-OACISS/e4s",
        "latest_release": null,
        "readme": "<p>This is a collection of configurations for building ECP SDK\ncontainers with combinations of packages, including the full\nE4S set.</p>\n<p>These are the set of stacks that are targeted for the first release:</p>\n<p><a href=\"figures/SDKdefinition1.png\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"figures/SDKdefinition1.png\" alt=\"SDK definitions\" style=\"max-width:100%;\"></a></p>\n<p>The configuration files for each container platform will be specified under each directory.  For example, the Docker configurations are under the \"docker\" subdirectory.  Each subdirectory will have a README.md file to explain how to build the container image for each stack.</p>\n",
        "stargazers_count": 11,
        "subscribers_count": 4,
        "topics": [],
        "updated_at": 1621369941.0
    },
    {
        "data_format": 2,
        "description": "Standalone Spack Tutorial Repository",
        "filenames": [
            "outputs/stacks/examples/3.spack.yaml.example",
            "outputs/stacks/examples/4.spack.yaml.example",
            "outputs/stacks/examples/1.spack.yaml.example",
            "outputs/stacks/examples/5.spack.yaml.example",
            "outputs/stacks/examples/6.spack.yaml.example",
            "outputs/stacks/examples/3.1.spack.yaml.example",
            "outputs/stacks/examples/2.spack.yaml.example",
            "outputs/stacks/examples/0.spack.yaml.example"
        ],
        "full_name": "spack/spack-tutorial",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content--spack-tutorial\" class=\"anchor\" href=\"#-spack-tutorial\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a01512f4480c4615a82f2b929789547a60d78e1f68d26be1a56e33d9258735d4/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\" width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\" style=\"max-width:100%;\"></a> Spack Tutorial</h1>\n<p><a href=\"https://spack-tutorial.readthedocs.io\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f38d9ceff55c2a7fea5d61861aa91b64fe00c220b83af1fd8af46da42ede70f5/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2d7475746f7269616c2f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack-tutorial/badge/?version=latest\" style=\"max-width:100%;\"></a></p>\n<p>Spack is a multi-platform package manager that builds and installs multiple versions and configurations of software. It works on Linux, macOS, and many supercomputers. Spack is non-destructive: installing a new version of a package does not break existing installations, so many configurations of the same package can coexist.</p>\n<p>This repository houses Spack's <a href=\"https://spack-tutorial.readthedocs.io/en/latest/\" rel=\"nofollow\"><strong>hands-on tutorial</strong></a>, which is a subset of Spack's <a href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"><strong>full documentation</strong></a> (or you can run <code>spack help</code> or <code>spack help --all</code>).</p>\n<p>This tutorial covers basic to advanced usage, packaging, developer features, and large HPC deployments.  You can do all of the exercises on your own laptop using a Docker container. Feel free to use these materials to teach users at your organization about Spack.</p>\n<h2>\n<a id=\"user-content-updating-the-tutorial\" class=\"anchor\" href=\"#updating-the-tutorial\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Updating the tutorial</h2>\n<ol>\n<li>Create a new branch named for the event/milestone that corresponds to the new version you want to create.</li>\n<li>Upload screen shot of first slide (244px wide, .png) to <a href=\"https://github.com/spack/spack-tutorial/tree/master/tutorial/images\">images directory</a> following existing file-naming convention.</li>\n<li>Upload PDF of slide deck to <a href=\"https://github.com/spack/spack-tutorial/tree/master/_static/slides\">slides directory</a> following existing file-naming convention.</li>\n<li>Update <a href=\"https://github.com/spack/spack-tutorial/blob/master/index.rst\">index.rst</a> with event name and date; full citation; and file paths for image and PDF.</li>\n<li>Update this README (lines 3 and 7) with link to new version's URL.</li>\n<li>Build docs locally.</li>\n<li>Push changes to GitHub and active new tag/version on Read the Docs.</li>\n<li>Build new version on Read the Docs.</li>\n</ol>\n<h2>\n<a id=\"user-content-updating-the-tutorial-container\" class=\"anchor\" href=\"#updating-the-tutorial-container\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Updating the tutorial container</h2>\n<p>The spack tutorial container is built from another <a href=\"https://github.com/spack/spack-tutorial-container\">repository</a> by an automated process.  For instructions on how to create an updated version of the tutorial container, see these <a href=\"https://github.com/spack/spack-tutorial-container/blob/master/UPDATING.md\">instructions</a>.  For a general description of the automated process used to build the tutorial container, read the <a href=\"https://github.com/spack/spack-tutorial-container/blob/master/DESCRIPTION.md\">description</a>.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed under the terms of both the MIT license and the Apache License (Version 2.0). Users may choose either license, at their option.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0 licenses.</p>\n<p>See <a href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\">LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\">LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack/blob/develop/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n",
        "stargazers_count": 13,
        "subscribers_count": 25,
        "topics": [],
        "updated_at": 1620598826.0
    },
    {
        "data_format": 2,
        "description": "Simplified Interface to Complex Memory",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "lanl/SICM",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-sicm\" class=\"anchor\" href=\"#sicm\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>SICM</h1>\n<p>Simplified Interface to Complex Memory</p>\n<p><a href=\"https://travis-ci.org/lanl/SICM\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b4e22f8e448f14a1f55a390ccbc015fe4d1758f0136c8329e78e74f2ce920e40/68747470733a2f2f7472617669732d63692e6f72672f6c616e6c2f5349434d2e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/lanl/SICM.svg?branch=master\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-introduction\" class=\"anchor\" href=\"#introduction\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Introduction</h2>\n<p>This project is split into two interfaces: <code>low</code> and <code>high</code>.</p>\n<p>The <code>low</code> interface provides a minimal interface for application wanting to\nmanage their own memory on heterogeneous memory tiers. It also provides an\narena allocator that application developers can use to create <code>jemalloc</code> arenas\non different memory tiers and allocate to those tiers.</p>\n<p>The <code>high</code> interface attempts to automatically manage the memory tiers for the\napplication. It provides an LLVM compiler pass (and compiler wrappers) to\nautomatically transform applications to make the appropriate <code>high</code> interface\ncalls, as well as a runtime library which provides profiling for the\napplication.  The profiling is currently meant to be used offline; that is,\nafter enabling the profiling for an application run, the results are printed\nout at the end of the run, and that information must be fed into a second run\nto make use of it. An online approach is planned.</p>\n<h2>\n<a id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<p>The only dependencies that you will need for the low-level interface\nare <code>libnuma</code> and <code>jemalloc</code>. We require that <code>jemalloc</code> be\nconfigured with the <code>je_</code> prefix (using the <code>--with-jemalloc-prefix</code> flag).\n<code>CMake</code> will use <code>pkg-config</code> to find <code>jemalloc</code>.</p>\n<p>For the high-level interface, you need an installation of LLVM. LLVM 4.0 and\nlater have been tested, although 3.9 may possibly work. For the profiling, you\nwill also need an installation of <code>libpfm</code>, which is a small helper library for\n<code>perf</code> that is available on most distributions.</p>\n<p>Additionally, several other packages are required, and can be installed through a package manager:</p>\n<h3>\n<a id=\"user-content-binaries\" class=\"anchor\" href=\"#binaries\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Binaries</h3>\n<ul>\n<li>A modern C compiler</li>\n<li>A modern C++ compiler</li>\n<li>A modern Fortran compiler</li>\n<li>CMake 3.0+</li>\n<li>Make</li>\n<li>numactl</li>\n<li>automake + friends (if jemalloc needs to be built)</li>\n</ul>\n<h3>\n<a id=\"user-content-development-libraries\" class=\"anchor\" href=\"#development-libraries\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Development Libraries</h3>\n<p>These packages are usually named <code>lib*-dev</code> or <code>lib*-devel</code>:</p>\n<ul>\n<li>numa</li>\n</ul>\n<p>Additional packages are required for the high level interface:</p>\n<ul>\n<li>hwloc</li>\n<li>llvm</li>\n<li>omp (if OpenMP is not available by default on your compilers)</li>\n<li>pfm4</li>\n</ul>\n<h2>\n<a id=\"user-content-compilation\" class=\"anchor\" href=\"#compilation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Compilation</h2>\n<pre><code>export PKG_CONFIG_PATH=&lt;jemalloc prefix&gt;/lib/pkgconfig:$PKG_CONFIG_PATH\nmkdir build\ncd build\ncmake .. -DCMAKE_INSTALL_PREFIX=&lt;prefix&gt;\nmake\nmake install\n</code></pre>\n<h2>\n<a id=\"user-content-low-level-api\" class=\"anchor\" href=\"#low-level-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Low-Level API</h2>\n<table>\n<thead>\n<tr>\n<th>Function Name</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>sicm_init</code></td>\n<td>Detects all memory devices on system, returns a list of them.</td>\n</tr>\n<tr>\n<td><code>sicm_fini</code></td>\n<td>Frees up a device list and associated SICM data structures.</td>\n</tr>\n<tr>\n<td><code>sicm_find_device</code></td>\n<td>Return the first device that matches a given type and page size.</td>\n</tr>\n<tr>\n<td><code>sicm_device_alloc</code></td>\n<td>Allocates to a given device.</td>\n</tr>\n<tr>\n<td><code>sicm_device_free</code></td>\n<td>Frees memory on a device.</td>\n</tr>\n<tr>\n<td><code>sicm_can_place_exact</code></td>\n<td>Returns whether or not a device supports exact placement.</td>\n</tr>\n<tr>\n<td><code>sicm_device_alloc_exact</code></td>\n<td>Allocate memory on a device with an exact base address.</td>\n</tr>\n<tr>\n<td><code>sicm_numa_id</code></td>\n<td>Returns the NUMA ID that a device is on.</td>\n</tr>\n<tr>\n<td><code>sicm_device_page_size</code></td>\n<td>Returns the page size of a given device.</td>\n</tr>\n<tr>\n<td><code>sicm_device_eq</code></td>\n<td>Returns if two devices are equal or not.</td>\n</tr>\n<tr>\n<td><code>sicm_move</code></td>\n<td>Moves memory from one device to another.</td>\n</tr>\n<tr>\n<td><code>sicm_pin</code></td>\n<td>Pin the current process to a device's memory.</td>\n</tr>\n<tr>\n<td><code>sicm_capacity</code></td>\n<td>Returns the capacity of a given device.</td>\n</tr>\n<tr>\n<td><code>sicm_avail</code></td>\n<td>Returns the amount of memory available on a given device.</td>\n</tr>\n<tr>\n<td><code>sicm_model_distance</code></td>\n<td>Returns the distance of a given memory device.</td>\n</tr>\n<tr>\n<td><code>sicm_is_near</code></td>\n<td>Returns whether or not a given memory device is nearby the current NUMA node.</td>\n</tr>\n<tr>\n<td><code>sicm_latency</code></td>\n<td>Measures the latency of a memory device.</td>\n</tr>\n<tr>\n<td><code>sicm_bandwidth_linear2</code></td>\n<td>Measures a memory device's linear access bandwidth.</td>\n</tr>\n<tr>\n<td><code>sicm_bandwidth_random2</code></td>\n<td>Measures random access bandwidth of a memory device.</td>\n</tr>\n<tr>\n<td><code>sicm_bandwidth_linear3</code></td>\n<td>Measures the linear bandwidth of a memory device.</td>\n</tr>\n<tr>\n<td><code>sicm_bandwidth_random3</code></td>\n<td>Measures the random access bandwidth of a memory device.</td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-arena-allocator-api\" class=\"anchor\" href=\"#arena-allocator-api\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Arena Allocator API</h2>\n<table>\n<thead>\n<tr>\n<th>Function Name</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>sicm_arenas_list</code></td>\n<td>List all arenas created in the arena allocator.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_create</code></td>\n<td>Create a new arena on the given device.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_destroy</code></td>\n<td>Frees up an arena, deleting all associated data structures.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_set_default</code></td>\n<td>Sets an arena as the default for the current thread.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_get_default</code></td>\n<td>Gets the default arena for the current thread.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_get_device</code></td>\n<td>Gets the device for a given arena.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_set_device</code></td>\n<td>Sets the memory device for a given arena. Moves all allocated memory already allocated to the arena.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_size</code></td>\n<td>Gets the size of memory allocated to the given arena.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_alloc</code></td>\n<td>Allocate to a given arena.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_alloc_aligned</code></td>\n<td>Allocate aligned memory to a given arena.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_realloc</code></td>\n<td>Resize allocated memory to a given arena.</td>\n</tr>\n<tr>\n<td><code>sicm_arena_lookup</code></td>\n<td>Returns which arena a given pointer belongs to.</td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-high-level-interface\" class=\"anchor\" href=\"#high-level-interface\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>High-Level Interface</h2>\n<p>The high-level interface is normally used with the compiler wrappers located in\n<code>bin/</code>. Users should use these wrappers to compile their applications, and a\ncompiler pass will automatically transform the code so that it calls the\nhigh-level interface with the appropriate arguments, including initialization,\ndestruction, and the proper allocation functions. Assuming the high-level\ninterface is linked to the application as a shared library, it automatically\ninitializes itself.  All heap allocation routines are replaced by calls to\n<code>void* sh_alloc(int id, size_t sz)</code>, which associates an ID with a given\nallocation and allocates the memory into an arena with other allocations of\nthat ID.</p>\n<h2>\n<a id=\"user-content-programming-practices\" class=\"anchor\" href=\"#programming-practices\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Programming Practices</h2>\n<ol>\n<li>All blocks use curly braces\n<ul>\n<li>Even one-line blocks</li>\n</ul>\n</li>\n<li>Constants on the left side of <code>==</code>\n<ul>\n<li><code>if(NULL == foo) { ...</code></li>\n</ul>\n</li>\n<li>Functions with no arguments are <code>(void)</code>\n</li>\n<li>No C++-style comments in C code</li>\n<li>No GCC extensions except in GCC-only code</li>\n<li>No C++ code in libraries\n<ul>\n<li>Discouraged in components</li>\n</ul>\n</li>\n<li>Always define preprocessor macros\n<ul>\n<li>Define logicals to 0 or 1 (vs. define or not define)</li>\n<li>Use <code>#if FOO</code>, not <code>#ifdef FOO</code>\n</li>\n</ul>\n</li>\n</ol>\n",
        "stargazers_count": 14,
        "subscribers_count": 18,
        "topics": [],
        "updated_at": 1616211072.0
    },
    {
        "data_format": 2,
        "description": "ForTrilinos provides portable object-oriented Fortran interfaces to Trilinos C++ packages.",
        "filenames": [
            "scripts/spack.yaml"
        ],
        "full_name": "trilinos/ForTrilinos",
        "latest_release": "v2.0.0",
        "readme": "<h1>\n<a id=\"user-content-fortrilinos\" class=\"anchor\" href=\"#fortrilinos\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>ForTrilinos</h1>\n<p><a href=\"https://cloud.cees.ornl.gov/jenkins-ci/job/ForTrilinos-master-continuous\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/857fffb6b672ed62abe998b01a81c3932111fcba10541918cb2f938f414440e6/68747470733a2f2f636c6f75642e636565732e6f726e6c2e676f762f6a656e6b696e732d63692f6275696c645374617475732f69636f6e3f6a6f623d466f725472696c696e6f732d6d61737465722d636f6e74696e756f7573\" alt=\"Build Status\" data-canonical-src=\"https://cloud.cees.ornl.gov/jenkins-ci/buildStatus/icon?job=ForTrilinos-master-continuous\" style=\"max-width:100%;\"></a>\n<a href=\"http://fortrilinos.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e261f09cffcfcbf7e647f541614bf7912e3018ccd3a085f035a1219a854f5867/687474703a2f2f72656164746865646f63732e6f72672f70726f6a656374732f666f727472696c696e6f732f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"http://readthedocs.org/projects/fortrilinos/badge/?version=latest\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/trilinos/ForTrilinos/branch/develop\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fbeea009914f87218441791dba76a1a512b7c287749f94ff47d7b76f49902d23/68747470733a2f2f636f6465636f762e696f2f67682f7472696c696e6f732f466f725472696c696e6f732f6272616e63682f646576656c6f702f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/trilinos/ForTrilinos/branch/develop/graph/badge.svg\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"http://trilinos.org/packages/fortrilinos\" rel=\"nofollow\">ForTrilinos</a> is a part of the <a href=\"http://trilinos.org\" rel=\"nofollow\">Trilinos</a> project and provides object-oriented Fortran interfaces to Trilinos C++ packages.</p>\n<p>This is the new effort to provide Fortran interfaces to Trilinos through\nautomatic code generation using SWIG. The previous effort (ca. 2008-2012) can\nbe obtained by downloading Trilinos releases prior to 12.12. See <a href=\"https://fortrilinos.readthedocs.io/en/latest/install.html#version-compatibility\" rel=\"nofollow\">the\ndocumentation</a> for details on version compatibility.</p>\n<h2>\n<a id=\"user-content-provided-functionality\" class=\"anchor\" href=\"#provided-functionality\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Provided functionality</h2>\n<p>ForTrilinos provides Fortran interfaces for the following capabilities:</p>\n<ul>\n<li>Parameter lists and XML parsers (through Teuchos);</li>\n<li>Distributed linear algebra object including sparse graphs, sparse matrices, and dense vectors (through Tpetra);</li>\n<li>Linear solvers and preconditioners (through Stratimikos, Ifpack2, Belos, MueLu);</li>\n<li>Eigen solvers (through Anasazi).</li>\n</ul>\n<h2>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<ul>\n<li>\n<p><a href=\"https://fortrilinos.readthedocs.org\" rel=\"nofollow\">Documentation</a></p>\n</li>\n<li>\n<p><a href=\"https://trilinos.github.io/ForTrilinos/\" rel=\"nofollow\">Summary</a></p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-installing-fortrilinos\" class=\"anchor\" href=\"#installing-fortrilinos\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing ForTrilinos</h2>\n<p>Please consult the documentation available <a href=\"https://fortrilinos.readthedocs.io/en/latest/install.html\" rel=\"nofollow\">here</a>.</p>\n<h2>\n<a id=\"user-content-questions-bug-reporting-and-issue-tracking\" class=\"anchor\" href=\"#questions-bug-reporting-and-issue-tracking\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Questions, Bug Reporting, and Issue Tracking</h2>\n<p>Questions, bug reporting and issue tracking are provided by GitHub. Please\nreport all bugs by creating a new issue with the bug tag. You can ask\nquestions by creating a new issue with the question tag.</p>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p>We encourage you to contribute to ForTrilinos! Please check out the\n<a href=\"CONTRIBUTING.md\">guidelines</a> about how to proceed.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>ForTrilinos is licensed under a BSD license.</p>\n",
        "stargazers_count": 22,
        "subscribers_count": 10,
        "topics": [
            "trilinos",
            "fortran",
            "swig",
            "scientific-computing"
        ],
        "updated_at": 1617178138.0
    },
    {
        "data_format": 2,
        "description": "Share Spack configuration files with other HPC sites",
        "filenames": [
            "OLCF/e4s-stacks/spack/var/spack/environments/test/spack.yaml",
            "NERSC/cori/e4s-20.10/prod/spack.yaml",
            "NREL/configs/eagle/compilers/spack.yaml",
            "NREL/configs/eagle/utilities/spack.yaml",
            "UOREGON/E4S-Develop/spack-ubuntu18.04-ppc64le.yaml",
            "NREL/configs/rhodes/base/spack.yaml",
            "UOREGON/E4S-Develop/spack-ubuntu20.04-x86_64.yaml",
            "NERSC/cori/e4s-stacks/knl/spack.yaml",
            "NERSC/cori/e4s-stacks/x86/spack.yaml",
            "UOREGON/E4S-Develop/spack-ubuntu20.04-ppc64le.yaml",
            "NREL/configs/rhodes/compilers/spack.yaml",
            "UOREGON/E4S-Develop/spack-rhel8-x86_64.yaml",
            "UOREGON/E4S-Develop/spack-rhel7-x86_64.yaml",
            "NREL/configs/eagle/software/spack.yaml",
            "NREL/configs/rhodes/utilities/spack.yaml",
            "UOREGON/E4S-Develop/spack-ubuntu18.04-x86_64.yaml",
            "UOREGON/E4S-Develop/spack-rhel7-ppc64le.yaml",
            "NREL/configs/eagle/base/spack.yaml",
            "UOREGON/E4S-Develop/spack-rhel8-ppc64le.yaml",
            "NREL/configs/rhodes/software/spack.yaml",
            "NERSC/cori/e4s-20.10/spack.yaml",
            "NERSC/cori/e4s-stacks/hsw/spack.yaml",
            "OLCF/e4s-stacks/etc/spack.yaml"
        ],
        "full_name": "spack/spack-configs",
        "latest_release": null,
        "readme": "<h1>\n<a id=\"user-content-spack-configs\" class=\"anchor\" href=\"#spack-configs\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Spack Configs</h1>\n<p>This is a repository that sites can use to share their configuration\nfiles for Spack.  You can contribute your own configuration files, or\nbrowse around and look at what others have done.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>Spack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.</p>\n<p>All new contributions must be made under both the MIT and Apache-2.0\nlicenses.</p>\n<p>See <a href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-MIT\">LICENSE-MIT</a>,\n<a href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE\">LICENSE-APACHE</a>,\n<a href=\"https://github.com/spack/spack-configs/blob/master/COPYRIGHT\">COPYRIGHT</a>, and\n<a href=\"https://github.com/spack/spack-configs/blob/master/NOTICE\">NOTICE</a> for details.</p>\n<p>SPDX-License-Identifier: (Apache-2.0 OR MIT)</p>\n<p>LLNL-CODE-811652</p>\n",
        "stargazers_count": 28,
        "subscribers_count": 22,
        "topics": [],
        "updated_at": 1621550978.0
    },
    {
        "data_format": 2,
        "description": ":floppy_disk: C++ & Python API for Scientific I/O",
        "filenames": [
            ".github/ci/spack-envs/clang5_nopy_ompi_h5_ad1_ad2_bp3/spack.yaml",
            "spack.yaml",
            ".github/ci/spack-envs/gcc5_py36_ompi_h5_ad1_ad2/spack.yaml",
            ".github/ci/spack-envs/clang5_nopy_nompi_h5/spack.yaml",
            ".github/ci/spack-envs/clang10_nopy_ompi_h5_ad1_ad2/spack.yaml",
            ".github/ci/spack-envs/clangtidy_nopy_ompi_h5_ad1_ad2/spack.yaml"
        ],
        "full_name": "openPMD/openPMD-api",
        "latest_release": "0.13.4",
        "readme": "<h1>\n<a id=\"user-content-c--python-api-for-scientific-io-with-openpmd\" class=\"anchor\" href=\"#c--python-api-for-scientific-io-with-openpmd\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++ &amp; Python API for Scientific I/O with openPMD</h1>\n<p><a href=\"https://github.com/openPMD/openPMD-standard/releases\"><img src=\"https://camo.githubusercontent.com/5957dc11cb68f6705ef9ef6683152c6c4fcc057a24dff340e1e8bada1bee0d01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\" alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://www.openpmd.org/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2d54fa5adcf7ca50d2cdb45823be5064379b613d526fa06f6e193ba2ce616318/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\" alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://gitter.im/openPMD/API\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f551141eea2176c34aa163092549d6fdde9a220d605d6efe9128b024c6e5932b/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\" alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\" style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/lgpl-3.0.html\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4fc8091716dbd967fa2a82eef3d29227110e5081f3128aaa38663e547c24f812/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\" alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.14278/rodare.27\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/104f6901ae04bff8385acc8273bb276ab84656a927a418108b940d09fd6e5d7c/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\" alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\" style=\"max-width:100%;\"></a><br>\n<a href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0d568047fbbd300af56b766d9a4235a20534485f5827194e859d4f5c20e58334/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\" alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\" style=\"max-width:100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/context:cpp\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/63a7f9e783999e3afc03ef38ee82e2048017e4e6d279ff4120ad8b8718480ccd/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f6370702f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\" alt=\"LGTM: C/C++\" data-canonical-src=\"https://img.shields.io/lgtm/grade/cpp/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\" style=\"max-width:100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/context:python\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/5046bf66a4612476a030d38de817c23fa03990183d2d74fa92c5f1379feb5d09/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\" alt=\"LGTM: Python\" data-canonical-src=\"https://img.shields.io/lgtm/grade/python/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\" style=\"max-width:100%;\"></a>\n<a href=\"https://lgtm.com/projects/g/openPMD/openPMD-api/alerts/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/85e32deb8face392eea9bfa2be4da4c11ca7c0f834fa069223fbc63758b68c4f/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f6f70656e504d442f6f70656e504d442d6170693f6c6f676f3d6c67746d266c6f676f57696474683d3138\" alt=\"LGTM: Total alerts\" data-canonical-src=\"https://img.shields.io/lgtm/alerts/g/openPMD/openPMD-api?logo=lgtm&amp;logoWidth=18\" style=\"max-width:100%;\"></a>\n<a href=\"https://coveralls.io/github/openPMD/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f0487a8fc14d269210ae8ce80b556d4afcd93684f02e61386d2d02daa4423cbd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\" style=\"max-width:100%;\"></a><br>\n<a href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8f438ca4eaa308f982d0a28c48f05bf63ca1a86e52c3d2817f6d7559d1dee68e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\" style=\"max-width:100%;\"></a>\n<a href=\"https://travis-ci.com/openPMD/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8278d89e3634e25a818a2d673fe997c2aa5a09fd5995f716aeffa743388030ee/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\" alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\" style=\"max-width:100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/30679331f3c6a5ae54970eda85f36a30347dee8a9111448d7aa48587fd524a1d/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\" alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"><img src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&amp;event=push\" alt=\"PyPI Wheel Release\" style=\"max-width:100%;\"></a>\n<a href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&amp;branchName=azure_install\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1fc9c860bb1fc8e7e145ea9dd6723b9ac6ac2743c195e5e899f6cfa3d38a5a69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\" alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&amp;label=nightly%20packages\" style=\"max-width:100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0b068d7b5718aafccb46e2ee35f8249938ef189a36ba353c15222ed5e6f65e49/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\" alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\" style=\"max-width:100%;\"></a></p>\n<p>openPMD is an open meta-data schema that provides meaning and self-description for data sets in science and engineering.\nSee <a href=\"https://github.com/openPMD/openPMD-standard\">the openPMD standard</a> for details of this schema.</p>\n<p>This library provides a reference API for openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable, hierarchical file formats, this library implements various backends such as HDF5, ADIOS1, ADIOS2 and JSON.\nWriting &amp; reading through those backends and their associated files is supported for serial and <a href=\"https://www.mpi-forum.org/docs/\" rel=\"nofollow\">MPI-parallel</a> workflows.</p>\n<h2>\n<a id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Usage</h2>\n<h3>\n<a id=\"user-content-c\" class=\"anchor\" href=\"#c\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>C++</h3>\n<p><a href=\"https://isocpp.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/042b5af19c304a2d4f876865d00baa90a284f2d35056ed9728c944befbb07733/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231342d79656c6c6f77677265656e\" alt=\"C++14\" title=\"C++14 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B14-yellowgreen\" style=\"max-width:100%;\"></a> <a href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" alt=\"C++14 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\" style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>openPMD/openPMD.hpp<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> ...</span>\n\n<span class=\"pl-k\">auto</span> s = openPMD::Series(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>samples/git-sample/data%T.h5<span class=\"pl-pds\">\"</span></span>, openPMD::Access::READ_ONLY);\n\n<span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp; i : s.iterations ) {\n    std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Iteration: <span class=\"pl-pds\">\"</span></span> &lt;&lt; i.<span class=\"pl-smi\">first</span> &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp; m : i.<span class=\"pl-smi\">second</span>.<span class=\"pl-smi\">meshes</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>  Mesh '<span class=\"pl-pds\">\"</span></span> &lt;&lt; m.<span class=\"pl-smi\">first</span> &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp; val : m.<span class=\"pl-smi\">second</span>.<span class=\"pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n\n    <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp; p : i.<span class=\"pl-smi\">second</span>.<span class=\"pl-smi\">particles</span> ) {\n        std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>  Particle species '<span class=\"pl-pds\">\"</span></span> &lt;&lt; p.<span class=\"pl-smi\">first</span> &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>' attributes:<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n        <span class=\"pl-k\">for</span>( <span class=\"pl-k\">auto</span> <span class=\"pl-k\">const</span>&amp; val : p.<span class=\"pl-smi\">second</span>.<span class=\"pl-c1\">attributes</span>() )\n            std::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>    <span class=\"pl-pds\">\"</span></span> &lt;&lt; val &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n    }\n}</pre></div>\n<h3>\n<a id=\"user-content-python\" class=\"anchor\" href=\"#python\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Python</h3>\n<p><a href=\"https://www.python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\" alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\" style=\"max-width:100%;\"></a> <a href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\" style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> <span class=\"pl-s1\">openpmd_api</span> <span class=\"pl-k\">as</span> <span class=\"pl-s1\">io</span>\n\n<span class=\"pl-c\"># ...</span>\n\n<span class=\"pl-s1\">series</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Series</span>(<span class=\"pl-s\">\"samples/git-sample/data%T.h5\"</span>, <span class=\"pl-s1\">io</span>.<span class=\"pl-v\">Access</span>.<span class=\"pl-s1\">read_only</span>)\n\n<span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_i</span>, <span class=\"pl-s1\">i</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">series</span>.<span class=\"pl-s1\">iterations</span>.<span class=\"pl-en\">items</span>():\n    <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"Iteration: {0}\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_i</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_m</span>, <span class=\"pl-s1\">m</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">meshes</span>.<span class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Mesh '{0}' attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_m</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">m</span>.<span class=\"pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))\n\n    <span class=\"pl-k\">for</span> <span class=\"pl-s1\">k_p</span>, <span class=\"pl-s1\">p</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">i</span>.<span class=\"pl-s1\">particles</span>.<span class=\"pl-en\">items</span>():\n        <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"  Particle species '{0}' attributes:\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">k_p</span>))\n        <span class=\"pl-k\">for</span> <span class=\"pl-s1\">a</span> <span class=\"pl-c1\">in</span> <span class=\"pl-s1\">p</span>.<span class=\"pl-s1\">attributes</span>:\n            <span class=\"pl-en\">print</span>(<span class=\"pl-s\">\"    {0}\"</span>.<span class=\"pl-en\">format</span>(<span class=\"pl-s1\">a</span>))</pre></div>\n<h3>\n<a id=\"user-content-more\" class=\"anchor\" href=\"#more\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>More!</h3>\n<p>Curious?\nOur manual shows full <a href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\" rel=\"nofollow\">read &amp; write examples</a>, both serial and MPI-parallel!</p>\n<h2>\n<a id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Dependencies</h2>\n<p>Required:</p>\n<ul>\n<li>CMake 3.15.0+</li>\n<li>C++14 capable compiler, e.g. g++ 5.0+, clang 5.0+, VS 2017+</li>\n</ul>\n<p>Shipped internally in <code>share/openPMD/thirdParty/</code>:</p>\n<ul>\n<li>\n<a href=\"https://github.com/mpark/variant\">MPark.Variant</a> 1.4.0+ (<a href=\"https://github.com/mpark/variant/blob/master/LICENSE.md\">BSL-1.0</a>)</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> 2.13.4+ (<a href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\">BSL-1.0</a>)</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> 2.6.2+ (<a href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\">new BSD</a>)</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">NLohmann-JSON</a> 3.9.1+ (<a href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\">MIT</a>)</li>\n</ul>\n<p>I/O backends:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/JSON\" rel=\"nofollow\">JSON</a></li>\n<li>\n<a href=\"https://support.hdfgroup.org/HDF5\" rel=\"nofollow\">HDF5</a> 1.8.13+ (optional)</li>\n<li>\n<a href=\"https://www.olcf.ornl.gov/center-projects/adios\" rel=\"nofollow\">ADIOS1</a> 1.13.1+ (optional)</li>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS2\">ADIOS2</a> 2.7.0+ (optional)</li>\n</ul>\n<p>while those can be built either with or without:</p>\n<ul>\n<li>MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2</li>\n</ul>\n<p>Optional language bindings:</p>\n<ul>\n<li>Python:\n<ul>\n<li>Python 3.6 - 3.9</li>\n<li>pybind11 2.6.2+</li>\n<li>numpy 1.15+</li>\n<li>mpi4py 2.1+ (optional, for MPI)</li>\n<li>pandas 1.0+ (optional, for dataframes)</li>\n<li>dask 2021+ (optional, for dask dataframes)</li>\n</ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/580cdb6331254f66680bd967326d9630f5124291efd5ace18549fbb93cbae6db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\" style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3c3728308a9e416589fa8b3b8168967287c515037bfbd4b40f1b14f266de56fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/openPMD/homebrew-openPMD\"><img src=\"https://camo.githubusercontent.com/92b7b7bb69b2b17d1981ae5fdcdb32f971ee57f54a98ea4804e93fd0a2eb58ef/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\" style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4eeb2c48c0e554ea8dbe8e90f73a6f2d217e775e0bd5e5cb90ddf4619ef3a6a0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\" style=\"max-width:100%;\"></a>\n<a href=\"https://cmake.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2babf79954ea524c24f2f9b1cfa05728fdaccbe0a80c2da6a7a7595cc131894c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\" alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\" style=\"max-width:100%;\"></a></p>\n<p>Our community loves to help each other.\nPlease <a href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install&amp;template=install_problem.md\">report installation problems</a> in case you should get stuck.</p>\n<p>Choose <em>one</em> of the install methods below to get started:</p>\n<h3>\n<a id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://spack.io\" rel=\"nofollow\">Spack</a>\n</h3>\n<p><a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/becffbecb6a50502286f02ec86c4e62f239f3671148d11341152e0dc695a2fc9/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\" alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\" style=\"max-width:100%;\"></a>\n<a href=\"https://spack.io\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\" alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b29fc54abf92a2a6d1d2c70159eb276df53b67a1294ae3f82b1b0bf22a3c586b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\" alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\" style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:               +python +adios1 -adios2 -hdf5 -mpi</span>\nspack install openpmd-api\nspack load -r openpmd-api</pre></div>\n<h3>\n<a id=\"user-content-conda\" class=\"anchor\" href=\"#conda\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://conda.io\" rel=\"nofollow\">Conda</a>\n</h3>\n<p><a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/3ad2b345bb3589aa2d733ca20df72938ed54a48342b69f7cbe9eacab43d84549/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\" style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\" alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\" style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a51d3cd2bfa3c6b01bd0f2e36abc206fb9db5700105fac2acd2c2105fced2ec4/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\" alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\" style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                      OpenMPI support  =*=mpi_openmpi*</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                        MPICH support  =*=mpi_mpich*</span>\nconda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd</pre></div>\n<h3>\n<a id=\"user-content-brew\" class=\"anchor\" href=\"#brew\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://brew.sh\" rel=\"nofollow\">Brew</a>\n</h3>\n<p><a href=\"https://github.com/openPMD/homebrew-openPMD\"><img src=\"https://camo.githubusercontent.com/d873c8c473fece8abf1c34a8299a50b7ee0da9772eb50cce8649e7ca32468a6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\" alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\" style=\"max-width:100%;\"></a>\n<a href=\"https://docs.brew.sh/Homebrew-on-Linux\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\" alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://brew.sh\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7b767b67facc26db7d850ae5c3155fa949048991dde7a0f5471c1e6862f0a586/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\" alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\" style=\"max-width:100%;\"></a></p>\n<div class=\"highlight highlight-source-shell\"><pre>brew tap openpmd/openpmd\nbrew install openpmd-api</pre></div>\n<h3>\n<a id=\"user-content-pypi\" class=\"anchor\" href=\"#pypi\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a>\n</h3>\n<p><a href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fc28bd368523d0b8adab5f4b414aebb304743130eef42bca203f4e9eed428ae7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\" alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\" style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api/#files\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\" alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\" style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7cef25e887c028f65d5d7e20f3e7abe394ab328ecb499e34e47460afd2c78558/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\" alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\" style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/82acdd95515851a5ba4a3006871151f76cfe4d6583f6c24e80bd0fd29d391845/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\" alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\" style=\"max-width:100%;\"></a></p>\n<p>On very old macOS versions (&lt;10.9) or on exotic processor architectures, this install method <em>compiles from source</em> against the found installations of HDF5, ADIOS1, ADIOS2, and/or MPI (in system paths, from other package managers, or loaded via a module system, ...).</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> we need pip 19 or newer</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                   --user</span>\npython3 -m pip install -U pip\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                        --user</span>\npython3 -m pip install openpmd-api</pre></div>\n<p>If MPI-support shall be enabled, we always have to recompile:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                                    --user</span>\npython3 -m pip install -U pip setuptools wheel\npython3 -m pip install -U cmake\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                                                                   --user</span>\nopenPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n<p>For some exotic architectures and compilers, you might need to disable a compiler feature called <a href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\" rel=\"nofollow\">link-time/interprocedural optimization</a> if you encounter linking problems:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional:                                                --user</span>\npython3 -m pip install openpmd-api --no-binary openpmd-api</pre></div>\n<h3>\n<a id=\"user-content-from-source\" class=\"anchor\" href=\"#from-source\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>From Source</h3>\n<p><a href=\"https://cmake.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0a40953107090abff3b564ec3436668756b873cd4d9e021738a046781a5a0e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\" alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\" style=\"max-width:100%;\"></a></p>\n<p>openPMD-api can also be built and installed from source using <a href=\"https://cmake.org/\" rel=\"nofollow\">CMake</a>:</p>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https://github.com/openPMD/openPMD-api.git\n\nmkdir openPMD-api-build\n<span class=\"pl-c1\">cd</span> openPMD-api-build\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: for full tests, with unzip</span>\n../openPMD-api/share/openPMD/download_samples.sh\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> for own install prefix append:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DCMAKE_INSTALL_PREFIX=$HOME/somepath</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> for options append:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_...=...</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> e.g. for python support add:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   -DopenPMD_USE_PYTHON=ON</span>\ncmake ../openPMD-api\n\ncmake --build <span class=\"pl-c1\">.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optional</span>\nctest\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sudo might be required for system paths</span>\ncmake --build <span class=\"pl-c1\">.</span> --target install</pre></div>\n<p>The following options can be added to the <code>cmake</code> call to control features.\nCMake controls options with prefixed <code>-D</code>, e.g. <code>-DopenPMD_USE_MPI=OFF</code>:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_MPI</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>Parallel, Multi-Node I/O for clusters</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_HDF5</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>HDF5 backend (<code>.h5</code> files)</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_ADIOS1</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>ADIOS1 backend (<code>.bp</code> files up to version BP3)</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_ADIOS2</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>ADIOS2 backend (<code>.bp</code> files in BP3, BP4 or higher)</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_PYTHON</code></td>\n<td>\n<strong>AUTO</strong>/ON/OFF</td>\n<td>Enable Python bindings</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INVASIVE_TESTS</code></td>\n<td>ON/<strong>OFF</strong>\n</td>\n<td>Enable unit tests that modify source code <sup>1</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_VERIFY</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>Enable internal VERIFY (assert) macro independent of build type <sup>2</sup>\n</td>\n</tr>\n<tr>\n<td><code>openPMD_INSTALL</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>Add installation targets</td>\n</tr>\n<tr>\n<td><code>Python_EXECUTABLE</code></td>\n<td>(newest found)</td>\n<td>Path to Python executable</td>\n</tr>\n</tbody>\n</table>\n<p><sup>1</sup> <em>e.g. changes C++ visibility keywords, breaks MSVC</em>\n<sup>2</sup> <em>this includes most pre-/post-condition checks, disabling without specific cause is highly discouraged</em></p>\n<p>Additionally, the following libraries are shipped internally.\nThe following options allow to switch to external installs:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n<th>Library</th>\n<th>Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_USE_INTERNAL_VARIANT</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>MPark.Variant</td>\n<td>1.4.0+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_CATCH</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>Catch2</td>\n<td>2.13.4+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_PYBIND11</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>pybind11</td>\n<td>2.6.2+</td>\n</tr>\n<tr>\n<td><code>openPMD_USE_INTERNAL_JSON</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>NLohmann-JSON</td>\n<td>3.9.1+</td>\n</tr>\n</tbody>\n</table>\n<p>By default, this will build as a shared library (<code>libopenPMD.[so|dylib|dll]</code>) and installs also its headers.\nIn order to build a static library, append <code>-DBUILD_SHARED_LIBS=OFF</code> to the <code>cmake</code> command.\nYou can only build a static or a shared library at a time.</p>\n<p>By default, the <code>Release</code> version is built.\nIn order to build with debug symbols, pass <code>-DCMAKE_BUILD_TYPE=Debug</code> to your <code>cmake</code> command.</p>\n<p>By default, tests, examples and command line tools are built.\nIn order to skip building those, pass <code>OFF</code> to these <code>cmake</code> options:</p>\n<table>\n<thead>\n<tr>\n<th>CMake Option</th>\n<th>Values</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>openPMD_BUILD_TESTING</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>Build tests</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_EXAMPLES</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>Build examples</td>\n</tr>\n<tr>\n<td><code>openPMD_BUILD_CLI_TOOLS</code></td>\n<td>\n<strong>ON</strong>/OFF</td>\n<td>Build command-line tools</td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-linking-to-your-project\" class=\"anchor\" href=\"#linking-to-your-project\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Linking to your project</h2>\n<p>The install will contain header files and libraries in the path set with <code>-DCMAKE_INSTALL_PREFIX</code>.</p>\n<h3>\n<a id=\"user-content-cmake\" class=\"anchor\" href=\"#cmake\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>CMake</h3>\n<p>If your project is using CMake for its build, one can conveniently use our provided <code>openPMDConfig.cmake</code> package which is installed alongside the library.</p>\n<p>First set the following environment hint if openPMD-api was <em>not</em> installed in a system path:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed if installed outside of system paths</span>\n<span class=\"pl-k\">export</span> CMAKE_PREFIX_PATH=<span class=\"pl-smi\">$HOME</span>/somepath:<span class=\"pl-smi\">$CMAKE_PREFIX_PATH</span></pre></div>\n<p>Use the following lines in your project's <code>CMakeLists.txt</code>:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> supports:                       COMPONENTS MPI NOMPI HDF5 ADIOS1 ADIOS2</span>\n<span class=\"pl-c1\">find_package</span>(openPMD 0.9.0 <span class=\"pl-k\">CONFIG</span>)\n\n<span class=\"pl-k\">if</span>(openPMD_FOUND)\n    <span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)\n<span class=\"pl-k\">endif</span>()</pre></div>\n<p><em>Alternatively</em>, add the openPMD-api repository source directly to your project and use it via:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"pl-c1\">add_subdirectory</span>(<span class=\"pl-s\">\"path/to/source/of/openPMD-api\"</span>)\n\n<span class=\"pl-c1\">target_link_libraries</span>(YourTarget <span class=\"pl-k\">PRIVATE</span> openPMD::openPMD)</pre></div>\n<p>For development workflows, you can even automatically download and build openPMD-api from within a depending CMake project.\nJust replace the <code>add_subdirectory</code> call with:</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"pl-c1\">include</span>(FetchContent)\n<span class=\"pl-c1\">set</span>(CMAKE_POLICY_DEFAULT_CMP0077 <span class=\"pl-k\">NEW</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_CLI_TOOLS <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_EXAMPLES <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c1\">set</span>(openPMD_BUILD_TESTING <span class=\"pl-k\">OFF</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> set(openPMD_BUILD_SHARED_LIBS OFF)  # precedence over BUILD_SHARED_LIBS if needed; or:</span>\n<span class=\"pl-c1\">set</span>(openPMD_INSTALL <span class=\"pl-smi\">${BUILD_SHARED_LIBS}</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> only install if used as shared a library</span>\n<span class=\"pl-c1\">set</span>(openPMD_USE_PYTHON <span class=\"pl-k\">OFF</span>)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY <span class=\"pl-s\">\"https://github.com/openPMD/openPMD-api.git\"</span>\n  GIT_TAG        <span class=\"pl-s\">\"dev\"</span>)\nFetchContent_MakeAvailable(openPMD)</pre></div>\n<h3>\n<a id=\"user-content-manually\" class=\"anchor\" href=\"#manually\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Manually</h3>\n<p>If your (Linux/OSX) project is build by calling the compiler directly or uses a manually written <code>Makefile</code>, consider using our <code>openPMD.pc</code> helper file for <code>pkg-config</code> which are installed alongside the library.</p>\n<p>First set the following environment hint if openPMD-api was <em>not</em> installed in a system path:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> optional: only needed if installed outside of system paths</span>\n<span class=\"pl-k\">export</span> PKG_CONFIG_PATH=<span class=\"pl-smi\">$HOME</span>/somepath/lib/pkgconfig:<span class=\"pl-smi\">$PKG_CONFIG_PATH</span></pre></div>\n<p>Additional linker and compiler flags for your project are available via:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> switch to check if openPMD-api was build as static library</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> (via BUILD_SHARED_LIBS=OFF) or as shared library (default)</span>\n<span class=\"pl-k\">if</span> [ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-s\"><span class=\"pl-pds\">$(</span>pkg-config --variable=static openPMD<span class=\"pl-pds\">)</span></span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>true<span class=\"pl-pds\">\"</span></span> ]\n<span class=\"pl-k\">then</span>\n    pkg-config --libs --static openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so</span>\n<span class=\"pl-k\">else</span>\n    pkg-config --libs openPMD\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> -L${HOME}/somepath/lib -lopenPMD</span>\n<span class=\"pl-k\">fi</span>\n\npkg-config --cflags openPMD\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> -I${HOME}/somepath/include</span></pre></div>\n<h2>\n<a id=\"user-content-author-contributions\" class=\"anchor\" href=\"#author-contributions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Author Contributions</h2>\n<p>openPMD-api is developed by many people.\nIt was initially started by the <a href=\"https://hzdr.de/crp\" rel=\"nofollow\">Computational Radiation Physics Group</a> at <a href=\"https://www.hzdr.de/\" rel=\"nofollow\">HZDR</a> as successor to <a href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\">libSplash</a>, generalizing the <a href=\"https://arxiv.org/abs/1706.00522\" rel=\"nofollow\">successful HDF5 &amp; ADIOS1 implementations</a> in <a href=\"https://github.com/ComputationalRadiationPhysics/picongpu\">PIConGPU</a>.\nThe following people and institutions <a href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\">contributed</a> to openPMD-api:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ax3l\">Axel Huebl (HZDR, now LBNL)</a>:\nproject lead, releases, documentation, automated CI/CD, Python bindings, Dask, installation &amp; packaging, prior reference implementations</li>\n<li>\n<a href=\"https://github.com/C0nsultant\">Fabian Koller (HZDR)</a>:\ninitial library design and implementation with HDF5 &amp; ADIOS1 backend</li>\n<li>\n<a href=\"https://github.com/franzpoeschel\">Franz Poeschel (CASUS)</a>:\nadded JSON &amp; ADIOS2 backend, data staging/streaming</li>\n<li>\n<a href=\"https://github.com/guj\">Junmin Gu (LBNL)</a>:\nnon-collective parallel I/O fixes, ADIOS improvements, benchmarks</li>\n</ul>\n<p>Further thanks go to improvements and contributions from:</p>\n<ul>\n<li>\n<a href=\"https://github.com/CFGrote\">Carsten Fortmann-Grote (EU XFEL GmbH, now MPI-EvolBio)</a>:\ndraft of our Python unit tests</li>\n<li>\n<a href=\"https://github.com/StanczakDominik\">Dominik Sta\u0144czak (Warsaw University of Technology)</a>:\ndocumentation improvements</li>\n<li>\n<a href=\"https://github.com/mingwandroid\">Ray Donnelly (Anaconda, Inc.)</a>:\nsupport on conda packaging and libc++ quirks</li>\n<li>\n<a href=\"https://github.com/amundson\">James Amundson (FNAL)</a>:\ncompile fix for newer compilers</li>\n<li>\n<a href=\"https://github.com/psychocoderHPC\">Ren\u00e9 Widera (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n<a href=\"https://github.com/erikzenker\">Erik Zenker (HZDR)</a>:\ndesign improvements for initial API design</li>\n<li>\n<a href=\"https://github.com/sbastrakov\">Sergei Bastrakov (HZDR)</a>:\ndocumentation improvements (windows)</li>\n<li>\n<a href=\"https://github.com/RemiLehe\">R\u00e9mi Lehe (LBNL)</a>:\npackage integration testing on macOS and Linux</li>\n<li>\n<a href=\"https://github.com/LDAmorim\">L\u00edgia Diana Amorim (LBNL)</a>:\npackage integration testing on macOS</li>\n<li>\n<a href=\"https://github.com/KseniaBastrakova\">Kseniia Bastrakova (HZDR)</a>:\ncompatibility testing</li>\n<li>\n<a href=\"https://github.com/PrometheusPi\">Richard Pausch (HZDR)</a>:\ncompatibility testing, documentation improvements</li>\n<li>\n<a href=\"https://github.com/pordyna\">Pawe\u0142 Ordyna (HZDR)</a>:\nreport on NVCC warnings</li>\n<li>\n<a href=\"https://github.com/dmitry-ganyushin\">Dmitry Ganyushin (ORNL)</a>:\nDask dataframe support</li>\n<li>\n<a href=\"https://github.com/jakirkham\">John Kirkham (NVIDIA)</a>:\nDask guidance &amp; reviews</li>\n</ul>\n<h3>\n<a id=\"user-content-grants\" class=\"anchor\" href=\"#grants\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Grants</h3>\n<p>The openPMD-api authors acknowledge support via the following programs.\nThis project has received funding from the European Unions Horizon 2020 research and innovation programme under grant agreement No 654220.\nSupported by the Consortium for Advanced Modeling of Particles Accelerators (CAMPA), funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\nSupported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S. Department of Energy organizations (Office of Science and the National Nuclear Security Administration).\nThis work was partially funded by the Center of Advanced Systems Understanding (CASUS), which is financed by Germany's Federal Ministry of Education and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism (SMWK) with tax funds on the basis of the budget approved by the Saxon State Parliament.</p>\n<h3>\n<a id=\"user-content-transitive-contributions\" class=\"anchor\" href=\"#transitive-contributions\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Transitive Contributions</h3>\n<p>openPMD-api stands on the shoulders of giants and we are grateful for the following projects included as direct dependencies:</p>\n<ul>\n<li>\n<a href=\"https://github.com/ornladios/ADIOS\">ADIOS1</a> and <a href=\"https://github.com/ornladios/ADIOS2\">ADIOS2</a> by <a href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\">S. Klasky (ORNL), team, collaborators</a> and <a href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\">contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/catchorg/Catch2\">Catch2</a> by <a href=\"https://github.com/philsquared\">Phil Nash</a>, <a href=\"https://github.com/horenmar\">Martin Ho\u0159e\u0148ovsk\u00fd</a> and <a href=\"https://github.com/catchorg/Catch2/graphs/contributors\">contributors</a>\n</li>\n<li>HDF5 by <a href=\"https://www.hdfgroup.org\" rel=\"nofollow\">the HDF group</a> and community</li>\n<li>\n<a href=\"https://github.com/nlohmann/json\">json</a> by <a href=\"https://github.com/nlohmann\">Niels Lohmann</a> and <a href=\"https://github.com/nlohmann/json/graphs/contributors\">contributors</a>\n</li>\n<li>\n<a href=\"https://github.com/pybind/pybind11\">pybind11</a> by <a href=\"https://github.com/wjakob\">Wenzel Jakob (EPFL)</a> and <a href=\"https://github.com/pybind/pybind11/graphs/contributors\">contributors</a>\n</li>\n<li>all contributors to the evolution of modern C++ and early library preview developers, e.g. <a href=\"https://github.com/mpark\">Michael Park (Facebook)</a>\n</li>\n<li>the <a href=\"https://cmake.org\" rel=\"nofollow\">CMake build system</a> and <a href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\">contributors</a>\n</li>\n<li>packaging support by the <a href=\"https://conda-forge.org\" rel=\"nofollow\">conda-forge</a>, <a href=\"https://pypi.org\" rel=\"nofollow\">PyPI</a> and <a href=\"https://spack.io\" rel=\"nofollow\">Spack</a> communities, among others</li>\n<li>the <a href=\"https://github.com/openPMD/openPMD-standard\">openPMD-standard</a> by <a href=\"https://github.com/ax3l\">Axel Huebl (HZDR, now LBNL)</a> and <a href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\">contributors</a>\n</li>\n</ul>\n",
        "stargazers_count": 65,
        "subscribers_count": 9,
        "topics": [
            "openpmd",
            "openscience",
            "hdf5",
            "adios",
            "mpi",
            "hpc",
            "research",
            "file-handling",
            "python3",
            "meta-data",
            "opendata",
            "cpp14"
        ],
        "updated_at": 1621566977.0
    },
    {
        "data_format": 2,
        "description": "A flyweight in situ visualization and analysis runtime for multi-physics HPC simulations",
        "filenames": [
            "scripts/uberenv/spack_envs/llnl/pascal-cuda/spack.yaml",
            "scripts/uberenv/spack_envs/llnl/quartz/spack.yaml",
            "scripts/uberenv/spack_envs/ci/ubuntu_18_devel/spack.yaml",
            "scripts/uberenv/spack_envs/olcf/summit/spack.yaml",
            "scripts/uberenv/spack_envs/ci/ubuntu_18_cuda_10.1_devel/spack.yaml"
        ],
        "full_name": "Alpine-DAV/ascent",
        "latest_release": "v0.7.1",
        "readme": "<h1>\n<a id=\"user-content-ascent\" class=\"anchor\" href=\"#ascent\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Ascent</h1>\n<p>Ascent is an open source many-core capable lightweight in situ visualization and analysis infrastructure for multi-physics HPC simulations.</p>\n<h1>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>To get started building and using Ascent, check out the full documentation:</p>\n<p><a href=\"https://alpine-dav.github.io/ascent/\" rel=\"nofollow\">https://alpine-dav.github.io/ascent/</a></p>\n<h1>\n<a id=\"user-content-source-repo\" class=\"anchor\" href=\"#source-repo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Source Repo</h1>\n<p>Ascent's source is hosted on GitHub:</p>\n<p><a href=\"https://github.com/Alpine-DAV/ascent\">https://github.com/Alpine-DAV/ascent</a></p>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h1>\n<p>Ascent is released under a BSD-style license - for detailed license info, refer to:</p>\n<p><a href=\"http://ascent.readthedocs.io/en/latest/Licenses.html\" rel=\"nofollow\">http://ascent.readthedocs.io/en/latest/Licenses.html</a></p>\n<p>or the following files in the Ascent source tree:</p>\n<ul>\n<li><a href=\"/LICENSE\">LICENSE</a></li>\n</ul>\n<h1>\n<a id=\"user-content-changelog\" class=\"anchor\" href=\"#changelog\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Changelog</h1>\n<ul>\n<li><a href=\"/CHANGELOG.md\">Changelog</a></li>\n</ul>\n",
        "stargazers_count": 79,
        "subscribers_count": 12,
        "topics": [
            "hpc",
            "parallel-computing",
            "cuda",
            "mpi",
            "rendering",
            "analysis",
            "scientific-computing",
            "data-viz",
            "radiuss"
        ],
        "updated_at": 1621557925.0
    },
    {
        "data_format": 2,
        "description": "Simplified Data Exchange for HPC Simulations",
        "filenames": [
            "scripts/uberenv_configs/spack_envs/llnl/quartz/spack.yaml"
        ],
        "full_name": "LLNL/conduit",
        "latest_release": "v0.7.2",
        "readme": "<h1>\n<a id=\"user-content-conduit\" class=\"anchor\" href=\"#conduit\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conduit</h1>\n<p><strong>Conduit: Simplified Data Exchange for HPC Simulations</strong></p>\n<p>Conduit is an open source project from Lawrence Livermore National Laboratory that provides an intuitive model for describing hierarchical scientific data in C++, C, Fortran, and Python. It is used for data coupling between packages in-core, serialization, and I/O tasks.</p>\n<p><a href=\"https://travis-ci.org/LLNL/conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/478365930966f70f879ae04d59ea3f5c5888bee7d2a50e7e281dc1da3cf9aff1/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67\" alt=\"Travis CI Build Status\" data-canonical-src=\"https://travis-ci.org/LLNL/conduit.png\" style=\"max-width:100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/cyrush/conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a0839e4a484ebb633a1c2ebcd90e345a176f5edc60e42f32636eefa9c3c79fad/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565\" alt=\"Appveyor Build Status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop&amp;svg=true\" style=\"max-width:100%;\"></a>\n<a href=\"https://coveralls.io/github/LLNL/conduit?branch=develop\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/50b12c605f0f4bcc64b6db415dddf2de99c5e19a526d7bc53e45db45c95b2931/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop\" style=\"max-width:100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/llnl-conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d4b204e42fe1ef30b166cdfd7cba043d5d74600b343aedd5e094a810b4c5c727/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31\" alt=\"Static Analysis Status\" data-canonical-src=\"https://scan.coverity.com/projects/8426/badge.svg?flat=1\" style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>To get started building and using Conduit, check out the full documentation:</p>\n<p><a href=\"http://llnl-conduit.readthedocs.io/\" rel=\"nofollow\">http://llnl-conduit.readthedocs.io/</a></p>\n<h1>\n<a id=\"user-content-source-repo\" class=\"anchor\" href=\"#source-repo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Source Repo</h1>\n<p>Conduit's source is hosted on GitHub:</p>\n<p><a href=\"https://github.com/llnl/conduit\">https://github.com/llnl/conduit</a></p>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h1>\n<p>Conduit is released under a BSD-style license - for detailed license info, refer to:</p>\n<p><a href=\"https://llnl-conduit.readthedocs.io/en/latest/licenses.html\" rel=\"nofollow\">https://llnl-conduit.readthedocs.io/en/latest/licenses.html</a></p>\n<p>or the following files in the Conduit source tree:</p>\n<ul>\n<li><a href=\"/LICENSE\">LICENSE</a></li>\n<li><a href=\"/thirdparty_licenses.md\">thirdparty_licenses.md</a></li>\n</ul>\n<h1>\n<a id=\"user-content-changelog\" class=\"anchor\" href=\"#changelog\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Changelog</h1>\n<ul>\n<li><a href=\"/CHANGELOG.md\">Changelog</a></li>\n</ul>\n",
        "stargazers_count": 88,
        "subscribers_count": 16,
        "topics": [
            "hpc",
            "scientific-computing",
            "cpp",
            "fortran",
            "python",
            "llnl",
            "json",
            "yaml",
            "hdf5",
            "radiuss",
            "data-management"
        ],
        "updated_at": 1621476188.0
    },
    {
        "data_format": 2,
        "description": "Simplified Data Exchange for HPC Simulations",
        "filenames": [
            "scripts/uberenv_configs/spack_envs/llnl/quartz/spack.yaml"
        ],
        "full_name": "LLNL/conduit",
        "latest_release": "v0.7.2",
        "readme": "<h1>\n<a id=\"user-content-conduit\" class=\"anchor\" href=\"#conduit\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conduit</h1>\n<p><strong>Conduit: Simplified Data Exchange for HPC Simulations</strong></p>\n<p>Conduit is an open source project from Lawrence Livermore National Laboratory that provides an intuitive model for describing hierarchical scientific data in C++, C, Fortran, and Python. It is used for data coupling between packages in-core, serialization, and I/O tasks.</p>\n<p><a href=\"https://travis-ci.org/LLNL/conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/478365930966f70f879ae04d59ea3f5c5888bee7d2a50e7e281dc1da3cf9aff1/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67\" alt=\"Travis CI Build Status\" data-canonical-src=\"https://travis-ci.org/LLNL/conduit.png\" style=\"max-width:100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/cyrush/conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a0839e4a484ebb633a1c2ebcd90e345a176f5edc60e42f32636eefa9c3c79fad/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565\" alt=\"Appveyor Build Status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop&amp;svg=true\" style=\"max-width:100%;\"></a>\n<a href=\"https://coveralls.io/github/LLNL/conduit?branch=develop\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/50b12c605f0f4bcc64b6db415dddf2de99c5e19a526d7bc53e45db45c95b2931/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop\" style=\"max-width:100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/llnl-conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d4b204e42fe1ef30b166cdfd7cba043d5d74600b343aedd5e094a810b4c5c727/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31\" alt=\"Static Analysis Status\" data-canonical-src=\"https://scan.coverity.com/projects/8426/badge.svg?flat=1\" style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>To get started building and using Conduit, check out the full documentation:</p>\n<p><a href=\"http://llnl-conduit.readthedocs.io/\" rel=\"nofollow\">http://llnl-conduit.readthedocs.io/</a></p>\n<h1>\n<a id=\"user-content-source-repo\" class=\"anchor\" href=\"#source-repo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Source Repo</h1>\n<p>Conduit's source is hosted on GitHub:</p>\n<p><a href=\"https://github.com/llnl/conduit\">https://github.com/llnl/conduit</a></p>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h1>\n<p>Conduit is released under a BSD-style license - for detailed license info, refer to:</p>\n<p><a href=\"https://llnl-conduit.readthedocs.io/en/latest/licenses.html\" rel=\"nofollow\">https://llnl-conduit.readthedocs.io/en/latest/licenses.html</a></p>\n<p>or the following files in the Conduit source tree:</p>\n<ul>\n<li><a href=\"/LICENSE\">LICENSE</a></li>\n<li><a href=\"/thirdparty_licenses.md\">thirdparty_licenses.md</a></li>\n</ul>\n<h1>\n<a id=\"user-content-changelog\" class=\"anchor\" href=\"#changelog\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Changelog</h1>\n<ul>\n<li><a href=\"/CHANGELOG.md\">Changelog</a></li>\n</ul>\n",
        "stargazers_count": 88,
        "subscribers_count": 16,
        "topics": [
            "hpc",
            "scientific-computing",
            "cpp",
            "fortran",
            "python",
            "llnl",
            "json",
            "yaml",
            "hdf5",
            "radiuss",
            "data-management"
        ],
        "updated_at": 1621476188.0
    },
    {
        "data_format": 2,
        "description": "Simplified Data Exchange for HPC Simulations",
        "filenames": [
            "scripts/uberenv_configs/spack_envs/llnl/quartz/spack.yaml"
        ],
        "full_name": "LLNL/conduit",
        "latest_release": "v0.7.2",
        "readme": "<h1>\n<a id=\"user-content-conduit\" class=\"anchor\" href=\"#conduit\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Conduit</h1>\n<p><strong>Conduit: Simplified Data Exchange for HPC Simulations</strong></p>\n<p>Conduit is an open source project from Lawrence Livermore National Laboratory that provides an intuitive model for describing hierarchical scientific data in C++, C, Fortran, and Python. It is used for data coupling between packages in-core, serialization, and I/O tasks.</p>\n<p><a href=\"https://travis-ci.org/LLNL/conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/478365930966f70f879ae04d59ea3f5c5888bee7d2a50e7e281dc1da3cf9aff1/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67\" alt=\"Travis CI Build Status\" data-canonical-src=\"https://travis-ci.org/LLNL/conduit.png\" style=\"max-width:100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/cyrush/conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a0839e4a484ebb633a1c2ebcd90e345a176f5edc60e42f32636eefa9c3c79fad/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565\" alt=\"Appveyor Build Status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop&amp;svg=true\" style=\"max-width:100%;\"></a>\n<a href=\"https://coveralls.io/github/LLNL/conduit?branch=develop\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/50b12c605f0f4bcc64b6db415dddf2de99c5e19a526d7bc53e45db45c95b2931/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop\" style=\"max-width:100%;\"></a>\n<a href=\"https://scan.coverity.com/projects/llnl-conduit\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d4b204e42fe1ef30b166cdfd7cba043d5d74600b343aedd5e094a810b4c5c727/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31\" alt=\"Static Analysis Status\" data-canonical-src=\"https://scan.coverity.com/projects/8426/badge.svg?flat=1\" style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h1>\n<p>To get started building and using Conduit, check out the full documentation:</p>\n<p><a href=\"http://llnl-conduit.readthedocs.io/\" rel=\"nofollow\">http://llnl-conduit.readthedocs.io/</a></p>\n<h1>\n<a id=\"user-content-source-repo\" class=\"anchor\" href=\"#source-repo\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Source Repo</h1>\n<p>Conduit's source is hosted on GitHub:</p>\n<p><a href=\"https://github.com/llnl/conduit\">https://github.com/llnl/conduit</a></p>\n<h1>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h1>\n<p>Conduit is released under a BSD-style license - for detailed license info, refer to:</p>\n<p><a href=\"https://llnl-conduit.readthedocs.io/en/latest/licenses.html\" rel=\"nofollow\">https://llnl-conduit.readthedocs.io/en/latest/licenses.html</a></p>\n<p>or the following files in the Conduit source tree:</p>\n<ul>\n<li><a href=\"/LICENSE\">LICENSE</a></li>\n<li><a href=\"/thirdparty_licenses.md\">thirdparty_licenses.md</a></li>\n</ul>\n<h1>\n<a id=\"user-content-changelog\" class=\"anchor\" href=\"#changelog\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Changelog</h1>\n<ul>\n<li><a href=\"/CHANGELOG.md\">Changelog</a></li>\n</ul>\n",
        "stargazers_count": 88,
        "subscribers_count": 16,
        "topics": [
            "hpc",
            "scientific-computing",
            "cpp",
            "fortran",
            "python",
            "llnl",
            "json",
            "yaml",
            "hdf5",
            "radiuss",
            "data-management"
        ],
        "updated_at": 1621476188.0
    },
    {
        "data_format": 2,
        "description": "WarpX is an advanced electromagnetic Particle-In-Cell code.",
        "filenames": [
            "Docs/spack.yaml"
        ],
        "full_name": "ECP-WarpX/WarpX",
        "latest_release": "21.05",
        "readme": "<h1>\n<a id=\"user-content-warpx\" class=\"anchor\" href=\"#warpx\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>WarpX</h1>\n<p><a href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1&amp;branchName=development\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74\" alt=\"Code Status development\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development\" style=\"max-width:100%;\"></a>\n<a href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573\" alt=\"Nightly Installation Tests\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly&amp;label=nightly%20packages\" style=\"max-width:100%;\"></a>\n<a href=\"https://warpx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/warpx/badge/?version=latest\" style=\"max-width:100%;\"></a>\n<a href=\"https://spack.readthedocs.io/en/latest/package_list.html#warpx\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078\" alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/warpx\" style=\"max-width:100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/warpx\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/warpx\" style=\"max-width:100%;\"></a>\n<a href=\"https://gitter.im/ECP-WarpX/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667\" alt=\"Gitter\" data-canonical-src=\"https://badges.gitter.im/ECP-WarpX/community.svg\" style=\"max-width:100%;\"></a><br>\n<a href=\"https://warpx.readthedocs.io/en/latest/install/users.html\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/ECP-WarpX/WarpX/compare/development\"><img src=\"https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667\" alt=\"GitHub commits since last release\" data-canonical-src=\"https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://www.exascaleproject.org/research/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765\" alt=\"Exascale Computing Project\" data-canonical-src=\"https://img.shields.io/badge/supported%20by-ECP-orange\" style=\"max-width:100%;\"></a>\n<a href=\"\"><img src=\"https://camo.githubusercontent.com/8d8c054b6da1ff81634c84041dfe111aec24b166c8ea31edb0ade140ea2c9015/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646576656c6f706d656e742532307374617475732d626574612d6f72616e67652e737667\" alt=\"Development Status\" data-canonical-src=\"https://img.shields.io/badge/development%20status-beta-orange.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://isocpp.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/1a52aaad4dbed7aa6cf7d2e23d60345c14458372f5c090f6210a85bc04727f62/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231342d6f72616e67652e737667\" alt=\"Language: C++14\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B14-orange.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://python.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\" alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\" style=\"max-width:100%;\"></a><br>\n<a href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License WarpX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.5281/zenodo.4571577\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667\" alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://doi.org/10.1063/5.0028512\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/217b9933935ad7327449ffac67bc3cf4c7054f7be207bcc3c43a5a694f81efff/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313036332f352e303032383531322d626c75652e737667\" alt=\"DOI (paper)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(paper)-10.1063/5.0028512-blue.svg\" style=\"max-width:100%;\"></a></p>\n<h2>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h2>\n<p>WarpX is an advanced electromagnetic Particle-In-Cell code.\nIt supports many features including Perfectly-Matched Layers (PML), mesh refinement, and the boosted-frame technique.</p>\n<h2>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p><a href=\"https://picmi-standard.github.io\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICMI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22PICMI%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"https://www.openPMD.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22openPMD%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"https://yt-project.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"yt-project\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22&amp;message=%22yt%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a></p>\n<p>In order to learn how to install and run the code, please see the online documentation:\n<a href=\"https://warpx.readthedocs.io\" rel=\"nofollow\">https://warpx.readthedocs.io</a></p>\n<p>To contact the developers, feel free to open an issue on this repo, or visit our Gitter room at <a href=\"https://gitter.im/ECP-WarpX/community\" rel=\"nofollow\">https://gitter.im/ECP-WarpX/community</a></p>\n<h2>\n<a id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributing</h2>\n<p><a href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22AMReX%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"https://picsar.net\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICSAR\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22PICSAR%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"https://openpmd-api.readthedocs.io\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD-api\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22openPMD-api%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"ADIOS\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22ADIOS%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"https://www.hdfgroup.org/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"HDF5\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22HDF5%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"http://www.ascent-dav.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"Ascent\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22Ascent%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a>\n<a href=\"https://sensei-insitu.org\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"SENSEI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22&amp;message=%22SENSEI%22&amp;color=%22blueviolet%22\" style=\"max-width:100%;\"></a></p>\n<p>Our workflow is described in <a href=\"CONTRIBUTING.rst\">CONTRIBUTING.rst</a>.</p>\n<h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n<p>WarpX Copyright (c) 2018-2021, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.</p>\n<p>If you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab's Innovation &amp; Partnerships Office at\n<a href=\"mailto:IPO@lbl.gov\">IPO@lbl.gov</a>.</p>\n<p>NOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.</p>\n<p>License for WarpX can be found at <a href=\"LICENSE.txt\">LICENSE.txt</a>.</p>\n",
        "stargazers_count": 90,
        "subscribers_count": 15,
        "topics": [
            "laser",
            "plasma",
            "physics",
            "gpu",
            "simulation",
            "particle-in-cell",
            "pic",
            "research"
        ],
        "updated_at": 1621571350.0
    },
    {
        "data_format": 2,
        "description": "File utilities designed for scalability and performance.",
        "filenames": [
            "spack.yaml"
        ],
        "full_name": "hpc/mpifileutils",
        "latest_release": "v0.11",
        "readme": "<h1>\n<a id=\"user-content-mpifileutils\" class=\"anchor\" href=\"#mpifileutils\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>mpiFileUtils</h1>\n<p>mpiFileUtils provides both a library called <a href=\"src/common/README.md\">libmfu</a> and a suite of MPI-based tools to manage large datasets, which may vary from large directory trees to large files. High-performance computing users often generate large datasets with parallel applications that run with many processes (millions in some cases). However those users are then stuck with single-process tools like cp and rm to manage their datasets. This suite provides MPI-based tools to handle typical jobs like copy, remove, and compare for such datasets, providing speedups of up to 20-30x.  It also provides a library that simplifies the creation of new tools or can be used in applications.</p>\n<p>Documentation is available on <a href=\"http://mpifileutils.readthedocs.io\" rel=\"nofollow\">ReadTheDocs</a>.</p>\n<h2>\n<a id=\"user-content-daos-support\" class=\"anchor\" href=\"#daos-support\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>DAOS Support</h2>\n<p>mpiFileUtils supports a DAOS backend for dcp, dsync, and dcmp. Custom serialization and deserialization for DAOS containers to and from a POSIX filesystem is provided with daos-serialize and daos-deserialize. Details and usage examples are provided in <a href=\"DAOS-Support.md\">DAOS Support</a>.</p>\n<h2>\n<a id=\"user-content-contributors\" class=\"anchor\" href=\"#contributors\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Contributors</h2>\n<p>We welcome contributions to the project.  For details on how to help, see our <a href=\".github/CONTRIBUTING.md\">Contributor Guide</a></p>\n<h3>\n<a id=\"user-content-copyrights\" class=\"anchor\" href=\"#copyrights\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Copyrights</h3>\n<p>Copyright (c) 2013-2015, Lawrence Livermore National Security, LLC.\nProduced at the Lawrence Livermore National Laboratory\nCODE-673838</p>\n<p>Copyright (c) 2006-2007,2011-2015, Los Alamos National Security, LLC.\n(LA-CC-06-077, LA-CC-10-066, LA-CC-14-046)</p>\n<p>Copyright (2013-2015) UT-Battelle, LLC under Contract No.\nDE-AC05-00OR22725 with the Department of Energy.</p>\n<p>Copyright (c) 2015, DataDirect Networks, Inc.</p>\n<p>All rights reserved.</p>\n<h2>\n<a id=\"user-content-build-status\" class=\"anchor\" href=\"#build-status\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Build Status</h2>\n<p>The current status of the mpiFileUtils master branch is <a href=\"https://travis-ci.org/hpc/mpifileutils\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/76717f664d99534173ac7e9fb8e904b0e4bd14fbd51ac6969a88de2e6e86a94f/68747470733a2f2f7472617669732d63692e6f72672f6870632f6d706966696c657574696c732e706e673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/hpc/mpifileutils.png?branch=master\" style=\"max-width:100%;\"></a>.</p>\n",
        "stargazers_count": 104,
        "subscribers_count": 23,
        "topics": [],
        "updated_at": 1621475795.0
    },
    {
        "data_format": 2,
        "description": "Modular C++ Toolkit for Performance Analysis and Logging. Profiling API and Tools for C, C++, CUDA, Fortran, and Python. The C++ template API is essentially a framework to creating tools: it is designed to provide a unifying interface for recording various performance measurements alongside data logging and interfaces to other tools.",
        "filenames": [
            "docker/cpu/spack.yaml",
            "docker/gpu/spack.yaml"
        ],
        "full_name": "NERSC/timemory",
        "latest_release": "v3.1.0",
        "readme": "<h1>\n<a id=\"user-content-timemory\" class=\"anchor\" href=\"#timemory\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>timemory</h1>\n<h2>\n<a id=\"user-content-timing--memory--hardware-counter-utilities-for-c--c--cuda--python\" class=\"anchor\" href=\"#timing--memory--hardware-counter-utilities-for-c--c--cuda--python\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Timing + Memory + Hardware Counter Utilities for C / C++ / CUDA / Python</h2>\n<p><a href=\"https://travis-ci.org/NERSC/timemory\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9505e1c9d1da422846396830ac218c61bb3343ebe5402ffb3b05b52558266d67/68747470733a2f2f7472617669732d63692e6f72672f4e455253432f74696d656d6f72792e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/NERSC/timemory.svg?branch=master\" style=\"max-width:100%;\"></a>\n<a href=\"https://ci.appveyor.com/project/jrmadsen/timemory/branch/master\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4a833ca1c608ec560c59f2db36c4ea6c9c466102cba6505d53e6fcd6deaa3d7c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38786b37326f6f7477736566693863312f6272616e63682f6d61737465723f7376673d74727565\" alt=\"Build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/8xk72ootwsefi8c1/branch/master?svg=true\" style=\"max-width:100%;\"></a>\n<a href=\"https://codecov.io/gh/NERSC/timemory\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/87983d45b3e2381d7edd4ba6c892d41b4aeddd939663bcf2fb8cc60d29d4496f/68747470733a2f2f636f6465636f762e696f2f67682f4e455253432f74696d656d6f72792f6272616e63682f6d61737465722f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/NERSC/timemory/branch/master/graph/badge.svg\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://github.com/NERSC/timemory\">timemory on GitHub (Source code)</a></p>\n<p><a href=\"https://timemory.readthedocs.io\" rel=\"nofollow\">timemory General Documentation (ReadTheDocs)</a></p>\n<p><a href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\">timemory Source Code Documentation (Doxygen)</a></p>\n<p><a href=\"https://cdash.nersc.gov/index.php?project=TiMemory\" rel=\"nofollow\">timemory Testing Dashboard (CDash)</a></p>\n<p><a href=\"https://github.com/NERSC/timemory-tutorials\">timemory Tutorials</a></p>\n<p><a href=\"https://github.com/NERSC/timemory/wiki\">timemory Wiki</a></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>GitHub</td>\n<td><code>git clone https://github.com/NERSC/timemory.git</code></td>\n</tr>\n<tr>\n<td>PyPi</td>\n<td><code>pip install timemory</code></td>\n</tr>\n<tr>\n<td>Spack</td>\n<td><code>spack install timemory</code></td>\n</tr>\n</tbody>\n</table>\n<h2>\n<a id=\"user-content-purpose\" class=\"anchor\" href=\"#purpose\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Purpose</h2>\n<p>The goal of timemory is to create an open-source performance measurement and analyis package\nwith modular and reusable components which can be used to adapt to any existing C/C++\nperformance measurement and analysis API and is arbitrarily extendable by users within their\napplication.\nTimemory is not just another profiling tool, it is a profling <em>toolkit</em> which streamlines building custom\nprofiling tools through modularity and then utilizes the toolkit to provides several pre-built tools.</p>\n<p>In other words, timemory provides many pre-built tools, libraries, and interfaces but, due to it's modularity,\ncodes can re-use only individual pieces -- such as the classes for measuring different timing intervals, memory usage,\nand hardware counters -- without the timemory \"runtime management\".</p>\n<h2>\n<a id=\"user-content-building-and-installing\" class=\"anchor\" href=\"#building-and-installing\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building and Installing</h2>\n<p>Timemory uses a standard CMake installation.\nSeveral installation examples can be found in the <a href=\"https://github.com/NERSC/timemory/wiki/Installation-Examples\">Wiki</a>. See the <a href=\"https://timemory.readthedocs.io/en/develop/installation.html\" rel=\"nofollow\">installation documentation</a> for detailed information on the CMake options.</p>\n<h2>\n<a id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Documentation</h2>\n<p>The full documentation is available at <a href=\"https://timemory.readthedocs.io\" rel=\"nofollow\">timemory.readthedocs.io</a>.\nDetailed source documentation is provided in the <a href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\">doygen</a>\nsection of the full documentation.\nTutorials are available in the <a href=\"https://github.com/NERSC/timemory-tutorials\">github.com/NERSC/timemory-tutorials</a>.</p>\n<h2>\n<a id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Overview</h2>\n<p><strong><em>The primary objective of the timemory is the development of a common framework for binding together software\nmonitoring code (i.e. performance analysis, debugging, logging) into a compact and highly-efficient interface.</em></strong></p>\n<p>Timemory arose out of the need for a universal adapator kit for the various APIs provided several existing tools\nand a straight-forward and intuitive method for creating new tools. Timemory makes it possible to bundle\ntogether deterministic performance measurements, statistical performance\nmeasurements (i.e. sampling), debug messages, data logging, and data validation into the same interface for\ncustom application-specific software monitoring interfaces, easily building tools like <code>time</code>,\n<code>netstat</code>, instrumentation profilers, sampling profilers, and writing implementations for MPI-P, MPI-T, OMPT,\nKokkosP, etc.</p>\n<p>Timemory provides a front-end <a href=\"https://timemory.readthedocs.io/en/develop/api/library.html\" rel=\"nofollow\">C/C++/Fortran API</a>\nand <a href=\"https://timemory.readthedocs.io/en/develop/api/python.html\" rel=\"nofollow\">Python API</a> which allows arbitrary selection\nof 50+ different components from timers to hardware counters to interfaces with third-party tools. This is all\nbuilt generically from the toolkit API with type-safe bundles of tools such as:\n<code>component_tuple&lt;wall_clock, papi_vector, nvtx_marker, user_bundle&gt;</code>\nwhere <code>wall_clock</code> is a wall-clock timer,\n<code>papi_vector</code> is a handle for hardware counters,\n<code>nvxt_marker</code> creates notations in the NVIDIA CUDA profilers, and\n<code>user_bundle</code> is a generic component which downstream users can insert more components into at runtime.</p>\n<p>Performance measurement components written with timemory are arbitrarily scalable up to any number of threads and\nprocesses and fully support intermixing different measurements at different locations within the program -- this\nuniquely enables timemory to be deployed to collect performance data at scale in HPC because highly detailed collection can\noccur at specific locations within the program where ubiquitous collection would simulatenously degrade performance\nsignificantly and require a prohibitive amount of memory.</p>\n<p>Timemory can be used as a backend to bundle instrumentation and sampling tools together, support serialization to JSON/XML,\nand provide statistics among other uses. It can also be utilized as a front-end to invoke\ncustom instrumentation and sampling tools. Timemory uses the abstract term \"component\" for a structure\nwhich encapsulates some performance analysis operation. The structure might encapsulate function\ncalls to another tool, record timestamps for timing, log values provided by the application,\nprovide a operator for replacing a function in the code dynamically, audit the incoming arguments\nand/or outgoing return value from function, or just provide stubs which can be overloaded by the linker.</p>\n<h3>\n<a id=\"user-content-visualization-and-analysis\" class=\"anchor\" href=\"#visualization-and-analysis\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Visualization and Analysis</h3>\n<p>The native output format of timemory is JSON and text; other output formats such as XML are also supported.\nThe text format is intended to be human readable. The JSON data\nis intended for analysis and comes in two flavors: hierarchical and flat. Basic plotting capabilities are\navailable via <code>timemory-plotting</code> but users are highly encouraged to use <a href=\"https://github.com/hatchet/hatchet\">hatchet</a>\nfor analyzing the heirarchical JSON data in pandas dataframes. <a href=\"https://github.com/hatchet/hatchet\">Hatchet</a> supports\nfiltering, unions, addition, subtractions, output to <code>dot</code> and flamegraph formats, and an interactive Jupyter notebook.\nAt present, timemory supports 45+ metric types for analysis in Hatchet.</p>\n<h3>\n<a id=\"user-content-categories\" class=\"anchor\" href=\"#categories\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Categories</h3>\n<p>There are 4 primary categories in timemory: components, operations, bundlers, and storage. Components provide\nthe specifics of how to perform a particular behavior, operations provide the scaffold for requesting that\na component perform an operation in complex scenarios, bundlers group components into a single generic handle,\nand storage manages data collection over the lifetime of the application. When all four categories are combined,\ntimemory effectively resembles a standard performance analysis tool which passively collects data and provides\nreports and analysis at the termination of the application. Timemory, however, makes it <em>very easy</em> to subtract\nstorage from the equation and, in doing so, transforms timemory into a toolkit for customized data collection.</p>\n<ol>\n<li>\n<strong><em>Components</em></strong>\n<ul>\n<li>Individual classes which encapsulate one or more measurement, analysis, logging, or third-party library action(s)</li>\n<li>Any data specific to one instance of performing the action is stored within the instance of the class</li>\n<li>Any configuration data specific to that type is typically stored within static member functions which return a reference to the configuration data</li>\n<li>These classes are designed to support direct usage within other tools, libraries, etc.</li>\n<li>Examples include:\n<ul>\n<li>\n<code>tim::component::wall_clock</code> : a simple wall-clock timer</li>\n<li>\n<code>tim::component::vtune_profiler</code> : a simple component which turns the VTune Profiler on and off (when VTune is actively profiling application)</li>\n<li>\n<code>tim::component::data_tracker_integer</code> : associates an integer values with a label as the application executes (e.g. number of loop iterations used somewhere)</li>\n<li>\n<code>tim::component::papi_vector</code> : uses the PAPI library to collect hardware-counters values</li>\n<li>\n<code>tim::component::user_bundle</code> : encapsulates an array of components which the user can dynamically manipulate during runtime</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Operations</em></strong>\n<ul>\n<li>Templated classes whose primary purpose is to provide the implementation for performing some action on a component, e.g. <code>tim::operation::start&lt;wall_clock&gt;</code> will attempt to call the <code>start()</code> member function on a <code>wall_clock</code> component instance</li>\n<li>Default implementations generally have one or two public functions: a constructor and/or a function call operator\n<ul>\n<li>These generally accept any/all arguments and use SFINAE to determine whether the operation can be performed with or without the given arguments (i.e. does <code>wall_clock</code> have a <code>store(int)</code> function? <code>store()</code>?)</li>\n</ul>\n</li>\n<li>Operations are (generally) not directly utilized by the user and are typically optimized out of the binary</li>\n<li>Examples include:\n<ul>\n<li>\n<code>tim::operation::start</code> : instruct a component to start collection</li>\n<li>\n<code>tim::operation::sample</code> : instruct a component to take individual measurement</li>\n<li>\n<code>tim::operation::derive</code> : extra data from other components if it is available</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Bundlers</em></strong>\n<ul>\n<li>Provide a generic handle for multiple components</li>\n<li>Member functions generally accept any/all arguments and use operations classes to correctly to handle differences between different capabilities of the components it is bundling</li>\n<li>Examples include:\n<ul>\n<li><code>tim::auto_tuple</code></li>\n<li><code>tim::component_tuple</code></li>\n<li><code>tim::component_list</code></li>\n<li><code>tim::lightweight_tuple</code></li>\n</ul>\n</li>\n<li>Various flavors provide different implicit behaviors and allocate memory differently\n<ul>\n<li>\n<code>auto_tuple</code> starts all components when constructed and stops all components when destructed whereas <code>component_tuple</code> requires an explicit start</li>\n<li>\n<code>component_tuple</code> allocates all components on the stack and components are \"always on\" whereas <code>component_list</code> allocates components on the heap and thus components can be activated/deactivated at runtime</li>\n<li>\n<code>lightweight_tuple</code> does not implicitly perform any expensive actions, such as call-stack tracking in \"Storage\"</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong><em>Storage</em></strong>\n<ul>\n<li>Provides persistent storage for multiple instances of components over the lifetime of a thread in the application</li>\n<li>Responsible for maintaining the hierarchy and order of component measurements, i.e. call-stack tracking</li>\n<li>Responsible for combining component data from multiple threads and/or processes and outputting the results</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: <code>tim::lightweight_tuple</code> is the recommended bundle for those seeking to use timemory as a toolkit for implementing custom tools and interfaces</p>\n</blockquote>\n<h2>\n<a id=\"user-content-features\" class=\"anchor\" href=\"#features\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Features</h2>\n<ul>\n<li>C++ Template API\n<ul>\n<li>Modular and fully-customizable</li>\n<li>Adheres to C++ standard template library paradigm of \"you don't pay for what you don't use\"</li>\n<li>Simplifies and facilitates creation and implementation of performance measurement tools\n<ul>\n<li>Create your own instrumentation profiler</li>\n<li>Create your own instrumentation library</li>\n<li>Create your own sampling profiler</li>\n<li>Create your own sampling library</li>\n<li>Create your own execution wrappers</li>\n<li>Supplement timemory-provided tools with your own custom component(s)</li>\n<li>Thread-safe data aggregation</li>\n<li>Aggregate collection over multiple processes (MPI and UPC++ support)</li>\n<li>Serialization to text, JSON, XML</li>\n</ul>\n</li>\n<li>Components are composable with other components</li>\n<li>Variadic component bundlers which maintain complete type-safety\n<ul>\n<li>Components can be bundled together into a single handle without abstractions</li>\n</ul>\n</li>\n<li>Components can store data in any valid C++ data type</li>\n<li>Components can return data in any valid C++ data type</li>\n</ul>\n</li>\n<li>C / C++ / CUDA / Fortran Library API\n<ul>\n<li>Straight-forward collection of functions and macros for creating built-in performance analysis to your code</li>\n<li>Component collection can be arbitrarily inter-mixed\n<ul>\n<li>E.g. collect \"A\" and \"B\" in one region, \"A\" and \"C\" in another region</li>\n</ul>\n</li>\n<li>Component collection can be dynamically manipulated at runtime\n<ul>\n<li>E.g. add/remove \"A\" at any point, on any thread, on any process</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Python API\n<ul>\n<li>Decorators and context-managers for functions or regions in code</li>\n<li>Python function profiling</li>\n<li>Python line-by-line profiling</li>\n<li>Every component in <code>timemory-avail</code> is provided as a stand-alone Python class\n<ul>\n<li>Provide low-overhead measurements for building your own Python profiling tools</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Python Analysis via <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\">pandas</a>\n</li>\n<li>Command-line Tools\n<ul>\n<li>\n<a href=\"source/tools/timemory-avail/README.md\">timemory-avail</a>\n<ul>\n<li>Provides available components, settings, and hardware counters</li>\n<li>Quick API reference tool</li>\n</ul>\n</li>\n<li>\n<a href=\"source/tools/timem/README.md\">timem</a> (UNIX)\n<ul>\n<li>Extended version of UNIX <code>time</code> command-line tool that includes additional information on memory usage, context switches, and hardware counters</li>\n<li>Support collecting hardware counters (Linux-only, requires PAPI)</li>\n</ul>\n</li>\n<li>\n<a href=\"source/tools/timemory-run/README.md\">timemory-run</a> (Linux)\n<ul>\n<li>Dynamic instrumentation profiling tool</li>\n<li>Supports runtime instrumentation and binary re-writing</li>\n</ul>\n</li>\n<li>\n<code>timemory-python-profiler</code>\n<ul>\n<li>Python function profiler supporting all timemory components</li>\n<li><code>from timemory.profiler import Profile</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-trace</code>\n<ul>\n<li>Python line-by-line profiler supporting all timemory components</li>\n<li><code>from timemory.trace import Trace</code></li>\n</ul>\n</li>\n<li>\n<code>timemory-python-line-profiler</code>\n<ul>\n<li>Python line-by-line profiler based on <a href=\"https://pypi.org/project/line-profiler/\" rel=\"nofollow\">line-profiler</a> package</li>\n<li>Extended to use components: cpu-clock, memory-usage, context-switches, etc. (all components which collect scalar values)</li>\n<li><code>from timemory.line_profiler import LineProfiler</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Instrumentation Libraries\n<ul>\n<li>\n<a href=\"source/tools/timemory-mpip/README.md\">timemory-mpip</a>: MPI Profiling Library (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ncclp/README.md\">timemory-ncclp</a>: NCCL Profiling Library (Linux-only)</li>\n<li>\n<a href=\"source/tools/timemory-ompt/README.md\">timemory-ompt</a>: OpenMP Profiling Library</li>\n<li>\n<a href=\"source/tools/timemory-compiler-instrument/README.md\">timemory-compiler-instrument</a>: Compiler instrumentation Library</li>\n<li>\n<a href=\"source/tools/kokkos-connector/README.md\">kokkos-connector</a>: Kokkos Profiling Libraries</li>\n</ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-versioning\" class=\"anchor\" href=\"#versioning\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Versioning</h2>\n<p>Timemory originated as a very simple tool for recording timing and memory measurements (hence the name) in C, C++, and Python and only supported\nthree modes prior to the 3.0.0 release: a fixed set of timers, a pair of memory measurements, and the combination of the two.\n<strong>Prior to the 3.0.0 release, timemory was almost completely rewritten from scratch</strong> with the sole exceptions of some C/C++ macro, e.g.\n<code>TIMEMORY_AUTO_TIMER</code>, and some Python decorators and context-manager, e.g. <code>timemory.util.auto_timer</code>, whose behavior were\nable to be fully replicated in the new release. Thus, while it may appear that timemory is a mature project at v3.0+, it\nis essentially still in it's first major release.</p>\n<h2>\n<a id=\"user-content-citing-timemory\" class=\"anchor\" href=\"#citing-timemory\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citing timemory</h2>\n<p>To reference timemory in a publication, please cite the following paper:</p>\n<ul>\n<li>Madsen, J.R. et al. (2020) Timemory: Modular Performance Analysis for HPC. In: Sadayappan P., Chamberlain B., Juckeland G., Ltaief H. (eds) High Performance Computing. ISC High Performance 2020. Lecture Notes in Computer Science, vol 12151. Springer, Cham</li>\n</ul>\n<h2>\n<a id=\"user-content-additional-information\" class=\"anchor\" href=\"#additional-information\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Additional Information</h2>\n<p>For more information, refer to the <a href=\"https://timemory.readthedocs.io/en/latest/\" rel=\"nofollow\">documentation</a>.</p>\n",
        "stargazers_count": 220,
        "subscribers_count": 12,
        "topics": [
            "python",
            "cpp",
            "cplusplus",
            "performance",
            "c",
            "cross-platform",
            "cross-language",
            "memory-measurements",
            "mpi",
            "cuda",
            "papi",
            "hardware-counters",
            "analysis",
            "roofline",
            "performance-measurement",
            "instrumentation-api",
            "gotcha",
            "cupti",
            "modular-design"
        ],
        "updated_at": 1621564278.0
    }
]
